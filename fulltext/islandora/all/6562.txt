EXPERIENCE AND EMOTIONAL FACE PROCESSING IN INFANCY By Kristina Safar Bachelor of Arts in Psychology, York University, 2009 Master of Arts in Psychology, Ryerson University, 2012 A dissertation presented to Ryerson University in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the program of Psychology

Toronto, Ontario, Canada 2017 © Kristina Safar 2017   

Experience and Emotional Face Processing AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A DISSERTATION I hereby declare that I am the sole author of this dissertation. This is a true copy of the dissertation, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this dissertation to other institutions or individuals for the purpose of scholarly research I further authorize Ryerson University to reproduce this dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my dissertation may be made electronically available to the public.  



ii

Experience and Emotional Face Processing


Abstract Experience and Emotional Face Processing in Infancy Doctor of Philosophy, 2017 Kristina Safar Psychology Ryerson University Experience is suggested to shape the development of emotion processing abilities in infancy. The current dissertation investigated the influence of familiarity with particular face types and emotional faces on emotional face processing within the first year of life using a variety of metrics. The first study examined whether experience with a particular face type (own- vs. other-race faces) affected 6- and 9-month-old infants' attentional looking preference to fearful facial expressions in a visual paired-comparison (VPC) task. Six-month-old infants showed an attentional preference for fearful over happy facial expressions when expressed by own-race faces, but not other race-faces, whereas 9month-old infants showed an attentional preference for fearful expressions when expressed by both own-race and other-race faces, suggesting that experience influences how infants deploy their attention to different facial expressions. Using a longitudinal design, the second study examined whether exposure to emotional faces via picture book training at 3 months of age affected infants' allocation of attention to fearful over happy facial expressions in both a VPC and ERP task at 5 months of age. In the VPC task, 3and 5-month-olds without exposure to emotional faces demonstrated greater allocation of attention to fearful facial expressions. Differential exposure to emotional faces revealed a potential effect of training: 5-month-olds infants who experienced fearful faces showed an attenuated preference for fearful facial expressions compared to infants who iii

Experience and Emotional Face Processing experienced happy faces or no training. Three- and 5-month-old infants did not, however, show differential neural processing of happy and fearful facial expressions. The third study examined whether 5- and 7-month-old infants can match fearful and happy faces and voices in an intermodal preference task, and whether exposure to happy or fearful faces influences this ability. Neither 5- nor 7-month-old infants showed intermodal matching of happy or fearful facial expressions, regardless of exposure to emotional faces. Overall, results from this series of studies add to our understanding of how experience influences the development of emotional face processing in infancy.

iv

Experience and Emotional Face Processing Acknowledgments I would like to extend a tremendous thank you to Dr. Margaret Moulson for her extensive time, commitment, guidance, and support in completing this dissertation and throughout my academic career. The expertise and research skills I have acquired over the course of graduate school are because of your dedication to my academic development. Thank you for your constant encouragement and reassurance along the way. I am also grateful to all the members of the BEE lab, especially the BEE lab research assistants for your extensive help with all projects over the years. Working with such a hard working and enthusiastic group of fellow students and researchers has been a wonderful experience. To all the families and infants who participated in all the studies, I truly appreciate your willingness to contribute to science, time, effort and interest in infant development. This research could not have been completed without you. Finally to my family, I cannot thank you enough for your endless support, encouragement and love. To Sebastian, thank you for your constant encouragement when I need it most, love and confidence in me always.

v

Experience and Emotional Face Processing Table of Contents Author's Declaration. ..................................................................................................... ii Abstract ......................................................................................................................... iii Acknowledgements ........................................................................................................ v Table of Contents ........................................................................................................... vi List of Tables ................................................................................................................ viii List of Figures ................................................................................................................ ix List of Appendices .......................................................................................................... x Chapter 1 General Introduction... ....................................................................................... 1 Chapter 2 - Study 1 Introduction ....................................................................................................... 29 Method .............................................................................................................. 34 Results ............................................................................................................... 39 Discussion ......................................................................................................... 43 Chapter 3 - Study 2 Introduction... ................................................................................................... 47 Method .............................................................................................................. 55 Results ............................................................................................................... 63 Discussion ......................................................................................................... 81 Chapter 4 ­ Study 3 Introduction... ................................................................................................... 87 Method... .......................................................................................................... 92

vi

Experience and Emotional Face Processing Results ............................................................................................................... 98 Discussion... .................................................................................................... 105 Chapter 5 General Discussion... ...................................................................................... 108 Appendices.................................................................................................................. 117 References ................................................................................................................... 162

vii

Experience and Emotional Face Processing List of Tables Table 1. Difference Score Analysis by Emotion and Condition............................ 69 Table 2. Average Numbers of Good Trials by Emotion and Condition ........................ 103

viii

Experience and Emotional Face Processing List of Figures Figure 1. Example of VPC task (own-race Caucasian faces) in Study 1 ...................... 38 Figure 2. Infant mean proportion looking time to fear in Study 1 ................................ 41 Figure 3. Example of VPC task in Study 2 ................................................................... 59 Figure 4. ERP trial structure in Study 2 ........................................................................ 61 Figure 5. Mean proportion looking time to fear in Study 2 .......................................... 67 Figure 6. Grand averaged event-related potential waveforms at 3 months of age ......... 72 Figure 7. Grand averaged event-related potential waveforms for 5-month-olds in the fearful training condition............................................................................. 75 Figure 8. Grand averaged event-related potential waveforms for 5-month-olds in the happy training condition... ................................................................................ 77 Figure 9. Grand averaged event-related potential waveforms for 5-month-olds in the no-training condition... ............................................................................... 79 Figure 10. Example of intermodal matching task in Study 3... ..................................... 97 Figure 11. Mean proportion looking time to the congruent happy and fearful expression in Study 3... ................................................................................... 100 Figure 12. Corrected proportion looking time to the congruent expression in Study 3 .............................................................................................................. 104

ix

Experience and Emotional Face Processing List of Appendices Appendix A: Consent form Study 1............................................................................117 Appendix B: Demographic Questionnaire .................................................................. 121 Appendix C: Caucasian and East Asian Face Exposure Questionnaire ....................... 122 Appendix D: Consent form Studies 2 and 3................................................ 131 Appendix E: Example of picture books ..................................................... 137 Appendix F: Reading schedule .................................................................................... 151 Appendix G: Reading log ............................................................................................ 152 Appendix H: Compliance Scale............................................................... 156 Appendix I: Consent form Study 3 .............................................................................. 158

x

Experience and Emotion Processing CHAPTER 1 General Introduction Infants' ability to perceive, discriminate, and interpret facial expressions of emotion is critical for infant-caregiver interaction and the development of attachment, emotion regulation, and later socio-emotional skills (Bornstein & Arterberry, 2003; Thompson, 1991; Tronick, 1989; Walker-Andrews & Dickson, 1997). An abundance of studies examining the development of emotion processing in infancy have focused on the developmental trajectory of the perception, discrimination, and recognition of facial expressions of emotion in infancy. These studies have established an approximate timeline for when emotion processing abilities may start to come online (see WalkerAndrews, 1997, for a review). Less is known, however, about what mechanisms underlie the development of infants' emotion processing abilities. Experience has been proposed to play an important role in the development of emotion processing abilities in infancy (Leppänen & Nelson, 2009; Nelson, 2001; Vaish, Grossmann, & Woodward, 2008). While studies have indirectly supported this view, little research has directly investigated how different types of experience may shape the development of emotion processing in infancy. It remains unclear whether exposure to particular face types (i.e., own-or otherrace faces11) or emotional faces influences infants' emotion processing abilities. The aim of this dissertation is to investigate the influence of familiarity with particular face types  1 In multiple disciplines, including anthropology, race is agreed to be improper terminology to refer to differences between human phenotypes (Edgar & Hunley, 2009; Lee et al., 2008; McKenzie & Crowcroft, 1996). Edgar and Hunley (2009) state, " race is not an accurate or productive way to describe human biological variation." However, throughout this dissertation the term race will be used to describe differences between particular face types, specifically in reference to the other-race effect (see Meissner & Brigham, 2001) as it is an established and frequently used word to refer to this phenomenon in the psychology literature.  1

Experience and Emotion Processing and emotional faces on different facets of emotional face processing within the first year of life. To investigate this we use a variety of metrics to assess emotion processing at the behavioural and neural level. Neural metrics assessing the influence of experience on emotion processing are necessary to elucidate underlying mechanisms fundamental to infants' emotional face processing abilities. This work will not only shed light on these neural mechanisms, but will also provide evidence necessary to evaluate recent hypotheses in the field. This introduction will first review the neural underpinnings of emotional face processing in adulthood. Second, the development of emotion processing in infancy, its neural underpinnings, and recent theoretical accounts of the development of emotion processing will be described. Lastly, empirical evidence will be outlined examining how experience shapes the development of various aspects of face and emotional face processing to provide necessary background for the present studies.  Neural underpinnings of emotion recognition in adulthood This section will outline the neural mechanisms underlying the perception and recognition of facial expressions of emotion in adulthood to provide a framework for understanding and considering neurological development in infancy. In adults, perception and recognition of facial expressions of emotion is a multistage process in the brain (Adolphs, 2002a). The perception of facial expressions involves the initial visual processing of structural information from faces, largely involving the medial and lateral areas of the occipital cortices that process basic structural information from the face (Adolphs, 2002a; 2002b). Beyond the perception of information inherent to the structural aspects of facial expressions, emotion recognition involves conceptual knowledge



2

Experience and Emotion Processing acquired via past experiences (Adolphs, 2002b). For example, recognition of fearful facial expressions requires not only perceptual information inherent to the structure of the expression itself, but also knowledge as to the emotional signal value of fear. Recognition of emotional faces involves the reconstruction and coordination of conceptual information (e.g., emotional label, vocal expression) via widespread neural representations initially associated with the perception of facial expressions (Adolphs, 2002b). Key neural structures critically implicated in the perception and recognition of facial expressions are discussed below. Two parallel pathways for processing facial expressions of emotion exist: a subcortical and cortical route depending on whether facial expressions are perceived unconsciously or consciously (Adolphs, 2002b; Morris et al., 1996; 1998; Morris, Öhman, Dolan, 1998). The subcortical route involves neural connections from the retina to extrastriate areas, such as the superior colliculus, and pulvinar nucleus of the thalamus. This pathway does not involve the primary visual cortex (V1) (Adolphs, 2002a; 2002b). In particular, the amygdala in the medial temporal lobe has been found to play a key role during the subcortical processing of facial expressions, especially fear (Adolphs, 2002a; 2002b; Le Doux, 1996; 2000; 2003; Liddell et al., 2004; Whalen et al., 1998; 2004). Many studies have reported robust activation of the amygdala during the subconscious presentation of fearful faces (Whalen et al., 1998; 2004; Liddell et al., 2004). Thus, the amygdala as part of a subcortical route for emotional face processing seems to be critical in the early, rapid and automatic detection of facial expressions (especially fear faces) (Adolphs, 2002a; 2002b; LeDoux, 1996).



3

Experience and Emotion Processing The cortical pathway for processing consciously perceived facial expressions of emotion first involves area V1 via the lateral geniculate nucleus of the thalamus (Adolphs, 2002a; Reinagel & Reid, 2000). Subsequently, the lateral areas of the inferior occipital gyrus, fusiform gyrus and posterior superior temporal gyrus positioned in the occipiotemporal cortex are important for more detailed face processing (Adolphs, 2002b; Haxby, Hoffman, & Gobbini, 2000; 2002). The lateral fusiform gyrus (FG) is critical for detecting faces from objects, face-specific information processing (e.g., face configuration, eye detection) and identity recognition (Haxby et al., 2000; 2002; Kanwisher, McDermott, & Chun, 1997). The posterior superior temporal sulcus (STS) is implicated in the processing of variant features of faces, such as facial expressions (Adolphs, 2002a; 2002b; Critchley et al., 2000; Hasselmo, Rolls & Baylis, 1989; Haxby et al., 2000; 2002). Considering its anatomical position, the inferior occipital gyrus is suggested to feed early visual information from the V1 to the lateral FG and posterior STS (Haxby et al., 2000; 2002). Event-related potential (ERP) studies corroborate these findings. An early component called the P1 occurs approximately 100 ms following face presentation and is presumed to reflect early global perceptual processing of faces (Batty & Taylor, 2003; Halit, de Haan & Johnson, 2000; Itier & Taylor, 2002). The amplitude of the P1 is influenced by emotion: neutral and surprised faces show smaller amplitudes compared to happy, angry, fearful, sad, and disgust faces (Batty & Taylor, 2003). The N170 component, occurring approximately 170 ms following face presentation over occipitotemporal cortex, reflects face-specific structural encoding (Allison, Puce, & McCarthy, 2000; Haxby, et al., 2002). The amplitude of the N170 is modulated by



4

Experience and Emotion Processing emotional faces. In particular, the N170 amplitude is larger for fearful relative to happy faces (Batty & Taylor, 2003; Leppänen, Moulson, Vogel-Farley, & Nelson, 2007; Rossignol, Philippot, Douilliez, Crommelinck & Campanella, 2005). One interpretation of these ERP findings is that enhanced early perceptual processing in the occipitotemporal cortices in response to emotional faces might reflect modulatory effects of the amygdala (Batty & Taylor, 2003; Leppänen, et al., 2007). The amygdala is implicated not only in unconscious processing of emotional faces, but also conscious processing of emotional faces via the cortical pathway (for reviews, see Adolphs, 2002a; 2002b; Le Doux 1996). The amygdala plays an important role in the detection, evaluation, and allocation of attention to salient emotional faces, especially fear faces (Adolphs, Tranel, Damasio, & Damasio, 1995; Davis & Whalen, 2001; Morris, Frith, Perrett, & Rowland, 1996; Thomas et al., 2001; Whalen et al., 2004; see Whalen & Phelps, 2009 for a review). Extensive connections exist between the amygdala and cortical brain regions, including connections to and from occpitotemporal visual cortices (Aggleton, Burton, & Passingham, 1980; Field, Johnston, Gati, Menon, & Everling, 2008). Activation of the amygdala in response to happy and fearful facial expressions predicts patterns of neural activity in the occipitotemporal cortices (Morris et al., 1998; Morris, Öhman, & Dolan, 1998), suggesting that the amygdala may modulate activity in the occipitotemporal cortices to enhance perception (Adolphs, 2002b; Emery & Amaral, 2000; Le Doux, 1996; Öhman, Carlsson, Lundqvist, & Ingvar, 2007). Amygdala response may allocate greater attention to salient emotional faces (e.g., fearful faces) by engaging attentional systems to modulate perceptual processing (see Adolphs et al., 1995; Davis & Whalen, 2001; see Pessoa & Adolphs, 2010; see Phelps & LeDoux,



5

Experience and Emotion Processing 2005; see Phillips, Drevets, Rauch, & Lane, 2003). Another way that the amygdala may enhance perception of emotionally salient faces is through projections to neurons in the basal forebrain (nucleus basalis of Meynert). These projections release acetylcholine onto sensory cortical regions, increasing excitability of neurons, and thereby enhancing visual processing (Bently, Vuilleumier, Thiel, Drive, & Dolan, 2003; Whalen, 1998). Additionally, the amygdala is suggested to coordinate conceptual information (e.g. emotional memory, reward value) with perceptual information, via activation of numerous cortical and subcortical areas (Iidaka et al., 2001; see Adolphs, 2002b for a review). The orbitofrontal cortex (OFC) may also be involved in evaluating the emotional reward value of faces, together with the amygdala (Schultz, Tremblay, Hollerman, 2000; Rolls, 1999; 2000; 2004). Damage to the orbitofrontal cortex is related to impairment in processing facial expressions of emotion (Hornak, Rolls, & Wade, 1996; Blair, Morris, Frith, Perrett, & Dolan, 1999; Hornak, et al., 2003). In particular, Hornak, Rolls and Wade (1996) found deficits in recognition of facial and vocal expressions in patients with orbitofrontal cortex damage. The OFC is particularly implicated in processing negative facial expressions, especially angry faces (Blair, Morris, Frith, Perrett & Dolan, 1999). The right anterior cingulate cortex (ACC) is involved in controlling attention and maintaining focus of attention in order to regulate cognitive and emotional processing (Bush, Luu & Posner, 2000; Etkin, Egner, & Kalisch, 2011). Thus, the ACC is implicated in evaluating and attending to the salience of emotional information, such as facial expressions, and control of emotional response via connections to frontal regions such as, the orbitofrontal cortex, anterior insula, and subcortical regions such as, the amygdala,



6

Experience and Emotion Processing nucleus accumbens, hypothalamus, hippocampus, as well as the periaqueductal gray (Amaral, Behniea, & Kelly, 2003; Bush et al., 2000; Kim, Kroger, & Kim, 2011). Taken together, these studies reveal that emotional face processing involves extensive brain regions, which participate in multiple levels of perceptual and cognitive processing. Particularly, these structures are involved in early perceptual processing important for discrimination of facial expressions, controlling attention to emotional stimuli, evaluating the emotional meaning of emotional information, and controlling emotional response (Adolphs, 2002b). The development of emotion processing in infancy The sections to follow will focus on the development of emotion recognition, encompassing topics such as the importance of emotion processing in infancy, the developmental trajectory of discrimination and recognition of facial expressions in infancy, the neural mechanisms underlying these abilities, and theoretical models of development. Importance of emotion processing in infancy. The recognition of facial expressions of emotion is critical for infant-caregiver communication, development of attachment patterns, and emotion regulation early in life (Barth & Bastiani, 1997; Denham et al., 2012; Izard et al., 2001; Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002; Tronick, 1989; Schultz, Izard, Ackerman & Youngstrom, 2001; Walker-Andrews & Dickson, 1997). Only days after birth neonates demonstrate the ability to discriminate and imitate happy, sad and surprised facial expressions when expressed by live models (Field, Woodson, Greenberg, & Cohen, 1982; Field, Woodson, Cohen, Greenberg, Garcia & Collins, 1983). As early as 2 to 3



7

Experience and Emotion Processing months of age infants demonstrate the ability to perceive caregiver facial expressions and respond through the use of their own facial expressions (Nelson, 1987). In particular, mothers tend to express greater positive (joy, surprise, interest) than negative emotions towards their young infants (3 months), and infants respond similarly in expression type, and tend to imitate brow and mouth region movement (Malatesta & Haviland, 1982). Frequent observation of mothers' smiling expressions fosters the emergence of social smiling between 2 to 3 months of age (Izard, et al., 1995; Lavelli & Fogel, 2005; Oster, Hegley & Nagel, 1992; Messinger & Fogel, 2007). Infants typically use social smiling to engage in voluntary communicative interactions with their primary caregivers (Kopp, 1989; Malatesta, Grigoryev, Lamb, Albin, & Culver, 1986). These interactions may initiate positive and synchronized exchanges of emotion, which serves to establish secure attachment (Bowlby, 1969/1982). Consistent positive exchanges of facial expressions of emotion and dependable caregiving allow infants to form reliable expectations of their caregivers' behaviour, which become internalized throughout the first year. These positive "internal working models" allow infants to regulate their own internal states according to caregiver expectations, and serve as a foundation for the development of secure attachment relationships (Bowlby, 1969/1982; Fox & Calkins, 2003; Thompson, 1991). Moreover, the type of attachment relationship (secure vs. insecure) is thought to influence emotion processing, particularly in potentially threatening scenarios involving the caregiver (e.g., separation anxiety) or when signals of potential threat are unclear, such as fearful facial expressions (Peltola et al., 2015; Vrticka & Vuilleumier, 2012). Accordingly, Peltola and colleagues examined whether 7-montholds' allocation of attention to fearful facial expressions predicted infant-caregiver



8

Experience and Emotion Processing attachment patterns at 14 months of age. Greater attention to fearful faces at 7 months compared to happy, neutral, and a scrambled face was associated with attachment security at 14 months, whereas greater attention to neutral compared to fearful faces was associated with attachment insecurity. It was suggested that insecurely attached infants might not show enhanced sensitivity to fearful faces in order to reduce emotional overarousal. Alternatively, insecurely attached infants may be generally less sensitive to fearful facial expressions (Peltola et al., 2015). Caregivers of securely attached infants also promote understanding of emotional expressions through open dialogue with their infants and young children and provide many exemplars of emotional faces during interactions (see Laible & Thompson, 1998; Steele, Steele & Croft, 2008). Laible and Thompson (1998) observed that age and attachment security predicted 2.5- to 6-year-olds' understanding of negative emotions. Similarly, securely attached infants at 12 months of age tend to demonstrate a better understanding of basic and more complex emotions (i.e., disappointment) at 6 years of age (Steele, Steele, Croft, & Fonagy, 1999). Steele and colleagues (2008) later replicated and extended these findings, such that attachment security at 12 months of age was found to be associated with an understanding of basic and complex emotions at both 6 and 11 years of age. Results were interpreted in light of the importance of early emotional learning during infant-mother interactions for shaping internal representations of attachment critical for later emotion understanding (Steele et al., 2008). An understanding of emotional faces is also related to greater emotion regulation abilities, positive social interactions, and academic success in childhood (Barth & Bastiani, 1997; Denham et al., 2012; Izard et al., 2001; Schultz et al., 2001). Denham and



9

Experience and Emotion Processing colleagues (2012) found that increased emotion knowledge was associated with higher levels of self-regulation skills (i.e., behaviour inhibitory control, social-emotional competence) and academic success in 3- to 4-year-old children. Furthermore, Izard and colleagues (2001) showed that emotion knowledge at 5 years of age predicted different aspects of social behaviour, including self-control at 9 years of age in socially disadvantaged children. Findings suggested that adept emotion recognition abilities foster positive peer relationships, academic success, and self-regulation. Taken together, this evidence suggests that the perception, discrimination, and recognition of facial expressions of emotion throughout the first year of life are imperative for the development of many more sophisticated socio-emotional abilities. Behavioural development. An abundance of literature has investigated infants' recognition of facial expressions of emotion during the first year (see Walker-Andrews, 1997 for a review). Shortly after birth newborns are able to discern happy, fearful, sad and surprised facial expressions (Farroni, Menon, Rigato & Johnson, 2007; Field et al., 1982; Field et al., 1983). Barrera and Maurer (1981) found that 3-month-old infants were able to discriminate between happy and angry facial expressions. Moreover, 3-montholds discriminate between happy and surprised, and surprised from sad facial expressions (Young-Browne et al., 1977). By 6 months of age infants demonstrate longer fixations in response to joy as compared to neutral and angry serially presented facial expressions (LaBarbera, Izard, Vietze, & Parisi, 1976). In sum, these results suggest that within the first 6 months of life infants are able to discriminate between many different facial expressions of emotion.



10

Experience and Emotion Processing Emerging at 4 months of age infants demonstrate the ability to categorize facial expressions of emotion For example, Kaneshige and Haryu (2015) investigated 4-montholds ability to categorize happy and angry facial expressions. Infants were habituated to three different female faces expressing happy or angry facial expressions. During the test phase, infants were shown a novel female face posing the familiar expression and novel expression. Results revealed that infants categorized the happy and angry facial expressions. By 7 months of age infants are able to categorize happy and surprised facial expressions of emotion (Caron, Caron & Myers, 1982), and consistently categorize happy facial expressions when tested against fearful expressions, but not vice versa (Ludemann, 1991; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Nelson, Morse, & Leavitt, 1979). For example, Nelson and Dolgin (1985) examined 7-month-old infants' ability to categorize happy and fearful facial expressions when expressed by multiple female faces. Infants demonstrated categorization after habituation to happy facial expressions (signaled by increased looking at the fearful face during test), whereas infants did not demonstrate categorization after habituation to fearful facial expressions (no increased looking at the happy face during test). This asymmetrical pattern of results has been documented several times (Kotsoni, de Haan, & Johnson, 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Nelson et al., 1979; Safar & Moulson, 2017), and has been interpreted as potentially due to a spontaneous preference for fear interfering with the expected novelty preference for the happy face (Ludemann & Nelson, 1988; Nelson & Dolgin, 1985). Many studies have now observed that young infants show a spontaneous attentional preference for happy facial expressions (Bayet et al., 2015; Farroni et al.,



11

Experience and Emotion Processing 2007; LaBarbera et al., 1976; Wilcox & Clayton, 1968), while emerging between 5 and 7 months of age infants show an attentional preference for fearful facial expressions (de Haan & Nelson, 1998; Kotsoni et al., 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola, Leppänen, Mäki, & Hietanen, 2009). These spontaneous attentional preferences often lead to asymmetrical findings in categorization paradigms. By approximately 5 to 7 months of age infants can match facial and vocal expressions of emotion intermodally (Soken & Pick, 1992; 1999; Walker, 1982; WalkerAndrews, 1986; 1988; 2008). By 7 months infants demonstrate robust intermodal matching of happy, sad, and angry facial and vocal expressions of emotion (Soken & Pick, 1992; 1999; Walker, 1982; Walker-Andrews, 1986; 1988; 2008). This ability is not disrupted when the facial and vocal information is expressed asynchronously (Walker, 1982), the lower half of the face is not shown (Walker-Andrews, 1986), or when infants are presented with facial movement only (i.e., point-light displays of facial expressions; Soken & Pick, 1992; 1999). By the end of the first year infants reference their caregivers and appear to alter their approach/avoidance behaviour according to caregivers' facial expressions of emotion during the presentation of novel toys or ambiguous situations (Klinnert, 1984; Feinman & Lewis, 1983; Sorce, Emde, Campos, & Kinnert, 1985; Walden & Ogan, 1988; see Walker-Andrews, 1997 for a review). Klinnert (1984) observed that 12- and 18-month-old infants referenced their mothers' facial expressions in response to remote novel toys. Specifically, at both ages infants did not approach the toys when she expressed fearful face, but did so when she expressed a happy face. Similarly using a visual cliff, Sorce and colleagues (1985) found that 12-month-old infants did not cross



12

Experience and Emotion Processing the deep side of the cliff when their mother expressed fearful or angry facial expressions, whereas most infants crossed when their mother expressed expressions of happiness or interest. Finally, Walden and Ogan (1988) investigated the developmental trajectory of social referencing in response to remote novel toys with 6- to 9-month-old, 10- to 13month-old and 14- to 22-month-old infants. Findings indicated that younger infants show increased looking to caregivers' positive displays of emotions compared to older infants who more frequently attend to caregivers' fearful faces. Furthermore, infants did not show behavioural regulation (i.e., approach vs. avoidance of the novel toy) in response to negative facial expressions until 10 to 13 months of age, and did not demonstrate inhibition of behavioural (e.g., touching a toy) response until 14 months of age. Overall, it is evident that infants' emotion processing abilities become rapidly more sophisticated throughout the first year. Early in life infants demonstrate sensitivity to and discriminate between different emotional faces. Just prior to the second half of the first year infants may begin to recognize the emotional signal value of emotional faces, as evidenced by their ability to categorize and intermodally match expressions of emotion. By the end of the first year infants can use emotional information expressed by faces to regulate their behaviour in response to novel toys and ambiguous scenarios (WalkerAndrews, 1997). Neural development. Research investigating the neural underpinnings of emotional face processing in infancy is limited due to restrictions with using methods like fMRI. However, studies using alternative methods, such as ERPs and near-infrared spectroscopy (fNIRS), along with evidence from other species has provided evidence about the neural mechanisms that are involved in emotion processing and a basic



13

Experience and Emotion Processing understanding of the anatomical and functional developmental trajectory of these mechanisms. Single-cell recording in the inferior temporal cortex (a visual area containing neurons particularly responsive to faces) of infant and adult macaque monkeys' reveals similar responsiveness of cells to visual stimuli and stimulus selectivity, however responses were weaker in magnitude and delayed in infants as compared to adult macaques (Rodman, Scalaidhe, & Gross, 1993). Moreover, the development of neural connections between the primary visual cortex and visual areas in the temporal cortex undergo protracted and vast changes prior to reaching maturity (Barone, Dehay, Berland, Bullier & Kennedy, 1995; Kennedy, Bullier & Dehay, 1989). In macaques, neurogenesis of the amygdala is completed by second month of gestation and by 2 weeks of age connections between the amygdala and cortical areas that subserve emotion processing are relatively established (Amaral, 2003; Amaral & Bennet, 2000; Bauman & Amaral, 2008). Although anatomical structures mature fairly early, neural connections between structures and myelination of axons within these structures continue to undergo specialization into adulthood (Herschkowitz, 2000; Machado & Bachevalier, 2003). For example, in infant macaques adult-like connections from the inferior temporal cortex (TE and TEO) to the amygdala are already established, however infant macaques show additional transient connections from region TEO to the amygdala that are not seen in adult macaques (Machado & Bachevalier, 2003; Webster, Ungerleider & Bachevalier, 1991). Additionally, myelination of the stria terminalis, an efferent connection of the amygdala is not adult-like until several years after birth (Gibson, 1991; see Machado & Bachevalier, 2003 for a review). Taken together this evidence suggests that visual



14

Experience and Emotion Processing cortices, and the amygdala appear to be mature very early in life in macaques, however these regions continue a protracted developmental course before becoming fully mature. The orbitofrontal cortex reaches maturity later than the amygdala (Machado & Bachevalier, 2003). Webster, Bachevalier and Ungerleider (1994) observed that connections between the OFC and inferior temporal cortex are mature 1 week after birth. Yet still connections from many frontal regions, including the OFC to inferior temporal cortex show ongoing development until 7 weeks of age. Moreover, additional transient connections from frontal cortical regions (e.g., lateral and ventral frontal cortices, and cingulate cortex) to the inferior temporal cortex appear to exist in infant, but not in adult macaques; suggesting protracted development (see Machado & Bachevalier, 2003; Rodman & Consuelos, 1994). In the human infant, increases in glucose metabolism in the parietal, temporal, and primary visual cortices, and basal ganglia indicate that these regions are functional by 2 to 3 months of age (Chugani, 1998). Using positron emission topography (PET) Tzourio-Mazoyer and colleagues (2002) found greater activation of the FG, inferior occipital cortex, and right inferior parietal cortex in response to faces compared to a visual control stimulus in 2-month-old infants. The STS was not activated in response to faces at 2 months of age (Tzourio-Mazoyer et al., 2002), however the STS is found to be responsive to faces in 5-month-old infants; suggesting its functional maturity emerges within this period of time (Otsuka et al., 2007). Consistent with this finding, using fNIRS, Nakato, Otsuka, Kanazawa, Yamaguchi and Kakigi (2011) examined hemodynamic response in 6-to 7-month-old infants while they viewed happy and angry facial expressions of emotion. In response to happy faces, findings revealed increased



15

Experience and Emotion Processing hemodynamic response following disappearance of the face. In contrast, increased hemodynamic response to angry faces dissipated after the face disappeared. Increased responses to happy and angry faces were found over left and right temporal regions, corresponding to the STS respectively. Whether the amygdala is functional in human infants has not been directly investigated due to imaging limitations. However, findings from the infant macaque research described above and indirect evidence from studies with human infants suggests that the amygdala might be developed at birth (Amaral, 2003; Amaral & Bennett, 2000; Bauman & Amaral, 2008; see Johnson, 2001; Balaban, 1995). For instance, 5-month-olds show a startle reflex when presented with bursts of white noise that produces an eye blink response (Balaban, 1995). The size of this eye-blink response is modulated by facial expressions of emotion (Balaban, 1995). Modulatory effects of the startle reflex are mediated by amygdala circuitry in adults and non-human primates (Angrilli et al., 1996; Funayama, Grillon, Davis, & Phelps, 2001; Pissiota et al., 2003). Thus, it is suggested that the amygdala might also mediate the startle reflex in response to facial expressions of emotion in infancy (see Leppänen & Nelson, 2006). The prefrontal cortex is involved in processing social information, such as faces, eye gaze direction, and facial expressions early in infancy (see Grossmann, 2013 for review). Two-month-old infants show greater activation of the medial prefrontal cortex when presented with faces compared to a visual control stimulus (Tzourio-Mazoyer et al., 2002). Using fNIRS, Grossmann and colleagues (2008) found that 4-month-olds showed greater neural activation in the medial prefrontal cortex in response to a dynamic face that established eye contact and smiled, compared to a face that averted its gaze and smiled.



16

Experience and Emotion Processing Additionally, using fNIRS Minagawa-Kawai and colleagues (2009) found that 12-monthold infants show increased neural activation in the orbitofrontal cortex (OFC) in response to viewing videos of their own mother and unfamiliar female smiling at them compared to expressing no emotion (neutral expression). Activation of the OFC was increased when infants viewed their own mother's smile as compared to an unfamiliar female smiling. Results of these studies suggest that early in the first year the prefrontal cortex already plays a functional role as part of a network processing social and affective information. Many ERP studies have found that particular ERP components including the N290 and P400 recorded at occipitotemporal sites and negative central (Nc) recorded at fronto-central sites differ in response to faces vs. non-face objects in infancy (see de Haan, Johnson, & Halit, 2003 for a review). The N290 is a negative-going deflection over medial posterior electrode sites with a mean latency of 290 ms post-stimulus onset. It is presumed to be a precursor to the development of the N170 component described earlier involved in the structural encoding of faces (Allison, Puce, & McCarthy, 2000; Haxby et al., 2002). Similarly, the P400 is a positive-going inflection over lateral posterior scalp areas with a mean latency of 400 ms post-stimulus onset. Like the N290, the P400 is also presumed to be a developmental precursor to the adult N170 as it responds faster to faces compared to objects (de Haan & Nelson, 1999). These two components are selectively responsive to the species of a face at 3 months (e.g., human vs. monkey faces) and the orientation of both human and monkey faces at 6 months of age. By 12 months the N290 and P400 respond specifically to the orientation of human faces, resembling the adult N170 more closely at this age (Halit et al., 2003).



17

Experience and Emotion Processing The Nc is a negative-going deflection occurring at approximately 400-800 ms in 6- to 7-month-old infants (de Haan et al., 2003; Nelson & de Haan, 1996). It is presumed to reflect activation of the anterior cingulate cortex and prefrontal cortex (Reynolds & Richards, 2005). The Nc reflects an attentional response to salient and familiar stimuli. De Haan and Nelson (1997) found a larger Nc response when 6-month-old infants viewed their own mothers' faces as compared to stranger faces. These results were interpreted to suggest that the larger Nc amplitude indexes recognition of familiar faces. However, it should be noted that no difference in Nc amplitude was found when infant mothers' faces looked similar to stranger faces, suggesting that infants did not recognize their mothers' faces as more familiar than the stranger faces (see de Haan, Johnson, & Halit, 2003; de Haan & Nelson, 1997). The Nc has also been shown to reflect infrequently presented stimuli in visual memory/odd ball tasks (Courchesne, Ganz, & Norcia, 1981; de Haan et al., 2002; Nelson, 1994). For example, 4- to 7-month-old infants show greater Nc amplitude in response to a less frequently presented face as compared to a frequently presented face when viewed in rapid succession (Courchesne et al., 1981). As mentioned earlier, neural activity over occipitotemporal scalp regions differentiates between facial expressions of emotion in adults (Batty & Taylor, 2003). However, few studies have examined whether the N290 and P400 components are influenced by facial expressions (Kobiella, Grossman, Reid, & Striano 2008; Leppänen et al., 2007; Leppänen, Kauppinen, Peltola, & Hietanen, 2007). Leppänen and colleagues (2007) found that the P400 was larger in response to fearful as compared to happy and neutral faces, however no effects on the N290 were observed. Furthermore, differences in



18

Experience and Emotion Processing amplitude of the N290 and P400 have been found in response to fearful as compared to angry facial expressions (Kobiella et al., 2008). The Nc is consistently larger in amplitude to fearful relative to happy facial expressions in 7-month-old infants (de Haan, Belsky, Reid, Volein, & Johnson, 2004; Leppänen et al, 2007; Nelson and de Haan, 1996; Peltola, Leppänen, Maki & Hietanen, 2009). Jessen and Grossman (2015) have recently extended these findings by demonstrating that 7-month-old infants show larger Nc amplitude for fearful vs. happy facial expressions regardless of whether facial expressions are presented consciously or subconsciously. Given that the amygdala is implicated in the subconscious processing of fearful facial expressions via the subcortical route in adults (Adolphs, 2002a; 2002b) and has many reciprocal connections with the anterior cingulate and prefrontal cortex (Aggleton et al., 1980; Field, Johnston, Gati, Menon, & Everling, 2008), it is speculated that the amygdala might underlie the processing of subconsciously presented facial expressions at 7 months of age (Jessen & Grossman, 2015). Interesting, this finding was not replicated in 5-month-olds, suggesting that amygdala function might emerge between 5 and 7 months of age (Jessen & Grossman, 2016). In summary, the above neuroimaging and ERP findings with human infants suggest functionality of particular neural structures in infancy implicated in face and emotional face processing in adults (Johnson, Grossman & Farroni, 2008). However, it is also evident that the maturity of neural mechanisms implicated in face and emotional face processing continue to become more specialized until appearing adult-like (Johnson et al., 2008; Leppänen & Nelson, 2006; Leppänen & Nelson, 2009).



19

Experience and Emotion Processing Theoretical perspectives on the development of emotion processing There are numerous theoretical views that attempt to explain what drives the development of emotion processing in the first year of life. These views differ in the extent to which they argue that experience influences this ability (Leppänen & Nelson, 2006; Werker, 1989). A maturational or innate perspective argues that emotion processing abilities mature irrespective of experiential influence due to their evolutionary significance (Nelson, 1987; Öhman, 2002; Werker, 1989). Emotion perception and recognition are governed by prewired neural mechanisms (e.g., amygdala) that preferentially respond to facial expressions because they are biologically important signals (Öhman, 2002). Consistent with this perspective it has been suggested that these prewired neural mechanisms might be specially designated to process facial expressions of emotion, developing with little experience (Nelson, 1987). Empirical evidence for this view is derived from research suggesting that facial expressions of emotion are universal in nature, such that they are expressed and recognized pan-culturally (Ekman, 1972; Ekman, Sorenson, & Friesen, 1969; Izard, 1971). Accordingly, many studies have found that participants from multiple cultures, including remote preliterate areas (i.e., South East Highlands of New Guinea) isolated from Western culture, recognize and produce facial expressions of emotion similarly (Ekman et al., 1970; Ekman & Friesen, 1971; Ekman, Sorenson, and Friesen, 1969; Izard, 1971). Additionally, this innate perspective is supported by studies showing that newborns are sensitive to facial expressions of emotion only hours after birth (Field et al., 1982; Field et al., 1983). This early sensitivity has been interpreted as an innate preparedness to selectively and rapidly attend to



20

Experience and Emotion Processing threatening emotional versus non-threatening emotional information in infancy (DeLoache & Lobue, 2009; Lobue & DeLoache, 2010). An intermediate view of the development of emotion recognition considers that neural mechanisms underlying this ability might be to a limited extent innate, however experience influences and enhances the complete development of this ability (Nelson, 1987; Werker, 1989). Leppänen and Nelson (2006; 2009; 2012) proposed that a nonspecialized experience-expectant mechanism might govern the development of emotion processing. Initially, emotion recognition might be primarily mediated by the subcortical route, particularly involving the amygdala in signifying a face as emotionally significant (Leppänen & Nelson, 2006; 2009; 2012). Importantly, during this time the developing system "expects" to receive experience with facial expressions of emotion to become more sophisticated and reach maturity (Leppänen & Nelson, 2009; 2012). The maturity of cortical regions critical for emotion processing (occipitotemporal, parietal, orbitofrontal) allows for the acquisition of more fine-tuned representations of speciestypical facial expressions in their environment; thus, experience is critical for the refinement and specialization of the emotion processing neural network (Leppänen & Nelson, 2006). Greater attention to particular facial expressions of emotion coincides with a time point in development when infants are likely to receive exposure to a wider repertoire of facial expressions expressed in their social environment (Campos, Kermoian, & Zumbahlen, 1992; Vaish et al., 2008). It is further proposed that individual differences in exposure to different facial expressions of emotion in the environment are critical in the continual shaping of this more refined neural network (founded subcortical-cortical connections) important for



21

Experience and Emotion Processing emotion processing throughout development (Leppänen & Nelson, 2009; 2012). This experience-dependent mechanism is not limited by a sensitive period in development, such that the emotion processing neural network can be shaped by individual experiences across the lifespan (Leppänen & Nelson, 2009). Consistent with this experiential perspective, research with adults has reported that emotion recognition is shaped by experience, such that recognition accuracy varies cross-culturally. Specifically, adults show an in-group advantage for recognition of emotions expressed by members of one's own cultural group due to slight differences in cultural learning (Elfenbein & Ambady, 2002; Elfenbein & Ambady, 2003a; 2003b; Elfenbein, Beaupré, Lévesque & Hess, 2007; Elfenbein, Mandal, Ambady, Harizuka & Kumar, 2004; Kang & Lau, 2012). In the following sections, we review evidence for the effects of experience on face processing and emotion processing during development. Experience affects the development of face processing. Face experience shapes the development of face processing during the first year of life (Nelson, 2001). For instance, exposure to particular face types shapes infants' attentional preferences to different faces. Shortly after birth newborns show a looking bias for their mother's face compared to a female stranger's face (Bushnell, Sai, & Mullin, 1989; Field et al., 1984). Bushnell (2001) has shown that the strength of newborns' visual preference for their mother over a stranger face is correlated with time spent viewing her face. Consistent with this finding 3-month-old infants' raised by female primary caregivers show an attentional bias for female vs. male faces (Quinn, Yahr, Kuhn, 2002). Three-month-olds also show an attentional preference for own-race over other-race faces, while newborns show no preference (Bar-Haim, Ziv, Lamy, & Hodes, 2006; Kelly et al., 2005).



22

Experience and Emotion Processing Interestingly, 3-month-olds only prefer female faces if females are of the infants' own race, whereas no preference is found in newborns (Quinn et al., 2008). These results are likely due to the increased amount of exposure infants have with female relative to male faces, and own- vs. other-race faces (Rennels & Davis, 2008; Sugden, Mohamed-Ali, & Moulson, 2014). Additionally, experience with particular face types tunes face perception abilities beginning in infancy. This pattern of typical development is perceptual narrowing, which is a process of maintained ability or increasing specialization for faces from familiar categories that comes at the expense of diminished ability for faces from unfamiliar categories (Pascalis et al., 2002; Pascalis et al., 2005; Scott et al., 2007). Pascalis, de Haan, and Nelson (2002) investigated whether perceptual narrowing influences face processing in 6- and 9-month-old infants. Infants' ability to discriminate between familiar and novel monkey and human faces was tested using a visual paired-comparison (VPC) task. Discrimination between individuals of both species was only evident at 6 months of age. Nine-month-olds demonstrated discrimination of two human faces but not two monkey faces. Thus, perceptual narrowing influences processing of own- vs. otherspecies face types, and appears in the second half of the first year (Pascalis et al., 2002). A similar effect is seen in the processing of own- versus other-race faces during the first year of life (see Anzures et al., 2013 for a review; Kelly et al., 2007; Kelly et al., 2009). For example, Kelly and colleagues (2007) found that 3-month-old Caucasian infants were able to discriminate between faces of their own race and between faces of other races, whereas 9-month-old Caucasian infants were only able to discriminate between faces of their own race. This specialization for own-race faces that emerges in infancy is a



23

Experience and Emotion Processing precursor to the "other-race effect" (ORE) in adulthood, where adults demonstrate greater recognition memory for faces of their own race compared to faces of other races (for a review, see Meissner & Brigham, 2001). Experience affects the development of emotion processing. Experience with familiar face types also seems to facilitate emotion recognition in infancy (Barrera & Maurer, 1981; Bayet et al., 2015; Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002; Vogel et al., 2011; Walker-Andrews et al., 2011). Barrera and Maurer (1981) found that a greater number of 3-month-old infants demonstrated discrimination between smiling and frowning faces when shown static pictures of their mothers versus static faces of strangers. Similarly, Walker-Andrews and her colleagues have demonstrated that 3.5-month-old infants are able to categorize happy and sad expressions if they are expressed by their mother and father, but not strangers (WalkerAndrews et al., 2011). They have also shown that 3.5-month-old infants can successfully match facial and vocal expressions of emotion when expressed by their mothers, but not female strangers or their fathers (Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002). Finally, Bayet and colleagues have shown that the spontaneous preference for happy faces observed early in the first year is found only when the emotions are expressed by female, but not male, faces (Bayet et al., 2015), likely because as mentioned earlier, infants have more exposure to female than male faces (Rennels & Davis, 2008; Sugden et al., 2014). One study has demonstrated that perceptual narrowing influences processing of facial expressions of emotion when expressed by own- and other-race faces in infancy (Vogel et al., 2012). Vogel and colleagues (2012) found differences in brain activity



24

Experience and Emotion Processing when 5- and 9-month-old infants were presented with own- and other-race faces expressing happy or sad facial and vocal expressions. Specifically, 9-month-olds showed race-specific differentiated neural processing of emotions when expressed by own-race vs. other-race faces; in contrast, 5-month-olds showed similar neural processing of emotion when expressed by own- and other-race faces. These findings suggest that the discrimination of emotional expressions is influenced by the increasing specialization for own-race faces that is characteristic of perceptual narrowing. Experience with emotional faces specifically facilitates emotion processing in infancy (Bornstein, Arterberry, Mash, & Manian, 2011; Kuchuk, Vibbert, & Bornstein, 1986; see Nelson, 1987; 2001). Kuchuk, Vibbert, and Bornstein (1986) observed that 3month-old infants show greater sensitivity to different intensities of smiling faces when their mothers engaged their infants' attention while smiling during at home interactions. Thus, early sensitivity to smiling faces is related to exposure to happy faces. Studies have observed that infants of depressed mothers demonstrate difficulty discriminating between (Bornstein et al., 2011) and habituating to (Hernandez-Reif, Field, Diego, Vera & Pickens, 2006) different facial expressions of emotion. For instance, Bornstein and colleagues (2011) found that 5-month-olds of non-depressed mothers were able to discriminate between happy and neutral facial expressions, whereas infants of clinically depressed mothers were not. The authors suggested that infants of depressed mothers might experience a lack of positive affect during interactions with their mothers. Similarly, Hernandez-Reif and colleagues (2006) observed that 3-month-old infants of depressed mothers habituate slower to short films of females expressing happy facial and vocal expressions, compared to infants of non-depressed mothers. It was suggested that



25

Experience and Emotion Processing infants of depressed mothers might show decreased attention to or difficulty perceiving happy facial/vocal expressions, as demonstrated by longer time to habituate because positive emotions are less familiar. Finally, de Haan and colleagues (2004) investigated maternal affect disposition (as an index of infants' emotional rearing environment) and 7month-old infants' neural and behavioural responses to neutral, fearful, and happy facial expressions of emotion. Infants of mothers who had a positive emotional disposition demonstrated longer looking time towards fearful facial expressions than happy facial expressions and showed a larger Nc amplitude ERP response to fearful as compared to happy facial expressions. This attentional preference for fearful facial expressions was not found for infants of mothers that had a negative emotional disposition. This suggests that early experience with happy facial expressions through mothers' disposition influences infants' attentional preference to attend to the relatively more novel fearful facial expressions (de Haan et al., 2004). Studies investigating the effects of physical abuse on emotion recognition in childhood provide evidence that increased exposure to angry faces shapes processing of angry facial expressions at the behavioural and neural level (Pollak, Cicchetti, Hornung, & Reed, 2000; Pollak & Kistler, 2002; Pollak, Messner, Kistler, & Cohn, 2009; Pollak & Sinha, 2002). Physically abused children are primarily exposed to negative facial expressions, such as anger in their home rearing environment and tend to be isolated from social interactions, thus decreasing the opportunity to learn about facial expressions (see Pollak & Sinha, 2002). These adverse experiences shape emotion processing abilities in these children (Pollak et al., 2000; Pollak & Kistler, 2002; Pollak, Klorman, Thatcher & Cicchetti, 2001; Pollak & Sinha, 2002; Pollak & Tolley-Schell, 2003). Pollak and Kistler



26

Experience and Emotion Processing (2002) found that 9-year-old children reared in physically abusive households were more sensitive in their recognition of angry facial expressions as compared to non-abused children, and their perceptual category representation of angry facial expressions is wider than non-abused children. However, processing of happy, sad and fearful facial expressions was intact in abused children (Pollak & Kistler, 2002). Moreover, physically abused children demonstrate greater allocation of attention to angry over fearful and happy facial expressions as indicated by greater amplitude of the P300, a positive ERP component reflecting allocation of attention (Pollak et al., 2001). Similarly, physically abused children show difficulty disengaging their attention from angry, but not happy facial expressions as compared to non-abused children also indicated by greater P300 amplitude (Pollak & Tolley-Schell, 2003). Thus, children of physically abusive parents develop a heightened sensitivity to angry facial expressions likely due to increased exposure to displays of anger indicative of threat as compared to non-abused children (Pollak et al., 2001; Pollak & Sinha, 2002; Pollak & Tolley-Schell, 2003). The Current Studies The current studies are designed to examine the effect of experience with particular face types and emotional faces on emotional face processing in infancy using three different metrics. Few studies have examined whether experience with a particular face category, particularly own- and other-race faces, influences emotion processing in infancy. Likewise, few studies have investigated whether exposure to emotional faces influences emotion processing in infancy, and to our knowledge none have used a training approach to examine this. The first study in this dissertation investigates whether a particular face type (own- vs. other-race faces) influences infants' attentional preference



27

Experience and Emotion Processing for fearful facial expressions in a visual paired-comparison (VPC) task (Chapter 2). Using a longitudinal design, the second study examines whether experience through training with emotional faces (happy or fearful) affects infants allocation of attention to fearful compared to happy facial expressions in both a VPC and ERP task (Chapter 3). Lastly, the third study explores whether infants can match fearful and happy faces and voices, and using the same approach as in Study 2, whether exposure to fearful or happy faces influences this ability in an intermodal preference task (Chapter 4). Because a developmental shift in allocation of attention to fearful faces is one of the most consistent findings in the literature (de Haan & Nelson, 1998; Kotsoni, et al., 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009), and because theoretical accounts of the development of emotion processing have suggested that experience with happy and fearful faces modulates attention to and recognition of fearful faces in infancy (Leppänen & Nelson, 2009; 2012), we chose to focus on infants' processing of happy and fearful faces in the current set of studies.







28

Experience and Emotion Processing CHAPTER 2 Face Experience and the Attentional Bias for Fearful Expressions in Infancy Faces are an important part of the infant's social world. Although newborns display preferences for face-like stimuli (Johnson & Morton, 1991; Turati, Simion, Milani, & Umiltà, 2002) and rudimentary face discrimination ability (Pascalis, de Schonen, Morton, De Ruelle, & Fabre-Grenet, 1995), their face processing ability undergoes significant development during the first year of life. There is now ample evidence that experience tunes the development of the face-processing system. Experience influences how infants deploy their attention to different faces. For example, soon after birth infants show a looking preference for their mother's face compared to a female stranger's face (Bushnell, Sai, & Mullin, 1989; Field, Cohen, Garcia, & Greenberg, 1984) and this preference is dose-dependent: newborn infants who see their mother more show a larger preference for her face (Bushnell, 2001). Three-month-old infants show a preference for female over male faces, unless they have a male primary caregiver (Quinn, Yahr, Kuhn, Slater, & Pascalis, 2002), and a preference for own-race over other-race faces, whereas newborn infants do not (Kelly et al., 2005). These attentional biases are almost certainly driven by greater exposure to female and own-race faces early in the first year of life (Rennels & Davis, 2008; Sugden, Mohamed-Ali, & Moulson, 2014). Experience also influences infants' discrimination ability with different face types. For example, 6-month-old infants are able to discriminate both own-species and other-species (monkey) faces whereas 9-month-old infants are only able to discriminate own-species faces (Pascalis, de Haan, & Nelson, 2002). This latter example of experiential effects is termed perceptual narrowing, and is defined as maintained



29

Experience and Emotion Processing ability or increased specialization for familiar face types that comes at the cost of decreased ability with unfamiliar face types (Scott & Monesson, 2010; Scott, Pascalis, & Nelson, 2007). Perceptual narrowing has also been demonstrated for other-race faces (Kelly et al., 2007). For example, Kelly and colleagues (2007) found that 3-month-old infants were able to discriminate between faces of their own race and between faces of other races, whereas 9-month-old infants were only able to discriminate between faces of their own race. Relatively fewer studies have examined the effects of experience on processing of facial emotion in the first year of life (Barrera & Maurer, 1981; Bayet et al., 2015; Vogel, Monesson, & Scott, 2012; Walker-Andrews, Krogh-Jespersen, Mayhew, Coffield, 2011). This paucity of studies may stem from the theoretical perspective that emotion recognition is universal, implying that experience may not play an important role in shaping this ability (Ekman & Friesen, 1971; Ekman, Sorenson, & Friesen, 1969). However, studies that have examined the influence of experience on emotion recognition in infancy show that experience with familiar faces seems to facilitate the ability to discriminate and recognize facial expressions (Barrera & Maurer, 1981; Kahana-Kalman & Walker-Andrews, 2001; Walker-Andrews et al., 2011), and alters attentional preferences for particular facial expressions (Bayet et al., 2015). For example, Barrera and Maurer (1981) showed that 3-month-olds were better able to discriminate between happy and sad faces when their mother rather than a female stranger posed the expressions. Similarly, Walker-Andrews and her colleagues showed that 3.5-month-old infants are able to match happy and sad facial and vocal expressions of emotion when posed by their mothers, but not their fathers or unfamiliar females (Kahana-Kalman &



30

Experience and Emotion Processing Walker-Andrews, 2001; Montague & Walker-Andrews, 2002). Successful bimodal matching of unfamiliar faces does not emerge until 5-7 months of age (Walker-Andrews, 1997). Thus, familiarity with particular faces (i.e., mother's face) facilitates early emotion processing ability. There is also some evidence that differential experience with particular face types (e.g., own- vs. other-race; own- vs. other-species) influences infant emotion processing. Vogel and colleagues (2012) examined infants' neural responses to congruent and incongruent pairings of happy and sad faces with happy and sad voices using both ownrace and other-race faces. They found that 9-month-old infants, but not 5-month-olds, showed race-specific differential neural processing of own-race and other-race face/voice pairs. These findings suggest that emotion processing may be influenced by the increasing specialization for own-race faces that is characteristic of perceptual narrowing. Similarly, Lewkowitz and Ghazanfar (2006) found that 4- and 6-month-old infants demonstrate intermodal matching of other-species (i.e., macaque) facial expressions and vocalizations, but 8- and 10-month-old infants do not. More recently, however, Flom and colleagues (2009) showed that 6-, 18-, and 24-month-old infants all show evidence of intermodal matching of canine facial and vocal expressions (i.e., aggressive vs. nonaggressive expressions). This suggests that ability with other-species emotional expressions does not decline (Flom, Whipple, & Hyde, 2009), although the way in which infants display intermodal matching might differ by age. Thus, further research is necessary to determine how experience influences processing of emotion expressed by familiar and unfamiliar face types.



31

Experience and Emotion Processing The goal of this study was to examine further the influence of experience on infant emotion processing using a different metric than most previous studies-- specifically, how infants deploy their attention to different emotional expressions. It is well established that young infants show a spontaneous preference for happy over other facial expressions (Farroni, Menon, Rigato, & Johnson, 2007; LaBarbera, Izard, Vietze, & Parisi, 1976; Wilcox & Clayton, 1968), but a shift in attentional preference for fearful faces seems to happen between 5 and 7 months of age (de Haan & Nelson, 1998; Kotsoni, de Haan, & Johnson, 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola, Leppänen, Mäki, & Hietanen, 2009), Behaviourally, this ability seems to become robust by 7 months of age (de Haan & Nelson, 1998; Kotsoni, de Haan, & Johnson, 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola, Leppänen, Mäki, & Hietanen, 2009). For instance, 7-month-olds, but not 5-month-olds, show a spontaneous preference for fearful over happy expressions (Peltola et al., 2009). Additionally, 7month-olds demonstrate greater heart rate deceleration (Peltola, Leppänen, & Heitanen, 2011), and show reduced attention disengagement from fearful than happy or neutral expressions (Peltola, Leppänen, Palokangas, & Hietanen, 2008). At the neural level, 7month-old infants also show a larger Nc, an event-related potential (ERP) component that reflects attentional allocation to salient stimuli (Courchesne, Ganz, & Norcia, 1981), in response to fearful than happy expressions (de Haan, Belsky, Reid, Volein, Johnson, 2004; de Haan & Nelson, 1998; Leppänen, Moulson, Vogel-Farley, & Nelson, 2007; Moulson, Fox, Zeanah, & Nelson, 2009; Nelson & de Haan, 1996; Peltola et al., 2009). However, more recent behavioural evidence suggests that this attentional preference to fearful over happy faces may emerge earlier, as more recent findings show a fear bias by



32

Experience and Emotion Processing 5 months of age (Yrttiaho, Forssmann, Kaatiala & Leppänen, 2014; Forssman et al., 2014; Heck, Hock, White & Bhatt, 2016; 2017). It is currently unclear why a shift in allocation of attention to fearful expressions occurs. Initially it was assumed that the novelty of the fearful expression was responsible for this increased allocation of attention, but more recent research provides evidence against this interpretation (Peltola et al., 2008). Alternative explanations for the development of a fear bias are the development of an overall negativity bias (Vaish, Grossman, & Woodward, 2008), and the developing understanding that a fearful facial expression signals threat in the environment (Nelson, 1987; see Quinn et al., 2011). Thus, increased allocation of visual attention to fearful faces has been increasingly viewed as an index of infants' developing emotion processing ability. No studies have yet examined whether face category influences the attentional bias for fearful expressions. However, a recent study from Bayet and colleagues (2015) found that the earlier preference for happy faces is modified by face gender. Specifically, 3.5-month-old infants showed a looking preference for smiling over neutral expressions when expressed by female faces, but not when expressed by male faces (Bayet et al., 2015). This finding suggests that the way in which infants deploy their attention to different facial expressions is modified by familiarity with the types of faces expressing the emotions. In the current study, 6- and 9-month-old infants viewed own-race and other-race fearful expressions paired with happy expressions posed by the same individual. Their spontaneous looking preferences were measured. We chose to test infants at 6 and 9 months of age based on literature indicating an effect of experience on intermodal



33

Experience and Emotion Processing matching of emotions (Vogel et al., 2012), while keeping in consideration that increased attention to fearful faces becomes robust sometime between 5 and 7 months of age (Peltola et al., 2008; 2009; Yrttiaho et al., 2014; Forssman et al., 2014; Heck et al., 2016; 2017). Previous literature demonstrating that emotion processing is enhanced for familiar faces (e.g., mother's face ­ Barrera & Maurer, 1981; Kahana-Kalman & WalkerAndrews, 2001; Montague & Walker-Andrews, 2002) and familiar face types (e.g., female faces ­ Bayet et al., 2015) would lead us to hypothesize that infants will display an attentional bias for fearful expressions only for own-race faces. In contrast, if infants' deployment of attention to different facial expressions is influenced by perceptual narrowing in the same way that bimodal matching of emotions is (Vogel et al., 2012), we might expect 6-month-olds to show a fear preference for both own- and other-race faces and 9-month-olds to show a fear preference only for own-race faces. Method Participants Thirty-three 6-month-old infants (M age= 196.45 days, SD= 10.52, 19 boys) and 31 9-month-old infants (M age= 289.13 days, SD= 12.30, 16 boys) participated. All infants were born within (+/-) 4 weeks of their due date. All participants were recruited through the Infant and Child Studies database at Ryerson University. This database contains contact information for parents from a large, diverse metropolitan area who had previously expressed an interest in participating in developmental research. Recruitment sites for the database include large parent conventions and libraries. Per parent report, none of the infants had been diagnosed with visual impairment or clinical disorders (e.g., pervasive developmental disorders, fetal alcohol spectrum disorders). All participants



34

Experience and Emotion Processing were Caucasian. An additional 40 infants were tested, but their data were eliminated from analysis due to: a) infant fussiness (n = 8), b) experimenter error (n = 4), c) the infant was not Caucasian (n = 25), d) side-bias during testing (> 95% looking time to one side across all four trials; n = 2), or e) twin with another infant in the study (n = 1). Stimuli and Procedure All appointment times were scheduled when infants were most active and alert, as reported by the primary caregiver. Informed consent was attained from all parents/legal guardians (see Appendix A). The Demographic Questionnaire was administered to parents at their first visit. The questionnaire obtained general history and background information about the infant. Specifically, information was collected regarding the infant's birthdate, race, whether the infant was born within (+/-) 4 weeks of his/her expected due date, whether the infant was diagnosed with any clinical disorders (e.g., fetal alcohol syndrome) and/or visual impairment (see Appendix B). Infants then participated in a visual paired-comparison (VPC) task. The infant was seated on the parent's lap facing a computer screen. Parents wore a sleep mask during the task, in order to avoid the possibility of parent behaviour influencing infant looking behaviour. A video camera situated directly above the computer screen captured infant looking behaviour. The video signal was projected onto a second computer screen, which allowed the experimenter to monitor infant looking behaviour online during the course of the experiment, such that trials were started only when the infant was looking at the screen. Following the VPC task, parents completed a brief questionnaire assessing the infant's exposure to Caucasian and East Asian faces (see Appendix C) and reported the identity and race of up to six caregivers.



35

Experience and Emotion Processing Colour photographs of four female faces displaying the facial expressions happiness and fear were drawn from the MacBrain Face Stimulus Set (Tottenham et al., 2009). Only high intensity (i.e., open-mouthed) versions of each emotion were used. To ensure that the particular faces we chose expressed emotions of similar intensity, we examined validity ratings for the happy and fearful expressions of each face. Adults' accuracy at identifying the happy expression averaged 97.5% for the two Caucasian models and 99.5% for the two East Asian models; adults' accuracy at identifying the fearful expression averaged 61% for the two Caucasian models and 72% for the two East Asian models (Tottenham et al., 2009). These accuracies were all significantly above chance. Thus, happy and fearful emotions expressed by both Caucasian and East Asian models were highly recognizable. Two versions of the task were created, one with two Caucasian (own-race) faces and one with two East Asian (other-race) faces. Approximately half of the infants in each age group (6-month-olds, 9-month-olds) viewed the task with own-race faces; the other half viewed the task with other-race faces. The VPC task was run using E-Prime (Psychology Software Tools, 2002). Infants saw four trials that each lasted for a fixed length of 10 seconds from the onset of the stimulus. Each trial consisted of one female face expressing happy and fearful facial expressions presented side-by-side on the computer screen. From a viewing distance of 60cm, each face image subtended approximately 19 x 24 degrees of visual angle. The first pair of trials showed the same female face, with the left/right position of the happy and fearful expressions reversed from trial 1 to trial 2. The second pair of trials showed a second female face, with the left/right position of the happy and fearful expressions reversed from trial 3 to trial 4



36

Experience and Emotion Processing (Figure 1). Which female face was shown in the first versus second pair of trials was counterbalanced across infants. Whether the fearful face appeared on the left versus the right first was also counterbalanced across infants. Between trials, an attention-getting stimulus (a bouncing ball) appeared in the center of the screen to redirect the infant's attention to the screen.



37

Experience and Emotion Processing Figure 1. Example of VPC task (own-race Caucasian faces) in Study 1. Infants saw all four 10-second trials. Due to publishing restrictions these are not the exact Caucasian faces that infants were shown.





 

Trial 1 (10s)

Trial 2 (10s)

Trial 3 (10s)

Trial 4 (10s)



38

Experience and Emotion Processing The experimenter and a research assistant blind to condition and left-right position of the fearful facial expression coded infant looking time offline. Trials were coded frame-by-frame at 30 frames/second using Adobe Premiere Pro (v5.5). Interobserver reliability was r = .88 based on 20% of total infant looking time data. Results Proportion looking time to the fearful facial expression was calculated for each trial (looking time to fearful/[looking time to fearful + looking time to happy]) and averaged across the four trials. A 2 (age: 6 months vs. 9 months) x 2 (condition: own-race vs. other-race) ANOVA was conducted on mean proportion looking time to the fearful facial expression. There were no main effects of age (F(1, 60) = .323, p = .572) or condition (F(1, 60) = .227, p = .635). However, there was a significant interaction between age and condition (F(1, 60) = 4.88, p = .031), indicating that 6- and 9-month-old infants performed differently depending on whether they viewed own-race compared to otherrace faces. To determine which age group(s) in which condition(s) showed a fear preference, one-sample t-tests against chance were then conducted separately by age and condition. Six-month-old infants who viewed own-race faces (n = 17) demonstrated a significant looking preference for fearful facial expressions compared to happy facial expressions (M = .58, SD = .09, t(16) = 3.85, p = .001, two-tailed, d = .93). Fourteen of these 17 infants showed a preference for the fearful expression that was greater than 50%, p = .013 using a binomial test. In contrast, 6-month-old infants who viewed other-race faces (n = 16) did not demonstrate a significant looking preference for fearful facial expressions or happy facial expressions (M = .52, SD = .12, t(15) =



39

Experience and Emotion Processing .74, p = .471, two-tailed, d = .18), and only 11 of 16 infants showed a preference for the fearful expression greater than 50%, binomial probability, p = .21. Thus, 6-monthold infants allocate greater attention to fearful than happy expressions only when the emotions are expressed by own-race individuals. Nine-month-old infants who viewed own-race faces (n = 15) showed a significant looking preference for fearful facial expressions compared to happy facial expressions (M = .55, SD = .07, t(14) = 2.39, p = .031, two-tailed, d = .62), and 11 of the 15 infants showed a fear preference greater than 50%, p = .118 using a binomial test. Similarly, 9month-old infants who viewed other-race faces (n = 16) showed a significant looking preference for fearful facial expressions compared to happy facial expressions (M = .59, SD = .06, t(15) = 5.43, p = .0001, two-tailed, d = 1.37), with 14 of 16 infants showing a fear preference greater than 50%, (binomial probability, p = .004). Thus, 9-month-old infants, unlike 6-month-old infants, allocate greater attention to fearful expressions for both own-race (Caucasian) and other-race (East Asian) faces (see Figure 2).



40

Experience and Emotion Processing Figure 2. Infant mean proportion looking time to fear in Study 1. The dark gray bars represent infants who viewed same-race Caucasian faces. The light gray bars represent infants who viewed other-race East Asian faces. Error bars represent standard error of the mean.
0.7 Proportion Looking Time to Fear *** .58 .02 .52 .03

0.6

* .55 .02

*** .59 .02

0.5

Own-race Other-race

0.4

0.3 6 months Age 9 months



41

Experience and Emotion Processing Face Exposure We created two subscales based on the exposure questionnaire. Subscale 1 reflected exposure to Caucasian faces. Subscale 2 reflected exposure to East Asian faces. Questions were reverse-scored as necessary, such that for each scale 1 = little exposure to faces of this type and 4 = much exposure to faces of this type. We conducted a 2 (age: 6 months vs. 9 months) x 2 (face type: Caucasian vs. East Asian) ANOVA. We found a significant main effect of face type: Parents reported that their infants received significantly more exposure to Caucasian faces (M = 3.76, SD = 0.44) than East Asian faces (M = 1.42, SD = 0.52), F(1,59) = 508.52, p < .0000001, d= 4.84. There was no main effect of age, or an age x face type interaction. Thus, 6- and 9-month-old infants received similar exposure to Caucasian (own-race) and East Asian (other-race) faces. We also examined the race of the three most frequently experienced caregivers for each infant. Jayaraman, Fausey, and Smith (2015) found that across the first year of life, the three most frequently experienced individuals accounted for more than 80% of all face exposures on average. For all infants in this study, the most frequently experienced caregiver was Caucasian (in all cases, it was the infant's mother). The second most frequently experienced caregiver was Caucasian for all infants except one, whose father self-identified as three-quarters Caucasian and one-quarter Aboriginal. The third most frequently experienced caregiver was Caucasian for all infants except two; one infant's third caregiver was a grandmother who was half Caucasian and half Aboriginal and one infant's third caregiver was a nanny who was East Asian. These findings, combined with the findings from our brief exposure questionnaire, suggest that all of the infants who



42

Experience and Emotion Processing participated in this study had highly homogenous face experience consisting of primarily own-race faces. Discussion The current study is the first to investigate whether experience with own- and other-race faces influences how infants deploy their attention to different facial expressions at 6 and 9 months of age. Six-month-old infants demonstrated a looking preference for fearful facial expressions compared to happy facial expressions when expressed by own-race faces, but not when expressed by other-race faces. In contrast, 9month-old infants demonstrated a looking preference for fearful expressions when expressed by both own-race and other-race faces. The current findings are consistent with previous literature demonstrating that experience with familiar faces (e.g., mother) and face types (e.g., female faces) influences emotion processing (Barrera & Maurer, 1981; Bayet et al., 2015; Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002; Walker-Andrews et al., 2011). In particular, our finding that 6-month-olds show an attentional bias for fear only when expressed by a familiar face category (own-race faces) echoes the finding that 3month-olds show an attentional bias for happy only when expressed by another familiar face category (female faces; Bayet et al., 2015). Although the particular preference being examined differs due to the different ages in the two studies, these parallel findings suggest that attentional deployment to facial expressions is modified by the face experiences that infants accumulate during their daily lives. For instance, previous studies have reported significantly more exposure to own-race than other-race faces. Sugden and colleagues (2014) found that 1- and 3-month-



43

Experience and Emotion Processing old infants' face exposure was highly biased towards own-race faces: 96% of time spent exposed to faces consisted of own-race face exposure. Similarly, Rennels and Davis (2008) reported that approximately 92% of the time infants are exposed to same-race caregivers. Exposure data from the current study indicate that infants in this sample had similarly homogenous own-race face experience. The current findings suggest that this heavily biased exposure to own-race faces affects the attentional bias for fearful facial expressions at 6 months. How might experience with own-race faces influence the attentional bias for fearful facial expressions? A recent account posits that the change in sensitivity to fearful facial expressions in the first year of life reflects functional maturation of neural mechanisms underlying emotion processing and attention (i.e., maturation of connections between amygdala and prefrontal cortex), combined with enhanced experience with fearful facial expressions (Leppänen & Nelson, 2009; 2012). Infants become locomotive around 6 to 7 months of age; this increase in motor ability is associated with greater exemplars of facial expressions expressed by caregivers and increased caregiver monitoring and referencing on the part of the infant (Campos, Kermoian, & Zumbahlen, 1992; Vaish et al., 2008). Leppänen and Nelson (2009; 2012) suggested that the maturation of neural mechanisms that underlie emotion processing might give rise to a sensitive period in development, in which the developing system becomes more responsive to a wider array of facial expressions. Consequently, during this time associations between threatening social objects or situations and fearful facial expressions expressed by their caregivers may be more readily processed (Leppänen & Nelson, 2009; 2012). The current findings suggest that experience with a particular face type may be



44

Experience and Emotion Processing necessary for the emergence of the attentional bias to fear. Potentially, this bias is initially tied to familiar face types, but by 9 months it is generalized to faces with which infants have less experience. It is unclear how specific this pattern of results might be to the paradigm, specific emotions, or specific face types examined in the current study. We chose to examine the effects of experience on emotion processing using the attentional bias for fear because this finding is well established in the literature (Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009). However, by using only one emotion comparison (happy vs. fear), it is impossible for us to determine whether our findings reflect a bias for fear per se, or negative expressions in general. This limitation extends to much of the previous literature examining the fear bias in infancy. Future research should investigate how specific the bias is for fearful expressions, which could elucidate the structure of infants' underlying emotion categories (Quinn et al., 2011). Additionally, it will be important for future research to replicate the current pattern of results using a comparable sample of East Asian infants presented with the same stimuli. Our conclusions will be considerably strengthened if the same pattern of results is observed. Finally, it is unclear how our findings on infants' deployment of attention relate to findings using other measures of infant emotion processing. For instance, our findings differ from those of Vogel and colleagues (2012), who used a bimodal matching task and found that 5-monthold infants process happy and sad emotions similarly when expressed by own- and otherrace faces, but 9-month-olds show differential neural responses to the emotions for ownrace faces. However, these disparate findings provide an interesting starting point for



45

Experience and Emotion Processing future research examining how different metrics of emotion processing might be differentially sensitive to the effects of experience. The current study is the first to examine the role of experience with own- and other-race faces on the attentional bias for fear in infancy. Our findings suggest that the attentional preference for fear might initially be restricted to faces with which infants have the most experience, and later be extended to faces with which they have less experience. This initial attentional preference for fear when expressed by own-race faces is almost certainly due to greater experience with own-race caregivers early in life.



46

Experience and Emotion Processing CHAPTER 3 Does Experience with Fearful Faces Influence Emotional Processing in Infancy? Infants' ability to perceive and recognize emotional information from faces rapidly improves throughout the first year of life. Hours after birth newborns discriminate and imitate happy, sad, and surprised facial expressions when expressed live (Field, Woodson, Greenberg, & Cohen, 1982; Field, Woodson, Cohen, Greenberg, Garcia & Collins, 1983) and discriminate between happy and fearful facial expressions when expressed in photographs (Farroni, Menon, Rigato & Johnson, 2007). By 3 months of age infants discriminate between happy, angry, and surprised facial expressions in a habituation paradigm (Barrera & Maurer, 1981; Young-Browne, Rosenfeld & Horowitz, 1977). Beginning as early as 4 months of age infants demonstrate the ability to categorize facial expressions of emotion and this ability becomes robust by approximately 7 months (Bornstein & Arterberry, 2003; Caron, Caron & Myers, 1982; Kaneshige & Haryu, 2015; Ludemann, 1991; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Nelson, Morse, & Leavitt, 1979). By approximately the same age range (5 to 7 months) infants reliably match happy, sad, neutral, and angry facial expressions to their corresponding vocal expressions (i.e., intermodal matching; Walker, 1982; Walker-Andrews, 1986; 1988; 2008). This ability is robust even with manipulations to temporal synchrony (Walker, 1982; Walker-Andrews, 1986; 1988) and when infants are provided with facial movement only (i.e., point-light displays of facial expressions; Soken & Pick, 1992; 1999). Research has reported that experience with familiar faces shapes emotion discrimination, recognition, and attentional preferences for particular facial expressions



47

Experience and Emotion Processing throughout infancy (Barrera & Maurer, 1981; Bayet et al., 2015; Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002; Vogel, Monesson & Scott, 2011). Barrera and Maurer (1981) demonstrated that a greater number of 3-month-old infants discriminated between smiling and frowning faces when shown static pictures of their mother's face than when shown static faces of female strangers. Similarly, WalkerAndrews and colleagues found that 3.5-month-olds demonstrated the ability to match facial and vocal expressions when their mothers presented the expressions, but not when their fathers or an unfamiliar female presented the expressions (Kahana-Kalman & Walker-Andrews, 2001). They have also shown that 3.5-month-old infants are able to categorize happy and sad expressions if they are expressed by their mother and father, but not strangers (Walker-Andrews, Krogh-Jespersen, Mayhew, & Coffield, 2011). It has been argued that frequent exposure to exemplars of facial expressions by caregivers facilitates early sensitivity to and better processing of emotional expressions when they are expressed by familiar compared to unfamiliar faces (Kahana-Kalman & WalkerAndrews, 2001). Consistent with this interpretation, increased experience with different exemplars of facial expressions facilitates discrimination and recognition of emotional faces (Bornstein, Arterberry, Mash & Manian, 2011; Kuchuk, Vibbert & Bornstein, 1986; Lundy, Field, Cigales, Cuadra & Pickens, 1997; see Nelson, 1987; 2001). Kuchuk, Vibbert, and Bornstein (1986) investigated 3-month-olds' sensitivity to different intensities of smiling faces and whether sensitivity is related to mother-infant behaviours during short interactions. Overall, infants discriminated between variations in intensities of smiling faces, however greater individual sensitivity was found for infants of mothers



48

Experience and Emotion Processing who engaged their infants' attention while smiling. These findings suggest that sensitivity to smiling faces is related to the infant's experiences with happy faces. Additionally, Bornstein and colleagues (2011) investigated whether 5-month-olds of non-depressed and clinically depressed mothers were able to discriminate between happy and neutral faces. Only infants of non-depressed mothers showed discrimination between the happy and neutral faces. It was suggested that depressed mothers are likelier to express attenuated affect, thereby providing an emotional rearing environment with reduced displays of positive facial expressions of emotion. Experience with emotional faces may also influence infants' allocation of visual attention to particular facial expressions (de Haan, Belsky, Reid, Volein, & Johnson, 2004; Farroni et al., 2007; Grossman, Striano & Friederici, 2007; Leppänen & Nelson, 2009; 2012; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; see Peltola, Leppänen, Mäki, & Hietanen, 2009; Safar & Moulson, 2017). During the first few months of life (i.e., 3 to 6 months) mothers' facial expressions are restricted to positive emotions (i.e., joy, interest, and surprise), particularly with younger infants (Malatesta & Haviland, 1982). Accordingly, young infants demonstrate a looking bias towards happy as compared to neutral, angry, and fearful facial expressions that emerges shortly after birth (Farroni et al., 2007; Grossmann et al., 2007; LaBarbera, Izard, Vietze, & Parisi, 1976; Wilcox & Clayton, 1968). However, later in the first year, infants demonstrate the reverse--that is, they allocate greater attention towards negative facial expressions such as fearful and angry faces as compared to happy faces (Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009; Safar & Moulson, 2017). Grossman and colleagues (2007) found that 7-month-old infants showed a larger Nc component of the



49

Experience and Emotion Processing event-related potential (ERP) waveform in response to happy faces than in response to angry faces; in contrast, 12-month-old infants showed a larger negative-going component over occipital electrodes in response to angry than happy faces. The Nc component is presumed to reflect greater allocation of attention to salient stimuli (Courchesne et al., 1981; de Haan, Johnson & Halit, 2003), and tends to be larger for infrequently presented novel stimuli (Nelson & Collins, 1991; 1992; Reynolds & Richards, 2005). Thus, older infants allocate more attention to negative expressions than younger infants do. It is somewhat unclear when infants begin to allocate increased attention to fearful faces (de Haan & Nelson, 1998; Heck et al., 2016; 2017; Kotsoni, de Haan, & Johnson, 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009; Yrttiaho et al., 2014). Peltola and colleagues (2009) found that 7-month-olds demonstrated increased attention towards fearful facial expressions compared to happy expressions in both the visual paired-comparison task and their Nc response. In contrast, 5-month-olds showed no difference in allocation of attention between happy and fearful facial expressions. This finding of enhanced allocation of attention towards fearful faces at 7 months of age has been replicated several times (de Haan & Nelson, 1998; Kotsoni, de Haan, & Johnson, 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009), suggesting that the fear preference is robust by 7 months of age. However, more recent research suggests that in some cases a bias to attend to fearful faces may appear earlier (e.g., 5 months of age; Heck et al., 2016; 2017; Yrttiaho et al., 2014); the mixed findings at 5 months of age suggest that the bias is less well established earlier in infancy. The increased allocation of attention to fearful faces was initially proposed to be the result of infrequent experience with fearful facial expressions throughout the first year. Since



50

Experience and Emotion Processing fearful expressions are encountered less frequently than happy expressions, fearful expressions are more novel, and therefore infants allocate greater attention to them (Nelson & Dolgin, 1985; Vaish, Grossmann & Woodward, 2008). More recent research provides evidence suggesting that novelty alone is not sufficient to explain the looking bias towards fearful expressions (see Peltola, Leppänen, Vogel-Farley, Hietanen, & Nelson, 2008). For instance, Peltola and colleagues (2008) investigated 7-month-olds' looking duration to individually presented fearful, happy, or a novel facial expression (i.e., lips closed, eyes open, and cheeks blown full of air) compared to a scrambled face. Findings showed that infants looked significantly longer at a fearful face than a scrambled face, but not at the happy or novel facial expressions compared to the scrambled face. Thus, novelty may not be the primary driving force behind 7-month-old infants' looking bias towards fearful expressions (Peltola et al., 2008). Additionally, Peltola and colleagues (2008) examined whether fearful facial expressions affected 7month-olds' ability to disengage their attention when presented with a peripheral target (i.e., checkerboard pattern). Infants were first shown a centrally presented fearful, happy, or novel facial expression or a scrambled face. Following a short delay infants were then presented with a peripheral target. Seven-month-olds disengaged their attention significantly less frequently when presented with a fearful facial expression compared to a happy facial expression or the scrambled face. However, the novel facial expression did not differ from the other stimuli in frequency of attention disengagement. These findings support the idea that the greater allocation of attention towards fearful faces may not be due to the novelty of fearful facial expressions, at least not entirely (Peltola et al., 2008). More recently, Leppänen and Nelson (2009; 2012) have hypothesized that an



51

Experience and Emotion Processing experience-expectant mechanism may underlie the early development of emotion recognition in infancy. Specifically, increased sensitivity to salient emotional faces, such as fear, might be accounted for by the maturation of neural mechanisms (i.e., amygdala, prefrontal cortex) that underlie emotion processing and attention networks, in which the developing system "expects" to receive experience with facial expressions. Increased sensitivity to fear may indicate that the developing system is "ready" to detect fear in the environment and serve to promote learning of associations between fearful faces and corresponding emotional signal value (Leppänen & Nelson, 2009; 2012). The maturity of these neural mechanisms seems to emerge at approximately the same point in time at which infants are more likely to be exposed to a greater variety of facial expressions, including fear, in their environment (Grossman et al., 2007; Leppänen & Nelson, 2009; 2012). Infants become locomotive around 6 to 7 months, which is associated with a wider repertoire of facial expressions expressed by caregivers and increased caregiver monitoring on the part of the infant (Campos, Kermoian, & Zumbahlen, 1992; Vaish et al., 2008). Consequently, associations between threatening social objects or situations and fearful facial expressions expressed by their caregivers may be more readily processed and sensitivity to the emotional signal value of fearful faces may develop (Leppänen & Nelson, 2009; 2012; Hoehl & Striano, 2010). Theoretical perspectives on the development of emotion processing have suggested that experience is important for the emergence of recognition. However, we currently have only indirect evidence for the relation between experience with emotional faces and the development of emotion processing. One way to investigate whether experience with emotional faces affects emotion processing is to measure infants' natural



52

Experience and Emotion Processing experience with emotional faces and see if it correlates with their processing ability. Another way--the way we have chosen to use in the current study--is to experimentally manipulate infants' exposure to emotional faces and measure the effect this manipulation has on this ability. This approach was inspired by research on the development of face perception in infancy. Perceptual narrowing is a general phenomenon in perceptual development whereby infants retain or improve their ability to discriminate stimuli to which they have been exposed (e.g., speech sounds in their native language; human faces), but lose their ability to discriminate stimuli to which they are infrequently or never exposed (e.g., speech sounds in a non-native language; monkey faces) (Scott, Pascalis, & Nelson, 2007). Perceptual narrowing appears to develop in the second half of the first year, and is evident for multiple face types, including other-species faces (Pascalis, de Haan, Nelson, 2002; Pascalis et al., 2005), other-race faces (Kelly et al., 2007; 2009); and other-age faces (Macchi Cassia, Bulf, Quadrelli & Proietti, 2013). Recent studies have demonstrated that the course of perceptual narrowing can be altered through training (Kuhl et al., 1992; Heron-Delaney et al., 2011; Scott & Monesson, 2009; 2010). For instance, Heron-Delaney and colleagues (2011) investigated whether early experience with Chinese faces would influence Caucasian infants' ability to discriminate between Chinese faces later in life--an ability that usually diminishes over time due to perceptual narrowing (Kelly et al., 2007). Six-month-old Caucasian infants were provided training with Chinese faces via a picture book for a 3-month period. A control group of 6-month-old infants did not receive this training. Infants receiving training demonstrated discrimination between Chinese faces at 9 months of age, whereas infants in the control condition did not. These results suggest that the face-



53

Experience and Emotion Processing processing system is malleable and may be shaped by experimental training with specific face types (Heron-Delaney et al., 2011). Similarly, Scott and Monesson (2009) trained 6month-old infants with individually labeled monkey faces (e.g., `Jane') or categorically labeled monkey faces (e.g., `monkey') via a picture book over a 3-month period. At 9 months of age, infants who received training with individually labeled monkey faces demonstrated discrimination between monkey faces, whereas infants who received training with monkey faces at the categorical level did not. Thus, maintaining ability with a particular face type depends on individual-level training, not mere exposure (Scott & Monesson, 2009). In the current study we applied this experimental approach to the question of whether experience with emotional faces affects the development of emotion processing. A longitudinal study was conducted to examine whether experience with fearful and happy facial expressions of emotion influences infants' allocation of attention to happy and fearful faces. Three-month-old infants were recruited and their allocation of attention to happy and fearful faces was measured using both a VPC task and an ERP task. Following this baseline assessment, infants were assigned to a happy condition, a fear condition, or a no-training condition. In the happy and fear training conditions, infants received a picture book containing pictures of female faces expressing either happiness or fear. All infants then participated again at 5 months of age in the VPC and ERP tasks. We hypothesized that 3-month-old infants would show a spontaneous preference for happy as compared to fearful faces in the VPC task. We are unaware of any studies that have investigated the ERP response to happy and fearful faces in infants younger than 5 months; therefore, it was uncertain whether 3-month-olds would show different Nc



54

Experience and Emotion Processing responses to happy and fearful faces. However, behavioural evidence demonstrating a "positivity bias" in infants younger than 7 months of age (Farroni et al., 2007; LaBarbera et al., 1976; Wilcox & Clayton, 1968) suggests that 3-month-old infants may show greater Nc amplitudes in response to happy as compared to fearful faces. We also hypothesized that 5-month-old infants would show differential performance depending on the condition to which they had been assigned. Specifically, 5-month-olds in the fearful condition, but not the happy condition or no-training condition, would demonstrate greater allocation of attention to fearful as compared to happy faces in both the VPC and ERP tasks because the training with fearful faces is expected to facilitate sensitivity to and detection of fearful faces earlier than 7 months of age. This result would also demonstrate that the novelty of fearful faces is not sufficient to account for infants' attentional bias to fearful faces, considering that greater allocation of attention towards fearful facial expressions in infants with increased exposure to fearful facial expressions could not be explained by a lack of familiarity with fear. No studies have investigated whether training with fearful facial expressions in early infancy accelerates infants' shift in preference to attend to fearful facial expressions later in the first year, either at the behavioural or neural level. Method Participants Sixty-nine 3-month-old infants (M age= 89.56 days, SD= 12.17, 43 boys) participated. Twenty-three infants were assigned to the fearful training condition (M age= 90.13 days, SD= 13.34, 15 boys), 26 infants were assigned to the happy training condition (M age= 87.85 days, SD= 12.28, 20 boys), and 19 infants were assigned to the



55

Experience and Emotion Processing no-training condition (M age= 91.21 days, SD= 10.74, 8 boys). All infants were born within (+/-) 4 weeks of their due date. Participants were recruited through a database that contains contact information for parents from a large metropolitan area who expressed an interest in participating in developmental research. Recruitment sites for the database include large parent conventions and libraries. Per parent report, none of the infants had been diagnosed with visual impairment or clinical disorders (e.g., pervasive developmental disorders, fetal alcohol spectrum disorders). Stimuli Stimuli for the VPC and ERP tasks consisted of colour photographs of four (VPC, image IDs F24HAS, F24AFS, F29HAS, F29AFS, F31HAS, F31AFS, F32HAS, F32AFS), and 24 (ERP, image IDs F01HAS, F01AFS, F02HAS, F02AFS, F03HAS, F03AFS, F07HAS, F07AFS, F08HAS, F08AFS, F09HAS, F09AFS, F11HAS, F11AFS, F13HAS, F13AFS, F14HAS, F14AFS, F15HAS, F15AFS, F16HAS, F16AFS, F17HAS, F17AFS, F19HAS, F19AFS, F21HAS, F21AFS, F22HAS, F22AFS, F24HAS, F24AFS, F26HAS, F26AFS, F27HAS, F27AFS, F28HAS, F28AFS, F29HAS, F29AFS, F30HAS, F30AFS, F31HAS, F31AFS, F32HAS, F32AFS, F33HAS, F33AFS) unfamiliar female Caucasian faces displaying happiness and fear drawn from the Karolinska Directed Emotional Face Set (Lundqvist, Flykt & Öhman, 1998). The set consists of 70 Caucasian individuals (35 males) expressing angry, fearful, disgust, sad, happy, surprise, and neutral emotions. Goeleven, De Raedt, Leyman and Verschuere (2008) obtained ratings on emotion, intensity, and arousal. Overall, happy faces were recognized more accurately than all other emotional faces, and fearful faces were recognized less accurately than all other emotional faces, which suggests higher validity for the happy faces. However, in



56

Experience and Emotion Processing both cases, recognition accuracy was greater than chance for the full set of emotional faces. Intensity was rated on a 9-point Likert scale ranging from "1- not at all" intense to "9-completely" intense. Goeleven and colleagues (2008) found that adults rated happy faces higher than fearful faces. Similar to intensity, arousal was rated on a 9-point scale ranging from "1-calm" to "9-aroused." Adults rated happy and fearful faces similar in arousal (Goeleven et al., 2008). The Karolinska Directed Emotional Faces Set has good overall validity and includes an extensive set of faces in comparison to other databases (Goeleven et al., 2008). Procedure Initial contact for the study occurred via telephone or email. The experimenter provided study information to the parents and interested parents were invited to participate with their infant. The first appointment was scheduled when infants were most active and alert, as reported by the primary caregiver. At the start of the appointment the parent was provided with a consent form (see Appendix D) and was provided with detailed information about the study. Next the parent was provided with the Demographic Questionnaire, which obtained general history and background information about the infant. Specifically, information was collected regarding the infant's birthdate, race/, whether the infant was born within (+/-) 4 weeks of his/her expected due date, whether the infant was diagnosed with any clinical disorders (e.g., fetal alcohol syndrome) and/or visual impairment (see Appendix B). Following completion of the questionnaire, participants were guided to a testing room where the infants participated in the VPC and ERP tasks. The infant sat on their parent's lap facing a computer screen. A video camera was situated directly above the computer screen to capture infant looking behaviour. The



57

Experience and Emotion Processing video signal was projected onto a second computer screen in an adjacent room viewed by the experimenter, which allowed the experimenter to monitor infant looking behaviour online throughout the experiment. Visual paired-comparison task. Parents wore a sleep mask throughout the task so that their behaviour did not influence the infant's looking behaviour. The VPC task was programmed in E-Prime (Psychology Software Tools, 2002). Four trials each appeared for a fixed length of 10 seconds from the onset of the stimuli. An attentiongrabbing stimulus (a bouncing ball) appeared in the center of the screen between trials to redirect the infant's attention to the screen. The experimenter only started a trial when the infant was looking at the screen. Each trial consisted of one female face expressing happy and fearful facial expressions side-by-side on the computer screen. From a viewing distance of 60cm, each face image subtended approximately 19 x 24 degrees of visual angle. The first pair of trials showed the same female face, with the left/right position of the happy and fearful expressions reversed from trial 1 to trial 2. The second pair of trials showed a second female face, with the left/right position of the happy and fearful expressions reversed from trial 3 to trial 4. Which female face was shown in the first versus second pair of trials was counterbalanced across infants. The left versus right appearance of the fearful face was also counterbalanced across infants (Figure 3). The experimenter and a research assistant blind to the left-right position of the fearful and happy expressions coded infant looking time offline. Trials were coded frame-by-frame at 30 frames/second using DataVyu (v1.2). Inter-observer reliability was r = .88 based on 20% of total infant looking time data.



58

Experience and Emotion Processing Figure 3. Example of VPC task in Study 2. Infants saw all four 10-second trials. Image IDs F31HAS, F31AFS, F32HAS, F32AFS.

Trial 1 (10s)

Trial 2 (10s)

Trial 3 (10s)

Trial 4 (10s)



59

Experience and Emotion Processing Event-related potential task. The ERP task was programmed in E-Prime (Psychology Software Tools, 2002). During EEG recording infants saw 12 female faces, each expressing happy and fearful facial expressions. These faces were all novel (i.e., none had been used in the VPC task). Each stimulus was presented one at a time in random order at viewing distance of 60 cm, and each face image subtended approximately 15 x 20 degrees of visual angle. Each trial consisted of a 200 ms baseline, a 500 ms stimulus presentation, and a 1000 ms inter-trial interval during which a blank white screen was presented. An attention-grabbing stimulus (a bouncing ball) appeared in the center of the screen between trials to redirect the infant's attention to the screen (Figure 4). The experimenter only started trials when the infant was looking at the screen. Trials continued until infants become too inattentive or fussy to continue or infants viewed a maximum of 240 trials.



60

Experience and Emotion Processing Figure 4. ERP trial structure in Study 2. Image ID displayed is F01AFS.

Attention-getter Stimulus 500 ms Poststimulus recording 1000 ms

Attention-getter



61

Experience and Emotion Processing Training Procedure. Following completion of these tasks, infants were randomly assigned to one of three conditions: 1) fearful condition, 2) happy condition, and 3) notraining condition. Parents of infants in the fearful and happy conditions were provided with a picture book consisting of six female faces expressing either fearful facial expressions or happy facial expressions, respectively. Each female face was labeled at the individual level (e.g., "This is Nicole. Nicole is feeling happy") as previous research has shown that perceptual training at the individual level facilitates perceptual expertise (Scott & Monesson, 2009). Infants in the happy or fearful training condition were assigned to one of three identity versions of the picture book, to ensure any effects were generalizable across many identities expressing happy and fearful expressions (see Appendix E). Parents were also provided with a reading schedule and reading log to record their reading sessions (see Appendix F and G, respectively). Parents were instructed to read to their infants for an 8-week period. Specifically, parents were instructed to read everyday for the first 2 weeks, every other day during weeks 3 and 4, every third day for weeks 5 and 6, and every fourth day for weeks 7 and 8 (Scott & Monesson, 2009). Parents were contacted twice throughout this period to track their adherence to the schedule. Parents of infants in the control condition did not receive a picture book. 5-month visit. At 5 months of age infants in all three conditions were invited back to the lab to participate in both the VPC and ERP tasks again. Upon arrival, the parent was provided with the consent form again (the consent form was identical to the copy provided at the first visit) and detailed study information was provided again. The parent was then given the Compliance Scale, which obtained information about



62

Experience and Emotion Processing adherence to the reading schedule during the 8-week training period (see Appendix H). Following completion of the questionnaire, participants were guided to the testing room where the infants participated in the VPC and ERP tasks again. It should be noted that the two faces used in the VPC task were different from the two faces used at the 3-monthvisit. Additionally, six of the 12 faces used during the ERP task were now familiar to the infants in the happy and fearful conditions because they had been used in the picture books. All 12 faces were unfamiliar to infants in the no-training condition. Adherence to training schedule. Nine participants completed more than the required number of reading sessions, 4 participants completed 100% of reading sessions, 21 participants completed 75-99% of reading sessions, 3 participants completed 55-74% of reading sessions and 4 participants did not return the compliance scale. On average participants completed 93% of the reading sessions. Results Behavioural Results To determine whether infants showed an attentional preference for the fearful facial expression at 3 and 5 months of age, proportion looking time to the fearful facial expression was calculated for each trial (looking time to fearful/[looking time to fearful + looking time to happy]) and averaged across the four trials. We first examined whether infants showed an effect of training on proportion looking time to the fearful facial expression using a 2 (age: 3 months, 5 months) x 3 (condition: fear, happy, no-training) repeated-measures ANOVA. For proportion looking time to the fearful facial expression, there was no main effect of age, F(1, 47) = .004, p = .948, p2 = 0, or condition, F(2, 47) = .429, p = .654, p2 = .018. Furthermore, no



63

Experience and Emotion Processing significant age x condition interaction was revealed, F(2, 47) = .453, p = .639, p2 = .019 Thus, the expected effect of training was not found. However, an examination of the descriptive data revealed that 3-month-olds seemed to show a looking preference for fearful facial expressions, which may have been influencing our ability to observe an effect of training. Therefore, we examined looking time to the fearful facial expression separately at 3 and 5 months of age in further analyses. 3-month-old analysis. Data from 60 3-month-old infants (36 boys, M age = 90.46 days, SD = 12.7) were included in the analysis prior to training. Ten additional infants were tested but their data were excluded due to side-bias during testing (> 95% looking time to one side across all four trials; n = 7), experimenter error (n = 1), or twin with another infant in the study (n = 1). The sample comprised Caucasian (n = 32), Black (n = 3), East Asian (n = 5), South Asian (n = 5), Hispanic (n = 1), and Mixed (n = 14) participants. To confirm no pre-existing looking biases to fearful facial expressions between training conditions at 3 months of age we conducted a one-way analysis of variance (ANOVA) comparing proportion looking time to the fearful facial expression in each of the training conditions (happy, fearful, neutral) prior to training. There was no significant difference in proportion looking time to the fearful facial expression between 3-monthold infants in the fearful training condition (M = .56, SD = .14), happy training condition (M = .54, SD = .15) or no-training condition (M = .58, SD = .14), F(2, 57) = .361, p = .699. Therefore, we collapsed across training conditions and conducted a one-sample ttest comparing proportion looking time to the fearful expression against chance (50%). Prior to training, 3-month-olds demonstrated a significant looking preference for fearful



64

Experience and Emotion Processing facial expressions compared to happy facial expressions (M = .56, SD = .14, t(59) = 3.234, p = .002, two-tailed, d = .42). To control for the possibility that 3-month-olds' looking preference to the fearful expression might be driven by a few infants with large fear preferences, we looked at whether the observed proportion of infants showing an attentional preference to fearful facial expressions significantly differed from chance. Results indicated that 39 of 60 3-month-olds showed a preference for the fearful expression. This proportion was significantly greater than expected by chance, binomial probability, p = .027, two-tailed. 5-month-old analysis. Fifty-six infants (32 boys, M age = 152.82 days, SD = 12.72) were tested at 5 months of age following training (fearful training condition: n= 17, 10 boys, M age = 153 days, SD = 11.66; happy training condition: n = 22, 15 boys, M age = 152.32 days, SD = 12.41; and no-training condition: n = 17, 7 boys, M age = 153.29 days, SD = 14.74). Two additional infants were tested but their data were excluded because one infant was a twin with another infant in the study; the other infant completed less than 50% of the reading schedule. Ten infants did not return for testing at 5 months of age following training. The total sample comprised Caucasian (n = 32), Black (n= 2), East Asian (n = 6), South Asian (n = 2), Hispanic (n = 1), Middle Eastern (n = 1), and Mixed (n = 12) participants. A one-way ANOVA comparing proportion looking time to the fearful facial expression in each of the training conditions (happy, fearful, neutral) was conducted. There was no significant difference in proportion looking time to the fearful facial expression between infants in the fearful training condition (M = .51, SD = .09), happy training condition (M = .55, SD = .11) or no-training condition (M = .57, SD = .09), F(2,



65

Experience and Emotion Processing 53) = 1.742, p = .185. Although a significant difference in proportion looking time to the fearful facial expression was not found between training conditions, it is possible that infants in each of the training conditions show a significant looking preference for fearful facial expressions when compared against chance (Figure 5). One-sample t-tests against chance indicated that infants in the fearful training condition (n = 17) did not demonstrate a significant looking preference for fearful facial expressions or happy facial expressions (M = .51, SD = .09, t(16) = .284, p = .78, two-tailed, d = .07). Only 10 of 17 infants showed a preference for the fearful facial expression, which was not significantly greater than expected by chance, binomial probability, p = .629, two-tailed. Infants in the happy training condition (n =22), showed a trending looking preference for fearful facial expressions as compared to happy facial expressions (M = .55, SD = .11, t(21) = 2.073, p = .051, two-tailed, d =.44). Sixteen of 22 infants showed a preference for the fearful expression. This proportion was trending significance, binomial probability, p = .052, two-tailed. Five-month-olds in the no-training condition (n= 17), demonstrated a significant looking preference for fearful facial expressions compared to happy facial expressions (M = .57, SD = .07, t(16) = 3.75, p = .002, two-tailed, d = .91). Fifteen of 17 infants in the no-training condition showed a preference for the fearful expression. This proportion was significantly greater than expected by chance, binomial probability, p = .002, two-tailed (Figure 5).



66

Experience and Emotion Processing Figure 5. Mean proportion looking time to fear in Study 2. Standard error of the mean is reported in parentheses and represented by error bars.
0.7 Proportion Looking Time to Fear 0.6 0.5 0.4 0.3 0.2 3 months 5 months Fearful 5 months Happy training training Condition 5 months Notraining * .56 (.02) * .55 (.02) * .57 (.02)

.51 (.02)



67

Experience and Emotion Processing ERP Results Electrophysiological recording and processing. Continuous EEG was recorded using a 128-channel Geodesic Sensor Net (Electrical Geodesics Inc.), connected to a high-input-impedance amplifier (Net Amps 300 Electrical Geodesics Inc.). The analog EEG signal was referenced online to vertex (Cz), digitized at a sampling rate of 500 Hz, band-pass filtered from 0.1 to 100 Hz, and stored on the hard drive of a Macintosh computer to be processed offline. Impedances for each electrode were at or less than 40k at the beginning of each recording. Net Station 4.2 (Electrical Geodesics Inc.) was used to process the data offline. Continuous EEG was band-pass filtered from 0.1 to 30 Hz and segmented into 1700 ms epochs, consisting of a 200 ms baseline, followed by 500 ms stimulus presentation and 1000 ms post-stimulus recording. Epochs were then baseline corrected to the mean of the 200 ms baseline period (before stimulus onset). Each trial was visually inspected for eye blinks, eye movements, and bad channels. Trials were excluded from analysis if more than 13 of 128 channels (~10%) were marked as bad. Bad channels were replaced using spherical spline interpolation in trials containing 10% or fewer bad channels. Participants with fewer than 10 trials in each stimulus category were excluded from further analysis (see Table 1 for the average number of good trials for each stimulus category). Individual waveform averages for each participant were generated for each of the stimulus categories and re-referenced to the average reference. Grand means were generated by averaging together the individual average waveforms.



68

Experience and Emotion Processing Table 1. Average Numbers of Good Trials by Emotion and Condition Emotion Fearful Condition 3 months 5 months Fearful Happy No-training 22.92 (9.08) 24.08 (12.98) 16.14 (9.55) 25.15 (9.63) 23.42 (13.5) 15.43 (6.53) M (SD) 24.94 (10.47) Happy M (SD) 26.27 (11.65)



69

Experience and Emotion Processing Grand means at each age (3 months, 5 months) and for each condition (fearful training, happy training, no-training) were inspected. Consistent with previous research on infant emotion processing, there was a prominent Nc over frontocentral leads. The mean amplitude and peak latency of the Nc component were determined within a time window of 380-650 ms post-stimulus onset (3 months) and 330-600 ms post-stimulus onset (5 months). This maturational shift in time window is consistent with previous studies showing that the peak latency of the Nc decreases with age throughout the first year of life (see de Haan, 2007, for a review). At both ages, the amplitude and latency of the Nc were averaged across clusters of sensors over the left hemisphere (electrodes 13, 19, 20, 28, 29, 30), midline (electrodes 5, 6, 7, 11, 12, 106, 129), and right hemisphere (electrodes 4, 105, 111, 112, 117, 118). Analysis plan. At 3 months (prior to training), the mean amplitude and peak latency of the Nc were examined using a 2 (emotion: happy, fear) x 3 (hemisphere: left, midline, right) repeated-measures ANOVA. At 5 months (following training), the same analysis was conducted with the addition of the variable condition (fearful training, happy training, no-training) in the repeated-measures ANOVA. Pairwise comparisons were conducted for significant and marginally significant main effects revealed by the ANOVA using paired sample t-tests, Bonferroni corrected for multiple comparisons. For all statistical tests an alpha level of 0.5 was used. Alpha levels were considered marginally significant between .05 and .08. 3-month-olds. The analysis at 3 months of age included 36 infants (21 boys, M age = 89.22, SD = 12.71). Thirty-three additional infants were tested but their data was excluded due to refusal to wear the ERP cap (n = 1), fussiness (n = 3), excessive artefact



70

Experience and Emotion Processing resulting in < 10 good trials per stimulus condition (n = 27), experiment error (n = 1), and twin with another infant in the study (n = 1). A marginally significant main effect of hemisphere for mean amplitude of the Nc was revealed, F(2, 70) = 3.017, p = .055, p2 = .079, indicating that infants showed a larger Nc over the midline than the left and right hemispheres. There was no main effect of emotion, F(1, 35) = .543, p = .466, p2= .015 or significant hemisphere x emotion interaction, F(2, 70) = .597, p = .553, p2 = .017. There was a significant main effect on hemisphere for peak latency of the Nc, F(2, 70) = 6.41, p = .003, p2 = .155, indicating that infants showed faster Nc latencies over the left hemisphere than the midline and right hemispheres. No main effect of emotion, F(1, 35) = .632, p = .432, p2 = .018, or emotion x hemisphere interaction, F(2, 70) = .396, p = .675, p2 = .011, was found. The grand averaged ERP waveforms for the 3-month-old infants are shown in Figures 6a, b, and c.



71

Experience and Emotion Processing Figure 6. Grand averaged event-related potential waveforms at 3 months of age. Waveforms displayed over left hemisphere (a), midline (b), and right hemisphere (c). The x axis represents latency in milliseconds and the y axis represents amplitude in microvolts. (a)
12 10 8 6 4 2 0 -2 -4 -6 -200 -100 0

Amplitude (microvolts)

Fear Happy

100 200 300 400 500 600 700 800 900 1000

Time (ms)

(b)
12 10 8 6 4 2 0 -2 -4 -6 -200 -100 0

Amplitude (microvolts)

Fear Happy

100 200 300 400 500 600 700 800 900 1000

Time (ms)



72

Experience and Emotion Processing

(c)
12 10 8 6 4 2 0 -2 -4 -6 -200 -100 0

Amplitude (microvolts)

Fear Happy
100 200 300 400 500 600 700 800 900 1000 Time (ms)



73

Experience and Emotion Processing 5-month-olds. The analysis at 5 months of age included 13 infants (7 boys, M age = 152.15 days, SD = 9.49) in the fearful training condition, 12 infants (9 boys, M age = 154.58 days, SD = 15.93) in the happy training condition, and 7 infants (3 boys, M age = 153.29 days, SD = 16.16) in the no-training condition. Twenty-seven additional infants were tested but their data was excluded due to refusal to wear the ERP cap (n = 3), excessive artefact resulting in < 10 good trials per stimulus condition (n = 18), equipment failure (n = 4), twin with another infant in the study (n = 1); and completion of less than 50% of the reading schedule (n = 1). Ten infants did not return for testing at 5 months of age following training. For mean amplitude of the Nc, there was no main effect of emotion, F(1, 29) = .008, p = .928, p2 = 0, hemisphere, F(2, 58) = .27, p = .765, p2 = .009, or training condition, F(1, 29) = 1.68, p = .205, p2 = ..104. Furthermore, no significant emotion x hemisphere F(2, 58) = .447, p = .642, p2 = .015, emotion x condition F(2, 29) = 6.04, p = .553, p2 = .04, hemisphere x condition, F(4, 58) = 1.52, p = .208, p2 = .095, or emotion x hemisphere x condition, F(4, 58) = .236, p = . .917, p2 = .016 interactions were revealed. Latency analysis revealed no significant main effects of emotion, F(1, 29) = 1.055, p = .313, p2 = .035, hemisphere F(2, 58) = .123, p = .884, p2 = .004, or condition F(2, 29) = .379, p = .688, p2 = .025. There were no significant emotion x hemisphere, F(2, 58) = .896, p = .414, p2 = .03, emotion x condition, F(2, 29) = .771, p = .472, p2 = .05, condition x hemisphere, F(4, 58) = 1.084, p = .373, p2 = .07, or emotion x hemisphere x condition, F(4, 58) = 1.358, p = .26, p2 = .086 interactions for latency. The grand averaged ERP waveforms for the 5-month-old infants are shown in Figures 7a, b, and c; 8a, b, and c; and 9a, b, and c.



74

Experience and Emotion Processing Figure 7. Grand averaged event-related potential waveforms for 5-month-olds in the fearful training condition. Waveforms displayed over left hemisphere (a), midline (b), and right hemisphere (c). The x axis represents latency in milliseconds and the y axis represents amplitude in microvolts. (a)

 (b)
Amplitude (microvolts)
25 20 15 10 5 0 -5 -10 -200 -100 0 100 200 300 400 500 600 700 800 900 1000

Fear Happy

Time (ms)



75

Experience and Emotion Processing (c)
25 20 15 10 5 0 -5 -10 -200 -100 0 100 200 300 400 500 600 700 800 900 1000

Amplitude (microvolts)

Fear Happy

Time (ms)



76

Experience and Emotion Processing Figure 8. Grand averaged event-related potential waveforms for 5-month-olds in the happy training condition. Waveforms displayed over left hemisphere (a), midline (b), and right hemisphere (c). The x axis represents latency in milliseconds and the y axis represents amplitude in microvolts. (a)

 (b)





77

Experience and Emotion Processing (c)





78

Experience and Emotion Processing Figure 9. Grand averaged event-related potential waveforms for 5-month-olds in the no-training condition. Waveforms displayed over left hemisphere (a), midline (b), and right hemisphere (c). The x axis represents latency in milliseconds and the y axis represents amplitude in microvolts. (a)
25 20 15 10 5 0 -5 -10 -200 -100 0 100 200 300 400 500 600 700 800 900 1000

Amplitude (microvolts)

Fear Happy

Time (ms)

(b)
25 20 15 10 5 0 -5 -10 -200 -100 0 100 200 300 400 500 600 700 800 900 1000

Amplitude (microvolts)

Fear Happy

Time (ms)



79

Experience and Emotion Processing (c)





80

Experience and Emotion Processing Discussion The current study examined whether exposure to happy and fearful facial expressions affects the development of allocation of attention to happy and fearful faces at 5 months of age. This ability was tested using a VPC task and an ERP task. Prior to training, 3-month-olds demonstrated a significant looking preference for fearful facial expressions compared to happy facial expressions. Following training, 5-month-olds who received exposure to fearful facial expressions did not demonstrate a significant looking preference for fearful facial expressions; in contrast, 5-month-olds who received exposure to happy facial expressions demonstrated a significant looking preference for fearful facial expressions, as did 5-month-olds in the no-training condition. At the neural level, we found no evidence of differential response to happy and fearful facial expressions at either 3 or 5 months of age. Our study is the first to find that 3-month-old infants show a looking preference for static fearful facial expressions in a VPC task. This finding is inconsistent with previous behavioural research reporting a "positivity bias" in young infants (Farroni et al., 2007; LaBarbera et al., 1976; Vaish et al., 2008; Wilcox & Clayton, 1968). These findings also contrast with those reporting that a looking preference for fearful facial expressions emerges after 5 months of age (de Haan & Nelson, 1998; Kotsoni et al., 2001; Peltola et al., 2009; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985). Why might 3-month-old infants show a fear preference in the current study? First, most studies reporting that young infants show a "positivity bias" have not tested this preference using happy and fearful emotion pairs. To our knowledge, only one study has reported a looking time preference for happy as compared to fearful facial expressions in young



81

Experience and Emotion Processing infants (Farroni et al., 2007). Specifically, Farroni and colleagues (2007) reported that 2to 4-day old newborns tended to look longer at a happy facial expression relative to a fearful facial expression (Farroni et al., 2007). More studies investigating a preference for positive facial expressions of emotion in younger infants, using different emotion pairs, are needed. Second, although we found an attentional looking preference for fearful faces earlier than reported in the earliest studies of this phenomenon (Nelson & de Haan, 1996; Kotsoni et al., 2001; Ludemann & Nelson, 1988; Peltola et al., 2009; Nelson & Dolgin, 1985), our findings are generally consistent with more recent studies showing this ability emerges as early as 5 months of age (Forssman et al., 2013; Heck et al., 2016; 2017; Yrttiaho, Forssman, Kaatiala & Leppänen, 2014). Yrttiaho and colleagues (2014) found that 5-month-old infants disengaged their attention significantly less frequently from a centrally presented fearful face as compared to a happy, neutral, or scrambled face when presented with a peripheral target (checkerboard pattern). Using the same paradigm, Heck and colleagues (2016) examined whether 3.5- and 5-month-olds show a fear preference when presented with dynamic stimuli. The authors argue that dynamic stimuli offer greater information than static faces, thus providing infants with the best opportunity to display their emotion processing capabilities (Walker-Andrews, 1997). Five-month-olds, unlike the 3.5-month-olds, showed longer looking to the centrally presented fearful face when presented with a peripheral target, as compared to a happy or neutral face. These findings, along with the results of the current study, suggest that an attentional looking bias for fear emerges earlier than initially reported.



82

Experience and Emotion Processing Following training, 5-month-olds' looking preference to fearful compared to happy facial expressions differed depending on training condition: Infants who received exposure to fearful facial expressions did not show a looking preference for fearful faces, whereas infants who received exposure to happy facial expressions and infants who received no training did show a looking preference for fearful faces. We had predicted the opposite pattern of results. Specifically, we hypothesized that only 5-month-old infants in the fearful training condition, but not 3-month-olds or 5-month-olds in the other training conditions, would show a fear preference because these were the only infants who would have had sufficient exposure to fearful facial expressions to learn about their threatening signal value. Our pattern of results suggests that, in fact, novelty might play an important role in the attentional bias for fearful faces in younger infants, since infants without experience with fearful faces showed a fear preference, whereas infants with experience did not. These findings are consistent with the suggestion that infrequent experience with fearful facial expressions drives increased allocation of attention to fearful faces (de Haan et al., 2004; Nelson & de Haan, 1996; Vaish et al., 2008). de Haan and colleagues (2004) investigated the relationship between maternal affect disposition and 7-month-old infants' processing of happy and fearful facial expressions of emotion. Infants with mothers who had positive dispositions rather than negative dispositions showed a stronger preference to look at fearful facial expressions and a larger Nc amplitude in response to fearful expressions compared to infants of mothers with less positive dispositions. These results suggest that greater experience with positive affect (and presumably less experience with negative affect) through their mothers' disposition might underlie infants' preference to attend to the relatively more novel fearful facial



83

Experience and Emotion Processing expressions (de Haan et al., 2004). In the context of the current behavioural findings, it seems that novelty affects 5-month-olds' attentional bias to fearful expressions. It is important to note that this interpretation should be considered as preliminary, given that no significant effect of training was revealed by the repeated-measures ANOVA analysis. In contrast to the behavioural findings, neither 3-month-old infants nor 5-monthold infants in any training condition showed significant differences in Nc amplitudes or latencies in response to the different facial expressions. Many studies have observed larger Nc amplitudes for fearful than happy faces in 7-month-olds (de Haan et al., 2004; Grossmann et al., 2011; Jessen & Grossmann, 2015; Leppänen, Moulson, Vogel-Farley & Nelson, 2007; Nelson & de Haan, 1996; Peltola et al., 2009). However, there are very few studies examining processing of fearful facial expressions in infants younger than 7 months of age. Peltola and colleagues (2009) reported greater Nc responses to fearful compared to happy facial expressions at 7 months, but not 5 months of age. Additionally, Hoehl and Striano (2010) found no difference in 3-month-olds' Nc responses to fearful facial expressions compared to neutral facial expressions when expressed with averted eye gaze referencing an unfamiliar object, or expressed with averted gaze referencing an empty space. Our ERP results are consistent with these studies, and suggest that attentional systems may not be more sensitive to fearful than happy facial expressions prior to 7 months of age. That there was no effect of emotion for the Nc is also inconsistent with behavioural findings in the same infants. Although it is difficult to interpret why behavioural results were not reflected in the Nc, it is possible that greater looking time to fearful facial expressions might reflect early perceptual processes not involving frontal



84

Experience and Emotion Processing cortical regions. If this is the case we should expect to find differences in N290 and P400 components over occipitotemporal scalp regions in response to happy and fearful facial expressions. The N290 and P400 are presumed to be developmental precursors to the adult N170 face sensitive component (see de Haan, Johnson & Halit, 2003 for a review). The N290 amplitude is larger for human compared to nonhuman primate faces or visual noise (de Haan, Johnson & Halit, 2003; de Haan, Pascalis, & Johnson, 2002; Halit, Csibra, & Johnson, 2004) and the P400 peaks faster in response to faces than other objects (de Haan & Nelson, 1999). Both components are modulated by facial expressions of emotion, particularly in response to fearful facial expressions (Hoehl & Striano, 2008; Kobriella et al., 2008; Leppänen et al., 2007). Leppänen and colleagues (2007) found greater P400 amplitude to fearful than to happy and neutral faces in 7-month-old infants. Yrttiaho and colleagues (2014) examined N290/P400 responses to fearful and non-fearful (i.e., happy and neutral) facial expressions at 5 and 7 months of age. Findings revealed a less negative N290 and early P400 response to fearful compared to non-fearful facial expressions at both ages. However, at 5 months this pattern of results was only observed in a bootstrap analysis and the scalp distribution of electrodes over posterior regions responsive to fearful faces was not completely clear. These results suggest that sensitivity of the N290 and P400 in response to fearful faces might start to emerge at 5 months of age and become established by 7 months of age (Yrttiaho et al., 2014). No studies have examined whether the N290/P400 are modulated by fearful and happy facial expressions younger than 5 months, so it is uncertain whether differences at 3 months exist, or whether the N290 and P400 are modulated by experience with these facial expressions. Investigating whether the N290 and P400 differentiate between happy and fearful facial



85

Experience and Emotion Processing expressions exist might help to explain the discrepant behavioural and ERP findings in our study. The current research adds to the small body of literature examining how experience with emotional faces impacts emotion processing in infancy. Our findings are the first to report an attentional looking preference for fearful facial expressions compared to happy facial expressions at 3 months of age. Additionally, although we did not find the predicted effect of training, preliminarily evidence suggests that experience with fearful faces attenuates an attentional looking preference for fearful facial expressions at 5 months of age. These findings were not reflected in ERPs, however, further investigation over occipitotemporal scalp regions might help clarify discrepant findings. Behavioural results shed light on the developmental trajectory of the emergence of an attentional looking bias to fearful facial expressions.  



86

Experience and Emotion Processing CHAPTER 4 Does Experience Influence Intermodal Matching of Facial and Vocal Expressions of Emotion in Infancy? From birth expressions of emotion are first and most often encountered during dynamic interactions with caregivers (Malatesta, Grigoryev, Lamb, Albin & Culver, 1986; Malatesta & Haviland, 1982). Thus, infants typically experience emotional information directed to them through multiple modalities, rather than a single modality (Grossman, 2010). Accordingly, newborns detect and are sensitive to expressions of emotion when expressed in a live multimodal context (Field, Woodson, Greenberg, & Cohen, 1982; Field, Woodson, Cohen, Green-berg, Garcia & Collins, 1983). Shortly after birth infants show discrimination and imitation of happy, sad, and surprised facial expressions when expressed live (Field et al., 1982; Field et al., 1983). By 10 weeks infants discriminate between the presentation of joy, anger, and sad facial expressions when expressed by their mothers during live interactions, as indicated by differential responses to each distinct expression (Haviland & Lelwica, 1987). Infants can also discriminate between different emotional expressions when expressed intermodally in a habituation paradigm, although the information which infants use to discriminate might differ by age (Caron, Caron & MacLean, 1982; Flom & Bahrick, 2007; see Walker-Andrews, 1997; 2008). For instance, Flom and Bahrick (2007) examined infants' discrimination of happy, sad and angry emotional expressions when expressed dynamically in different modalities: intermodal (face and voice), or unimodal (face or voice only). By 4 months infants differentiated between the expressions only when expressed by the face and voice, whereas older infants



87

Experience and Emotion Processing differentiated between the expressions when only vocal information was available (5 months), or when only facial information was available (7 months). Further, 4-montholds required temporal synchrony of faces and voices to differentiate between expressions. Infants might initially require emotions to be expressed through multiple modalities to demonstrate discrimination because infants attend to and base their discrimination on redundant information expressed simultaneously and synchronously (Bahrick, Lickliter & Flom, 2004; Flom & Bahrick, 2007). Later in the first year, infants learn to extract the relevant information from each modality on its own, developing modality-specific expertise (Walker-Andrews, 1997). Other studies have examined infants' ability to detect common invariant emotional information expressed across the face and voice using an adapted intermodal preference technique (Spelke, 1976; Soken & Pick, 1992; 1999; Walker, 1982; WalkerAndrews, 1986). This technique involves presenting infants with two simultaneous videos of facial expressions (e.g., happy and sad) and a vocal track that corresponds in expression to one of the two facial expressions. If infants can identify the common underlying emotion expressed they will show greater looking towards the emotionally matching facial expression. Using this paradigm, Walker (1982) investigated 5- and 7month-olds' ability to match happy, sad, and neutral facial expressions to the appropriate vocal expression and found that at both ages infants increased their looking time to the facial expression that was displayed with its matching vocal expression. In additional experiments, Walker (1982) examined whether infants were attending to common emotional information or other types of non-emotional information unrelated to the emotion tested, such as temporal synchrony and intensity of the emotions expressed. By 7



88

Experience and Emotion Processing months, infants are able to match happy, sad, and angry facial expressions to the appropriate vocal expression when the facial and vocal information is asynchronous (Walker, 1982). Furthermore, 7-month-olds are able to match happy and angry facial and vocal expressions when the mouth region of the facial stimulus is occluded (WalkerAndrews, 1986), and based on facial movement only (i.e., point-light displays of facial expressions are used; Soken & Pick, 1992). Finally, 7-month-olds show an inversion effect: They do not demonstrate intermodal matching when the face stimuli are inverted (Walker, 1982). Since the inversion effect is a hallmark of expert face processing (Yin, 1969), this suggests that by 7 months, infants use mature face processing strategies to perform this task. Thus, by 7 months of age, infants' intermodal emotion recognition ability is robust. More recent research has shown that experience facilitates infants' discrimination of intermodal emotional expressions (Kahana-Kalman & Walker-Andrews, 2001; Lewkowitz and Ghazanfar, 2006; Montague & Walker-Andrews, 2001; 2002; Vogel, Monesson & Scott, 2011; Walker-Andrews, Krogh-Jespersen, Mayhew, & Coffield, 2011). Walker-Andrews and her colleagues have demonstrated that 3.5-month-old infants are able to categorize happy and sad expressions expressed intermodally if they are expressed by their mother and father, but not strangers (Walker-Andrews et al., 2011). Additionally, they have found that 3.5-month-old infants can successfully match happy and sad facial expressions to the appropriate vocal expressions when expressed by their mothers, but not their fathers or female strangers (Kahana-Kalman & Walker-Andrews, 2001; Montague & Walker-Andrews, 2002; Walker-Andrews, 1998). This finding was replicated when face and voice information was presented asynchronously (Kahana-



89

Experience and Emotion Processing Kalman & Walker-Andrews, 2001). These results suggest that increased experience with and enhanced attention to emotions when expressed by familiar compared to unfamiliar persons might facilitate early sensitivity to these emotions (Kahana-Kalman & WalkerAndrews, 2001; Montague & Walker-Andrews, 2002). Consistent exposure to particular face types (e.g., own- vs. other-race; own- vs. other-species) also seems to shape infants' discrimination and recognition of emotions expressed intermodally (Flom, Whipple, & Hyde, 2009; Lewkowitz and Ghazanfar, 2006; Vogel, Monesson, & Scott, 2012). Vogel and colleagues (2012) examined 5-and 9month-old infants' neural responses to congruent and incongruent pairings of happy and sad faces and vocal expressions of emotion using both own-race and other-race faces. Findings indicated no difference in 5-month-olds' neural processing of own- vs. otherrace faces when expressing happy or sad facial and vocal expressions. In contrast, 9month-olds showed a greater P400 response to own-race as compared to other-race faces expressing happy or sad facial and vocal expressions. Furthermore, 9-month-olds showed faster processing (i.e., faster peak latency of the P400) of incongruent face/voice pairs as compared to congruent face/voice pairs for own-race, but not other-race faces. These findings suggest that the discrimination of emotional expressions is influenced by perceptual narrowing, which is a process of maintained or increased specialization for faces from familiar categories (e.g., own-race) that comes at the expense of diminished ability for faces from unfamiliar categories (e.g., other-race) (Scott, Pascalis, & Nelson, 2007). Similar effects of experience have been observed for infants' intermodal perception of other-species faces and vocalizations (Lewkowitz and Ghazanfar, 2006). Lewkowicz and Ghazanfar (2006) observed that 4- and 6-month-old infants matched



90

Experience and Emotion Processing facial expressions to the appropriate vocal calls expressed by other-species (i.e., macaques), however 8- and 10-month-old infants did not. Thus, in the beginning detection and matching of invariant common emotional information across face and voice modalities may be broad, allowing infants to form intermodal associations across all species types, and this ability becomes specialized throughout the first year with increased perceptual experience. The studies reviewed above highlight that experience with particular face types is important for the development of intermodal emotion processing. However, there is a lack of research directly examining whether experience with emotional faces influences the development of this ability. In the current study, rather than examining the relationship between infants' natural experiences and their ability to match emotional information expressed across the face and voice, we experimentally manipulated infants' exposure to emotional faces and measured the effect this manipulation has on this ability. Specifically, we investigated whether infants can match fearful and happy faces and voices and whether consistent exposure to fearful or happy facial expressions will influence their ability to match fearful and happy faces and voices in an intermodal preference task. We chose to examine infants' ability to intermodally match happy and fearful expressions of emotion because this ability has not been assessed using this emotion pair and it is unknown whether exposure to happy and fearful faces in early infancy influences this ability. Three-month-old infants were recruited and assigned to a happy condition, a fear condition, or a no-training condition. In the happy and fear training conditions, infants received a picture book containing pictures of female faces expressing either happiness or fear. At 5 months, the ability to match happy and fearful



91

Experience and Emotion Processing facial and vocal expressions of emotion was measured in an intermodal preference task. Given that no studies have examined whether infants' can match facial and vocal fearful expressions of emotion we also assessed this ability in an independent group of 7-monthold infants, an age at which we know intermodal matching is robust for other emotions. Infants reliably demonstrate the ability to detect common emotion expressed by both face and voice (e.g., happy, sad, angry, interested) by 7 months of age (see Grossmann, 2010 for a review). Additionally, by 7 months, infants demonstrate reliable looking preferences for fearful over happy faces, suggesting that they are able to discriminate these emotions. Thus, we predicted that 7-month-olds would demonstrate successful matching. We hypothesized that 5-month-old infants would show differential performance depending on the condition to which they had been assigned. Specifically, we predicted that 5-month-olds in the fearful condition, but not the happy condition or no-training condition, would match fearful and happy facial expressions of emotion to the appropriate vocal expression because training with fearful faces might facilitate sensitivity to and detection of fearful faces earlier than 7 months of age. Method Participants Forty-two infants between 4.5 and 5.5 months (M age = 152.02 days, SD = 11.67 days, 24 boys) participated. These infants were recruited at 3 months of age and returned to the lab following training with fearful faces, training with happy faces, or no training (as described in Chapter 3). An independent group of 16 infants between 6.5 and 7.5 months of age (M age = 211.5 days, SD = 12.32 days, 7 boys) participated. All infants were born within (+/-) 4 weeks of their due date. Per parent report, none of the infants



92

Experience and Emotion Processing had been diagnosed with visual impairment or clinical disorders (e.g., pervasive developmental disorders, fetal alcohol spectrum disorders). The sample comprised Caucasian (n = 31), Black (n = 2), East Asian (n = 9), South Asian (n = 1), and Mixed (n = 14) participants. Eleven additional infants were tested at both ages but their data were excluded from analysis due to fussiness (n = 8), experiment error (n = 2), completed less than 50% of the reading schedule (n = 1). Stimuli Auditory stimuli consisted of one audio speech statement "Dogs are sitting by the door" expressed in a happy and fearful tone of voice by two adult females. These stimuli were obtained from the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) (Livingstone, Peck, & Russo, 2012). The database consists of two intensity versions of each of the stimuli: strong and normal. We used the strong intensity version of the speech statement as stimuli in the current study because stronger intensity expressions were identified more accurately than normal intensity expressions (Livingstone, Peck, & Russo, 2012). Fearful speech expressions were identified more accurately than happy speech expressions (Livingstone et al., 2012). Test-retest reliability indicated high overall concordance between raters' identification of happy and fearful speech expressions. Overall, validity and reliability obtained for the full set of expressions was considered to be high relative to other stimulus sets (Livingstone et al., 2012). Face stimuli consisted of colour photographs of two female models displaying the facial expressions happy and fear obtained from the Karolinska Directed Emotional Face Set (image IDs F20HAS, F20AFS, F33HAS, F33AFS, Lundqvist, Flykt & Öhman, 1998).



93

Experience and Emotion Processing Procedure This study was part of the larger study described in Chapter 3. As described in the Method section in Chapter 3, the initial visit for the larger study occurred when the infant was 3 months old. Infants visited the lab and the parent was provided with a consent form (see Appendix D) and the Demographic Questionnaire (see Appendix B). Next infants participated in two tasks (VPC and ERP), and were then randomly assigned to the fearful condition, the happy condition, or the no-training condition. Infants in the fearful and happy conditions were sent home with a picture book containing six faces expressing either fearful or happy facial expressions (see Appendix E) and were given a reading schedule (see Appendix F) and reading log (see Appendix G). Infants in the no-training condition did not receive any training. Infants returned to the lab at 5 months of age. At this visit, the parent was provided with the same consent form as in the first visit and the experimenter explained the study in detail. Parents filled out the Compliance Scale (see Appendix H) to determine how closely they followed the reading schedule. Of the infants in the fearful and happy training conditions, 7 participants completed greater than 100% of reading sessions, 3 participants completed 100% of reading sessions, 15 participants completed 75-99% of reading sessions, 2 participants completed 55-74% of reading sessions and 3 participants did not return the compliance scale. On average parents completed 93% of the reading sessions. Following completion of the questionnaire, participants were guided to a testing room where the infants participated in three tasks: the VPC and ERP tasks described in Chapter 3 and the intermodal preference task. During the intermodal preference task, infants sat on their parent's lap facing a computer screen. A video camera was situated



94

Experience and Emotion Processing directly above the computer screen to capture infant looking behaviour. The video signal was projected onto a second computer screen in an adjacent room viewed by the experimenter, which allowed the experimenter to monitor infant looking behaviour online throughout the experiment. Parents wore a sleep mask throughout the task to control for possible parent influence on infant looking behaviour. The intermodal preference task was programmed in E-Prime (Psychology Software Tools, 2002). The experimenter only started trials when the infant was looking at the screen. The task consisted of four trials: two silent trials and two sound trials. Infants were first presented with two 20-second silent trials consisting of happy and fearful facial expressions, expressed by one female face, paired on a computer screen. Infants then saw two 20-second sound trials consisting of the same happy and fearful facial expressions paired on a computer screen as in the first two trials. From a viewing distance of 60cm, each face image subtended approximately 19 x 24 degrees of visual angle. Simultaneously infants heard the speech statement "dogs are sitting by the door" expressed by one female in either a happy or fearful tone of voice. The speech statement was looped to create a 20-second soundtrack. The intensity of the soundtracks expressed by female 1 was 62.8 dBA for the happy soundtrack and 65.4 dBA for the fear soundtrack; and for female 2 was 54.3 dBA for the happy soundtrack and 62.8 dBA for the fear soundtrack. The order of the soundtracks, and left/right presentation order of the facial expressions were reversed and counterbalanced across all trials. Two identity versions of the experiment were created and counterbalanced across infants (Figure 10). The task procedure was identical for the independent group of 7-month-old infants tested (see Appendix I for consent form). The experimenter and a research assistant blind to the left-right position of the fearful and



95

Experience and Emotion Processing happy facial and vocal expressions coded infant looking time offline. Trials were coded frame-by-frame at 30 frames/second using DataVyu (v1.2). Inter-observer reliability was r = .87 based on 20% of total infant looking time data.



96

Experience and Emotion Processing Figure 10. Example of intermodal matching task in Study 3. Infants saw all four 20second trials. Image IDs displayed F20HAS and F20AFS.





 

Trial 1 Silent (20s)

Trial 2 Silent (20s)

Trial 3 Happy soundtrack (20s)

Trial 4 Fearful soundtrack (20s)



97

Experience and Emotion Processing Results Analysis plan We calculated two metrics to determine whether infants demonstrated intermodal matching. First, we examined infants' performance in the sound trials only by calculating proportion looking time to the congruent expression for each of the sound trials (looking time to congruent expression/looking time to the congruent expression + incongruent expression) and averaged these values across the two trials. One sample t-tests were then computed comparing infants' proportion looking time to the congruent facial expression against a chance value of .5, in each of the training conditions. Second, we examined infants' performance in the sound trials, correcting for pre-existing looking preferences, by calculating two difference scores for each infant (see Flom, Whipple & Hyde, 2009): (1) Fearful difference score = proportion of looking time to the fearful facial expression in the presence of the congruent sound - proportion of looking time to the fearful facial expression across both silent trials (2) Happy difference score = proportion of looking time to the happy facial expression in the presence of the congruent sound - proportion of looking time to the happy facial expression across both silent trials Next, one sample t-tests were conducted comparing these happy and fearful difference scores against a value of 0 (indicating no difference in infants' proportion looking to the congruent facial expression in sound trials as compared to looking to facial expression in the silent trials). Congruency analysis One sample t-tests revealed that neither 7-month-old infants nor 5-month-olds in



98

Experience and Emotion Processing any training condition (fearful, happy, neutral) demonstrated significantly greater looking to the congruent expression across both sound trials (7-month-olds: M = .46, SD = .16, t(15) = -.932, p = .366, d = .23; 5-month-old fearful condition: M = .52, SD = .23, t(11) = .406, p = .693, d =.12; 5-month-old happy condition: M = .56, SD = .25, t(16) = 1.026, p = .32, d = .25; 5-month-old no-training condition: M = .51, SD = .21, t(12) = .171, p = .867, d = .05). Thus, contrary to our hypotheses, none of the infants demonstrated intermodal matching of happy and fearful facial expressions to the appropriate vocal expressions (Figure 11).



99

Experience and Emotion Processing Figure 11. Mean proportion looking time to the congruent happy and fearful expression in Study 3. Standard error of the mean is reported in parentheses and represented in error bars.
0.7 0.6 0.5 0.4 0.3 0.2 7 Months 5 Months Fearful 5 Months Happy 5 Months NoTraining Training training Condition .46 (.04) .52 (.07)

Proportion Looking Time to the Congruent Expression

.56 (.06)

.51 (.06)



100

Experience and Emotion Processing Although the preceding analysis demonstrated no intermodal matching when averaging across the fearful and happy trials, it is possible that infants might successfully match one of the two expressions only. Therefore, we compared proportion looking to the congruent expression to chance separately for the happy trial and fearful trial. As above, one sample t-tests against chance revealed that 5-month-olds in any of the training conditions (fearful, happy, neutral) did not demonstrate significantly greater looking to the congruent fearful expression (5-month-old fearful condition: M = .53, SD = .2, t(11) = .377, p = .714, d =.11; 5-month-old happy condition: M = .6, SD = .25, t(16) = 1.702, p = .108, d = .41; 5-month-old no-training condition: M = .55, SD = .27, t(12) = .644, p = .532, d = .18) or the congruent happy expression (5-month-old fearful condition: M = .52, SD = .27, t(11) = .308, p = .764, d =.09; 5-month-old happy condition: M = .51, SD = .28, t(16) = .215, p = .833, d = .05; 5-month-old no-training condition: M = .47, SD = .16, t(12) = -.718, p = .486, d = .2). Similarly, 7-month-olds did not demonstrate intermodal matching of the happy expression M = .47, SD = .23, t(15) = -.608, p = .552, d = .15. Due to violation of normality indicated by the Shapiro-Wilk test, w(16)= .855, p=.016, we conducted a binomial test to determine whether the observed proportion of 7-month-old infants demonstrating intermodal matching of the fearful facial expression significantly differed from chance (50%). Results revealed that only 3 of 16 7-month-olds demonstrated longer looking to the congruent fearful facial expression; this proportion was significantly less than expected by chance, binomial probability, p = .021, two-tailed. Congruency analysis corrected. One sample t-tests revealed neither 7-month-old infants, nor 5-month-olds in any training condition (fearful, happy, neutral), demonstrated a congruency effect when correcting for performance on the silent trials for either the



101

Experience and Emotion Processing happy or fearful expression (Table 2, Figure 12). This confirms our first analysis showing no evidence of intermodal matching of happy and fearful facial and vocal expressions.



102

Experience and Emotion Processing Table 2. Difference Score Analysis by Emotion and Condition Emotion Fearful Condition 7 months 5 months Fearful Happy No-training    .064 (.26) .068 (.25) .005 (.27) 11 16 12 .84 1.106 .061 .419 .285 .952 .24 .27 .02 -.018 (.26) .048 (.32) .007 (.2) 11 16 12 -.232 .617 .128 .821 .546 .901 .07 .15 .04 M (SD) df t p d .38 M (SD) -.018 (.2) df 15 Happy t -.358 p .725 d .09

-.067 (.17) 15

-1.534 .146



103

Experience and Emotion Processing Figure 12. Corrected proportion looking time to the congruent expression in Study 3. The dark gray bars represent mean difference scores for the happy expression. The light gray bars represent mean difference scores for the fearful difference scores. Error bars represent standard error of the mean.
0.15 0.1 Differemce Score 0.05 0 -0.05 -0.1 7 months 5 months Fearful 5 months Happy 5 months Notraining Fearful Happy

Condition



104

Experience and Emotion Processing Discussion This study examined whether infants are able to intermodally match fearful and happy faces and voices and whether consistent exposure to fearful or happy facial expressions influences this ability in an intermodal preference task. Neither 7-month-old infants nor 5-month-olds in any training condition (fearful, happy, no-training) demonstrated significantly greater looking to the congruent expression across both sound trials, nor when happy and fearful expressions were considered separately. There was also no evidence of intermodal matching when we corrected for pre-existing looking preferences. Therefore, we found no evidence of intermodal matching of happy and fearful facial and vocal expressions at either 5 or 7 months of age. We hypothesized that both 7-month-old infants and 5-month-old infants in the fearful training condition would display intermodal matching of these expressions, yet they did not. This is surprising because a) intermodal matching of other emotional expressions (e.g., happy, sad, angry) is robust by 7 months (Soken & Pick, 1992; 1999; Walker, 1982; Walker-Andrews, 1986); b) 5-month-olds are also able to match happy and sad facial and vocal expressions under certain conditions (i.e., temporal synchrony; Walker, 1982); and c) experience facilitates intermodal matching of emotional expressions and discrimination of intermodal emotional expressions (Kahana-Kalman & Walker-Andrews, 2001; Lewkowitz & Ghazanfar, 2006; Montague & Walker-Andrews, 2001; 2002; Vogel et al., 2011; Walker-Andrews et al., 2011). There are several explanations that might account for why infants did not display intermodal matching of happy and fearful emotional expressions. First, it is possible that intermodal matching is only present for certain emotion pairs. The current study is the



105

Experience and Emotion Processing first to test infants using happy and fearful emotion pairs. It is possible that infants need sufficient experience with both expressions of emotion in a pair to display successful matching. Although infants are frequently exposed to happy facial expressions, exposure to negative expressions, perhaps especially fear and anger, is less frequent (Malatesta & Haviland, 1982), particularly for younger infants who are less likely to be mobile. Second, several aspects of the particular procedure used in this study may have made it more difficult for infants to display intermodal matching. We used static photographs of faces, whereas previous intermodal matching studies have primarily used dynamic presentation of facial expressions (Walker, 1982; Walker-Andrews, 1986). Some researchers have argued that the use of dynamic emotional faces provides infants with the best opportunity to display their capabilities because the changes expressed in dynamic faces may offer more information than static faces (Heck, Hock, White, Jubran & Bhatt, 2016; 2017; Walker-Andrews, 1997). In addition to the lack of dynamic information, using static photographs also prevents infants from using temporal synchrony to assess the match between facial and vocal expressions of emotion. WalkerAndrews (1986) found that temporal synchrony is necessary for 5-month-old infants to intermodally match happy and sad facial and vocal expressions, although 7-month-olds are able to match even temporally asynchronous stimuli (Walker, 1982; WalkerAndrews, 1986). Finally, trials in the current study were only 20 seconds long, whereas most previous studies investigating intermodal matching using longer trials (e.g., 2 minutes; Walker, 1982; Walker-Andrews, 1986). It is possible that infants, particularly 5month-olds, required more time to process the common invariant emotional information expressed across the face and voice to demonstrate intermodal matching. However, Flom,



106

Experience and Emotion Processing Whipple and Hyde (2009) found that 6-month-old infants showed intermodal matching of canine facial and vocal emotional expressions during 20-second test trials, although older (14- and 18-month-old) infants only showed intermodal matching during the first half of the test trials. It is possible that at least 7-month-olds might show intermodal matching of happy and fearful facial and vocal expressions if we examine infant looking to the congruent expression pair in the first and second 10 seconds of the sound test trials independently. Third, it is possible that the stimuli used in the current study were not the best representations of happy and fearful facial and vocal expressions. In particular, adult accuracy in recognizing the fearful faces was relatively low (43%; Goeleven et al., 2008), although it was still significantly above chance. The happy and fearful vocal expressions were also not rated for intensity; if the facial and vocal expressions were not matched in intensity, this might have made it more difficult for infants to match them. Overall, the present findings suggest that 5- and 7-month-old infants do not demonstrate intermodal matching of happy and fearful facial and vocal expressions of emotion. Importantly, exposure to happy and fearful facial expressions did not influence this ability. The fact that 7-month-olds did not show this ability make it difficult to interpret why a specific effect of training was not found at 5 months of age. Studies testing infants at different ages with different emotion pairs and methodological parameters are needed to better understand the effect of experience on intermodal matching in infancy. For example, future research should consider training with happy and angry facial expressions, since matching of these facial and vocal expressions is robust by 7 months of age.



107

Experience and Emotion Processing CHAPTER 5 General Discussion The overall goal of this dissertation was to examine the effects of experience with familiar face types and emotional faces on emotional face processing in infancy. We examined infants' performance using three different metrics (visual paired-comparison, ERP, and intermodal preference). There were five main findings. First, experience with familiar face types (i.e., own-race faces) influenced how infants deploy their attention to different facial expressions at 6 and 9 months of age. In a VPC task, 6-month-old infants showed an attentional preference for fearful over happy facial expressions when expressed by own-race faces, but not other race-faces, whereas 9-month-old infants showed an attentional preference for fearful expressions when expressed by both ownrace and other-race faces (Chapter 2). These results suggest that the attentional preference for fear might initially be restricted to face types with which infants have the most experience, and later be generalized to faces with which they have less experience. Second, sensitivity to fearful facial expressions is already established by 3 months of age. In a VPC task, 3-month-old infants and 5-month-old infants without training on fearful faces showed an attentional preference for fearful over happy facial expressions (Chapter 3). Third, 3- and 5-month-old infants do not show differential neural processing of happy and fearful facial expressions, at least for the Nc component over frontocentral brain regions (Chapter 3). Fourth, 5- and 7-month-old infants did not show intermodal matching of happy or fearful facial expressions (Chapter 4). Fifth, differential experience with emotional faces through picture books did not affect infant emotion processing in the ways we hypothesized. The only potential effect of training appeared for the VPC



108

Experience and Emotion Processing task (Chapter 3), where the direction of effects was the opposite of the predicted pattern of results. Specifically, infants who experienced fearful faces during training showed an attenuated preference for fearful facial expressions compared to infants who experienced happy faces or no training. Stepping back, what does this series of studies reveal about the effects of experience on emotional face processing? We found some evidence that experience does influence emotional face processing, however effects were not in the directions we initially hypothesized. In Chapter 2, infants showed greater sensitivity to fearful facial expressions when expressed by faces with which infants had experience (own-race faces), and only later did this sensitivity generalize to less familiar face types (other-race faces; Chapter 2). This is consistent with previous studies reporting that experience with familiar faces (i.e., mother), and face types (i.e., female faces) facilitates emotion processing (Barrera & Maurer, 1981; Bayet et al., 2015; Kahana-Kalman & WalkerAndrews, 2001; Montague & Walker-Andrews, 2002; Walker-Andrews et al., 2011). Why does familiarity with a particular face type facilitate emotional face processing? It is possible that 6-month-old infants more readily attend to fearful facial expressions when expressed by own-race faces because these faces are comprised of perceptual features with which they are familiar (e.g., shape of eyes); thus, infants are better able to detect changes in these facial features, which in turn, facilitates their sensitivity to facial expressions (Kelly et al., 2007). Alternatively, or in addition, it is possible that infants may be greater attuned to facial expressions expressed by frequently experienced faces because they have learned that these facial expressions are relevant indicators of



109

Experience and Emotion Processing subsequent actions, thus allowing infants to anticipate upcoming interactions and behavior (Kahana-Kalman & Walker-Andrews, 2001). Additional evidence that experience affects emotion processing comes from our investigation examining how experience with emotional faces impacts fearful face processing (Chapter 3). Contrary to our predictions, experience with fearful faces between 3 and 5 months of age did not engender an attentional bias for fear in 5-montholds; rather, 5-month-olds who had more experience with fearful faces showed, if anything, an attenuated looking preference for fearful faces. Perhaps training led to increased familiarity with fearful faces, such that they did not demonstrate a looking preference. This interpretation is consistent with some studies suggesting that infrequent experience with fearful faces drives infants' attentional looking preference for fearful facial expressions (de Haan et al., 2004; Nelson & Dolgin, 1985; Vaish et al., 2008). However, this explanation contrasts with more recent theoretical perspectives suggesting that experience with fearful faces facilitates sensitivity to fearful facial expressions and subsequent learning (Leppänen & Nelson, 2009; 2012). Several reasons might account for why experience with fearful facial expressions might not have facilitated an attentional looking preference for fearful faces. One possibility might be related to an absence of fear learning prior to the formation of attachment patterns. Recent studies investigating early associational learning and attachment patterns in rat pups suggests that during the first 10 days of life rat pups show less aversion to negative or threat-related stimuli, and thus do not readily form aversive associations with behaviour (Languille, Richer, & Hars, 2009; Moriceau & Sullivan, 2005; 2006; Roth & Sullivan, 2005; Sullivan, Landers, Yeaman, & Wilson, 2000). This is



110

Experience and Emotion Processing due to a functionally undeveloped amygdala, which later plays a key role in emotional learning (Tottenham, 2013). This period is critical for the development of attachment patterns, thus a delay in fear learning may serve to safeguard the development of secure attachment patterns with the caregiver. After this early period, when attachment patterns are established and rat pups begin to explore away from the nest or their mother leaves the nest, typical avoidance behaviour toward aversive and threat evoking stimuli is demonstrated (Languille, Richer, & Hars, 2009; Moriceau & Sullivan, 2006). It is speculated that a similar pattern of development may occur in human infants, such that fear learning may not develop until later in the first year to facilitate the development of infant-caregiver attachment (Tottenham, 2013). Thus, despite enhanced detection to and experience with fearful stimuli, fear learning may not develop until later in the first year to facilitate the development of infant-caregiver attachment. Consistent with this hypothesis, stranger anxiety and social referencing when presented with a potentially threatening situation does not emerge until 6 to 7 months of age (Hoehl et al., 2008; see Leppänen & Nelson, 2012; Schaffer, 1966; Striano & Rochat, 2000; Vaish & Striano, 2004). Additionally, it is possible that the type of experience infants in our study received did not promote increased sensitivity to fearful facial expressions. It is suggested that enhanced attention to fearful facial expressions of emotion coincides with the development of motor skills, such as crawling and increased time away from their caregiver (Campos, Kermoian, & Zumbahlen, 1992; Vaish et al., 2008). For example, the onset of crawling is associated with a wider repertoire of facial expressions expressed by caregivers and greater caregiver monitoring on the part of the infant. During this time



111

Experience and Emotion Processing increased detection of fearful facial expressions expressed by caregivers and associations between threatening social objects or situations and fearful facial expressions is behaviourally relevant (Campos et al., 1992; Peltola et al., 2013). Perhaps infants in our investigation did not form these associations because the quality of experience is important. In our study we showed infants photographs of females expressing fearful faces labeled at the individual level. Perhaps infants require experience with ecologically valid stimuli expressed by relevant faces for fear learning to occur. Since infants are first exposed to facial expressions of emotion through interactions with caregivers, providing infants with training with infant caregiver faces might have facilitated sensitivity to fearful facial expressions and encouraged fear learning. In addition, it is possible that fearful expressions need be experienced in a triadic context. Hoehl and Striano (2010) examined whether 3-, 6- and 9-month-old infants demonstrate increased sensitivity to fearful facial expressions when expressed in a triadic context. Fearful facial expressions were either expressed with averted eye gaze referencing an unfamiliar object (triadic context), or expressed with averted gaze referencing no object. Six-month-olds, but not 3-month-olds displayed increased allocation of attention (indexed by greater Nc amplitudes) in response to fearful facial expressions compared to neutral facial expressions only when fear was expressed in a triadic context. In contrast, at 9 months of age infants demonstrated greater Nc amplitudes in response to fearful facial expressions compared to neutral facial expressions in both types of contexts. Results suggest that infants are first sensitive to fearful facial expressions when expressed within certain social contexts, particularly those by which information regarding the source of threat is provided. However, by 9 months of age detection of fearful facial expressions is no



112

Experience and Emotion Processing longer dependent on context (Hoehl & Striano, 2010). In our investigation providing infants exposure to fearful facial expressions within context might have promoted fear detection and learning. Limitations and Future Directions It is important to consider a number of possible limitations that may have influenced the results in the current series of studies. First, in our investigation of experience with own- and other-race face types on emotion processing (Chapter 2, Study 1), we only tested Caucasian infants' attentional looking preference to facial expressions expressed by own- and other-race faces. The current conclusions should be treated as tentative until the results are replicated in a comparable sample of East Asian infants presented with the same stimuli. If the same pattern of results emerges, this would provide considerable support for the current findings. A second limitation, specific to our study examining the effect of experience with emotional faces on emotion processing (Chapter 3, Study 2), was reduced statistical power as a result of small sample sizes at 5 months of age, especially in the ERP task. This was due to a) attrition rate (~15% of babies did not return at 5 months), and b) exclusion of ERP data due to excess artifact in the ERP data, although it is important to point out that our attrition rate is comparable with other studies using ERP with infants (Stets, Stahl, & Rield, 2012). It is possible that with increased power we might have found differences in Nc response to happy and fearful facial expressions at 3 and/or 5 months of age. Although a strength of this study was its longitudinal design in order to track the development of attentional preferences to happy and fearful facial expressions and effect



113

Experience and Emotion Processing of experience, a limitation was that we did not test infants at 7 months of age. Given that a preference for fearful facial expressions is robust by this age (Kotsoni et al., 2001; Ludemann & Nelson, 1988; Nelson & Dolgin, 1985; Peltola et al., 2009), continued tracking of this ability may have potentially provided a clearer picture of its developmental trajectory and experiential effects at the behavioural and neural level. Thus, results should be replicated in a larger study with larger sample sizes, and extended longitudinal design. It should also be acknowledged that the samples in this study and in our study examining the effect of experience with emotional faces on emotion processing using intermodal matching (Chapter 4, Study 3) were ethnically diverse. Considering our findings in Study 1 suggesting an influence of face category (own- and other-race faces) on an attentional looking bias to fearful faces it would be interesting to examine whether the our findings in Studies 2 and 3 (Chapters 3 and 4, respectively) differ if we only included the Caucasian infants in our sample in the analyses. However, this would further reduce our already small sample size in each of the three training conditions, making it even more difficult to draw meaningful conclusions. Another limitation was the use of static stimuli across all studies. Dynamic stimuli are likely to offer more information about emotions portrayed in facial expressions than static stimuli (Walker-Andrews, 1997). Infants also tend to demonstrate better face processing abilities when tested with dynamic compared to static stimuli (Heck et al., 2016; 2017; see Quinn et al., 2011; Walker-Andrews, 1997). Moreover, dynamic stimuli are encountered more often by infants, and are thus more ecologically valid (see Quinn et al., 2011). Future studies using dynamic stimuli are needed to see whether infants'



114

Experience and Emotion Processing performance differs if stimuli are dynamic. For instance, it is possible that in our investigation 5-and 7-month-olds may have shown intermodal matching of happy and fearful facial expressions (Chapter 4, Study 3) if stimuli were dynamically rather than statically presented. A strength of the current series of studies was our use of multiple metrics of emotion processing. Although the metrics we chose are established in the field for examining infant emotion processing, they are difficult to interpret (e.g., VPC task), a criticism that can be leveled at much of the field. This is especially the case when metrics do not yield consistent findings. Eye-tracking should be considered for future studies examining emotion processing in order to elucidate the actual mechanisms underlying infants' emotion preferences, and to track how these mechanisms change across development. Lastly, a caveat across all studies was that we only investigated processing of happy and fearful facial expressions. Thus, it is unclear whether our pattern of results might be specific to these emotions tested. Infants show dissimilar developmental trajectories for different emotional expressions (see Walker-Andrews, 1997 for a review) and it is possible that processing of emotional faces other than happy and fear are differentially susceptible to experience. Future work is needed to investigate how experience with familiar face types and emotional faces influences infants' processing of other emotional faces. The current series of studies are a valuable addition to the literature examining the effects of experience on emotion processing in infancy. Importantly, findings contribute to our understanding of the developmental trajectory of fear processing, indicating



115

Experience and Emotion Processing sensitivity at an earlier age than previously documented. Additionally, preliminary findings shed light on experiential perspectives of the development of emotion processing, suggesting that infrequent exposure to fearful faces might drive, in part at least, an increased attentional looking preference for fearful facial expressions at an early age. Results contribute to the evolving literature highlighting the importance of experience on the development of emotional face processing in infancy.



116

Experience and Emotion Processing Appendix A Ryerson University Consent Agreement Investigating the Role of Experience in Infants' Ability to Recognize Facial Expressions of Emotion You and your infant are being asked to participate in a research study. Before you give your consent to be a volunteer, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do. Investigators: This study is being conducted by Kristina Safar, a PhD student in the Department of Psychology at Ryerson University. The research supervisor on this project is Margaret Moulson, PhD, director of the Brain and Early Experiences (BEE) Lab in the Department of Psychology at Ryerson University. Purpose of the Study: Facial expressions of emotion are one of the first ways in which infants interact and communicate with other individuals. The ability to discriminate between facial expressions is fundamental for the development of caregiver relationships, regulation of emotions and later more sophisticated social skills. Therefore, it is essential to fully understand an infant's ability to perceive facial expressions. However, it is unclear whether previous experience with specific faces, such as faces of the same ethnic background as the infant, may affect an infant's ability to tell the difference between facial expressions. In this study, using a looking time paradigm, we will examine whether 6-month-old and 9-month-old infants can recognize facial expressions when posed by different individuals of the same or of a different background than the infant. Sixty-four infants and their parents/legal guardians are being recruited to participate in this study. You and your infant were identified as possible participants in this study because your infant is currently within our age range (6 or 9 months of age), and you had previously expressed interest in participating in developmental research studies at Ryerson University. Description of the Study: In this study, your infant will complete a looking time procedure. During this procedure, your infant will be sitting on your lap in front of a computer screen so that he/she can watch two photographs presented side-by-side of the same unfamiliar female face, either of the same ethnic background or of a different ethic background than your infant (i.e., Caucasian or Asian), expressing two different emotions (i.e., fear and happy). Throughout the study session infants will be recorded using a video camera in order to determine how long they looked at each photograph. This study is a one-time visit only, and will take place here in the Brain and Early Experiences (BEE) Lab, in a separate room. You will remain with your infant at all times throughout the study. The entire study session will take approximately 30 minutes, but the looking time procedure itself will only take about 10 minutes.

117

Experience and Emotion Processing What is Experimental in this Study: None of the procedures used in this study are experimental in nature, in the sense that they are commonly used by other researchers and have been found to be useful procedures for understanding infant development. From a technical or procedural point of view, part of this study is considered "experimental," because the looking time procedure described above examines the impact of one variable (called the "independent variable" ­ in this case, new vs. old facial expression and ethnic background) on another variable (called the "dependent variable" ­ in this case, infant looking time). Risks or Discomforts: It is possible that your infant may become bored or fussy while participating in this study, but no more than he/she might during day-to-day life. You are allowed to take breaks at any time you wish if your infant is becoming bored or fussy while viewing the photographs, and you can take as long as you need to settle him/her before we continue with the study. Additionally, you can discontinue the study at any point if you feel uncomfortable for any reason, or if your infant has become too tired or fussy to continue with it. Benefits of the Study: There are no direct benefits to you or your infant for participating in this study. However, parents who have participated in similar studies conducted by the research supervisor, Dr. Margaret Moulson, have generally reported that it was a fun and interesting experience. Additionally, this study will contribute to the scientific community by advancing our understanding of infants' perception of facial expressions of emotion when expressed by same and other race faces. Confidentiality: All of the information that we collect from you and your infant during this study will remain confidential. Your infant will be assigned a participant ID number, and any written notes we take, photographs, and the videotape of the study session will be identified only by this participant ID number. This material will be stored in locked filing cabinets in the BEE Lab, and stored separately from this consent form. All electronic copies of your information will be stored on password-protected computers in the BEE Lab. Only those researchers directly involved in this study will have access to your information, including the videotape of the study session. Researchers directly involved in the study will not use the data for any other studies (e.g., secondary- or meta-analysis). The data, videotape, and photographs will be stored for as long as required by the ethical and publication guidelines of psychology (generally 5 years following publication of the findings), after which time they will be destroyed. Incentives to Participate: For participating in this study, your infant will receive a small gift (e.g., a toy) at the end of the study session (approximate value $3.00). Even if you decide not to participate in this study, or discontinue participation partway through the study, your infant will still receive the gift as a token of our appreciation for coming in to the lab. Costs of Participation: There are transportation costs associated with participating in this study, due to your travel to the BEE Lab from your home. These costs will vary depending on your method of transportation, but will generally not exceed $10. These costs will not be compensated. However, if you drove or took TTC to campus, you will be compensated for your parking costs and TTC costs there and back (approximately $6.00). Voluntary Nature of Participation: Participation in this study is voluntary. Your choice of

118

Experience and Emotion Processing whether or not to participate will not influence your future relations with Ryerson University. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time without penalty or loss of benefits to which you are allowed. At any particular point in the study, you may refuse to answer any particular question or stop participation altogether. Questions about the Study: If you have any questions about the research now or during the study session, please ask. If you have questions later about the research, you may contact: Principal Investigator: Kristina Safar, Ph.D. student, Department of Psychology Telephone Number: 416-979-5000 x2189 Research Supervisor: Margaret Moulson, Ph.D., Department of Psychology Telephone Number: 416-979-5000 x2661 If you have questions regarding your rights as a human subject and participant in this study, you may contact the Ryerson University Research Ethics Board for information. Research Ethics Board c/o Office of the Vice President, Research and Innovation Ryerson University 350 Victoria Street Toronto, ON M5B 2K3 416-979-5042 Agreement: Your signature below indicates that you have read the information in this agreement and have had a chance to ask any questions you have about the study. Your signature also indicates that you agree to have your infant participate in the study, and that you have been told that you can change your mind and withdraw your consent to participate at any time. You have been given a copy of this agreement. You have been told that by signing this consent agreement you are not giving up any of your legal rights.

Name of Parent/Guardian of Participant (please print)

Name of Infant (please print)

Signature of Parent/Guardian of Participant

Date

119

Experience and Emotion Processing

Consent to Videotape: Your signature below indicates that you agree to have your infant videotaped during the study session. Videotaping during the study session can be stopped at anytime.

Signature of Parent/Guardian of Participant

Date

Signature of Investigator

Date

120

Experience and Emotion Processing Appendix B Demographic Questionnaire Demographic Information
 

Please fill out the following demographic information: 1. Infant's birthdate 2. Infant's race/ethnicity (please check all applicable): O Asian O Black/African American O Middle Eastern O Hispanic O Caucasian O Other (Pleasespecify) 3. Was the infant born full- term (born +/- 2 weeks from the expected due date)?

O Yes O No, please specify how many weeks before or after expected due date infant was born 4. Was the infant diagnosed with any clinical disorders? (i.e. pervasive developmental disorders, mental retardation, fetal alcohol spectrum disorders) O Yes O No 5. Was the infant diagnosed with any visual impairment? O Yes O No

121

Experience and Emotion Processing Appendix C Caucasian and East Asian Face Exposure Questionnaire Part A. Please fill out the following demographic information: 1. Infant's ethnicity (please check all applicable): oo oo oo oo oo oo oo South Asian East Asian Black/African American Middle Eastern Hispanic Caucasian Other (Please specify)

Part B. Please fill out the following information regarding YOUR interactions with your infant. 1b. What is YOUR relation to the infant (please check one)? oo Mother oo Father oo Legal Guardian 2b. Your ethnicity (please check all applicable): oo Asian oo Black/African American oo Middle Eastern oo Hispanic oo Caucasian oo Other (Please specify) 3b. How many days per week does the infant interact with you (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 4b. On average, what is the amount of time that the infant spends interacting with you during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour

122

Experience and Emotion Processing 5b. On average, what types of interactions does the infant typically have with you (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) Please fill out the following questionnaires about the SIX other caregivers with whom the infant interacts the most during a typical week. If your infant does not have six caregivers, please leave the section blank. Part C. Caregiver 1: 1c. What is the caregiver's relation to the infant (please check one)? oo Mother oo Father oo Grandmother oo Grandfather oo Aunt oo Uncle oo Cousin oo Great-grandparent oo Nanny oo Baby sitter oo Family friend oo Other (Please specify) 2c. Caregiver's ethnicity (please check all applicable): oo oo oo oo oo oo Asian Black/African American Middle Eastern Hispanic Caucasian Other (Please specify)

3c. How many days per week does the infant interact with this caregiver (please check one)? oo 1-2 days oo 3-4 days

123

Experience and Emotion Processing oo 5-7 days 4c. On average, what is the amount of time that the infant spends interacting with this caregiver during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour 5c. On average, what types of interactions does the infant typically have with this caregiver (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) Part D. Caregiver 2: 1d. What is the caregiver's relation to the infant (please check one)? oo Mother oo Father oo Grandmother oo Grandfather oo Aunt oo Uncle oo Cousin oo Great-grandparent oo Nanny oo Baby sitter oo Family friend oo Other (Please specify) 2d. Caregiver's ethnicity (please check all applicable): oo oo oo oo oo Asian Black/African American Middle Eastern Hispanic Caucasian

124

Experience and Emotion Processing oo Other (Please specify) 3d. How many days per week does the infant interact with this caregiver (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 4d. On average, what is the amount of time that the infant spends interacting with this caregiver during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour 5d. On average, what types of interactions does the infant typically have with this caregiver (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) Part E. Caregiver 4: 1e. What is the caregiver's relation to the infant (please check one)? oo Mother oo Father oo Grandmother oo Grandfather oo Aunt oo Uncle oo Cousin oo Great-grandparent oo Nanny oo Baby sitter oo Family friend oo Other (Please specify)

125

Experience and Emotion Processing 2e. Caregiver's ethnicity (please check all applicable): oo oo oo oo oo oo Asian Black/African American Middle Eastern Hispanic Caucasian Other (Please specify)

3e. How many days per week does the infant interact with this caregiver (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 4e. On average, what is the amount of time that the infant spends interacting with this caregiver during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour 5e. On average, what types of interactions does the infant typically have with this caregiver (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) Part F. Caregiver 5: 1f. What is the caregiver's relation to the infant (please check one)? oo Mother oo Father oo Grandmother oo Grandfather oo Aunt oo Uncle oo Cousin

126

Experience and Emotion Processing oo oo oo oo oo Great-grandparent Nanny Baby sitter Family friend Other (Please specify)

2f. Caregiver's ethnicity (please check all applicable): oo oo oo oo oo oo Asian Black/African American Middle Eastern Hispanic Caucasian Other (Please specify)

3f. How many days per week does the infant interact with this caregiver (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 4f. On average, what is the amount of time that the infant spends interacting with this caregiver during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour 5f. On average, what types of interactions does the infant typically have with this caregiver (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) Part G. Caregiver 6: 1g. What is the caregiver's relation to the infant (please check one)? oo Mother

127

Experience and Emotion Processing oo Father oo Grandmother oo Grandfather oo Aunt oo Uncle oo Cousin oo Great-grandparent oo Nanny oo Baby sitter oo Family friend oo Other (Please specify) 2g. Caregiver's ethnicity (please check all applicable): oo oo oo oo oo oo Asian Black/African American Middle Eastern Hispanic Caucasian Other (Please specify)

3g. How many days per week does the infant interact with this caregiver (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 4g. On average, what is the amount of time that the infant spends interacting with this caregiver during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour 5g. On average, what types of interactions does the infant typically have with this caregiver (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify)

128

Experience and Emotion Processing

Part H. Please indicate the amount of exposure to Caucasian and East Asian faces your infant encounters according to the following scale: 1-Strongly Disagree, 2-Disagree, 3Agree, 4- Strong Agree. 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. My infant sees many Caucasian caregivers on a daily basis... 1 2 3 4 My infant sees many East Asian caregivers on a daily basis... 1 2 3 4 My infant sees many Caucasian caregivers on a weekly basis... 1 2 3 4 My infant sees many East Asian caregivers on a weekly basis... 1 2 3 4 My infant spends the majority of time with Caucasian caregivers... 1 2 3 4 My infant spends minimal time with Caucasian caregivers...1 2 3 4 My infant spends the majority of time with East Asian caregivers... 1 2 3 4 My infant spends minimal time with East Asian caregivers...1 2 3 4 My infant interacts often with East Asian faces.... 1 2 3 4 My infants interacts predominately with Caucasian faces... 1 2 3 4 My infant interacts minimally with East Asian faces... 1 2 3 4 My infant interacts minimally with Caucasian faces... 1 2 3 4

Part I. Please fill out the following information regarding the infant's interactions with unfamiliar people. 1i. How many days per week does the infant visit public places (e.g., malls, parks, daycare, etc.) (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days 2i. How many days per week does the infant interact with unfamiliar people (please check one)? oo 1-2 days oo 3-4 days oo 5-7 days

129

Experience and Emotion Processing 3i. On average, what types of interactions does the infant typically have with unfamiliar people (please check one)? oo Non-direct interaction oo Direct brief interaction oo Direct interaction involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and not involving play with the infant oo Direct interaction during feeding, changing and other necessary caregiver activities and involving play with the infant oo Other (please specify) 4i. On average, what is the amount of time that the infant spends interacting with unfamiliar people during a typical interaction (please check one)? oo Less than 10 minutes oo Approximately half an hour oo Approximately one hour oo Greater than one hour

130

Experience and Emotion Processing Appendix D Ryerson University Consent Agreement The Role of Experience in Infants' Recognition of Facial Expressions of Emotion

 

You and your infant are being asked to participate in a research study. Before you give your consent to be a volunteer, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do.

 

Investigators: This study is being conducted by Kristina Safar, MA, a doctoral student in the Department of Psychology at Ryerson University. The research supervisor on this project is Margaret Moulson, PhD, director of the Brain and Early Experiences (BEE) Lab in the Department of Psychology at Ryerson University.

 
Purpose of the Study: Throughout the first year infants demonstrate a shift in their attention towards emotional facial expressions. Younger infants show a preference to look towards happy facial expressions; however, by approximately the second half of the first year infants show a preference to look at fearful facial expressions. This study is designed to look at what drives this change in looking preference. To do so, we will examine how early experience with particular emotions (e.g., fearful or happy facial expressions) shapes infants' preferences for emotions and how their brain responds to these emotions.

 
Approximately 80 infants and their parents/legal guardians are being recruited to participate in this study. You and your infant were identified as possible participants in this study because your infant is currently within our age range (3 months of age), and you had previously expressed interest in participating in developmental research studies at Ryerson University. Description of the Study: To participate, you and your infant will be asked to do the following: Attend Ryerson University for a 2-hour visit to: 1. complete a questionnaire about your infant, including demographic information 2. have your infant complete a computer-based looking task and a brain-based task   The tasks include: 1. A preference task: We will show your infant pairs of photographs of unfamiliar female faces posing facial expressions (happy and fearful). We can determine which emotional expression your infant prefers based on which face he/she looks at most. 2. A brain activity task: We will show your infant many faces expressing emotions while we record his/her natural brain activity using electroencephalogram (EEG). EEG is a safe, infantfriendly, non-invasive way of recording electrical brain activity. O During this task, your infant will sit on your lap. We will measure his/her head, draw a small `x' in grease pencil on the top of his/her head, then put on the special cap we use to record brain activity. The cap will first be soaked in warm water that has a little bit of salt and baby shampoo in it, so it will be damp when it is placed on your baby's head.

131

Experience and Emotion Processing O During these tasks, your infant will sit on your lap, but you will be asked to wear a sleep mask so that you do not influence your infant's reactions to the faces. (You may view the photographs your infant was shown after the task.) O Your infant will be video-recorded during all of these tasks, so that we can review, more precisely, how much time your infant spent looking at each emotional face. This will help us determine if your infant shows a preference for either of the emotions.

 
At the end of the visit you will receive a $10 honourarium for your time.

 

After the visit to Ryerson, you will be asked to read a picture book to your infant over the course of an 8-week period. The picture book is called "My First Facial Expressions of Emotion" and it has photographs of unfamiliar female faces expressing emotions (i.e., happy, fearful, or neutral). We will give you a reading schedule and ask you to log each time you read the book over the 8week period.

 
When your infant is 5 months of age you will be invited back to Ryerson University for another 2-hour visit. Your infant will complete the same computer-based and brain-based tasks that he/she completed during your initial visit to Ryerson University. Your infant will also complete one more computer-based task, an emotional matching task. During the matching task we will show your infant pairs of photographs of unfamiliar female faces posing facial expressions (happy and fearful). At the same time your infant will hear either a happy or fearful voice that will match one of the facial expressions. If your infant looks longer at the facial expression that matches the emotional voice, we can conclude that your infant has matched the emotional expressions. At the end of the second visit you will receive a $10 honourarium for your time.

 
What is Experimental in this Study: None of the procedures used in this study are experimental in nature, in the sense that they are commonly used by other researchers and have been found to be useful procedures for understanding infant development. The only experimental aspect of this study is the gathering of information for the purpose of analysis. Risks or Discomforts: It is possible that your infant may become bored or fussy while participating in the computer-based tasks, but no more than he/she might during day-to-day life. You are allowed to take breaks at any time you wish if your infant is becoming bored or fussy while viewing the photographs, and you can take as long as you need to settle him/her before we continue with the study. You can stop the study at any point if you feel uncomfortable for any reason, or if your infant has become too tired or fussy to continue with it.

 
Your infant may find the EEG cap uncomfortable. The cap is moist and snug, like a swim-cap, and some babies don't like the feeling of it when it is first placed on their head.We will adjust the cap to ensure your infant is as comfortable as possible and distract him/her with toys while we put it on. At any point, if you feel like your baby is uncomfortable, we can take the cap off.

 

132

Experience and Emotion Processing


We do not expect that learning fearful facial expressions over a two-month period will pose risks greater than that would be encountered in daily life. Infants in this study will be exposed to fearful faces for only a few minutes a day in the form of a picture book. This is very minimal compared to the large amount of time they spend interacting with their parents and other caregivers who likely express predominantly positive emotions to their infants. Thus, we expect that although exposure to fearful faces will facilitate infants' learning about fearful faces, there is no reason to suspect that this will adversely impact the development of emotion recognition more generally or negatively affect their social interactions with caregivers.
 

  

Benefits of the Study: There are no direct benefits to you or your infant for participating in this study. However, this study will contribute to the scientific community by advancing our understanding of infants' perception of facial expressions of emotion.   Confidentiality: All of the information that we collect from you and your infant during this study will remain confidential. Your infant will be assigned a participant ID number, and any written notes we take, photographs, and the videotape of the study session will be identified only by this participant ID number. This material will be stored in locked filing cabinets in the BEE Lab, and stored separately from this consent form. All electronic copies of your information will be stored on password-protected computers in the BEE Lab. Only those researchers directly involved in this study will have access to your information, including the videotape of the study session. The data, videotape, and photographs will be stored for as long as required by the ethical and publication guidelines of psychology (generally 5 years following publication of the findings), after which time they will be destroyed.

 

Incentives to Participate: For participating in this study, your infant will receive a small gift (e.g., a toy) at the end of the study session. Even if you decide not to participate in this study, or discontinue participation partway through the study, your infant will still receive the gift as a token of our appreciation for coming in to the lab. You will also receive a $10 honorarium for participating in this study.

 
Costs of Participation: There are transportation costs associated with participating in this study, due to your travel to the BEE Lab from your home. These costs will not be compensated.

 
Voluntary Nature of Participation: Participation in this study is voluntary. Your choice of whether or not to participate will not influence your future relations with Ryerson University. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time without penalty or loss of benefits to which you are allowed.

133

Experience and Emotion Processing At any particular point in the study, you may refuse to answer any particular question or stop participation altogether.

 

Questions about the Study: If you have any questions about the research now or during the study session, please ask. If you have questions later about the research, you may contact:

 
Principal Investigator: Kristina Safar, Ph.D. student, Department of Psychology Telephone Number: 416-979-5000 x2189

 
     

Research Supervisor: Margaret Moulson, Ph.D., Department of Psychology Telephone Number: 416-979-5000 x2661   If you have questions regarding your rights as a human subject and participant in this study, you may contact the Ryerson University Research Ethics Board for information. Research Ethics Board c/o Office of the Vice President, Research and Innovation Ryerson University 350 Victoria Street Toronto, ON M5B 2K3 416-979-5042

 

134 134

Experience and Emotion Processing Agreement:   Your signature below indicates that you have read the information in this agreement and have had a chance to ask any questions you have about the study. Your signature also indicates that you agree to have your infant participate in the study and be videotaped, and that you have been told that you can change your mind and withdraw your consent to participate at any time. You have been given a copy of this agreement.

 
You have been told that by signing this consent agreement you are not giving up any of your legal rights.
      


Name of Parent/Guardian of Participant (please print)

Name of Infant (please print)

  

135 135

Experience and Emotion Processing
 








Signature of Parent/Guardian of Participant

Date

Signature of Investigator

Date

136 136

Appendix E

 



137




138



139





140





141



142



143





144



145



146



147



148

149

150

Appendix F Reading Schedule


Reading Week # 1 2 3 4 5 6 7 8


Schedule Read once everyday Read once everyday Read once every other day Read once every other day Read once every third day Read once every third day Read once every fourth day Read once every fourth day

 

151

   Tuesday Wednesday Reading Log Thursday Friday Saturday Sunday

Monday

Week 1 Notes: Notes: Notes: Notes: Notes:

Read: Yes/No If yes, time read: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Notes:

Appendix G

152 Notes: Notes: Notes: Notes:

Week 2

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read: Notes:

Read: Yes/No If yes, time read: Notes:

Notes:

  

   Tuesday Wednesday Thursday Friday Saturday Sunday

Monday

Week 3 Notes: Notes: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Week 4 Notes: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read: Notes:

153

Notes:

  

   Tuesday Wednesday Thursday Friday Saturday Sunday

Monday

Week 5 Notes: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

Week 6 Notes: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

154

  

   Tuesday Wednesday Thursday Friday Saturday Sunday

Monday

Week 7 Notes: Notes:

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read:

155 Notes:

Week 8

Read: Yes/No If yes, time read:

Read: Yes/No If yes, time read: Notes:

  

  

Appendix H Compliance Scale 1. During weeks 1 and 2 of reading did you read to your infant a) everyday b) miss 1-2 days c) miss 3-4 days d) miss 5-7 days 1. During weeks 3 and 4 of reading did you read to your infant a) everyday other day b) miss 1-2 days c) miss 3-4 days d) miss 5-6 days 1. During weeks 5 and 6 of reading did you read to your infant a) everyday third day b) miss 1-2 days c) miss 3-4 days d) miss 5-6 days 1. During weeks 7 and 8 of reading did you read to your infant a) everyday fourth day b) miss 1-2 days c) miss 3-4 days d) miss 5-6 days 5. Who most often read to your infant? a) mother b) father c) grandma d) grandpa e) aunt f) uncle g) sibling h) nanny i) other, please specify 6. Did you find it easy to stick to the reading schedule? a) yes b) no Details 7. Did you read more often than stated on the reading schedule? a) yes


156

b) no If yes, how much more often? 8. Did your baby seem to enjoy reading time? a) yes b) no If no, do you have a sense of why not?

9. Did your baby seem interested in the pictures in the story book? a) yes b) no If no, do you have a sense of why not?

10. At what time of day did you most often read to your baby? a) mornings b) afternoons c) evenings d) variable If variable, what time of day did the majority of reading take place?

11. How long did each reading session last approximately? a) 5 minutes b) 10 minutes c) 15 minutes d) 20 minutes e) 25 minutes f) 30 minutes

157

Appendix I Ryerson University Consent Agreement Matching Facial Expressions of Emotion in Infancy You and your infant are being asked to participate in a research study. Before you give your consent to be a volunteer, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do. Investigators: This study is being conducted by Kristina Safar, MA, a doctoral student in the Department of Psychology at Ryerson University. The research supervisor on this project is Margaret Moulson, PhD, director of the Brain and Early Experiences (BEE) Lab in the Department of Psychology at Ryerson University. Purpose of the Study: Infants show the ability to detect emotions expressed by both faces and voices by 7 months of age. They can also match emotions in the face and voice ­ for example, they know that a happy face goes with a happy voice, and a sad face goes with a sad voice. However, no studies have examined whether infants can match fearful faces and voices. The goal of this study is to see if 7-month- old infants can do this. Approximately 20 infants and their parents/legal guardians are being recruited to participate in this study. You and your infant were identified as possible participants in this study because your infant is currently within our age range (7 months of age), and you had previously expressed interest in participating in developmental research studies at Ryerson University. Description of the Study: To participate, you and your infant will be asked to attend Ryerson University for a 30-minute visit. During the visit, we will ask you to complete a 5-minute questionnaire about your infant, including demographic information, crawling information, and the people your infant sees and interacts with. We will also have your infant participate in a computer-based emotion matching task. In this task, we will show your infant paired films of unfamiliar female faces posing happy and fearful facial expressions. At the same time, your infant will hear either a happy voice or a fearful voice. If your infant looks longer at the face that matches the voice, we can conclude that your infant can match these expressions. Your infant will sit on your lap during this task, but we will ask you to wear a sleep mask, so that you do not influence your infant's reactions to the faces expressing emotions. (You may view the photographs your infant was shown after the task.) We will video-record your infant during this task so that we can review how much time your infant spent looking at each emotional face. This study is a one-time visit only, and will take place here in the Brain and Early Experiences (BEE) Lab, in a separate room. You will remain with your infant at all times throughout the study. The entire study session will take approximately 30

158

minutes, but the emotion matching task itself will only take about 10 minutes. At the end of the study you will be provided with a $10 honourarium for your time have been found to be useful procedures for understanding infant development. The only experimental aspect of this study is the gathering of information for the purpose of analysis. What is Experimental in this Study: None of the procedures used in this study are experimental in nature, in the sense that they are commonly used by other researchers and have been found to be useful procedures for understanding infant development. The only experimental aspect of this study is the gathering of information for the purpose of analysis. Risks or Discomforts: It is possible that your infant may become bored or fussy while participating in the task, but no more than he/she might during day-to-day life. You are allowed to take breaks at any time you wish if your infant is becoming bored or fussy, and you can take as long as you need to settle him/her before we continue with the study. Additionally, you can discontinue the study at any point if you feel uncomfortable for any reason, or if your infant has become too tired or fussy to continue with it. Benefits of the Study: There are no direct benefits to you or your infant for participating in this study. However, this study will contribute to the scientific community by advancing our understanding of infants' perception of facial expressions of emotion. Confidentiality: All of the information that we collect from you and your infant during this study will remain confidential. Your infant will be assigned a participant ID number, and any written notes we take, photographs, and the videotape of the study session will be identified only by this participant ID number. This material will be stored in locked filing cabinets in the BEE Lab, and stored separately from this consent form. All electronic copies of your information will be stored on passwordprotected computers in the BEE Lab. Only those researchers directly involved in this study will have access to your information, including the videotape of the study session. The data, videotape, and photographs will be stored for as long as required by the ethical and publication guidelines of psychology (generally 5 years following publication of the findings), after which time they will be destroyed. Incentives to Participate: For participating in this study, your infant will receive a small gift (e.g., a toy) at the end of the study session. Even if you decide not to participate in this study, or discontinue participation partway through the study, your infant will still receive the gift as a token of our appreciation for coming in to the lab. You will also receive a $10 honorarium for participating. Costs of Participation: There are transportation costs associated with participating in this study, due to your travel to the BEE Lab from your home. These costs will not be compensated.

159

Voluntary Nature of Participation: Participation in this study is voluntary. Your choice of whether or not to participate will not influence your future relations with Ryerson University. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time without penalty or loss of benefits to which you are allowed. At any particular point in the study, you may refuse to answer any particular question or stop participation altogether. Questions about the Study: If you have any questions about the research now or during the study session, please ask. If you have questions later about the research, you may conta Principal Investigator: Kristina Safar, Ph.D. student, Department of Psychology Telephone Number: 416-979-5000 x2189 Research Supervisor: Margaret Moulson, Ph.D., Department of Psychology Telephone Number: 416-9795000 x2661 If you have questions regarding your rights as a human subject and participant in this study, you may contact the Ryerson University Research Ethics Board for information. Research Ethics Board c/o Office of the Vice President, Research and Innovation Ryerson University 350 Victoria Street Toronto, ON M5B 2K3 416-979-5042 Agreement: Your signature below indicates that you have read the information in this agreement and have had a chance to ask any questions you have about the study. Your signature also indicates that you agree to have your infant participate in the study and be videotaped, and that you have been told that you can change your mind and withdraw your consent to participate at any time. You have been given a copy of this agreement. You have been told that by signing this consent agreement you are not giving up any of your legal rights.

Name of Parent/Guardian of Participant (please print)

Name of Infant (please print)

160

Signature of Parent/Guardian of Participant

Date

Signature of Investigator

Date

Consent to Videotape Your signature below indicates that you agree to have your infant videotaped during the study session. Videotaping during the study session can be stopped at anytime.

Signature of Parent/Guardian of Participant

Date

Signature of investigator

Date

161

References Adolphs, R. (2002a). Neural systems for recognizing emotion. Current Opinion in Neurobiology, 12, 169-177. doi: 10.1016/S0959-4388(02)00301-X Adolphs, R. (2002b). Recognizing emotion from facial expressions: psychological and neurological mechanisms. Behavioral and Cognitive Neuroscience Reviews, 1, 21-62. doi: 10.1177/1534582302001001003 Adolphs, R., Tranel, D., Damasio, H., & Damasio, A. R. (1995). Fear and the human amygdala. Journal of Neuroscience, 15, 5879-5891. Aggleton, J. P., Burton, M. J., & Passingham, R. E. (1980). Cortical and subcortical afferents to the amygdala of the rhesus monkey (Macaca mulatta). Brain Research, 190, 347-368. doi: 10.1016/0006-8993(80)90279-6 Allison, T., Puce, A., & McCarthy, G. (2000). Social perception from visual cues: Role of the STS region. Trends in Cognitive Sciences, 4, 267-278. doi: 10.1016/S13646613(00)01501-1 Amaral, D. G. (2003). The amygdala, social behavior, and danger detection. Annals of the New York Academy of Sciences, 1000, 337-347. doi: 10.1196/annals.1280.015 Amaral, D.G., & Bennett, J. (2000). Development of amygdalo-cortical connections in the macaque monkey. Society for Neuroscience Abstracts, 26, 17­26. Amaral, D. G., Behniea, H., & Kelly, J. L. (2003). Topographic organization of projections from the amygdala to the visual cortex in the macaque monkey. Neuroscience, 118, 1099-1120. doi: 10.1016/S0306-4522(02)01001-1 Angrilli, A., Mauri, A., Palomba, D., Flor, H., Birbaumer, N., Sartori, G., & Di Paola, F. (1996). Startle reflex and emotion modulation impairment after a right amygdala

162

lesion. Brain, 119, 1991-2004. doi: 10.1093/brain/119.6.1991 Anzures, G., Quinn, P. C., Pascalis, O., Slater, A. M., Tanaka, J. W., & Lee, K. (2013). Developmental origins of the other-race effect. Current Directions in Psychological Science, 22, 173-178. doi: 10.1177/0963721412474459 Balaban, M. T. (1995). Affective influences on startle in five-month-old infants: Reactions to facial expressions of emotion. Child Development, 66, 28-36. doi: 10.1111/j.1467-8624.1995.tb00853.x Batty, M., & Taylor, M. J. (2003). Early processing of the six basic facial emotional expressions. Cognitive Brain Research, 17, 613-620. doi: 10.1016/S09266410(03)00174-5 Bar-Haim, Y., Ziv, T., Lamy, D., & Hodes, R. M. (2006). Nature and nurture in own-race face processing. Psychological Science, 17, 159-163. doi: 10.1111/j.14679280.2006.01679.x Bahrick, L. E., Lickliter, R., & Flom, R. (2004). Intersensory redundancy guides the development of selective attention, perception, and cognition in infancy. Current Directions in Psychological Science, 13, 99-102. doi: 10.1111/j.09637214.2004.00283.x Barone, P., Dehay, C., Berland, M., Bullier, J., & Kennedy, H. (1995). Developmental remodeling of primate visual cortical pathways. Cerebral Cortex, 5, doi: 22-38. 10.1093/cercor/5.1.22 Barrera, M. E., & Maurer, D. (1981). The perception of facial expressions by the threemonth-old. Child Development, 203-206. doi: 10.2307/1129231

163

Barth, J. M., & Bastiani, A. (1997). A longitudinal study of emotion recognition and preschool children's social behavior. Merrill-Palmer Quarterly, 43, 107-128. Bauman, M. D., & Amaral, D. G. (2008). Neurodevelopment of social cognition. In C. A. Nelson, & M. Luciana (Eds.), Handbook of developmental cognitive neuroscience (2nd ed., pp. 161-185). Cambridge, MA: MIT Press Bayet, L., Quinn, P. C., Tanaka, J. W., Lee, K., Gentaz, É., & Pascalis, O. (2015). Face gender influences the looking preference for smiling expressions in 3.5-month-old human infants. PloS one, 10, e0129812. doi: 10.6084/m9. figshare.1363637. Bentley, P., Vuilleumier, P., Thiel, C. M., Driver, J., & Dolan, R. J. (2003). Effects of attention and emotion on repetition priming and their modulation by cholinergic enhancement. Journal of Neurophysiology, 90, 1171-1181. Blair, R. J. R., Morris, J. S., Frith, C. D., Perrett, D. I., & Dolan, R. J. (1999). Dissociable neural responses to facial expressions of sadness and anger. Brain, 122. doi: 883893. 10.1093/brain/122.5.883 Bornstein, M. H., & Arterberry, M. E. (2003). Recognition, discrimination and categorization of smiling by 5-month-old infants. Developmental Science, 6, 585599. doi: 10.1111/1467-7687.00314 Bornstein, M. H., Arterberry, M. E., Mash, C., & Manian, N. (2011). Discrimination of facial expression by 5-month-old infants of non-depressed and clinically depressed mothers. Infant Behavior and Development, 34, 100-106. doi: 10.1016/j.infbeh.2010.10.002 Bowlby, J. (1982). Attachment and loss. Vol. I: Attachment (2nd ed.). New York: Basic (Original work published 1969).

164

Bush, G., Luu, P., & Posner, M. I. (2000). Cognitive and emotional influences in anterior cingulate cortex. Trends in Cognitive Sciences, 4, 215-222. doi: 10.1016/S13646613(00)01483-2 Bushnell, I. W. R., Sai, F., & Mullin, J. T. (1989). Neonatal recognition of the mother's face. British Journal of Developmental Psychology, 7, 3-15. doi: 10.1111/j.2044835X.1989.tb00784.x Campos, J. J., Kermoian, R., & Zumbahlen, M. R. (1992). Socioemotional transformations in the family system following infant crawling onset. New Directions for Child and Adolescent Development, 1992, 25-40. doi: 10.1002/cd.23219925504 Caron, A. J., Caron, R. F., & MacLean, D. J. (1988). Infant discrimination of naturalistic emotional expressions: The role of face and voice. Child Development, 604-616. doi: 10.2307/1130560 Caron, R. F., Caron, A. J., & Myers, R. S. (1982). Abstraction of invariant face expressions in infancy. Child Development, 1008-1015. doi: 10.2307/1129141 Chugani, H. T. (1998). A critical period of brain development: studies of cerebral glucose utilization with PET. Preventive Medicine, 27, 184-188. doi: 10.1006/pmed.1998.0274 Courchesne, E., Ganz, L., & Norcia, A. M. (1981). Event-related brain potentials to human faces in infants. Child Development, 804-811. doi: 10.2307/1129080 Critchley, H., Daly, E., Phillips, M., Brammer, M., Bullmore, E., Williams, S., Van Amelsvoort, T., Robertson, D., David, A., & Murphy, D. (2000). Explicit and implicit neural mechanisms for processing of social information from facial

165

expressions: A functional magnetic resonance imaging study. Human Brain Mapping, 9, 93-105. doi: 10.1002/(SICI)1097-0193(200002)9:2<93::AIDHBM4>3.0.CO;2-Z Davis, M., & Whalen, P. J. (2001). The amygdala: vigilance and emotion. Molecular Psychiatry, 6, 13-34. doi: 10.1038/sj.mp.4000812 De Haan, M., Belsky, J., Reid, V., Volein, A., & Johnson, M. H. (2004). Maternal personality and infants' neural and visual responsivity to facial expressions of emotion. Journal of Child Psychology and Psychiatry, 45, 1209-1218. doi: 10.1111/j.1469-7610.2004.00320.x De Haan, M., Johnson, M. H., & Halit, H. (2003). Development of face-sensitive eventrelated potentials during infancy: a review. International Journal of Psychophysiology, 51, 45-58. doi: 10.1016/S0167-8760(03)00152-1 De Haan, M., Pascalis, O., & Johnson, M. H. (2002). Specialization of neural mechanisms underlying face recognition in human infants. Journal of Cognitive Neuroscience, 14, 199-209. doi: 10.1162/089892902317236849 De Haan, M., & Nelson, C.A. (1998). Discrimination and categorisation of facial expressions of emotion during infancy. In A. Slater (Ed.), Perceptual development (pp. 287­309). Hove, UK: Psychology Press. De Haan, M., & Nelson, C. A. (1999). Brain activity differentiates face and object processing in 6-month-old infants. Developmental Psychology, 35, 1113-1121. doi: 10.1037/0012-1649.35.4.1113 DeLoache, J. S., & LoBue, V. (2009). The narrow fellow in the grass: Human infants associate snakes and fear. Developmental Science, 12, 201-207. doi:

166

10.1111/j.1467-7687.2008.00753.x Denham, S. A., Bassett, H. H., & Zinsser, K. (2012). Early childhood teachers as socializers of young children's emotional competence. Early Childhood Education Journal, 40(3), 137-143. 10.1007/s10643-012-0504-2 Ekman, Paul. (1972). "Universals and cultural differences in facial expressions of emotion. In J.Cole (ed.), Nebraska Symposium on Motivation 1971. Lincoln, NE: University of Nebraska Press. Ekman, P., & Friesen, W. V. (1971). Constants across cultures in the face and emotion. Journal of Personality and Social Psychology, 17, 124-129. doi: 10.1037/h0030377 Ekman, P., & Keltner, D. (1970). Universal facial expressions of emotion. California Mental Health Research Digest, 8, 151-158. Ekman, P., Sorenson, R.E., & Friesen, W.V. (1969). Pan-cultural elements in facial displays of emotion. Science, 164, 86-88. doi: 10.1126/science.164.3875.86 Elfenbein, H. A., & Ambady, N. (2002). On the universality and cultural specificity of emotion recognition: a meta-analysis. Psychological Bulletin, 128, 203-235. doi: 10.1037/0033-2909.128.2.203 Elfenbein, H. A., & Ambady, N. (2003). Universals and cultural differences in recognizing emotions. Current Directions in Psychological Science, 12, 159-164. doi: 10.1111/1467-8721.01252 Elfenbein, H. A., & Ambady, N. (2003). When familiarity breeds accuracy: cultural exposure and facial emotion recognition. Journal of Personality and Social Psychology, 85, 276-290. doi: 10.1037/0022-3514.85.2.276

167

Elfenbein, H. A., Beaupré, M., Lévesque, M., & Hess, U. (2007). Toward a dialect theory: cultural differences in the expression and recognition of posed facial expressions. Emotion, 7, 131-146. doi: 10.1037/1528-3542.7.1.131 Elfenbein, H.A., Mandal, M., Ambady, N., Harizuka, S., & Kumar, S. (2004). Hemifacial differences in the in-group advantage in emotion recognition. Cognition and Emotion, 18, 613-629. doi: 10.1080/02699930341000257 Emery, N. J., & Amaral, D. G. (2000). The role of the amygdala in primate social cognition. In R. Lane & L. Nadel (Eds.), Cognitive Neuroscience of Emotion (pp. 156­191). New York: Oxford University Press. Etkin, A., Egner, T., & Kalisch, R. (2011). Emotional processing in anterior cingulate and medial prefrontal cortex. Trends in Cognitive Sciences, 15, 85-93. doi: 10.1016/j.tics.2010.11.004 Farroni, T., Menon, E., Rigato, S., & Johnson, M. H. (2007). The perception of facial expressions in newborns. European Journal of Developmental Psychology, 4, 213. doi: 10.1080/17405620601046832 Feinman, S., & Lewis, M. (1983). Social referencing at ten months: A second-order effect on infants' responses to strangers. Child Development, 878-887. doi: 10.2307/1129892 Field, C. B., Johnston, K., Gati, J. S., Menon, R. S., & Everling, S. (2008). Connectivity of the primate superior colliculus mapped by concurrent microstimulation and event-related FMRI. PloS one, 3, e3928. doi: 10.1371/journal.pone.0003928

168

Field, T. M., Woodson, R., Greenberg, R., & Cohen, D. (1982). Discrimination and imitation of facial expression by neonates. Science, 218, 179-181. doi: 10.1126/science.7123230 Field, T. M., Woodson, R., Cohen, D., Greenberg, R., Garcia, R., & Collins, K. (1983). Discrimination and imitation of facial expressions by term and preterm neonates. Infant Behavior and Development, 6, 485-489. doi: 10.1016/S01636383(83)90316-8 Field, T. M., Cohen, D., Garcia, R., & Greenberg, R. (1984). Mother-stranger face discrimination by the newborn. Infant Behavior and Development, 7, 19-25. doi: 10.1016/S0163-6383(84)80019-3 Flom, R., & Bahrick, L. E. (2007). The development of infant discrimination of affect in multimodal and unimodal stimulation: The role of intersensory redundancy. Developmental Psychology, 43, 238-252. doi: 10.1037/0012-1649.43.1.238 Flom, R., Whipple, H., & Hyde, D. (2009). Infants' intermodal perception of canine (Canis familairis) facial expressions and vocalizations. Developmental Psychology, 45, 1143-1151. doi: 10.1037/a0015367 Forssman, L., Peltola, M. J., Yrttiaho, S., Puura, K., Mononen, N., Lehtimäki, T., & Leppänen, J. M. (2014). Regulatory variant of the TPH2 gene and early life stress are associated with heightened attention to social signals of fear in infants. Journal of Child Psychology and Psychiatry, 55, 793-801. doi: 10.1111/jcpp.12181 Fox, N. A., & Calkins, S. D. (2003). The development of self-control of emotion: Intrinsic and extrinsic influences. Motivation and Emotion, 27, 7-26. doi:

169

10.1023/A:1023622324898 Funayama, E. S., Grillon, C., Davis, M., & Phelps, E. A. (2001). A double dissociation in the affective modulation of startle in humans: effects of unilateral temporal lobectomy. Journal of Cognitive Neuroscience, 13, 721-729. doi:10.1162/08989290152541395 Goeleven, E., De Raedt, R., Leyman, L., & Verschuere, B. (2008). The Karolinska directed emotional faces: a validation study. Cognition and Emotion, 22, 10941118. doi: 10.1080/02699930701626582 Grossmann, T. (2010). The development of emotion perception in face and voice during infancy. Restorative Neurology and Neuroscience, 28, 219-236. doi: 10.3233/RNN-2010-0499 Grossmann, T., Johnson, M. H., Lloyd-Fox, S., Blasi, A., Deligianni, F., Elwell, C., & Csibra, G. (2008). Early cortical specialization for face-to-face communication in human infants. Proceedings of the Royal Society of London B: Biological Sciences, 275, 2803-2811. doi: 10.1098/rspb.2008.0986 Grossmann, T., Johnson, M. H., Vaish, A., Hughes, D. A., Quinque, D., Stoneking, M., & Friederici, A. D. (2011). Genetic and neural dissociation of individual responses to emotional expressions in human infants. Developmental Cognitive Neuroscience, 1, 57-66. doi: 10.1016/j.dcn.2010.07.001 Grossmann, T., Striano, T., & Friederici, A. D. (2007). Developmental changes in infants' processing of happy and angry facial expressions: A neurobehavioral study. Brain and Cognition, 64, 30-41. doi: 10.1016/j.bandc.2006.10.002

170

Halit, H., Csibra, G., Volein, A., & Johnson, M. H. (2004). Face-sensitive cortical processing in early infancy. Journal of Child Psychology and Psychiatry, 45, 1228-1234. doi: 10.1111/j.1469-7610.2004.00321.x Halit, H., de Haan, M., & Johnson, M. H. (2000). Modulation of event-related potentials by prototypical and atypical faces. Neuroreport, 11, 1871-1875. doi: 10.1097/00001756-200006260-00014 Hasselmo, M. E., Rolls, E. T., & Baylis, G. C. (1989). The role of expression and identity in the face-selective responses of neurons in the temporal visual cortex of the monkey. Behavioural Brain Research, 32, 203-218. doi: 10.1016/S01664328(89)80054-3 Haviland, J. M., & Lelwica, M. (1987). The induced affect response: 10-week-old infants' responses to three emotion expressions. Developmental Psychology, 23, 97-104. doi: 10.1037/0012-1649.23.1.97 Haxby, J. V., Hoffman, E. A., & Gobbini, M. I. (2000). The distributed human neural system for face perception. Trends in Cognitive Sciences, 4, 223-233. doi: 10.1016/S1364-6613(00)01482-0 Haxby, J. V., Hoffman, E. A., & Gobbini, M. I. (2002). Human neural systems for face recognition and social communication. Biological Psychiatry, 51, 59-67. doi: 10.1016/S0006-3223(01)01330-0 Heck, A., Hock, A., White, H., Jubran, R., & Bhatt, R. S. (2016). The development of attention to dynamic facial emotions. Journal of Experimental Child Psychology, 147, 100-110. doi: 10.1016/j.jecp.2016.03.005

171

Heck, A., Hock, A., White, H., Jubran, R., & Bhatt, R. S. (2017). Further evidence of early development of attention to dynamic facial emotions: Reply to Grossmann and Jessen. Journal of Experimental Child Psychology, 153, 155-162. doi: 10.1111/infa.12177 Heron-Delaney, M., Anzures, G., Herbert, J. S., Quinn, P. C., Slater, A. M., Tanaka, J. W., Lee, K., & Pascalis, O. (2011). Perceptual training prevents the emergence of the other race effect during infancy. PLoS One, 6, e19858. doi: 10.1371/journal.pone.0019858 Hernandez-Reif, M., Field, T., Diego, M., Vera, Y., & Pickens, J. (2006). Happy faces are habituated more slowly by infants of depressed mothers. Infant Behavior and Development, 29, 131-135. doi: 10.1016/j.infbeh.2005.07.003 Herschkowitz, N. (2000). Neurological bases of behavioral development in infancy. Brain and Development, 22, 411-416. doi: 10.1016/S0387-7604(00)00185-6 Hoehl, S., & Striano, T. (2008). Neural Processing of Eye Gaze and ThreatRelated Emotional Facial Expressions in Infancy. Child Development, 79, 1752-1760. doi: 10.1111/j.1467-8624.2008.01223.x Hoehl, S., & Striano, T. (2010). The development of emotional face and eye gaze processing. Developmental Science, 13, 813-825. doi: 10.1111/j.14677687.2009.00944.x Hornak, J., Bramham, J., Rolls, E. T., Morris, R. G., O'Doherty, J., Bullock, P. R., & Polkey, C. E. (2003). Changes in emotion after circumscribed surgical lesions of the orbitofrontal and cingulate cortices. Brain, 126, 1691-1712. doi: 10.1093/brain/awg168

172

Hornak, H., Rolls, E. T., & Wade, D. (1996). Face and voice expression identification in patients with emotional and behavioral changes following ventral frontal lobe damage. Neuropsychologia, 34, 247-61. doi: 10.1016/0028-3932(95)00106-9 Iidaka, T., Omori, M., Murata, T., Kosaka, H., Yonekura, Y., Okada, T., & Sadato, N. (2001). Neural interaction of the amygdala with the prefrontal and temporal cortices in the processing of facial expressions as revealed by fMRI. Journal of Cognitive Neuroscience, 13, 1035-1047. doi:10.1162/089892901753294338 Itier, R. J., & Taylor, M. J. (2002). Inversion and contrast polarity reversal affect both encoding and recognition processes of unfamiliar faces: a repetition study using ERPs. Neuroimage, 15, 353-372. doi: 10.1006/nimg.2001.0982 Izard, C.E. (1971). The face of emotion. New York: Meredith Corporation. Izard, C. E., Fantauzzo, C. A., Castle, J. M., Haynes, O. M., Rayias, M. F., & Putnam, P. H. (1995). The ontogeny and significance of infants' facial expressions in the first 9 months of life. Developmental Psychology, 31, 997-1013. doi: 10.1037/00121649.31.6.997 Izard, C., Fine, S., Schultz, D., Mostow, A., Ackerman, B., & Youngstrom, E. (2001). Emotion knowledge as a predictor of social behavior and academic competence in children at risk. Psychological Science, 12, 18-23. doi: 10.1111/1467-9280.00304 Jayaraman, S., Fausey, C. M., & Smith, L. B. (2015). The faces in infant perspective scenes change over the first year of life. PloS one, 10, e0123780. doi: 10.1371/journal.pone.0123780 Jessen, S., & Grossmann, T. (2015). Neural signatures of conscious and unconscious emotional face processing in human infants. Cortex, 64, 260-270. doi:

173

10.1016/j.cortex.2014.11.007 Jessen, S., & Grossmann, T. (2016). The developmental emergence of unconscious fear processing from eyes during infancy. Journal of Experimental Child Psychology, 142, 334-343. doi: 10.1016/j.jecp.2015.09.009 Johnson, M. H., Grossmann, T., & Farroni, T. (2008). The social cognitive neuroscience of infancy: Illuminating the early development of social brain functions. Advances in Child Development and Behavior, 36, 331-372. doi: 10.1016/S00652407(08)00008-6 Kahana-Kalman, R., & Walker-Andrews, A. S. (2001). The role of person familiarity in young infants' perception of emotional expressions. Child Development, 72, 352369. doi: 10.1111/1467-8624.00283 Kaneshige, T., & Haryu, E. (2015). Categorization and understanding of facial expressions in 4-month-old infants. Japanese Psychological Research, 57, doi: 135-142. 10.1111/jpr.12075 Kang, S. M., & Lau, A. S. (2013). Revisiting the out-group advantage in emotion recognition in a multicultural society: Further evidence for the in-group advantage. Emotion, 13, doi: 203-215. 10.1037/a0030013 Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The fusiform face area: a module in human extrastriate cortex specialized for face perception. Journal of Neuroscience, 17, 4302-4311. Kelly, D. J., Quinn, P. C., Slater, A. M., Lee, K., Ge, L., & Pascalis, O. (2007). The other-race effect develops during infancy: Evidence of perceptual narrowing. Psychological Science, 18, 1084-1089. doi: 10.1111/j.1467-9280.2007.02029.x

174

Kelly, D. J., Quinn, P. C., Slater, A. M., Lee, K., Gibson, A., Smith, M., Ge, L., & Pascalis, O. (2005). Three-month-olds, but not newborns, prefer own-race faces. Developmental Science, 8, F31-F36. doi: 10.1111/j.1467-7687.2005.0434a.x Kelly, D. J., Liu, S., Lee, K., Quinn, P. C., Pascalis, O., Slater, A. M., & Ge, L. (2009). Development of the other-race effect during infancy: Evidence toward universality?. Journal of Experimental Child Psychology, 104, 105-114. doi: 10.1016/j.jecp.2009.01.006 Kennedy, H., Bullier, J., & Dehay, C. (1989). Transient projection from the superior temporal sulcus to area 17 in the newborn macaque monkey. Proceedings of the National Academy of Sciences, 86, 8093-8097. Kim, C., Kroger, J. K., & Kim, J. (2011). A functional dissociation of conflict processing within anterior cingulate cortex. Human Brain Mapping, 32, 304-312. doi: 10.1002/hbm.21020 Klinnert, M. D. (1984). The regulation of infant behavior by maternal facial expression. Infant Behavior and Development, 7, 447-465. doi: 10.1016/S01636383(84)80005-3 Kobiella, A., Grossmann, T., Reid, V. M., & Striano, T. (2008). The discrimination of angry and fearful facial expressions in 7-month-old infants: An event-related potential study. Cognition and Emotion, 22, 134-146. doi:10.1080/02699930701394256. Kopp, C. B. (1989). Regulation of distress and negative emotions: A developmental view. Developmental Psychology, 25, 343-354. Kotsoni, E., de Haan, M., & Johnson, M. H. (2001). Categorical perception of facial

175

expressions by 7-month-old infants. Perception, 30, 1115-1125. doi: 10.1068/p3155 Kuchuk, A., Vibbert, M., & Bornstein, M. H. (1986). The perception of smiling and its experiential correlates in three-month-old infants. Child Development, 1054-1061. doi: 10.2307/1130379 Kuhl, P., Williams, K., Lacerda, F., Stevens, K., & Lindblom, B. (1992). Linguistic experience alters phonetic perception in infants by 6 months of age. Science 255, 606­608. doi: 10.1126/science.1736 LaBarbera, J. D., Izard, C. E., Vietze, P., & Parisi, S. A. (1976). Four-and six-month-old infants' visual responses to joy, anger, and neutral expressions. Child Development, 535-538. doi: 10.2307/1128816 Laible, D. J., & Thompson, R. A. (1998). Attachment and emotional understanding in preschool children. Developmental Psychology, 34, 1038-1045. doi: 10.1037/0012-1649.34.5.1038 Languille, S., Richer, P., & Hars, B. (2009). Approach memory turns to avoidance memory with age. Behavioural Brain Research, 202, 278-284. doi: 10.1016/j.bbr.2009.04.004 Lavelli, M., & Fogel, A. (2005). Developmental changes in the relationship between the infant's attention and emotion during early face-to-face communication: the 2month transition. Developmental Psychology, 41, 265-280. doi: 10.1037/00121649.41.1.265 LeDoux, J. E. (1996). The Emotional Brain, Simon and Schuster: New York.

176

LeDoux, J. E. (2000). Emotion circuits in the brain. Annual Review of Neuroscience, 23, 155-184. doi: 10.1146/annurev.neuro.23.1.155 LeDoux, J. (2003). The emotional brain, fear, and the amygdala. Cellular and Molecular Neurobiology, 23, 727-738. doi: 10.1023/A:1025048802629 Leppänen, J. M., Moulson, M. C., VogelFarley, V. K., & Nelson, C. A. (2007). An ERP study of emotional face processing in the adult and infant brain. Child Development, 78, 232-245. doi: 10.1111/j.1467-8624.2007.00994.x Leppänen, J. M., & Nelson, C. A. (2006). The development and neural bases of facial emotion recognition. Advances in Child Development and Behavior, 34, 207-246. doi: 10.1016/S0065-2407(06)80008-X Leppänen, J. M., Kauppinen, P., Peltola, M. J., & Hietanen, J. K. (2007). Differential electrocortical responses to increasing intensities of fearful and happy emotional expressions. Brain Research, 1166, 103-109. doi: 10.1016/j.brainres.2007.06.060 Leppänen, J. M., & Nelson, C. A. (2009). Tuning the developing brain to social signals of emotions. Nature Reviews Neuroscience, 10, 37-47. doi:10.1038/nrn2554 Leppänen, J. M., & Nelson, C. A. (2012). Early development of fear processing. Current Directions in Psychological Science, 21, 200-204. doi: 10.1177/096372141143584 Lewkowicz, D. J., & Ghazanfar, A. A. (2006). The decline of cross-species intersensory perception in human infants. Proceedings of the National Academy of Sciences, 103, 6771-6774. doi: 10.1073/pnas.0602027103 Liddell, B. J., Williams, L. M., Rathjen, J., Shevrin, H., & Gordon, E. (2004). A temporal dissociation of subliminal versus supraliminal fear perception: an event-related

177

potential study. Journal of Cognitive Neuroscience, 16, 479-486. doi:10.1162/089892904322926809 Livingstone, S. R., Peck, K., & Russo, F. A. (2012). RAVDESS: The Ryerson AudioVisual Database of Emotional Speech and Song. Paper presented at the 22nd Annual Meeting of the Canadian Society for Brain, Behaviour and Cognitive Science (CSBBCS), Kingston, ON. LoBue, V., & DeLoache, J. S. (2010). Superior detection of threat-relevant stimuli in infancy. Developmental Science, 13, 221-228. doi: 10.1111/j.14677687.2009.00872.x Ludemann, P. M. (1991). Generalized discrimination of positive facial expressions by seven-and ten-month-old infants. Child Development, 62, 55-67. doi: 10.1111/j.1467-8624.1991.tb01514.x Ludemann, P. M., & Nelson, C. A. (1988). Categorical representation of facial expressions by 7-month-old infants. Developmental Psychology, 24, 492. doi: 10.1037/0012-1649.24.4.492 Lundqvist, D., Flykt, A., & Öhman, A. (1998). The Karolinska Directed Emotional Faces - KDEF, CD ROM from Department of Clinical Neuroscience, Psychology section, Karolinska Institute, ISBN 91-630-7164-9. Lundy, B., Field, T., Cigales, M., Cuadra, A., & Pickens, J. (1997). Vocal and facial expression matching in infants of mothers with depressive symptoms. Infant Mental Health Journal, 18, 265-273. doi: 10.1002/(SICI)10970355(199723)18:3<265::AID-IMHJ3>3.0.CO;2-M

178

Macchi Cassia, V., Bulf, H., Quadrelli, E., & Proietti, V. (2014). Age-related face processing bias in infancy: Evidence of perceptual narrowing for adult faces. Developmental Psychobiology, 56, 238-248. doi: 10.1002/dev.21191 Machado, C. J., & Bachevalier, J. (2003). Non-human primate models of childhood psychopathology: The promise and the limitations. Journal of Child Psychology and Psychiatry, 44, 64-87. doi: 10.1111/1469-7610.00103 Malatesta, C. Z., Grigoryev, P., Lamb, C., Albin, M., & Culver, C. (1986). Emotion socialization and expressive development in preterm and full-term infants. Child Development, 316-330. doi: 10.2307/1130587 Malatesta, C. Z., & Haviland, J. M. (1982). Learning display rules: The socialization of emotion expression in infancy. Child Development, 991-1003. doi: 10.2307/1129139 Meissner, C. A., & Brigham, J. C. (2001). Thirty years of investigating the own-race bias in memory for faces: A meta-analytic review. Psychology, Public Policy, and Law, 7, 3-35. doi: 10.1037//1076-8971.7.1.3 Messinger, D., & Fogel, A. (2007). The interactive development of social smiling. Advances in Child Development and Behaviour, 35, 328-366. doi: 10.1016/B9780-12-009735-7.50014-1 Minagawa-Kawai, Y., Matsuoka, S., Dan, I., Naoi, N., Nakamura, K., & Kojima, S. (2009). Prefrontal activation associated with social attachment: Facial-emotion recognition in mothers and infants. Cerebral Cortex, 19, 284-292. doi: 10.1093/cercor/bhn081

179

Montague, D. P., & Walker-Andrews, A. S. (2001). Peekaboo: A new look at infants' perception of emotion expressions. Developmental Psychology, 37, 826-838. doi: 10.1037/0012-1649.37.6.826 Montague, D. P., & Walker­Andrews, A. S. (2002). Mothers, fathers, and infants: The role of person familiarity and parental involvement in infants' perception of emotion expressions. Child Development, 73, 1339-1352. doi: 10.1111/14678624.00475 Moriceau, S., & Sullivan, R. M. (2005). Neurobiology of infant attachment. Developmental Psychobiology, 47, 230-242. doi: 10.1002/dev.20093 Moriceau, S., & Sullivan, R. M. (2006). Maternal presence serves as a switch between learning fear and attraction in infancy. Nature Neuroscience, 9, doi: 1004-1006. doi:10.1038/nn1733 Morris, J. S., Friston, K. J., Büchel, C., Frith, C. D., Young, A. W., Calder, A. J., & Dolan, R. J. (1998). A neuromodulatory role for the human amygdala in processing emotional facial expressions. Brain, 121, 47-57. doi: 10.1093/brain/121.1.47 Morris, J. S., Frith, C. D., Perrett, D. I., & Rowland, D. (1996). A differential neural response in the human amygdala to fearful and happy facial expressions. Nature, 383, 812-815. doi: 10.1038/383812a0 Morris, J. S., Öhman, A., & Dolan, R. J. (1998). Conscious and unconscious emotional learning in the human amygdala. Nature, 393, 467-470. doi:10.1038/30976

180

Morton, J., & Johnson, M. H. (1991). CONSPEC and CONLERN: A two-process theory of infant face recognition. Psychological Review, 98, 164-181. doi: 10.1037/0033295X.98.2.164 Moulson, M. C., Fox, N. A., Zeanah, C. H., & Nelson, C. A. (2009). Early adverse experiences and the neurobiology of facial emotion processing. Developmental Psychology, 45, 17-30. doi: 10.1037/a0014035 Nakato, E., Otsuka, Y., Kanazawa, S., Yamaguchi, M. K., & Kakigi, R. (2011). Distinct differences in the pattern of hemodynamic response to happy and angry facial expressions in infants--A near-infrared spectroscopic study. NeuroImage, 54, 1600-1606. doi: 10.1016/j.neuroimage.2010.09.021 Nelson, C. A. (1987). The recognition of facial expressions in the first two years of life: Mechanisms of development. Child Development, 889-909. doi: 10.2307/1130530 Nelson, CA. (1994). Neural correlates of recognition memory in the first postnatal year of life. In G. Dawson & K. Fischer (EDs). Human development and the developing brain (pp. 269-313). New York: Guilford Press. Nelson, C. A. (2001). The development and neural bases of face recognition. Infant and Child Development, 10, 3-18. doi: 10.1002/icd.239 Nelson, C. A., & De Haan, M. (1996). Neural correlates of infants' visual responsiveness to facial expressions of emotion. Developmental Psychobiology, 29, 577-595. doi: 10.1002/(SICI)1098-2302(199611)29:7<577::AID-DEV3>3.0.CO;2-R Nelson, C.A., & De Haan, M. (1997). A neurobehavioral approach to the recognition of facial expression in infancy. In J.A. Russell & J.M. Fernandez-Dols (Eds.), The psychology of facial expression. New York: Cambridge University Press.

181

Nelson, C. A., & Dolgin, K. G. (1985). The generalized discrimination of facial expressions by seven-month-old infants. Child Development, 58-61. doi: 10.2307/1130173 Nelson, C. A., & Collins, P. F. (1991). Event-related potential and looking-time analysis of infants' responses to familiar and novel events: Implications for visual recognition memory. Developmental Psychology, 27, 50-58. doi: 10.1037/00121649.27.1.50 Nelson, C. A., & Collins, P. F. (1992). Neural and behavioral correlates of visual recognition memory in 4-and 8-month-old infants. Brain and Cognition, 19, 105121. doi: 10.1016/0278-2626(92)90039-O Nelson, C. A., Morse, P. A., & Leavitt, L. A. (1979). Recognition of facial expressions by seven-month-old infants. Child Development, 1239-1242. doi: 10.2307/1129358 Öhman, A. (2002). Automaticity and the amygdala: Nonconscious responses to emotional faces. Current Directions in Psychological Science, 11, 62-66. doi: 10.1111/1467-8721.00169 Öhman, A., Carlsson, K., Lundqvist, D., & Ingvar, M. (2007). On the unconscious subcortical origin of human fear. Physiology & Behavior, 92, 180-185. doi: 10.1016/j.physbeh.2007.05.057 Oster, H., Hegley, D., & Nagel, L. (1992). Adult judgments and fine-grained analysis of infant facial expressions: Testing the validity of a priori coding formulas. Developmental Psychology, 28, 1115-1131. doi: 10.1037/0012-1649.28.6.1115 Otsuka, Y., Nakato, E., Kanazawa, S., Yamaguchi, M. K., Watanabe, S., & Kakigi, R.

182

(2007). Neural activation to upright and inverted faces in infants measured by near infrared spectroscopy. NeuroImage, 34, 399-406. doi: 10.1016/j.neuroimage.2006.08.013 Pascalis, O., de Haan, M., & Nelson, C. A. (2002). Is face processing species-specific during the first year of life?. Science, 296, 1321-1323. doi: 10.1126/science.1070223 Pascalis, O., de Schonen, S., Morton, J., Deruelle, C., & Fabre-Grenet, M. (1995). Mother's face recognition by neonates: A replication and an extension. Infant Behaviour and Development, 18, 79­85. doi: 10.1016/0163-6383(95)90009-8 Pascalis, O., Scott, L. S., Kelly, D. J., Shannon, R. W., Nicholson, E., Coleman, M., & Nelson, C. A. (2005). Plasticity of face processing in infancy. Proceedings of the National Academy of Sciences of the United States of America, 102, 5297-5300. doi: 10.1073/pnas.0406627102 Peltola, M. J., Forssman, L., Puura, K., IJzendoorn, M. H., & Leppänen, J. M. (2015). Attention to faces expressing negative emotion at 7 months predicts attachment security at 14 months. Child Development, 86, 1321-1332. doi: 10.1111/cdev.12380 Peltola, M. J., Hietanen, J. K., Forssman, L., & Leppänen, J. M. (2013). The emergence and stability of the attentional bias to fearful faces in infancy. Infancy, 18, 905926. doi: 10.1111/infa.12013 Peltola, M. J., Leppänen, J. M., & Hietanen, J. K. (2011). Enhanced cardiac and attentional responding to fearful faces in 7-month-old infants. Psychophysiology, 48, 1291-1298. doi: 10.1111/j.1469-8986.2011.01188.x

183

Peltola, M. J., Leppänen, J. M., Mäki, S., & Hietanen, J. K. (2009). Emergence of enhanced attention to fearful faces between 5 and 7 months of age. Social Cognitive and Affective Neuroscience, 4,134-142. doi: 10.1093/scan/nsn046 Peltola, M. J., Leppänen, J. M., Palokangas, T., & Hietanen, J. K. (2008). Fearful faces modulate looking duration and attention disengagement in 7-month-old infants. Developmental Science, 11, 60-68. doi: 10.1111/j.1467-7687.2007.00659.x Pessoa, L., & Adolphs, R. (2010). Emotion processing and the amygdala: from a'low road'to'many roads' of evaluating biological significance. Nature Reviews Neuroscience, 11, 773-783. doi:10.1038/nrn2920 Phillips, M. L., Drevets, W. C., Rauch, S. L., & Lane, R. (2003). Neurobiology of emotion perception I: The neural basis of normal emotion perception. Biological Psychiatry, 54, 504-514. doi: 10.1016/S0006-3223(03)00168-9 Phelps, E. A., & LeDoux, J. E. (2005). Contributions of the amygdala to emotion processing: From animal models to human behavior. Neuron, 48, 175-187. doi: 10.1016/j.neuron.2005.09.025 Pissiota, A., Frans, Ö., Michelgård, Å., Appel, L., Långström, B., Flaten, M. A., & Fredrikson, M. (2003). Amygdala and anterior cingulate cortex activation during affective startle modulation: a PET study of fear. European Journal of Neuroscience, 18, 1325-1331. doi: 10.1046/j.1460-9568.2003.02855.x Pollak, S. D., Cicchetti, D., Hornung, K., & Reed, A. (2000). Recognizing emotion in faces: Developmental effects of child abuse and neglect. Developmental Psychology, 36, 679-688. doi: 10.1037/0012-1649.36.5.679

184

Pollak, S. D., & Kistler, D. J. (2002). Early experience is associated with the development of categorical representations for facial expressions of emotion. Proceedings of the National Academy of Sciences, 99, 9072-9076. doi: 10.1073/pnas.142165999 Pollak, S. D., Klorman, R., Thatcher, J. E., & Cicchetti, D. (2001). P3b reflects maltreated children's reactions to facial displays of emotion. Psychophysiology, 38, 267-274. Pollak, S. D., Messner, M., Kistler, D. J., & Cohn, J. F. (2009). Development of perceptual expertise in emotion recognition. Cognition, 110, 242-247. doi: 10.1016/j.cognition.2008.10.010 Pollak, S. D., & Sinha, P. (2002). Effects of early experience on children's recognition of facial displays of emotion. Developmental Psychology, 38, 784-791. doi: 10.1037/0012-1649.38.5.784 Pollak, S. D., & Tolley-Schell, S. A. (2003). Selective attention to facial emotion in physically abused children. Journal of Abnormal Psychology, 112, 323-338. doi: 10.1037/0021-843X.112.3.323 Quinn, P. C., Anzures, G., Izard, C. E., Lee, K., Pascalis, O., Slater, A. M., & Tanaka, J. W. (2011). Looking across domains to understand infant representation of emotion. Emotion Review, 3, 197-206. doi: 10.1177/1754073910387941 Quinn, P. C., Uttley, L., Lee, K., Gibson, A., Smith, M., Slater, A. M., & Pascalis, O. (2008). Infant preference for female faces occurs for same-but not other-race faces. Journal of Neuropsychology, 2, 15-26. doi: 10.1348/174866407X231029

185

Quinn, P. C., Yahr, J., Kuhn, A., Slater, A. M., & Pascalis, O. (2002). Representation of the gender of human faces by infants: A preference for female. Perception, 31, 1109-1121. doi: 10.1068/p3331 Reinagel, P., & Reid, R. C. (2000). Temporal coding of visual information in the thalamus. Journal of Neuroscience, 20, 5392-5400. Rennels, J. L., & Davis, R. E. (2008). Facial experience during the first year. Infant Behavior and Development, 31, 665-678. doi: 10.1016/j.infbeh.2008.04.009 Reynolds, G. D., & Richards, J. E. (2005). Familiarization, attention, and recognition memory in infancy: An event-related potential and cortical source localization study. Developmental Psychology, 41, 598-614. doi: 10.1037/0012-1649.41.4.598 Rodman, H. R., Scalaidhe, S. P., & Gross, C. G. (1993). Response properties of neurons in temporal cortical visual areas of infant monkeys. Journal of Neurophysiology, 70, 1115-1136. Rolls, E. T. (1999). The functions of the orbitofrontal cortex. Neurocase, 5, 301-312. doi: 10.1080/13554799908411984 Rolls, E. T. (2000). The orbitofrontal cortex and reward. Cerebral Cortex, 10, 284-294. doi: 10.1093/cercor/10.3.284 Rolls, E. T. (2004). The functions of the orbitofrontal cortex. Brain and Cognition, 55, 11-29. doi: 10.1016/S0278-2626(03)00277-X Rodman, H. R., & Consuelos, M. J. (1994). Cortical projections to anterior inferior temporal cortex in infant macaque monkeys. Visual Neuroscience, 11, 119-133. doi: 10.1017/S0952523800011160 Rossignol, M., Philippot, P., Douilliez, C., Crommelinck, M., & Campanella, S. (2005).

186

The perception of fearful and happy facial expression is modulated by anxiety: an event-related potential study. Neuroscience Letters, 377, 115-120. doi: 10.1016/j.neulet.2004.11.091 Roth, T. L., & Sullivan, R. M. (2005). Memory of early maltreatment: neonatal behavioral and neural correlates of maternal maltreatment within the context of classical conditioning. Biological Psychiatry, 57, 823-831. doi: 10.1016/j.biopsych.2005.01.032 Safar, K., & Moulson, M.C. (2017). Recognizing facial expressions of emotion in infancy: A replication and extension. Developmental Psychobiology, 59, 507-514. doi: 10.1002/dev.21515 Schaffer, H. R. (1966). The onset of fear of strangers and the incongruity hypothesis. Journal of Child Psychology and Psychiatry, 7, 95-106. doi: 10.1111/j.1469-7610.1966.tb02167.x Schultz, D., Izard, C. E., Ackerman, B. P., & Youngstrom, E. A. (2001). Emotion knowledge in economically disadvantaged children: Self-regulatory antecedents and relations to social difficulties and withdrawal. Development and Psychopathology, 13, 53-67. doi: 10.1017/S0954579401001043 Schultz, W., Tremblay, L., & Hollerman, J. R. (2000). Reward processing in primate orbitofrontal cortex and basal ganglia. Cerebral Cortex, 10, 272-283. doi: 10.1093/cercor/10.3.272 Scott, L. S., Pascalis, O., & Nelson, C. A. (2007). A domain-general theory of the development of perceptual discrimination. Current Directions in Psychological Science, 16, 197-201. doi: 10.1111/j.1467-8721.2007.00503.x

187

Scott, L. S., & Monesson, A. (2010). Experience-dependent neural specialization during infancy. Neuropsychologia, 48, 1857-1861. doi: 10.1016/j.neuropsychologia.2010.02.008 Scott, L. S., & Monesson, A. (2009). The origin of biases in face perception. Psychological Science, 20, 676-680. doi: 10.1111/j.1467-9280.2009.02348.x Spelke, E. (1976). Infants' intermodal perception of events. Cognitive Psychology, 8, 553560. doi: 10.1016/0010-0285(76)90018-9 Soken, N. H., & Pick, A. D. (1992). Intermodal perception of happy and angry expressive behaviors by seven-month-old infants. Child Development, 63, 787-795. doi: 10.1111/j.1467-8624.1992.tb01661.x Soken, N. H., & Pick, A. D. (1999). Infants' perception of dynamic affective expressions: Do infants distinguish specific expressions?. Child Development, 70, 1275-1282. Doi: 10.1111/1467-8624.00093 Sorce, J. F, Emde, R. N., Campos, J. J., & Klinnert, M. D. (1985). Maternal emotional signaling: Its effects on the visual cliff behavior of 1-year-olds. Developmental Psychology, 21, 195-200. doi: 10.1037/0012-1649.21.1.195 Steele, H., Steele, M., & Croft, C. (2008). Early attachment predicts emotion recognition at 6 and 11 years old. Attachment & Human Development, 10, 379-393. doi: 10.1080/14616730802461409 Steele, H., Steele, M., Croft, C., & Fonagy, P. (1999). Infant-mother attachment at one year predicts children's understanding of mixed emotions at six years. Social Development, 8, 161-178. doi: 10.1111/1467-9507.00089

188

Stets, M., Stahl, D., & Reid, V. M. (2012). A meta-analysis investigating factors underlying attrition rates in infant ERP studies. Developmental Neuropsychology, 37, 226-252. doi: 10.1080/87565641.2012.654867 Striano, T., & Rochat, P. (2000). Emergence of selective social referencing in infancy. Infancy, 1, 253-264. doi: 10.1207/S15327078IN0102_7 Sugden, N. A., Mohamed-Ali, M. I., & Moulson, M. C. (2014). I spy with my little eye: Typical, daily exposure to faces documented from a first-person infant perspective. Developmental Psychobiology, 56, 249-261. doi: 10.1002/dev.21183 Sullivan, R. M., Landers, M., Yeaman, B., & Wilson, D. A. (2000). Neurophysiology: Good memories of bad events in infancy. Nature, 407, 38-39. doi:10.1038/35024156 Thomas, K. M., Drevets, W. C., Whalen, P. J., Eccard, C. H., Dahl, R. E., Ryan, N. D., & Casey, B. J. (2001). Amygdala response to facial expressions in children and adults. Biological Psychiatry, 49, 309-316. doi: 10.1016/S0006-3223(00)01066-0 Thompson, R. A. (1991). Emotional regulation and emotional development. Educational Psychology Review, 3, 269-307. doi: 10.1007/BF01319934 Tottenham, N. (2014). The Importance of Early Experiences for Neuro-affective Development. Current Topics in Behavioral Neurosciences, 16, 109­129. doi: 10.1007/7854_2013_254 Tottenham, N., Tanaka, J.W., Leon, A.C., McCarry, T., Nurse, M., Hare, T.A., Marcus, D.J., Westerlund, A., Casey, B.J., Nelson, C. (2009). The NimStim set of facial expressions: Judgments from untrained research participants, Psychiatry Research, 168, 242-249. doi:10.1016/j.psychres.2008.05.006

189

Tronick, E. Z. (1989). Emotions and emotional communication in infants. American Psychologist, 44, 112-119. doi: 10.1037/0003-066X.44.2.112 Turati, C., Simion, F., Milani, I., & Umiltà, C. (2002). Newborns' preference for faces: what is crucial?.Developmental Psychology, 38, 875-881. doi: 10.1037//00121649.38.6.875 Tzourio-Mazoyer, N., De Schonen, S., Crivello, F., Reutter, B., Aujard, Y., & Mazoyer, B. (2002). Neural correlates of woman face processing by 2-month-old infants. Neuroimage, 15, 454-461. doi: 10.1006/nimg.2001.0979 Vaish, A., Grossmann, T., & Woodward, A. (2008). Not all emotions are created equal: the negativity bias in social-emotional development. Psychological Bulletin, 134, 383. doi:10.1037/0033-2909.134.3.383 Vaish, A., & Striano, T. (2004). Is visual reference necessary? Contributions of facial versus vocal cues in 12-month-olds' social referencing behavior. Developmental Science, 7, 261-269. doi: 10.1111/j.1467-7687.2004.00344.x Vogel, M., Monesson, A., & Scott, L. S. (2012). Building biases in infancy: The influence of race on face and voice emotion matching. Developmental Science, 15, 359-372. doi: 10.1111/j.1467-7687.2012.01138.x Vrticka, P., & Vuilleumier, P. (2012). Neuroscience of human social interactions and adult attachment style. Frontiers in Human Neuroscience, 6, 212-217. doi: 10.3389/fnhum.2012.00212 Walden, T. A., & Ogan, T. A. (1988). The development of social referencing. Child Development, 1230-1240. doi: 10.2307/1130486 Walker, A. S. (1982). Intermodal perception of expressive behaviors by human infants.

190

Journal of Experimental Child Psychology, 33, 514-535. doi: 10.1016/00220965(82)90063-7 Walker-Andrews, A. S. (1986). Intermodal perception of expressive behaviors: Relation of eye and voice?. Developmental Psychology, 22, 373-377. doi: 10.1037/00121649.22.3.373 Walker-Andrews, A. S. (1997). Infants' perception of expressive behaviors: differentiation of multimodal information. Psychological Bulletin, 121, 437-456. doi: 10.1037/0033-2909.121.3.437 Walker-Andrews, A. S. (2008). Intermodal emotional processes in infancy. In M. Lewis, J. M. Haviland-Jones, & L. F. Barrett (Eds.), Handbook of Emotions (3rd ed., pp. 364­375). New York, NY: Guilford Press. Walker-Andrews, A. S., & Dickson, L. R. (1997). Infants' understanding of affect. In S. Hala (Ed.), The Development of Social Cognition (pp. 161­186). West Sussex, England: Psychology Press. Walker-Andrews, A. S., Krogh-Jespersen, S., Mayhew, E. M., & Coffield, C. N. (2011). Young infants' generalization of emotional expressions: Effects of familiarity. Emotion, 11, 842-851. doi: 10.1037/a0024435 Webster, M. J., Bachevalier, J., & Ungerleider, L. G. (1994). Connections of inferior temporal areas TEO and TE with parietal and frontal cortex in macaque monkeys. Cerebral Cortex, 4, 470-483. doi: 10.1093/cercor/4.5.470 Webster, M. J., Ungerleider, L. G., & Bachevalier, J. (1991). Lesions of inferior temporal area TE in infant monkeys alter cortico-amygdalar projections. Neuroreport, 2, 769-772.

191

Werker, J. F. (1989). Becoming a native listener. American Scientist, 77, 54-59. Whalen, P. J. (1998). Fear, vigilance, and ambiguity: Initial neuroimaging studies of the human amygdala. Current Directions in Psychological Science, 7, 177-188. doi: 10.1111/1467-8721.ep10836912 Whalen, P. J., Kagan, J., Cook, R. G., Davis, F. C., Kim, H., Polis, S., McLaren, D.G., Somerville, L.H., McLean, A.A., Maxwell, J.S., & Johnstone, T. (2004). Human amygdala responsivity to masked fearful eye whites. Science, 306, 2061-2061. doi: 10.1126/science.1103617 Wilcox, B. M., & Clayton, F. L. (1968). Infant visual fixation on motion pictures of the human face. Journal of Experimental Child Psychology, 6, 22-32. doi: 10.1016/0022-0965(68)90068-4 Young-Browne, G., Rosenfeld, H. M., & Horowitz, F. D. (1977). Infant discrimination of facial expressions. Child Development, 555-562. doi: 10.2307/1128653 Yrttiaho, S., Forssman, L., Kaatiala, J., & Leppänen, J. M. (2014). Developmental precursors of social brain networks: The emergence of attentional and cortical sensitivity to facial expressions in 5 to 7 months old infants. PloS one, 9, e100811. doi: 10.1371/journal.pone.0100811

192

