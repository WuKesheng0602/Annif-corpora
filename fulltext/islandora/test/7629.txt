Understanding policy workers' policy innovation capacity:
An exploratory and qualitative mixed methods evaluation study of a policy hackathon program in Prince Edward Island, Canada

Bobby Thomas Cameron PhD (candidate), MPPA, CE Manager of Policy, Government of PEI, Department of Agriculture and Fisheries October 2018

Acknowledgements
The author wishes to thank the Government of Prince Edward Island and the Centre for Policy Innovation and Public Engagement for allowing this paper to be shared with the academic and practitioner communities. In particular, the author acknowledges Kathleen Brennan, Policy & Intergovernmental Affairs Coordinator (PEI) for her leadership in organizing and implementing the Policy Hackathon Program. The author also acknowledges the support provided to the Policy Hackathon Program by the Government of PEI, Veterans Affairs Canada, Atlantic Canada Opportunities Agency, and the Start-Up Zone.

Author
Bobby Thomas Cameron is the Manager of Policy, Planning & FPT Relations with the PEI Department of Agriculture and Fisheries in Prince Edward Island. Bobby is currently in his final year of a PhD in Policy Studies at Ryerson University. His dissertation is on sub-national public sector policy capacity in PEI. At the moment his research interests revolve around public administration theory and practice, applied research in public policy, and qualitative mixed methods. In addition to a Master of Arts in Public Policy and Administration (Ryerson University, 2011) he holds a Bachelor of Arts in History and Political Studies (University of PEI, 2009). Currently he is an Adjunct Professor with UPEI's Applied Communication, Culture and Leadership Program. Contact Bobby Thomas Cameron at bcameron@gov.pe.ca

Centre for Policy Innovation and Public Engagement (CPIPE)
The Centre for Policy Innovation and Public Engagement provides a forum for the pursuit and promotion of interdisciplinary research, education, and professional applications relating to public policy innovation. The mission of the Centre is to promote collaborative, interdisciplinary research, teaching, learning, and partnership opportunities relating to innovative policy solutions around a range of topical, contentious, and difficult social issues. The Centre for Policy Innovation and Public Engagements opens spaces for designers and consumers of public policy ­ governments, corporations, civil society organizations, communities, and citizen groups ­ to contribute to the policy process through participation in new policy cocreation methodologies, and in researching and designing new ways to think about policies.

For more information, visit ryerson.ca/cpipe Inquiries about the Centre for Policy Innovation and Public Engagement can be sent to: Prof. Bryan Evans, PhD Director, Centre for Policy Innovation and Public Engagement b1evans@politics.ryerson.ca

PEI Policy Hackathon Program

Page 1 of 73

Table of Contents
EXECUTIVE SUMMARY INTRODUCTION BACKGROUND AND CONCEPTUAL FRAMEWORK 4 6 6

ISLANDNESS AND PUBLIC POLICY 7 POLICY INNOVATION 8 POLICY HACKATHONS 9 HUMAN-CENTERED DESIGN 11 PROGRAM RELEVANCE, PERFORMANCE AND IMPACT 12 THEORETICAL FRAMEWORK: DESIGN FOR POLICY THEORY AND CORE SKILLS FOR PUBLIC SECTOR INNOVATION 12 STUDY DESIGN METHODS STUDY AREA AND PROGRAM PARTICIPANTS THE POLICY HACKATHON PROGRAM RESULTS SURVEY RESPONDENTS AND INTERVIEWEES PROGRAM RELEVANCE PROGRAM PERFORMANCE PROGRAM IMPACT POLICY INNOVATION RECOMMENDATIONS DISCUSSION OF RESULTS PROGRAM RELEVANCE PROGRAM PERFORMANCE PROGRAM IMPACT POLICY INNOVATION CONCLUSION ISLANDNESS AND PUBLIC POLICY POLICY INNOVATION POLICY HACKATHONS PROGRAM `RELEVANCE', `PERFORMANCE' AND `IMPACT' AS HEURISTICS AUSTERITY AND CITIZEN-FOCUS APPENDICES APPENDIX A: PRE-PROGRAM SURVEY APPENDIX B: POST-PROGRAM SURVEY APPENDIX C: INTERVIEW GUIDES APPENDIX D: EVALUATION MATRIX FOR THE PRE- AND POST-PROGRAM SURVEY REFERENCES 13 13 14 15 17 17 18 21 23 26 35 37 37 37 38 39 40 40 40 41 41 42 43 43 50 59 60 66

PEI Policy Hackathon Program

Page 2 of 73

List of Figures
Figure 1 Conceptual Framework ................................................................................................................... 7 Figure 2 Human-Centered Design .............................................................................................................. 11 Figure 3 Design for Policy (Bason, 2014) ................................................................................................... 12 Figure 4 Core Skills for Public Sector Innovation (OECD, 2017)................................................................ 12 Figure 5 Prince Edward Island (Google Map, 2018) ................................................................................... 14 Figure 6 Program Logic Model .................................................................................................................... 15 Figure 7 Pre-survey result: Do you think that the policy capacity of professionals needs to improve? ...... 20 Figure 8 Pre-survey result: How important are opportunities to learn about innovative policy development? .............................................................................................................................................. 20 Figure 9 Pre-survey result: Are there currently positive mentorship opportunities in your organization? .. 20 Figure 10 Pre-survey results: Respondents' perceptions of PEI's Policy Innovation Environme nt ............ 21 Figure 11 Post-survey result: Please rate the quality of your experience being either a mentor or mentee (or both) ....................................................................................................................................................... 23 Figure 13 Post-survey result: How likely are you to integrate similar learning opportunities into your professional development plan? ................................................................................................................. 25 Figure 12 Post-survey result: Do you think that the Program improved the policy capacity of the group as a whole? ...................................................................................................................................................... 25 Figure 14 Post-survey result: Do you think that individuals who participated in the Program will transfer what they learned to organizational processes? ......................................................................................... 26 Figure 15 Post-survey result: Questions on Program's impact related to Policy Innovation Capacity ....... 28 Figure 16 Post-survey result: Do you think that individuals who participated in the Program are now more prepared to conduct innovative policy work?" ............................................................................................. 28 Figure 17 Data Literacy Codes (Interviews) ................................................................................................ 29 Figure 18 Storytelling Codes (Interviews) ................................................................................................... 29 Figure 19 New Alliances Codes (Interviews) .............................................................................................. 30 Figure 20 Complexity Codes (Interviews) ................................................................................................... 31 Figure 21 Insurgency Codes (Interviews) ................................................................................................... 31 Figure 22 Vision Codes (Interviews) ........................................................................................................... 32 Figure 23 Policy Impact Codes (Interviews) ............................................................................................... 32 Figure 24 Stewardship Codes (Interviews) ................................................................................................. 33 Figure 25 Citizen Focus Codes (Interviews) ............................................................................................... 33 Figure 26 Curiosity Codes (Interviews) ....................................................................................................... 34 Figure 27 Iteration Codes (Interviews) ........................................................................................................ 35

List of Tables
Table 1 Profile of Respondents of the Pre- and Post-Program Survey ...................................................... 17 Table 2 Profiles of Interviewees .................................................................................................................. 18

PEI Policy Hackathon Program

Page 3 of 73

Executive Summary
Background In 2018, the Government of PEI, Veterans Affairs Canada, Atlantic Canada Opportunities Agency and the Start-Up Zone brought together 49 individuals from the public and private sector to participate in a Policy Hackathon Program. A series of learning sessions were delivered while participants moved through a public policy case competition. This paper evaluates and studies this program and makes design recommendations for future policy hackathon programs. In the process, the paper draws attention to not only the relevance, performance and impact of the Program, but also larger discussions related to the unique attributes of the islandness of public policy, policy innovation, and austerity on an island. Methods The evaluation study adopted a social-constructivist worldview, whereby the perceptions of participants and the interpretation of the researcher were used to understand the Program. A qualitative mixed methods design was employed which involved generating qualitative and quantitative data through a pre-program survey (N=48), post-program survey (N=38), interviews with a random sample of participants (N=6), and interviews with a purposive sample of key informants (N=2). Bason's (2014) design for policy theory and the OECD's (2017) core skills for public sector innovation framework were operationalized to understand the results in relation to theory and best practice. Quantitative and qualitative results were interpreted by the researcher to understand the Program and also to connect the results to public policy theory and constructs. Results Relevance The Program responded to a need in PEI's policy environment. There was clear indication that participants believed that PEI needs new micro- and meso-level policy tools to develop public policy. Participants indicated that having opportunities to learn about policy innovation was important to them. The Program's emphasis on mentorship was relevant, given that participants believed that such multidisciplinary connections were important for policy development. Performance The Program performed well in terms of increasing participants' individual policy capacity as well as that of the entire group, meeting participants' expectations to receive valuable learni ng, and allowing participants to meaningfully connect with a broad range of individuals. The Program performed less optimally in the areas of providing participants with new policy tools, mentorship, and connecting with citizens. Impact Participants perceived the Program to have had a positive impact on their skill development in a wide range of areas and in increasing their comfort level with on-the-spot decision-making. Participants indicated that they would seek to integrate similar learning opportunities into their professional development plans in the future. Participants also reported that they believed the Program had a positive impact on the group's policy capacity and capacity to undertake innovative policy work. Policy Innovation The policy workers involved in the Program (i.e., participants) have cognitively established the positive connection between mentorship and innovation. Participants reported an increase in their confidence to apply human-centered design concepts. In terms of Bason's (2014) theory and the OECD's (2017) framework, the Program exposed participants to important policy innovation concepts. Given that participants indicated they thought that individuals who participated in the Program were better prepared to conduct innovative policy work in the future, it is assumed that the Program had a positive impact, to some degree, on increasing the policy innovation capacity of policy workers. Conclusion The study concludes by reiterating that the value of a policy hackathon program is as much related to process as new policies. In other words, in order for policy hackathon programs to be successful, they do

PEI Policy Hackathon Program

Page 4 of 73

not necessarily need to result in the development of a new policy. Rather, as shown in this study, there can be positive impacts to participants' policy innovation capacity which can occur during the program. Policy hackathon programs therefore should not be judged entirely on the intervention's outputs. The study also concludes with a discussion in relation to the islandness of public policy, policy innovation, policy hackathons, and evaluation heuristics. Finally, the paper offers some thoughts on findings which pointed to the existence of austerity and the need for greater citizen-focus in public policy. Recommendations for Practitioners `Performance', `relevance', and `impact' can be used as heuristics/models in a systematic way to evaluate policy hackathon programs. When designing professional development curriculum to be delivered during a policy hackathon program, the OECD's core skills for public sector innovation framework can act as a guide for the selection of topics. Questions related to the OECD's framework should also be included in evaluations of policy hackathon programs (e.g., operationalized through surveys, interviews, etc.). Policy hackathon programs should o clearly communicate to prospective participants the amount of time and commitment required to complete the program (and ensure that the amount of time and commitment communicated is accurate); o Seek support from participants' employers and present them with a business case as to how the program will benefit the workplace (this may support employers in re-prioritizing participants' workloads while they participate in the program); o be strategic in the order of delivery of professional development sessions; o clearly define the role of coaches/mentors and judges; o include the participation of citizens and community stakeholders; and o provide opportunities for formal and informal networking. Recommendations for Academic Researchers Policy hackathon programs can provide opportunities to understand a broad range of public policy phenomenon. These programs therefore make for interesting case studies for the exploration of public policy in theory and practice. Future research should: 1) focus on conceptualizing policy hackathon programs as policy instruments; 2) empirically study the extent to which organizations in Canada and elsewhere have employed policy hackathon programs as instruments to pursue a policy innovation agenda; 3) further conceptualize and theorize how islandness is expressed at the micro-level of policy work; and 4) explore more closely the policy tools and processes employed by small islands.

PEI Policy Hackathon Program

Page 5 of 73

Introduction
There has been a recent surge of interest in public sector innovation among both academics and practitioners (Tate, Bongiovanni, Kowalkiewicz, et al., 2018:186). It is generally accepted that policy innovation is needed to maintain public sector services that are being challenged by contemporary economic and social problems (Bloch & Bugge, 2013:133) that are considered to be "wicked" and complex (Head, 2018; McGann, Blomkamp & Lewis, 2018:2). Yet, theoretical literature on public sector innovation is limited (Bloch & Bugge, 2013:134) as is "knowledge about the ways in which the organization of education and training influences the development and diffusion of innovations" (Chaminade & Edquist, 2005:22). Given the relative lack of theoretical knowledge on public sector policy innovation, it is not surprising that there is a limited amount of literature on the utility of using Policy Hackathons or "Hacks" as instruments to develop the policy innovation capacity of policy workers1. This gap leaves little guidance for practitioners who are seeking to design interventions to improve the policy innovation capacity of policy workers, particularly to ensure that interventions are relevant (i.e., respond to the appropriate need in the policy environment), adequately perform (i.e., meet objectives to increase innovation capacity), and have an impact (i.e., change the policy development behavior of participants). This paper heeds to Robinson and Johnson's (2016) recommendation that "capturing staff perceptions of hackathons can provide not only a frame for evaluating the event itself, but reveal the underlying motivations and goals that drive government-citizen connections" (68). Based on the interpretation of results from interviews and a pre- and post-program survey administered to participants of a Policy Hackathon Program organized by the Government of Prince Edward Island (PEI), this paper seeks to narrow the gap in knowledge about policy innovation capacity development interventions through the perceptions of participants. This paper also adds to the limited body of knowledge on policy hackathons and policy innovation (see for example Briscoe & Mulligan, 2014; Jones, Semel & Le, 2015:341; Seravalli & Simeone, 2016; Thornham & Cruz, 2016) and the body of knowledge on public sector-led policy innovation initiatives on small islands, where currently there seems to be a dearth of literature. The objective of this paper is to describe the intervention, its evaluation study design and results, and to propose recommendations for practitioners in other jurisdictions who are seeking to enhance the policy innovation capacity of policy workers using policy hackathons. Drawing on design for policy theory (Bason, 2014) and the OECD's (2017) core skills for public sector innovation framework, this paper adds to the knowledge base on how policy innovation theory can be operationalized in the form of a program.

Background and Conceptual Framework
As shown in the diagram below, the study was guided from the outset by a conceptual framework consisting of three constructs: islandness and public policy, policy innovation, and evaluation, as well as several sub-constructs. This conceptual framework directs attention to those ideas which the study considered important to understand the policy innovation capacity of policy workers involved in the Policy Hackathon Program.

`Policy workers' in this study refers to individuals from any sector who are involved in the development, implementation, or evaluation of public policy (see Colebatch, Hoppe & Noordegraff, Eds., 2010, p. 17 for a social-constructivist account of `policy workers' and policy work).
1

PEI Policy Hackathon Program

Page 6 of 73

Islandness and Public Policy
Concept

Debated Challenges and opportunities
Limited autonomy Smallness and social capital

Evaluation

Policy Innovation

Heuristics

Policy Hackathons

Skills Framework (OECD, 2017) Iteration

Design for Policy (Bason, 2014)

Relevance
Performance

Open-innovation systems
Rooted in I.T.

Embracing complexity
Vision-oriented New alliances Stewardship

Data Literacy
User-centricity

Impact

Mentorship Cultural processes Responses to austerity

Curiosity
Storytelling

Impact emphasis
Citizen focus

Insurgency

Figure 1 Conceptual Framework

Islandness and Public Policy
The usefulness of islandness as a category for analysis has been debated. Selwyn (1980:950) argued that the attempt to use islands as "useful categories" for social analysis represented an "illegitimate extension" of an ecological perspective to the social sciences. However others, such as Conkling (2007), have argued the exact opposite, and posited that "islandness [is] a metaphysical sensation that derives from the heightened experiences that accompany the physical isolation of island life. Islandness is a sense that is absorbed into the bones of islanders through the obstinate and tenacious hold that island communities exert on their native-born as well as on their converts, who experience it as an instantaneous recognition. Islandness thus is an important metacultural phenomenon that helps maintain island communities in spite of daunting economic pressures to abandon them" (200). As such, islandness can be understood "corporeally, affectually, practically, intimately, [and] as a visceral experience" (Vannini & Taggart, 2012:225). Smallness and globalization have impacted public policy in PEI. In this jurisdiction, globalized processes related to interprovincial and international trade and migration have brought about both positive and negative impacts for the province's economic and social development agenda (Clark, Prochazka, Yirdoe et al., 2007; Institute of Island Studies, 1996; PEI, 2017, "Mighty Island Strategy"). Compounding

PEI Policy Hackathon Program

Page 7 of 73

this is the smallness of PEI (Population: 152,021; Land area: 5,656 sq. km 2) and its relatively limited resources which creates different demands for the Government of PEI, its institutional arrangements and policy work (Baldacchino, 2008:24; Connor, 2008:35 ­ 36). In the complexity of a globalized world, small governments in rural island jurisdictions may struggle to develop effective public policies (PEI, Cabinet Committee on Government Reform, 1992a;1992b) and to ensure access to extra-territorial resources (Baldacchino, 2006b). Indeed, Kukucha (2008) remarked that, "[i]n comparison to other provinces in Atlantic Canada, PEI has the least developed bureaucratic capacity" (88). The need for innovative solutions to public policy problems in PEI is therefore important, and the development of such solutions may be additionally challenging given the smallness of the jurisdiction. On the other hand, small island jurisdictions are also characterized with having the strong social capital essential for economic growth (Baldacchino, 1999; 2006a:855; PEI, 2017, "Mighty Island Strategy") and the ability to act strategically by leveraging networks of stakeholders (Inwood, O'Reilly, & Johns, 2011:431). As noted by Baldacchino (2005: 40), "islandness is almost certain to provide an inducement for some degree of political or administrative autonomy" given the geographic separation between an island and other territories. Furthermore, having a shared identity of islandness (Hay, 2006) and "a complex web of acquaintances, contacts and networks" where there is role diffusion, role enlargement, and role multiplicity (Baldacchino, 1999 & 2005:36) potentially results in creating an atmosphere where innovative policy ideas can be quickly developed, implemented and tested (McKenna, 2014:91). The character of social capital in PEI may therefore promote a "willingness to learn, flexibility and the readiness to adapt in a world of change" (Baldacchino, 2005:36); all of which are important for enhancing the public sector's policy innovation capacity. The limited autonomy between policymakers and the public, the conceptual distinction between the island and the mainland, the reduced scale of PEI, and the character of social capital in this jurisdiction thus essentially constitutes many of the components of the islandness of public policy in PEI. Studying the relevance, performance and impact of a policy hackathon in this unique context therefore offers the opportunity to understand the combination of policy innovation and innovation development interventions vis-à-vis a policy hackathon program, as well as public policy development in small island jurisdictions.

Policy Innovation
Attempts to introduce innovation in the public sector is not a new phenomenon (McGann, Blomkamp & Lewis, 2018). The push for a more entrepreneurial government and the neoliberal new public management reforms in the 1990s shows that governments have long promoted attempts to reconstruct how programs and policies are developed and implemented (Osborne & Gaebler, 1992; Shields & Evans, 1998; Evans, Richmond & Shields, 2017). What is new, perhaps, is that `innovation' has become more explicit in public sector discourses and further institutionalized. This is exemplified best by the emergence of what have been called innovation labs (Carstensen & Bason, 2012; Williamson, 2015; Tõnurist, Kattel & Lember, 2015 & 2017; McGann, Blomkamp & Lewis, 2018); public collaboration labs (McGann, Blomkamp & Lewis, 2018; Thorpe & Rhodes, 2018); and living labs (Kusiak, 2007; Almilrall & Wareham, 2011; Edwards-Schachter, Matti & Alcántara, 2012; Schuurman & Tõnurist, 2017). These labs take various institutional forms, however, conceptually and pragmatically, labs often adopt the assumption that policy innovation is not an activity or outcome which is isolated to the public sector (McGann, Blomkamp & Lewis, 2018). Rather, policy innovation can involve the public, private and not-for-profit sector, or at least "a more diverse range of voices and inputs into the policy process" than allowed for in orthodox policy approaches (McGann, Blomkamp & Lewis, 201816). In theory, it is thought that since "innovation is a shared and distributed practice across several different actors" (Malmberg & Holmlid, 2013:1), it is through the co designing of solutions with a broad range of stakeholders that cooperation, support for change, and social capital will increase. As a result, the combination of the former will lead to more innovative solutions (Blomkamp, 2017) particularly through policy learning supported by "policy instruments directed at networking, clustering, and personnel mobility" (Mytelka & Smith, 2002:1468). The program in the present study was indeed based on the idea that `policy learning' 3 was important for innovation (Borras, 2011; Federighi, 2007:12), and that policy innovation is characterized by being systemic and interactive, generally uncertain and therefore requiring experimentation, and diverse given
Government of PEI. Department of Finance. (2018). 44th annual statistical review ­ 2017. PEI Statistics Bureau. Sanderson (2002) defines `policy learning' as "a socially-conditioned discursive or argumentative process of development of cognitive schemes or frames which questions the goals and assumptions of policies" (6).
2 3

PEI Policy Hackathon Program

Page 8 of 73

that different policy environments will produce different outcomes (World Bank & OECD, 2013). Policy learning was therefore considered by the Program as being critical to navigate these characteristics as well as the policy innovation process which was considered to be inherently non-linear and impacted by the system within which it is found (Smits & Kuhlmann, 2004:6 ­ 7). As noted by Federighi (2007), policy innovation learning "may be generated either locally (in an in-house fashion) or in the relationship to a range of subjects and situations into which innovation is introduced (externally). In both cases consideration must be paid to the effect of the network of relationships" (10). However, Borras (2011:726) argues that organizational capacity building and the effectiveness of policy learning go hand-in-hand. In other words, in order for policy learning for innovation purposes to be effective, organizations must have the capacity and intelligence to apply policy innovation knowledge instrumentally to solve problems. The Program in the present study reflected this idea, as evidenced in its offering of professional development sessions which aimed to improve participants' policy capacity. While in public administration practice there are several examples of attempts to promote innovative public policy through policy hackathons (see for example Accenture, 2018; City of Oshawa, n.d.; Government of Canada, 2017; Government of Prince Edward Island, 2018; "The `Hackathon' as an Instrument in Policy Design", 2016), less is known theoretically about what constitutes policy innovation and how and why it may emerge through a hackathon program. Indeed, even merely defining what constitutes public sector innovation is somewhat muddled (Demircioglu & Audretsch, 2017). According to Bloch (2011) public sector innovations "comprise new or significant changes to services and goods, operational processes, organizational methods, or the way your organization communicates with users. Innovations must be new to your organization, although they can have been d eveloped by others" (14). However, as noted by Demircioglu and Audretsch (2017:1682), most definitions of innovation are set in the context of the private sector. As such, understanding and measuring innovation in the context of the public sector is difficult.

Policy Hackathons
Policy hackathons can be thought of as open innovation policy instruments which typically serve the purpose to provide a structure for the public, private and not-for-profit sectors to engage in problem identification and solution development (Almirall, Lee & Majchrzak, 2014). Policy hackathons are generally characterized with:  an intense series of sessions where participants focus on problem identification and solution development for issues of significance;  the participation of individuals from a broad range of sectors and areas of society;  the administration of a final prize to encourage competition and personal gain among participants; and  a relaxed environment which is assumed to be conducive for innovation and tolerance of risk (Briscoe & Mulligan, 2014:2; Irani, 2015:803). Additionally, hackathons are often characterized by a "discursive, technological and material significance of data" which then becomes an "underlying and connective thread" among hackathons in different sectors (Thornham & Cruz, 2016:2; see also Desouza & Jacob, 2017:1044). In the present study, the Program was designed with these characteristics in mind. While the idea of `hacking'4 to solve computer problems has existed in the IT sector since at least the 1960's (Levy, 2010:9), it was not until the late 1990's that coding hackathons seemed to gain popularity among the larger IT community (Briscoe & Mulligan, 2014:2). Since then, hackathons have been adopted in a broad range of domains (Irani, 2015:804) including education (Rogers & Hewson, 2016) and environment (Haasnoot, Laurens & Jaap, 2017), and have been employed globally including in places such as Australia (Rogers & Hewson, 2016), the UK (Briscoe & Mulligan, 2014), the United States (Chiu, Pei & Jean, 2018), the Netherlands (Haasnoot, Laurens & Jaap, 2017), Russia (Ermoshina, 2018) and India (Birkinshaw, 2013); so much so that Briscoe and Mulligan (2014) have said that we are now witnessing a "hackathon phenomenon". The civic-oriented policy hackathons which we see today draw from the genre

Mtsweni and Abdullah (2015:88) note that the term `hacking' tends to have a negative connotation. However, in their study th ey adopted a more positive definition of a hacker which, in the context of a hackathon, is "an individual who is technically adept and has passion for solving problems within a community environment" (88).
4

PEI Policy Hackathon Program

Page 9 of 73

of computer hackathons to cultivate a hacking culture which values iteration in the solution development process and "participation, contribution, and learning" (Mtsweni & Abdullah, 2015:88). Nevertheless, anecdotal evidence from case studies suggest that hackathons are increasing in popularity among governments and other organizations as a method to encourage experimentation, entrepreneurialism, creativity, and ultimately solutions for problems (Briscoe & Mulligan, 2014:1; Haasnoot, Laurens & Jaap, 2017; Johnson & Robinson, 2014:355; Sükürer, 2014). Hackathons have also become spaces for The significance of a hackathon is the ethnographic exploration of cultural processes (see for not limited to what is produced example Ermoshina, 2018; Irani, 2015; Jones, Semel & Le, 2015; Seravalli & Simeone, 2016). Seravalli and from the interaction of participants Simeone (2016) noted in their ethnographic study of two and extends to including the culture hackathons that "hackathons can be looked upon as ... which can emerge from the [events] where ... cultures and ... boundaries ... emerge from the interactions between the organizers, the interaction of participants during participants, the programs and the material elements. the process itself. When we say that during the events some boundaries are established and communicated we mean that ... hackathons ... present specific visions about themselves and their own interpretation" (329). As such, the significance of a hackathon is not limited to what is produced from the interaction of participants (i.e., the solution to a problem) and extends to including the culture which can emerge from the interaction of participants during the process itself (see also Robinson & Johnson, 2016:68). This idea of the hackathon's importance of being as much about process as results was noted in Irani's (2015) ethnographic study of a hackathon in India when she wrote that, "The hackathon's lack of concrete results did not de ter entrepreneurial citizens from continuing to try. Days later, Krish spoke on the festival stage and proposed a traveling bus full of educated Indians who could go from village to village, pursuing a series of small, fast reform projects--like a hackathon on wheels" (814). Furthermore, Jones, Semel and Le's (2015) ethnographic study of one hackathon found that participants pursued social relatedness while also maintaining commitment to individual projects (328), which further confirms that the hackathon is as a unique and socially significant phenomenon. Hackathons are indeed unique spaces for social collaboration, human interaction, entrepreneurialism and innovation (Irani, 2015:806). This is perhaps due to the semi-structured environment associated with hackathons and the conflictive and negotiative interactions among participants which this structuredness may promote. Jones, Semel and Le (2015) speak to this idea when they noted that, "a hackathon ... makes a fascinating case study in joint activity. Drawn by the theme of a particular event, participants bring skills and interests relevant to the topic at hand, but they mostly come alone, seeking a project to work on and/or collaborators with whom to work. They must find both quickly at the beginning of the first day of the event, so as to waste as little time possible in getting to work" (323). Hackathons have not only increased in popularity but they have also been seen as responses to austerity (see for example (Briscoe & Mulligan, 2014:2; Gregg, 2015). Irani (2015) notes that "the hackathon is Viewed through the lens of one of a number of spaces that have become neoliberalism, hackathons may transnationally legible emblems of innovation" (800). The optimize and improve existing rise in popularity of hackathons has been attributed by Briscoe and Mulligan (2014:2) to the desire for bureaucratic and administrative organizations to promote innovation under austerity. In processes without questioning the theory "the relaxed organizational structure [of a Policy status quo. Hackathons have Hackathon] encourages participants to innovate and therefore been understood as a bycreates an environment that can sustain innovation. [Policy Hackathons can help to] manage the failure product of neoliberal austerity necessary for innovation to emerge" (Briscoe & Mulligan, measures which have transferred 2014:2). In times of cutbacks and a general attitude the responsibility of ensuring among governments to "do more with less" (Peters, 2012:216), the ability for public servants to support "rapid effective public policy from innovation" (Tate, Bongiovanni, Kowalkiewicz, et al., Government onto volunteers in the 2018) through quick and effective on-the-spot decisionprivate or not-for-profit sector. making may be more important than ever before.

PEI Policy Hackathon Program

Page 10 of 73

Hackathons may indeed be emblematic of neoliberalization (Ermoshina, 2018: 83; Cardullo, Kitchin & Di Feliciantonio, 2018; Gregg, 2015). As noted by Ermoshina (2018), "the recent wave of critical research on civic hackathons argues that they must be analyzed as a form of speculative labor, as a form of unpaid work, and thus, as part of the neoliberal restructuring of the high-tech market" (83). As such, viewed through the lens of neoliberalism, hackathons may "optimize and improve existing bureaucratic and administrative processes without questioning the status quo" (Ermoshina, 2018: 84). Hackathons have therefore been understood as a by-product of neoliberal austerity measures which have transferred the responsibility of ensuring effective public policy from Government onto volunteers in the private or not-for-profit sector (Gregg, 2015: 185). Furthermore, while conceptual and theoretical research has pointed to the important role mentorship plays both formally and informally in policy innovation (see for example Samier, 2000; Schepers, 2015), less is known specifically about the connection between mentorship, policy hackathons and innovation. In theory, "the `hackathon' represents a new model of mentorship and collaboration that has been extremely successful in fostering innovation" (Chiu, Pei & Jean, 2018:1). It assumed that the informal, peer-to-peer mentorship which occurs during a hackathon promotes a "safe environment" to think "outside the box" and innovate (Chiu, Pei & Jean, 2018:1). This idea is further supported by Samier (2000) who, writing in the context of public of administration, posited that, "planned mentorship can assis t organizations in responding to many of the extra-organizational pressures produced by major social and economic trends, identified by Zey [1986] as the quest for innovation, mergers, changing composition of the workforce, [etc.]" (84). As such, this stud y sought to understand mentorship and its relationship with policy innovation capacity through an interpretation of participant perceptions. Finally, for the purposes of public sector-led policy hackathons, most could likely be categorized as "socially-oriented" (Briscoe & Mulligan, 2014:6). "Socially-oriented hackathons aim to address or contribute to an issue of social concern, such as public services or crisis management. Examples of hackathons aimed at improving public services has included improving education, improving city transit systems and improving government" (6). Given the types of topics and issues which participants "hacked", the Program in the present study is aligned with the socially-oriented type of hackathon.

Human-centered design

Cognitive empathy

Emotional empathy

Humancentricity

Iteration HumanCentered Design

Figure 2 Human-Centered Design

Finally, for the purposes of the present study, it is important to note that in the literature `human centered design' (HCD) has intersected with dominant ideas related to policy innovation (and often times vice versa). While HCD is often characterized with an emphasis on the "views and experiences" of users (Blomkamp, 2017:8), it has also been seen as critical for the identification and implementation of innovative solutions. It is thought that the HCD concepts of human-centricity (i.e., focusing on the problems experienced by users of policies); cognitive empathy (i.e., understanding other's feelings); emotional empathy (i.e., connecting with other's feelings); and iteration (i.e. designing prototypes, testing, and adjusting) provides more opportunity to discover solutions which are not only innovative, but are also grounded in context, the experience of users, and are open to continuous development and adjustment

PEI Policy Hackathon Program

Page 11 of 73

(Dong, Dong & Yuan, 2018; IDEO, 2015; Efeoglu, Møller, Sérié, et al., 2013:241). The present study sought to understand participants' experiences with HCD and their skill development in this area.

Program Relevance, Performance and Impact
To aid in understanding the Policy Hackathon Program, this study treated `relevance', `performance', and `impact' as heuristic devices­ essentially tools to direct where to focus one's research, analysis and write-up (West, 2001: 129). Relevance, performance and impact are important concepts to consider when designing and evaluating a program (Canada, Directive on Results, 2016, C.2.2.1.5). While there is indeed debate in evaluation as to the appropriateness of these concepts in certain types of evaluations (for example, see McDavid & Howthorn, 2006:4 for a discussion of `performance' in program evaluations versus program management), best practice guidelines have nevertheless encouraged their consideration in one form or another (see for example Ontario, "Program Evaluation Reference & Resource Guide", 2007; Swiss State Secretariat for Economic Affairs, "Evaluation Guidelines", n.d; World Bank "Independent Evaluation: Principles, Guidelines and Good Practice", 2003). For the purposes of the present study, relevance was the extent to which the Policy Hackathon Program addressed and was responsive to a demonstrable need (Canada, Policy on Results, 2016; Small, Cooney & O'Connor, 2009:5). "Assessments of relevance are almost always qualitative and rely substantially on the experience and judgment of the evaluators as well as of stakeholders" (McDavid & Ho wthorn, 2006:20). Performance was considered the degree to which the Program achieved results in accordance with the stated goals of the Program (as indicated in the Program's logic model) (Ontario, "Program Evaluation Reference & Resource Guide", 2007). Finally, impact, while notoriously difficult to measure, was considered to be the Program's effect on outcomes (both intended and unintended), particularly those which indicated a change in behavior. Given the short time period between the conclusion and evaluation of the Program, impact was assessed primarily through participants' opinions of how their behavior may change in the future as a result of participating in the Program.

Theoretical Framework: Design for Policy Theory and Core Skills for Public Sector Innovation
The present study sought to understand how a policy hackathon program could have intended or unintended impacts with respect to policy design theory and core skills for public sector innovation.

Citizen-focus

New alliances

User centricity Stewardship Data literacy

Curiosity

Visionoriented

Storytelling

Embracing complexity

Policy Innovation

Impact emphasis

Iteration

Policy Innovation

Insurgency

Figure 3 Design for Policy (Bason, 2014)

Figure 4 Core Skills for Public Sector Innovation (OECD, 2017)

As shown in the diagrams above, Bason's (2014) design for policy theory establishes six core constructs necessary for policy innovation: Embracing complexity; Vision-oriented; Citizen-focus; Shaping new alliances; Stewardship; and Impact emphasis. These constructs are contrasted with rational (and orthodox) forms of policymaking which resist complexity, are reactive, focus on systems, are unilateral in action, and privilege strategy as opposed to outcomes. The OECD's (2017) core skills for public sector innovation framework includes Bason's (2014) constructs, however, it further operationalizes them into the specific skills and capabilities needed for officials to successfully innovate to solve contemporary problems. PEI Policy Hackathon Program Page 12 of 73

In summary, the OECD has encouraged governments to promote Iteration, Data literacy, User centricity, Curiosity, Storytelling, and Insurgency as the specific skills and capabilities required for public sector policy innovation. The study operationalized these theories and best practices through survey questions, interview questions, and an interpretive analysis of results.

Study Design
Methods
The study adopted a qualitative mixed methods design (Mason, 2006; Morse & Cheek, 2014: 4; Uneke, Ezeoha, Uro-Chukwu, et al., 2015: 601). Inductive, deductive and abductive forms of logic were employed to understand the qualitative and quantitative data. Inductive logic involved looking at the data to understand implied results and develop an inference, deductive logic involved beginning with theory and then proceeding through the data to arrive at a result, and abductive logic involved looking at the data to explain Given that public policy is an possible causes and effects which were "hidden from inherently moral, heterogeneous, view" (Timmermans & Tavory, 2012:170-171). The contested, and messy qualitative component of the design included interviews with participants and key informants after the Program phenomenon, an interpretive and concluded. The quantitative component involved a survey qualitative approach was adopted administered to participants two weeks before beginning because its potential to understand the Program and two days after their participation in the meaning was assumed to be Program (three reminders were sent for the pre- and postsurvey). Participant interviewees were randomly selected greater than a purely positivist and from the entire list of participants. Key informant quantitative approach. interviewees were selected based on the recommendation of the Program's stakeholders. What makes the mixed method design qualitative is the way in which it treats numbers in its analysis and discussion of results (Jansen, 2010:4). In the case of this paper, numbers have been analyzed qualitatively (Sandelowski, 2001:235), meaning that the quantitative results of the surveys are interpreted and described to support understanding the Program's relevance, performance, and impacts. Given that public policy is an inherently moral, heterogeneous, contested, and messy phenomenon (Dryzek, 1982:322; Lindblom, 1959; Wagenaar, 2011:242), an interpretive and qualitative approach was adopted because its potential to understand meaning was assumed to be greater than a purely positivist and quantitative approach. As such, overall, the evaluation study adopted a qualitative drive (Morse, Niehaus, Wolfe et al, 2006:283 & 284) but mixed the types of methods used. The mix of survey question types (e.g., open-ended, Likert-type, check-all-thatapply, etc.) also supported a more qualitative form of data analysis given that different types of questions necessitated different types of descriptions. The survey items in the pre-program survey were developed from the immediate, intermediate and long-term goals as articulated in the Program's logic model. The post-program survey mirrored many of the questions in the pre- survey, however, questions were added based on Bason's (2014) design for policy theory and the OECD's (2017) public sector innovation framework. This allowed the study to see how ­ and to what extent ­ the Program developed participants' policy innovation capa city in relation to theory. The interview questions for participants and key informants were also developed from Bason (2014) and the OECD (2017). To ensure clarity and ease of completion, all instruments were pre-tested and reviewed by the Program Advisory Committee, Steering Committee and a sample of PEI public administrators not affiliated with the Program.5 Participants were informed that information was being collected for the purposes of evaluating the Program. Institutional permission was provided by the Government of PEI to complete an evaluation and to share the results with public administration practitioners. The Evaluation Advisory Committee as well as a Program Steering Committee guided the study, its research questions, and analysis
In the post-program survey, respondents were asked to assess the survey instrument. Ninety-five per cent (37) indicated that the amount of time it took to complete the survey was "just right" and 72% (28) indicated that overall, the survey questions were easy to u nderstand (13%/5 reported `very easy'; 13%/5 reported `some difficult and some easy'; and 3%/1 reported `difficult').
5

PEI Policy Hackathon Program

Page 13 of 73

of data. The Canadian Evaluation Society's (2014) Program Evaluation Standards steered the evaluation study to support the utility of the results, the overall effectiveness and efficiency of research processes, ethical decision-making, accuracy of results, and accountability.

Study Area and Program Participants

Figure 5 Prince Edward Island (Google Map, 2018)

The area in which this study is situated is the Atlantic Canadian province of Prince Edward Island; located in the eastern part of Canada next to New Brunswick and Nova Scotia. With a population of 152,021 the province is one of the smallest jurisdictions in Canada in terms of population, and the smallest in terms of geography. Prospective program participants were recruited primarily through e-mails to staff and members from the Program's sponsors (Government of PEI, Veterans Affairs Canada, Atlantic Canada Opportunities Agency, and the Start-Up Zone) as well as word-of-mouth.6

In the pre-program survey, respondents were asked to identify all of the ways they heard about the Program (check-all-that-apply). The results for this questions showed that 67% (32) received an e-mail invitation, 31% (15) heard about the Program from their supervisor, and 10% (5) heard from a colleague.
6

PEI Policy Hackathon Program

Page 14 of 73

The Policy Hackathon Program

Figure 6 Program Logic Model

In total, 50 participants from the provincial government, federal government and private sector participated in five program sessions. Four learning and development sessions were organized, culminating in a fifth "case competition day" session. The four learning and development sessions included 1) Problem Solving Through Creative Design; 2) Writing Effective Executive Council Memos; 3) Human Centered Design; 4) Collaboration; and 5) Pitching and Presentations. Teams were comprised of groups of 3 to 5 people. The objectives of the Program were to provide a unique professional development forum, support networking, and foster government collaboration. The intended outcomes of the Program were to offer unique learning opportunities and provide opportunities for networking and collaboration across sectors. The PEI Policy Hackathon Program also drew from lessons learned by policy hackathon program planners in Nova Scotia and New Brunswick. Both Nova Scotia and New Brunswick have been running public service case competitions for a number of years and were invaluable in their sharing of materials, time and knowledge on how to successfully execute a case competition.

PEI Policy Hackathon Program

Page 15 of 73

Case questions used for the Policy Hackathon Program in Prince Edward Island, Canada
How could the Government of PEI create a `One Citizen/One Number' approach to serving the needs of Islanders? How can public-private land use tensions be overcome to support PEI's overarching sustainability objectives? How could cider production be developed in the province in the face of trade protectionism? How can the public be better engaged in traffic safety (i.e., texting and driving, safe cycling, pedestrians, speeding, substance use, etc.) beyond traditional regulatory approaches? How can the Government of PEI foster social connectedness and cohesion through Island-wide solutions for vulnerable populations? How can opportunities for tourism shoulder season expansion be optimized in Atlantic Canada? What can be done to prevent harassment and promote respect in the workplace? How could government lead by example for a greener future (i.e., operations, modern work spaces, etc.)? How can the provincial Social Assistance Program be redesigned to better meet the needs of clients exempt from seeking employment? How might Veterans' access to family physicians be enhanced?

Session 1 ­ Part A Problem Solving Through Creative Design During this session, facilitators used an activity involving LEGO® Bricks to encourage a sense of fun and create a relaxed environment to deepen understanding, sharpen insight and create connections among team members who were meeting each other for the first time. Participants were introduced to the engineering design process as a method for problem solving; essentially, defining the problem, researching, specifying requirements, brainstorming, developing a prototype, testing the solution, and communicating results. Teams of 3-4 participants were given a scenario for which they used the engineering design process to design and build a prototype using LEGO® Bricks. Session 1 ­ Part B Writing Effective Executive Council Memos Participants learned about the process to present issues to Cabinet and the provincial requirements for a submission to Cabinet. Participants were taught strategies for effective writing and how to present their submission in the Executive Council format. Session 1 ­ Part C Human Centered Design Participants were exposed to human centered design in both theory and practice by completing an interactive session of learning how to design solutions to suit the needs of the end user. Teams were engaged in how to apply a human centered design process to their case problem and were offered advice on how to implement human centered design solutions. Sessions 2 and 3 Collaboration Participants learned strategies for building collaborative skills and fostering collaborative solutions. Objectives of this learning session involved finding ways to problem solve differences of opinion over what, why, and how solutions are developed. Participants learned how to approach differences that naturally arise with the idea that it is possible to find solutions which meet the needs of everyone involved. The session was offered on two days with half the participants participating in the first session and the remainder participating in the second day. Foundational skills to support team collaboration with a focus on effectively leading and participating in team problem solving were the focal points of the course on both days.

PEI Policy Hackathon Program

Page 16 of 73

Session 4 Pitching and Presentations Participants learned techniques to help them increase public speaking skills and to understand what a good pitch entails. Topics covered included: tips for effective PowerPoint use, design, font and typography; knowing your audience; and effective communication. There was also an interactive component involving an actual presentation. Session 5 Final Case Competition All teams applied learnings from the "Pitching and Presentations" session to pitch their solutions to a panel of judges and their peers on the last day of the competition. The participants had an opportunity to learn from each other and observe how each team came to the solution for their case question.

Results
Survey respondents and interviewees
From the 49 public sector and private sector policy workers invited to participate in the Program, 48 participants completed the pre-program survey and 38 completed the post-program survey. The profile of respondents (i.e., participants) who completed the pre- and post-program survey is presented in the table below. Note that in the presentation and discussion of results, comments from survey respondents are identified with the abbreviation `SR'.
Profile of Respondents of the Pre- and Post-Program Survey for the Policy Hackathon Program in Prince Edward Island, Canada Pre-Survey Post-Survey No. (%1) of No. (%1) of Respondent Attributes Respondents, Respondents, N= 48 N= 38 Gender Female 27 (56%) 17 (44%) Male 18 (37%) 13 (34%) Prefer not to answer 3 (6%) 8 (21%) Institutional Affiliation Provincial Government 31 (65%) 27 (71%) Private Sector 4 (8%) 3 (8%) Provincial Crown Agency 4 (8%) 3 (7%) Other 5 (10%) 2 (5%) Federal Government 3 (6%) 2 (5%) Municipal Government 1 (2%) 1 (3%) Length of Time with Current Employer More than 20 years 8 (17%) 6 (16%) 15-20 years 11 (23%) 8 (21%) 10-14 years 7 (15%) 7 (18%) 6-9 years 9 (19%) 6 (16%) 3-5 years 4 (8%) 3 (8%) 1-2 years 5 (10%) 6 (16%) Less than 1 year 4 (8%) 2 (5%) Participation Session 1: "ECMs & HCD" 38 (97%) Session 2: "Collaboration 1" 26 (67%) Session 3: "Collaboration 2" 24 (62%) Session 4: "Pitching" 36 (92%) Session 5: "Case competition" 33 (85%) Abbreviations: ECM, executive council memo; HCD, Human Centered Design Table 1 Profile of Respondents of the Pre- and Post-Program Survey

In the pre- and post-survey, the sample was comprised of a relatively even split of genders (56% female/37% male in the pre and 44% female/34% male in the post). Most respondents worked for the Government of PEI (65% in the pre and 71% in the post). In terms of experience (i.e., length of time with current employer), there was a range of work experience in the sample. A few had been working for less than one year (8% in the pre and 5% in the post), many had been working 15 to 20 years (23%/pre and PEI Policy Hackathon Program Page 17 of 73

21%/post), and some had been with their current employer for more than 20 years (17%/pre and 16%/post). There was also a good program attendance rate in the sample: Sessions 1, 4, and 5 were attended by over 80% of the sample, and Sessions 2 and 3 were attended by over 60%. As such, the sample's opinions of the Program can be characterized as coming from primarily a provincial government perspective with a mix of short and long-term career histories and with a strong knowledge of the activities associated with each session. In total, six participants were randomly selected and two key informants were purposively selected to be interviewed and asked questions related to the Program's performance, relevance, impact and relationship with policy innovation. The table below provides a profile of the interviewees.
Profiles of Interviewees (Participants and Key Informants) Job Sector Key

R1 R2 R3 R4 R5 R6 R7 R8

Policy Advisor Public Director Public Project Officer Public IT Officer Public Policy Advisor Public Manager Public Clerk Public Communications Public Officer Table 2 Profiles of Interviewees

(Provincial) (Federal) (Provincial) (Provincial) (Provincial) (Provincial) (Provincial) (Provincial)

Informant or Participant Participant Key Informant Participant Participant Key Informant Participant Participant Participant

Note that in this paper, comments from interview respondents are identified with the abbreviation `R'.

Program relevance
In terms of participants' perceptions of the relevancy of the Progra m, prior to enrolling, 90% of the respondents (43) considered government-led efforts to improve policy capacity among policy workers important. In terms of individual and organizational policy capacity, 88% (42) reported that the policy capacity of professionals in PEI needs to improve, 79% (37) reported that Island organizations need new tools to solve policy problems, and 96% answered that it is important for Island organizations to be able to identify staff who have an interest in conducting innovative types of policy work. In terms of the processes that organizations in PEI maintain to develop public policy, a majority (55%/26) were not sure if organizations currently had good processes in place, and many (43%/20) said no. In terms of peer-to-peer mentorship, going into the Program there was a range of experiences with mentorship. Even though when asked, "Are there currently positive mentorship opportunities in your organization?", 33% (16) indicated yes, 33% (16) indicated no, and 33% (16) indicated not sure, a strong majority (98%/47) indicated that multidisciplinary connections among professionals across sectors is important for solving problems. Registered participants had high expectations for the case competition process: 94% (44) indicated that they thought competing through a case competition to solve problems and pitch solutions would be a valuable exercise. Finally, opportunities to learn about innovative policy development was important to those who had registered for the Program (56%/27 indicated that opportunities were `very important' and 27%/13 indicated `extremely important').

PEI Policy Hackathon Program

Page 18 of 73

Pre-Program Survey Question Result7

Are government-led efforts to improve policy capacity among public servants important? (Yes, No, Not sure)

Yes 90% (43) No 2% (1) Not Sure 8% (4)

Do you think that multidisciplinary connections among professionals across sectors is important for solving problems? (Yes, No, Not Sure) Do you think that competing through a case competition to solve problems and pitch solutions will be a valuable exercise? (Yes, No, Not Sure)

Yes 98% (47) No 0% (0) Not Sure 2% (1)

Yes 94% (44) No 0% (0) Not Sure 6% (3)

Post-Program Survey Question Result8 Decreased greatly 0% (0) "As a result of participating in the Decreased slightly Program, my opinion of the 0% (0) importance of government-led Stayed the same 26% efforts to improve policy capacity (10) among public has . . ." (1 Increased slightly `Decreased greatly'; 5 `Increased 44% (17) greatly') Increased greatly 31% (12) Decreased greatly 3% (1)9 "As a result of participating in the Decreased slightly Program, my opinion of the 3% (1) importance of multidisciplinary Stayed the same 15% connections among public (6) servants for solving problems has Increased slightly . . ." (1 `Decreased greatly'; 5 38% (15) `Increased greatly') Increased greatly 41% (16) Yes 95% (37) Was competing through a case No 3% (1) competition to solve problems and Not Sure 3% (1) pitch solutions a valuable exercise? (Yes/No/Not sure)

The post-program results provide an additional layer of evidence on the relevancy of the Program to participants. In terms of respondents' perceptions of the importance of government -led efforts to improve policy capacity, 44% (17) indicated that their perception had `increased slightly' and 31% (12) indicated that it had `increased greatly'. No respondents reported a decrease. Similar results were reported to the question related to respondents' perceptions of the importance of multidisciplinary connections in solving prob lems (41%/16 `increased greatly' and 38%/15 `increased slightly'). Finally, 95% of respondents (37) found the process of competing through a case competition to solve problems and pitch solution to be a valuable exercise.

Percentage is rounded to nearest whole number Percentage is rounded to nearest whole number 9 Those who answered `decreased greatly' or `slightly' were asked to explain why through an open-ended question. Comments from one respondent indicated that participants were "working in silos". Comments from another respondent indicated that participants were not collaborating.
7 8

PEI Policy Hackathon Program

Page 19 of 73

Results for pre-survey question, "Do you think that the policy capacity of professionals needs to improve?"
13% 0% 88% Yes No Not Sure

Figure 7 Pre-survey result: Do you think that the policy capacity of professionals needs to improve?

Results for pre-survey question, "How important are opportunities to learn about innovative policy development?"
100% 50% 0%

0%
Not at all , Low, Slightly

6%
Neutral

10%
Moderately

56%
Very

27%
Extremely

Figure 8 Pre-survey result: How important are opportunities to learn about innovative policy development?

Results for pre-survey question, "Are there currently positive mentorship opportunities in your organization?"
Yes 33% 34% 33% No Not Sure

Figure 9 Pre-survey result: Are there currently positive mentorship opportunities in your organization?

PEI Policy Hackathon Program

Page 20 of 73

Pre-survey results related to respondents' perceptions of PEI's Policy Innovation Environment

96% 79% 55% 43% 2% Not Sure No Yes Yes 21% Not Sure 0% No Yes 4% Not Sure 0% No

Do you think that Island organizations currently have a good process in place to develop public policy?

Do you think that Island organizations need new tools to solve policy problems?

Is it important for Island organizations to be able to identify staff who have an interest in conducting innovative types of policy work?

Figure 10 Pre-survey results: Respondents' perceptions of PEI's Policy Innovation Environment

Program performance
The study sought to assess the Program's performance by comparing the results of pre - and postprogram survey questions which asked about changes in both perceptions and skills. These questions were developed based on the stated purpose of the Program, described earlier in this paper. In terms of participants' policy capacity, going into the Program, respondents indicated that they considered themselves to have fairly high levels of policy capacity (41%/19 repo rted have a `good' level of policy capacity, 33%/15 `very good' and 11%/5 `excellent'). After the Program, 75% of respondents (29) indicated an increase in their policy capacity, and some indicated that their policy capacity stayed the same (26%/10). In terms `valuable learning' and connections to other actors, 96% of pre -survey respondents (45) expected valuable learning going into the Program while 92% (36) reported in the post-survey that the Program provided them access to valuable learning. While many respondents (48%/22) reported in the presurvey that they were already connected to a broad range of Island organizations, some were said they were not well connected (30%/14) and some were not sure (22%/10). Following the Program, however, a strong majority (90%/35), indicated that the Program allowed them to meaningfully connect with a broad range of individuals. In terms of having the necessary tools to develop policy, the pre-survey results indicate that 44% of respondents (20) did not have all of the tools they need to solve problems, 35% were not sure, and some (22%/10) indicated that they had all of the necessary tools. In the post-survey, 64% indicated that the Program had provided them with new tools to solve problems, some (21%/8) said that the Program did not provide them with new tools, and some (15%/6) were not sure. In terms of the performance of the Program's mentorship and coaching components, the pre -survey results show that 45% of respondents (21) expected the Program to increase mentorship opportunities, while many (55%/26) were not sure. Following the Program, the post-survey results showed that 36% of respondents (14) indicated that the Program did not increase mentorship opportunities, 36% were not sure if mentorship opportunities had increased, and some (28%/11) indicated that for them mentorship opportunities had indeed increased. In terms of the quality of the experience of being either a mentor or mentee (or both), results were mixed. Thirty-three per cent (13) reported that the experience being either a mentor or mentee (or both) was `good', 31% (12) indicated `excellent', 13% (5) indicated `fair', 10% (4) indicated `very good', 1 person indicated `exceptional' and 1 person indicated `poor'.

PEI Policy Hackathon Program

Page 21 of 73

Pre-Program Survey Question

Please rate your current policy capacity (1 `very poor'; 7 `exceptional)

Result Very poor 0% (0) Poor 4% (2) Fair 11% (5) Good 41% (19) Very good 33% (15) Excellent 11% (5) Exceptional 0% (0) Yes 96% (45) No 0% (0) Not Sure 4% (2) Yes 45% (21) No 0% (0) Not Sure 55% (26) Yes 48% (22) No 30% (14) Not Sure 22% (10) Yes 22% (10) No 44% (20) Not Sure 35% (16)

Post-Program Survey Question Result Decreased greatly 0% (0) Decreased slightly 0% (0) Stayed the same 26% (10) Increased slightly 44% (17) Increased greatly 31% (12) Yes 92% (36) No 0% (0) Not Sure 8% (3) Yes 28% (11) No 36% (14) Not Sure 36% (14) Yes 90% (35)10 No 8% (3) Not Sure 3% (1)

"As a result of participating in the Program, my policy capacity has . . ." (`Decreased greatly' to `Increased greatly')

Do you expect that your participation in the Policy Hack Program will provide you with access to valuable learning(Yes/No/Not Sure) Do you think that the Policy Hack Program is likely to increase mentorship opportunities? (Yes/No/Not Sure) Do you feel that you are well connected to a broad range of Island organizations (e.g., federal, provincial, municipal public servants, private sector talent, etc.) (Yes/No/Not Sure) Do you feel that you have all the tools you need to solve problems in your day-to-day work? (Yes/No/Not Sure)

Did the program provide you access to valuable learning? (Yes/No/Not Sure) Did the program increase mentorship opportunities for you? (Yes, No, Not Sure) Did the program allow you to meaningfully connect with a broad range of professionals? (Yes/No/Not Sure) Did the program provide you with new tools to solve problems in your day-to-day work? (Yes/No/Not Sure)

Yes 64% (25) No 21% (8) Not Sure 15% (6)

For those who answered `Yes', they were asked to provide examples of possible benefits of the connections. Thirty-four examples were provided which belonged to one of the following categories: Opportunity to learn new perspectives (12); Expanded information network (6); Gained new contacts (12); and Other (4).
10

PEI Policy Hackathon Program

Page 22 of 73

Results for post-survey question, "Please rate the quality of your experience being either a mentor or mentee (or both)"
35% 30% 25% 20% 15% 10% 5% 0% 0% Very poor Poor Fair Good Very good Excellent Exceptional N/A 3% 3% 13% 10% 8% 33% 31%

Figure 11 Post-survey result: Please rate the quality of your experience being either a mentor or mentee (or both)

Program impact
Generally, impact is assessed by "building a `plausible' bridge between the project's [i.e., program's] direct benefits and wider level impacts" (Douthwaite, Kuby, van de Fliert, et al., 2003:250). However, the method used to determine a program's impact will vary depending on the paradigm within which the study is operating (Ryan, 1988). In the present study, a primarily interpretive and qualitative approach has been used. As such, in opposition to a positivist evaluation study which would assume that "the `true' nature of external reality is discoverable through the scientific method" (Fishman, 1992: 263), the present study assumed that there are "alternative, subjective constructions of reality produced by different individuals" (Fishman, 1992:263). What this means for the present study is that understanding the Po licy Hackathon Program's impact is highly contingent upon what respondents perceived to be impacts as well as my interpretation of their perceptions. "Since interpretive evaluation makes no claim to have uncovered the absolute truth of a situation ... then the decision-makers [i.e., users of this study] are faced with the task of coming to an appreciation of the ways in which the [study] will be useful to them" (Ryan, 1988:36). As such, claims this paper makes with respect to the causal links between responde nts' participation in the Program and changes in their behavior are best read as being tentative and open for alternate interpretations (see Thorne, Kirkham & O'Flynn-Magee, 2004: 4 & 7 for a discussion of the tentativeness of interpretive description). Furthermore, with respect to assessing the impact of an intervention specifically on participants' policy capacity, it is important to note that "policy capacity research will require significant methodological development" before studies are able to judge policy capacity based on the outcomes of a policy or program (Gleeson, Hegge, O'Neill et al., 2015:244). For an interpretive evaluation study, this means that the researcher-evaluator has to rely on "the judgements of policy practitioners themselves to refl ect on policy capacity" (Gleeson, Hegge, O'Neill et al., 2015:24). Therefore, adopting a more positivist -scientific approach to collecting and analyzing data to assess the Program's outcomes on policy capacity would not only be extremely difficult, but potentially impossible. In the pre-survey, respondents were asked to describe what professional development outcomes/goals they expected to achieve. In total, 46 respondents answered this question. The responses were thematically analyzed into 10 codes: Problem solving skills; Knowledge of policy work; Presentation skills; Communication Skills; Teamwork skills; Policy development skills; Critical thinking skills; Leadership

PEI Policy Hackathon Program

Page 23 of 73

skills; Writing skills; and Networking skills. The post-survey used these codes as response options in a check-all-that-apply (CATA) question to determine if the Program had an impact in supporting participants in achieving their professional development goals. The post-survey results show that most respondents felt that they developed Teamwork skills (76%/29) and more knowledge of policy work (71%/27). Presentation skills, Networking skills, Problem solving skills, and Leadership skills showed results in the 60 th percentile. Slightly over half felt that they achieved professional development outcomes related to policy development, communications skills, and critical thinking skills. Finally, some respondents (37%/14) felt that they gained writing skills as a result of participating in the Program. In terms of comfort levels with on-the-spot/quick decision making, going in to the Program participants assessed themselves as having fairly strong skills in this area. When asked to rate their comfort level with "on-the-spot/quick decision making" in the pre-survey, 85% (39 respondents) indicated good or higher, 13% (6) indicated fair, and 2% (1) indicated poor. Even with a cohort of participants with strong skills in on-the-spot decision-making, the majority of respondents (64%/25) indicated in the post-survey that their skills in this area had increased as a result of participating in the Program. In terms of longer-term impacts of the Program on participants' future policy learning, respondents were asked if they thought they are likely to integrate similar learning opportunities into their professional development plan. The results showed that the majority of respondents were likely, to some degree, to seek similar learning opportunities in the future (18%/7 `very likely'; 38%/15 `likely; 21%/8 somewhat likely). When asked to reflect on the polic y capacity of the entire group in the post-survey, the majority of respondents (74%/31) thought that the Program improved the policy capacity of the group as a whole, while some (18%/7) were not sure.
Pre-Program Survey Question Result Codes for open-ended What professional responses: development outcomes do you expect to achieve by Problem solving skills participating in the Policy Knowledge of policy work Hack Program? (OpenPresentation skills ended) Communication Skills Teamwork skills Policy development skills Critical thinking skills Leadership skills Writing skills Networking skills Post-Program Survey Question Result Did you achieve any Problem solving skills of the following 63% (24) professional Knowledge of policy work development 71% (27) outcomes? (checkPresentation skills all-that-apply) 68% (26) Communication Skills 53% (20) Teamwork skills 76% (29) Policy development skills 58% (22) Critical thinking skills 53% (20) Leadership skills 63% (24) Writing skills 37% (14) Networking skills 66% (25) Decreased greatly 0% (0) "As a result of Decreased slightly 0% (0) participating in the Stayed the same 36% (14) Program, my comfort Increased slightly 64% (25) level with on-theIncreased greatly 0% (0) spot/quick decision making has . . ." (1 `Decreased greatly'; 5 `Increased greatly')

Please rate your comfort level with on-the-spot/quick decision making ((1 `very poor'; 7 `exceptional)

Very poor 0% (0) Poor 2% (1) Fair 13% (6) Good 37% (17) Very good 37% (17) Excellent 11% (5) Exceptional 0% (0)

PEI Policy Hackathon Program

Page 24 of 73

Results for post-survey question,"How likely are you to integrate similar learning opportunities into your professional development plan?"
40% 35% 30% 25% 20% 15% 10% 5% 0% Very unlikely Unlikely Somewhat Undecided Somewhat unlikely likely Likely Very likely 5% 0% 5% 13% 21% 18% 38%

Figure 12 Post-survey result: How likely are you to integrate similar learning opportunities into your professional development plan?

Results for post-survey question, "Do you think that the Program improved the policy capacity of the group as a whole?"

19% 3% Yes No Not Sure 78%

Figure 13 Post-survey result: Do you think that the Program improved the policy capacity of the group as a whole?

PEI Policy Hackathon Program

Page 25 of 73

Results for post-survey question, "Do you think that individuals who participated in the Program will transfer what they learned to organizational processes?"

Yes 41% 59% 0% No Not Sure

Figure 14 Post-survey result: Do you think that individuals who participated in the Program will transfer what they learned to organizational processes?

Policy Innovation
In addition to understanding the performance, relevance and impact of the Program, the study sought to specifically understand the relationship between the Program and policy innovation. Many of the results already presented and discussed indeed speak to characteristics of policy innovation (e.g., quick decision-making, team work, multi-disciplinary connections, knowledge of policy work, etc.). However, as mentioned, Bason's (2014) design for policy theory, the OECD's (2017) core skills for public sector innovation framework, and HCD theory were operationalized through survey questions as well as through interview questions. As previously discussed, the OECD has encouraged governments to promote Iteration, Data literacy, User centricity, Curiosity, Storytelling, and Insurgency as the specific skills and capabilities required for public sector policy innovation. Bason's (2014) design for policy theory establishes six core constructs necessary for policy innovation: Embracing complexity; Vision-Oriented; Citizen-focus; Shaping new alliances; Stewardship; and Impact emphasis. Finally, HCD directs policy designers to ensure humancentricity, cognitive empathy, emotional empathy and iteration in the policy development, implementation and evaluation process (Dong, Dong & Yuan, 2018; IDEO, 2015; Efeoglu, Møller, Sérié, et al., 2013:241). The following first presents the survey results, followed by a presentation of the interview results. Thematic analysis (Braun & Clarke, 2006) was used to develop codes for interviewee's responses to questions which promoted them to discuss Bason's (2014) and the OECD's (2017) policy innovation constructs. The collections of codes provide additional depth and context to the discussion of survey results related to policy innovation (the policy innovation themes arising from interviewee's responses have been organized into sets of diagrams). In terms of the connection between mentorship and policy innovation, the pre-survey showed that the majority of respondents (78%/37) going in to the Program believed that mentorship opportunities were important for innovative policy development while some (17%/8) were not sure. Following the Program, most respondents (62%/24) reported that as a result of participating in the Program, their opinion of the importance of mentorship opportunities for innovative policy development increased to some degree (18%/7 `increased greatly'; 44%/17 `increased slightly') while some (36%/14) reported that their opinion stayed the same. With respect to confidence in applying human-centered design concepts when developing solutions, going in to the Program participants reported fairly high levels of confidence. The weighted average for confidence in applying `human-centricity' was 3.59/5, `cognitive empathy' was 3.65/5, `emotional empathy' was 3.63/5, and `iteration' was 3.54/5. Following the Program, the majority of respondents reported an increase, to some degree, in their confidence in applying these concepts.

PEI Policy Hackathon Program

Page 26 of 73

Pre-Program Survey Question Result

Are mentorship opportunities important for innovative policy development? (Yes, No, Not Sure)

Yes 78% (37) No 4% (2) Not Sure 17% (8)

Post-Program Survey Question Result Decreased greatly 0% (0) "As a result of Decreased slightly 3% (1)11 participating in Stayed the same 36% (14) the Program, my Increased slightly 44% (17) opinion of the Increased greatly 18% (7) importance of mentorship opportunities for innovative policy development has . . ." (1 `Decreased greatly'; 5 `Increased greatly')

(Weighted average) Humancentricity "As a result of participating in the Program, my confidence in applying human centricity; cognitive empathy; emotional empathy; and iteration when developing solutions has . . .": (each rated, 1 `Decreased greatly'; 5 `Increased greatly')

Human-centricity Decreased greatly 0% (0) Decreased slightly 0% (0) Stayed the same 15% (6) Increased slightly 67% (26) Increased greatly 18% (7)

3.59/5 How confident are you in applying the following concepts when developing solutions: human centricity; cognitive empathy; emotional empathy; iteration (each rated, 1 `not at all confident'; 5 `very confident') Cognitive empathy

3.65/5 Emotional empathy

Cognitive empathy Decreased greatly 0% (0) Decreased slightly 0% (0) Stayed the same 31% (12) Increased slightly 62% (24) Increased greatly 8% (3) Emotional empathy Decreased greatly 0% (0) Decreased slightly 0% (0) Stayed the same 44% (17) Increased slightly 46% (18) Increased greatly 10% (4) Iteration Decreased greatly 0% (0) Decreased slightly 0% (0) Stayed the same 18% (7) Increased slightly 72% (28) Increased greatly 10% (4)

3.63/5 Iteration

3.54/5

Those who answered `decreased greatly' or `slightly' were asked to explain why through an open-ended question. The comment from the respondent who indicated `decreased slightly' seemed to point to how innovative coaching is as opposed to an actual decrease in his or her opinion: "'[There is] clear evidence and research to support coaching model. This is not new".
11

PEI Policy Hackathon Program

Page 27 of 73

Respondents reporting 'agree' and 'strongly agree' (combined) for postsurvey questions on Program's impact related to Policy Innovation Capacity (Bason, 2014; OECD, 2017)
100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0%
Better Better Increased appreciation forappreciation for ability to data storytelling develop new alliances Increased ability to embrace complexity More More visioncomfortable oriented with challenging the status quo More More More citizencomfortable comfortable oriented with with connecting determining problems and policy impacts solutions

90%

90% 80% 79% 79% 77% 67% 66% 64%

Figure 15 Post-survey result: Questions on Program's impact related to Policy Innovation Capacity

Results for post-survey quesion, "Do you think that individuals who participated in the Program are now more prepared to conduct innovative policy work?"

21% Yes 5% 74% No Not Sure

Figure 16 Post-survey result: Do you think that individuals who participated in the Program are now more prepared to conduct innovative policy work?"

PEI Policy Hackathon Program

Page 28 of 73

Data Literacy For some participants, `data' was a theme during the Program, particularly in terms of its importance for policy. For others, they struggled to effectively gain access to (or meaningfully use) data during the case competition process.
 "We learned a bit about data; but we did not
Struggled with data

Understood importance of data

Lack of data

The Program and "Data Literacy"

Data was a theme

Contemplated data

Learned a lot about data

Figure 17 Data Literacy Codes (Interviews)

dive down deep into data" (R4).  "[Data literacy] was a theme because our question involved a lot of data. It may of depended on what other people's questions. No sessions, however, [explicitly] dealt with data " (R6).  "My group looked at data. But, we did not go too deeply into the data. We understood that we had to look at what was available however. It was a component but minimal overall" (R7).  "Data from stakeholders was not available to us." (R8).  "Our group struggled with data. Knowing what data exists was difficult. There was a lack of data for our problem. Therefore, our question had us thinking about data and how little existed" (R1).  "So we did a lot of research and collected evidence" (R2).

Storytelling Participants were indeed exposed to the importance of storytelling for policy during the Program. Stories were considered to be "powerful" mechanisms for both explaining and promoting a policy.
 "Storytelling was related to the pitch. Our
group took this to heart. However, there was a disconnect with the pitch and the ECM. Some said the ECM was more important, whereas others said the pitch was more important. Therefore, we cut out a lot of substance from the ECM to have more of an emotional pull" (R1).  "Storytelling sort of came out of our team. In the beginning we were too number-based. I think we could have done better with the storytelling approach" (R4).  "It was the story that won people over, not the product" (R6).  "The topic of storytelling was brought up. I learned that it is important to tell the story to see how it resonates with the audience. We were cognizant of this in our work" (R7).  "Definitely, the last workshop really brought home the importance of storytelling. The group exercises demonstrated the power of using stories to develop a pitch. Stories helped us to develop a pitch" (R8).

Pitch exercise reinforced importance of storytelling

Stories are powerful

The Program and "Storytelling"

Teams understood importance of storytelling

Stories are important

Figure 18 Storytelling Codes (Interviews)

PEI Policy Hackathon Program

Page 29 of 73

New Alliances For some participants, the Program allowed for networking which may not have occurred without them having been enrolled in the Program. However, many others said that there were not enough opportunities to network, primarily due to a lack of time.
 "I think the Program assisted with developing
Limited opportunity for networking

Program facilitated new public-private networks

The Program and "New Alliances"

Need more networking opportunities

Unequal distribution of Program tasks limits networking

Figure 19 New Alliances Codes (Interviews)

new networks. The teams would not have organically come together without the Program. Having a member of the private sector on my team was very valuable. It helped to give our issue a new point of view from someone who doesn't know how government works" (R8).  "I did some positive networking in my own group, but did not have contact with other people in the Program. So there was not a lot of socializing or opportunity to talk to other groups. It was limited" (R3).  "There were a few areas the Program could have improved on: one being that there could have been more networking. At the very beginning, there was no way to figure out who everyone was" (R6).  "The Program had a minimal impact for me in the area of networking. Because most of the work was left to only 3 group members, I missed out on networking. There were not lunches provided, so we did not have much opportunity to network. [Nevertheless,] pulling people from different areas is good for policy." (R7).

Complexity Participants communicated that `complexity' was indeed a theme during the Program. More specifically, the Program was thought to have effectively demonstrated to participants that problems in general are complex, and more specifically, implementing strategies across government is complex.

PEI Policy Hackathon Program

Page 30 of 73

 "The Program helped people to see how
Policy problems are complex

Important to document complexity in a final report The Program and "Complexity"

Interdepartmental policy is complex

Not enough time to deal with complexity

Complexity creates challenges

complex problems really were" (R1).  "I learned that problems are complex. Project was about implementing strategy across government. Was exposed to the complexity " (R2).  "The Program introduced that policy is complex. For example, our case was really broad ­ it was very complex with many areas and sub-areas. The program reinforced the challenges of how complex policy is" (R3).  "A [final] report would have been able to capture more of the complexity" (R6).  "The questions that were provided to the groups were quite broad and did not have a narrow focus (which is fine), but we did not have enough time to deal with this complexity" (R7).

Figure 20 Complexity Codes (Interviews)

Insurgency (Challenging the status quo) On the one hand, the Program was thought to have inspired some individuals to challenge the status quo, think outside the box, and to practice being bold in the face of challenges. For others, however, the Program was seen to have contributed to maintaining the status quo because some were encouraged to structure their solutions around existing frameworks.
 "I think having diverse points of view is
Program maintained status quo

Inspired to challenge status quo The Program and "Insurgency"

Need to know "what is happening" to challenge status quo

Encouraged to think outside of the box

Boldness is important

Figure 21 Insurgency Codes (Interviews)

essential for solving problems in government. Not sure how effective this is for challenging the status quo. A lot of times we do not see what is happening" (R3).  "We were told to be bold and felt like our case had to be bold to solve the problem" (R4).  "I think challenging the status quo came out. We had to look outside of the box" (R6).  "We were encouraged to think outside of the box. The challenge is to take people who are not doing policy and allow them to participate more; do more of this. And perhaps then more innovative solutions may come about" (R7).  "Yes, actually, we discussed this [i.e., challenging the status quo] as a group. We talked about how we can go back to our employers and show them that consultations and policy development can indeed be completed in 5 weeks, so there is no reason why government processes should take 6-8 months" (R8).  "The Program may have actually enhanced the status quo instead of changing it. There was a lot of pressure to structure solutions around existing frameworks" (R1).

Vision (Envisioning desirable futures) For some participants, `vision' was a theme during the Program. Participants communicated that they were encouraged to envision a desirable future through thinking long-term about how to address issues in PEI.

PEI Policy Hackathon Program

Page 31 of 73

Knowing audience is important for vision

 "My team used vision to think strategically and
long-term. Government processes are currently short term. We argued that we have to look beyond the election cycle" (R4).  "Program was vision-oriented" (R6).  "When were doing our research and figuring out the target audience, we read a lot of mandate letters from 2018 to get the vision of government" (R1).

The Program was vision-oriented The Program and "Vision"

Government Mandate Letters provide vision

Visionary public policy conflicts with politics (elections)

Using vision is strategic

Figure 22 Vision Codes (Interviews)

Policy Impact `Impact' seems to have been a theme to varying degrees during the Program. For some group s, they were encouraged to think about how the policy they were considering may impact other people. Others viewed the Program being primarily oriented towards understanding potential impact to government (i.e., internal impacts). Finally, for others, there was not enough time to fully consider policy impacts during the Program.
 "With my group, impact was a theme. My group was
given a question on how to improve access to primary care. Our sponsor said, we cannot change the policy. So we were structurally pushed in one direction. So we already knew that our impact was going to be internal" (R1).  "For me, it helped open my eyes of being exposed to a diversity of different backgrounds. It subliminally put into my mind the broad impacts of developing policy on other people" (R4).  "The Program did not focus that much on policy impacts. If we had more time, we may have looked at potential impacts of ideas and solutions" (R7).

Internal vs. external impacts

Not enough time to focus on impact

The Program and "Policy Impact"

Impacts of policy on other people

Not a lot of focus on impact

Figure 23 Policy Impact Codes (Interviews) Stewardship (Connecting problems and solutions) "Design Stewardship is [in part] about connecting problem definition to solution delivery, through an iterative process" (Bason, 2014: 97). During the Program, some groups struggled to define the problem they were addressing, while for others, the Program facilitated problem identification. For one participant, the Program was instrumental in them learning that problem identification was essential for effective policy development: "Going into the Program I did not view policy as being problem solving. By the end of the program, I realized problem solving is really important for policy development " (R4).

PEI Policy Hackathon Program

Page 32 of 73

 "It depended on the question each group was
Struggled with defining problem HCD is helpful for solution development Focussed on connecting problem to solution

New insights re: policy and problems

The Program and "Stewardship"

The Executive Council Memo was a distraction

Problem solving and policy development are synonymous

Teamwork is important for problem definition

Figure 24 Stewardship Codes (Interviews)

given to tackle and the level of support given by sponsor. I think groups struggled with defining the problem" (R1).  "We were very focused on defining the actual problem. The ECM format did not help with connecting the problem to the solution. Some team members became very focused on writing the ECM, as opposed to working as a team and working through the problem definition stage." (R3).  "Going into the Program I did not view policy as being problem solving. By the end of the program, I realized problem solving is really important for policy development: `Something is broken and you gotta fix it!'. With policy, it is a different flavor of problem solving: You have to be looking for long-term solutions." (R4).  "Problem definition/solution development was not new for me, but I practiced my graduate [education] skills" (R6).  "I think the Program taught us how to focus a problem to manage; how to continue to drill down and make the scope appropriate. The original policy issue was quite vague. The HCD session helped us in defining a problem" (R8).

Citizen Focus While the Program may not have included the actual participation of citizens, being `citizen-focused' was nevertheless a theme for some participants. Connections were made between HCD and making life easier for citizens as well as the importance of helping clients to navigate the system. For others, they were more focused on impacts to government as opposed to the individual citizen.
 "The one theme that came out was human-centered
HCD makes life easier for clients

Focus was on government not clients The Program and "Citizen Focus"

Citizen-focus was a theme

Client identification issues Short time frame limited citizen-focus

Helping clients navigate the system

design. And designing programs that make life easier" (R1).  "Citizen-focus was a theme. I think this was a theme with every group. Our group was very resident focused" (R6).  "The Program did bring up the fact that Government needs to help [clients] navigate the system better" (R8).  "I think the Program had elements related to being citizen-focused. However, the timeframe did not allow a lot of exploration of policy and citizens. In order to develop policy, citizens are an important element" (R7).  "The problem chosen was going to impact government and citizens, we had a difficult time determining who exactly was the client" (R3).

 "My team did not focus on being citizenfocused that much. We were thinking more about the government worker, not the public so much" (R4).

Figure 25 Citizen Focus Codes (Interviews)

PEI Policy Hackathon Program

Page 33 of 73

Curiosity12 `Curiosity' seems to have been a strong theme throughout the Program. Participants described how the Program helped them to understand that a questioning and inquisitive mind is important for policy development. Other participants were exposed to how different mixes of personalities can either promote or inhibit curious thinking.
 "Personally, curiosity was a theme. My interest in
participating in the Program was to have a learning opportunity just to do something that was purely creative. The manufactured bubble we were working in allowed us to be more creative, because we did not have real-world pressures" (R8).
Questioning assumptions is important for curiosity Structured programs provide good conditions for curiosity

 "There should have been more questioning
assumptions that each of the teams were given" (R1).  "We tried to foster curiosity and creative thinking. A few group members tried to block the creative process. (they wanted to stick with one solution). Had some issues with being creative. We were blocked because other members were unwilling. Going forward, coaches could step in and moderate the `alphas' on the team, which would also help with promoting creative thinking" (R3).  "I know that creative thinking and curiosity was one thing we wanted to include in what we were doing. When it came to the Policy Hack team, we really did not know each other or each other's fields of work: This makes for a good environment for creative thinking. I thought that there could have been more work to take advantage of this diverse team. To expand upon our mixed background, methodologies of creative thinking etc." (R4).  "The Program helped build curiosity" (R6).  "The program gave me new insights about a lot of new processes" (R7).

The Program and "Curiosity"

Actors may block the creative process

The Program supported a culture of curiosity

Diversity promotes creative thinking

Figure 26 Curiosity Codes (Interviews)

Iteration The post-program survey results show that many respondents reported that their comfort level with the concept of iteration had either `improved slightly' or `stayed the same' fo llowing the Program. The interviews with a random sample of participants show that there were a mix of participants in the sample who had likely either reported `increased slightly' or `stayed the same' in the survey. Some participants indeed communicated that `iteration' was not a theme, during the Program while others reported that they not only learned about the importance of iteration but also practiced it.

12

Note that the post-program survey erroneously did not ask respondents about curiosity.

PEI Policy Hackathon Program

Page 34 of 73

 "We learned about the

Iteration was not a theme

The Program and "Iteration"

importance of introducing a pilot, and then tweaking it" (R4).  "Thinking, writing, and thinking again; the program taught me this was a good process. We also often came back to the core problem, and reexamined it over and over again" (R7).  "No, this was not really theme. If it was, it was minor" (R1).  "The cycle focus was not prevalent" (R3).  "I am not sure [if iteration was a theme]" (R8).  "I do not remember anything really about being iterative" (R6).
Learned about iteration

Practiced iteration

Figure 27 Iteration Codes (Interviews)

Recommendations
Respondents and interviewees were asked to provide recommendations on how the Program could be improved in the future. A thematic analysis of responses supported developing the following seven recommendations. 1. Future policy hackathon programs should clearly communicate to prospective participants the amount of time and commitment required to complete the program. "There needs to be an honest account of the time investment before people sign up. Not one group was able to achieve their necessary result in the time that was indicated on sign up - it took much longer given the breadth and depth of the problems given" (R17). "I found the time commitment to be very challenging" (R18). "The amount of time needed to invest in the program was underrepresented" (R19). "It was likely more of a time commitment than originally anticipated but very worth-while of the time spent - just more to be aware of (especially given the additional PD components each week - these were very valuable but was additional time on top of the hack work " (R22). "Make potential participants aware of time commitment required for team work" (R25). "Better communication on what is expected from the hackers - heard a lot of comments from participants who were surprised at the amount of work it was " (SR2). "The workload [was] underestimated" (R26) "A clear outline of what the program entails at the onset" (R31).

2. Future policy hackathon programs should consider increasing the time frame from 6 to 8 weeks. "Longer time frame" (R31 & R39) "I think an 8 week program may work a little better to facilitate everyone's schedules " (R22). "Longer length" (R19). "Longer duration" (R10). "Perhaps [the Program] could be spread out over more time. Spring tends to be a very busy time of year" (SR4). "With the legislature in session it made the time lines very tight" (R32).

3. Future policy hackathon programs should be more strategic in the order of sessions. Professional development sessions should be completed prior to the exercises related to the case competition.

PEI Policy Hackathon Program

Page 35 of 73

"All PD up front" (SR12). "The courses before the case so you can apply courses more to case" (SR8). "The training sessions need to be at the beginning as by the time we got them, it was too late to apply them" (R19). "Training opportunities to be at the beginning" (SR24). "Move presentations up towards the beginning" (SR23). "Provision of the material in advance" (R28). "Education should be provided at the beginning, not throughout the program. Particularly the collaboration session, although repetitive for many participants, would have been valuable as a starting point for those who hadn't previously attended, not part way through the process. It would have been better to have the professional development days up front. It would have better prepared us for navigating the team work" (R28). "I would like to see an adjustment to the schedule of the learning events. The Human Centered Design would have been better suited to mid-project when teams had a better idea of the proposed solutions to the problems" (SR20). "I would recommend a more intense session (3 days together with the meeting with sponsors being figured out in advance so as the problem definition exercises could be applied during the learning development" (SR26). "Rearrangement of sessions. Include the middle ones first" (SR3). "Reorder the professional development sessions to better align to the program. Team building first. Problem defining later" (SR5) "Include more front end work including collaborative problem solving, pitching and presenting in the early days, more time on human centered design, hold off on releasing cases to groups until this work has been complete" (R15).

4. Future policy hackathon programs should clearly define the role of coaches/mentors and judges, particularly their role in providing feedback to participants. "Need more clarity on role of coach, what type of feedback is expected or appropriate, direction seemed to vary widely" (SR 28). "Coaches and sponsors should be required to attend the first session - not having a clear idea of our topic/question made this day somewhat wasteful because our coach and sponsor were absent. I understand things come up, but having them there would be really valuable!" (SR 27). "Feedback to the teams. Those of us who have never completed an ECM still do not know if what we submitted was accurate. I am walking away not knowing how to do an ECM. Feedback on what issues we did not address would have been a better learning experience " (SR19). "Feedback should be provided to all teams by the judges " (SR 28).

5. Future policy hackathon programs should be structured so that the participation of citizens and community stakeholders (such as academics and universities) are required. "For this policy hack, [we were] to adopt a citizen-centric perspective. [In theory,] this means, you [should] identify a need, a citizen who has that need and what it costs them. You will then talk to at least 2 citizens and validate with them their problem. [In the future,] groups that spend the most time talking to citizens [should] get more points in the competition. ... This is if you want the gro ups to really focus on citizens' problems and service delivery " (SR7). "Also, maybe [the Program] could not have an ECM as I felt this was counter to the idea of having [the Program] be citizen-centric. The ECM to me seems [to be] government-centric. I would suggest rejigging it [i.e. the ECM] (adding a section for `citizens issues' and `how many citizens did you consult', [and] `what did they say about their problem', etc." (SR7). "The organizers should involve the UPEI School of Business to help them with forming Business Case questions" (SR9). PEI Policy Hackathon Program Page 36 of 73

"Involving an academic with Business or Research background to help with developing the Program would give the entire Policy Hack exercise more credibility " (SR9). 6. Future policy hackathon programs should provide more opportunities for formal and informal networking. "More networking opportunities with the larger group. Perhaps some informal events " (SR1) "I would like to have learned what other participants were working on at their desks, in their day to day work. I think this would have provided a little more opportunity to network, even after the event was complete" (SR20). "Limited ability for networking outside of your 4-5 person team was a missed opportunity" (SR28). "More opportunities to meet the people in the other groups" (SR35).

7. Future policy hackathon programs (and future professional development opportunities) should focus on topics related to policy work, the structure of government, leadership, and team dynamics. "Consider organising a workshop on how ... actual policy development work occurs in ... government" (SR13). "A little background knowledge of the department would be useful" (SR14). "Provision of some training on team development and dynamics; team leadership and facilitation; and meeting management" (SR30). "Require pre-requisites [to participate in the Program] such as evaluation and communication. Add these sessions from the Hackathon to the [PEI] Public Service Commission's catalogue of training events" (SR37).

Discussion of Results
Program relevance
The pre- and post-program survey results support the claim that the Program was responding to a need in PEI's policy environment. Not only did a strong majority indicate that government -led efforts to improve policy capacity were important, but there was also a clear indication that the respondents believed that PEI needs new micro- and meso-level policy tools to develop public policy. It is obvious from the results that respondents indicated that opportunities to learn about policy innovation were important to them. This finding is supported by the results of the interviews with participants and key informants. One interviewee stated that "internal policy capacity building is a must. Therefore, the Program was relevant. It was clear to me that the Program was valued [among participants]" (R1). Another interviewee communicated that "from speaking with people in government, the Program was addressing a real problem " (R3). The Program's decision to focus on imparting human-centered design skills on to participants was therefore logical, given that HCD has been theorized to support policy actors in discovering and implementing innovative solutions (Dong, Dong & Yuan, 2018; IDEO, 2015; Efeoglu, Møller, Sérié, et al., 2013:241). Additionally, the Program's emphasis on mentorship was relevant, given that the majority of survey respondents believed that multidisciplinary connections were important for policy development. Since there was a range of individuals with prior mentorship experience, there were ample opportunities for the Program to capitalize on making connections between seasoned and junior mentors and mentees.

Program performance
In terms of the degree to which the Program achieved results in accordance with the stated goals of the Program, a number of observations can be made. Overall, according to survey respondents, the Program performed well in terms of increasing participants' individual policy capacity as well as that of the

PEI Policy Hackathon Program

Page 37 of 73

of the entire group. It is assumed that the combination of session topics and the range of skills which participants were required to use contributed to this perceived increase in policy capacity. The Program's overall performance was assessed by one interviewee when it was stated that, "[the Program] did achieve what it was supposed to do. Any time you do something new, you are learning along the way. If the goal was to build collaborative relationships across government, then the Program did this. If the goal was to learn how to write ECMs, then the Program did this" (R1). Other interviewees noted that, "generally, everything went quite well. [The Program] flowed well and ended on a good note " (R3) and "I think it went well. The Program did what it was supposed to do" (R6). The Program also met participant expectations in terms of them receiving valuable learning. While some pre-survey respondents reported that they were already connected to a broad range of actors prior to joining the Program, nevertheless, according to the post-survey results, the Program performed well in terms of allowing participants to meaningfully connect with a broad range of individuals. This finding from the survey data is further described through an interviewee's observation that, " I think the Program assisted with developing new networks. The teams would not have organically come together without the Program. Having a member of the private sector on my team was very valuable. It helped to give our issue a new point of view from someone who doesn't know how government works " (R8). According to the survey results on `policy tools', the Program's performance in this area varied. For some, the Program provided them new tools to solve problems, while for others, the Program did not. These mixed results could perhaps be explained in part due to the varied backgrounds of participants: There was a range of work experiences in the Program in terms of participants' length of time with their current employer. It is possible that those with more experience working for government may have had a more advanced policy tool kit prior to completing the Program (thus explaining in part why some felt they did not provide them with new tools). This survey finding is indeed supported by one interviewee who communicated that, "I was aware of the various processes to develop policy [prior to the Program], but for others (such as those from the private sector), it exposed them to the policy process " (R8). Nevertheless, given that some individuals were not sure if the Program provided them with new policy tools, the Program's performance in this area could be improved. The survey results show that there was a serious deficiency in the Program's performance in terms of mentorship. Given that many respondents indicated that a) they were not sure if the Program increased mentorship opportunities or b) the Program did not increase mentorship opportunities, it can be concluded that the mentorship component of the Program did not meet participant expectations, nor did the mentorship component achieve results in accordance with the stated goals of the Program. There was also a notable number of survey respondents who reported that the mentorship experience was `fair' or `poor'. Seven of the 9 responses to an open-ended question on the mentorship component of the Program provided negative assessments and only 1 response was positive. Comments such as, "Not a great deal of mentoring happened" (SR1); "Our coach did not participate at all other than to book us a meeting space on one occasion. There were no mentoring opportunities as our group was all experienced" (SR4) and "Our coach had very limited involvement with our team and appeared unclear what level of involvement was appropriate" (SR9) further confirms that the Program's performance in terms of achieving results in accordance with the stated mentorship goals of the Program was less than optimal. The survey finding which points to a negative assessment of the mentorship component is further explained by one interviewee who stated that "There needs to be a more defined and clear role for coaches [i.e., mentors]. There was a haphazard approach between different coaches" (R1). This finding that the mentorship component of the Program was an area needing improvement is not all that surprising, given that "a growing sub -literature on failed and negative mentoring" has shown that mentorship programs "have not been universally successful" (Samier, 2000:84).

Program impact
Looking at the results related to performance, relevance and impact allows some observations to be made with respect to the Program's results on outcomes (both intended and unintended), particularly those which indicate a change in participants' future behavior. In terms of learning, participants indeed perceived the Program to have had a positive impact on their skill development in a wide range of areas (e.g., team work skills, knowledge of policy work, presentation skills, etc.). Given the importance of rapid innovation in times of public sector austerity (Tate, Bongiovanni, Kowalkiewicz,, et al., 2018), the results which showed that the Program had a positive impact in increasing participants' comfort level with on -the-

PEI Policy Hackathon Program

Page 38 of 73

spot decision-making is promising for future policy innovation. Additionally, what is promising for more sustained changes in participants' polic y innovation behavior in the future is the fact that the majority of respondents indicated that they would seek to integrate similar learning opportunities into their professional development plans in the future. This result speaks to the impact that the Program may have on further entrenching and institutionalizing policy innovation learning in the policy environment in PEI. Finally, the results which showed that the majority of respondents believed that the Program increased the policy capacity group as a whole further supports the claim the Program indeed had a positive impact on policy innovation to some degree. Yet, in line with the orthodox social-constructivist critique that identifying an absolute "truth" related to a program's impact is problematic (given that alternate explanations of impact are always present), it is important to reiterate that any claims made to immediate or long-term impacts are interpretive in nature and open to alternate interpretations. The social-constructivist nature of participants' perceptions of the Program's impact is demonstrated in the range of interviewee's responses to a question which prompted them to discuss the Program's impact (if any):  "The initial impact [of the Program] would be seeing other people from other agencies. In terms of just getting people acting outside of their silo, this is an immediate impact " (R1).  "The collaborative teams approach, lessening the silos, and multi-tiered government interaction was impactful" (R2).  "For me, it helped open my eyes of being exposed to a diversity of different backgrounds. It subliminally put into my mind the broad impacts of developing policy on other people " (R4).  "Some things I would not have learned otherwise. For example, writing ECMs. Doing strategic planning [however] was new for me. In this sense, the Program gave me an opportunity to get a taste of these activities" (R7).  "Personally, I do not expect any impact because I do not work in this area [i.e. policy] " (R3).

Policy innovation
The results show that the majority of policy workers involved in this study understood mentorship as being important for policy innovation even before beginning the Program. In theory, "only when governments ... focus on coaching and mentoring the available capacities with the purpo se of creating an ecosystem of innovation" can innovation itself be expected to flourish (Schepers, 2015:90). Therefore, it is promising for future policy innovation capacity development interventions in PEI that policy workers seem to have already established the positive connection between mentorship and innovation. This idea is further supported by the program performance result which indicated that 96% of respondents thought that it was important for island organizations to be able to identify staff who have an interest in conducting innovative types of policy work. In theory, the consciousness among policy workers of the mentorship-policy innovation connection may indicate an openness for institutional relationships which are important for innovation, which in turn may further support the cultivation of a strong innovation ecosystem (see Bogers, Chesborough & Moedas, 2018 for a discussion on innovation ecosystems). Furthermore, even given the fact that many respondents did not view the mentorship component of the Program as being a success, the majority said that their opinion of the importance of mentorship either stayed the same or increased (to some degree) following the Program. As such, while in practice the Program may not have established an effective relationship between mentorship and policy innovation, participants seemed to nevertheless continue to value the relationship in theory. When it comes to the Program and human-centered design (HCD) capacities, it is interesting that many respondents rated their confidence levels in this area as high going into the Program. This sheds additional light on the character of the policy innovation ecosystem in PEI and possibly also speaks to the idea that HCD concepts are already a part of a policy worker's lexicon in this small jurisdiction. The fact that the majority of respondents reported an increase in their confidence to apply HCD concepts following the Program is promising for public policy challenges which this group may encounter in the future. Indeed, future research should look more closely at HCD in theory and practice in PEI to better understand the character of the policy innovation ecosystem in the context of islandness. In terms of Bason's (2014) design for policy theory and the OECD's (2017) core skills for public sector innovation framework, the Program indeed exposed participants to important policy innovation concepts. This is perhaps the greatest success of the Program, given that the concepts related to policy innovation are vast and the amount of time provided by the Program to impart knowledge was rather limited.

PEI Policy Hackathon Program

Page 39 of 73

The results related to the Program's impact on increasing participants' appreciation of data as well as storytelling is particularly interesting. This result perhaps speaks to the way in which policy hackathon programs can, either intentionally or unintentionally, promote multiple modes of enquiry for fostering policy innovation. In other words, the merging of quantitative/positivist and qualitative/interpretive evidence and other information seemed to have happened during the Program rather organically, given that this outcome was not identified as a goal at the outset of the Program. Finally, participants' assessment of how prepared they are to conduct innovative policy work in the future provides a summative veneer for the entirety of results thus far presented. Given that a large majority indicated they thought that individuals who participated in the Program were better prepared to conduct innovative policy work in the future, it can be assumed that the Program indeed had a positive impact, to some degree, on increasing the policy innovation capacity of policy workers.

Conclusion
Islandness and public policy
So what can the results of a program evaluation study with policy workers from the public and private sector in PEI tell us about the islandness of public policy? According to the findings of the present study, Baldacchino's (2006) argument that innovative strategies are pursued by small island jurisdictions, even in the face of economic vulnerability, has credence in this jurisdiction. Participants indeed viewed PEI's first public sector-led Policy Hackathon Program as being important and relevant to this jurisdiction. Yet, it is worth noting that limited resources, which often characterizes small island jurisdictions (Baldacchino, 2008:24; Connor, 2008:35 ­ 36) did have an impact on the effectiveness of the Program. The comments from participants speak to the former point on limited resources: " If we had more time, we may have looked at potential impacts of ideas and solutions " (R7); "I found the time commitment to be very challenging" (R18); and "There needs to be an honest account of the time investment before people sign up. Not one group was able to achieve their necessary result in the time that was indicated on sign up - it took much longer given the breadth and depth of the problems given" (R17). From interviewing key informants and participants, this study found that the "lack of time" to pursue innovation was due to the fact that many individuals were required to maintain full-time work while completing Program activities. As such, this speaks to the idea that - while islandess may be associated with opportunities for innovation due to social capital and the ability to quickly implement new ideas (McKenna, 2014) - there are also unique challenges which islandess, particularly small islandess, poses for policy innovation. Indeed, the study found that policy workers assessed PEI's policy innovation environment as mediocre in terms of organizational processes, policy tools, mentorship and institutional ability to identify staff who are interested in innovative types of policy work. Using a systems perspective to understand policy innovation points to the idea that organizations do not innovate in a silo, rather, in the context of a system of actors and institutions (Smits & Kuhlmann, 2004:7). As such, future research should build on Baldacchino and Stuart (Eds., 2008) and look more closely at the barriers and enablers of policy innovation in small, sub-national island jurisdictions as well as the particular character of public policy in this unique context.

Policy innovation
Policy innovation can be pursued through policy hackathon programs. As shown in this study, having Program sessions that were explicit in their intention to impart HCD knowledge, ideas from Bason's design for policy theory (2014) and concepts from the OECD's (2017) core skills for public sector innovation framework resulted in - according to participants - an increase in knowledge and skills important for policy innovation. In particular, the findings of this study support Chiu, Pei and Jean's (2018:1) argument that hackathons can provide a safe environment to think outside the box (and as such are conducive to promoting innovative ways of thinking). As noted by one interviewee: " We were encouraged to think outside of the box. The challenge is to take people who are not doing policy and allow them to participate more; do more of this. And perhaps then more innovative solutions may come about" (R7). The findings from this exploratory study also speak to the idea that policy innovation can emerge through a policy hackathon program in unpredictable ways. " For me, [the Program] helped open my eyes of being exposed to a diversity of different backgrounds. It subliminally put into my mind the broad impacts of developing policy on other people" (R4). The notion that policy innovation learning can be `subliminal' provides an important discussion point on how structured policy innovation capacity development PEI Policy Hackathon Program Page 40 of 73

interventions should be. Even though the extent to which `policy innovation' can be planned and predicted has been debated for quite some time, the structure-innovation relationship continues to be somewhat muddled (Damanpour & Gopalakrishnan, 1998; Drucker, 1985). As communicated by one participant " The manufactured bubble we were working in allowed us to be more creative, because we did not have realworld pressures" (R8). As such, in the future, during the plan ning stages of a policy hackathon program, practitioners should carefully consider how explicit instructions are for participants to innovate. In other words, it may be more beneficial for program designers to craft program structures which more covertly promote an environment for policy innovation as opposed to communicating to participants that, "the purpose of this program is for you to innovate". The diverse body of theoretical frameworks on optimal environments and structures for policy innovation can provide practitioners with guidance in this area (see for example Smits & Kuhlmann, 2004). As such, close and open relationships between public policy academics and practitioners, while indeed becoming less and less attainable than they were in the past, are nevertheless important to bridge the academic-practitioner divide in public administration innovation (Head, 2015; Pollitt, 2017).

Policy hackathons
This study has shown that policy hackathons and public policy are in many ways aligned in both theory and practice. In past and recent times, numerous policy scholars have conceptualized public policy and policy research as having a distinct problem-orientation, a focus on contextualization, and an openness for methodological plurality (Lasswell, 1943 in Brunner & Willard, 2003:3; Bobrow, Eulau, Landau, et al., 1977:417; de Leon 1981:1; Brunner, 1982:125 & 1997:192; Ascher, 1987:3; Farr, Hacker, & Kazee, 2006:582; Wellstead & Stedman, 2015:48). Particularly as demonstrated in this study's discussion of the Program's intersection with "storytelling" and "data literacy", many of the normative and theoretical hallmarks of public policy emerged. Given that hackathons originated in the private IT sector, a domain unlike the public sector in many ways, this study concludes that hackathons represent an example of a new public management phenomenon which has been imported from the private to public sector. As such, Allison's (1979) early assumption that "the notion that there is any significant body of private managem ent practices and skills that can be transferred directly to public management tasks in a way that produces significant improvements is wrong" (472) was not supported in the present study. Finally, with respect to conceptualizing hackathons, this study argues that hackathons are emblematic of larger shifts in modes of governance. Governance scholars have posited that Government is experiencing a "decentering of power" and increased attention has been given towards the co -production of public solutions, "interactive forms of governing", networks, and partnerships as opposed to siloed public sector policy work (Ansell & Torfing, 2016:9-10). Indeed, the hackathon's focus on multi and intersectoral interaction, collaboration, and partnership speaks to the need for future theoretical and empirical research on new forms of governance as experienced through hackathons.

Program `relevance', `performance' and `impact' as heuristics
With respect to the use of `relevance', `performance' and `impact' as heuristics to u nderstand a program and its outcomes, this study is able to make several observations. First, contrary to scientific discourses in evaluation (see for example McMullan, Chrisman & Vesper, 2001 who problematize the validity of evaluations which rely on part icipants' perceptions of impact), these heuristics can be applied using a social-constructivist paradigm and interpretive methodology and subsequently produce useful insights. Second, while there continues to be debate in evaluation with regards to the exact definition of each of these terms, this study adopted definitions which proved useful in organizing and understanding the results. Finally, social-constructivist and interpretivist researchers may need to focus their attention on the idea of program `impact'. Whereas positivist researchers may comfortably assume that the "Capital T truth" of a program's impact can be discovered, interpretivist researchers may be more comfortable with "Lowercase t truths" ­ instrumental and provisional truths which are given through experience (see Johnson & Onwuegbuzie, 2004:18 for a discussion of `Capital T' versus `lowercase t' truths). As such, future philosophical and methodological research should look at how social constructivist and interpretive researchers can contribute to understanding plausible links between a program and micro-, meso-, and macro-level changes.

PEI Policy Hackathon Program

Page 41 of 73

Austerity and citizen-focus
The results related to recommendations provide direction for practitioners who are seeking to implement policy hackathon programs in their jurisdiction. In particular, however, the recommendations that future policy hackathon programs should: Clearly communicate to prospective participants the amount of time and commitment required to complete the program; Consider increasing the time frame from 6 to 8 weeks; and Be structured so that the participation of citizens and community stakeholders are required provide an opportunity for some thoughts on austerity and citizen-focus. In light of current public sector austerity discourses, it is perhaps not surprising that many respondents communicated that future programs should more clearly communicate the amount of time and commitment required. As noted by Colley (2012), "Professionals in ... public services are increasingly finding themselves under pressure from austerity policies which seek to reduce public expenditure sharply, and devolve responsibility for inadequate services onto individual practitioners through the use of often unfeasible targets" (331). Austerity measures in North America and Europe have been shown to pose challenges for in-service learning when tangible results are not guaranteed (Colley, 2012). "Austerity thus not only changes the conditions of the field, but in doing so also seeks to re-orient practice within in" (Colley, 2012: 331). This is problematic for policy hackathon programs that do not produce tangible results. In other words, when organizations are expected to do more with less, it may be challenging for participants' employers to support the idea of allowing staff to engage in weeks of ideation, planning, and learning without any guarantee of a tangible business improvement (Colley, 2012: 320). Indeed, the present study confirmed Johnson and Robinson's (2014) finding that, "if hackathon[s] ... have little prospect of being widely adopted, and have no life or impact beyond the event itself, host governments run the risk of the hackathon process being labeled as disingenuous engagement activities and also of exhausting participants' appetite for future involvement in new activities" (355). As such, in addition to better communicating to prospective participants the amount of time and commitment required, program planners should also seek buy-in from participants' employers and present them with a business case as to how the program will benefit the workplace. This may support employers in re-prioritizing participants' workloads while they participate in the program. It is thought that when governments seek to co-design or co-produce public policy with citizens, that there are benefits for the public sector and society. Namely that the democratic deficit is reduced and more resources are added to an already austere public service (Osborne, Radnor & Strokosch, 2016). However, in the case of the present study, while participants indicated an increase in their knowledge of being citizen-centric, the actual participation of citizen's in the policy hackathon process was minimal. Therefore, it may be the case that this recommendation confirms that, "despite [a] growing body of empirical research, co-production continues to be poorly formulated and has become one of a series of `woolly-words' in public policy" (Osborne, Radnor and Strokosch, 2016:640). Nevertheless, co -design and co-production poses challenges for civil servants who are accustomed to looking inward as opposed to outward for solutions (Bason, 2018:171). Future programs should adopt a more structured approach to the involvement of citizens, stakeholders, and policy users to encourage participants to "put the ir own professional backgrounds and experience on hold, and allow themselves to discover a different reality than their own" (Bason, 2018:171). Theory builds on the recommendation participants put forth by suggesting that future programs should define co-production more clearly, perhaps using Osborne, Radnor and Strokosch's (2016) definition: "We define co-production as the voluntary or involuntary involvement of public service users in any of the design, management, delivery and/or evaluation of public se rvices" (640).

PEI Policy Hackathon Program

Page 42 of 73

Appendices
Appendix A: Pre-Program Survey

PEI Policy Hackathon Program

Page 43 of 73

PEI Policy Hackathon Program

Page 44 of 73

PEI Policy Hackathon Program

Page 45 of 73

PEI Policy Hackathon Program

Page 46 of 73

PEI Policy Hackathon Program

Page 47 of 73

PEI Policy Hackathon Program

Page 48 of 73

PEI Policy Hackathon Program

Page 49 of 73

Appendix B: Post-Program Survey

PEI Policy Hackathon Program

Page 50 of 73

PEI Policy Hackathon Program

Page 51 of 73

PEI Policy Hackathon Program

Page 52 of 73

PEI Policy Hackathon Program

Page 53 of 73

PEI Policy Hackathon Program

Page 54 of 73

PEI Policy Hackathon Program

Page 55 of 73

PEI Policy Hackathon Program

Page 56 of 73

PEI Policy Hackathon Program

Page 57 of 73

PEI Policy Hackathon Program

Page 58 of 73

Appendix C: Interview Guides
Program Participants

Theory

Construct

Questions (Semi-Structured) "Did the program X, Y, or Z? If yes, how?"
Q. 1.A Perform well overall? (If no, why?) Q.1. B Respond to a need? (If no, why?) Q.1.C. Have an impact? (If no, why?) Q. 2. Prepare participants to embrace the complexity of policymaking? Q. 3. Provide participants with skills to envision desirable futures for policy? Q. 4. Cultivate an environment for human-centred design or a citizen-focus for policy? Q. 5. Allow participants to shape new alliances with a broader group of actors? Q. 6.Improve participants' ability to connect problem definition and solution development? Q. 7. Improve participants' ability to focus on policy impact as opposed to policy-asstrategy? Q. 8. Improve participants' skills to solve problems through iterative processes? Q. 9. Improve participants' appreciation for the value of data? Q. 10. Promote an environment where creative thinking is valued? Q. 11. Improve participants' understanding of the use of storytelling in policy development? Q. 12. Challenge the status quo?

Interviewee Answer

General

Performance Relevance Impact Complexity Vision

Bason (2014) OECD (2017)

CitizenFocus New Alliances Stewardship Impact Iteration Data Literacy Curiosity Storytelling Insurgency

Key Informants 1. Overall, what is your thoughts on the performance, relevance and/or impact of the Policy Hack Program? 2. Do you think the Program encountered any challenges? If yes, please describe. 3. Do you have any thoughts on the Program in terms of providing mentorship/coaching for participants? 4. Do you have any thoughts on the Program in terms of its impact on participants' policy capacity? 5. In what ways do you think the Program could improve in the future? 6. Do you have anything else you would like to add? PEI Policy Hackathon Program Page 59 of 73

Appendix D: Evaluation Matrix for the Pre- and Post-Program Survey
Key Terms Performance Relevance Impact

The degree to which a program operates according to specific criteria/standards/guidelines or achieves results in accordance with stated goals or plans of the program. The extent to which a program, policy or other entity addresses and is responsive to a demonstrable need. How the intervention being evaluated affects outcomes, whether these effects are intended or unintended.

Program Outcomes Evaluation from Logic Factor Model

Evaluation Question

Evidence

Pre-Program Survey (Apr.20-29, 2018) What are the characteristics of the sample?

Post-Program Survey (Jun.10-20, 2018)

All participants N/A Demographics Gender; Length of employment w/ public service; Fed. Prov. or Private employee; and total sessions attended (for post-program survey). Post Survey Q. 14 Please complete the Pre Survey Q. 18 On a following sentence: "As a scale of 1 to 7 where 1 result of participating in means `very poor' and 7 the Program, my policy means `exceptional', capacity (i.e., my ability to please rate your current identify problems and policy capacity (i.e., your propose solutions) has . . ability to identify problems ." (`Decreased greatly' to and propose solutions)? `Increased greatly')

P Performance

To what degree did the program improve policy capacity among policy workers for improved policy outcomes?

Public servant's policy capacity improves (which results in improved policy outcomes in the future). To what extent do respondents think that improving policy capacity among policy workers for improved policy outcomes is important?

Data captured elsewhere

R Relevance

Pre Survey Q. 8 Do you think that government-led efforts to improve policy capacity among public servants (for improved policy outcomes) is important? (Yes, No, Not Sure)

Post Survey Q. 9 Do you think that individuals who participated in the program are now more prepared to conduct innovative policy work? (Yes, No, Not Sure) *Also will record impact Post-Survey Q. 5 Please complete the following sentence: "As a result of participating in the Program, my opinion of the importance of government-led efforts to improve policy capacity among public servants (for improved policy outcomes) has . . ." (`Decreased greatly' to `increased greatly') *Also will record impact N/A

Pre Survey Q. 7 Do you think that the policy capacity of professionals

PEI Policy Hackathon Program

Page 60 of 73

needs to improve (i.e., ability of public servants or staff in your organization to identify problems and propose solutions) (Yes, No, Not sure)? *Also will record impact (see Post Survey Q.15) Post Survey Q. 15 Thinking about the experience of all participants in the program, do you think that the program improved the policy capacity of the group as a whole? (Yes, No, Not Sure) Post Survey Q. 21 Did you achieve any of the following professional development outcomes (Answer options based on responses to Pre-Survey Q.23). Post Survey Q. 19 On a scale of 1 to 5, where 1 means `decreased greatly' and 5 means `increased greatly, please complete the following sentence: "As a result of participating in the Program, my comfort level with on-thespot/quick decision making has . . ."

Data captured elsewhere

Pre Survey Q. 23 What professional development outcomes do you expect to achieve by participating in the Policy Hack Program? (Open)

I Impact

What were the intended and unintended outcomes of increasing better outcomes/stronger policy for decision-makers? (if applicable)

Pre Survey Q. 19 On a scale of to 7 where 1 means `very poor' and 7 means `exceptional', please rate your comfort level with on-thespot/quick decision making. .

Pre Survey Q. 20 On a scale of 1 to 5, where 1 means `not at all confident' and 5 means `very confident', how confident are you in applying the following concepts when developing solutions: human centricity; cognitive empathy; emotional empathy iteration

N/A

Post Survey Q. 20 On a scale of 1 to 5, where 1 means `decreased greatly' and 5 means `increased greatly', please complete the following sentence: "As a result of participating in the Program, my confidence in applying the following human-centred design concepts when developing solutions has . . .": (human centricity; cognitive empathy; emotional empathy iteration.) Post Survey Q.22 On a scale of 1 to 7, where 1 means `very unlikely' and 7 means `very likely', as a result of participating in the Program, how likely

PEI Policy Hackathon Program

Page 61 of 73

are you to integrate similar learning opportunities into your professional development plan? To what degree did the program provide access and coordination of learning through the Policy Hack for public servants? To what extent do respondents think that providing access and coordination of learning through the Policy Hack is important? What were the intended and unintended outcomes of providing access and coordination of learning through the Policy Hack? (if applicable) Pre Survey Q. 17 Do you expect that your participation in the Policy Hack Program will provide you with access to valuable learning?(Yes, No, Not Sure) Pre Survey Q. 6. On a scale of 1 to 7, where 1 means `not at all important' and 7 means `extremely important, how important are opportunities to learn about innovative policy development? Post Survey Q. 7 Did the program provide you access to valuable learning? (Yes, No, Not Sure) *Also will record impact

P Performance

Provide access and coordination of learning through the Policy Hack for public servants

R Relevance

Data captured elsewhere

I Impact

Data captured elsewhere

Data captured elsewhere

P Performance

To what degree did the program increase mentorship opportunities in government?

Pre Survey Q. 16 Do you think that the Policy Hack Program is likely to increase mentorship opportunities? (Yes, No, Not Sure)

Post Survey Q. 12 Did the program increase mentorship opportunities for you? (Yes, No, Not Sure) *Also will record impact

N/A There is an increase of mentorship opportunities in government. To what extent do respondents think that increasing mentorship opportunities in government is important? Pre Survey Q. 12 Are mentorship opportunities important for innovative policy development? (Yes, No, Not Sure)

R Relevance

Post Survey Q. 13 On a scale of 1 to 7, where 1 means 'very poor' and 7 means 'exceptional', please rate the quality of your experience being either a mentor or mentee (or both) Post Survey Q. 11 Please complete the following sentence: "As a result of participating in the Program, my opinion of the importance of mentorship opportunities for innovative policy development has . . ." (`Decreased greatly' to `increased greatly') N/A

Pre Survey Q. 10 Are there currently positive mentorship opportunities

PEI Policy Hackathon Program

Page 62 of 73

in your organization? (Yes, No, Not Sure) [If yes] In a few sentences, please describe the positive mentorship opportunities in your organization. What were the intended or unintended outcomes of increasing mentorship opportunities in government? (if applicable) To what degree did the program develop new approaches and/or processes to improve policy development? To what extent do respondents think that developing new approaches and/or processes to improve policy development is important? What were the intended or unintended outcomes of developing new approaches and/or processes to improve policy development? To what degree did the program identify who is interested in doing innovative policy work? To what extent do respondents think that understanding who is interested in doing innovative policy work is important?

I Impact

Data captured elsewhere

Data captured elsewhere

P Performance

Data captured elsewhere

Data captured elsewhere

Develop new approaches and/or processes to improve policy development

R Relevance

Pre Survey Q. 14 Do you think that Island organizations currently have a good process in place to develop public policy? (Yes, No, Not Sure)

See Post Survey Q.10

I Impact

Data captured elsewhere

Post Survey Q. 10 Do you think that individuals who participated in the Program will transfer what they learned to organizational processes? (Yes, No, Not Sure) *Also will record performance

P Performance Government understands who is interested in innovative policy work

Data captured elsewhere

Data captured elsewhere

R Relevance

Pre Survey Q. 5. Is it important for Island organizations to be able to identify staff who have any interest in conducting innovative types of policy work? (Yes, No, Not sure)

Data captured elsewhere

PEI Policy Hackathon Program

Page 63 of 73

I Impact

What were the intended or unintended outcomes of understanding who is interested in doing innovative policy work? To what degree did the program create multidisciplinary connections among public servants? To what extent do respondents think multidisciplinary connections among public servants are important? What were the intended or unintended outcomes of creating multidisciplinary connections among professionals? (if applicable) To what degree did the program provide participants with new tools to solve problems? To what extent do respondents think that new tools to solve problems is important? What were the intended or unintended outcomes of providing participants with new tools to solve problems? (if applicable) To what degree did the program

Data captured elsewhere

Data captured elsewhere

P Performance

Pre Survey Q. 21 Do you feel that you are well connected to a broad range of Island organizations (e.g., federal, provincial, municipal public servants, private sector talent, etc.) (Yes/No/Not Sure) Pre Survey Q. 9 Do you think that multidisciplinary connections among professionals across sectors is important for solving problems? (Yes, No, Not Sure)

Post Survey Q. 16 Did the program allow you to meaningfully connect with a broad range of professionals? (Yes/No/Not Sure) *Also will record impact Post Survey Q. 6 After completing the program, do you think that multidisciplinary connections among professionals is important for solving problems? (Yes, No, Not Sure)

Multidisciplinary connections among professionals across sectors are created

R Relevance

I Impact

Data captured elsewhere

Post Survey Q. 17 If yes, what are some of the possible benefits of these connections (please describe or check N/A)?

P Performance

Pre Survey Q. 22 Do you feel that you have all the tools you need to solve problems in your day-today work? (Yes/No/Not Sure)

Post Survey Q. 18 Did the program provide you with new tools to solve problems in your day-today work? (Yes/No/Not Sure) *Also will record impact

Participants have new tools to solve problems Note: New = new to participant

R Relevance

Pre Survey Q. 13 Do you think that Island organizations need new tools to solve policy problems? (Yes, No, Not Sure)

Data captured elsewhere

I Impact

Data captured elsewhere

Data captured elsewhere

P Performance

Data captured elsewhere

Data captured elsewhere

PEI Policy Hackathon Program

Page 64 of 73

Participants gain experience competing through a case competition to problem solve and pitch solutions

facilitate competing through a case competition to problem solve and pitch solutions? To what extent do respondents think that competing through a case competition to solve problems and pitch solutions is important? What are the intended or unintended outcomes of competing through a case competition to problem solve and pitch solutions? (if applicable) Pre Survey Q. 15 Do you think that competing through a case competition to solve problems and pitch solutions will be a valuable exercise? (Yes, No, Not Sure)

R Relevance

Post Survey Q. 8 Was competing through a case competition to solve problems and pitch solutions a valuable exercise? (Yes/No/Not sure)

I Impact

Data captured elsewhere

Data captured elsewhere

PEI Policy Hackathon Program

Page 65 of 73

References Accenture. (2018). #PSHACK 100 public service hackathon. Retrieved from http://ps-hackathon.fi/ Allison, G. (1979 in 1992). Public and private management: Are they fundamentally alike in all unimportant respects? J. Shafritz & A. Hyde (Eds), Classics of Public Administration. Belmont: Wadsworth. Almirall, E., Lee, M. & Majchrzak, A. (2014). Open innovation requires integrated competition-community ecosystems: Lessons learned from civic open innovation. Business Horizons, 57 (3), 391-400. Almilrall E., & Wareham J. (2011). Living labs: Arbiters of mid- and ground-level innovation. Technology Analysis & Strategic Management, 23 (1), 87-102. Ansell, C. & Torfing, J. (2016). Introduction: Theories of governance. In C. Ansell & J. Torfing (Eds) Handbook on Theories of Governance (1-17). United Kingdom: Edward Elgar Publishing Limited. Ascher, W. (1987). Editorial: Policy sciences and the economic approach in a `post -positivist' era. Policy Sciences, 20 (3), 3-9. Baldacchino, G. (1999). A double dose of unitarism: Employment relations in a small firm in a small island state. International Journal of Employment Studies, 7 (2), 103-121. Baldacchino, G. (2005). The contribution of `social capital' to economic growth: Lessons from island jurisdictions. The Round Table, 94 (1), 31-46. Baldacchino, G. (2006a). Innovative development strategies from non-sovereign Island jurisdictions? A global review of economic policy and governance practices. World Development, 34 (5), 852-867. Baldacchino, G. (2006b). Managing the hinterland and beyond: Two ideal-type strategies of economic development for small island territories. Asia Pacific Viewpoint, 47 (1): 45-60. Baldacchino, G. (2008). The power of jurisdiction. In G. Baldacchino & K. Stuart (Eds.), Pulling Strings: Policy Insights for Prince Edward Island from Other Sub-National Jurisdictions (pp. 23-31). Charlottetown: Island Studies Press. Baldacchino, G. & Stuart, K. (Eds.). (2008). Pulling strings: Policy insights for Prince Edward Island from other sub-national island jurisdictions. Charlottetown: Island Studies Press. Bason, C. (2014). Design for policy. England: Gower Publishing Ltd. Bason, C. (2018). Leading public sector innovation: Co-creating for a better society (second edition). United Kingdom: The Policy Press. Birkinshaw, M. (2013). Policy hackathoning in Bangalore [blog post]. London School of Economics. Bloch, C. (2011). Measuring public innovation in the Nordic countries (MEPIN). Norden Nordic Innovation. Bloch, C. & Bugge, M. (2013). Public sector innovation --From theory to measurement. Structural Change and Economic Dynamics, 27, 133-145. Blomkamp, E. (2017). Co-design for government: Magic bullet or magical thinking? Paper presented at the 3rd International Conference on Public Policy, Singapore, June 28-30. Bobrow, D., Eulau, H., Landau, M., Jones, C., & Axelrod, R. (1977). The place of policy analysis in political science: Five perspectives. American Journal of Political Science, 21 (2), 415-433. PEI Policy Hackathon Program Page 66 of 73

Bogers, M., Chesbrough, H., Moedas, C. (2018). Open innovation: Research, practices, and policies. California Management Review, 60 (2), 5-16. Borras, S. (2011). Policy learning and organizational capacities in innovation policies. Science and Public Policy, 38 (9), 725-734. Braun, V. & Clarke, V. (2006). Using thematic analysis in psychology. Qualitative Research in Psychology, 3 (2), 77-101. Briscoe, G. & Mulligan, C. (2014). Digital innovation: The hackathon phenomenon. Queen Mary University of London. Brunner, R. (1982). The policy sciences as science. Policy Sciences, 15 (2), 115-135. Brunner, R. (1997). Introduction to the policy sciences. Policy Sciences, 30 (4), 191-215. Brunner, R., & Willard, A. (2003). On the policy sciences in 1943. Policy Sciences, 36 (1), 71-98. Canadian Evaluation Society. (2014). Program evaluation standards. Retrieved from https://evaluationcanada.ca/program-evaluation-standards Cardullo, P., Kitchin, R. & Di Feliciantonio, C. (2018). Living labs and vacancy in the neoliberal city. Cities, 73, 44-50. Carstensen H., & Bason, C. (2012). Powering collaborative policy innovation: Can innovation labs help? The Innovation Journal: The Public Sector Journal, 17 (1), 1-26. Chaminade, C. & Edquist, C. (2005). From theory to practice: The use of systems of innovation approach in innovation policy. Center for Innovation, Research and Competence in the Learning Economy Electronic Working Paper Series, No. 2005/02. Retrieved from https://www.obs.ee/~siim/seminars/chaminade+edquist2005.pdf Chiu, A., Pei, K., & Jean, R. (2018). Mentoring sideways ­ A model of resident-to-residence research mentorship. Journal of Surgical Education, latest articles. City of Oshawa. (n.d.). Hackathon. Retrieved from https://www.oshawa.ca/business-andinvestment/hackathon.asp Clark, J., Prochazka, P., & Yiridoe, E. (2007). PVYn and potato wart disease outbreaks in PEI: Policy response and analysis. Canadian Journal of Agricultural Economics, 55 (4), 527-534. Colebatch, H., Hoppe, R. & Noordegraaf, M. (Eds.). (2010). Working for Policy. Amsterdam: Amsterdam University Press. Colley, H. (2012). Not learning in the workplace: Austerity and the shattering of illusio in public service work. Journal of Workplace Learning, 24 (5), 317-337. Connor, H. (2008). The capacity for sub-national island jurisdictions to increase autonomy: The example of Prince Edward Island. In G. Baldacchino & K. Stuart (Eds.), Pulling Strings: Policy Insights for Prince Edward Island from Other Sub-National Jurisdictions (pp. 35-51). Charlottetown: Island Studies Press. Conkling, P. (2007). On islanders and islandness. The Geographical Review, 97 (2), 191-201.

PEI Policy Hackathon Program

Page 67 of 73

Damanpour, F. & Gopalakrishnan, S. (1998). Theories of organizational structure and innovation adoption: The role of environmental change. Journal of Engineering and Technology Management, 15 (1), 1-24. deLeon, P. (1981). Policy sciences: The discipline and the profession. Policy Sciences, 13 (1), 1-7. Demircioglu, M. & Audretsch, D. (2017). Conditions for innovation in public sector organizations. Research Policy, 46 (9), 1681-1691. Desouza, K. & Jacob, B. (2017). Big data in the public sector: Lessons for practitioners and scholars. Administration & Society, 49 (7), 1043-1064. Dong, Y., Dong, H. & Yuan, S. (2018). Empathy in design: A historical and cross-disciplinary perspective. Advances in Neuroergonomics and Cognitive Engineering. Proceedings of the AHFE 2017 International Conference on Neuroergonomics and Cognitive Engineering, Los Angeles, California, USA July 17­21, 2017, pp. 295-304. Douthwaite, B., Kuby, T., van de Fliert, E. & Schulz, S. (2003). Impact pathway evaluation: An approach for achieving and attributing impact in complex systems. Agricultural Systems, 78, 243-265. Drucker, P. (1985). The discipline of innovation. Harvard Business Review, 63 (3), 67-72. Dryzek, J. (1982). Policy analysis as a hermeneutic activity. Policy Sciences, 14 (4), 309-329. Edwards-Schachter M., Matti C., & Alcántara, E. (2012). Fostering quality of life through social innovation: A living lab methodology study case. Review of Policy Research, 29 (6), 672-692. Efeoglu, A., Møller, C. Sérié, M. & Boer, H. (2013). Design thinking: Characteristics and promises. In Proceedings, 14th International CINet Conference on Business Development and Co-creation (pp. 241256). Enschede: Continuous Innovation Network. Ermoshina, K. (2018). Civic hacking: Redefining hackers and civic participation. Tecnoscienza, 9 (1), 79101. Evans, B., Richmond, T. & Shields, J. (2017). Structuring neoliberal governance: The nonprofit sector, emerging new modes of control and the marketisation of service delivery. Policy and Society, 24 (1), 7397. Farr, J., Hacker, J., & Kazee, N. (2006). The policy scientist of democracy: The discipline of Harold D. Lasswell. The American Political Science Review, 100 (4), 579-587. Federighi, P. (2007). Policy learning and transfer in regional lifelong learning policies. In P. Federighi, C. Abréu; & E. Nuissl von Rein (Eds.), Learning Among Regional Governments: Quality of Policy Learning and Policy Transfer in Regional Lifelong Learning Policies (9-36). Bielefeld, Germany: W. Bertelsmann Verlag. Fishman, D. (1992). Postmodernism comes to program evaluation: A critical review of Guba and Lincoln's Fourth Generation Evaluation. Evaluation and Program Planning, 15 (3), 263-270. Gleeson, D., Legge, D. O'Neill, D. & Pfeffer, M. (2011). Negotiating tensions in developing organizational policy capacity: Comparative lessons to be drawn. Journal of Comparative Policy Analysis: Research and Practice, 13 (3), 237-263. Government of Canada, Treasury Board of Canada. (2016). Directive on results.

PEI Policy Hackathon Program

Page 68 of 73

Government of Canada. (2017). GCtools hackathon. Retrieved from https://www.canada.ca/en/treasuryboard-secretariat/campaigns/gctools-hackathon.html Gregg, M. (2015). Speculative labour, app development and the burden of austerity. The Fibreculture Journal, 25, 183-201. Haasnoot, M., Bouwer, L. & Kwadijk, J. (2017). A policy hackathon for analysing impacts and solutions up to 20 metres sea-level rise. Proceedings from the 19th EGU General Assembly, Vienna, Austria, April 2328, 17237. Hay, P. (2006). A phenomenology of islands. Island Studies Journal, 1 (1), 19-42. Head, B. (2015). Relationships between policy academics and public servants: Learning at a distance? Australian Journal of Public Administration, 74 (1), 5-12. Head, B. (2018). Forty years of wicked problems literature: Forging closer links to policy studies. Policy and Society, latest articles. IDEO. (2015). The field guide to human-centered design [1st Edition]. Retrieved from https://www.ideo.com/post/design-kit Institute of Island Studies. (1996, November). Agriculture on PEI: Sunset industry or economic cornerstone? Papers from a Symposium presented by The Institute of Island Studies, PEI Federation of Agriculture, The Round Table on Resource Land Use and Stewardship, and the PEI Department of Agriculture, Fisheries and Forestry. University of PEI, Charlottetown, PE, Canada. Inwood, G., Johns, M., & O'Reilly, P. (2011). Intergovernmental policy capacity in Canada: Inside the worlds of finance, environment, trade, and health. Montreal and Kingston: McGill-Queen's University Press. Irani, L. (2015). Hackathons and the making of entrepreneurial citizenship. Science, Technology, & Human Values, 40 (5), 799-824. Jansen, H. (2010). The logic of qualitative survey research and its position in the field of social research methods. Forum: Qualitative Social Research, 11 (2), 1-21. Johnson, P. & Robinson, P. (2014). Civic hackathons: Innovation, procurement, or civic engagement? Review of Policy Research, 31 (4), 349-357. Johnson, R. & Onwuegbuzie, A. (2004). Mixed methods research: A research paradigm whose time has come. Educational Researcher, 33 (7), 14-26. Jones, G., Semel, B. & Le, A. (2015). "There's no rules. It's hackathon.": Negotiating commitment in a context of volatile sociality. Journal of Linguistic Anthropology, 25 (3), 322-345. Kusiak A. (2007). Innovation: The living laboratory perspective. Computer-Aided Design & Applications, 4 (6), 863-876. Levy, S. (2010). Hackers: Heroes of the computer revolution - 25th anniversary edition. California: O'Reilly Media, Incorporated. Lindblom, C. (1959). The science of `muddling through'. Public Administration Review, 19 (2), 79-88. Malmberg, L. & Holmlid, S. (2013). Embedding design capacity in research driven organizations. In Proceedings from Design-Driven Innovation, Tsinghua International Design Management Symposium (DMI and IEEE, Shenzhen, China, December 1-3.

PEI Policy Hackathon Program

Page 69 of 73

Mason, J. (2006). Mixing methods in a qualitatively-driven way. Qualitative Research, 6 (1), 9-25. McDavid, J. & Hawthorn, L. (2004). Program evaluation & performance measurement: An introduction to practice. Thousand Oaks: Sage Publications. McGann, M., Blomkamp, E. & Lewis, J. (2018). The rise of public sector innovation labs: Experiments in design thinking for policy, Policy Sciences, 1-19, most recent issue. McKenna, P. (2014). Deputy ministers in Prince Edward Island: Professionalism, policymaking, and patronage. In J. Bourgault & C. Dunn (Eds.), Deputy Minister in Canada: Comparative and Jurisdictional Perspectives (72-99). Toronto: University of Toronto Press. McMullan, E., Chrisman, J. & Vesper, K. (2001). Some problems in using subjective measures of effectiveness to evaluate entrepreneurial assistance programs. Entrepreneurship Theory and Practice, 26 (1), 37-54. Morse, J. & Cheek, J. (2014). Making room for qualitatively-driven mixed-method research. Qualitative Human Research, 24 (1), 3-5. Mtsweni, J. & Abdullah, H. (2015). Stimulating and maintaining students' interest in computer science using the hackathon model. The Independent Journal of Teaching and Learning, 10, 85-97. Mytelka, L. & Smith, K. (2002). Policy learning and innovation theory: An interactive and co-evolving process. Research Policy, 31 (8-9), 1467-1479. OECD. (2017). Core skills for public sector innovation: A beta model of skills to promote and enable innovation in public sector organisations. Horizon 2020 Framework Programme for the European Union.Retrieved from https://www.oecd.org/media/oecdorg/satellitesites/opsi/contents/files/OECD_OPSIcore_skills_for_public_sector_innovation-201704.pdf Ontario. (2007). Program evaluation reference & resource guide. Retrieved from http://otf.ca/sites/default/files/274278.pdf Osborne, D. & Gaebler, T. (1992). Reinventing government: How the entrepreneurial spirit is transforming the public sector. New York: Penguin. Osborne, S., Radnor, Z. & Strokosch, K. (2016). Co-production and the co-creation of value in public services. Public Management Review, 18 (5), 639-653. PEI. (2017). Mighty island strategy. Retrieved from https://www.princeedwardisland.ca/en/topic/themighty-island PEI. (2018). Hacking for better outcomes for islanders. Retrieved from https://psc.gpei.ca/hacking-betteroutcomes-islanders PEI, Cabinet Committee on Government Reform. (1992a). Enhancing organizational capacity. The Report of the Management of Government Initiative (University of PEI, Robertson Library, Regular Collections No. JL 215.P75 1992 c.2). PEI, Cabinet Committee on Government Reform. (1992b). The management of quality: An investment in our future. The Report of the P.E.I. Task Force on Quality Assurance. (University of PEI, Robertson Library, Regular Collections No. JL 215.R46 P753 1992 c.2). Peters, J. (2012). Neoliberal convergence in North America and Western Europe: Fiscal austerity, privatization, and public sector reform. Review of International Political Economy, 19 (2), 208-235.

PEI Policy Hackathon Program

Page 70 of 73

Pollitt, C. (2017). Public administration research since 1980: slipping away from the real world? International Journal of Public Sector Management, 30 (6-7), 555-565. Robinson, P. & Johnson, P. (2016). Civic hackathons: New terrain for local government-citizen interaction? Urban Planning, 1 (2), 65-74. Rogers A. & Hewson E. (2016). Development of an early on-set innovation culture in Australia. Small Enterprise Research, 23 (2), 182-189. Ryan, A. (1988). Program evaluation within the paradigms: Mapping the territory. Science Communication, 10 (1), 25-47. Samier, E. (2000). Public administration mentorship: Conceptual and pragmatic considerations. Journal of Educational Administration, 38 (1), 83-101. Sandelowski, M. (2001). Real qualitative researchers do not count: The use of numbers in qualitative research. Research in Nursing and Health, 24 (3), 230-240. Sanderson, I. (2002). Evaluation, policy learning, and evidence-based policy making. Public Administration, 80 (1), 1-22. Schepers, S. (2015). Managing the politics of innovation and sustainability. Journal of Public Affairs, 15 (1), 88-97. Schuurman D. & Tõnurist, P. (2017). Innovation in the public sector: Exploring the characteristics and potential of living labs and innovation labs. Technology Innovation Management Review, 7 (1), 7 - 14. Selwyn, P. (1980). Smallness and islandess. World Development, 8 (12), 945-951. Seravalli, A. & Simeone, L. (2016). Performing hackathons as a way of positioning boundary organizations. Journal of Organizational Change Management, 29 (3), 326-343. Shields, J. & Evans, B. (1998). Shrinking the state: Globalization and public administration "reform". Halifax: Fernwood. Small, S., Cooney, S., & O'Connor, C. (2009). Evidence-informed program improvement: Using principles of effectiveness to enhance the quality and impact of family-based prevention programs. Family Relations, 58 (1), 1-13. Smits, R. & Kuhlmann, S. (2004). The rise of systemic instruments in innovation policy. International Journal of Foresight and Innovation Policy, 1 (1/2), 4-32. Sükürer, Z. (2015). Organizing of the hackathon phenomenon with regards to creation and development of entrepreneurial opportunities: An explorative case study on the interrelations between the temporalspatial elements of the hackathon environment and the social interactions of hackathon participants . Master's Dissertation, Vrije Universiteit Amsterdam and Universiteit van Amsterdam. Swiss State Secretariat for Economic Affairs. (n.d.). Evaluation guidelines. Retrieved from https://www.oecd.org/dac/evaluation/seco_guidelines.pdf Tate, M., Bongiovannib, I., Kowalkiewiczb, M. & Townson, P. (2018). Managing the "Fuzzy front end" of open digital service innovation in the public sector: A methodology. International Journal of Information Management, 39, 186-198.

PEI Policy Hackathon Program

Page 71 of 73

The `hackathon' as an instrument in policy design. (2018 Nov. 10). Canadian Government Executive. Retrieved from https://canadiangovernmentexecutive.ca/the-hackathon-as-an-instrument-in-policy-design/ Thorne, S., Kirkham, S. & O'Flynn-Magee, K. (2004). The analytic challenge in interpretive description. International Journal of Qualitative Methods, 3 (1), 1-11. Thornham, H. & Cruz, E. (2016). Hackathons, data and discourse: Convolutions of the data (logical). Big Data & Society, 1-11. Thorpe A. & Rhodes S. (2018). The public collaboration lab--Infrastructuring redundancy with communities-in-place. The Journal of Design, Economics, and Innovation , 4 (1), 60-74. Timmermans, S. & Tavory, I. (2012). Theory construction in qualitative research: From grounded theory to abductive analysis. Sociological Theory, 30 (3), 167-186. Tõnurist P., Kattel R., & Lember, V. (2015). Discovering innovation labs in the public sector. Working Papers in Technology Governance and Economic Dynamics No. 61, Technology Governance. Tõnurist P., Kattel R., & Lember, V. (2017). Innovation labs in the public sector: What they are and what they do? Public Management Review, 19 (10), 1455-1479. Vannini, P. & Taggart, J. (2012). Doing islandness: A non-representational approach to an island's sense of place. Cultural Geographies, 20 (2), 225-242. Wagenaar, H. (2011). Meaning in action: Interpretation and dialogue in policy analysis . New York: M.E. Sharpe. Wellstead, A. & Stedman, R. (2015). Mainstreaming and beyond: Policy capacity and climate change decision-making. Michigan Journal of Sustainability, 3 (Spring), 47-63. West, W. (2001). Beyond grounded theory: the use of a heuristic approach to qualitative research. Counselling and Psychotherapy Research, 1 (2), 126-131. Williamson, B. (2015). Governing methods: Policy innovation labs, design and data science in the digital governance of education. Journal of Educational Administration and History , 27 (3), 251-271. World Bank. (2003 Nov). Independent evaluation: Principles, guidelines and good practice . Development Grant Facility Technical Note. Retrieved from http://siteresources.worldbank.org/INTDGF/Resources/Evaluation&LearningNote.pdf World Bank and OECD. (2013). Policy learning. The Innovation Policy Platform. Retrieved from https://www.innovationpolicyplatform.org/content/policy-learning

PEI Policy Hackathon Program

Page 72 of 73

PEI Policy Hackathon Program

Page 73 of 73

