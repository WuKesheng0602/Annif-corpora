A DYNAMIC PREDICTIVE SEARCH ALGORITHM FOR FAST BLOCK-BASED MOTION ESTIMATION

By Behnaz Abdoli Bachelor of Applied Science in Electronics and Computer Engineering Yazd University Yazd, Iran, 2004

A thesis Presented to Ryerson University In partial fulfillment of the requirements for the degree of Master of Applied Science In the Program of Electrical and Computer Engineering

Toronto, Ontario, Canada, 2012 ©Behnaz Abdoli 2012

Author's Declaration
I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

* Signature

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

* Signature

ii

ABSTRACT
Title of Thesis: A DYNAMIC PREDICTIVE SEARCH ALGORITHM FOR FAST BLOCK-BASED MOTION ESTIMATION

Thesis Submitted By: Behnaz Abdoli Optimization Problems Research and Application Laboratory (OPR-AL) ELCE, Master of Applied Science, Ryerson University 2012

Thesis Directed By: Dr. Reza Sedaghat Electrical and Computer Engineering Department, Ryerson University Predictive fast Motion Estimation (ME) algorithms have been widely used in video CODECs due to their performance efficiency and low computational complexity. In this thesis, a new block-based fast motion estimation technique named Dynamic Predictive Search Algorithm (DPSA) is developed, which can be considered in predictive zonal search category. The proposed approach is based on the observation that temporally and spatially adjacent macroblocks are not just statically correlated, but also dynamic alterations in their motion content are highly coherent. DPSA introduces a new set of six candidate predicted motion vectors. For early termination criteria, DPSA modifies termination procedure of already existing EPZS algorithm. Performance of this newly proposed algorithm has been compared to four other state-of-the-art algorithms implemented on JVT, H.264 standard software platform. Experimental results have proven that DPSA accomplishes up to 38% compression ratio enhancement achieved by a process with more 14.75% less computational complexity and up to

iii

0.47 dB higher PSNR values over the EPZS. It also manages to have up to 13% speed up over EPZS algorithm. Because of its simplicity and low computational complexity DPSA is energy efficient for portable video processing in computation- or power-constrained applications and easy to be implemented on both FPGA- and Microcontroller-based embedded systems. Also, higher compression ratio makes DPSA more compatible with limited capacity storage media, and limited band-width transmission networks.

Acknowledgement
I am very thankful to my supervisor, Dr. Reza Sedaghat for his thoughtful guidance and OPRAL members for their endless support.

I would like to acknowledge and extend my heartfelt gratitude to my husband, Manuchehr Taghiloo who has made the completion of this research possible with his valuable comments, and supports throughout tough moments and difficulties. I am deeply indebted to my parents for their great guidance and sacrifice throughout my whole life. Further I highly owe them for being a constant source of love and motivation throughout my life. I am also thankful to my friends, who encouraged me to accomplish my goals.

v

TABLE OF CONTENTS
ABSTRACT.................................................................................................................................iiiii Acknowledgement .......................................................................................................................... v vi List of Tables ................................................................................................................................. ix List of Figures ................................................................................................................................. x CHAPTER1: INTRODUCTION .......................................................................................................................... 1 1.1 1.2 1.3 Background ...................................................................................................................... 1 Video coders..................................................................................................................... 4 Quality measurement........................................................................................................ 7

CHAPTER2: Block based Motion Compensation ................................................................................................ 9 2.1. 2.2. 2.3. 2.4. Motion compensation....................................................................................................... 9 Full search method ......................................................................................................... 11 Fast search algorithms .................................................................................................... 11 Predictive search algorithms .......................................................................................... 13

CHAPTER3: Fast Motion Estimation................................................................................................................. 14 3.1. Three-step search (TSS) algorithm ................................................................................ 14 New Three-Step Search (NTSS) ............................................................................. 14 Efficient Three-Step Search (ETSS) ....................................................................... 15

3.1.1. 3.1.2. 3.2.

Diamond search algorithm ............................................................................................. 16 Unrestricted Center-biased Diamond Search.......................................................... 16

3.2.1.

vi

3.2.2. 3.3. 3.4.

Improved Diamond Search ..................................................................................... 17

Cross search algorithm ................................................................................................... 18 Hexagon search pattern .................................................................................................. 19

CHAPTER4: Predictive search algorithms ......................................................................................................... 21 4.1. 4.2. 4.3. Motion Vector Field Adaptive Search Techniques ........................................................ 22 Un-Symmetrical Multi-Hexagon Search algorithms...................................................... 22 Enhanced Predictive Zonal Search (EPZS).................................................................... 23

CHAPTER5: Proposed Algorithm ...................................................................................................................... 26 5.1. 5.2. 5.3. 5.4. Prediction sub-set ........................................................................................................... 26 Early termination strategy .............................................................................................. 30 Algorithm block-diagram ............................................................................................... 30 Example.......................................................................................................................... 33

CHAPTER6: Experimental results...................................................................................................................... 35 6.1. 6.2. 6.3. PSNR.............................................................................................................................. 40 Compression ratio .......................................................................................................... 42 Computational complexity ............................................................................................. 44 Motion Estimation Process time ............................................................................. 44 Search points ........................................................................................................... 44

6.3.1. 6.3.2. 6.4. 6.5.

Variable Quantization parameter ................................................................................... 46 Comparison between DPSA1 and DPSA2..................................................................... 49

CHAPTER7: Conclusion .................................................................................................................................... 51

vii

7.1. 7.2.

Advantages..................................................................................................................... 51 Future works................................................................................................................... 52

PUBLICATIONS.......................................................................................................................... 54 BIBLIOGRAPHY ......................................................................................................................... 55 Nomenclature................................................................................................................................ 60

viii

List of Tables
TABLE 1: RESOLUTION FORMATS.......................................................................................... 3 TABLE 2: PERFORMANCE TABLE 3: PERFORMANCE TABLE 4: PERFORMANCE TABLE 5: PERFORMANCE TABLE 6: PERFORMANCE TABLE 7: PERFORMANCE TABLE 8: PERFORMANCE TABLE 9: PERFORMANCE TABLE 10: PERFORMANC TABLE 11: PERFORMANC TABLE 12: PERFORMANC T................................................... 37 .................................................. 37 ........................................ 37 ER & DA .................. 37

........................................... 38 ................................ 38 .................................. 38

RFALL ...................................... 38 .......................................... 39 ............................................. 39 ..................................................... 39

TABLE 13: PERFORMANCE IMPROVEMENT IN DPSA1 AND DPSA2 OVER EPZS ....... 53

ix

List of Figures
FIGURE 1: VARIABLE BLOCK SIZES ...................................................................................... 4 FIGURE 2: RASTER SCAN ORDER ........................................................................................... 6 FIGURE 3: DIGITAL VIDEO CODEC BLOCK-DIAGRAM...................................................... 7 FIGURE 4: "FLOWER" AND "MOBILE"; TWO EXAMPLES OF COLOURFUL SEQUENCES ................................................................................................................................. 8 FIGURE 5: 17 SEARCH POINTS IN NTSS ............................................................................... 15 FIGURE 6: ETSS SEARCH POINT ............................................................................................ 16 FIGURE 7: SIMPLE DIAMOND SEARCH PATH .................................................................... 17 FIGURE 8: A) IMPROVED LARGE DIAMOND SEARCH PATTERN ................................. 18 FIGURE 9: HEXBS INITIAL SEARCH POINT [14] ................................................................. 20 FIGURE 10: INNER SEARCH POINTS IN HEXBS [14] .......................................................... 20 FIGURE 11: CORRELATED MBS IN CURRENT AND REFERENCE FRAMES.................. 22 FIGURE 12: ACCELERATION PREDICTING ......................................................................... 24 FIGURE 13: SPATIAL AND TEMPORAL MBS ....................................................................... 26 FIGURE 14: A) REFERENCE FRAME B) CURRENT FRAME............................................. 28 FIGURE 15: DPSA BLOCK-DIAGRAM.................................................................................... 32 FIGURE 16: ONE EXAMPLE FOR DPSA1 ALGORITHM ...................................................... 33 FIGURE 17: DPSA1 ALGORITHM SEARCH STEPS FOR EXAMPLE1................................ 34 FIGURE 18: YUV VIDEO SEQUENCES; QCIF FORMAT (176X144) ................................... 35 FIGURE 19: YUV VIDEO SEQUENCES; CIF FORMAT (352X288) ...................................... 36 FIGURE 20: FRAME BY FRAME PSNR COMPARISON FOR EPZS AND DPSA1 ON ................................................................................................................................. 40

x

FIGURE 21: FRAME BY FRAME PSNR COMPARISON FOR EPZS AND DPSA1 ON ....................................................................................................... 41 FIGURE 22: FRAME BY FRAME Y-PSNR COMPARISON FOR FIGURE 23: FRAME BY FRAME Y-PSNR COMPARISON FOR FIGURE 24: FRAME BY FRAME Y-PSNR COMPARISON FOR ....................... 41 .......... 42

.............................. 42

FIGURE 25: FRAME BY FRAME DATA BITS/FRAME COMPARISON FOR EPZS AND ................................................................................... 43 FIGURE 26: FRAME BY FRAME DATA BITS/FRAME COMPARISON FOR EPZS AND ............................................................................................................. 43 FIGURE 27: FRAME BY FRAME NUMBER OF SEAR N FOR ............................................................... 45 FIGURE 28: FRAME BY FRAME SEARCH POINT COMPARISON FOR ...................................................................................................................................................... 45 FIGURE 29: FRAME BY FRAME SEARCH POINT COMPARISON FOR ............... 46

FIGURE 30: FRAME BY FRAME NUMBER OF SEARCH POINT COMPARISON ON ................................................................................................................................. 46 FIGURE 31: NUMBER OF SEARCH POINTS COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMETER ................ 47 FIGURE 32: PSNR COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMET ........................................................... 47 FIGURE 33: BIT-RATE COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMET ........................................................... 48 FIGURE 34: NUMBER OF SEARCH POINTS COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMET ............... 48 FIGURE 35: PSNR COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMET ......................................................... 48 FIGURE 36: BIT-RATE COMPARISON FOR EPZS AND DPSA1WITH VARIOUS QUANTIZATION PARAMET ......................................................... 49

xi

CHAPTER1 INTRODUCTION
1.1 Background
digital video is reduced for transmission or storage, and decompression part, or Decoder that reconstructs the video sequence for display. Therefore, compression is an essential component of multimedia services, and good compression and decompression processes is key for providing better image quality products. Moreover, the need for better compression tools has led to developing further standards for video [1] [2].

Digital video data flow from a source to a destination consists of two specific parts: compression

This chapter is a brief review on main characteristics of digital images and video signals and examines concepts such as sampling formats and quality metrics, as well as introducing structure of video coding systems. The first subject is sampling in colour images. To represent a colour images, at least three numbers per pixel position are required for brightness, or luminance (Luma), and to indicate the colour, or chrominance (Chroma). Two methods are well-known for this purpose: RGB colour space [3] and YUV. [4] [5] In the RGB colour space, each pixel is formed with three numbers that describe the relative proportions of three primary color components Red, Green and Blue. In this model the three colour contents are stored with the same resolution. When one of colour component has the strongest intensity, the pixel is visualized with that primary colour, and when two or more components have almost the same intensity, then the colour is a shade of a secondary colour (such as purple, yellow cyan) or it can be white or black. The other colour model is YCbCr colour space, also known as YUV. This model is based on a fact that human vision is less sensitive to colour than to luminance. Hence, it is more efficient to

1

represent a colour image by luminance (Y) component, with higher resolution, and Cb; Cr; and Cg that present the colour intensity or Chrominance components, with lower resolution. This decreases size of data required to be stored or transmitted with no obvious difference on visual quality. Luma component, Y, can be calculated as an average of R, G and B with weighting factors of Kr; Kg; and Kb: Y= KrR + KgG + KbB The chrominance is defined as the difference between R, G or B proportions and the Luma: Cb= B-Y; Cr= R-Y; Cg= G-Y

However, since (Cb + Cr + Cg) is a constant, only two Chroma components need to be stored or transmitted. The third component can always be calculated from the other two. So, in the YUV colour space, only the Luma (Y) and blue and red Chroma (Cb, Cr), also known as U and V are transmitted. Representing Chroma with a lower resolution than Luma in this way is a simple and yet, effective model of image compression. Three patterns for sampling resolution ratio for YUV format are supported by MPEG-4 Visual and H.264/AVC standards: 4:4:4 sampling in which the three components (Y, U and V) have the same number of samples for each component at every pixel position. Thus for every four luminance samples there are four Cb and four Cr samples. 4:4:4 sampling keeps the full fidelity of the chrominance components. In 4:2:2 sampling, the chrominance components vertical resolution is the same as the Luma but their horizontal resolution is half of Luma. In other words, for every four luminance samples in the horizontal direction there are two Cb and two Cr samples. 4:2:2 video is useful for highquality colour reproduction. The popular sampling format is 4:2:0, in which Cb and Cr each have half the horizontal and vertical resolution of Y. 4:2:0 sampling is suitable for consumer applications such as video conferencing, digital television and digital versatile disk (DVD) storage. Because each colour difference component contains one quarter of the number of samples in the Y component, 4:2:0 YUV video requires exactly half as many samples as 4:4:4 (or RGB) video.

2

For example, in a 720 x 576 pixels image resolution: Y component is represented with eight bits for each sample in all three ratios. In 4:4:4 Cb, Cr components are eight bits for each sample, and the total number of bits is: 720 x 576 x 8 x 3 = 9953280 bits per frame In 4:2:2 Cb, Cr components resolution is 360 x 288 samples, each eight bits and the total number of bits: (720 x 576 x 8) + (360 x 288 x 8 x 2) = 4976640 bits per frame In 4:2:0 versions require half as many bits as the 4:4:4 versions and the total number of bits is: 4976640 bits per frame As well, there are different intermediate formats to standardize the horizontal and vertical resolutions in pixels to capture YUV video sequences prior to compression and transmission, such as SQCIF, QCIF, CIF, 4CIF. The CIF (Common Intermediate Format), which is the basis for other formats, means 352 x 288 Y samples per frame. For example in 4:2:0 resolution there are 352 x 288 x 8 = 811008 bits for Y samples and half of this much (405504 bits) for Chroma samples. Some of the most popular formats are listed in table 1. Table 1: Resolution formats
Format Y resolution (Hrzntl x Vrtcl) bits per frame for 4:2:0 resolution

4CIF CIF QCIF SCIF

704 x 576 352 x 288 176 x 144 128 x 96

4866048 1216512 304128 147456

The choice of frame resolution depends on the application and available storage or transmission capacity. For example, 4CIF is appropriate for standard-definition television and DVD-video; CIF and QCIF are popular for videoconferencing applications; QCIF or SQCIF are widely used in mobile multimedia applications where the display resolution and the bitrate are limited.
3

Most video standards, particularly the most recent ones: MPEG-4 Visual and H.264/AVC, follow the so-called Block-based video coding [6] approach, in which each coded frame is split into fixed or variable size non-overlapping blocks of associated Luma and Chroma samples, known as Macro-blocks (MB). Usually, each MB covers a rectangular area of 16 x 16 samples of the Luma component and 8 x 8 samples of each of the two Chroma components. Macro-blocks are the basic building units of the standard for which the decoding process is specified, and all Luma and Chroma samples of a MB are encoded or decoded at a time. However, in H.264/AVC standard, the luminance component of a MB also, could be partitioned into 16 x 16, 16 x 8, 8 x 16, 8 x 8, 8 x 4, 4 x 8 or 4 x 4 blocks in a similar way as depicted in Figure 1.

Figure 1: Variable block sizes

1.2

Video coders

As mentioned earlier, a video coding system consists of a pair of encoder and decoder components and the whole system is known as a CODEC. The encoder is in charge of video compression, which is the process of compacting digital video sequences into smaller number of bits. The decoder, on the other hand, converts the compressed form back into an approximation version of the original video data. Video compression enables more efficient use of transmission and storage resources. Even with constant advances in storage and transmission capacity, compression is still likely to be an essential component of multimedia services for many years to come. An information-carrying signal may be compressed by removing redundancy from the signal. Most video compression

4

algorithms operate by removing redundancy in the temporal, spatial and/or frequency domains to achieve compression. In the temporal domain, there is usually a high correlation between following frames of video that were captured at around the same time. Especially in high sampling rates (the frame rate) temporally adjacent frames are often highly correlated. For example, when the sequence is captured from a camera at 30 frames per second, there is little change between the two frames in the short interval of 1/ 30 of a second. There is clearly significant temporal redundancy, and most of the image remains unchanged between successive frames. In the spatial domain, there is usually a high correlation between pixels that are close to each other, inside a frame. Because neighbouring samples most possibly are part of the same object and have the same or very close colour intensity and luminance, hence their values are often very similar. Frequency domain compression is based on the fact that human eyes and brain are more sensitive to lower frequencies [4]. In a video frame, if we low-pass filter the background region, by removing some of the higher-frequency content, the image becomes smoother and less information is required to store or transmit. However, the image is still recognisable for human eye, with no visible quality distortion. By removing spatial, frequency and/or temporal redundancies it is possible to compress the data significantly at the expense of an acceptable range of distortion. A video encoder consists of three main functional units: a temporal model, a spatial model and an entropy encoder. The H.264 and MPEG-4 Visual standards assume a CODEC model that uses block-based motion compensation, transformation, quantisation and entropy coding. Each of these components processes one MB at a time. There are some specific orders to code the MBs. One of the most popular ones is called raster scan. If the frame is processed in raster order, then coding starts from the most top-left pixel in the frame and continues to the right first. When one whole line is finished, it jumps to the most left pixel in the next line. Raster scan order is demonstrated in figure 2.

5

Figure 2: Raster Scan Order The first functional unit in encoder is temporal model. The input to the temporal model is an uncompressed video sequence. The temporal model attempts to reduce temporal redundancy by exploiting the similarities between neighbouring video frames, usually by constructing a prediction of the current video frame. In MPEG-4 Visual and H.264, the prediction is formed from one or more previous or future frames and is improved by compensating for differences between the frames (motion compensated prediction). The output of the temporal model is a residual frame, created by subtracting the prediction from the actual current frame, and a set of motion vectors describing how the motion was compensated. The residual frame forms the input to the spatial model which makes use of similarities between neighbouring samples in the residual frame to reduce spatial redundancy. In MPEG -4 Visual and H.264 this is achieved by applying a transform to the residual samples and quantizing the results. The transform converts the samples into another domain in which they are represented by transform coefficients. The coefficients are quantised to remove insignificant values, leaving a small number of significant coefficients that provide a more compact representation of the residual frame. The output of the spatial model is a set of quantized transform coefficients. Temporal model parameters are usually motion vectors and spatial model parameters are coefficients. These parameters are compressed by the entropy encoder to remove statistical redundancy in the data such as representing common vectors and coefficients by short binary codes. A compressed sequence consists of coded motion vector parameters; coded residual coef ficients; and header information form the bit stream exiting from encoder. The video decoder reconstructs a video frame from the compressed bit stream. After decoding the spatial model, coefficients and motion vectors are decoded by an entropy decoder to
6

reconstruct an estimated version of the residual frame. Then the decoder uses the motion vector parameters and one or more reference frames, to create a prediction of the current frame. Eventually, the frame itself is reconstructed by adding this prediction to the residual frame.

Figure 3: Digital video CODEC block-diagram

1.3

Quality measurement

In order to evaluate and compare video processing systems, determining the quality of the encoded video images is required. The most popular scale to measure the so-called objective quality of compressed video sequences is a logarithmic parameter, known as Peak Signal to Noise Ratio (PSNR) which depends on the mean squared error (MSE) between an original and a compressed video frame, as in equation (1-1). PSNRdB= 10 Log10 [(2n-1)2/MSE] n:# of bits/ image sample. (1-1)

PSNR is a very popular, and widely used to evaluate the fidelity between compressed and decompressed video images, because it can be calculated easily and quickly. To have a general perspective, an image with PSNR of 30.6 dB reflects a good quality, while that same image with PSNR of 28.3 dB is considered the poorer image quality.

7

In a colour image, PSNR is attributed to three different values, for Y; U and V samples. As explained, Chroma components can be represented with a lower resolution than Y, to reduce the amount of data required to be stored or transmitted with no obvious difference on visual quality. That is why in many studies Y samples illustrate the quality of encoded images. However, in some cases where the color content in a frame is very diverse and it changes dramatically block to block (figure 4). In these cases, it is important to evaluate U and V samples to determine the quality of encoded sequence.

Figure 4: "Flower" and "Mobile"; two examples of colourful sequences Another factor that describes the performance of a CODEC is compression ratio. For a fixed resolution and on a single image, the higher the compression ratio is in an encoder the lower number of bits is required to be stored or transmitted and lower band-width network or smaller media storage is needed.

8

CHAPTER2 Block based Motion Compensation
2.1. Motion compensation

The first compression module in encoders is Motion Compensation (MC) which exploits temporal redundancy between frames and describes a picture in terms of the transformation of a reference picture to the current picture. MC is based on the fact that usually, for most of the frames of a sequence, the only difference between one frame and the next one is the result of either the camera moving or an object in the frame moving. With sampling rates like 30 frames per second, the motion of objects or camera in just 1/30 of a second is clearly very small. This means much of the information that represents one frame will be the same as the information used in the next frame. In most recent visual coding standards including MPEG-4 Visual, and H.264/AVC, the macroblock (MB), corresponding to a MxN-pixel region of a frame, is the basic unit for motion compensated. For instance, in a video material in 4:2:0 format, a macro block is organised as a 16 x 16-pixel region representing 256 luminance samples, 64 blue chrominance samples and 64 red chrominance samples, giving a total of six 8 x 8 blocks. An MPEG-4 Visual or H.264 CODEC processes each MB at a time and provides a Motion Vector (MV) associated to that MB. Finding the MV of a MB involves Motion Estimation (ME) process, in which, a macro block of MxN-sample region in a reference frame is found that closely matches the current macro block. The reference frame is a previously encoded frame from the sequence that can be before or after the current frame in display order. Inside an area centred on that MB position in a previously encoded frame, called reference frame (search window) is searched, to find a MxN -pel region that closely matches the current MB. This is carried out by comparing the current MB in the current frame with the possible MxN-samples regions in the search window to find the block that

9

minimises a matching criterion, such as most widely-used Sum of Absolute Differences (SAD) value. Then MC process continues with subtracting the selected the best matching MB in the reference frame from current MB to produce a residual MB of Luma and Chroma samples that will be encoded and transmitted together with a Motion Vector (MV), describing the position of the best

SAD is the most popular distortion criterion to measure the residual energy. For an MxN block, it can be described as equation (2-1):

SAD (d) =

|C(x, y)

R(x + dx,y + dy)|

(2-1)

Where d = (dx, dy) is the MV, C(x, y) and R(x, y) are intensity of given pixel in current and reference MB, respectively. The region with minimum SAD indicates the offset that produces a minimal residual energy and this is likely to produce the most matching MB to the current MB. The decoder uses the received motion vector to re-create the predictor region and decodes the residual block, adds it to the predictor and reconstructs a version of the original block. Block-based motion compensation is popular for a number of reasons. It is relatively straightforward and computationally tractable, it fits well with rectangular video frames and with block-based image transforms (e.g. the Discrete Cosine Transform) and it provides a reasonably effective temporal model for many video sequences. However, there are a some disadvantages: [4] for example real objects rarely have neat edges that match rectangular boundaries; objects often have movements that are fractional number of pixel positions between frames and many types of object motion are hard to compensate for using block-based methods, such as deformable objects, rotation and warping, and complex motions. In spite of these drawbacks, block-based motion compensation is the base of the temporal model used by all current video coding standards.

10

Motion estimation is the most computationally intensive and time consuming module of encoders. Many studies are conducted to find an algorithm to reduce the computational complexity of ME process. These algorithms can be generally categorized in three groups: Full search method; fast search algorithms; and predictive search algorithms.

2.2.

Full search method

Full Search algorithm [7] is the conventional motion estimation technique that calculates SAD value at all (2w+1)2 possible MBs in the search window with size of w pixels (± w samples around position (0,0), the position of the current MB) to find the best matching block. This method is guaranteed to find the minimum SAD in the search window but it is computationally intensive. The conventional full search process starts with searching the most top-left of the window (position [ w, w]) and the search proceeds in raster order until all positions have been

evaluated. In a typical video sequence, most motion vectors are found around (0,0). That is why some researchers recommend simplifying the computation of the full search algorithm by starting the search from (0,0) position, and proceeding in a spiral pattern around this location. They define an early termination condition such as a SAD value threshold. If the calculated SAD for zero MV is less than that threshold, the computation is stopped from further searching. These new Full search approaches are still popular due to their accuracy, but even with the use of early termination, Full Search motion estimation is very computationally intensive and can be undesirable and very expensive for some applications especially where real time encoding is required.

2.3.

Fast search algorithms

Fast motion estimation algorithms, are introduced in effort to reduce the computational complexity of intensive full search method. These algorithms operate by calculating the SAD criterion at a subset of locations, with a specific pattern, within the search window, instead of all over the search window. In computation- or power-limited applications, fast ME algorithms are preferable.

11

Many fast ME patterns have been proposed over the last decades. The most popular ones include: Three Step Search (TSS) [8], New Three Step Search (NTSS) [9], Cross Search [10][11], Diamond Search [12][13], Hexagon search [14] and the hybrid combinations of them. In the next chapter some of these algorithms are described to illustrate how fast ME techniques work. Each fast ME technique can be considered as a trade-off between three main criteria: encoded image quality; compressed bit-rate; and computational complexity. As mentioned in chapter 1, image quality is measured with PSNR parameter. Computational cost in a fast ME technique is measured by the factor of the required number of searching points to find the MV of each MB, whilst the bit-rate of encoded streams represents compression efficiency of the encoder. Another parameter to compare different algorithms is ME process time. Clearly, full search method has extremely long process time, and all fast search algorithms are significantly effective in terms of speed up over full search. Ideally, in a constant sampling frame rate, all ME algorithms are meant to achieve as few bit-rate as possible and the highest possible quality (PSNR), with as low number of search points as possible. Most fast ME patterns achieve lower number of search points with the price of lower quality and compression ratio. In fact, in case of constant frame rate systems, PSNR and data bitrate are anti-correlated. The more accurate MV estimation leads to further fidelity between encoded and original videos. As a result, the energy content of residual frames is much lower, and fewer data bits are required to be transmitted or stored, which means lower bit-rate. Also, it results in higher quality images, measured in high PSNR values for Luma and Chroma samples. Hence, both parameters represent the accuracy of ME process. Fast search methods just search a few positions inside the search window and assume the minimal SAD verdict is close enough to the ultimate MV. Therefore there is a chance of getting trapped in a local minima, and having a less optimal answer. Hence, these plain fast search algorithms could not compete with the high accuracy of full search.

12

2.4.

Predictive search algorithms

Predictive search algorithms are a new category of fast ME techniques that introduce some solutions for lowering the computational intensity of ME, with a performance much closer to conventional full search method. These solutions can be classified into two steps: one is predicting the most likely initial sub-set of search points based on the temporal and spatial correlation between MV of current MB and previously coded MBs; and the second step is defining some early termination conditions to avoid being trapped in local minima and enhance the speed up. In these approaches, a set of correlated MB to the current MB is introduced. All these blocks must be already encoded at the time of coding current block. In most existing predictive algorithms, this set includes some adjacent MBs in current frame and, some blocks in reference frame, or other close frames in time order, which are already encoded. MV of these blocks is used to predict a set of initial search points. Then, SAD parameter for all initial points are calculated and the verdict with minimum SAD is set as the origin of a local search pattern, which could be a diamond, square or hexagon shaped pattern. Most recent techniques define an early stop criterion, and in each step, that criterion is checked. If the condition is met the processor stops further searching and returns a found vector as the final MV of current MB. This termination condition can be a SAD value threshold. As soon as a verdict meets the defined threshold, further searching is terminated and location of that verdict will define the ultimate MV. Many proposed predictive algorithms first examine (0,0) position, due to the high possibility of zero MV [15]. This is why they .

Some examples of existing predictive zonal search approaches are described in chapter 4, to clarify how this type of coding techniques functions. In chapter 5, a new predictive algorithm will be proposed, based on dynamic and static correlated macro-blocks, which improves performance of other methods, significantly.

13

CHAPTER3 Fast Motion Estimation
In this chapter four main fast motion estimation patterns, including three-step search; cross search; diamond search; and hexagon search patterns are explained.

3.1.

Three-step search (TSS) algorithm

Three-step search was first introduced around 1993, and became one of the most popular algorithms for MC, due to its simplicity and efficiency. Since then many studies were conducted to improve this algorithm including a new three-step search; and enhanced three-step search that were based on the original TSS algorithm. Two of these proposed ideas are described here.

3.1.1. New Three-Step Search (NTSS)
Initial search points in New Three-step Search (NTSS) algorithm [9] for a search window size of 7 is shown in figure 5. In the first step, 17 points including the center; 8 points with 1 pixel distance from the center; and 8 points on the larger 9x9 grid are checked. If the minimum SAD happens to be found at the center of the search window, the search will stop. If the minimum SAD point is one of the eight points on the 3x3 grid, again another 3x3 grid pattern is formed around that center, to check three or five extra points and the minimum SAD found in this step is final MV. Otherwise the large 9x9 search window size is reduced by half and the center moves to the minimum SAD point in Step1, the algorithm is repeated until the search distance cannot be subdivided further.

14

Figure 5: 17 search points in NTSS

3.1.2. Efficient Three-Step Search (ETSS)
In order to exploit the center-biased characteristics of motion vector distribution in real-world video sequences, ETSS utilizes a small diamond search pattern in the search window center [8]. Figure 6 shows the search pattern used in the first step of ETSS for a search window size of 7. Thus, in the first step, a total of 13 points will be searched instead of 17 points in N3SS. If the winning point is found to be on the center of search window, it will stop further searching. If the minimum SAD point is one of the eight points on the large 9x9 grid, the following process will be the same as in NTSS. If the minimum is one of the four points on the small diamond, the small diamond center is set to the origin of another small diamond pattern, and another three points will be examined. The center of the small diamond is moved to the minimum SAD point each time until the minimum is found in the center of small diamond. Two main differences between ETSS and NTSS include: 1- A small diamond pattern is used instead of a square pattern in the central area 2- Unrestricted search step for the small diamond rather than a single movement for the small square.

15

Figure 6: ETSS search point

3.2.

Diamond search algorithm 3.2.1. Unrestricted Center-biased Diamond Search

A basic diamond search pattern is named UCBDS [17]. This fast search pattern can be summarized in following steps: Step1: The original diamond pattern is formed at the center of the search window, that we call it (c,c). The SAD is evaluated for each of the nine candidate search points. If the minimum SAD point is found to be at the center, go to step5; otherwise, go to step2. Step2: If the minimum SAD point in the previous search step is located at one of the four vertices (c-2,c); (c+2,c) ; (c,c-2) ; (c,c+2), then go to step3. Else, if it is located at one of the four possible faces of the previous diamond (c-1,c-1); (c+1,c+1) ; (c-1,c+1) ; (c+1,c-1), then go to step4. Step3: Another diamond pattern is formed around the minimum SAD point (updating the center (c,c)). Five new candidate search points are evaluated. Step4: Another diamond pattern is formed around the minimum SAD point (updating the center (c,c)). Three new candidate search points are checked. Note that any candidate point that extends
16

beyond the search window is ignored. If the minimum SAD is found at (c,c), then go to step5 otherwise, go to step2 to continue the next search step. Step5: The shrunk diamond pattern is used with the same center (c,c). Now, the final four internal points of the previous diamond are searched. Similarly, any internal candidate point that extends beyond the search window is also ignored. The candidate point that gives the minimum SAD is chosen as the final motion vector (mx, my).

Figure 7: Simple diamond search path

3.2.2. Improved Diamond Search
[13][18] From the analysis of different sequences, it has been found that nearly 80% MVs are horizontal and vertical [16] ment

tilting, etc. It can therefore be concluded that most motion vectors contained in real-world
17

sequences are horizontal and vertical. Thus, authors in [13] suggest eliminating the points located at the face of the large diamond in the DS to speed up the computation. They call this new search pattern Improved LDSP (ILDSP), as shown in figure 8.

Figure 8: a) Improved Large Diamond Search Pattern b) Small Square Search Pattern Besides, to ensure the global optimum point being reached, the Improved Diamond Search (IDS) algorithm expand the original small diamond from five check points to nine and change its name from SDSP (small diamond search pattern) to procedure can be summarized as follows: Step1: The initial ILDSP is centered at the origin of the search window, and distortion criterion for five points including the origin is calculated. If the minimum SAD is found at the center position, go to Step 3; otherwise, go to Step 2. Step2: The origin is repositioned to the minimum SAD point found in the previous search step, to form a new ILDSP. As the prior step, SAD values for five points are calculated. If the new minimum SAD point is obtained at the center position, go to Step 3; otherwise, recursively repeat this step. Step3: Switch the search pattern from ILDSP to SSSP. The minimum SAD point found in this step is the final solution of the motion vector which points to the best matching block. mall Square Search Pattern (SSSP). IDS

3.3.

Cross search algorithm

One recent example of cross patterns [18][19] for motion estimation is Zero-MV biased crossdiamond search algorithm (ZCDS) [15]. Here, an adaptive dynamic threshold (Thrs.) is defined

18

based on the block motion content via a linear model. In this model the ratio between SAD of zero MV macro block and average minimum SAD is used. The ZCDS process consists of the following steps: Step1 (Thrs computation): If the SAD of zero MV block is less than the threshold Thrs, then the search stops, otherwise, go to Step2 with a LCSP. Step 2 (Large Cross Shape Pattern LCSP): Examine nine search points of the LCSP located at the center of search window. If the SAD of any candidate block is less than Thrs, the search stops; otherwise go to Step (3). Step 3 (Half Diamond Searching): Two additional search points closest to the current minimum SAD in the central LCSP are checked. If the SAD value is less than Thrs, the search stops immediately. If the minimum SAD found in previous step located at the middle wing of the LCSP and the new minimum SAD found in this step still coincides with this point, go to Step (4). Step 4 (Diamond Searching Pattern DSP): A DSP is formed by repositioning the center of DSP to the minimum SAD found in previous step. The DSP points are checked. If the SAD of any candidate is less than Thrs, the search stops immediately; If the new minimum SAD point is at the center of the newly formed DSP, then go to Step (5) for converging to the final solution; otherwise, this step is repeated. Step 5 (Ending SCSP Converging step): With the minimum SAD point in the previous step as

the center, a SCSP is formed. The SCSP points are checked one-by-one. If the SAD of any candidate is less than Thrs, the search stops immediately; otherwise, identify the new minimum SAD point for the SCSP, which is the final motion vector.

3.4.

Hexagon search pattern

[14][19]In the original hexagonal search (HEXBS) algorithm, two search patterns are involved. First the large hexagon search pattern in figure 9, consisting of six endpoints is formed to find the region in which the optimal motion vector is expected to be in. This coarse search continues based on a gradient scheme until the center point of the hexagon has the minimum SAD value.

19

After a coarse hexagonal search the some fine-resolution search looks into the small area inside the large hexagon, as shown in figure 9.

Figure 9: HEXBS initial search point [14] This method considers grouping the search points in the six sides of the hexagon, resulting in six pairs of points, as shown in figure 10. For each group, a group distortion is defined by summing the distortions of all the points within the group. The area near to the group with the minimum group distortion is considered as the final solution for the search. Two or three search points are examined in the focused inner search, depending on the position of the group.

Figure 10: Inner search points in HEXBS [14] Most of these fast motion estimation algorithms accomplish a speed up improvement over full search technique. However, this is mostly at the cost of PSNR and compression ratio.

20

CHAPTER4 Predictive search algorithms
To alleviate the computation burden in a video encoder while keeping the quality and compression ratio, Predictive Zonal search algorithms are proposed some solutions for lowering the computational intensity of ME, with a quality and compression performance closer, to conventional full search method. In these approaches, the idea is basically to predict the most likely initial sub-set of search points based on the temporal and spatial correlation between MV of current MB and previously coded MBs. Afterwards, they measure the SAD parameter, for all initial points and set the verdict with minimum SAD as the origin of a local checking pattern, which could be diamond, square or hexagon shape pattern. Also they usually define some early termination conditions to avoid being trapped in local minima and enhance the speed up. In this chapter some examples of predictive search algorithms are listed. One very common initial point is median MV of adjacent blocks in the current frame which has been used in many predictive algorithms [20]. In H.264/AVC standard, after finishing the ME process the encoder needs to calculate this spatial median MV for other modules any ways, hence using that in initial step of ME does not add any extra calculation to the process. Also, because this MB is located at the same location as the current MB, it is highly possible that their MV is very similar. Therefore, many proposed approaches suggest having it in the list of predicted MVs. Also, most of predictive techniques take advantage of the fact that zero motion vector probability is considerably high and put that in their prediction set. [15] In gentle videos, on average, more than 70% of MVs can be located inside a 3x3 window around zero MV. Even in the case of high motion content videos, the possibility of zero motion is more than 25%. Thus, the second predicted initial MV is MV (0, 0).

21

4.1.

Motion Vector Field Adaptive Search Techniques

The first predictive algorithm named Motion Vector Field Adaptive Search Technique (MVFAST) [21] suggests using MV of left; top; and top-right adjacent blocks in current frame, and zero motion vector (0,0) as initial predictors, combined with a two stage diamond search pattern and a fixed early-stopping criterion after examining the (0,0) predictor. Then, another algorithm known as Predictive Motion Vector Field Adaptive Search Technique (PMVFAST) [22][23][24] introduced two initial predicted MVs, including: the median MV of three spatially adjacent blocks in current frame, and the MV of the collocated block in the reference frame. This algorithm used an adaptive early-stopping criterion, which were more reliable, sequence independent, and calculated based on correlations between adjacent blocks.

Figure 11: Correlated MBs in current and reference frames The next proposed algorithm was Advanced Predictive Diamond Zonal Search (APDZS)[25][26], which modified search pattern of PMVFAST algorithm to multiple stage diamonds, and achieved higher PSNR than PMVFAST at an insignificant cost in speed up, but still better than MVFAST.

4.2.

Un-Symmetrical Multi-Hexagon Search algorithms

Another example of predictive algorithms, Un-Symmetrical Multi-Hexagon Search (UMHEX) [27] has defined 13 initial search points in 2 sets. Five predictors in set1 including: the zero MV (0,0); median MV of the spatially adjacent blocks on the left, top, and top-right of the current block; MV of co-located block in reference frame; neighbouring reference frame prediction ,

frame; and upper layer prediction, which is a larger size block. For example, the 16 x 16 is used

22

as upper layer predictor for 16x8 and 8x16 blocks. Set 2 consists of four MVs around the spatial median prediction and four MVs around the zero MV (0, 0). After testing all these predictors, the region with min cost becomes the center of an Unsymmetrical cross search with a horizontal search window size of W and vertical search range of W/2. Again, the motion vector with the minimum cost is chosen as the origin of a full search in a 2X2 area. There are a total of 25 search points in this step. In the next step, first a 16-points hexagon search pattern is carried out as the basic search pattern followed by an uneven-multi-hexagon-grid, performed by extending the 16-points hexagon pattern with different scale factors and starting the search process from the inner hexagon to the outer one. The final step is an Extended-hexagon-based search including a hexagon and a diamond search pattern. This algorithm also proposed floating point calculation-based early termination criterion in each step of the searching process. [28] Because of quite large number of predictors; complex searching steps; and a computationally intensive early-stop criterion this algorithm, as it will be shown in experimental result section, is not highly successful in speed up. Authors in [29] proposed Simplified-Un-Symmetrical Multi-Hexagon Search (SUMHEX)

algorithm, which only uses spatial median and upper layer predictors of UMHEX to reduce the memory space of MV prediction module. Combining with an adaptive search pattern for various levels of motion contents in different images, SUMHEX was able to improve UMHEX speed up, by 57%.

4.3.

Enhanced Predictive Zonal Search (EPZS)

Enhanced Predictive Zonal Search (EPZS) [30][31], is the most famous predictive method and currently implemented in JVT, H.264/AVC standard software platform. EPZS considered initial set points introduced by previously developed algorithms, and added 5 more predictions to them. Four of new predictors come from MV of four adjacent blocks in up, right, down and left side of co-located MB in reference frame. And the other one is accelerator MV (figure 12), which is the differentially increased or decreased MV of co-located MB in reference frame and one frame

23

before that. The idea behind it is that a block MV may be following the acceleration instead of a constant velocity.

Figure 12: Acceleration predicting

efficient than all previous algorithms and could achieve a significant improvement in computational complexity. For early-stop criterion, EPZS essentially defines some constant threshold range for each valid block size in H.264 standard. In particular for 16x16-samples blocks in H.264 reference model software this range included Min-threshold of zero, Medthreshold of 8192 and Max-threshold of 48192. [32]In the first step of EPZS procedure, SAD of median predictor is calculated and compared with an initial Stop-criterion which is equal to the defined Med-threshold. If it is smaller than this threshold, it stops further searching and takes median predictor as the final MV. Otherwise, at this point a new Stop-Criterion is calculated based on equations (4-1) to (4-4). In the next step, SAD values of other spatial and temporal predictors are calculated. Then the minimum SAD predictor is compared with the new Stop-Criterion. If it is smaller, further searching is terminated and that minimal SAD predictor is taken as final MV, otherwise it starts a local diamond search around MB with minimum SAD, and it continues till the final MV is found. Min-SAD = Min (SAD (Acur), SAD (Bcur), SAD (Ccur)) Step1-Criterion = Min (Min-SAD, Max-threshold) Step2-Criterion= Max (Step2-Criterion, Med-threshold) Stop-Criterion = [9*(Step2-Criterion) + 2*Med-threshold]/8
24

(4-1) (4-2) (4-3) (4-4)

The author in [33] suggests that it is better to increase the early-stop criterion of EPZS, to reduce the searching predictor processing without loss of quality. This method modifies EPZS earlytermination process by introducing a motion factor, based on the distortions difference of the three adjacent blocks in current frame, and adding this adaptive motion factor to the criterion. Then it replaces equation (4-3) by the following formula, (4-5). Step2-Criterion= Step1-Criterion + motion_factor*((Max_SAD) (Min_SAD)) (4-5)

Where, Max_SAD and Min_SAD are respectively the maximum and the minimum values of the three distortions of adjacent blocks. The prediction set of all these Zonal algorithms seems to be the most principal feature and key to their performance. In the next section a Dynamic Predictive Search algorithm (DPSA) is proposed, which could be considered as an improvement of EPZS. The aim of this new approach is to introduce the most effective spatial and temporal correlated MBs for a simple but optimum initial sub-set that leads to higher performance (PSNR), lower computational complexity (search points), and lower bit rates compared with EPZS.

25

CHAPTER5 Proposed Algorithm
In this chapter we propose a Dynamic Predictive Search Algorithm (DPSA), which introduces the most effective spatially and temporally correlated MBs for a simple but optimum initial subset, combining with an early termination criterion that leads to higher quality (PSNR), lower computational complexity (search points), higher speed up, and lower bit rates compared to other existing predictive algorithms.

5.1.

Prediction sub-set

The most prominent feature that results in high performance in zonal search algorithms is their set of predictors associated to spatial and temporal correlation between adjacent MBs in current and reference frames. These blocks are consisting of: Left; top; and top-right MBs in current frame, which in this document, henceforth, are called spatial MBs, since they are spatially correlated to the current MB, (Sptl_left_MB, Sptl_up_MB, and Sptl_upright_MB) Left; top; and top-right MBs in reference frame, which are called temporal MBs, since they are temporally correlated to their co-positioned blocks in the current frame (tmprl_left_MB, tmprl_up_MB, and tmprl_upright_MB). These are shown in figure 13.

Figure 13: Spatial and temporal MBs

26

The first two predictors in DPSA are what previously have been used and proved to be efficient in other techniques, including spatial median MV of adjacent blocks in current frame; as well as zero motion vectors. One closely correlated MB to current one is the co-located block in reference frame (Tmprl_MB). These two blocks are most probably associated to the same object and therefore have similar motion behaviour. One similarity is the direction and speed of their movement. Another aspect is dynamic correlation between them. For example, if MV of co-located MB (Tmprl_MB) differs from its neighbouring blocks in reference frame in terms of direction and velocity, then this difference might be repeated for MV of current MB in current frame, too. It is possible that the object included Tmprl_MB has stopped or accelerated or even changed its direction from reference frame to current frame. To consider these possibilities, proposed DPSA algorithm suggests that if direction and velocity of tmprl_left_MB; tmprl_up_MB; tmprl_upright_MB in reference frame have changed in previously calculated MV of Sptl_left_MB; Sptl_up_MB; Sptl_upright_MB in current frame then we can assume that this alteration has happened between MV of current MB in current frame, and its co-located MB in reference frame, too. However, it has been observed that not all neighbouring blocks have equal correlation to tmprl_MB. As a matter of fact, two top and left adjacent blocks appeared to be the highest correlated neighbours, while adding tmprl_upright_MB in search options, in most cases, only increases the number of search points without any improvement in quality or compression ratio. For that reason in proposed DPSA, only MVs of left and top MBs are considered. At the moment of calculating MV for current macro block, motion vectors for left and top MBs are already calculated (because of raster scan order) (figure 14). A new predicted MV is created by finding the changes ( (tmprl_left_MV; tmprl_up_MV respectively) with their co-positioned blocks Sptl_left_MV; Sptl_up_MV in current frame and then applying that on MV of Tmprl_MB, a new predicted MV is created. This predictor is referred to here as the spatial-temporal predictor (Sptl_tmprl_prdctor), since all temporal and spatial correlations of adjacent macro blocks are consider at the same time.

27

Figure 14: a) Reference frame b) Current frame

Avrg_

+

(5-1)

Avrg_ Sptl_tmprl_prdctor 1= (Tmprl_MB_MV) + Avrg_ To enhance the performance of initial set points, two other predictors are defined using adding and subtracting

(5-2) (5-3) By

-located MB in reference frame, second and

third spatial-temporal predictors (Sptl_tmprl_prdctor2 and Sptl_tmprl_prdctor3) are created. These predicted MVs cover the possibility that Tmprl_MB_MV changing speed or direction is not exactly as its neighbours. This way, the algorithm sweeps vaster area to get closer to the real MV. Consequently, it will result in higher performance with an insignificant increasing in search points, especially in complex scenes and motion activities. Sptl_tmprl_prdctor2= (Tmprl_MB_MV ) + (Avrg_ )/2 Sptl_tmprl_prdctor3= (Tmprl_MB_MV ) _ (Avrg_ )/2 (5-4) (5-5)

To cover the spatial correlation between neighbouring MBs, many algorithms suggest using MV of three adjacent MBs, left; top; and top-right blocks in current frame as three initial search points. Again, with the same logic as discussed, it can be assumed that blocks in left and top, are more redundant to current MB than top-right block. Consequently, Sptl_upright_MV can be

28

eliminated in the process. Now, two neighbouring blocks in each frame are remained, which are considered the most efficient MBs to predict the MV of Current_MB. sptl_prdctor1 = (Sptl_left_MV) sptl_prdctor2= (Sptl_up_MV) As it is seen in equation (5-1) in Avrg_ (5-6) (5-7) Sptl_left_MV and Sptl_up_MV have been

used. On the other hand, the redundancy between these two MBs and the current MB has been considered in defining sptl_prdctor1 and sptl_prdctor2. To minimize computation required for the prediction process only one of these adjacent blocks can be used in spatial prediction. In other words, spatial predictor can be defined as: Up_sptl_prdctor = (Sptl_up_MV) Then, for spatial-temporal prediction there are two options: Either would be left MB. Therefore: Left_ ( _ _ ) ( _ _ ) (5-9) (5-10) (5-1), or it can be only one of the neighbours, which (5-8)

Sptl_tmprl_prdctor 1= (Tmprl_MB_MV) + Left_ And two other predictors have to be obtained by: Sptl_tmprl_prdctor2= (Tmprl_MB_MV ) + (left_ )/2 Sptl_tmprl_prdctor3= (Tmprl_MB_MV ) - (left_ )/2

(5-11) (5-12)

This way, the proposed algorithm can be divided in two branches. One is called DPSA1, in which Avrg_ is named DPSA2, and uses Left_ Generally, after defining the predictors, the processor starts calculating SAD value for all of predicted regions. Then, the verdict with minimal SAD is set as the origin of a local search to find the most matching MB. In DPSA algorithm the local search pattern is chosen to be small diamond search due to its well-known high complexity-performance ratio. In each step minimum
29

-set of MVs. The second branch

SAD value is compared to an early stop criterion. If it satisfies the criterion the processor stops further searching and take that MV as the best description of current MB movement.

5.2.

Early termination strategy

For early termination conditions, EPZS criteria are base of proposed DPSA, with adding one more condition. In DPSA algorithm, after testing all initial predicted MVs, if one of three spatialtemporal predictors using and has minimum SAD value then it can skip the local search

step and take that predictor as the final MV of the current MB. This claim is based on the fact that, in the definition of these three initial predicted MVs, all possible correlations between adjacent blocks in current frame, and co-located MB, as well as its surrounding neighbours in reference frame have been considered. In other words, if the minimum SAD of initial predictors is associated to one of the zero MV, median spatial MV, or Up_sptl_prdctor, and this minimum SAD value does not satisfy the calculated Stop-Criterion in equation (4-4), it starts small diamond search around that minimal SAD verdict to find the accurate MV. This process continues until either reaching a MB with smaller SAD value than the criterion, or the center of the search turns out to be the minimum SAD between the others, as in ordinary diamond search algorithm. All these six predictors, along with the new early stop condition, have been tested and evaluated in JVT software platform, which will be elaborated further in the next section.

5.3.

Algorithm block-diagram

DPSA1 algorithm process can be summarized in the following steps: Step1: SAD value for median MV of three adjacent MBs in current frame including Left; Top; and Top-Right MBs and zero MV (0,0) are calculated. Step2: MB pointed by Up_sptl_prdctor is found and its SAD value is calculated. Step3: Avrg_ 5-2)

Step4: Three spatial-temporally predicted MV are found with equations (5-3), ( 5-4), and ( 5-5) and their SAD values are calculated.
30

Step5: The Min. SAD value between previous steps is found Step6: If the Min. SAD is corresponding to MBs in step4, then it stops search. Otherwise, it goes to step7. Step7: Based on equations ( 4-1) to ( 4-4), Stop-Criterion is measured. Step8: If the Min. SAD value is less than this criterion, then it stops search. Otherwise, it goes to step9. Step9: The verdict with Min. SAD becomes center of a small diamond search pattern. SAD value for four new p oints in small diamond pattern is calculated, and the Min. SAD is found. Step10: If the Min. SAD is associated to the center of the search, then it stops search. Otherwise, it goes back to step9. For DPSA2, steps 3 and 4 are as follow, and remaining steps are the same as DPSA1: Step3: Left_ 5-9)

Step4: Three spatial-temporally predicted MV are found with equations (5-10), ( 5-11), and ( 512) and their SAD values are calculated. All these steps are shown in the block-diagram of figure 15.

31

Figure 15: DPSA block-diagram

32

5.4.

Example

To make the algorithm more clear one example of DPSA1 is shown in this part (figure 16).

Figure 16: One example for DPSA1 algorithm Median MV = median [(4,5); (-2,9); (-2,2)] = (-2,5) Up_sptl_prdctor = (-2, 9) Avrg_ (Avrg_ -(10, 0)]/2 + [(-2, 9)-(4, 2)]/2 = (-6, 6) -3, 3)

Sptl_tmprl_prdctor1 = (2, 2) + (-6, 6) = (-4, 8) Sptl_tmprl_prdctor2 = (2, 2) + (-3, 3) = (-1, 5) Sptl_tmprl_prdctor3= (2, 2) - (-3, 3) = (5, -1) In first step, six predictors are examined to find the Min SAD. Based on experimental results, in majority of cases, one of the three spatial-temporal predictors turn to be the min SAD, in that case the verdict with min SAD is final MV. In this example to clarify all other steps, it is assumed that the spatial predictor (-2, 9) is Min SAD verdict. Thus, in step 2, a small diamond search is formed around (-2, 9) vector. At this stage, vector (-2, 9) points to the minimal SAD parameter. Again, in step 3, another small diamond search pattern centered on (-2, 9) is formed. Since the center of this diamond is the minimum one, at this step, search is stopped and (-2, 9) is returned as final MV. These steps are shown in figure 17.

33

Figure 17: DPSA1 algorithm search steps for example1

34

CHAPTER6 Experimental results
Several experiments have been conducted to investigate performance of our proposed algorithm. Amongst, over 250 frames of Six 4:2:0 YUV, QCIF (176 x144), shown in figure 18, and five CIF (352x288) format test video sequences, shown in figure 19, are encoded with DPSA1 and DPSA2 along with 4 accepted algorithms in H.264 reference software, including FS; UMHEX; SUMHEX; and EPZS, all implemented in common test conditions. A 2.4GHZ dual-core CPU, with 4G RAM are used in this experiments. Each time, ME process is carried on search window size of 32x32 pixels finding minimum SAD value as distortion criterion. The encoder is set to 30 frames per second for I and P frames, disabled skip mode and intra blocks in P frames, each frame divided into non-overlapping blocks of 16x16 samples H.264/144096-10 reference software version 18.1 from JVT [34][35] is chosen to be the test reference platform.

(a) Akiyo

(b) News

(c) Coastguard

(d) car-phone

(e) Mother& daughter

(f) Foreman

Figure 18: YUV video sequences; QCIF format (176x144)

35

(a)BUS

(b) Stefan

(c) Water fall

(d) Tempete

(e) Hall-monitor

Figure 19: YUV video sequences; CIF format (352x288) Software is developed to display four main criteria: total number of search points (sp); ME process time; data bit-rate; and PSNR of each encoded test sequence, to be evaluated. The results of these essential parameters are demonstrated and compared with 4 other algorithms, including EPZS and Full search techniques, in tables (2) to (12) and figures (20) to (36). In all above tables, two different versions of DPSA have been implemented. In the sixth row, Left_ (Left_ )/2 are calculated with equation (5-9). In seventh row Avrg_

(Avrg_ )/2 are measured with equation (5-1). Between 4 already existing algorithms applied in this study, Full search method reaches the highest quality encoded images with the cost of extensive computational complexity. UMHEX and SUMHEX decrease full search number of search points by 10 times with an insignificant cost of PSNR. EPZS manages to have the least number of search points, significantly, with acceptable range of PSNR. Hence, between these algorithm, EPZS is the most reasonable base to compare the newly proposed algorithm with. Though, EPZS does not have in positive effect on bit-rate. As these experimental results indicate, DPSA not only improves the compression ratio, but decreases EPZS computational complexity too. Also, unlike most other fast ME algorithms,

36

DPSA not only does not reduce the quality of compressed videos, but also, boost the PSNR by 0.47dB. Table 2
Algorithms EPZ UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 396.86 2838.01 3185.94 112141.00 358.38 361.16 ME Time 0.405 1.121 1.001 18.427 0.371 0.374 Y-PSNR 36.599 36.629 36.623 36.629 36.615 36.620 U-PSNR 39.222 39.259 39.234 39.250 39.253 39.249 V-PSNR 40.001 40.034 40.001 40.060 40.093 40.047 BR(kb/s) 113.94 114.01 113.80 113.55 107.73 105.31

Table 3
Algorithms EPZ UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 354.60 1950.83 1998.23 113180.65 302.31 305.46 ME Time 0.367 0.812 0.716 17.410 0.343 0.342 Y-PSNR 37.967 37.968 37.968 37.963 37.969 37.983 U-PSNR 40.704 40.709 40.708 40.692 40.713 40.715 V-PSNR 41.754 41.764 41.764 41.768 41.774 41.761 BR(kb/s) 57.58 57.70 57.69 57.84 57.83 57.16

Table 4
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/frame 582 7085 8897 410967 504 512 ME Time 1.594 6.696 7.020 22.517 1.446 1.463

Y-PSNR 37.182 37.172 37.199 37.192 37.301 37.341 U-PSNR 39.997 39.963 39.975 39.893 39.970 39.965 V-PSNR 40.477 40.478 40.428 40.449 40.472 40.534 BR (kb/s) 265.52 262.85 265.94 260.60 245.35 241.09

Table 5
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/frame 388 4766 7001 399621 334 338 ME Time 1.252 4.816 5.960 178.000 1.137 1.133 Y-PSNR 36.659 36.672 36.682 36.701 36.836 36.919 U-PSNR 41.278 41.248 41.272 41.249 41.325 41.353 V-PSNR 41.956 42.014 42.009 41.968 42.111 42.072 BR (kb/s) 88.23 87.44 87.85 87.13 83.68 81.01

37

Table 6: Performance
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/frame 638 9382 13310 413380 571 582 ME Time 1.764 8.847 10.734 208.077 1.605 1.648 Y-PSNR 36.15 36.18 36.16 36.16 36.44 36.49 U-PSNR 40.19 40.17 40.18 40.23 40.21 40.17 V-PSNR 41.04 41.05 41.07 41.05 41.12 41.11 BR (kb/s) 339.80 332.55 341.88 327.84 289.01 279.49

Table 7
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 1208.396 12777.78 12615.68 1655893 1080.192 1083.192 ME Time 4.269 14.684 11.038 819.869 3.944 3.967

Y-PSNR 37.96 37.96 37.96 37.96 37.98 37.99 U-PSNR 39.72 39.72 39.71 39.72 39.71 39.72 V-PSNR 41.64 41.64 41.66 41.65 41.66 41.66 BR (kb/s) 363.58 364.61 363.93 363.09 361.17 360.52

Table 8
Algorithms EPZ UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 486.46 6607.41 10925.11 113201.55 429.91 444.69 ME Time 0.462 2.439 3.566 26.602 0.446 0.461

Y-PSNR 34.274 34.283 34.287 34.292 34.453 34.482 U-PSNR 43.256 43.307 43.299 43.301 43.259 43.277 V-PSNR 43.995 43.998 44.017 44.009 44.128 44.097 BR(kb/s) 394.83 392.95 390.21 389.93 358.09 348.01

Table 9
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 1402 24477 71623 1666408 1264 1289 ME Time 5.192 25.254 58.133 1024.884 4.608 4.879 Y-PSNR 34.00 34.05 34.05 34.05 34.37 34.41 U-PSNR 35.04 35.11 35.09 35.09 35.13 35.13 V-PSNR 36.93 36.98 36.97 36.96 36.98 36.97 BR (kb/s) 1186.96 1161.78 1163.36 1161.34 798.35 736.03

38

Table 10
Algorithms EPZS UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 2286 39434 65470 1659335 2213 2227 ME Time 6.344 38.196 56.336 1028.996 6.277 6.215 Y-PSNR 35.60 35.62 35.61 35.62 35.60 35.61 U-PSNR 36.78 36.79 36.78 36.80 36.92 36.93 V-PSNR 38.40 38.42 38.43 38.44 38.53 38.54 BR (kb/s) 2745.44 2738.47 2742.37 2733.29 2061.98 1988.52

Table 11:
Algorithms EPZ UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 2696.54 23420.49 32947.06 452803.90 2457.39 2481.31 ME Time 2.378 9.225 9.938 98.346 2.150 2.203 Y-PSNR 36.179 36.190 36.176 36.177 38.437 36.449 U-PSNR 38.029 38.049 38.024 38.046 38.082 38.095 V-PSNR 38.034 38.033 38.030 38.033 38.103 38.081 BR(kb/s) 2454.71 2474.40 2469.40 2450.41 2035.02 1980.05

Table 12
Algorithms EPZ UHEX SUHEX Full DPSA2 DPSA1 SP/ frame 2819.54 29063.56 41113.46 452806.20 2580.34 2567.53 ME Time 2.625 12.867 14.430 113.952 2.305 2.285 Y-PSNR 35.359 35.384 35.368 35.361 35.599 35.591 U-PSNR 39.723 39.691 39.738 39.720 39.745 39.745 V-PSNR 41.331 41.269 41.302 41.267 41.420 41.385 BR(kb/s) 2617 2640.69 2630.63 2602.51 2107.95 2077.09

39

6.1.

PSNR

As it has been discussed in chapter1 in our tables PSNR is associated to three different values, Y; U and V samples .It has been observed that DPSA improves almost all components, considerably, compare to EPZS algorithm. For instance, Tempete a good example of detailed images which is very colourful

and the color content changes sharply between MBs. In this type of sequences, PSNR values associated to U- and V- samples are as important as Y components in the quality of encoded image. In figures 20, U-PSNR values are compared between DPSA1 and EPZS, frame by frame Tempete , to demonstrate DPSA performance.
DPSA1 EPZS

37.4 37.2 37 U_PSNR/Frame 36.8 36.6 36.4 36.2 5

25 45 65 85 105 125 145 165 185 Frame Number

Figure 20 However, since in most image samplings Y components have the higher resolution, and are more important, only this part of samples are compared for the rest of test videos. Some tested sequences -

are representing small to medium motion content videos. In simple and smaller MV images most ME algorithms are quite accurate, Still figure 21 shows better PSNR curve in DPSA, compare to EPZS.

40

38 DPSA1 37.5 37 EPZS

Y_PSNR/Frame

36.5 36 5 25 45 65 85 105 125 145 165 185 Frame Number

Figure 21: Frame by frame PSNR comparison for EPZS and DPSA1 on On the other hand, in medium to large motion content images, such as ; ;

are three good examples of detailed images. In this category, usually blurring of features due to a crude de-blocking filter is very obvious. Hence, the accuracy of motion compensation module is essential to have good quality encoded images. Comparing PSNR values earned in different algorithms in tables (8) to (12) indicates that almost in all cases DPSA has higher PSNR values over EPZS and other techniques. Also, frame by frame comparisons for PSNR of three detailed images are shown in figures (22) to (24).

37.2 36.8 36.4 36 35.6 Y_PSNR/Frame for Stefan 35.2 5 15 25 35 45 55 65 75 85 OPZS-delta&delta/2 EPZS

Frame Number

Figure 22: Frame by frame Y-

41

35.6 35.2 34.8 34.4 34 Y_PSNR/FrameforCoastguard 33.6 5 15

OPZS-delta&delta/2 EPZS

25

35

45

55

65 75 85 Frame Number

Figure 23: Frame by frame Y-PSNR comparison for

-

36

35.6

35.2

Y_PSNR/Frame for BUS

34.8

OPZS-delta&delta/2 EPZS

34.4 5 15 25 35 45 55 65 75 85 Frame Number

Figure 24: Frame by frame Y-PSNR comparison for

6.2.

Compression ratio

One of the most significant achievements of proposed DPSA algorithm is the high compression ratio. Somehow, this criterion represents the level of motion compensation accuracy. The more accurate MV estimation leads to further fidelity between encoded and original videos. As a result, the energy content of residual frames are much lower, and fewer data bits are required to be transmitted or stored, which means lower bit-rate or higher compression ratio. Reviewing result-tables (2) to (12) shows that amongst 4 existing algorithms, EPZS has improved the computational complexity, but it does not have any effect on compression ratio. DPSA on the other hand, creates an outright reduction in bit-rates between all tested techniques.
42

Specifically, in sophisticated pictures, with lots of details, this factor can be clearly compared. For instance, Tables (8) to (12) are corresponding to five CIF streams with medium to large MVs. In this scale typically an encoder with constant parameters will produce higher bit-rates. These tables prove a significant improvement on data bit-rate over the state-of-the-art EPZS algorithm. In figures 25 and 26 one video sequence of QCIF category and one from detailed CIF format category are chosen to illustrate frame by frame comparison on generated data-bits between DPSA1 and EPZS algorithms. It can be seen that in both scales, proposed DPSA has better curve in all individual frames.
6 5 4 3 DPSA1 EPZS

Kbits/Frame

2 1 0 5 25 45 65 85 105 125 145 165 185 Frame Number

Figure 25

120 100

DPSA1 EPZS

Kbits/Frame

80 60 40 20 0 5 25 45 65 85 105 125 145 165 185 Frame Number

Figure 26: Frame by frame data Bits/frame comparison for EPZS and DPSA1 on

43

6.3.

Computational complexity Motion Estimation Process time
is to compare ME process time, or

6.3.1.
One way to

speed up. As third columns in tables (2) to (12) show, intensive FS algorithm has most definitely the longest process time. UHEX and SUHEX algorithms considering the fact that are categorized in fast ME techniques, are not that much helpful in terms of speed up. EPZS algorithm, on the other hand, managed to have considerably good improvement in speed up over other techniques. Still, proposed DPSA has improved EPZS motion estimation process time by 13%. Having said that, because, especially in software implementation, algorithms are implemented on multi-purpose computers, and the processor might be involved in other tasks and interrupts, we believe ME process time is not the ultimate reliable parameter. Hence, we developed the software to display total number of search points for much more accurate evaluation. This parameter is discussed in next section.

6.3.2.

Search points

The other criterion that indicates computational complexity of an algorithm is the number of search points. Between 4 already existing algorithms applied in this study, Full search method reaches the highest quality encoded images with the cost of extensive computational complexity. UMHEX and SUMHEX decrease full search number of search points by 10 times with an insignificant cost of PSNR. EPZS manages to have the least number of search points, significantly. As these experimental results indicate, DPSA not only improves the compression ratio, but even it decreases EPZS computational complexity too. In figures (27) and (28) frame by frame number of search points per frame comparison is conducted for two QCIF vide sequences These two

files represent streams with small to medium MVs and details. In simple and smaller MV images, most ME algorithms are quite accurate, and produce few bits, but the point is which algorithm can perform faster and with less number of search points. It can be seen that DPSA has the lowest number of search points in most frames.

44

600 500 400 Searh Point/Frame 300 200 100 0 5

DPSA1 EPZS

25 45 65 85 105 125 145 165 185 Frame Number

Figure 27

700

OPZS_delta&delta/2
Srch Pnt/Frame

EPZS
600

500

400

300 5 15 25 35 45 55 65 75 85

Frame Number

Figure 28: Frame by frame search point comparison for

-

They also prove considerably good improvement on computational complexity over well-known EPZS algorithm, shown in figure (29) and (30).

45

Srch Pnt/Frame

2,850 2,600

2,350 2,100

OPZS_delta&delta/2 EPZS

1,850 5 15 25 35 45 55 65 75 85

Frame Number

Figure 29: Frame by frame search point comparison for

30 25 20 15 Searh Points/Frame (x10 ) 10 5

EPZS

25 45 65 85 105 125 145 165 185 Frame Number

Figure 30: Frame by frame number of search point Based on these tables (2) to (12), although EPZS has much lower number of search points than other three already existing approaches, DPSA1 and 2 have improved its result by about 14.7%.

6.4.

Variable Quantization parameter

Another factor that has been studied in this research is step size of the quantization, carried out on the residual frames (quantization parameter). In figure (31) to (34), three main parameters: parameters (QP). As we can see for all three parameters, almost always, DPSA1 curves show better results than EPZS.

46

Figures (34) to (36)

, as an example of

detailed images. DPSA has considerably good performance in these cases, as well. As evident in these graphs, step size (QP) is a critical parameter. If the step size is large, the range of quantised values is small and it leads to highly compressed data, during transmission. However, the re-quantised values in decoder are not a close approximation of the original ones and create lower PSNR values. With smaller step size, the re-quantised values match the original signal more closely, which means higher PSNR, with the price of lower compression efficiency. QP of 28 seems to be the most optimum step size, and has been applied in all other experimental steps.

700 600 500

DPSA EPZS

Searh Point/Frame

400 300 25 26 27 28 29 30 31 32 33 34

QP

Figure 31: Number of search points comparison for EPZS and DPSA1with various quantization -

40 39 38 37 36 35 34 33 32 25 26 27 28 29 30 31 32 33

DPSA EPZS

Y_PSNR

34

QP

Figure 32: PSNR comparison for EPZS and DPSA1with various quantization parameters on 47

0.5 0.4

DPSA EPZS

Kbit/Frame

0.3 0.2 0.1 0 25 26 27 28 29 30 31 32 33 34QP

Figure 33: Bit-Rate comparison for EPZS and DPSA1with various quantization parameters on -

18 17 16 15 14 Searh Point/Frame (x10 ) 13 12 25 26 27 28 29 30 31 32 33

DPSA EPZS

34

QP

Figure 34: Number of search points comparison for EPZS and DPSA1with various quantization

40

DPSA EPZS

Y_PSNR

38 36 34 32 30 25 26 27 28 29 30 31 32 33 34

QP

Figure 35: PSNR comparison for EPZS and DPSA1with various quantization parameters on

48

0.5 0.4 0.3

DPSA EPZS

Kbit/Frame

0.2 0.1 0 25 26 27 28 29 30 31 32 33 34

QP

Figure 36: Bit-Rate comparison for EPZS and DPSA1with various quantization parameters on

6.5.

Comparison between DPSA1 and DPSA2

Comparing two proposed versions: DPSA1 and DPSA2, overall both methods improve all main criteria in EPZS. DPSA1, using Avrg_ (Avrg_ )/2, in all test videos creates the least

number of bit-rate with the highest PSNR values. However, the number of search points and ME process time in this approach is higher than DPSA2. DPSA2, on the other hand, uses Left_ (Left_ )/2. It manages to have the least number of

search points, even up to 14.7% less than EPZS which is well-known for its computational complexity, and the highest speed up among all tested algorithms. Though, it does not increase the compression ratio, as much as DPSA1 does. Therefore, although the differences between DPSA1 and DPSA2 performance are insignificant, they can be recommended in this way: For applications, with computational complexity constraint, such as real time encoders, in which, the computational cost must be low enough to ensure encoding of at least intended frames per second (in this experiment: 30 fps) DPSA2 is highly recommended.

49

band-width is limited, or the capacity of storage is the main concern, DPSA1 with the lowest required bit-rate, insures the much needed compression ratio.

50

CHAPTER7 Conclusion
Fast ME algorithms are patterns which try to reduce the computational complexity of ME process time. Predictive zonal search algorithms are a category of block-based fast ME methods that promise to keep the encoded images quality and compression ratio besides lowering the computational complexity. In this thesis a new block-based dynamic predictive search algorithm (DPSA) is proposed, for video encoders.

7.1. Advantages
Encoding several test sequences with DPSA along with 4 other existing algorithms indicates that this technique clearly outperforms other methods in terms of PSNR; compression ratio; and computational complexity. All achieved improvements through DPSA1 and DPSA2 compare to EPZS algorithm for the 11 tested video sequences are listed in table 13. Unlike most other fast ME algorithms, DPSA not only produces up to 38% lower bit-rate, but also, increases the PSNR parameter by 0.47dB. This confirms finding more accurate MVs and minimizing the energy content of residual images. This is a highly desirable feature in many applications, particularly in limited bit-rate and band-path channel networks and fixed capacity storage media like CDs and DVDs. Moreover, based on experimental results, DPSA accomplishes up to 14.75% lower number of search points than state-of-the-art EPZS with up to 13% speed up. This accomplishment makes DPSA energy efficient for portable video processing in computation- or power-constrained applications. One advantage of DPSA, over the other algorithms is simplicity. Unlike well-known EPZS that uses over 10 predictors, proposed DPSA takes advantage of the most optimum correlated MBs for prediction, and only with six initial search points, manages to achieve the highest

51

performance and the shortest process time. This feature makes it easier to be implemented on both hardware and software platforms. Another feature of DPSA is its scalability for various levels of motion contents, small to medium to large. It also has considerably good performance over different sampling resolutions, as we have presented experimental results for both QCIF and CIF movie streams in this paper. This makes DPSA generally beneficial for different applications from offline film processing to online video-conferencing.

7.2. Future works
Experimental measurements prove that DPSA improves PSNR values as a factor of quality, over EPZS algorithm, on almost all encoded videos. Watching encoded frames in single colour areas of these images, it is even visually distinctive that DPSA creates smoother frames. However, in some colourful images such as waterfall, with high frequency samples, DPSA results in some kind of washed out colours. One suggestion on future works in this area might be finding a solution to resolve this issue in order to improve the sharpness of colours in encoded images.

52

Table 13: Performance improvement in DPSA1 and DPSA2 over EPZS
ME Sequence name DPSA algrthm DPSA1 Car-phone DPSA2 Mother & Daughter DPSA1 DPSA2 DPSA1 Foreman DPSA2 DPSA1 Waterfall DPSA2 DPSA1 Tempete DPSA2 Hall monitor DPSA1 DPSA2 DPSA1 Stefan DPSA2 DPSA1 Bus DPSA2 DPSA1 Coast-guard DPSA2 DPSA1 News DPSA2 DPSA1 Akiyo DPSA2 0.002 -0.03 14.75 0.016 0.016 5.45 0.73 9.70 13.86 0.179 0.021 9.31 7.57 11.62 9.00 0.240 0.208 19.45 11.86 8.48 8.59 0.258 0.232 17.10 20.63 8.87 8.94 0.1 0.031 0.017 0.270 24.89 0.84 0.66 19.34 3.17 10.36 10.61 7.98 1 0.3 0.3 7.4 9.6 13.0 12.2 0.2 3.5 7.7 8.4 6.8 6.5 0.374 0.1 32.74 27.57 9.85 2.58 11.25 2 0.29 0.410 14.95 37.99 10.42 8.1 9 6 0.12 0.26 0.177 0.345 7.60 8.18 5.16 17.75 13.41 12.91 14.05 8.77 9.3 9.5 9.2 6.6 PSNR improvement (dB) 0.16 Bit-Rate improvement (%) 9.20 Search point improvement (%) 12.03 process time (%) 8.2

53

PUBLICATIONS

1. Abdoli, B; IEEE Transaction on multimedia, submitted, 2012

2. journal of Signal Processing: Image communication, Elsevier, submitted, 2012

-based

54

BIBLIOGRAPHY
[1] Kneip, J.; Robert Bosch GmbH; Hildesheim Bauer, S. ; Vollmer, J. ; Schmale, B. ; Kuhn, P. ; Reissmann, M. The MPEG-4 video coding standard a VLSI point of view

conference on signal processing systems 98, pp.43-52, October 1998 [2] Wiegand, Thomas; Sullivan, Gary J.; Bjontegaard, Gisle; Luthra, Ajay, IEEE Transactions on Circuits and Systems for Video Technology, vol. 13, NO. 7, pp. 560-575, JUL 2003. [3] Ahirwal,B.; Mechatron. Pune Khadtare, M.; Mehta, R. Space Transformation RGB to YIQ and YCbCr Intelligent and advanced systems, pp. 1345-1349, November 2007 [5] Xiao-Fan Feng Vision-Based Strategy to Reduce the Perceived Color MisEEE, VOL. 90, NO. 1, FPGA based system for Color

registration of Image-Capturing Devices pp. 18-27, January 2002 [6] Kalva, Hari, 86-90, October 2006

in IEEE Multimedia, vol.13, NO.4, pp.

[7] Jong-Nam Kim ; Sung-Cheal Byun ; Yong-Hoon Kim ; Byung-Ha Ahn,

Fast Full Search

Motion Estimation Algorithm Using Early Detection of Impossible Candidate Vectors IEEE Transactions on Signal processing, vol. 50, NO.9, pp. 2355 2365, September 2002

[8] Jing, Xuan; Chau, Lap-Pui, E

-Step Search Algorithm for Block Motion

IEEE Transaction on Multimedia, vol. 6, NO.3, pp. 435-438, June 2004 -step search algorithm for block motion

[9] Li, Reoxiang; Zeng, Bing; Liou, M.L.;

IEEE Transactions on Circuits and Systems for Video Technology, vol.4, NO.4, pp. 438-442, Aug1994.
55

[10] Chi-Wai Lam ; Lai-Man Po ; Chun Ho Cheun

A Novel Kite -Cross-Diamond Search , in IEEE

international conference on Acoustics, Speech, and Signal Processing, vol.3, pp. 365368, May 2004 [11] Liang Yaling ; Liu Jing; Du Minghui A Cross Octagonal search algorithm for fast block motion estimation Communication Systems 2005, pp. 357 [12] Cheung, Chun-Ho; Po, Lai-Man, Intelligent Signal Processing and 360, December 2005 -Diamond Search Algorithm for Fast

, IEEE Transactions on Circuits and Systems for Video Technology, vol.12, NO.12, pp. 1168-1177, Dec 2002 [13] Improved Diamond Search Algorithm for H.264/AVC Video Coding Standard [14] Zhu, Ce; Lin, Xiao; Chau, Lappui; Po, Lai-Man, "Enhanced hexagonal search for fast block motion estimation", IEEE Transactions on Circuits and Systems for Video Technology, vol.14, NO.10, pp. 1210-1214, October 2004 [15] X. Yi -biased cross diamond search for rapid motion in Image and Video Communications and Processing, San Jose, SPIE vol. 5685, pp. 995-1006, Jan 2005 [16] Zhiru Shi, W.A.C. Fernando an on predictive intensive direction search for H.264/AVC Multimedia and Expo (ICME), pp. 667-672, September 2010 [17] Jo Yew Tham ; Ranganath, S. ; Ranganath, M. ; Kassim, A.A., center-biased diamond search algorithm for block ME A Novel unrestricted A motion estimation algorithm based

IEEE Transactions on Circuits and

Systems for Video Technology, vol.8, NO.4, pp. 369 - 377, Aug 1998 [18] Tourapis, A.M. ; Au, O.C. ; Liou, M.L. ; Shen, G. ; Ahmad, I. Encoder - Advanced Diamond Zonal Search Systems 2000, vol.3, pp. 674 - 677, 2000 Optimizing the MPEG-4

IEEE international symposium on Circuits and

56

[19] Li Hong-ye; Liu Ming-jun, Cross-Hexagon-based Motion Estimation Algorithm Using Moti on Vector Adaptive Search Technique communication and signal processing, pp. 1-4, November 2009 [20] Ahmed, Zaynab ; Hussain, Abir Jaafar ; Al-Jumeily, Dhiya, Matching (MPBM) for fast Block-Matching motion estimation on Visual Information Processing (EUVIP), pp. 67-72, October 2011 [21] Hosur, Prabhudev I.; Ma, Kai-Kuang, Second International Conference on Information, Communications and Signal Processing (ICICS 1999), Singapore, Dec1999. [22] Tourapis, Alexis Michael; Au, Oscar C.; Liou, Ming L., "Predictive Motion Vector Field Adaptive Search Technique (PMVFAST) in Mean Predictive Block

proceedings of Visual Communications and Image Processing 2001(VCIP-2001), pp.883-892, San Jose, CA, January 2001. [23] Lihui Yang Research on the Motion Estimation Algorithm in AVS conference on networking and digital society, vol. 2, pp. 625 [24] Hoi-Ming Wong PMVFAST) and Expo, July 2005 [25] Tourapis, Alexis Michael; Au, Oscar C.; Liou, Ming L.; Shen, Guobin; Ahmad, Ishfaq, Optimizing the MPEG-4 Encoder - Advanced Diamond Zonal Search IEEE International 677, August 628, May 2010

Enhanced predictive motion vector field adaptive search technique (E, IEEE International Conference on multimedia

Symposium on Circuits and Systems, Geneva, Switzerland , vol.3, pp. 674 2002 [26] Tourapis, A.M.; Au, O.C.; Liou, M.L.

New Results on Zonal Based Motion Estimation

Algorithms -Advanced Predictive Diamond Zonal Search IEEE International conference on Circuits and Systems, vol.5, pp. 183 - 186, 2001

57

UMHexagonS Search Algorithm for Fast Motion Estimation pp. 483-487, May 2011 [28] Chou, Lei-Chun; Ye, Cheng-Da; Liu, Yuan-Chen; Jhao, Bin-Cheng, Search Algorithm for Video Motion Estimation Analysis and Processing, pp. 399 406, October 2007 Fast Predictive

[29] Yoon, Hyosun; Kim, Hyesuk; Kim, Miyoung; Nga, Lai; Lee, Gueesang, , IEEE 8th International Conference on Computer and Information Technology Workshops , Sydney, QLD, pp. 391 395, July 2008 [30] Marcelino S., Faria S., Assuncao P., Moiron S., Ghanbari M., in IEEE International Workshop on Multimedia Signal Processing (MMSP), pp. 228 232, Dec 2010

[31] Tourapis, Alexis Michael; Au, Oscar C.; Liou, Ming L., "Highly efficient predictive zonal algorithms for fast block-matching motion estimation" IEEE Transactions on Circuits and Systems for Video Technology, vol. 12, NO.10, pp. 934-947, October 2002 [32] Tourapis, Alexis Enhanced Predictive Zonal Search for Single and Multiple

Frame Motion Estimation in proceedings of Visual Communications and Image Processing 2002 (VCIP-2002), pp. 1069-79, San Jose, CA, Jan 2002 Enhanced Adaptive Early T ermination for Enhanced Predictive Zonal Search Algorithm in motion estimation Network Security (IJCSNS), vol. 8 NO. 6, pp. 236 -240, June 2008 [34] Tourapis, Alexis Michael; Sühring, Karsten; Sullivan, Gary, -10 AVC

, Joint Vide Team (JVT) of ISO iIEC and ITU-T VCEG, Input document to JVT, June-July2009

58

Fast Integer and Fractional Pel Motion Estimation Team (JVT) of ISO iIEC and ITU-T VCEG, Input document to JVT, 5th Meeting, Geneva, Switzerland, October 2002.

59

Nomenclature
DPSA EPZS PSNR ME MC SAD SDSP LDSP MV MB SP BR QP Dynamic Predictive Search Algorithm Enhanced Predictive Zonal Search Peak Signal to Noise Ratio Motion Estimation Motion Compensation Sum Of Absolute Difference Small Diamond Search Pattern Large Diamond Search Pattern Motion Vector Macro Block Number of Search Points Data Bit Rate Quantization Parameter

60

