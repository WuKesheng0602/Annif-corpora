CONTINUOUS AUTHENTICATION BASED ON LEARNING USER COMMAND SEQUENCE

by

Bijan Khalilian B.Sc., Ryerson University, Toronto, Ontario, Canada, 2007

A Dissertation Submitted in Partial Fulfillment of the Requirements for the Degree of MASTER OF SCIENCE in the Program of Computer Science

Toronto, Ontario, Canada, 2010 © Bijan Khalilian 2010 Ryerson University

I hereby declare that I am the sole author of this thesis or dissertation. I authorize Ryerson University to lend this thesis or dissertation to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis or dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

ii

CONTINUOUS AUTHENTICATION BASED ON LEARNING USER COMMAND SEQUENCE

Bijan Khalilian M.Sc., Computer Science, Ryerson University, 2010 Abstract
In the context of information and computer security, a masquerader is an individual who can gain access to a system by disguising itself as a legitimate user. One of the prominent and popular methods for authenticating masqueraders is by using an intrusion detection system (IDS). This thesis promotes the idea that learning the user command sequence can be served as an alternative for addressing intrusion detection. Several approaches have been proposed in the literature, where this idea has been explored. To our knowledge, the method by Maxion and Townsend produces the best results of all past techniques so far in terms of detection rate (82.1% using the Greenberg dataset). In this thesis, we propose an IDS-based approach that consists in combining a novel Naïve Bayes classifier with a recently proposed sequential sampling technique for continuous authentication, applied to user command sequence, to detect masqueraders. Our experimental evaluation shows that our proposed scheme achieves a detection rate of 98%.

iii

Acknowledgments
It is a pleasure to thank those who made this thesis possible. I owe my deepest gratitude to my supervisor Dr. Isaac Woungang and my co-supervisor Dr. Issa Traore for sharing their knowledge and providing continuous support. Without their help and guidance the

completion of this work would have not been possible. I would also like to thank William Zereneh for making his valuable time available to me and many of my colleagues. I am grateful for his timely help and for always keeping his door open for many of us.

iv

Dedication
I dedicate this thesis to my loving parents, Hamid and Mansoureh. Without their patience, support, and most of all love, the completion of this work would have not been possible. Furthermore, I would also like to dedicate this work to my wonderful and loving siblings Bita, Anahita and Aria.

v

Table of Contents
Abstract...................................................................................................................................................... iii Acknowledgments .................................................................................................................................... iv Dedication................................................................................................................................................... v Table of Contents ..................................................................................................................................... vi List of Tables .......................................................................................................................................... viii List of Figures .......................................................................................................................................... ix List of Acronyms ....................................................................................................................................... x Chapter 1: Introduction........................................................................................................................... 1 1.1 1.2 1.3 1.4 1.5 Context of Our Study ............................................................................................................... 1 Research Problem ..................................................................................................................... 2 Our Approach ............................................................................................................................ 3 Contribution ............................................................................................................................... 4 Thesis Organization ................................................................................................................. 4

Chapter 2: Background Research ......................................................................................................... 6 2.1 2.2 Intrusion detection System Approaches .............................................................................. 6 Quantitative Modeling Methods............................................................................................ 7 Naïve Bayes Classifier ..................................................................................................... 8 Intrusion Detection Systems in Conjunction with Naïve Bayes Classifier ......... 9

2.2.1 2.2.2 2.3

Continuous Authentication Based on Learning User Command Sequence .............. 10

Chapter 3: Continuous Authentication Based on Learning User Command Sequence (CABLUCS) .............................................................................................................................................. 15 3.1 Design Space ............................................................................................................................ 15 Data Collection ................................................................................................................ 15 Greenberg's Data Organization ................................................................................... 18 Reproducing Greenberg's Methodology ..................................................................... 19

3.1.1 3.1.2 3.1.3 3.2 3.3

System Architecture............................................................................................................... 21 Implementation ....................................................................................................................... 22 Data Structure................................................................................................................. 22 Pre-processing the Dataset ........................................................................................... 25 Naïve Bayes Classifier ................................................................................................... 34

3.3.1 3.3.2 3.3.3

vi

3.3.3.1 3.3.3.2 3.3.3.3

Profiling Users............................................................................................................. 37 Classifying Users ........................................................................................................ 41 Continuous Authentication and the Sequential Sampling Technique ........... 43

Chapter 4: Experimental Evaluation ................................................................................................. 48 4.1 4.2 4.2. 4.3. Challenges ................................................................................................................................ 48 Evaluation Approach and Setup ......................................................................................... 49 Performance Results .............................................................................................................. 62 Discussion ................................................................................................................................. 71

Chapter 5: Conclusion ........................................................................................................................... 79 Appendix A: Generated Statistics for the Greenberg Dataset (Ordered by Commands) ....... 80 Appendix B: Generated Statistics for the Greenberg Dataset (Ordered by History) .............. 83 Appendix C: Generated Statistics for the Greenberg Dataset (Ordered by Errors) ................ 86 Appendix D: Generated Statistics for the Greenberg Dataset (Ordered by Aliases) .............. 89 Appendix E: Generated Statistics for the Greenberg Dataset (Ordered by Lines) .................. 92 Appendix F: List of User Profiles (Victims) ...................................................................................... 95 Appendix G: Undecided Results .......................................................................................................... 96 References ................................................................................................................................................ 97

vii

List of Tables
Table 1: Results produced by 6 methods to detect masquerades. Schonlau et al .................... 12 Table 2: Results produced by implementing the Naive Bayes classifier. [10; 26] .................... 12 Table 3: A list of detection methods and their relative results .................................................... 13 Table 4: Login session record ............................................................................................................... 18 Table 5: Command line record ............................................................................................................. 18 Table 6: Greenberg's reproduced dataset sample ............................................................................ 20 Table 7: Filename structure used in the dataset............................................................................. 24 Table 8: User types (user_types) database table schema .............................................................. 26 Table 9: User types (user_types) database table sample data...................................................... 27 Table 10: Users (users) database table schema ............................................................................... 27 Table 11: Users (users) database table sample data ...................................................................... 28 Table 12: Sessions (sessions) database table schema ..................................................................... 29 Table 13: User sessions (sessions) database table sample data ................................................... 30 Table 14: Data items (data) database table schema ....................................................................... 30 Table 15: Sample command lines in the 'data' table from User 1 ............................................... 32 Table 16: Data report (insert_report) database table schema ...................................................... 32 Table 17: Sample reports in the 'insert_report' table from 5 different users ............................ 34 Table 18: Small segment of a given profile ....................................................................................... 41 Table 19: Probability distribution for an arbitrary user ................................................................ 42 Table 20: Three selected sampling plans .......................................................................................... 54 Table 21: engine_report MySQL table schema ................................................................................ 58 Table 22: engine_output MySQL table schema ............................................................................... 60 Table 23: Details of the final results made by using CABLUCS ................................................. 61 Table 24: Successive progression of the decision making process ............................................... 61 Table 25: List of prepared sampling plans and tests ...................................................................... 62 Table 26: Decision making process of the sequential sampling technique ................................ 65 Table 27: Results achieved based on different parameters and sampling sizes....................... 67 Table 28: Result comparison based on Cost = (FAR) + (FRR) ...................................................... 74 Table 29: Result ranking comparison based on Cost = (FAR) + (FRR) ...................................... 75 Table 30: Result comparison based on Cost = (FAR) + 6(FRR) .................................................... 76 Table 31: Result ranking comparison based on Cost = (FAR) + 6(FRR) .................................... 77 Table 32 :Users that were falsely rejected in 21 different test cases .......................................... 78

viii

List of Figures
Figure 1: System architecture ............................................................................................................. 21 Figure 2: Greenberg's dataset user session sample ........................................................................ 24 Figure 3: General sampling plan ........................................................................................................ 45 Figure 4: Sampling Plan A (p1 = 0.29, p2 = 0.71, = 0.01,  = 0.01). ........................................... 55 Figure 5: Sampling Plan B (p1 = 0.30 p2 = 0.70, = 0.01,  = 0.01). ............................................ 55 Figure 6: Sampling Plan C (p1 = 0.31 p2 = 0.69, = 0.01,  = 0.01) ............................................. 56 Figure 7: User 1's new input tested on User 1's profile ................................................................. 63 Figure 8: User 2's input tested on User 1's profile .......................................................................... 64 Figure 9: Analysing the system's FAR rate versus the sample size............................................ 68 Figure 10: Analysing the system's FRR rate versus the sample size ......................................... 69 Figure 11: Analysis of the system's MTTA value as the sample size is increased................... 69 Figure 12: Analysing the system's MTTA value versus the sample size ................................... 70 Figure 13: Analyzing the systems CPU Usage versus the sample size ...................................... 71 Figure 14: Relationship between sample size and FRR/FAR using sampling plan A............. 72 Figure 15: Relationship between sample size and FRR/FAR using sampling plan B............. 72 Figure 16: Relationship between sample size and FRR/FAR using sampling plan C............. 73

ix

List of Acronyms
ANN CA CR DR FAR FRR HCS IDS CABLUCS MTTA NN PHP SVM TTA Artificial Neural Network Continuous Authentication Confidence Ratio Detection Rate False Accept Rate False Reject Rate Hybrid Command Sequence Intrusion Detection System Continuous Authentication Based on Learning User Command Sequence Mean Time-to-Alarm Neural Network PHP: Hypertext Processor Support Vector Machine Time-to-Alarm

x

Chapter 1: 1: Introduction
1.1 Context of Our Study
This thesis introduces a new approach in detecting masquerade attacks in systems, by implementing an intrusion detection system that consists of a Naïve Bayes classifier complemented with a recently proposed sequential sampling technique [1] for continuous authentication, applied to user command sequence. The Naïve Bayes

classifier is used to train a dataset that consists of command-line history taken from 168 different users.
1.2 Motivation

In general, intrusion detection systems (IDS) are designed to handle masqueraders, i.e. users who impersonate other users, trying to gain access within a secure network. Typically, it is assumed that sophisticated masqueraders possess insider's knowledge on various features of the system such as topologies, potential vulnerabilities and the how various security products have been installed. To protect systems against masqueraders, security technologies such as firewalls, network-based intrusion detection systems, and strong authentication protocols are utilized. In general, most authentication systems are only concerned about the point of entry [2]. Once a user has successfully passed the initial phase of authentication (i.e. user login), the user is deemed genuine. However, this assumption can be quite costly. In the case where such initial phase of authentication is compromised, the entire system can be in dire jeopardy. IDSs in conjunction with continuous authentication can
1

be used to address this problem since these systems have been designed to detect different types of security hazardous behaviours after the user has already been given permission to access the system. The general idea of using continuous authentication is that the legitimacy of an active user session can be validated continuously, leading to a predefined and distinctive user profile (i.e. signature) during a live session within intermediate intervals. To this effect, a continuous authentication system can be used to investigate a user's typing habits [3], mouse dynamics [4] or command line sequence, in order to determine the legitimacy of a given user. IDSs differ from conventional firewall systems and authentication protocols in the sense that in addition to prevent non-privileged users from accessing sensitive data or performing restricted tasks, they can also be used to control the access capability for users with the appropriate and official privileges who abuse their concessions. In other words, IDSs can be used to detect malicious insiders that use their privileges to perform unauthorized actions. For this reason, IDSs are considered as network security schemes of choice [5; 6]. Designing an IDS that can achieve a high level of accuracy while detecting masquerade attacks, is the primary motivation of our work.

1.2 Research Problem
Several IDS-based approaches for masquerade detection have been investigated, ranging from approaches based on support vector machine classifiers [7; 8]; to the pioneer approaches based on mouse dynamics [1] and keystroke dynamics to approaches based on sequence-based user commands profile [9; 10], to name a few. In the latter case, several attempts to learn user command sequence for masquerade detection have been investigated [10]. The proposal that yields the best result so far in
2

terms of accuracy (using the Greenberg dataset) ­ measured by the level of detection achieved, is the work by Maxion and Townsend [10]. Yet, this performance is still inadequate, especially in the context of commercial-based systems. Therefore, designing IDS-based systems that can detect the above-mentioned canonical masquerade attack based on learning sequence-based user commands while producing a better level of accuracy compared to that obtained by the Maxion and Townsend's approach, would be highly desirable. This is the challenge addressed in this thesis.

1.3 Our Approach
In this thesis, to address the above-mentioned challenge, we follow up on an idea inherited from the pioneer work in [10], i.e. using a Naïve Bayes classification algorithm to learn sequence-based user commands, with the goal to provide a solution to the problem of masquerade detection. Our approach differs from that presented in [10] with respect to the use of updating mechanisms that dynamically recompute the classifier probabilities as monitored sequences are analyzed and classified by our Naïve Bayes classifier. More precisely, our approach consists of an integration of three

components: (1) a data pre-processing module ­ that captures the user's data input and restructured them to a more manageable format; (2) a detector ­ which deploys a Naïve Bayes classification algorithm (as in [10]) in order to create a set of distinct user profiles; and (3) a dynamic sampling technique for continuous authentication (so-called sequential sampling technique) ­ which is inherited from a recently pioneered work on continuous authentication [1] and is used to distinguish the legitimacy of a given user based on a given user profile.

3

1.4 Contribution
There have been a lot of works dealing with learning using command sequence to detect masquerade attacks in systems [10]. To our knowledge, the best detection rate achieved so far is attributed to the approach proposed by Maxion and Townsend [10]. The contribution of this thesis is the design of a novel intrusion detection system that learns from sequence-based user commands profile to detect classical masquerade attacks while learning the behavioural tendencies of a given user. This design is realized by complementing a recently proposed evaluation technique for continuous

authentication [1] (so-called sequential sampling) with a novel Naïve Bayes learning
algorithm, applied to user command sequence. Our approach is shown to achieve a significant improvement over the above-mentioned performance by Maxion and Townsend [10].

1.5 Thesis Organization
This thesis is composed of the following Chapters. Chapter 2: Background Research In this chapter, we discuss previous works on the subject and their limitations. Chapter 3: Continuous Authentication Based on Learning User Command Sequence (CABLUCS) The chapter constitute the core of this thesis. We describe our CABLUCS intrusion detection system, including a discussion on its implementation.

4

Chapter 4: Experimental Evaluation Validating the proposed Continuous Authentication Based on Learning User Command Sequence (CABLUCS) scheme is of course an essential part of this research work. In this chapter, we describe the experimental setup as well as the performance parameters and the obtained results. Chapter 5: Conclusion We conclude our work and present future possible works that can be done to extend the scope of the content of this thesis.

5

Chapter 2: Background Research
This chapter discusses related works on intrusion detection systems. Common methods and models employed within this field of research are discussed, as well as related research challenges. Finally, our new approach is contrasted against these related works.

2.1

Intrusion detection System Approaches

Various design approaches to Intrusion Detection Systems (IDSs) have been proposed in the literature, as well as a few attempts to produce taxonomies of IDSs [11], [12; 13; 14; 15; 16; 17], Typically, IDSs can be classified into three categories: sensors, detectors, and positive intrusion handlers (not including false alarms) [11]. Researches focus

their attention mostly on detector entity along the system characteristics. There are currently two major types of detection approaches: Anomaly Detection and Signature Detection (Misuse Detection). Anomaly Detection is based on abnormal behavior. It relies on self-learning for the purpose of detecting abnormal behaviors. A drawback of such system is that some behaviors may not be undesirable, leading to a high false positive rate [11]. Self-

learning systems are broken down into two categories: non-time series systems and time series ones. Non-time series systems use stochastic models to determine what a normal behavior would be disregarding time constraints. On the other hand, timeseries systems determine normality based on techniques such as Markov models, artificial neural networks, to name a few [11; 18]. As instance, sequence learning for anomaly detection is an example of approach that records the normal working state of a

6

system (i.e. the system's call traces, network packet traces, resource consumption patterns) with regards to its user, then uses this dataset to differentiate between normal and suspicious behavior, by comparing expected behavior patterns with lively detected behavior patterns. The goal is to produce a cost-effective and preeminent

model that can, swiftly and appropriately be managed by a certain mechanism. This latter criteria is important because once these systems are deployed in large organizations, the datasets can be very large and in some cases unreliable in terms of timely masquerade detection. Misuse detection systems are based on previously known intrusion attempts that are fairly common; therefore they may not be reliable in terms of catching new malicious behaviors. However, these systems can be used to detect sequences of

instructions that violate the security policies. They make use of rule sets to distinguish behaviors; thus are unable to detect violations that are unknown to these rule sets.

2.2

Quantitative Modeling Methods

For quantitative modeling purpose, artificial neural networks are considered as an important class of tools [19]. These types of systems or computing models have been applied to various problems in many different areas, particularly for identifying the fundamental relationships among a set of variables or patterns in the data [19]. Two important characteristics of these systems are: parallel processing of information and learning and generalizing from experience.

7

2.2.1

Naïve Bayes Classifier

In addition to artificial neural network, Bayesian learning algorithms have been used as a tool of choice for modeling various systems [19]. The Bayesian learning concept consists in inferring a set of parameters of a predefined model from the information

contained in some data. The Naive Bayes classifiers are among the most successful known class of Bayesian learning algorithms, for learning to classify text documents [20; 21]. The
Naïve Bayes classifier is also widely used to detect and classify spam [23; 24] and many other unwanted electronic documents. The Naïve Bayes classifier is directly related to tasks where each instance  is described by a combination of attribute values. The target function () can represent any available value from a finite set  . Given a set of training examples of the target function, the algorithm can classify a new instance. More precisely, given the new instance tuple of attribute values ( ,  ...  ), the classifier indicates the most probable target value  as follows:  = argmax    | ,  ...   (1)

By applying the Bayes theorem, Equation 1 can be re-formulated as:

8

 = argmax
  

 ,  ...  |   ( ,  ...  ) (2)

= argmax    ,  ...   ( )

Given the training data, an estimation can be made using the two terms ( ,  ...  | ) and ( ). In order to evaluate ( ), we calculate the frequency of which the target value  appears in the training examples. The Naïve Bayes classifier is built on the assumption that the tuple of attribute values ( ,  ...  ) is conditionally independent given the target value [20]. Therefore, this naive assumption indicates that  ,  ...    =  ( | ) and hence the Naïve Bayes classifier is expressed as:  = argmax        ( | ) (3)

The Naïve Bayes classifier has a specific characteristic that is different from other learning algorithms. The hypothesis is evaluated by examining the frequency of

different data combinations throughout the training examples and without the need of querying. A comprehensive description of this machine learning algorithm can be found in [20]. The procedural steps required to implement the Naïve Bayes classifier is

detailed in Chapter 3. 2.2.2 Intrusion Detection Systems in Conjunction with Naïve Bayes Classifier Classifier Typically, the Naïve Bayes classifier is used to classify text documents [25]. However, a successful implementation of a Naïve Bayes classifier in an intrusion detection environment has also been presented [26; 27; 6; 10; 28]. Due to the nature of this

9

learning algorithm, it is natural to employ it in an application where the learning involves strings of text, such as command-lines. A description of procedures involved to implement such machine learning algorithm in an IDS based on learning user command-line sequences is given in Chapter 3.

2.3

Continuous Authentication Based on Learning User Command Sequence

The source of input data used in anomaly detection is normally extracted from different types of user/system input. The most commonly used data source in anomaly based intrusion detection systems involves one of, mouse dynamics [4; 29], keystroke dynamics, system processes [30; 31; 32; 33; 34], and/or command line sequence. In most literatures that involve learning command line sequence, the data is produced using UNIX or UNIX-like operating systems. The most commonly used dataset in this field, is the work of Schonlau et al. [9]. In the work of Schonlau et al., six different methods were used in order to learn and profile [35] user behaviour, based on their given UNIX command line history. These methods include: Uniqueness Bayes one-step Markov Hybrid multi-step Markov Compression IPAM (Incremental Probabilistic Action Modeling) Sequence-match

· · · · · ·

10

The uniqueness method is established based on the command frequency in the training data. A command line that is not witnessed in the training data is deemed to be

malicious. Commands that have a low frequency in the training data will demonstrate a higher indication of malicious behaviour. The Bayes one-step Markov method is based on the concept of single iterations between commands. The system will compare the given sequence of iteration probabilities to previously known iteration tendencies and determine the legitimacy of the given user. The hybrid multi-step Markov method is based on the nth-order Markov chain and a given model that determines the proportionality of commands that were not witnessed in the training data. The compression method is based on generating reversible maps for the data in correspondence to a representation that utilizes less storage than the original. New input from the user is compressed and compared to the given maps and tested for legitimacy based on the compression rates. The IPAM (Incremental Probabilistic Action Modeling) method is based on one-step command iteration probabilities with regards to a given training data, while continuously expanding and updating its arrangement. The sequence-matching method is based on determining the similarities between the ten most recent commands of a given user in comparison with a user's profile. The following table demonstrates the results achieved in each implemented method by Schonlau et al. [9].

11

Table 1: Results produced by 6 methods to detect masquerades. Schonlau et al
Method Uniqueness Bayes one-step Markov Hybrid multistep Markov Compression Sequence-Match IPAM FRR (%) 1.4 6.7 3.2 5.0 3.7 2.7 FAR (%) 60.6 30.7 50.7 65.8 63.2 58.9 DR (%) 39.4 69.3 49.3 34.2 36.8 41.1

Looking at the results produced by Schonlau et al., we can clearly observe that the

Uniqueness method has the lowest False Rejection Rate (FRR), while lacking a
convincing False Acceptance Rate (FAR). Although the FRR value is relatively low, the chance of detecting malicious behaviour (DR) is 39.4%. Other recent work done in this field includes the work of Maxion and Townsend [10]. Using the Naïve Bayes classifier as their learning algorithm, they have produced encouraging results. The following table demonstrates their final results after testing their method against both the Schonlau et al. dataset (typically denoted as SEA) and the Greenberg [36] dataset.

Table 2: Results produced by implementing the Naive Bayes classifier. [10; 26]
Method Naïve Bayes (updating) Naïve Bayes (no-updating) Naïve Bayes (truncated) Naïve Bayes (enriched) FRR (%) 1.3 4.6 4.7 5.7 FAR (%) 38.5 33.8 29.1 17.9 DR (%) 61.5 66.2 70.9 82.1 Dataset SEA SEA Greenberg Greenberg

The hybrid command sequence (HCS) [37] model is another method used in order to detect malicious behaviour based on learning user command sequence. By using a genetic algorithm, the model profiles users based on recorded sessions. It evaluates users considering multiple command sequence fragments in a single session [37].

12

Other detection methods with regards to learning command sequences include the use of SVM (Support Vector Machine) [7; 38]. SVM is a pattern recognition classifier. It has shown significant results in terms of producing high detection rates [7; 38]. However the FRR rates are still considered to be high. The following table demonstrates a comprehensive statistical look at the results gained from implementing each of the mentioned methods with respect to a given dataset.

Table 3: A list of detection methods and their relative results
Method Naïve Bayes (updating) [10] Naïve Bayes (no-updating) [10] Uniqueness [9] Bayes one-step Markov [9] Hybrid multistep Markov [9] Compression [9] Sequence-Match [9] IPAM [9] SVM (RBF Kernel) [7] SVM (K-gram Kernel) [38] SVM (String Kernel) [38] HCS [37] Naïve Bayes (truncated) [26] Naïve Bayes (enriched) [26] FRR (%) 1.3 4.6 1.4 6.7 3.2 5.0 3.7 2.7 9.7 14.19 23.77 33.9 4.7 5.7 FAR (%) 38.5 33.8 60.6 30.7 50.7 65.8 63.2 58.9 19.9 10.39 2.6 1.4 29.1 17.9 DR (%) 61.5 66.2 39.4 69.3 49.3 34.2 36.8 41.1 80.1 89.61 97.40 98.6 70.9 82.1 Dataset SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA Greenberg Greenberg

These methods can be evaluated and ranked based on certain ranking functions [39; 9; 6; 26]. These ranking functions depend solely on certain predefined criteria.

Depending on the application, the significance of the errors produced by each detection method can vary. The ranking functions involved in determining the quality of a

detection method is discussed in more detail in further chapters.

13

The detection rates (DR) in most of the mentioned methods are very low. In cases where the detection rate is above 90% the FRR rates are above 20-30%. The challenge is to develop a system that would notably reduce the FAR and FRR rates. In this thesis, we propose a novel IDS termed as Continuous Authentication Based on Learning User Command Sequence (CABLUCS). Our approach consists of using the sequential sampling technique (a novel proposed evaluation technique for continuous

authentication [1]) in conjunction with the Naïve Bayes learning, applied to user
command sequence, to detect masquerade attacks while learning the behavioural tendencies of a given user. More precisely, the user's normal behaviours are recorded

and profiled using the Naïve Bayes classifier. The generated profile is used as their signature, while individuals whose behavioural tendency fails to match the given signature are identified as masqueraders.

14

Chapter 3: Continuous ntinuous Authentication Based on Learning User 3: Co Command Sequence (CABLUCS)
This Chapter constitutes the main contribution of this thesis. Here, we describe the design of our proposed Continuous Authentication Based on Learning User Command
Sequence (CABLUCS) scheme. The design space, system architecture, and data collection and processing methodologies are described in-depth. A typical intrusion scenario is also

introduced to assess the stated design.

3.1

Design Space

Designing an IDS involves a few challenges, including the methods involved in implementing data collectors, detectors and the different responses offered by the intrusion handlers. 3.1.1 Data Collection Data collection is an important part of the system. Sensors are placed in appropriate locations within the system, in order to listen to the system's activities and collect important data that will determine whether or not an intrusion has taken place. However, depending on the native system, this task can be rather difficult. Learning user command sequences will be a challenge in terms of being able to analyze this data in such a way as to produce the appropriate analysis of the active situation, which will then serve to take the proper actions. In UNIX based systems or other similar systems, one can take advantage of the input provided by the user within a shell (a separate software program that provides direct communication between the user and the operating system). This data is collected by the operating system and is usually defined
15

by the term shell history. Although datasets can be controversial in terms of privacy issues [40], in most cases, shell history is readily available. The shell history can be used to achieve a basic understanding of the user's common patterns. Typically, the command-line history is used when attempting to develop an IDS within a UNIX environment [26; 10; 41; 42]. In 1988, Dr. Saul Greenberg of the Department of Computer Science at the University of Calgary, has collected traces of 168 users using the UNIX C shell (csh). These traces correspond to command line data executed by each user and the data was intended to be used for research purposes. This dataset [36] was kindly granted to us and we have used it in this thesis. Running this dataset using a slight modification of the C shell (csh) command interpreter has enabled us to duplicate Dr. Greenberg's data collection method, which is crucial in the context of this thesis in order to accomplish our data collection objectives. Data collection in correspondence to different categories and groups of subjects is of importance. In order to relate different behaviours, it is important to have certain understanding of the given subjects, in which the data is being collected from. In this case, subjects were 168 unpaid volunteers, either students or employees of the University of Calgary. Subjects are divided by Greenberg into 4 different groups, which include: · Novice Programmers o This group consisted of individuals that had no prior programming experience, minimal knowledge of operating systems or UNIX-like command interpreters. These users spent the majority of their time

16

learning programming techniques and concepts, while familiarizing themselves with the system's facilities [36]. · Experienced Programmers o This group consisted of undergraduate Computer Science students completing their senior years. An understanding of the UNIX

environment and moderate knowledge of programming languages were expected from this group. [36]. · Computer Scientists o This group consisted of Computer Science graduates, including the members of the Faculty, researchers and past graduates from the Department of Computer Science [36]. · Non-programmers o This group consisted of members that mostly concentrated on the use of word processing applications. These members had little or no experience in programming languages or no knowledge of the UNIX environment [36]. It should be acknowledged that subjects were assigned as members of these groups given their current agenda at the University of Calgary. Therefore, the assumption that all members fit the given criteria of a particular group cannot be made thoroughly. From the months of February 1987 through June 1987, command line data was continuously collected on site, at Dr. Greenberg's laboratory. The collected data had a specific formatting that includes different annotation for explaining certain situations

17

that had incurred during data collection. These annotations along certain drawbacks to the collected data are discussed next. 3.1.2 Greenberg's Data Organization

The given data was organized through hierarchal folders. The base folder was named as unix_data. This base folder was composed of five subfolders. Four of these

subfolders corresponded to the groups of subjects, which themselves stored all command trace data of every subject (e.g. novice programmers, experienced programmers, computer scientists, and non-programmers). The fifth subfolder, showerrorcode, included a C program, which was designed to provide explanations for the error codes that were generated by users when executing certain command-lines. The following tables give a brief description of the attributes used in this dataset.

Table 4: Login session record
Code S E Description Start time of the login session End time of the login session Example S Thu Sep 20 14:23:32 2008 E Thu Sep 20 19:11:12 2008

Table 5: Command line record
Code C D Description The line entered by the user The current working directory Example C gedit document.txt& D /home/user/documents/

18

A H

The alias expansion of the previous command (if any) The line entered had a history expansion in it (True or Nil) The error detected in the line by csh (if any). A following letter and number code indicates the category and actual error type. The time the command line was executed by the command interpreter.

A NIL H NIL

X T

X NIL T Thu Sep 20 16:11:43 2008

3.1.3 Reproducing Greenberg's Greenberg's Methodology

In order to understand the data collection mechanism used by Greenberg et al. [36], we had to reproduce it using the software package that was kindly granted to us. C shell is a UNIX command interpreter that introduced new features such as aliases and command history. This justifies (in some sense) why Dr. Greenberg used this shell in order to collect command line history. In order to achieve a consistent duplication of work, we also use C shell to reproduce Dr. Greenberg's data collection mechanism. Although this tool may be

considered inadequate compared to more recent command interpreters, it is important to note that it serves its purpose in the case of collecting command line history. In order to reproduce Dr. Greenberg's data collection mechanism, a copy of the C shell source code was acquired from one of the Ubuntu's available repositories within our laboratory1.

1

The Distributed Applications and Broadband Network laboratory (DABNEL), Department of Computer Science, Ryerson University, Toronto, Canada

19

After making appropriate modifications to the C shell code provided by Greenberg et al. [36], sensors were placed accordingly in order to produce similar results. In addition to Dr. Greenberg's selection of attributes, a new attribute called

Time (denoted T) is introduced. This attribute is used to determine the system time
that the command line was executed by the command interpreter. Although Dr.

Greenberg had included the attributes S and E which denote the starting and the ending time of each session respectively, it appeared important for us to track the displacement time  of each command line. This is done in order to gain a better understanding of the user's intentions. The output of our modified csh scheme compared to that of the Greenberg dataset scheme is captured in Table 6.

Table 6: Greenberg's reproduced dataset sample
Greenberg Sample Data C ls D /home/XXXX/documents/ A ls ­la H NIL X NIL Reproduced Sample Data C ls D /home/XXXX/documents/ A ls ­la H NIL X NIL T Thu Sep 20 16:11:43 2008

Few drawbacks of the Greenberg's approach for data collection [36] are as follows. o Given the structure of the implementation, the "details of history directives were not recorded" [36]. However, there are indications of history being used and the command-line that was retrieved.

20

o It is important to acknowledge that the system was unable to capture all user activity. This mainly relates to software packages that are invoked by the user, where the command line is no longer used (e.g. emacs versus ls). o The command line executed does not necessarily determine the program that was actually invoked. Because of the many ways a program can be invoked (e.g. through an alias or a script). Although the records for the alias used are included in the dataset, the dataset fails to compensate for events where an alias is used to invoke another alias.

3.2

System Architecture

Similarly to many existing intrusion detection systems, our architecture is composed of sensors, detectors and intrusion handlers as depicted in Figure 1.

Sensor Log Alarm Pre-processing

User Input

Detector

DB

Figure 1: System architecture

21

The user input is captured by a sensor and restructured into a desired format (by undergoing a pre-processing step). The output of the pre-processing step is then placed in an incoming pool in the database and made ready for use. The detection mechanism (so-called Detector) will then deploy its intrinsic evaluation algorithm (in the form of a Naïve Bayes classifier) and a decision of an acceptance or a rejection will be made. If the input is rejected, the system will be alarmed and appropriate actions will be taken. Meantime, the system will keep maintaining a Log file that stores all the activities that have been running the system's operations. In case of an acceptance, the users will continue to use their concessions while the system will continue to authenticate their behaviours.

3.3

Implementation

This section describes the implementation of the Continuous Authentication Based on
Learning User Command Sequence (CABLUCS) design approach. The Greenberg dataset

[36] is used as the source for generating user profiles and user inputs. The Naïve Bayes classifier is used in conjunction with a new evaluation technique based on continuous authentication [1], namely the sequential sampling technique, to classify and evaluate a given user.
3.3.1 Data Structure

The Greenberg dataset is used as the source of data for this implementation, for training and testing purposes. The data is in its raw format. It consists of multiple folders, each representing a separate category of subjects. The categories are defined by each user's level of

22

experience or position (i.e. novice programmers, experienced programmers, computer scientists, and non-programmers) within the set of test subjects. For the purpose of our implementation, the category under which the user falls into is ignored. This

information may be useful for the implementations of certain IDSs. However, due to the nature of our approach, the user categories are deemed to be extraneous. A discussion on future works that can incorporate a primary and secondary levels of classification in a multi-category based user environment is given in the Conclusion Chapter. Each user is separated with a text file that contains the recorded command line history of the user. Each session is separated by a start and end time stamp.
Figure 2 illustrates a single user session.

23

S Wed Feb 18 16:37:25 1987 E Wed Feb 18 16:56:22 1987

C date D /user/srdg/xxxxx A NIL H NIL X NIL

C mail D /user/srdg/xxxxx A NIL H NIL X NIL

C p audio.mail D /user/srdg/xxxxx A page audio.mail H NIL

Figure 2: Greenberg's dataset user session sample

The filename for each user is constructed using the name of the category that the user is part of, and is concatenated with a numerical digit. An example is given in Table 7.

Table 7: Filename structure used in the dataset
User Category Computer Scientist Filenames scientist-1, scientist-2, ... , scientist-52

24

Experienced Programmers NonNon-Programmers Novice Programmers

experienced-1, experienced-2, ... , experienced-36 non-1, non-2, ... , non-25 novice-1, novice-2, ... , novice-55

In this dataset (Table 7), there are 168 users, among which 52 are Computer Scientists, 36 are Experienced Programmers, 25 are Non-Programmers and 55 are Novice Programmers.
3.3.2 PrePre-processing the Dataset

Due to the difficulty encountered in using the data in its current raw format, we had to restructure the data into a more manageable configuration. To this effect, the data was pre-processed and restructured into a relational database. This step is vital in order to maintain the relations between the command-lines, sessions, users and the user categories while this process is being completed. During the pre-processing

progression, the complete structure and integrity of the data was preserved and tested. The dataset was restructured into four database tables, referred to as user_types, users, sessions and data (as shown in Tables 8 to 14). o The user_types table (Table 8) is created in order to maintain the different user categories involved in the dataset. This table can also be used to merge other datasets of similar nature into Greenberg's dataset by introducing new sets of categories.

25

Table 8: User types (user_types) database table schema
Field Name utid Description This field maintains the id for each user category. This id is used in other tables to indicate which category a particular user belongs to. type This field defines a two character identification of a user type. (i.e. `cs' for Computer Scientist) description This field is used to maintain a brief description of each user type. It is used for the purpose of describing the types in English for individuals who are new to using the Greenberg dataset.

o The user_types table (Table 9) maintains the four records that directly correspond to the four different categories involved in the dataset.

26

Table 9: User types (user_types) database table sample data
utid 1 2 3 4 type cs ep np nv description Computer Scientist Experienced Programmer Non-Programmer Novice Programmer

These values in Table 9 are static. They are used as a reference point to indicate which category a user belongs to. o In order to maintain the identity of each user, the users' table (Table 10) is introduced. This table holds the basic records of all 168 users involved in the dataset. The uid field is used consistently throughout the database in order to maintain the data integrity.

Table 10: Users (users) database table schema
Field Name uid Description This field maintains the id for each user. This id is used in other tables to identify each user. utid This field is used to indicate which category a particular user belongs to within the user_type table. greenberg_name This field maintains the filename used in the Greenberg dataset that

27

corresponds to the given user. (i.e. scientist-1)

o The users table (Table 11) can also be used as a quick reference in order to distinguish between the different users while manually traversing through the database. This table plays a major role in keeping the integrity of the

restructured dataset. Manipulation of this table can compromise the integrity of the overall dataset and hence it is only used as a reference.

Table 11: Users (users) database table sample data
Uid 1 2 3 4 5 Utid 1 1 2 3 4 greenberg_name scientist-1 scientist-2 experienced-1 programmer-1 non-1

o Sessions were handled with two lines at the beginning of each of the sessions. Each session's start and end time was parsed and converted into a UNIX Timestamp, and then inserted into the sessions table (Table 12). It is important to notice that once the newly converted timestamp is made available, date, time calculations and manipulations become simpler.

28

Table 12: Sessions (sessions) database table schema
Field Name sid Description This field maintains the session id for each session within a user's stored data. This id is used in other tables to identify a session. uid This field is used to indicate the user that this session belongs to. start This field indicates the start time of a session. The values are kept in

UNIX Timestamp format. end This field indicates the start time of a session. The values are kept in

UNIX Timestamp format.

A UNIX Timestamp is an integer which indicates the number of seconds elapsed since midnight proleptic Coordinated Universal Time (UTC) of January 1, 1970 [43]. For example, the UNIX Timestamp of 540682645 is the equivalent of

February 18, 1987 at 3:37:25 pm. Every data item (command line) belongs to a particular session. Using the sessions table, we can immediately identify such session's start and end time/date as shown in Table 13.

29

Table 13: User sessions (sessions) database table sample data
sid 1 2 3 4 5 Uid 1 1 2 2 2 start 540682645 540742586 544203016 544424264 544449748 end 540683782 540744368 544203669 544438849 544459510

o The data table (along with its relations with the user_types, users and sessions tables) holds the entire dataset. It contains 303,628 data items (command-lines) from 168 different users. Its main fields are shown in Table 14.

Table 14: Data items (data) database table schema
Field Name did Description This field maintains the data id for each command line in the

Greenberg dataset. This id is used in other tables to identify a

command line. sid This field indicates which session this command line belongs to. Using this id we can indicate the start and end time of the session.

30

uid

This field is used to indicate the user that this command line

belongs to. order This field is used to maintain the order in which command lines in a session were entered. command This field contains the entire

command line. directory This field contains the current working directory in which the command line was executed. alias This field will indicate if the command line was in fact an alias to execute another program. It

will contain the command in which the alias is executing otherwise a NIL value will be given. history This field indicates whether or not History was used to execute this command line. error This field indicates if an error occurred during the executing of this command line.

31

o The data table (Table 15) encompasses the completely restructured dataset. In its new format, the data can be searched, manipulated and tested at a higher rate of efficiency. Furthermore, this higher rate of efficiency can also be

transferred onto any available platforms.

Table 15: Sample command lines in the 'data' table from User 1
did 1 2 3 4 sid uid order 1 1 1 2 1 1 1 1 1 2 3 1 command Date Mail p audio.mail Ls directory /user/srdg/xxxxx /user/srdg/xxxxx /user/srdg/xxxxx /user/srdg/xxxxx alias NIL NIL page audio.mail /bin/ls ­Fs history NIL NIL NIL NIL error NIL NIL NIL NIL

In order to gain a better understanding of the simple statistical features of the dataset, the insert_report table (Table 16) is introduced. This table gives a general

understanding on the number of command-lines, aliases, use of history and errors, which are involved in the dataset.

Table 16: Data report (insert_report) database table schema
Field Name id filename Description This field contains the report id. This field indicates the filename for which this report was generated. uid This field is used to indicate the

32

user that this report belongs to. commands This field indicates the number of command lines that were executed by the given user. history This field indicates the number of times the user resorted to using its history database. errors This field indicates the number of times an error occurred while a user executed its command lines. aliases This field indicates the number of times the user resorted to using an alias. lines This field indicates the number of lines in the filename.

Primarily, the generated reports (Table 17) allow us to test the integrity of the database by comparing the results to its raw counterparts. The general statistical understanding of the dataset will also allow us to plan our implementation in a more meaningful way. Our new knowledge of the data allows us to make better choices for the future. For example, based on this, we can determine which users will be beneficial for our testing purposes. Hence, if a user does not have sufficient amount of data items, then it

33

becomes difficult to process a complete set of tasks in most training environments. The reports will also be helpful to index users who have made use of their history, aliases or are disposed to make errors in their command lines or vice versa. This type of

information can become crucial in many research related tasks, particularly tasks that involve datasets being used in a controlled environment. The generated statistics for the Greenberg's dataset is made available in Appendix A: Generated Statistics for the Greenberg Dataset (Ordered by Commands).

Table 17: Sample reports in the 'insert_report' table from 5 different users
id 1 2 3 4 5 filename scientist-1 scientist-10 scientist-11 scientist-12 scientist-13 uid commands 1 2 3 4 5 1856 2024 205 2499 3593 history 54 77 0 53 357 errors 111 120 13 52 118 aliases 761 730 0 1162 204 lines 11792 12658 1380 15412 21988

3.3.3

Naïve Bayes Classifier

The Naïve Bayes classifier is used as a learning mechanism (Detector box of Figure 1) in order to understand the available sample data. The sample data is used in order to train the system and to familiarize it with possible outcomes. In principle, the available sample dataset will determine our

expectations in anticipating accurate results in detecting legitimate versus illegitimate

34

user sessions. The quality and the scale of available training data to the system will dictate our confidence in its results. The basic algorithm involved in recognizing different predefined classifications with the use of the Naïve Bayes classifier involves two procedures, namely the Naïve Bayes learning mechanism and the Naïve Bayes classification. We first train our

classifier with the available training data by using the Naïve Bayes learning mechanism. Once our learning procedure is completed, we classify new sets of input using our trained system. In order to proceed with the learning mechanism, we first determine certain attributes that directly influence the Naïve Bayes learning algorithm. As previously stated, the Naïve Bayes classifier is typically used to classify text documents such as electronic news articles [44; 45] or to classify spam, websites, documents, to name a few [23; 24]. But in the case of intrusion detection and profiling of legitimate users (that we deal with in this thesis), the classification must be achieved differently. Here, our approach for classification consists in considering the possible outcomes of an IDS, i.e. the detection of a masquerader (illegitimate user) or the detection of a legitimate user. Therefore, we determine that our target value is either

legitimate or illegitimate. Based on our training data, we can then determine the
characteristics of a legitimate user. Yet, we do not have a direct understanding of what characterizes an illegitimate user. Naturally if a legitimate user is not detected, then the user must be considered as illegitimate. However the Naïve Bayes classifier requires us to have certain understanding on all defined classifications in our dataset

35

prior to the detection. The absence of the training data for illegitimate users prevents us from gaining any understanding on the behavioural tendencies of a potential masquerader. Therefore, due to this shortcoming, we are obliged to practice the

common adaptation [10] of using any training data available to us that does not belong to the potential legitimate user and consider this as the training data for an illegitimate user. Certainly, such an assumption may have certain consequences that may skew the final classification results. Depending on the scale of the dataset, an immediate consequence based on this assumption is as follows. Due to the nature of the Naïve Bayes classifier algorithm, the number of incidences in any classification is of importance. For instance, in our dataset of 168 users, the available training data for one legitimate user compared to its illegitimate counterpart (167 users) can potentially disrupt the classification. The reasoning behind this claim lies solely in the nature of the Naïve Bayes classifier algorithm. Once the target values for the classification have been decided, we need to traverse through the training data and identify each element as a member of each target value. We then introduce the set  to represent all the possible target values  . In order to begin the learning process we also introduce the set . This set includes all the distinct words (command lines) that are available within the training data. The Vocabulary set can be regarded as our dataset dictionary. Two probability terms ( ) and ( | ) are used as the driving forces of the learning mechanism within the Naïve Bayes classifier. The term ( ) also known as the prior probability, represents the probability of the target value  occurring within

36

the available training data. The term ( | ) represents the conditional probability, that a randomly selected word (command-line) from the training data belonging to the target value  will be the word  . Once learning is completed, we can then classify new sets of input using the following Equation:  = argmax        ( | ) (4)

The procedural steps that are required to train (hence produce the profile of a user) and classify user command sequences using the Naïve Bayes classifier are discussed next.
3.3.3.1 Profiling Users

In order to test the legitimacy of a user session, we must first develop an understanding of what constitutes a legitimate user session. To this effect, it is required to make use of the available training data which corresponds to the normal working state of any particular user within the system, then, develop a profile that accurately represents such user. This can be achieved by using a Naïve Bayes learning mechanism. The detailed procedural steps involved in implementing our Naïve Bayes learning mechanism with our dataset, in order to create a set of independent and distinct user profiles, is described as follows. Our target value set  is defined as as:  = {, } (5)

37

As previously mentioned, the Naïve Bayes classifier requires the evaluation of the two probability terms ( ) and ( | ) with regards to the training data, in order to successfully classify the new input. To calculate ( ) with respect to our new target value set  , we evaluate the following: || =   


=   +   where  is our training data.   =
  ||

(6)

(7)   || (8)

  =

= 1 - ( )

We estimate the conditional probability ( | ) the same way as done in [20], i.e.

   =
where   ,

||

 

(9)

             and           

38

Having the preceding algorithms outlined, we can begin to document and profile every user within our training dataset. In order to implement a successful training session, it is required to have a sufficient amount of data for each user's profile. Lack of sufficient data will directly contribute to inaccurate results. Our initial confidence in the system relies on the quality and the availability of a rich representation of a user's behavioural tendencies in a form of a dataset. By investigating the general statistical information (See

Appendix A) regarding the available dataset, we can make certain decisions in regards to possible usability and suitability for each user's data and their potential candidacy for our training sessions. Retrieving the generated statistical information allows us to consider each user as a potential candidate for a training session. As a rule of thumb, we consider each user that has equal or greater than 1500 command lines in its data pool as such candidate. After applying this rule to our 168 user dataset, we witness that 75 of the users meet the requirements. These 75 users will be denoted as victims. We then use the available data

associated with each victim to build our profiles. To this effect, we have considered the first 1000 command lines of each victim as the source for our training data. Once the victims have been identified and their designated training data has been extracted, we proceed to gain a more detailed understanding on the overall commuted training data. Based on the final commuted training data, a vocabulary is built, which consists of all

39

distinct command lines used by all victims along with their number of occurrences. This vocabulary is used as a reference to build each victim's profile. Along with the vocabulary, each user's distinct command lines are identified and recorded in a separate table. This table contains all the distinct command lines

witnessed in the training data that belong to each user, along with their number of occurrences. In order to build a profile for every user, all command lines witnessed in the vocabulary are coupled with each user. A user profile consists of all the terms

(command-lines) within the vocabulary along with the probabilities  and  associated with the term with respect to the user. These probabilities are the representations of the results gained from evaluating the probability term   , where  represents each command line in the vocabulary.  indicates the probability that the given command line belongs to the user, where 

indicates the probability that the given command line belongs to other users within the training data. The vocabulary associated with our training data consisted of 17,982 terms (command lines). Therefore, each user's profile consists of the same number of terms along with their associated probabilities. After the completion of the learning

mechanism, 1,348,650 records were generated, representing the profile information for the 75 victims. The following table (Table 18) represents a small segment of a profile belonging to one of the victims.

40

Table 18: Small segment of a given profile
uid 78 78 78 78 78 78 78 78 78 78 78 78 78 Command Line ls fg e lpq bye myada e conq.a ada ­m conq.a a.out who purge rwho | more e queens.a  0.40874959414524 0.12359203459912 0.11171047003469 0.092699966731619 0.059431585951238 0.052302647212585 0.052302647212585 0.049926334299701 0.042797395561047 0.03329214390951 0.03329214390951 0.035668456822394 0.016657953519319  0.43698392003477 0.12143113580107 0.052685310845613 0.046794399410464 0.023954223940219 5.5574636180644e-07 5.5574636180644e-07 5.5574636180644e-07 0.018062312505071 0.040570040158232 0.0016122201956005 0.0043909520046327 5.5574636180644e-07

In Table 18, each command line is represented with its associated  and  . In the next section, we discuss the classification process involved in determining whether a command line is classified as  or  .
3.3.3.2 Classifying Classifying Users

Once we have established the probability values  and  for all the terms within the vocabulary with respect to each victim, we can proceed to classify new terms (command-lines). As previously mentioned, ideally  should represent the probability that the command line belongs to masqueraders. However, due to the absence of such data, it is required to build the probability from other sources. Although it may seem that the data is not authentic, it will nevertheless give a fair representation of what a legitimate user is not, which is the sole purpose of creating the counterpart classification to the target value . As a result of this assumption,
41

( ) will always dominate ( ), since the available data ratio is 74:1. Consequently, the probability term ( ) will dominate the Naïve Bayes classification, which in turn, will always classify inputs as  . In order to compensate for the dominating factor of the probability term ( ), we have to make the assumption that the likelihood of a masquerader will be equal to that of the legitimate user (victim). Thus, the consideration of the term ( ) can be eliminated from the classification process. As an example, given the sequence of command lines described in the set {,  ,  511,  , }, the Naïve Bayes classifier will determine the classification based on each command-line's predetermined probability. For

instance, if the probability distribution for an arbitrary user who has entered the command-lines within the given set is captured in Table 19, the Naïve Bayes classifier can be used to classify the set as whether it is  or  compared to the given sample user profile. The Naïve Bayes classifier makes the assumption that each element in the set is independent, which explains the naïve nature of the classifier.

Table 19: Probability distribution for an arbitrary user
Command Line ls cd classes cd cps511 pico deadlines exit  0.3121 0.3123 0.0422 0.0911 0.0332  0.4351 0.0922 0.0311 0.0022 0.0021

In this example, to determine the classification, we perform the following calculations:

42

 = argmax      ( | ) (10)  Pa v  = Plsv Pcd classesv  ... Pexitv  = (0.3121)(0.3123)(0.0422)(0.0911)(0.0332) = 1.24 × 10  (11)

  

  

Pa v  = Plsv Pcd classesv  ... Pexitv  = (0.4351)(0.0922)(0.0311)(0.0022)(0.0021) = 5.76 × 10 (12)

Since 5.76 × 10 < 1.24 × 10 , it is concluded that the set is classified as , i.e. the given set is recognized as legitimate input produced by the owner of our sample user profile. In our implementation, we use the Naïve Bayes classifier to classify each new input that is witnessed in our evaluation. However, the final decision to accept or reject a user is made by using the sequential sampling method, as described in the next section.
3.3.3.3 Continuous Authentication and the Sequential Sampling Technique

In order to appropriately evaluate the legitimacy of a particular user against a certain profile, an evaluation technique is required, where the crucial characteristics of the system are recognized. In an IDS, decisions can be made using any number of input values, regardless of the relevancy of the data in question. However, the accuracy of the decisions can be questionable. In order to maintain a certain confidence rate in our
43

system, we have adopted a recently proposed evaluation technique [1], which can be considered as a pioneer method for achieving continuous authentication based on learning biometrics data. In this thesis, this technique has been adapted for use in the case of user command sequence. The term continuous authentication [46; 47; 48] refers to a system where the authentication process is continuously active throughout the session. Typically, the behavioural patterns of the user are tested and evaluated against a predefined signature. The data rates for the input streams are unknown. Hence, the authenticity of the user is tested continuously as data becomes available. Due to the nature of our application, the input data flow rate is also unknown; hence an evaluation technique is required that can systematically adapt itself to the rate at which new input data are available. In order to evaluate the legitimacy of a user, we use the above-mentioned evaluation technique (sequential sampling technique [1]). This method has previously been used to evaluate the legitimacy of a user based on mouse dynamics. This is the first time that the method is being used for evaluating command line sequences. The sequential sampling technique is a dynamic sample size decision technique. Typically, a classical sampling is used to make the decision on the validity of a particular user [1]. In classical sampling, the sample size is predetermined and

decisions are only made when the end of the data collection procedure is met. The sequential sampling method was introduced to compensate for certain shortcomings of the classical sampling approach when dealing with continuous authentication. In a

44

classical sampling approach, a decision cannot be made, until there is a sufficient amount of data available. Hence, the system can be vulnerable during that time, and thus the system's TTA (Time-to-Alarm) can be significantly influenced by such a method. By using the sequential sampling method, the decision making is active

during data collection. Therefore, decisions can be made as new input is presented, and data collection and analysis can be done simultaneously [1]. In order to utilize the sequential sampling technique, it is required to first model a sampling plan which consists of three regions, namely, Accept, Reject and Continue. While the data is being collected continuously (as shown in Figure 3), the sample size is incremented accordingly until a decision is made.

Normalized Test Output

ACCEPT REGION

CONTINUE REGION

REJECT REGION

Number of Samples

Figure 3: General sampling plan
45

The sequential sampling technique will continuously test the null hypothesis as the number of test inputs increases. The amount of collected data within each iteration is based on a predetermined sample size, while the sample size itself is determined based on the application in which the sequential sampling technique is used. Depending on the application the sample size can range from collecting only a single data item to collecting a large set of data items. The sampling plan is developed in accordance with the following parameters [1]:  = acceptable type I error (false positive)  = acceptable type II error (false negative)  = lower threshold limit (as proportion)  = higher threshold limit (as proportion) A decision is only made when a normalized confidence rate value enters one of the decision regions (i.e. accept or reject). The acceptance and rejection lines are expressed as follows [1]:  =  +   = - + 

(13) (14)

where  is the normalized value of the confidence ratio computed for test number .

 =  ×





(15)

The parameters  ,  and  can be expressed as follows:

46

 =   =   = 

 

÷  ÷  ÷ 

 ( )  ( )

(16)

 

 ( )  ( )

(17)

 



 ( )

 ( )

(18)

It can be observed that equation 13 and 14, follow the basic principles of a straight line. Therefore, the variables  and  influence the distance between the two lines and  represents their slope [1].

47

Chapter 4: 4: Experimental Evaluation
This Chapter discusses the performance evaluation of the Continuous Authentication Based on Learning User Command Sequence (CABLUCS) scheme proposed in this thesis. This includes the evaluation approach, the experiments setup and operational aspects, and finally a description of the results obtained.

4.1

Challenges

The goal of a IDS is to accurately determine the legitimacy of a given user in a timely fashion. To this effect, several parameters can been predefined and then used to

measure the efficiency and accuracy of the system in terms of detection rate. In this thesis, we have considered the following parameters. The Detection Rate (DR): this is the rate at which the system can successfully detect an intrusion, in the event of a masquerade attack. · False Reject Rate (FRR) and False Accept Rate (FAR): Typically, two types of errors arose when decisions are made using experimental data in an IDS. symbolized as Type I and Type II errors, respectively o A Type I error implies that a reject decision has inappropriately been made, indicating that a false rejection has occurred. In this case, the rejection of a They are

·

legitimate user has happened. The FRR represents the percentage in which the system has falsely rejected a legitimate user. o A Type II error implies that an accept decision has inappropriately been made. This type of error indicates that a false acceptance has occurred. In this case, the acceptance of a masquerader as a legitimate user has happened. The FAR represents the percentage in which the system has falsely accepted a
48

masquerader as a legitimate user. It is also an indication of the rate at which the system has been compromised. o Time-to-Alarm (TTA) and Mean-Time-to-Alarm (MTTA): The accuracy of the detection mechanism is an important factor. However, if the decision is not made in a timely fashion, the system can be jeopardised. The TTA indicates the time elapsed until the masquerader was detected and the MTTA represents its responsiveness. In the design of an IDS, attempting to minimize the FRR, FAR, and the MTTA rates is a difficult task in the sense that these attributes are loosely related to each other. In order to reduce the MTTA value, decisions must be made faster. However, a quick decision may not be appropriate since this may lead to increased FAR and FRR. The challenge is thus to minimize all attributes while maintaining an efficient and operational system.

4.2

Evaluation Approach Approach and Setup

In order to setup the working environment for our experiments, we have acquired the LAMP software bundle. LAMP was installed on a Dell Workstation, Quad Xeon

Processors at 1.86 GHz with 8 GB RAM. LAMP is an open source software bundle that consists of Linux, Apache HTTP Server, MySQL relational database management system and PHP. This combination is generally used to create dynamic, database

driven, web applications. LAMP projects tend to be platform independent, hence once developed, they can be executed on most operating systems.

49

PHP is a scripting language with syntax similar to the C programming language, which is simple to deploy and execute. It is generally bundled for the use of dynamic web programming in relations with MySQL. The setup was configured to be sensitive to errors, while disabling caching and timeouts. Caching is typically used in PHP for the purpose of enhancing the processing time for the re-runs of the same code. Because we are interested in monitoring and differentiating the processing time (in seconds) of the different test cases, we have set this feature to `disabled'. PHP processing timeouts are usually set to 30 seconds, which is a reasonable time if we are concerned with executing a program that results in producing a simple web page. However, due to the nature of our experiment, we anticipate a much higher of processing time. Therefore, timeouts have also been disabled. In our experiments, we have also configured PHP warning and error settings, to make all potential warnings and errors visible within our apparatus. Along with PHP, the MySQL server and the Apache HTTP Server also utilize caching and other performance enhancing features as the system adapts itself to its environment. Therefore, for every test case, the servers are reset to their original As a result, certain tests could not be done

status and restarted accordingly.

simultaneously and longer testing times are required to test different parameters. This procedure is followed to maintain a fair comparison between the different test cases in comparative processing times (measured in seconds). These precautionary steps do not influence the FRR, FAR and MTTA values since these values do not incorporate time (in seconds) as their unit. The MTTA value is based on the number of actions required to make a decision, thus is not based on the processing time (in seconds) since different
50

workstations can produce different processing times while testing the same IDS, but in contrast, they will all output the same MTTA value. 4.2.1 Extracting the Data from Its Raw Format A PHP script was written in order to extract the data from its raw format into a MySQL database. The script traverses through the different folders looking for files that matched the required criteria. The criteria are set based on the provided

Greenberg dataset structure. Once the script has determined that a file meets the criteria, it detects the user and its type. Using the discovered information regarding the user, the script then creates a user record in the database, while documenting the related information. Once the user has been determined, the script traverses through its given data, scanning for user sessions. Each user session that is found is recorded in the database. The related information on this user is documented, which include the session's start and end time. A function is then used to convert the start and end time to a UNIX timestamp value. 4.2.2 Extracting the Command Line of a Session Once a session has been determined, the data collection proceeds to extract command lines relative to the given session. Each command line is extracted from the session and is given an order number, which represents the order in which the command line is seen within that session.

51

Certain string values (i.e. command-line, working directory and alias) are required to be character-escaped in order to meet certain PHP and MySQL compatibility issues. Due to the nature of the Greenberg dataset, each command line is known to be coupled with certain attributes (such as working directory, history, alias and error). In order to retrieve the attributes with respect to the command line, the script is parsed through each item and the necessary information is collected. An audit is also kept on the general statistical information of each user (i.e. the number of command lines, the errors, to name a few). Due to certain hidden characters within the Greenberg dataset, several string comparisons in each user session tended to fail. By trimming whitespaces and other unknown hidden characters, this issue has been fixed. Binary data comparison is used in all tests, in order to represent a perfect match. The script finally traverses through every session within every 168 users available in the Greenberg dataset and records their entire data, while maintaining complete data integrity. The resulting data in its new format is highly accessible, easy to use, flexible and customizable. 4.2.3 Deciding the Victims and Masqueraders After the above-mentioned data extraction, 31 masqueraders and 75 victims are decided by examining the general statistical information acquired. A PHP script is written in order to train the 75 profiles using our Naïve Bayes learning algorithm. The profiling process took approximately 5 hours to complete, yielding a total of 1,348,650 data items.

52

4.2.4 4.2.4 Calculating the Confidence Ratio In order to calculate the confidence ratio (CR), a set of command lines are tested against a given profile. For instance, considering the following test input set of five command-lines {,  ,  . , , }, we test each command line against user  's profile. Assuming that after each command line's independent

classification based on the Naïve Bayes classifier, 4 command lines are classified as legitimate and 1 is classified as illegitimate. In this example, our CR for the five
 

command lines belonging to user  is obtained as

× 100 = 80. Although initially it

may seem that the tested input set belongs to user  given a CR of 80%, this conclusion is based on only five command lines. If the next five command lines produces a CR of 5%, we can immediately sense that our original hypothesis may be faulty. 4.2.5 Determining the Legitimacy of Users We use the sequential sampling technique in order to complement the nature of continuous authentication systems. The sequential sampling technique allows us to make better decisions as the size of our input set increases based on a given sample size. Different applications require different sample sizes. The sequential sampling technique has been used to determine the legitimacy of users based on mouse dynamics, where sample sizes ranged from 25 to 100 [1]. The sample size used in a mouse dynamics application differs from that of a command-line based application. For instance, five command lines may differ in significance than five mouse gestures or clicks.

53

In order to use the sequential sampling technique, we have built different sampling plans that will allow us to test the legitimacy of a given user. To build a sampling plan, we have to determine the accept, continue and reject regions. In order to determine these regions, we have established the parameters involved in producing the two lines that separate the three regions. Depending on the application, the values of the required parameters are different. In order to determine suitable values for the required parameters  and  , which represent the lower and higher thresholds respectively, we have conducted a simple test. This test consisted in determining

values that will adjust the distance between the accept/reject lines in such a way that it will satisfy the overall range of our CR values. After several trials and error cases, three sampling plans are selected. recorded in Table 20. The values chosen for each sampling plan are

Table 20: Three selected sampling plans
Sampling Plan A B C  0.29 0.30 0.31  0.71 0.70 0.69  0.01 0.01 0.01  0.01 0.01 0.01

In Table 20,  and  represent the acceptable type I and the acceptable type II errors respectively. In all our test cases, the values for these two parameters are set to 0.01. The three selected sampling plans are illustrated in Figure 4, Figure 5 and Figure 6.

54

40 35 Normalized Confidence Ratio 30 25 20 Accept 15 10 5 0 0 -5 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Test Number Reject

Figure 4: Sampling Plan A (p1 = 0.29, p2 = 0.71, = 0.01,  = 0.01).

40 35 Normalized Confidence Ratio 30 25 20 Accept 15 10 5 0 0 -5 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Test Number Reject

Figure 5: Sampling Plan B (p1 = 0.30 p2 = 0.70, = 0.01,  = 0.01).

55

40 35 Normalized Confidence Ratio 30 25 20 Accept 15 10 5 0 0 -5 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Test Number Reject

Figure 6: Sampling Plan C (p1 = 0.31 p2 = 0.69, = 0.01,  = 0.01)

4.2.6 4.2.6 Calculating the MTTA, FAR, and FRR The  and  values determine the sensitivity of the system to decision making. As  is decremented, the continue region becomes smaller and the system becomes more susceptible to making faster decisions. Hence, Sampling Plan A is expected to have a lower Mean-Time-to-Alarm (MTTA) value than Sampling Plan B and C. As  is incremented, the MTTA value is expected to climb, hence, decisions are made slower. A lower MTTA does not always suggest a better system. The challenge is to lower the MTTA while making accurate decisions. In order to calculate the False Rejection Rate (FRR), every victim is tested against its own profile. As previously mentioned, the first 1,000 command lines of a user are utilized in order to build its relative profile. It is crucial not to use the same

56

data source as the new input for testing purposes; otherwise the results will not carry great weight in our conclusion. The first command-line used to test the user against its own profile is the 1,001st element in the given user's data pool. There are 75 victims in total, hence, 75 tests are completed for each sampling plan in order to calculate the relative FRR. Calculating the FAR value involves testing all masqueraders against all victims for each sampling plan. All 31 masqueraders are contributing in attacking each of the 75 victims. The expected results in this test are rejections. In the case where an acceptance has been issued to a masquerader, the result is recorded and the FAR value is updated accordingly. A maximum TTA of 1000 command-lines is set in order to compensate for system halts. System halts can occur when a decision cannot be made using the available input data against the sampling plan. This can occur if the normalized confidence ratio continues to be in the continue region of the sampling plan without penetrating the final decision regions (i.e. accept or reject). System halts can also be triggered as a result of insufficient input data that can cause the prevention of a decision from being made. 4.2.7 4.2.7 Comparing a User against a Given Profile Profile In order to utilize the sequential sampling technique, for each sampling plan, a sample size must be set before any testing can begin. The sample size determines the number of command lines to sample before attempting to make a decision. For instance, a sample size of 5 means that the iterator will sample and accumulate every 5 command57

lines as they are made available. Every iteration is recognized by a number, which is denoted as a test number. With a sample size of 5 command-lines, test number 3 indicates that 15 command lines have been collected and tested. A PHP script is written in order to simulate the testing process of a user against a given profile. This script incorporates the sequential sampling technique in order to make decisions on the legitimacy of the test user. The three different sampling plans are tested using different sample sizes, while the results are recorded in two different MySQL tables. The engine_report MySQL table (Table 21) is used to detail the final results made by the algorithm as a user is tested against a profile.

Table 21: engine_report MySQL table schema
Field Name id Description This field is used as the primary key for this table. It is used to identify the given report (record). uid_input This field identifies the user that is being tested against a given profile. uid_profile iteration This field indicates the user-profile. This field indicates the number of iterations decision. decision_expected This field indicates the expected decision to be made. (i.e. Accept if required to make a

58

uid_input is equal to uid_profile)
decisioin_made This field indicates the final decision made after the testing was completed. seconds This field indicates the number of seconds required to make a decision. sample_size This field indicates the sample size used in the sequential sampling technique. num_commands This field indicates the number of command-lines that were required in order to make a decision. num_trained_items This field indicates the number of command-lines that were used to train the profile. In all of the tested cases, 1,000. p1 This field indicates the lower this number remained at

threshold used in the sampling plan. p2 This field indicates the higher

threshold used in the sampling plan. alpha This field represents the acceptable type I error (false positive) beta This field represents the acceptable
59

type II error (false negative) max_iterations This field indicates the maximum allowed number of iterations.

The details of each decision are recorded in the engine_output MySQL table (Table 22). This table outlined the successive progression of the decision making process of the sequential sampling technique (as shown in Table 23 and Table 24).

Table 22: engine_output MySQL table schema
Field Name report_id report_id Description This field identifies the report that this record belongs to. test_num This field indicates the test number for the given iteration. (i.e. 1,2,3..) accept_limit This field represents the accept

value, given the test number,p1, p2, alpha and beta. reject_limit This field represents the reject value, given the test number, p1, p2, alpha and beta. normalized_cr This field represents the normalized confidence ratio after testing n*N command lines, where n is the test

60

number and N is the sample size. cr This field represents the confidence ratio after testing n*N command lines, where n is the test number and N is the sample size. num_commands This field represents the number of command-lines used to calculate the confidence ratio.

Table 23: Details of the final results made by using CABLUCS
Id Uid Input Uid Profile Iteration Decision Expected Decision Made Seconds Sample Size Number of Commands Number of Trained Commands P1 P2 Alpha Beta Max Iteration

1

86

86

12

Accept

Accept

20

5

55

1000

0.3

0.7

0.01

0.01

1000

2

30

30

67

Accept

Reject

138

5

330

1000

0.3

0.7

0.01

0.01

1000

3

89

55

6

Reject

Reject

9

3

15

1000

0.31

0.69

0.01

0.01

1000

4

24

24

9

Accept

Accept

77

20

160

1000

0.29

0.71

0.01

0.01

1000

Table 24: Successive progression of the decision making process
Report id Test Number Accept Limit Reject Limit Normalized CR CR Number of Commands

3 3 3 3 3

1 2 3 4 5

3.3715216902596 3.8715216902596 4.3715216902596 4.8715216902596 5.3715216902596

-2.3715216902596 -1.8715216902596 -1.3715216902596 -0.8715216902596 -0.3715216902596

0 0 0 0 0

0 0 0 0 0

3 6 9 12 15

61

3

6

5.8715216902596

0.12847830974036

0

0

18

4.2.

Performance Results

The following table describes the annotations used to describe each completed test. Here, TID is used to indicate the given test. The list of prepared sampling plans and tests are shown in Table 25.

Table 25: List of prepared sampling plans and tests
TID 1A 1R 2A 2R 3A 3R 4A 5A 6A 7A 8A 4R 9A 9R 10A 10R 11A 11R 12A 12R 13A 13R 14R 15R 16R 17R 18R 19R Sample Size 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 10 10 10 10 10 10 15 15 15 20 20 20 Sampling Plan A A B B C B A A B B C C A A B B C C A B C A B C  0.29 0.29 0.30 0.30 0.31 0.31 0.32 0.33 0.34 0.35 0.29 0.29 0.30 0.30 0.31 0.31 0.29 0.29 0.30 0.30 0.31 0.31 0.29 0.30 0.31 0.29 0.30 0.31
62

 0.71 0.71 0.70 0.70 0.69 0.69 0.68 0.67 0.66 0.65 0.71 0.71 0.70 0.70 0.69 0.69 0.71 0.71 0.70 0.70 0.69 0.69 0.71 0.70 0.69 0.71 0.70 0.69

 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

Figure 7 and Figure 8 illustrate a visualization of the sequential sampling technique

using actual data taken from our experiment. Figure 7 shows a user's test input on its own profile based on TID 9A. TID values with the subscript letter A, represent a test case where the expected decision is an acceptance, and values with the subscript letter

R, represent a test case where the expected decision is a rejection.

40 35 Normalized Confidence Ratio 30 25 20 15 10 5 0 0 -5 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Test Number Accept Reject User 1

Figure 7: User 1's new input tested on User 1's profile

The user's normalized confidence ratio (CR) navigates through the continue region, until a decision has been made. We can witness a decision being made at test number

55, where the user's normalized confidence ratio crosses the acceptance line and hence
the user is accepted. This is an example of a successful trial. Figure 8 demonstrates a test (TID 9R) on the same profile, however this time, the profile does not belong to the

63

user. By looking at this figure, we can witness that the system comes close to detecting the masquerader near test number 24, however the confidence ratio climbs as new data is made available. Eventually, this user is rejected at test number 70, where the

confidence ratio penetrates the reject region.

40 35 Normalized Confidence Ratio 30 25 20 15 10 5 0 0 -5 5 10 15 20 25 30 35 40 45 50 55 60 65 70 Test Number Accept Reject User 2

Figure 8: User 2's input tested on User 1's profile
During the course of the system's analysis of the user, we can witness that the decision can go either way. Depending on the sensitivity of the system, decisions can be altered dramatically. For instance, if the continue region was reduced in size, a faster decision would have been made at test number 24, which is more than 50% faster than the latter. The challenge lies in determining a sampling plan that will be ideal to the given application. It is important to mention that a sampling plan must be built, such that it compensates for the entire training range. The following table (Table 26) illustrates the decision making process of the

64

system for the previous two examples.

Table 26: Decision making process of the sequential sampling technique
Test Number Number of Commands Accept Limit Reject Limit User 1's Normalized CR User 2's Normalized CR Decision

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38

5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180 185 190

3.211632 3.711632 4.211632 4.711632 5.211632 5.711632 6.211632 6.711632 7.211632 7.711632 8.211632 8.711632 9.211632 9.711632 10.21163 10.71163 11.21163 11.71163 12.21163 12.71163 13.21163 13.71163 14.21163 14.71163 15.21163 15.71163 16.21163 16.71163 17.21163 17.71163 18.21163 18.71163 19.21163 19.71163 20.21163 20.71163 21.21163 21.71163

-2.21163 -1.71163 -1.21163 -0.71163 -0.21163 0.288368 0.788368 1.288368 1.788368 2.288368 2.788368 3.288368 3.788368 4.288368 4.788368 5.288368 5.788368 6.288368 6.788368 7.288368 7.788368 8.288368 8.788368 9.288368 9.788368 10.28837 10.78837 11.28837 11.78837 12.28837 12.78837 13.28837 13.78837 14.28837 14.78837 15.28837 15.78837 16.28837 65

0.5 1.111111 1.384615 2 2.222222 2.7 3.333333 4.173913 4.695652 5 6.233333 6.75 6.685714 7.388889 8.076923 8.8 9.536585 9.857143 10.40476 11.16279 12.13333 13.29167 13.26923 13.47368 13.75 14.06557 14.12308 14 14.5 15 15.5 16.8 17.85882 18.13333 19.15789 19.8 19.38095 19.53271

0.666667 0.8 1.285714 1.333333 1.5 1.8 2.333333 2.666667 3 3.846154 5.133333 6 5.473684 6 6.25 6.4 6.925926 6.967742 7.71875 8.235294 8.4 8.555556 9.684211 10.2 11.36364 11.86957 12.375 12.62745 13.07843 13.58491 14.03774 14.22222 15 15.45455 15.90909 16.71429 17.52632 18.34483

Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue

39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70

195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350

22.21163 22.71163 23.21163 23.71163 24.21163 24.71163 25.21163 25.71163 26.21163 26.71163 27.21163 27.71163 28.21163 28.71163 29.21163 29.71163 30.21163 30.71163 31.21163 31.71163 32.21163 32.71163 33.21163 33.71163 34.21163 34.71163 35.21163 35.71163 36.21163 36.71163 37.21163 37.71163

16.78837 17.28837 17.78837 18.28837 18.78837 19.28837 19.78837 20.28837 20.78837 21.28837 21.78837 22.28837 22.78837 23.28837 23.78837 24.28837 24.78837 25.28837 25.78837 26.28837 26.78837 27.28837 27.78837 28.28837 28.78837 29.28837 29.78837 30.28837 30.78837 31.28837 31.78837 32.28837

19.5 19.82301 20.32479 21.52066 21.5 21.824 22.14286 22.64063 22.78788 22.75556 23.8 25.17241 26.18 27.02632 28.03871 29.3625 30.21605

19.16949 20 20.5 21 21.5 21.66154 22.16418 23.33333 23.84058 25.01408 25.18056 25 26.17105 26 26.5 27.65854 28.15476 28.32941 28.5 29 30.17045 30.66667 31.82609 32.66667 32.84043 33.68421 33.85417 34.02062 33.5 32.69231 31.94444 31.81818

Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Accept User 1 Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Continue Reject User 2

The two types of tests that were conducted in this experiment include the testing for rejection and the testing for acceptance. Acceptance tests involved the testing of a user against its own profile. The purpose of this test is to calculate the FRR of our intrusion detection system. Given that there are 75 victims, this type of testing did not require vast amount of computational time. Depending on the sample size, the acceptance tests
66

did not require more than an hour to complete a single trial on our workstation. However, in the case of a rejection test, 31 masqueraders are used as input to 75 profiles. Depending on the sample size, this type of test can take up to 10 hours to complete a single trial on our workstation. The purpose of a rejection test is to

calculate the FAR of our intrusion detection system. The following table (Table 27) illustrates the final results that we have achieved by implementing a Naïve Bayes learning mechanism in conjunction with the decision making of the sequential sampling technique.

Table 27: Results achieved based on different parameters and sampling sizes
Test ID Sample Size N (Actions)     FAR (%) FRR (%) DR (%) Min TTA (Commands) Max TTA (Actions) Mean TTA (Actions) CPU Usage (Seconds)

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

3 3 3 3 3 3 3 3 3 5 5 5 10 10 10 15 15 15 20 20 20

0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.29 0.30 0.31 0.29 0.30 0.31 0.29 0.30 0.31 0.30 0.31 0.29

0.73 0.72 0.71 0.70 0.69 0.68 0.67 0.66 0.65 0.71 0.70 0.69 0.71 0.70 0.69 0.71 0.70 0.69 0.70 0.69 0.71

0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

03.225 03.183 02.968 02.882 02.882 02.796 02.581 02.581 02.581 02.237 02.237 02.237 01.464 01.421 01.421 -

12.00 12.00 12.00 12.00 12.00 12.00 12.00 12.00 12.00 12.00 13.33 13.33 13.33 12.00 12.00 12.00 13.33 13.33 13.33

96.78 96.82 97.03 97.12 97.12 97.20 97.42 97.42 97.42 97.76 97.76 97.76 98.41 98.45 98.41

12 12 15 15 15 18 18 18 21 25 25 25 50 50 50 -

183 186 198 237 252 252 300 546 552 555 575 575 910 910 920 -

16.28 16.61 19.35 20.09 20.60 23.63 24.46 25.25 29.13 34.26 35.17 36.16 67.94 70.22 72.59 -

6.97 7.20 7.35 10.42 10.47 10.59 17.61 18.10 18.75 -

Looking at the results, a few patterns are visible. We can witness that as the sample size increases the FAR rate is decreased. A larger sample size allows the system to gain a

better understanding of the given user, before making a decision. Figure 9 illustrates
67

the three different sampling plans used in testing the system. We can clearly notice that as the sample size is increased, the FAR rate decreases.

10 Sample Size

5

3

0

0.5

1

1.5 FAR (%)

2

2.5

3

p1=0.31,p2=0.69

p1=0.30,p2=0.70

p1=0.29, p2=0.71

Figure 9: Analysing the system's FAR rate versus the sample size
Figure 10 illustrates the analysis of the FRR rate as the sample size increases. We can
witness that as the sample size increases the FRR rate also increased.

68

10 Sample Size

5

3

0

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15

FRR (%) p1=0.31,p2=0.69 p1=0.30,p2=0.70 p1=0.29, p2=0.71

Figure 10: Analysing the system's FRR rate versus the sample size

Figure 11 illustrates the pattern of the MTTA value as the sample size is increased. It
is observed that the Time-to-Alarm (TTA) is increased as the sample size is increased.
75 65 55 45 35 25 15 3 5 Sample Size p1=0.29, p2=0.71 p1=0.30, p2=0.71 p1=0.31, p2=0.69 10

Figure 11: Analysis of the system's MTTA value as the sample size is increased

Figure 12 shows a closer view at the effects of the sample size on the MTTA value. We
69

MTTA (Number of Commands)

can observed that depending on the sampling plan, the MTTA is also affected. This is understandable due to the fact that as the lower threshold is increased within the sampling plan, the continue region is also increased in size. Therefore, the time spent in the continue region is increased.

10 Sample Size

5

3

0

5

10 15 20 25 30 35 40 45 50 55 60 65 70 75 MTTA (Number of Commands)

p1=0.31,p2=0.69

p1=0.30,p2=0.70

p1=0.29, p2=0.71

Figure 12: Analysing the system's MTTA value versus the sample size

Figure 13 illustrates the pattern between the CPU usages and the different sample
sizes. Naturally, the CPU usage follows the same pattern as the MTTA value.

Depending on the workstation used, the values in seconds are different. However, the illustrated pattern should remain the same.

70

10 Sample Size

5

3

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CPU Usage (Seconds) p1=0.31,p2=0.69 p1=0.30,p2=0.70 p1=0.29, p2=0.71

Figure 13: Analyzing the systems CPU Usage versus the sample size

A brief discussion on the given results will be given in the next section.

4.3.

Discussion

As stated earlier, it is the goal of any intrusion detection system to reduce the FAR, FRR and the MTTA values. The challenge lies in finding suitable approaches that can accomplish this task in an efficient way. Looking at our results, we can witness a common trend, the more accurate our results are, the more time is consumed. Figure
14, Figure 15 and Figure 16 show the relationship between the FRR and the FAR value

in three different sampling plans, using three different sample sizes.

71

3 2.8 2.6 2.4 FAR (%) 2.2 2 1.8 1.6 1.4 1.2 1 11.5 12 12.5 FRR (%) 13 13.5 3 5 10

Figure 14: Relationship between sample size and FRR/FAR using sampling plan A
3 2.8 2.6 2.4 FAR (%) 2.2 2 1.8 1.6 1.4 1.2 1 11.5 12 12.5 FRR (%) 13 13.5 3 5 10

Figure 15: Relationship between sample size and FRR/FAR using sampling plan B

72

3 2.8 2.6 2.4 FAR (%) 2.2 2 1.8 1.6 1.4 1.2 1 11.5 12 12.5 FRR (%) 13 13.5 3 5 10

Figure 16: Relationship between sample size and FRR/FAR using sampling plan C
It is important to acknowledge that the data used to calculate the FRR rate as opposed to the FAR rate was minimal. In order to calculate the FRR rate, 75 cases were tested, whereas the FAR rate was calculated by testing 3,235 cases. The FRR rate may become quite different if a more extensive testing procedure is applied. The results show a promising range of detection rates. Depending on the sampling plan and sample size, the detection rate ranged from 96.78% to 98.41%. These values represent a promising system compared to other proposed intrusion detection systems [15]. Although there are not many literatures in the intrusion

detection field where the Greenberg dataset has been used used, comparing these results solely on the basis of the outcome achieved, we can confirm that the results produced are quite competitive. Depending on the ranking function used to evaluate the integrity of the system, the ranking results can vary. Hence, the emphasis can be set either on type I errors or
73

type II errors.

The following ranking function [10] represents the foundation for

determining such emphasis.  = () + () (19)

If there is no preference to the type of error considered, the  and  attributes can be ignored, i.e. set to 1. Therefore, in order to calculate the cost of a given detection algorithm, we add the FAR and FRR rates. Table 28 shows comparison comparative study of numerous detection methods based on a ranking function that does not emphasize on a particular type of error.

Table 28: Result comparison based on Cost = (FAR) + (FRR)
Method N. Bayes Classifier N. Bayes Classifier CABLUCS CABLUCS CABLUCS Customized Grammars Customized Grammars Self Signature with Uniqueness Self Signature with Uniqueness Boosting Decision Stumps SVM ECM N. Bayes (no updating) N. Bayes (updating) Uniqueness IPAM Hybrid Markov Cost 33.8 23.6 14.97 14.24 14.75 14.1 30.6 14.6 33.9 20.9 29.6 30.2 38.4 39.8 62 61.3 53.9 DR (%) 70.9 82.1 97.3 97.76 98.45 93.1 71.0 91.3 67.5 89.2 80.1 72.3 66.2 61.5 39.4 41.4 49.3 FAR (%) 29.1 17.9 2.97 2.24 1.42 6.9 29.0 8.7 32.5 10.8 19.9 27.7 33.8 38.5 60.6 58.6 50.7
74

FRR (%) 4.7 5.7 12 12 13.33 7.2 1.6 5.9 1.4 10.1 9.7 2.5 4.6 1.3 1.4 2.7 3.2

Sample Size 10 10 3 5 10 -

Trained Data 1000 1000 1000 1000 1000 Greenberg Greenberg Greenberg Greenberg Greenberg SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA

Sequence match Compression Bayes one-step Markov

66.9 70.8 37.4

36.8 34.2 69.3

63.2 65.8 30.7

3.7 5.0 6.7

-

-

SEA SEA SEA

Using this ranking function, we can witness that our system ranks 1st in the detection methods that use the Greenberg dataset, and ranks 2nd overall, regardless of the dataset used.

Table 29: Result ranking comparison based on Cost = (FAR) + (FRR)
Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Method Customized Grammars CABLUCS Self Signature with Uniqueness CABLUCS CABLUCS S Boosting Decision Stumps Naïve Bayes Classifier SVM ECM Customized Grammars Naïve Bayes Classifier Self Signature with Uniqueness Bayes one-step Markov Naïve Bayes (no updating) Naïve Bayes (updating) Hybrid Markov IPAM Uniqueness Sequence match Compression Cost 14.1 14.24 14.6 14.75 14.97 20.9 23.6 29.6 30.2 30.6 33.8 33.9 37.4 38.4 39.8 53.9 61.3 62 66.9 70.8 Dataset SEA Greenberg SEA Greenberg Greenberg SEA Greenberg SEA SEA SEA Greenberg SEA SEA SEA SEA SEA SEA SEA SEA SEA

The SEA dataset is the work of Schonlau et al. [9], which is a more commonly used benchmark dataset. In their work, the emphasis was set based on achieving a 1% FRR rate [10]. After the completion of their tests, the only successful method to achieve the given FRR rate was Uniqueness. In order to rank Uniqueness as the best detection

75

method based on the given criteria, the  (type II error) emphasis was set to 6. Table 30 shows the results in comparison to the Schonlau et al. ranking function.

Table 30: Result comparison based on Cost = (FAR) + 6(FRR)
Method N. Bayes Classifier Naïve Bayes Classifier CABLUCS CABLUCS CABLUCS Customized Grammars Customized Grammars Self Signature with Uniqueness Self Signature with Uniqueness Boosting Decision Stumps SVM ECM N. Bayes (no updating) N. Bayes (updating) Uniqueness IPAM Hybrid Markov Sequence match Compression Bayes one-step Markov Cost 57.3 52.1 74.97 74.24 81.4 14.1 30.6 14.6 33.9 20.9 29.6 30.2 38.4 39.8 62.0 61.3 53.9 66.9 70.8 37.4 DR (%) 70.9 82.1 97.3 97.76 98.45 93.1 71.0 91.3 67.5 89.2 80.1 72.3 66.2 61.5 39.4 41.4 49.3 36.8 34.2 69.3 FAR (%) 29.1 17.9 2.97 2.24 1.42 6.9 29.0 8.7 32.5 10.8 19.9 27.7 33.8 38.5 60.6 58.6 50.7 63.2 65.8 30.7 FRR (%) 4.7 5.7 12 12 13.33 7.2 1.6 5.9 1.4 10.1 9.7 2.5 4.6 1.3 1.4 2.7 3.2 3.7 5.0 6.7 Sample Size 10 10 3 5 10 Trained Dataset Dataset 1000 1000 1000 1000 1000 Greenberg Greenberg Greenberg Greenberg Greenberg SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA

Table 31 shows the ranking comparison of the detection methods based on the new

criteria. We can witness that the results have dramatically changed given that the emphasis is now based on the type II error. Considering the relatively high FRR rate of

76

our system in comparison to other mentioned detection methods, it comes as no surprise that our system is now ranked the lowest.

Table 31: Result ranking comparison based on Cost = (FAR) + 6(FRR)
Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Method Customized Grammars Self Signature with Uniqueness Boosting Decision Stumps SVM ECM Customized Grammars Self Signature with Uniqueness Bayes one-step Markov N. Bayes (no updating) N. Bayes (updating) Naïve Bayes Classifier Hybrid Markov N. Bayes Classifier IPAM Uniqueness Sequence match Compression CABLUCS CABLUCS CABLUCS Cost 14.1 14.6 20.9 29.6 30.2 30.6 33.9 37.4 38.4 39.8 52.1 53.9 57.3 61.3 62 66.9 70.8 74.24 74.97 81.4 Dataset SEA SEA SEA SEA SEA SEA SEA SEA SEA SEA Greenberg SEA Greenberg SEA SEA SEA SEA Greenberg Greenberg Greenberg

Depending on the favouritism of the ranking function, each detection method can be ranked and used differently, in contingent with the application in question. It can be said that the FAR value of our system shows a more accurate representation of our detection method than the FRR rate. As previously stated, the FAR value is

determined after numerous testing for each given trial (3,235 cases per trial), while the FRR value is tested using only 75 cases per trial. Hence, a single incident of a false rejection can significantly skew the overall results.

77

Looking at the cases where the false rejections were witnessed, we can gain a better understanding for the reasoning behind our high FRR rate.
Table 32 shows

the 13 profiles that were consistently rejected throughout 21 different test cases. Our high FRR rate is based on 17.33% of our victims that have an average probability of 72.16% in producing a false rejection. Further investigation of the relative sampling plans and the sequential progression in the decision making process of these 13 profiles can demonstrate the reasoning for such consistently high rejection rates.

Table 32 :Users that were falsely rejected in 21 different test cases
Uid 10 13 19 20 30 40 43 45 71 126 128 129 154 157 FRR (%) 100 4.76 100 33.33 76.19 100 100 100 52.38 14.29 33.33 76.19 47.62 100

78

Chapter Chapter 5: Conclusion
In this thesis, we have proposed a hybrid approach based on learning user command sequence for detecting classical masquerade attacks. Our approach (so-called CABLUCS) consisted of two methods, the Naïve Bayes classifier and the sequential sampling technique, used to enhance the capability of a continuous authentication mechanism within an intrusion detection system. In addition, a newly structured dataset was formed using the Greenberg raw dataset, in such a way as to maximize its usability and efficiency. Using this newly structured dataset, a general statistical

analysis of the given data was produced, which can be quite helpful to future researchers using the Greenberg dataset. Through experimental evaluation, we found that our scheme achieves a significant improvement over the Maxion and Townsend

scheme in terms of accuracy detection.
We believe that this performance is largely attributed to the contribution of the part of our approach that deal with sequential sampling technique for continuous authentication, which constitutes the core of the decision making regarding the legitimacy of a user.

Departing from the results achieved in this thesis, we can infer that our
technique can provide significant advancement to the field of masquerade detection, by opening the possibility of exploring the method to other areas of anomaly detection. This can be classified as future work.

79

Appendix A: A: Generated Statistics for the Greenberg Dataset (Ordered by Commands)
User scientistscientist -36 scientistscientist -52 scientistscientist -42 experiencedexperienced -7 scientistscientist -18 nonnon -4 scientistscientist -40 experiencedexperienced -20 scientistscientist -4 experiencedexperienced -35 scientistscientist -37 novicenovice -46 scientistscientist -9 nonnon -20 experiencedexperienced -5 experiencedexperienced-28 scientistscientist -27 experiencedexperienced -4 scientistscientist -38 experiencedexperienced -1 scientistscientist -13 scientistscientist -25 scientistscientist -14 novicenovice -19 scientistscientist -23 experiencedexperienced -24 novicenovice -36 novicenovice -14 novicenovice -33 scientistscientist -43 scientistscientist -2 experiencedexperienced -8 scientistscientist -19 experiencedexperienced -22 scientistscientist -20 scientistscientist -29 scientistscientist -34 scientistscientist -46 scientistscientist -12 novicenovice -1 novicenovice -12 experiencedexperienced-21 experiencedexperienced -9 experiencedexperienced -17 novicenovice-3 novicenovice -41 experiencedexperienced -23 novicenovice -28 experiencedexperienced -29 novicenovice -23 scientistscientist -30 novicenovice -31 novicenovice -25 scientistscientist -41 experiencedexperienced -30 scientistscientist -10 novicenovice -37 Uid 20 15 10 55 48 106 38 53 23 78 32 146 26 99 62 74 37 75 24 80 42 30 47 164 16 86 142 126 122 39 25 68 43 73 45 17 52 3 28 151 118 59 71 79 150 115 81 136 84 129 40 157 155 49 66 27 154 Commands 12056 7705 6068 5857 5584 5050 4605 4556 4507 4272 4187 4163 4067 4042 4015 3893 3817 3776 3775 3714 3593 3508 3433 3401 3360 3331 3213 3194 3127 3106 2954 2930 2831 2814 2697 2683 2639 2551 2499 2457 2436 2394 2351 2343 2337 2317 2306 2221 2214 2138 2129 2073 2066 2037 2028 2024 1949 History 488 231 6 67 6 18 0 435 178 28 121 112 224 165 35 78 102 2 48 174 357 7 178 7 52 222 0 0 0 0 236 67 106 325 74 20 15 80 53 37 0 157 86 0 0 0 189 0 59 0 186 0 2 0 82 77 0 Errors 566 299 644 612 240 161 98 370 320 169 83 372 65 124 222 60 85 123 168 298 118 122 183 363 135 228 137 208 106 101 149 265 112 122 189 243 88 110 52 213 210 83 136 144 93 51 119 120 133 72 123 102 217 36 110 120 57 Aliases 3161 717 3243 2926 1816 3296 628 1646 789 2504 1866 1909 665 2122 910 2516 0 1329 1312 1906 204 379 2 0 481 1456 0 0 0 546 1656 625 1330 560 804 530 910 495 1162 1381 0 974 502 102 0 1000 1004 0 1072 0 409 18 0 0 624 730 0 Lines 73434 47280 37598 35896 34258 30830 29020 28054 27992 26290 25604 26080 25424 24798 25220 25116 23344 23258 23172 22830 21988 22706 21404 20816 21454 20440 19840 19786 19556 19066 18514 18114 17560 17478 17080 16632 16648 16480 15412 14960 16366 14762 14500 14396 15400 14244 14214 13816 13566 13186 13492 12692 13070 13036 12686 12658 12044

80

novicenovice -4 novicenovice -22 experiencedexperienced -34 scientistscientist -1 nonnon -11 novicenovice -8 experiencedexperienced -14 experiencedexperienced -19 experiencedexperienced -12 scientistscientist -21 scientistscientist -39 experiencedexperienced -27 novicenovice -55 nonnon -1 experiencedexperienced -36 nonnon -22 scientistscientist -5 scientistscientist -44 scientistscientist -50 scientistscientist -24 experiencedexperienced -25 novicenovice-10 experiencedexperienced -11 scientistscientist -49 novicenovice -35 scientistscientist -15 nonnon -18 novicenovice -47 nonnon -23 experiencedexperienced -33 novicenovice -44 novice cenovi ce -34 novicenovice -2 nonnon -3 nonnon -7 novicenovice -29 scientistscientist -47 novicenovice -27 novicenovice -17 novice icenov ice -15 novicenovice -26 experiencedexperienced -13 novicenovice -39 scientistscientist -6 novicenovice -18 novicenovice -42 scientistscientist -35 novicenovice-7 novicenovice -53 novicenovice -50 scientistscientist -26 scientistscientist -3 experiencedexperienced -32 novicenovice -40 novicenovice -30 experiencedexperienced -3 scientistscientist -51 novicenovice -6 scientistscientist -45 novicenovice -9

131 166 76 13 98 153 88 58 77 19 41 67 128 90 63 112 21 44 12 29 83 114 70 51 135 50 111 148 89 82 158 147 160 108 101 120 11 139 132 141 137 85 163 14 167 119 22 145 124 117 6 36 54 165 149 87 34 123 35 134

1919 1893 1869 1856 1848 1822 1810 1807 1763 1762 1753 1693 1662 1622 1580 1567 1563 1543 1496 1494 1465 1464 1456 1448 1444 1429 1403 1316 1294 1292 1277 1276 1267 1265 1231 1230 1229 1195 1194 1139 1120 1109 1107 1103 1088 1068 1049 1039 1028 985 983 978 974 967 946 915 910 871 862 853

0 1 206 54 0 0 23 163 106 50 173 77 6 0 56 48 18 12 219 0 69 0 21 138 0 200 0 0 0 83 0 4 0 9 3 0 9 1 0 0 0 25 0 33 0 0 23 98 0 0 0 1 47 0 0 88 0 0 17 0

123 51 218 111 61 19 153 88 92 134 77 54 40 59 116 56 78 84 225 55 89 40 86 97 54 81 64 78 48 65 40 46 58 15 54 44 81 63 59 48 60 160 51 49 38 33 29 51 41 92 70 69 87 24 28 42 67 44 59 63

0 547 598 761 0 0 996 829 889 586 530 741 0 410 781 0 558 394 387 1217 346 872 927 179 50 175 0 0 636 649 0 0 0 209 792 0 618 414 0 0 0 446 9 278 0 5 594 36 51 0 231 255 303 722 0 356 358 0 223 0

11758 11844 11676 11792 12210 11298 11270 11328 10840 10894 10992 11032 10218 10110 9718 10004 10164 9544 9526 9250 9072 9038 9126 9106 9022 9216 8804 8118 8118 7986 7896 8146 8072 7928 7704 7754 7672 7452 7702 7148 7066 6848 6936 7196 6710 6774 6612 6608 6558 6100 6388 6398 6102 6032 5986 5600 5754 5520 5330 5292

81

novicenovice -21 novicenovice -24 nonnon -17 scientistscientist -8 novicenovice -38 nonnon -16 scientistscientist -48 experiencedexperienced -16 scientistscientist -28 experiencedexperienced -6 scientistscientist -22 novicenovice -49 novicenovice -54 experiencedexperienced -31 experiencedexperienced -26 novicenovice -13 novicenovice -45 novicenovice -52 novicenovice -43 scientistscientist -32 novicenovice -5 experiencedexperienced-18 nonnon -15 scientistscientist -17 nonnon -24 nonnon -10 nonnon -13 novicenovice -51 nonnon -2 experiencedexperienced -10 novicenovice -20 novicenovice -32 scientistscientist -7 nonnon -9 nonnon -25 scientistscientist -16 scientistscientist -33 novicenovice -48 novicenovice -11 novicenovice -16 scientistscientist -31 nonnon -5 nonnon -8 experiencedexperienced -15 experiencedexperienced -2 nonnon -12 scientistscientist -11 nonnon-14 nonnon -6 nonnon -19 nonnon -21

127 130 110 2 159 105 9 60 18 57 7 156 138 61 72 168 116 140 125 5 121 69 94 46 96 93 100 143 113 56 144 133 33 102 104 8 4 152 162 161 1 103 97 65 64 107 31 109 95 92 91

849 849 848 842 839 821 819 795 765 757 750 723 683 683 679 652 651 650 608 601 593 575 571 569 542 495 487 480 454 446 418 385 366 357 327 326 325 269 256 256 250 244 239 225 219 216 205 201 177 175 132

1 48 0 0 0 144 0 24 64 0 0 0 0 19 0 0 0 0 0 0 1 5 0 0 0 0 0 0 0 2 5 0 0 4 3 0 0 0 2 0 9 0 28 0 6 0 0 1 0 0 0

42 53 65 51 17 26 43 22 26 32 39 31 56 38 66 49 16 38 26 20 67 21 28 38 34 20 5 20 15 26 19 37 28 23 18 29 12 9 21 25 20 11 13 12 11 26 13 4 7 7 7

0 118 0 79 0 0 0 245 235 69 20 0 0 454 59 0 0 0 45 0 0 114 0 0 0 0 0 0 63 170 0 60 169 45 48 38 0 0 0 0 12 0 18 85 33 0 0 0 0 116 0

5268 5436 5330 5294 5468 5108 5216 4932 5032 4752 5026 4428 4248 4368 4192 4106 4120 4174 3778 3916 3804 3548 3736 3792 3390 3096 3072 3046 2934 2774 2722 2512 2246 2432 2264 2250 2044 1704 1770 1598 1758 1770 1524 1404 1414 1390 1380 1272 1152 1356 890

82

Appendix Appendix B: B: Generated Statistics for the Greenberg Dataset (Ordered by History)
User scientistscientist -36 experiencedexperienced -20 scientistscientist -13 experienced encedexperi enced -22 scientistscientist -2 scientistscientist -52 scientistscientist -9 experiencedexperienced -24 scientistscientist -50 experiencedexperienced -34 scientistscientist -15 experiencedexperienced -23 scientistscientist -30 scientistscientist -4 scientistscientist -14 experiencedexperienced-1 scientistscientist -39 nonnon -20 experiencedexperienced -19 experiencedexperienced -21 nonnon -16 scientistscientist -49 scientistscientist -37 novicenovice -46 scientistscientist -19 experiencedexperienced -12 scientistscientist -27 novicenovice -7 experiencedexperienced -3 experiencedexperienced -9 experiencedexperienced -33 experiencedexperienced -30 scientistscientist -46 experiencedexperienced -28 experiencedexperienced -27 scientistscientist -10 scientistscientist -20 experiencedexperienced -25 experiencedexperienced -7 experiencedexperienced -8 scientistscientist -28 experiencedexperienced-29 experiencedexperienced -36 scientistscientist -1 scientistscientist-12 scientistscientist -23 scientistscientist -21 scientistscientist -38 nonnon -22 ovicenovice -24 experiencedexperienced -32 novicenovice -1 experiencedexperienced -5 scientistscientist -6 experiencedexperienced -35 nonnon -8 experienced periencedex perienced -13 Uid 20 53 42 73 25 15 26 86 12 76 50 81 40 23 47 80 41 99 58 59 105 51 32 146 43 77 37 145 87 71 82 66 3 74 67 27 45 83 55 68 18 84 63 13 28 16 19 24 112 130 54 151 62 14 78 97 85 Commands 12056 4556 3593 2814 2954 7705 4067 3331 1496 1869 1429 2306 2129 4507 3433 3714 1753 4042 1807 2394 821 1448 4187 4163 2831 1763 3817 1039 915 2351 1292 2028 2551 3893 1693 2024 2697 1465 5857 2930 765 2214 1580 1856 2499 3360 1762 3775 1567 849 974 2457 4015 1103 4272 239 1109 History 488 435 357 325 236 231 224 222 219 206 200 189 186 178 178 174 173 165 163 157 144 138 121 112 106 106 102 98 88 86 83 82 80 78 77 77 74 69 67 67 64 59 56 54 53 52 50 48 48 48 47 37 35 33 28 28 25 Errors 566 370 118 122 149 299 65 228 225 218 81 119 123 320 183 298 77 124 88 83 26 97 83 372 112 92 85 51 42 136 65 110 110 60 54 120 189 89 612 265 26 133 116 111 52 135 134 168 56 53 87 213 222 49 169 13 160 Aliases 3161 1646 204 560 1656 717 665 1456 387 598 175 1004 409 789 2 1906 530 2122 829 974 0 179 1866 1909 1330 889 0 36 356 502 649 624 495 2516 741 730 804 346 2926 625 235 1072 781 761 1162 481 586 1312 0 118 303 1381 910 278 2504 18 446 Lines 73434 28054 21988 17478 18514 47280 25424 20440 9526 11676 9216 14214 13492 27992 21404 22830 10992 24798 11328 14762 5108 9106 25604 26080 17560 10840 23344 6608 5600 14500 7986 12686 16480 25116 11032 12658 17080 9072 35896 18114 5032 13566 9718 11792 15412 21454 10894 23172 10004 5436 6102 14960 25220 7196 26290 1524 6848

83

experiencedexperienced -16 scientistscientist -35 experiencedexperienced -14 experiencedexperienced -11 scientistscientist -29 experiencedexperienced -31 nonnon -4 scientistscientist -5 scientistscientist -45 scientistscientist -34 scientistscientist -44 nonnon -3 scientistscientist -47 scientistscientist -31 scientistscientist -25 novicenovice -19 experiencedexperienced -2 novicenovice -55 scientistscientist -18 scientistscientist -42 novicenovice -20 experiencedexperienced-18 nonnon -9 novicenovice -34 nonnon -25 nonnon -7 novicenovice -25 novicenovice -11 experienced eriencedexp erienced -4 experiencedexperienced -10 nonnon -14 novicenovice -27 novicenovice -21 scientistscientist -3 novicenovice -22 novicenovice -5 novicenovice -9 novicenovice -17 novicenovice -23 novicenovice -40 scientistscientist -26 novicenovice -4 novicenovice -15 novicenovice -32 novicenovice -54 novicenovice -26 novicenovice -28 novicenovice-35 novicenovice -52 novicenovice -51 scientistscientist -32 novicenovice -49 novicenovice -31 novicenovice -44 novicenovice -38 novicenovice -2 novicenovice -16 novicenovice -39 novicenovice -18 novicenovice -36

60 22 88 70 17 61 106 21 35 52 44 108 11 1 30 164 64 128 48 10 144 69 102 147 104 101 155 162 75 56 109 139 127 36 166 121 134 132 129 165 6 131 141 133 138 137 136 135 140 143 5 156 157 158 159 160 161 163 167 142

795 1049 1810 1456 2683 683 5050 1563 862 2639 1543 1265 1229 250 3508 3401 219 1662 5584 6068 418 575 357 1276 327 1231 2066 256 3776 446 201 1195 849 978 1893 593 853 1194 2138 967 983 1919 1139 385 683 1120 2221 1444 650 480 601 723 2073 1277 839 1267 256 1107 1088 3213

24 23 23 21 20 19 18 18 17 15 12 9 9 9 7 7 6 6 6 6 5 5 4 4 3 3 2 2 2 2 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

22 29 153 86 243 38 161 78 59 88 84 15 81 20 122 363 11 40 240 644 19 21 23 46 18 54 217 21 123 26 4 63 42 69 51 67 63 59 72 24 70 123 48 37 56 60 120 54 38 20 20 31 102 40 17 58 25 51 38 137

245 594 996 927 530 454 3296 558 223 910 394 209 618 12 379 0 33 0 1816 3243 0 114 45 0 48 792 0 0 1329 170 0 414 0 255 547 0 0 0 0 722 231 0 0 60 0 0 0 50 0 0 0 0 18 0 0 0 0 9 0 0

4932 6612 11270 9126 16632 4368 30830 10164 5330 16648 9544 7928 7672 1758 22706 20816 1414 10218 34258 37598 2722 3548 2432 8146 2264 7704 13070 1770 23258 2774 1272 7452 5268 6398 11844 3804 5292 7702 13186 6032 6388 11758 7148 2512 4248 7066 13816 9022 4174 3046 3916 4428 12692 7896 5468 8072 1598 6936 6710 19840

84

novicenovice -37 scientistscientist -33 novicenovice -14 novicenovice -47 novicenovice -30 novicenovice -3 scientistscientist -8 novicenovice -48 novicenovice -8 novicenovice -13 experiencedexperienced -15 scientistscientist -24 nonnon -23 nonnon -1 nonnon -21 nonnon -19 nonnon -10 nonnon -15 nonnon -6 scientistscientist -11 scientistscientist -7 experiencedexperienced-6 scientistscientist -41 experiencedexperienced -26 scientistscientist -17 scientistscientist -43 scientistscientist -40 experiencedexperienced -17 scientistscientist -51 nonnon -24 nonnon -11 scientistscientist -48 novicenovice -45 novicenovice -50 novicenovice -12 novicenovice -42 novicenovice -29 novicenovice -33 novicenovice -6 novicenovice -53 novicenovice -41 novicenovice -10 nonnon -13 nonnon -5 scientistscientist -16 nonnon -12 nonnon -17 nonnon-18 scientistscientist -22 nonnon -2 novicenovice -43

154 4 126 148 149 150 2 152 153 168 65 29 89 90 91 92 93 94 95 31 33 57 49 72 46 39 38 79 34 96 98 9 116 117 118 119 120 122 123 124 115 114 100 103 8 107 110 111 7 113 125

1949 325 3194 1316 946 2337 842 269 1822 652 225 1494 1294 1622 132 175 495 571 177 205 366 757 2037 679 569 3106 4605 2343 910 542 1848 819 651 985 2436 1068 1230 3127 871 1028 2317 1464 487 244 326 216 848 1403 750 454 608

0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

57 12 208 78 28 93 51 9 19 49 12 55 48 59 7 7 20 28 7 13 28 32 36 66 38 101 98 144 67 34 61 43 16 92 210 33 44 106 44 41 51 40 5 11 29 26 65 64 39 15 26

0 0 0 0 0 0 79 0 0 0 85 1217 636 410 0 116 0 0 0 0 169 69 0 59 0 546 628 102 358 0 0 0 0 0 0 5 0 0 0 51 1000 872 0 0 38 0 0 0 20 63 45

12044 2044 19786 8118 5986 15400 5294 1704 11298 4106 1404 9250 8118 10110 890 1356 3096 3736 1152 1380 2246 4752 13036 4192 3792 19066 29020 14396 5754 3390 12210 5216 4120 6100 16366 6774 7754 19556 5520 6558 14244 9038 3072 1770 2250 1390 5330 8804 5026 2934 3778

85

Appendix C: C: Generated Statistics for the Greenberg Dataset (Ordered by Errors)
User scientistscientist -42 experiencedexperienced -7 scientistscientist -36 novicenovice -46 experiencedexperienced -20 novicenovice -19 scientistscientist -4 scientist scientis t-52 experiencedexperienced -1 experiencedexperienced -8 scientistscientist -29 scientistscientist -18 experiencedexperienced -24 scientistscientist -50 experiencedexperienced -5 experiencedexperienced-34 novicenovice -25 novicenovice -1 novicenovice -12 novicenovice -14 scientistscientist -20 scientistscientist -14 experiencedexperienced -35 scientistscientist -38 nonnon -4 experiencedexperienced -13 experiencedexperienced -14 scientistscientist -2 experiencedexperienced -17 novicenovice -36 experiencedexperienced -9 scientistscientist -23 scientistscientist -21 experiencedexperienced -29 nonnon -20 experiencedexperienced -4 novicenovice -4 scientistscientist -30 scientistscientist -25 experiencedexperienced -22 scientistscientist -10 novicenovice-28 experiencedexperienced -23 scientistscientist -13 experiencedexperienced-36 scientistscientist -19 scientistscientist -1 experiencedexperienced -30 scientistscientist -46 novicenovice -33 novicenovice -31 scientistscientist -43 scientistscientist -40 scientistscientist -49 novicenovice -3 novicenovice -50 experiencedexperienced -12 Uid 10 55 20 146 53 164 23 15 80 68 17 48 86 12 62 76 155 151 118 126 45 47 78 24 106 85 88 25 79 142 71 16 19 84 99 75 131 40 30 73 27 136 81 42 63 43 13 66 3 122 157 39 38 51 150 117 77 Commands 6068 5857 12056 4163 4556 3401 4507 7705 3714 2930 2683 5584 3331 1496 4015 1869 2066 2457 2436 3194 2697 3433 4272 3775 5050 1109 1810 2954 2343 3213 2351 3360 1762 2214 4042 3776 1919 2129 3508 2814 2024 2221 2306 3593 1580 2831 1856 2028 2551 3127 2073 3106 4605 1448 2337 985 1763 History 6 67 488 112 435 7 178 231 174 67 20 6 222 219 35 206 2 37 0 0 74 178 28 48 18 25 23 236 0 0 86 52 50 59 165 2 0 186 7 325 77 0 189 357 56 106 54 82 80 0 0 0 0 138 0 0 106 Errors 644 612 566 372 370 363 320 299 298 265 243 240 228 225 222 218 217 213 210 208 189 183 169 168 161 160 153 149 144 137 136 135 134 133 124 123 123 123 122 122 120 120 119 118 116 112 111 110 110 106 102 101 98 97 93 92 92 Aliases 3243 2926 3161 1909 1646 0 789 717 1906 625 530 1816 1456 387 910 598 0 1381 0 0 804 2 2504 1312 3296 446 996 1656 102 0 502 481 586 1072 2122 1329 0 409 379 560 730 0 1004 204 781 1330 761 624 495 0 18 546 628 179 0 0 889 Lines 37598 35896 73434 26080 28054 20816 27992 47280 22830 18114 16632 34258 20440 9526 25220 11676 13070 14960 16366 19786 17080 21404 26290 23172 30830 6848 11270 18514 14396 19840 14500 21454 10894 13566 24798 23258 11758 13492 22706 17478 12658 13816 14214 21988 9718 17560 11792 12686 16480 19556 12692 19066 29020 9106 15400 6100 10840

86

experiencedexperienced -25 scientistscientist -34 experiencedexperienced -19 experiencedexperienced -32 experiencedexperienced -11 scientistscientist -27 scientistscientist -44 scientistscientist -37 experiencedexperienced -21 scientistscientist -47 scientist stscienti st -15 scientistscientist -5 novicenovice -47 scientistscientist -39 novicenovice -23 scientistscientist -26 scientistscientist -3 novicenovice -5 scientistscientist -51 experiencedexperienced -26 scientistscientist -9 experiencedexperienced-33 nonnon -17 nonnon -18 novicenovice -27 novice icenov ice -9 nonnon -11 novicenovice -26 experiencedexperienced -28 novicenovice -17 scientistscientist -45 nonnon -1 novicenovice -2 novicenovice -37 nonnon -22 novicenovice -54 scientistscientist -24 nonnon -7 experiencedexperienced -27 novicenovice -35 novicenovice -24 scientistscientist -12 novicenovice -22 scientistscientist -8 novicenovice -41 novicenovice -39 novicenovice -7 novicenovice-13 scientist entistsci entist -6 nonnon -23 novicenovice -15 novicenovice -34 novicenovice -6 novicenovice -29 scientistscientist -48 experiencedexperienced -3 novicenovice -21 novicenovice -53 novicenovice -10 novicenovice -44

83 52 58 54 70 37 44 32 59 11 50 21 148 41 129 6 36 121 34 72 26 82 110 111 139 134 98 137 74 132 35 90 160 154 112 138 29 101 67 135 130 28 166 2 115 163 145 168 14 89 141 147 123 120 9 87 127 124 114 158

1465 2639 1807 974 1456 3817 1543 4187 2394 1229 1429 1563 1316 1753 2138 983 978 593 910 679 4067 1292 848 1403 1195 853 1848 1120 3893 1194 862 1622 1267 1949 1567 683 1494 1231 1693 1444 849 2499 1893 842 2317 1107 1039 652 1103 1294 1139 1276 871 1230 819 915 849 1028 1464 1277

69 15 163 47 21 102 12 121 157 9 200 18 0 173 0 0 1 1 0 0 224 83 0 0 1 0 0 0 78 0 17 0 0 0 48 0 0 3 77 0 48 53 1 0 0 0 98 0 33 0 0 4 0 0 0 88 1 0 0 0

89 88 88 87 86 85 84 83 83 81 81 78 78 77 72 70 69 67 67 66 65 65 65 64 63 63 61 60 60 59 59 59 58 57 56 56 55 54 54 54 53 52 51 51 51 51 51 49 49 48 48 46 44 44 43 42 42 41 40 40

346 910 829 303 927 0 394 1866 974 618 175 558 0 530 0 231 255 0 358 59 665 649 0 0 414 0 0 0 2516 0 223 410 0 0 0 0 1217 792 741 50 118 1162 547 79 1000 9 36 0 278 636 0 0 0 0 0 356 0 51 872 0

9072 16648 11328 6102 9126 23344 9544 25604 14762 7672 9216 10164 8118 10992 13186 6388 6398 3804 5754 4192 25424 7986 5330 8804 7452 5292 12210 7066 25116 7702 5330 10110 8072 12044 10004 4248 9250 7704 11032 9022 5436 15412 11844 5294 14244 6936 6608 4106 7196 8118 7148 8146 5520 7754 5216 5600 5268 6558 9038 7896

87

novicenovice -55 scientistscientist -22 experiencedexperienced -31 scientistscientist -17 novicenovice -18 novicenovice -52 novicenovice -32 scientistscientist -41 nonnon -24 novicenovice -42 experiencedexperienced -6 novicenovice -49 scientistscientist -16 scientistscientist -35 scientistscientist -7 novicenovice -30 nonnon -15 nonnon -12 scientistscientist -28 novicenovice -43 nonnon -16 experiencedexperienced-10 novicenovice -16 novicenovice -40 nonnon -9 experiencedexperienced -16 novicenovice -11 experiencedexperienced -18 nonnon -10 novicenovice -51 scientistscientist -32 scientistscientist -31 novicenovice -20 novicenovice -8 nonnon -25 novicenovice -38 novicenovice -45 nonnon -3 nonnon -2 scientistscientist -11 nonnon -8 experiencedexperienced -15 scientistscientist -33 nonnon -5 experiencedexperienced -2 novicenovice -48 nonnon -19 nonnon-6 nonnon -21 nonnon -13 nonnon -14

128 7 61 46 167 140 133 49 96 119 57 156 8 22 33 149 94 107 18 125 105 56 161 165 102 60 162 69 93 143 5 1 144 153 104 159 116 108 113 31 97 65 4 103 64 152 92 95 91 100 109

1662 750 683 569 1088 650 385 2037 542 1068 757 723 326 1049 366 946 571 216 765 608 821 446 256 967 357 795 256 575 495 480 601 250 418 1822 327 839 651 1265 454 205 239 225 325 244 219 269 175 177 132 487 201

6 0 19 0 0 0 0 0 0 0 0 0 0 23 0 0 0 0 64 0 144 2 0 0 4 24 2 5 0 0 0 9 5 0 3 0 0 9 0 0 28 0 0 0 6 0 0 0 0 0 1

40 39 38 38 38 38 37 36 34 33 32 31 29 29 28 28 28 26 26 26 26 26 25 24 23 22 21 21 20 20 20 20 19 19 18 17 16 15 15 13 13 12 12 11 11 9 7 7 7 5 4

0 20 454 0 0 0 60 0 0 5 69 0 38 594 169 0 0 0 235 45 0 170 0 722 45 245 0 114 0 0 0 12 0 0 48 0 0 209 63 0 18 85 0 0 33 0 116 0 0 0 0

10218 5026 4368 3792 6710 4174 2512 13036 3390 6774 4752 4428 2250 6612 2246 5986 3736 1390 5032 3778 5108 2774 1598 6032 2432 4932 1770 3548 3096 3046 3916 1758 2722 11298 2264 5468 4120 7928 2934 1380 1524 1404 2044 1770 1414 1704 1356 1152 890 3072 1272

88

Appendix D: D: Generated Statistics for the Greenberg Dataset Dataset (Ordered by Aliases)
User nonnon -4 scientistscientist -42 scientistscientist -36 experiencedexperienced -7 experiencedexperienced -28 experiencedexperienced -35 nonnon -20 novicenovice -46 experiencedexperienced -1 scientistscientist -37 scientistscientist -18 scientist ntistscie ntist -2 experiencedexperienced -20 experiencedexperienced -24 novicenovice -1 scientistscientist-19 experiencedexperienced -4 scientistscientist -38 scientistscientist -24 scientistscientist -12 experiencedexperienced -29 experiencedexperienced -23 novicenovice -41 experiencedexperienced -14 experiencedexperienced -21 experiencedexperienced -11 scientistscientist -34 experiencedexperienced -5 experiencedexperienced -12 novicenovice -10 experiencedexperienced -19 scientistscientist -20 nonnon -7 scientistscientist -4 experiencedexperienced -36 scientistscientist -1 experiencedexperienced -27 scientist istscient ist -10 novicenovice -40 scientistscientist -52 scientistscientist -9 experiencedexperienced-33 nonnon -23 scientistscientist -40 experienced experienced enced-8 experiencedexperienced -30 scientistscientist -47 experiencedexperienced -34 scientistscientist -35 scientistscientist -21 experiencedexperienced -22 scientistscientist -5 novicenovice -22 scientistscientist -43 scientistscientist -29 scientistscientist -39 experiencedexperienced -9 Uid 106 10 20 55 74 78 99 146 80 32 48 25 53 86 151 43 75 24 29 28 84 81 115 88 59 70 52 62 77 114 58 45 101 23 63 13 67 27 165 15 26 82 89 38 68 66 11 76 22 19 73 21 166 39 17 41 71 Commands 5050 6068 12056 5857 3893 4272 4042 4163 3714 4187 5584 2954 4556 3331 2457 2831 3776 3775 1494 2499 2214 2306 2317 1810 2394 1456 2639 4015 1763 1464 1807 2697 1231 4507 1580 1856 1693 2024 967 7705 4067 1292 1294 4605 2930 2028 1229 1869 1049 1762 2814 1563 1893 3106 2683 1753 2351 History 18 6 488 67 78 28 165 112 174 121 6 236 435 222 37 106 2 48 0 53 59 189 0 23 157 21 15 35 106 0 163 74 3 178 56 54 77 77 0 231 224 83 0 0 67 82 9 206 23 50 325 18 1 0 20 173 86 Errors 161 644 566 612 60 169 124 372 298 83 240 149 370 228 213 112 123 168 55 52 133 119 51 153 83 86 88 222 92 40 88 189 54 320 116 111 54 120 24 299 65 65 48 98 265 110 81 218 29 134 122 78 51 101 243 77 136 Aliases 3296 3243 3161 2926 2516 2504 2122 1909 1906 1866 1816 1656 1646 1456 1381 1330 1329 1312 1217 1162 1072 1004 1000 996 974 927 910 910 889 872 829 804 792 789 781 761 741 730 722 717 665 649 636 628 625 624 618 598 594 586 560 558 547 546 530 530 502 Lines 30830 37598 73434 35896 25116 26290 24798 26080 22830 25604 34258 18514 28054 20440 14960 17560 23258 23172 9250 15412 13566 14214 14244 11270 14762 9126 16648 25220 10840 9038 11328 17080 7704 27992 9718 11792 11032 12658 6032 47280 25424 7986 8118 29020 18114 12686 7672 11676 6612 10894 17478 10164 11844 19066 16632 10992 14500

89

scientistscientist -46 scientistscientist -23 experiencedexperienced -31 experiencedexperienced -13 novicenovice -27 nonnon -1 scientistscientist -30 scientistscientist -44 scientistscientist -50 scientistscientist -25 scientistscientist -51 experiencedexperienced -3 experiencedexperienced -25 experiencedexperienced -32 scientist entistsci entist -6 scientistscientist -3 experiencedexperienced -16 scientistscientist -28 scientistscientist -26 scientistscientist -45 nonnon -3 scientistscientist-13 scientistscientist -49 scientistscientist -15 experiencedexperienced -10 scientistscientist -7 novicenovice -24 nonnon -19 experiencedexperienced -18 experiencedexperienced -17 experiencedexperienced -15 scientistscientist -8 experiencedexperienced -6 nonnon -2 novicenovice -32 experiencedexperienced -26 novice viceno vice -53 novicenovice -35 nonnon -25 nonnon -9 novicenovice -43 scientistscientist -16 novicenovice -7 experiencedexperienced -2 scientist ientistsc ientist -22 nonnon -8 novicenovice -31 scientistscientist-31 novicenovice -39 novicenovice -42 scientistscientist -14 novicenovice -30 novicenovice -47 novicenovice -3 novicenovice -34 scientistscientist -17 novicenovice -20 novicenovice -51 novicenovice -36 novicenovice -15

3 16 61 85 139 90 40 44 12 30 34 87 83 54 14 36 60 18 6 35 108 42 51 50 56 33 130 92 69 79 65 2 57 113 133 72 124 135 104 102 125 8 145 64 7 97 157 1 163 119 47 149 148 150 147 46 144 143 142 141

2551 3360 683 1109 1195 1622 2129 1543 1496 3508 910 915 1465 974 1103 978 795 765 983 862 1265 3593 1448 1429 446 366 849 175 575 2343 225 842 757 454 385 679 1028 1444 327 357 608 326 1039 219 750 239 2073 250 1107 1068 3433 946 1316 2337 1276 569 418 480 3213 1139

80 52 19 25 1 0 186 12 219 7 0 88 69 47 33 1 24 64 0 17 9 357 138 200 2 0 48 0 5 0 0 0 0 0 0 0 0 0 3 4 0 0 98 6 0 28 0 9 0 0 178 0 0 0 4 0 5 0 0 0

110 135 38 160 63 59 123 84 225 122 67 42 89 87 49 69 22 26 70 59 15 118 97 81 26 28 53 7 21 144 12 51 32 15 37 66 41 54 18 23 26 29 51 11 39 13 102 20 51 33 183 28 78 93 46 38 19 20 137 48

495 481 454 446 414 410 409 394 387 379 358 356 346 303 278 255 245 235 231 223 209 204 179 175 170 169 118 116 114 102 85 79 69 63 60 59 51 50 48 45 45 38 36 33 20 18 18 12 9 5 2 0 0 0 0 0 0 0 0 0

16480 21454 4368 6848 7452 10110 13492 9544 9526 22706 5754 5600 9072 6102 7196 6398 4932 5032 6388 5330 7928 21988 9106 9216 2774 2246 5436 1356 3548 14396 1404 5294 4752 2934 2512 4192 6558 9022 2264 2432 3778 2250 6608 1414 5026 1524 12692 1758 6936 6774 21404 5986 8118 15400 8146 3792 2722 3046 19840 7148

90

novicenovice -52 scientistscientist -27 scientistscientist -32 novicenovice -48 novicenovice -8 novicenovice -13 novicenovice -18 scientistscientist -41 scientistscientist -33 novicenovice -19 novicenovice -11 novicenovice -16 novicenovice -2 novicenovice -38 novicenovice -44 novicenovice -49 novicenovice -25 novicenovice -37 novicenovice -54 novicenovice -26 novicenovice -28 novicenovice-12 novicenovice -50 novicenovice -45 nonnon -6 nonnon -24 nonnon -22 nonnon -18 nonnon -17 nonnon -14 nonnon -11 nonnon -12 nonnon -13 nonnon -16 nonnon -5 novicenovice -29 novicenovice -5 scientistscientist -11 novicenovice -9 novicenovice -17 novicenovice -4 nonnon -21 novicenovice -23 novicenovice -55 novicenovice -21 novicenovice -14 nonnon -10 nonnon-15 novicenovice -6 novicenovice -33 scientistscientist -48

140 37 5 152 153 168 167 49 4 164 162 161 160 159 158 156 155 154 138 137 136 118 117 116 95 96 112 111 110 109 98 107 100 105 103 120 121 31 134 132 131 91 129 128 127 126 93 94 123 122 9

650 3817 601 269 1822 652 1088 2037 325 3401 256 256 1267 839 1277 723 2066 1949 683 1120 2221 2436 985 651 177 542 1567 1403 848 201 1848 216 487 821 244 1230 593 205 853 1194 1919 132 2138 1662 849 3194 495 571 871 3127 819

0 102 0 0 0 0 0 0 0 7 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 48 0 0 1 0 0 0 144 0 0 1 0 0 0 0 0 0 6 1 0 0 0 0 0 0

38 85 20 9 19 49 38 36 12 363 21 25 58 17 40 31 217 57 56 60 120 210 92 16 7 34 56 64 65 4 61 26 5 26 11 44 67 13 63 59 123 7 72 40 42 208 20 28 44 106 43

0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

4174 23344 3916 1704 11298 4106 6710 13036 2044 20816 1770 1598 8072 5468 7896 4428 13070 12044 4248 7066 13816 16366 6100 4120 1152 3390 10004 8804 5330 1272 12210 1390 3072 5108 1770 7754 3804 1380 5292 7702 11758 890 13186 10218 5268 19786 3096 3736 5520 19556 5216

91

Appendix E: E: Generated Statistics for the Greenberg Dataset (Ordered by Lines)
User scientistscientist -36 scientistscientist -52 scientistscientist -42 experiencedexperienced -7 scientistscientist -18 nonnon -4 scientistscientist -40 experiencedexperienced -20 scientistscientist -4 experiencedexperienced -35 novicenovice -46 scientistscientist -37 scientistscientist -9 experiencedexperienced -5 experiencedexperienced -28 nonnon-20 scientistscientist -27 experiencedexperienced -4 scientistscientist -38 experiencedexperienced -1 scientistscientist -25 scientistscientist -13 scientistscientist -23 scientistscientist -14 novicenovice -19 experiencedexperienced -24 novicenovice -36 novicenovice -14 novicenovice -33 scientistscientist -43 scientistscientist -2 experiencedexperienced -8 scientistscientist -19 experiencedexperienced -22 scientistscientist -20 scientistscientist -34 scientistscientist -29 scientistscientist -46 novicenovice -12 scientistscientist -12 novicenovice -3 novicenovice-1 experiencedexperienced -21 experiencedexperienced -9 experiencedexperienced-17 novicenovice -41 experiencedexperienced -23 novicenovice -28 experiencedexperienced -29 scientistscientist -30 novicenovice -23 novicenovice -25 scientistscientist -41 novicenovice -31 experiencedexperienced -30 scientistscientist -10 nonnon -11 Uid 20 15 10 55 48 106 38 53 23 78 146 32 26 62 74 99 37 75 24 80 30 42 16 47 164 86 142 126 122 39 25 68 43 73 45 52 17 3 118 28 150 151 59 71 79 115 81 136 84 40 129 155 49 157 66 27 98 Commands 12056 7705 6068 5857 5584 5050 4605 4556 4507 4272 4163 4187 4067 4015 3893 4042 3817 3776 3775 3714 3508 3593 3360 3433 3401 3331 3213 3194 3127 3106 2954 2930 2831 2814 2697 2639 2683 2551 2436 2499 2337 2457 2394 2351 2343 2317 2306 2221 2214 2129 2138 2066 2037 2073 2028 2024 1848 History 488 231 6 67 6 18 0 435 178 28 112 121 224 35 78 165 102 2 48 174 7 357 52 178 7 222 0 0 0 0 236 67 106 325 74 15 20 80 0 53 0 37 157 86 0 0 189 0 59 186 0 2 0 0 82 77 0 Errors 566 299 644 612 240 161 98 370 320 169 372 83 65 222 60 124 85 123 168 298 122 118 135 183 363 228 137 208 106 101 149 265 112 122 189 88 243 110 210 52 93 213 83 136 144 51 119 120 133 123 72 217 36 102 110 120 61 Aliases 3161 717 3243 2926 1816 3296 628 1646 789 2504 1909 1866 665 910 2516 2122 0 1329 1312 1906 379 204 481 2 0 1456 0 0 0 546 1656 625 1330 560 804 910 530 495 0 1162 0 1381 974 502 102 1000 1004 0 1072 409 0 0 0 18 624 730 0 Lines 73434 47280 37598 35896 34258 30830 29020 28054 27992 26290 26080 25604 25424 25220 25116 24798 23344 23258 23172 22830 22706 21988 21454 21404 20816 20440 19840 19786 19556 19066 18514 18114 17560 17478 17080 16648 16632 16480 16366 15412 15400 14960 14762 14500 14396 14244 14214 13816 13566 13492 13186 13070 13036 12692 12686 12658 12210

92

novicenovice -37 novicenovice -22 scientistscientist -1 novicenovice -4 experiencedexperienced -34 experiencedexperienced -19 novicenovice -8 experiencedexperienced -14 experiencedexperienced -27 scientistscientist -39 scientistscientist -21 experiencedexperienced -12 novicenovice -55 scientistscientist -5 nonnon -1 nonnon -22 experiencedexperienced -36 scientistscientist -44 scientistscientist -50 scientistscientist -24 scientistscientist -15 experiencedexperienced-11 scientistscientist -49 experiencedexperienced -25 novicenovice -10 novicenovice -35 nonnon -18 novicenovice -34 novicenovice -47 nonnon -23 novicenovice -2 experiencedexperienced -33 nonnon -3 novicenovice -44 novicenovice -29 nonnon -7 novicenovice -17 scientistscientist -47 novicenovice -27 scientistscientist -6 novicenovice -15 novicenovice -26 novicenovice -39 experiencedexperienced -13 novicenovice -42 novicenovice -18 scientistscientist -35 novicenovice-7 novicenovice -53 scientistscientist -3 scientistscientist -26 experiencedexperienced -32 novicenovice -50 novicenovice -40 novicenovice -30 scientistscientist -51 experiencedexperienced -3 novicenovice -6 novicenovice -38 novicenovice -24

154 166 13 131 76 58 153 88 67 41 19 77 128 21 90 112 63 44 12 29 50 70 51 83 114 135 111 147 148 89 160 82 108 158 120 101 132 11 139 14 141 137 163 85 119 167 22 145 124 36 6 54 117 165 149 34 87 123 159 130

1949 1893 1856 1919 1869 1807 1822 1810 1693 1753 1762 1763 1662 1563 1622 1567 1580 1543 1496 1494 1429 1456 1448 1465 1464 1444 1403 1276 1316 1294 1267 1292 1265 1277 1230 1231 1194 1229 1195 1103 1139 1120 1107 1109 1068 1088 1049 1039 1028 978 983 974 985 967 946 910 915 871 839 849

0 1 54 0 206 163 0 23 77 173 50 106 6 18 0 48 56 12 219 0 200 21 138 69 0 0 0 4 0 0 0 83 9 0 0 3 0 9 1 33 0 0 0 25 0 0 23 98 0 1 0 47 0 0 0 0 88 0 0 48

57 51 111 123 218 88 19 153 54 77 134 92 40 78 59 56 116 84 225 55 81 86 97 89 40 54 64 46 78 48 58 65 15 40 44 54 59 81 63 49 48 60 51 160 33 38 29 51 41 69 70 87 92 24 28 67 42 44 17 53

0 547 761 0 598 829 0 996 741 530 586 889 0 558 410 0 781 394 387 1217 175 927 179 346 872 50 0 0 0 636 0 649 209 0 0 792 0 618 414 278 0 0 9 446 5 0 594 36 51 255 231 303 0 722 0 358 356 0 0 118

12044 11844 11792 11758 11676 11328 11298 11270 11032 10992 10894 10840 10218 10164 10110 10004 9718 9544 9526 9250 9216 9126 9106 9072 9038 9022 8804 8146 8118 8118 8072 7986 7928 7896 7754 7704 7702 7672 7452 7196 7148 7066 6936 6848 6774 6710 6612 6608 6558 6398 6388 6102 6100 6032 5986 5754 5600 5520 5468 5436

93

scientistscientist -45 nonnon -17 scientistscientist -8 novicenovice -9 novicenovice -21 scientistscientist -48 nonnon -16 scientistscientist -28 scientistscientist -22 experiencedexperienced -16 experiencedexperienced -6 novicenovice -49 experiencedexperienced -31 novicenovice -54 experiencedexperienced -26 novicenovice -52 novicenovice -45 novicenovice -13 scientistscientist -32 novicenovice -5 scientistscientist -17 novicenovice-43 nonnon -15 experiencedexperienced -18 nonnon -24 nonnon -10 nonnon -13 novicenovice -51 nonnon -2 experiencedexperienced -10 novicenovice -20 novicenovice -32 nonnon -9 nonnon -25 scientistscientist -16 scientistscientist -7 scientistscientist -33 nonnon -5 novicenovice -11 scientistscientist -31 novicenovice -48 novicenovice -16 nonnon -8 experiencedexperienced -2 experiencedexperienced -15 nonnon -12 scientistscientist -11 nonnon-19 nonnon -14 nonnon -6 nonnon -21

35 110 2 134 127 9 105 18 7 60 57 156 61 138 72 140 116 168 5 121 46 125 94 69 96 93 100 143 113 56 144 133 102 104 8 33 4 103 162 1 152 161 97 64 65 107 31 92 109 95 91

862 848 842 853 849 819 821 765 750 795 757 723 683 683 679 650 651 652 601 593 569 608 571 575 542 495 487 480 454 446 418 385 357 327 326 366 325 244 256 250 269 256 239 219 225 216 205 175 201 177 132

17 0 0 0 1 0 144 64 0 24 0 0 19 0 0 0 0 0 0 1 0 0 0 5 0 0 0 0 0 2 5 0 4 3 0 0 0 0 2 9 0 0 28 6 0 0 0 0 1 0 0

59 65 51 63 42 43 26 26 39 22 32 31 38 56 66 38 16 49 20 67 38 26 28 21 34 20 5 20 15 26 19 37 23 18 29 28 12 11 21 20 9 25 13 11 12 26 13 7 4 7 7

223 0 79 0 0 0 0 235 20 245 69 0 454 0 59 0 0 0 0 0 0 45 0 114 0 0 0 0 63 170 0 60 45 48 38 169 0 0 0 12 0 0 18 33 85 0 0 116 0 0 0

5330 5330 5294 5292 5268 5216 5108 5032 5026 4932 4752 4428 4368 4248 4192 4174 4120 4106 3916 3804 3792 3778 3736 3548 3390 3096 3072 3046 2934 2774 2722 2512 2432 2264 2250 2246 2044 1770 1770 1758 1704 1598 1524 1414 1404 1390 1380 1356 1272 1152 890

94

Appendix F: F: List of User Profiles (Victims)
Uid 3 10 13 15 16 17 19 20 21 23 24 25 26 27 28 30 32 37 38 39 40 41 42 43 44 45 47 48 49 52 53 55 58 59 62 63 66 67 68 71 Number of Distinct Commands 427 427 425 316 273 507 412 376 345 351 426 286 311 312 314 462 320 275 329 349 389 342 222 307 367 422 334 314 267 214 168 339 321 195 267 274 204 341 335 341 Uid 73 74 75 76 77 78 79 80 81 84 86 88 90 98 99 106 112 115 118 122 126 128 129 131 136 142 146 150 151 153 154 155 157 164 166 Number of Distinct Commnds 234 350 193 244 336 241 338 241 188 230 420 274 341 472 262 322 277 252 138 138 358 137 126 255 195 157 339 119 284 107 230 339 129 206 208

95

Appendix G: G: Undecided Results
Uid Input 70 22 82 70 22 82 108 70 22 82 13 13 13 13 13 13 13 13 13 30 30 30 30 30 30 30 30 55 55 55 55 55 55 55 55 55 55 58 58 78 98 98 98 98 136 136 136 Uid Profile 52 52 52 52 52 52 84 84 84 84 13 13 13 13 13 13 13 13 13 30 30 30 30 30 30 30 30 55 55 55 55 55 55 55 55 55 55 58 58 78 98 98 98 98 136 136 136 Decision Expected Reject Reject Reject Reject Reject Reject Reject Reject Reject Reject Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Accept Interval Size 10 10 10 10 10 10 10 10 10 10 15 20 15 15 15 20 10 10 20 15 5 20 15 20 20 15 15 20 20 15 15 10 10 20 15 15 10 20 20 20 15 20 20 20 20 20 20 0.29 0.29 0.29 0.30 0.30 0.30 0.31 0.31 0.31 0.31 0.29 0.31 0.30 0.30 0.31 0.29 0.31 0.30 0.30 0.31 0.45 0.29 0.30 0.30 0.31 0.30 0.29 0.30 0.29 0.31 0.30 0.31 0.29 0.31 0.30 0.29 0.30 0.31 0.30 0.31 0.31 0.31 0.30 0.29 0.31 0.30 0.29


0.71 0.71 0.71 0.70 0.70 0.70 0.69 0.69 0.69 0.69 0.71 0.69 0.7 0.7 0.69 0.71 0.69 0.7 0.7 0.69 0.55 0.71 0.7 0.7 0.69 0.7 0.71 0.7 0.71 0.69 0.7 0.69 0.71 0.69 0.7 0.71 0.7 0.69 0.7 0.69 0.69 0.69 0.7 0.71 0.69 0.7 0.71



 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01

96

References
[1] Ahmed, A. A., & Traore, I. (2008). Performance Metrics and Model for Continuous Authentication Systems. submitted to the IEEE Transactions on Dependable and. [2] O'Gorman, L. (2003). Comparing Passwords, Tokens, and Biometrics for User Authentication. IEEE, Dec. 03 Vol. 91, (pp. 2021-2040). [3] Shepherd, S. (1995). Continuous authentication by analysis of keyboard typing characteristics. Security and Detection, European Convention, (pp. 111-114). Brighton. [4] Ahmed, A., & Traore, I. (2007). A New Biometric Technology Based on Mouse Dynamics. Dependable and Secure Computing, IEEE Transactions, (pp. 165-179). [5] Loeb, V. (2001). Spy Case Prompts Computer Search. Washington Post, DC , A01-00. [6] Maxion, R., & Townsend, T. (2004). Masquerade detection augmented with error analysis. Reliability, IEEE Transactions (pp. 124-147). Pittsburgh: IEEE Reliability Society. [7] Kim, H., & Cha, S. (2005). Empirical evaluation of SVM-based masquerade detection using UNIX commands. Computer & Security , 24, 160-168. [8] Wang, K., & S, S. (2003). One-class training for masquerade detection. 3rd IEEE Conference Data Mining Workshop on Data Mining for Computer Security. [9] Schonlau, M., DuMouchel, W., Ju, W., Karr, A. F., Theus, M., & Vardi, Y. (2001). Computer Intrusion: Detecting masquerades. Statistical Science , I (16), 58-74. [10] Maxion, R., & Townsend, T. (2002). Masquerade detection using truncated command lines. Dependable Systems and Networks. DSN 2002. Proceedings. International Conference, (pp. 219-228). Pittsburgh. [11] Axelsson, S. (2000, March 14). Intrusion Detection Systems: A Survey and Taxonomy. 1-27. Sweden. [12] Armstrong, D., & Peile, C. (2005). Perimeter intruder detection systems performance standard. Security Technology, 2005. CCST '05. 39th Annual 2005 International Carnahan Conference, (pp. 33-36). Las Palmas. [13] Cannady, J. (1998). Artificial Neural Networks for Misuse Detection. Retrieved from http://csrc.nist.gov/nissc/1998/proceedings/paperF13.pdf [14] Ghosh, A. K., & Schwartzbard, A. (1999). A study in using neural networks for anomaly and misuse detection. Proceedings of the 8th conference on USENIX Security Symposium - Volume 8 , 12-12.

97

[15] Jali, K. A., Kamarudin, M. H., & Masrek, M. N. (2010). Comparison of Machine Learning algorithms performance in detecting network intrusion. Networking and Information Technology (ICNIT), International Conference, (pp. 221-226). Manila, Philippines. [16] Kemmerer, R. A., & Vigna, G. (2002). Intrusion detection: A brief history and overview. Computer 35 (SUPPL) , 27-30. [17] Lin, M., Miikkulainen, R., & Ryan, J. (1998, June). Intrusion Detection with Neural Networks. Advances in Neural Information Processing Systems . [18] Liu, Z., Florez, G., & Bridges, S. (2002). A comparison of input representations in neural networks: a case study in intrusion detection. Neural Networks. IJCNN '02. Proceedings of the 2002 International Joint Conference on, (pp. 1708-1713). Honolulu, HI. [19] Zhang, P. (2005). Neural Networks. In Data Mining and Knowledge Discovery Handbook (pp. 487507). Springer US. [20] Mitchell, T. (1997). Machine Learning. The McGraw-Hill Companies, Inc. [21] Kim, S.-B., Han, K.-S., Rim, H.-C., & Myaeng, S. H. (2006). Some Effective Techniques for Naive Bayes Text Classification. Knowledge and Data Engineering, IEEE Transactions, (pp. 1457-1466). Los Angeles. [22] Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (1994). Machine learning, neural and statistical classification. New York: Ellis Horwood. [23] Almeida, T., Yamakami, A., & Almeida, J. (2009). Evaluation of Approaches for Dimensionality Reduction Applied with Naive Bayes Anti-Spam Filters. Machine Learning and Applications. ICMLA '09. International Conference, (pp. 517-522). Miami Beach, FL. [24] Yang, Z., Nie, X., Xu, W., & Guo, J. (2006). An Approach to Spam Detection by Naive Bayes Ensemble Based on Decision Induction. Intelligent Systems Design and Applications. ISDA '06. Sixth International Conference, (pp. 861-866). Jinan. [25] Joachims, T. (1996). A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. Carnegie Mellon University: Computer Science Technical Report CMU-CS-96-118. [26] Maxion, R. (2003). Masquerade detection using enriched command lines. Dependable Systems and Networks. Proceedings. 2003 International Conference, (pp. 5-14). [27] Maxion, R., & Tan, K. (2000). Benchmarking anomaly-based detection systems. Dependable Systems and Networks, 2000. DSN 2000. Proceedings International Conference, (pp. 623-630). New York, NY. [28] Jiang, L., Zhang, H., & Cai, Z. (2009). A Novel Bayes Model: Hidden Naive Bayes. Knowledge and Data Engineering, IEEE Transactions, (pp. 1361-1371). [29] Garg, A., Rahalkar, R., Upadhyaya, S., & Kwiat, K. (2006). Profiling Users in GUI Based Systems for Masquerade Detection. West Point: Information Assurance Workshop IEEE. 98

[30] Ghosh, A. K., Schwartzbard, A., & Schatz, M. (1999). Learning Program Behavior Profiles for Intrusion Detection. [31] Ghosh, A. K., Wanken, J., & Charron, F. (1998). Detecting anomalous and unknown intrusions against programs. In Proceedings of the 1998 Annual Computer Security Applications Conference . [32] Heywood, M., Lichodzijewski, P., & Zincir-Heywood, N. (2001). Host-Based Intrusion Detection Using Self-Organizing Maps. Retrieved from http://users.cs.dal.ca/~mheywood/Xfiles/Publications/PeterSOM-ids.pdf [33] Hoglund, A. J., Hatonen, K., & Sorvari, A. S. (2000). A computer host-based user anomaly detection system using theself-organizing map. Proceedings of the IEEE-INNS-ENNS International Joint Conference on , 411 - 416. [34] Wang, W., Guan, X., & Zhan, X. (2004). Profiling program and user behaviors for anomaly intrusion detection based on non-negative matrix factorization. Decision and Control, 2004. CDC. 43rd IEEE Conference, (pp. 99 - 104 Vol.1 ). Atlantis. [35] Marin, J., Ragsdale, D., & Sirdu, J. (2001). A hybrid approach to the profile creation and intrusion detection. DARPA Information Survivability Conference & Exposition II. DISCEX '01. Proceedings, (pp. 6976). Anaheim. [36] Greenberg, S. (1988). Using Unix: collected traces of 168 users. Calgary: Research report 88/333/45, Department of Computer Science, University of Calgary. [37] Jian, Z., Shirai, H., Takahashi, I., Kuroiwa, J., Odaka, T., & Ogura, H. (2007). A Hybrid Command Sequence Model for Anomaly Detection. Advances In Knowledge Discovery and Data Mining , 4426 (1), 108-118. [38] Seo, J., & Cha, S. (2007). Masquerade detection based on SVM and sequence-based user commands profile. 2nd ACM symposium on Information, computer and communications security, (pp. 398-400). Singapore. [39] Zhang, H., & Sheng, S. (2004). Learning weighted naive Bayes with accurate ranking. Data Mining. ICDM '04. Fourth IEEE International Conference, (pp. 567-570). [40] Masrom, M., & Ismail, Z. (2008). Computer security and computer ethics awareness: A component of management information system. Information Technology. ITSim 2008. International Symposium, (pp. 1-7). Kuala Lumpur. [41] Yurcik, W., & Liu, C. (2005). A first step toward detecting SSH identity theft in HPC cluster environments: discriminating masqueraders based on command behavior. Cluster Computing and the Grid, 2005. CCGrid 2005. IEEE International Symposium, (pp. 111 - 120). Cardiff, UK. [42] Bishop, M. (2009). Reflections on UNIX Vulnerabilities. Computer Security Applications Conference. ACSAC '09. Annual , (pp. 161-184). Honolulu, HI. 99

[43] Robbins, A. (2005). Unix in a Nutshell (4th ed.). (M. Loukides, Ed.) Sebastopol, United States of America: O'Reilly Media Inc. [44] Lang, K. (1995). Newsweeder: Learning to filter netnews. 12th International Conference on Machine Learning (pp. 331-339). San Francisco: Morgan Kaufmann Publishers. [45] Leng, C., Wang, S., & Wang, H. (2009). Learning Naive Bayes Classifiers with Incomplete Data. Artificial Intelligence and Computational Intelligence. AICI '09. International Conference, (pp. 350-353). Shanghai. [46] Brosso, I., Ferreira, F., Bressan, G., & Ruggiero, W. (2010). Known User Continuous Authentication System. Consumer Communications and Networking Conference (CCNC), 2010 7th IEEE, (pp. 1-2). Las Vegas, NV. [47] Ferro, M., Pioggia, G., Tognetti, A., Dalle Mura, G., & De Rossi, D. (2009). Event Related Biometrics: Towards an Unobtrusive Sensing Seat System for Continuous Human Authentication. Intelligent Systems Design and Applications. ISDA '09. Ninth International Conference on, (pp. 679-682). Pisa. [48] Liu, J., Yu, F., Lung, C.-H., & Tang, H. (2008). A Framework of Combining Intrusion Detection and Continuous Authentication in Mobile Ad Hoc Networks. Communications. ICC '08. IEEE International Conference on , (pp. 1515-1519). Beijing. [49] Kohonen, T. (2001). Self-Organizing Maps (3rd ed.). New York, United States of America: Springer. [50] Lane, T., & Brodley, C. E. (2003). An Empirical Study of Two Approaches to Sequence Learning for Anomaly Detection. Machine Learning Vol. 51 , 73-107. [51] Johnson, R. A. (2005). Miller & Freund's Probability and Statistics for Engineers. Toronto: Pearson Education, Inc. [52] Wan, M. D., Wu, H.-C., Kuo, Y.-W., Marshall, J., & Huang, S.-H. (2008). Detecting Masqueraders Using High Frequency Commands as Signatures. Advanced Information Networking and Applications Workshops. AINAW 2008. 22nd International Conference, (pp. 596-601). Okinawa.

100

