USE OF TOPOGRAPHIC LIDAR POINT CLOUDS FOR BUILDING RECONSTRUCTION

by

YipengYuan B.A., Computer Science, York University, Toronto, Ontario, Canada, 2003

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Applied Science in the Program of Civil Engineering

Toronto, Ontario, Canada ©Yipeng Yuan, 2009
PROP~ OF RYEf1:;DN lJ~Pr'!!f)uTY UWRY

DECLARATION

I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the

purpose of scholarly research.

(Signature above) Yipeng Yuan

I further authorize Ryerson University to reproduce this thesis by photocopying or by other

means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

(SIgnature above) Yipeng Yuan

ii

BORROWER'S PAGE

Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

I

Name

Address

Date

Signature

,

,

I
i

I
I

I I

I

iii

USE OF TOPOGRAPHIC LIDAR POINT CLOUDS FOR BUILDING RECONSTRUCTION
YipengYuan Master of Applied Science, Ryerson University, Toronto, Ontario, Canada, 2009

ABSTRACT

Demand for three-dimensional (3D) urban models keeps growing in various civil and military applications. Topographic LiDAR systems are capable of acquiring elevation data directly over terrain features. However, the task of creating a large-scale virtual environment still remains a time-consuming and manual work. In this thesis a method for 3D building reconstruction, consisting of building roof detection, roof outline extraction and regularization, and 3D building model generation, directly from LiDAR point clouds is developed. In the proposed approach, a new algorithm called Gaussian Markov Random Field (GMRF) and Markov Chain Monte Carlo (MCMC) is used to segment point clouds for building roof detection. The modified convex huH (MCH) algorithm is used for the extraction of roof outlines followed by the regularization of the extracted outlines using the modified hierarchical regularization algorithm. Finally, 3D building models are generated in an ArcGIS environment. The results obtained demonstrate the effectiveness and satisfactory accuracy of the developed method.
iv

ACKNOWLEDGEMENTS

I would like to express my gratitude and appreciation to my supervisors, Professor Dr. Jonathan Li and Professor Dr. Michael A. Chapman for guiding me throughout my work, for their continuous and generous help and support. Their valuable advice and comments are exceptionally precious for me.

Many thanks to the members of examining cOIIlIJ?ittee, Professor Dr. Songnian Li, Professor Dr. Ahmad Shaker for reviewing and commenting my thesis.

Special thanks go to Yu Li for his encouragement and great help in my study. Time spent with him is rewarding and appreciated. I also acknowledge the support from my fellow graduate students, Xiangyu Si, Wenxia Tan, Yao Lu, Xian Guan and Faranak Amirsalari.

I would like to thank Tao Cui, Xu Lin and Yanrong Liu for their sincere friendship and encouragement during the hardest time while completing my thesis.

My deepest appreciation goes to my parents, my sisters and their families. Without their unconditional love and faith, I could not have achieved success in my career.

v

TO MY PARENTS

vi

TABLE OF CONTENTS

Declaration ................................................................................................................................ ii Borrower's Page ....................................................................................................................... iii Abstract .................................................................................................................................... iv Acknowledgements ................................................................................................................... v Dedication ................................................................................................................................ vi Table of Contents .................................................................................................................... vii List of Tables ............................................................................................................................. x List of Figures .......................................................................................................................... xi List of Acronyms ..................................................................................................................... xv 1. INTRODUCTION ................................................................................................................ 1 1.1. Motivations and Signification ................................................................................. 1 1.2. Obj ectives ................................................................................................................ 4 1.3. Thesis Structure ....................................................................................................... 6 2. TOPOGRAPHIC LIDAR FOR 3D CITY MODELING: AN OVERVIEW ........................ 8 2.1. Background of Topographic LiDAR ....................................................................... 8 2.2. Working Principles of Topographic LiDAR .......................................................... 10 2.3. Summary of Main Topographic LiDAR Systems ................................................. 15 2.4. Basic Ranging Formulas ....................................................................................... 17
vii

2.5. Segmentation of Topographic LiDAR Point Clouds ............................................. 20 2.6. Building Outline Extraction and Regularization ................................................... 26 2.7. Topographic LiDAR for 3D City Modeling .......................................................... 29 2.8. Chapter Summary .................................................................................................. 34 3. DESCRIPTION OF TOPOGRAPHIC LIDAR DATA ....................................................... 36 3.1. Topographic LiDAR Data Standards ..................................................................... 36 3.2. Data Format ........................................................................................................... 38 3.3. Data Products ........................................................................................................ 44 3.4. Error Sources ......................................................................................................... 46 3.5. Data Ground Processing ........................................................................................ 51 3.6. Chapter Summary .................................................................................................. 52 4. METHODOLOGY FOR BUILDING RECONSTRUCTION ........................................... 54 4.1. Segmentation Algorithm for Building Roof Detection ......................................... 54 4.1.1. Mathematical Model ................................................................................... 54 4.1.2. MCMC for Segmentation ........................................................................... 61 4.2. Building Outline Extraction and Regularization Algorithms ................................ 64 4.2.1. Building Outline Extraction Algorithm ...................................................... 64 4.2.2. Building Outline Regularization Algorithm ................................................ 68 4.3. 3D Building Generation ........................................................................................ 70
\

4.4. Chapter Summary .................................................................................................. 71
viii

5. RESULTS AND DISCUSSIONS ....................................................................................... 73 5.1. Study Area and Data .............................................................................................. 73 5.2. Experiments ........................................................................................................... 79 5.2.1. Segmentation................. ,............................................................................. 79 5.2.2. Filtering ....................................................................................................... 95 5.2.3. 3D Building Reconstruction in ArcGIS .................................................... 100 5.3. Accuracy Evaluation ........................................................................................... 106 5.4. Chapter Summary ................................................................................................. Ill 6. CONCLUSIONS AND RECOMMENDATIONS ............................................................ 113 6.1. Conclusions ......................................................................................................... 113 6.2. Recommendations for Future Research .............................................................. 115 REFERENCES ..................................................................................................................... 117

ix

LIST OF TABLES

Table 2.1 Main manufacturers oftopographic LiDAR systems ............................................. 16 Table 2.2 Comparison between topographic LiDAR and photogrammetry ........................... 34 Table 3.1 Existing common LiDAR data file formats ............................................................ 40 Table 5.1 Topographic LiDAR data specifications ................................................................. 74 Table 5.2 Aerial image specification ....................................................................................... 76 Table 5.3 Sample building properties ..................................................................................... 77 Table 5.4 Input constants ........................................................................................................ 80 Table 5.5 Parameters of sample buildings .............................................................................. 81 Table 5.6 Means and their colour representations ................................................................... 91 Table 5.7 Building roof outline extraction and regularization ................................................ 99 Table 5.8 Building height estimation .................................................................................... 104 Table 5.9 Shapefiles and their area coverage ........................................................................ 108 Table 5.10 Accuracy evaluation ............................................................................................ 109

\

x

LIST OF FIGURES

Figure 2.1 Light spectrum ......................................................................................................... 9 Figure 2.2 Paradigm of topographic LiDAR .......................................................................... 10 Figure 2.3 A topographic LiDAR system ............................................................................... 12 Figure 2.4 A LiDAR ranging unit ........................................................................................... 13 Figure 2.5 Selected scanning mechanisms ..................................................................... :........ 14 Figure 3.1 Sample topographic LiDAR data in ASCII format ............................................... 41 Figure 3.2 Generalized structure of binary file ....................................................................... 42 Figure 3.3 LAS format 1.1 ...................................................................................................... 43 Figure 3.4 Error components oftopographic LiDAR data ..................................................... 46 Figure 3.5 Illustrations of the results of misalignments .......................................................... 48 Figure 3.6 Time bias ............................................................................................................... 49 Figure 3.7 ALTM data processing flow .................................................................................. 52 Figure 4.1 Relationship between label field and data field ..................................................... 56 Figure 4.2 MRF property of topographic LiDAR data ........................................................... 58 Figure 4.3 GMRF parameters and their interrelationships ..................................................... 61 Figure 4.4 Flowchart illustrating Metropolis-Hastings algorithm ........................................ 63 Figure 4.5 Convex hull of a point set.. .................................................................................... 65 Figure 4.6 Convex hull computation procedure ..................................................................... 66
Xl

Figure 4.7 Regular concave shaped buildings ........................................................................ 67 Figure 4.8 Modified convex hull algorithm ............................................................................ 68 Figure 4.9 Line replacement of multiple points .................................................................... 69 Figure 4.10 Process of 3D building generation in ArcGIS ..................................................... 71 Figure 5.1 Topographic LiDAR point clouds of the University of Waterloo campus and surrounding area .............................................................................................................. 73 Figure 5.2 Reference map to topographic LiDAR image ....................................................... 74 Figure 5.3 Part of header file .................................................................................................. 75 Figure 5.4 Aerial image ofUW campus ................................................................................. 76 Figure 5.5 RIM.txt file ............................................................................................................ 78 Figure 5.6 Topographic LiDAR Images of sample buildings ................................................. 79 Figure 5.7 Segmentation of scene one .................................................................................... 82 Figure 5.8 Acceptance rate of k ...................................................................................... ......... 82 Figure 5.9 # Values against iteration ....................................................................................... 83 Figure 5.10 Acceptance rate of #1 ........................................................................................... 84 Figure 5.11 Acceptance rate of #2 ........................................................................................... 85 Figure 5.12 Segmentation of scene two .................................................................................. 85 Figure 5.13 Acceptance rate of k ............................................................................................. 86 Figure 5.14 # Values against iteration .................................................................................. 87 Figure\5.15 Acceptance rate of #1 ........................................................................................... 87
XII

Figure 5.16 Acceptance rate of /12 ........................................................................................... 88 Figure 5.17 Acceptance rate of /13 ........................................................................................... 89 Figure 5.18 Segmentation of scene three ................................................................................ 89 Figure 5.19 Acceptance rate of k ................................................................................ ............. 90 Figure 5.20/1 Values against iteration ..................................................................................... 91 Figure 5.21 Acceptance rate of /11 ........................................................................................... 92 Figure 5.22 Acceptance rate of /12 ........................................................................................... 93 Figure 5.23 Acceptance rate of /13 ........................................................................................... 93
\

Figure 5.24 Acceptance rate of /14 ........................................................................................... 94 Figure 5.25 Acceptance rate of /15 ........................................................................................... 94 Figure 5.26 Acceptance rate of /16 ........................................................................................... 95 Figure 5.27 Optometry building and its neighboring HRV .................................................... 96 Figure 5.28 HRV points removal (phase one) ......................................................................... 97 Figure 5.29 HRV points removal (phase two) ........................................................................ 98 Figure 5.30 File re-formatting of RIM building roof outline points ................................... 100 Figure 5.31 RIM building line coverage file in ArcGIS ..................................................... 101 Figure 5.32 RIM building roof shapefile .............................................................................. 10 1 Figure 5.33 Shapefiles of three selected buildings ............................................................... 102 Figure 5.34 3D view of selected buildings ........................................................................... 105 Figure 5.35 3D view ofUW campus .................................................................................... 105
xiii

Figure 5.36 Overlay of shapefiles ......................................................................................... 107 Figure 5.37 Overlay ofRlM building roof points from topographic LiDAR data and standard shapefile ......................................................................................................................... 111

\

xiv

LIST OF ACRONYMS
AGL AMSL ANSI AOI AR ASCII ASPRS CE CW DEM DGPS DSM DTM Above Ground Level Above Mean Sea Level American National Standards Institute Area Of Interest Acceptance Rate American Standard Code for Information Interchange American Society for Photogrammetry and Remote Sensing Commission Error Continuous Wave Digital Elevation Model Differential Global Positioning System Digital Surface Model Digital Terrain Model Phase Ranging Geospatial Information System Gaussian Markov Random Field Global Positioning System
,

FR
GIS GMRF GPS HRV

High Rise Vegetation

xv

IFOV IMU INS ISO ISWG LiDAR LRV MCH MCMC MMSE NDVI OA OE POS PR UTM UW WGS TIN

Instantaneous Field Of View Inertial Measurement Unit Inertial Navigation System The International Standardization Organization IEEE Committee on Earth Observations Standards Working Group Light Detection And Ranging Low Rise Vegetation Modified Convex Hull Markov Chain Monte Carlo Minimum Mean Square Estimate N orrnalized Difference Vegetation Index Overall Accuracy Omission Error Position and Orientation System Pulse Ranging Universal Transverse Mercator University of Waterloo World Geodetic System Triangulated Irregular Network

xvi

1. INTRODUCTION
Spatial information is gaining increasing attention from the general public, government agencies and commercial establishments. Topographic light detection and ranging (LiDAR), which integrates a laser scanner, a Global Positional System (GPS) receiver and an Inertial' Measurement Unit (IMU) , is capable of acquiring dense elevation point data over terrain rapidly, economically and accurately. Since the appearance of topographic LiDAR in 1990s, its applications extend from Digital Elevation Model (DEM) generation (Lee and Younan, 2003; Shan and Sampath, 2005), urban modeling (Haala and' Brenner, 1997; Schwalbe et aI., 2005) to disaster management (Webster et aI., 2004; Dash et aI., 2004). Topographic LiDAR has grown to a viable and valuable tool in the survey's toolbox (Jonas and Byrne, 2003). In this chapter, the motivations and the objectives of the study are illustrated, the structure of the thesis is summarized.

1.1. Motivations and Signification
Today more than half of the world's population lives in urban areas. As large cities around the globe keep propagating and become more populated, up-to-date geospatial information and three-dimensional (3D) city models are becoming increasingly important for applications such as city planning, crisis management, visualization, architecture, and landscaping (Tolt et aI.,2007).

Traditionally 3D city models are produced by conventional aerial photogrammetry or by semi-automated procedures for measurements in aerial imagery (Vosselman and Dijkman, 2001), in which the process is labour-intensive, time-consuming, expensive and error prone. Topographic LiDAR provides direct 3D information precisely over urban areas regardless of illumination conditions and reduces or eliminates the interpretation errors that may occur in traditional elevation data generation. These superior attributes make topographic LiDAR systems ideal for high-fidelity 3D urban model reconstruction. The scanning rate of modem topographic LiDAR systems is as high as 200 kHz with the precision to centimeter level. As a result topographic LiDAR datasets are notoriously famous for their huge volume of data size. When a topographic LiDAR system is in operation, the data collected are non-selective. The system records everything under the flying route, which includes less wanted data like vegetation in metropolitan areas. In the past decade a wealth of research activities developed various approaches to extract topographic features from topographic LiDAR data. Several standardized workflows for the reconstruction of 3D city models exist, they are either based on photogrammetry or on LiDAR or on a combination of both data acquisition techniques. However, the automated reconstruction of reliable and highly accurate 3D city models is still a challenging task, requiring a workflow comprising several processing steps. Some of the most relevant challenges are building detection, building outline generation, building modeling, and
\

last but not least, an accuracy assessment.
2

Building detection focuses on locating point sets covering building roofs in the dataset and is achieved by using either segmentation or filtering methods. It is the most critical step in building reconstruction process and determines the quality of the building model. In the building outline extraction step, edge points forming the shape of the building roof arc traced out from building roof points. Due to the nature of topographic LiDAR , some of building roof edge points are missing, which makes building roof outlines distorted. The building shape regularization method removes distortions produced in the previous step. In the last step, 3D city models are reconstructed in a 3D environment. Commercial software tools for building modeling require, generally, a high degree of human interaction and most automated approaches described in literature stress the steps of such a workflow (Dominger and Pfeifer, 2008).

As the demand for reconstruction of 3D building models keeps growing and high quality topographic LiDAR data become available, practical, integrated and efficient approaches are expected urgently. A greater number of research papers examine only one of aforementioned four aspects. For instance, Brovelli et al. (2002), Chen et al. (2007), Kilian et al. (1996), Kraus and Pfeifer (1998), Lee and Younan (2003), Sithole (2001), Vosselmann (2000) presented building detection approaches from gridded topographic LiDAR data. Huber et al. (2003) and Kim et al. (2006) depicted 3D building reconstruction methods with building roof shapes acquired from auxiliary data. Jwa et al. (2008) and Sampath and Shan (2007)
3

illustrated the building outline extraction and building shape regularization methods from building point set of topographic LiDAR data. These partly finished algorithms may cause confusion and contradiction when choosing proper combination of approaches to achieve 3D applications. At the same time, few researchers presented the complete methodology including above four aspects for 3D city modeling.

The work demonstrated in this study is motivated by presenting an approach for generation of 3D city models from topographic LiDAR point clouds, which comprises the entire sequence from building detection, extraction and regularization to reconstruction. The proposed approach works on topographic LiDAR point cloud directly without an interpolation process and does not need maps, construction plan or GIS data to establish building roof shape. This approach has a substantial advantage over previous methods as the 3D building models are created solely from topographic LiDAR data. The algorithm is versatile in term of data resolution and, is applicable for topographic LiDAR data with a density around two points per square meter. However, it is capable of processing topographic LiDAR data with higher point density.

1.2. Objectives
The objective of this study is to develop a methodology for the generation of 3D building models from topographic LiDAR point cloud data. The proposed approach consists of five

4

parts: building detection, roof outline extraction, building shape regularization, 3D building model creation and accuracy assessment. The methodology is implemented using the following four steps: 1. 2. 3. 4. Point cloud segmentation. Building roof outline extraction. Roof outline regularization. 3D building reconstruction in a GIS environment.

First, this study attempts an overview of the working principles of topographic LiDAR, physical components, data formats and various data processing algorithms, which offers the background for further study on point cloud segmentation and building reconstruction.

Second, this study attempts an extension of the literature to the utilization of Gaussian Markov Random Field (GMRF) and Markov Chain Monte Carlo (MCMC) algorithm for the segmentation of point clouds. The advantages of the algorithm include:
1.

The GMRF-MCMC algorithm works directly on topographic LiDAR raw data without any data conversion.

2.

The GMRF-MCMC algorithm does not require data pre-processing or support data.

The segmentation algorithm achieves satisfactory results based on an accuracy analysis of sample data.

5

Third, this study verifies building outline extraction and regularization algorithms from other researchers. Future studies will benefit in term of choosing proper matching methods with respect to the outcome from building extraction.

1.3. Thesis Structure
The thesis is comprised of six chapters.

Chapter 1 outlines the motivations of the study. Subsequently the study objectives are defined.

Chapter 2 provides a review of the working principle of topographic LiDAR systems and the methods used for building reconstruction from LiDAR data.

Chapter 3 describes the characteristics of topographic LiDAR data, various data formats, different levels of products, main error sources and data ground processing workflow.

Chapter 4 presents the methodology for building reconstruction. The GMRF-MCMC segmentation algorithm is described first, followed by the algorithms for building roof outline extraction and regularization. Finally the reconstruction of 3D building models is \ implemented in an ArcGIS environment.

6

Chapter 5 reports the experimental results of building roof detection, roof outline extraction and regularization, and the generation of 3D building models in the GIS environment. The accuracy of the developed method is discussed.

Chapter 6 presents conclusions related to the developed method and suggests future work to extend the study.

7

2. TOPOGRAPHIC LIDAR FOR 3D CITY MODELING:

AN OVERVIEW
As the name suggests, topographic LiDAR involves mounting a laser scanner on an aircraft or helicopter and setting it to scan the measurements of the surface along the flying route. In this chapter, some basic working principles and mathematical formulas are elaborated, then various algorithms on building extraction, building outline extraction and regularization and 3D city modeling will be examined and compared.

2.1. Background of Topographic LiDAR
Topographic LiDAR transmits laser beams to acquire elevation data of surface, its frequency is in the 500-1500 nm (0.5xl0-6 m -1.5xl0-6 m) range, with typical values of 1040-1060 nm (Baltsavias, 1999a). Figure 2.1 shows the composition of the light spectrum. The laser falls in the near infrared portion of the infrared region (red part close to visible light portion). According to the definitions from the European X-ray Laser Project, laser has three distinct aspects in contrast to other light sources: 1.
Monochromatic. The light emitted from laser is monochromatic, which mean it only

produces radiation of a specific wavelength, whereas visible light includes red, green and blue wavelengths (see Figure 2.1), and appears white/yellow when three wavelengths are added together.
\

8

2.

C(}liaet/('{'.

IleLlromugnetlc radiation can he regan.kd as a compnsition

or
fhe

mdividual wa\etrams (flx.:d \\U\clcngth rill:' a length and a position).

mdi\ Idua! \\'a\'etrain:, arc extremely long tor laser light, and adjacent \vavetrall1s oscillate
III

:,ynchronization manner. for visible light. the wavdrains an; qUltc short. Laser beams can be \ery thin. As a result. a laser is usually laser beam docs not diverge,

3.

fnlef7stly LI/ld emittunce

e tremely intellse as it i. concentrated on a tiny area .

which means it remains the "thin" state during its jOLllllCy, sn it is more focused than other light sourcc:, .
Frequency . Hz
1.0

,

10

,"

10'" ',,,

10~

10 I /0

'0 10 I

lk2

10'2 I 1~ 4

'4 10 ,

1~"

1 .8 10

1 · 10 10

I 12 10

I 14 10

10

1. 16

Wavelength . m L ong radll-' wav8S /

Infrared

liltraviolet Gamma rays

MICrowAves

TV, FM
VISible light

Figure 2. 1 Light spectrum (. cillincl Archi\'ing, Inc .. 2(08)

All the above important properties make the lascr the excellent candidatc of more accurate distance detcction . So shortly after tbc advent

f laser, very precise ranging was carried out

v. ith this new tool (Wehr ami Lohr, 1(99). LiDAR technology began to develop in late
196(),s, the tirst commercial topographic LiDAR mapping system became in 199_ (NOAA, 200(') thanks to the dcvclopm nt 0(' GPS and inertial na\ igation technologies.

l)

2.

Coherence. Electromagnetic radiation can be regarded as a composition of individual wavetrains (fixed wavelength plus a length and a position). The individual wavetrains are extremely long for laser light, and adjacent wavetrains oscillate in synchronization manner, for visible light, the wavetrains are quite short.

3.

Intensity and emittance. Laser beams can be very thin. As a result, a laser is usually extremely intense as it is concentrated on a tiny area. A laser beam does not diverge, which means it remains the "thin" state during its journey, so it is more focused than other light sources.
Frequency, Hz
1.0 I 10E> 3 10 10 10
I

12 10
I

14 10
I

101E>

I",
10°

10

14

I

,102

1~O

I

I

13 10
I

20 10
1

1k2

1'0-4

1k"

Wavelength. m

Infrared

I Ultraviolet
I

1~-$

10'.l'.l I

24 10 I

1'0- 10

1k12

,k 14

1k1E>

Long radio \4Vaves TV,FM

MICrowaves

E(t£.··x~-·rays-"i·G·a·m·m-a·ra·ys~

i

Visible light

Figure 2.1 Light spectrum (Sentinel Archiving, Inc., 2008)

All the above important properties make the laser the excellent candidate of more accurate distance detection. So shortly after the advent of laser, very precise ranging was carried out with this new tool (Wehr and Lohr, 1999). LiDAR technology began to develop in late 1960's, the first commercial topographic LiDAR mapping system became in 1993 (NOAA, 2008) thanks to the development of GPS and inertial navigation technologies.

9

2.2. Working Principles of Topographic LiDAR
Figure 2.2 demonstrates generic topographic LiDAR in operation. The preferred platforms of topographic LiDAR systems are fixed-wing aircrafts or helicopters. According to Baltsavias (1999c), helicopters cruise at 40-90krn/h with a typical flying height of 200-300m, and are typically used in applications of small width, elongated areas (e.g., power lines, corridor mapping, topographic and bathymetric mapping along coastlines) or small areas (e.g., airports, open pit mines). They are also capable of conducting data capture when low speed (flood mapping) or high maneuverability (road mapping) is required. The fixed-wing aircrafts usually travel at 160-270kmlh with altitude of 500-1 OOOm, which can cover a larger area in a relatively short time.

W= 2h Ian(o:)

GPS
Base station

Figure 2.2 Paradigm oftopographic LiDAR (Straatsma and Middelkoop, 2006)

When the aircraft flies over the target area, the scanner mounted emits LiDAR beams to the

10

ground and, the scanning rate could be as high as 200 kHz/so Absorptions and reflections occur with atoms, molecules and aerosol which float in the air during the emitted LiDAR beam's travel to the ground. These changes could be recorded for atmosphere remote sensing, which is the scope of atmospheric science studies. For photogrammetric applications the interactions with man-made or natural features on the ground should be concentrated on. After the LiDAR beams hit the ground, the same phenomenon happens as it does in the air, part of LiDAR beams are back scattered to the air and are recoded. The velocity of light is constant, 299,792 ,458 mis, and by calculating the difference between the time when LiDAR beams is generated and the time when its return' is captured" the accurate elevation data of sampled points on the earth can be determined. The divergence of LiDAR beam is quite limited and the ground surface covered by single LiDAR beam is limited as well. By adding oscillating devices, LiDAR beams can scan the earth in a systemic way covering a wider area in one strip of flight.

Topographic LiDAR point cloud data, like images in photogrammetry, must be geo-referenced, so they can be utilized by other geo-spatial applications. On-board GPS device provides the geo-Iocation of each sample point. Using ground GPS stations, high accuracy can be reached. INS device records aircraft orientation (i.e., attitude) data. Through the integration of LiDAR scanning data, GPS data and INS data, a densely sampled, geo-referenced yet highly precise elevation dataset is achieved. Millions of points are
II

sampled in one dataset, sometimes referred to as a point cloud.

A complete topographic ,LiDAR system consists of several integrated parts. Flood and Gutelius (1997), Wehr and Lohr(1999) and Webster and Dias (2006) all analyzed the composition of topographic LiDAR systems. These researchers agreed that the three parts should be included in order to maintain its full functionality.

Figure 2.3 shows a complete topographic LiDAR system. According to Wehr and Lohr (1999), a typical topographic LiDAR system is comprised of three main parts: ranging unit, opto-mechanical scanner and control and processing unit. The ranging unit comprises the emitting LiDAR beam and the electro-optical receiver. The LiDAR scanner deflects a ranging beam in a certain pattern, causing it to move back and forth along the flying path, so that an object surface is sampled with a high point density. The control and processing unit consists of scanning control and monitor equipment, position and orientation system (POS) and on-board computers to record elevation and auxiliary data.
i~;;';;------------'

I
I I

I I

~ '""- JI , _______
I _,

I

Figure 2.3 A topographic LiDAR system (Wehr and Lohr, 1999)
12

Figure 2.4 displays the composition of a ranging unit. A pulse generator usually applies xenon flash tubes, arc lamps, metal-vapor lamps or semiconductors to generate the LiDAR beam. Through the aperture on the transmitter, the LiDAR beam is emitted to the ground, at the same time the counter is triggered. When the LiDAR beam hits the earth, a tiny part of surface is illuminated that is called a footprint. The smaller the footprint size, the higher the accuracy of the LiDAR range unit. When the echo of LiDAR beam is captured by the receiver, the counter is stopped, the accurate round trip time of LiDAR beam is documented. The intensity of echo may be recorded as well, which is the ratio to the emitted the LiDAR beam, and symbolized as a digital number.

Figure 2.4 A LiDAR ranging unit (Pfeifer and Briese, 2007)

Since the divergence rate of LiDAR beam is so small, a scanner is introduced in order to cover the reasonable swath of the ground surface beneath the fly route. Figure 2.5 lists some of scanning mechanisms applied by scanners. An oscillating mirror usually produces Z-shaped lines and its scanning pattern is bidirectional. This type of systems involves stopping and accelerating when each scanning line is finished. The Palmer scan (mutating
13

mirrors) results in elliptical pattern due to its inclining mirror design. The rotating polygon scanners (including its variation-multifaeeted scanner) generate parallel lines and always start to scan from one direction. For a fiber scanner, an array of optical fibers is mounted in the focal plane of both transmitting and receiving lenses respectively. Two fiber arrays have identical number of fibers. Fibers on the transmitting side emit LiDAR beam to ground in sequence, fibers on the receiver side detect reflected LiDAR beam in sequence. No mechanical movement is involved during the set-up, which is distinct from the three above mentioned scanning patterns, so a higher scanning rate can be achieved.
fiber switch fiber

~

--

==- -

--.;;:::

Figure 2.5 Selected scanning mechanisms (Wehr and Lohr, 1999) From left: oscillating mirror, Palmer scan, rotating polygon, fiber scanner.

Due to the structure of scanners, elevation data collected at the margin area of the swath shows distinct properties and needs to be removed from the dataset. Usually there are certain overlapping parts between the adjacent strips to ensure those areas are normally sampled.

In the control and processing unit, control and monitor equipment integrate and synchronize components to ensure efficient and error-free functionality of the system. Data storage equipment offers depository media for data collected.
14

POS contributes critical auxiliary data to dataset and it consists of two components: an inertial measurement unit (IMU) and a differential global positioning system (DGPS). When topographic LiDAR is in operation, the IMU measures velocity and position adjustments of the aircraft, thus the pitch, roll and yaw of the aircraft can be acquired. The DGPS contains an on-board GPS receiver and a base GPS station on the ground within the vicinity of the . operation site, GPS mounted on the aircraft geo-references the sample points and the base GPS station can correct the inaccuracies of on-board GPS to insure high precision of geo-representation of a dataset.

2.3. Summary of Main Topographic LiDAR'Systems
Table 2.1 lists topographic LiDAR systems from five main manufacturers worldwide. Compared with major technical parameters of topographic LiDAR systems summarized by Baltsavias (1 999c), the functionality of current systems has dramatically improved. Scanning angle augments by 20° to 60°. Pulse rate reaches above 200 kHz, almost quadruples their predecessors. Range accuracy increases to around 5cm in contrast to more than 10cm a couple of years ago. The flying height has also increased, but not as much as other parameters. The current systems can operate on higher altitude, larger area, with a denser sampling rate and shorter time intervaL

15

Table 2.1 Main manufacturers of topographic LiDAR systems (modified from GIM International)
Manufacturer Type/name of scanner Dimension & weight Wavelength Pulse length Scanning method Leica ALS50-II 37x56x24cm, 30kg . 1,064nm Optech ALTM Gemini 26x19x57cm 23.4kg 1,060nm 17ns oscillating mirror 167kHz 50 0 4 0.05cm Rollei 39 Mpixe1 200-4000m unlimited 56x20x22cm 20kg; 1,500nm <4 ns rotating multi-facet mirror Max. pulse frequency Max. scanning angle Max.#. of echoes/pulse Range precision Cameras Fly height Max. operation time 150,kHz 75 0 4 <10cm 1.3 MP digital frame camera 200 - 6,000m
~17
i

Riegl LMS-Q560 400

Fugro FLI-MAP 50x30x30cm 30kg, 1,500nm 4ns rotating mirror 250kHz 60 0 4 2-3cm 11Mpix still and video 50 - 400m 3-6 hrs

I

TopoSys Harrier 56 N/A, > 15kg 1,550nm <4 ns rotating multi -facet mirror 200,Khz 45 0 or 60 0 Unlimited 5 - 30cm Applanix POSAV 410 30m/800m /l,OOOm > 8 hrs

i <9ns
oscillating mirror,

200kHz 60° unlimited 2cm IGI DigiCA.\1 30m/500m/ 1,000m
~

hrs

8 hrs

Besides the above advantages, current systems have two properties which were not well established in previous systems: multiple echoed recording and a digital camera. Multiple echoes occur when the LiDAR beam penetrates the surface of the object (e.g., tree canopies) or hits the border portion of objects (e.g., edge of a building). By applying these extra data, classification in the dense urban area can achieve higher accuracies. A digital camera has become a standard component of today's topographic LiDAR systems. Topographic LiDAR

16

is a single wavelength detector. Its gray scale images are obscure to visualize by naked eye while on board camera enables real-time views of the scanning surface underneath the flight route by offering images (multiband or visible band) at a fixed time interval. Combining these two kinds of images, true colour 3D imagery can be generated.

2.4. Basic Ranging Formulas
In topographic LiDAR ranging, two principles are utilized: pulse ranging (PR) and phase ranging (FR). PR calculates the time interval between emitted LiDAR beam and its echo, FR measure the phase difference between the transmi,tted and the returned LiDAR beam through continuous wave (CW) LiDAR beam generation. Both principles measure the travel time of the signal, however, different physical effects are utilized (Wehr and Lohr, 1999). Since the pulse LiDAR beam is applied in most of the systems (Wehr and Lohr, 1999, Flood, 2001, Pfeifer and Briese, 2007), this section will mainly describe formulas related to PR.

In the early stages of topographic LiDAR research, rich sets of formulas were examined by some renowned contributors in the community (Baltsavias, 1999b; Wehr and Lohr, 1999). In the following sections, basic formulas are elaborated for the interest of remote sensing. For simplicity, the attitude of aircraft is assumed zero while the flying height and ground speed are assumed as constants. 1. Range

17

Range is the distance from LiDAR scanner to ground surface, and is represented by

R, c is the velocity of light, t is traveling time of LiDAR beam captured by counter.

R=-c*t
where t is the round trip time and needs to be divided by two. 2. Maximum Range

1 2

(2.1)

(2.2)

The maximum range (Rmru) is limited by the maximum traveling time (tmax) of LiDAR beam and the time that could be captured by the counter in the scanner. 3. Range Accuracy (2.3)

Range accuracy (8) is dependent on the wave length (A) of the LiDAR beam and inversely proportional to the square root of signal to noise ratio (SIN). Typical factors contributing to the ratio are the cloud condition in the sky, the power of received signal and radiation property of the terrain surface. 4. LiDAR Beam Divergence Typically the value of instantaneous field of view (IFOV) is applied to describe the divergence of LiDAR beam. IFOV is detennined by the wave length of LiDAR (A) and the diameter of the aperture (D) on the ranging unit.

18

IFOV=2.44~
D

(2.4)

The emitted LiDAR beam and its echo share the same aperture, which ensures that the terrain surface covered by the LiDAR beam is always within the receiver's field of view. The value oflFOV is normally between 0.3-3mrad. 5. LiDAR beam Footprint Diameter As shown in Figure 2.2, let h be the flying height of the aircraft and a be the half angle value between emitted LiDAR beam and its echo.
w=2h*tan~)

(2.5a)

Since a is relatively a small value, w can be approximately evaluated by the following equation.
w

= 2h * IFOV

(2.5b)

where h is measured in metre and IFOV in mrad. 6. Scanning Swath Let Q be the swath width of the topographic LiDAR system, h is the flying height of the aircraft and fJ is the swath angle of the scanner.

Q=2h*tan(fJ) 2
7. Minimum Required Number of Strips

(2.6)

Multiple strips are required if the width of target area is larger than the scanning swath of the topographic LiDAR system. Let N be the minimum number of strips, L
19

is the width of ground surface region of interest, Q is the scanning swath and p is the overlapping fraction. N= L (1- p)*Q

(2.7)

When N is not an integer, one more strip is needed to complete the mapping. 8. Point Density Point density refers to the number of sampled points within a unit area (usually one square metre). A higher point density can achieve more accurate rate in mapping elevation data. Let d be the point density,jis the frequency of LiDAR, I is the strip length, v is the velocity of aircraft, N is the number of strips and A is the total area covered.

d =

A

(2.8)

Two main factors influence the point density: the design of ranging unit, and the flying speed; the lower speed, the higher the point density.

2.S. Segmentation of Topographic LiDAR Point Clouds
The topographic LiDAR raw data consist of a combination of terrain, buildings, vegetation, roads and other man-made structures (Charaniya et aI., 2004). There have been a large number of works concentrating on data mining from topographic LiDAR data and they can \be classified into two categories: filtering and segmentation. In this section both approaches

20

are reviewed in detail.

Filtering refers to the elimination of points caused by reflections of LiDAR pulses on vegetation and buildings (Vosselman and Maas, 200 I). After filtering, ground and non-ground points are separated. Ground points are widely employed for generating DEM, . which is essential for many topographic, hydrographic, agricultural, and construction applications (Fowler, 2001). Above terrain features can be further extracted from non-ground points and building footprint derivation is one of main tasks. Most topographic LiDAR data
,

filtering techniques consist of morphology, slope and surface'approaches.

Morphology filters are very popular in optical image processing and were introduced to handle topographic LiDAR data in the 1990s. Kilian et aL (1996) applied the lowest elevation value plus a certain band width threshold (determined by accuracy level of LiDAR scanner) within a moving window to remove building roof and vegetation points. Zhang et al. (2003) introduced a progressive morphology filter, which engaged a series of windows whose size grew in increasing order to generate DEM. Combined with elevation difference thresholds, the algorithm can create smoother DEM without pre-defining the size of windows and with improved efficiency. Arefi and Hahn (2005) designed construction element opening which held feature needs to be removed through morphology filtering, by overlaying opening with rasterized topographic LiDAR image and imposing feature constraints like shape, size
21

and orientation, not only DEM, but also buildings and vegetation can also be separated.

Slope-based filters were developed by Vosselmann (2000). It utilizes the slope of line connecting any two points in topographic LiDAR data set as benchmark to determine terrain points. The algorithm assumes that inclinations among ground points are obviously distinct from those between ground and non-ground points, by comparing gradients with pre-defined threshold to detect terrain points. Roggero (2001) constructed a local linear regression model to estimate intercept, gradient and its standard deviation. Then, a curve function of ground points is established based on these parameters to separate terrain points. Buildings and vegetation can be further segregated from non-terrain points by variance difference in their spatial distributions. Sithole (2001) modified Vosselmann (2000)'s algorithm by introducing a threshold variable, its value varies with respect to the steepness of the terrain and is acquired by computing slope map based on gridded minimum height image in which pixel values are the least elevations within the local neighborhood.

In surface-based filter approach, mathematical equation which best describes the curve of terrain is established. Kraus and Pfeifer (1998) designed weight functions to recursively remove non-terrain points above interpolation surface. After each iteration, the points remaining are getting closer to the actual ground elevation until the cycle limit is reached. Schickler and Thorpe (2001) modified Kraus and Pfeifer (1998)'s algorithm by
\

22

incorporating the concept of surface classes to guide the estimation process and additional curvature and slope constraints to control the shape of the estimated surface. With auxiliary mass-points and break line data, the algorithm can create smoother terrain surface model with a reduced noise level. Lee and Younan (2003) added a post processing step to optimize the result acquired from Kraus and Pfeifer (1998)'s algorithm where the terrain points obtained' were compared with the original topographic LiDAR data to extract the matched points with identical georeference characteristics, then interpolation was implemented for refinement.

,

The performances of different filtering algorithms were reviewed by Sithole and Vosselman (2004). They concluded that none of them are capable of handling every kind of data reflecting various terrain types. All above mentioned filtering algorithms suffer from different problems. The choice of moving window size is critical in morphological filters. The ideal way to locate it with respect to the original topographic LiDAR data is still under investigation. In slope filtering, deciding how to locate the optimal slope of a point with its neighboring points which matches real terrain situation is not finalized yet. Surface-based filtering algorithms require long processing time and it is difficult to extract the exact edge points because the scan data are made up of discrete points and edge points are not always included in the scan data (Woo et aI., 2002). Another common issue for filtering algorithms is reformatting. As a pre-processing step, irregular distributed 3D points are converted into rasterized images, the nodes of the gridded network have to be constructed by interpolation
23

in the original data set, and consequently some of the information will be lost (Roggero, 2001). In recent years, some researchers started to apply new filtering algorithms on point cloud data directly. Shan and Sampath (2005) proposed a two directional labeling approach to generate DEM. Lin and Wu (2006) presented sweep line method to extract off-terrain points.

In segmentation, points are grouped into segments according to some homogeneity criterion (Tovari and Pfeifer, 2005). In most cases, result of segmentation reveals topographic LiDAR data more explicitly than simply terrain points and object points, so filtering can be regarded as special case of segmentation, which results in two groups without regard to what features are involved in point cloud data. Traditional segmentation approaches can be classified into two categories: edge detection and region growing.

Edge detection is performed by searching the discontinuities along the borders of closed terrain features. Fan et al. (1987) employed zero-crossings and local extrema of curvature along a given direction to extract edge points, by grouping these points into different classes, important physical properties are distinguished from range data. Brovelli et al. (2002) applied spline threshold to separate ground points and non-ground points, then edge points are connected, if edges are closed and heights of points within edges are greater than the mean heights of edge points, then they are labeled as terrain features. This algorithm
24
IS

implemented in GRASS (Geographic Resources Analysis Support System). ThuyVu and Tokunaga (2002) engaged wavelets to partition range images (converted from topographic LiDAR raw data), then object edges are detected using scale factor, as a result, features with different sizes and shapes are distinguished.

Region growing, on the other hand, conglomerates the points sharing similar geometrical properties or belonging to the same terrain features. Jiang and Bunke (1994) reported a straight line based method. A small portion of lines are selected by optimal criterion as seed
\

region, neighboring lines are added into the region until no new line segments are detected in the data set. Lee and Schenk (200 l) utilized Delaunay triangulation to represent topographic LiDAR raw data and then those triangles are grouped within adjacency area according to plane parameters and the roughness. Finally patches with similar geo-spatial properties are merged to form meaningful terrain features. Gorte (2002) introduced a Triangulated Irregular Network (TIN) approach, the algorithm iteratively merges TIN meshes created from topographic LiDAR raw data into planar segments by calculating similarities among adjacent triangle meshes. After each iteration, planar segments become larger until all the small triangle structures are properly grouped.

Both of aforementioned approaches have some limitations. Edge-based methods run short when a portion of an edge shows a small difference or when regions are homogeneous (Woo
25

et aI., 2002) or the edges are not closed. Region-growing methods have problems in noisy data and data in which points from different surfaces overlap (Sithole, 2005). Besides, some of the algorithms still suffer from information loss resulting from rasterization. In recent years, novel techniques to segment topographic LiDAR data have been introduced with some of the typical ways including a split and merge approach (Wang and Tseng, 2004), a graph approach (Sithole and Vosselman, 2005), an object approach (Lohmann, 2002) and a scanning line approach (Han et aI., 2007).

2.6. Building Outline Extraction and Regularization
Building outlines refer to roof boundaries that segregate the building areas from other terrain features like vegetation or the ground. There are two general assumptions about the building outlines: walls of the buildings are perpendicular, roof areas equal to building planar coverage. These assumptions simplify the work and can produce more generalized building models.

Since LiDAR beams are randomly emitted during flight operation, some points may be missing at the building roof boundaries or shadowed by trees nearby the building. Usually building edge points extracted are zigzagged and further refinement called regularization is needed to regularize the shape of the building roof before they can be employed in a geo-database for3D building reconstruction.
\

26

In the early stage of 3D building modeling, due to the limitations from both topographic LiDAR technology and immaturity of algorithms, the point cloud data are rasterized before processing. Meaningful building outline extraction and regularization operations cannot be performed on raster data. There some popular remedies including digital cadastral map (Haala and Brenner, 1997), ground plans (Vosselman and Dijkman, 200 I), aerial images (Huber et at, 2003) and orhoimages (Kim et aI., 2006) to provide regularized building shapes for 3D city modeling.

In recent years, as scanning rate and accuracy level increase, it becomes possible that 3D building models can be reconstructed solely from topographic LiDAR raw data without rasterization and other supporting data. After points covering building roofs are detected, edge points have to be separated from non-edge points in order to estimate building roof outline. A traditional convex hull algorithm is the start point of most edge point extraction algorithms and some modifications are applied to make the algorithm work for various shaped buildings. Lee et at. (2007) separated building points by grids and restricted the search space within current and adjacent grids. By joining the edge points within each grid, building edge points are achievable. The algorithm presented in Sampath and Shan (2007) started with corner edge point, and then calculates localized minimum clock-wise angle repeatedly to trace the next edge point until the start point is reached.

27

Line simplification, aiming at reducing the number of boundary segments in a polygon, shares some similarities with building outline regularization. There are a number of algorithms dealing with this application in cartography for decades. Douglas and Peuker (1973) proposed a simple algorithm that recursively eliminates intermediate point if its distance to a polygon is less than distance threshold, otherwise it is maintained. The algorithm terminates when all of the points in the polygon are checked. Jenks (1989) introduced neighbourhood algorithm. It considers three points for each iteration, if the distance from middle point to the line connecting the first and the third point is less than distance tolerance, middle point is discarded and point next to the third point is included in a three point group, otherwise the first point is kept and next three points are chosen to continue calculation until all the points are checked.

The algorithms for building outline regularization from topographic LiDAR point clouds go back in the 1990s. They are based on line simplification algorithms and take the properties of the building into consideration. 'Weidner and Forstner (1995) presented a minimum description length-based approach. Four points are selected as a group of polylines to fit in one of ten regularization models. With consideration of orthogonality of adjacent polylines, models are created by either reorganizing two middle points or removing one of the middle points. Sampath and Shan (2007) developed a hierarchical regularization approach. First long line segments from building outline are extracted and their linear equations are fixed through
28

a least squares solution, then long line segments are divided into groups which are perpendicular each other, finally all line segments are determined by applying the slopes of lines as estimation parameters. Jwa et aI. (2008) modified Weidner and Forstner (1995)'s algorithm, such that the directionality all the edge segments are labeled according to compass line filter and weighted with scores, and then three points are chosen in one time to fit in one of three hypothetical solutions by the scores of their line segments.

2.7. Topographic LiDAR for 3D City Modeling
The 3D city model consists of landmarks, buildings, vegetation, traffic and transportation networks, etc, among which buildings receive most interest from city planners, environmental managers, commercial organizations and the general public.

Traditionally, 3D objects are reconstructed by two properly angled 2D optical images, which are called a stereo image pair. In the geo-science domain, photogrammetry is a classic, accurate and operational approach for 3D data acquisition (Tao, 2005). However manual 3D processing of aerial images is time consuming and requires the expertise of highly qualified persons (Deng et aI., 2004). Rescarchers are applying multi-sensor data or fusion of data from different sources to recreate 3D city models out of consideration of cost, efficiency and accuracy.

29

As a newly emerged remote sensing technique, topographic LiDAR mainly focused on generation of DEMs or Digital Terrain Models (DTMs) at early stage thanks to its unique properties presented in previous section. Several researchers including Kraus and, Axelsson (2000) and Baltsavias et al. (2001) and Pfeifer (1997) examined the suitability through different approaches. Modem topographic LiDAR systems are capable of generating much denser sampling rate (more than 200 kHz), buildings and other man-made features in urban areas are represented by hundreds of points, which makes it possible to model 3D cities using topographic LiDAR point cloud data.

Due to topographic LiDAR's ability to directly geo-referencing 3D features, it is natural to integrate topographic LiDAR data with existing 2D maps for fast, accurate and highly automated acquisition of 3D maps (Elberink et aI., 2006). Haala and Brenner (1997) segmented the Digital Surface Model (DSM) from topographic LiDAR data to extract building regions, then building parameters were defined by a least squares adjustment procedure. Based on these predefined references roof elevations were estimated, with available building map data 3D city model were recovered. Vosselman and Dijkman (2001) applied Hough transform algorithm to extract planner faces of buildings from topographic LiDAR point cloud, by the support of building ground plan, building models were recovered.

Besides 2D maps, optical images are another popular remote sensing data type utilized
30

together with topographic LiDAR data to achieve better outcome in 3D city modeling. Huber et al. (2003) extracted building shapes and boundaries from aerial images and DSM from topographic LiDAR data, through fusion of two data layers, accurately positioned 3D buildings were remodeled. Rottensteiner et aL (2003) computed normalized difference vegetation index (NDVI) from green and near infrared bands of the geocoded multi-spectral images, which helped to remove vegetation regions from DSM created from topographic LiDAR data. After traditional morphologic filtering processes, building points were preserved for 3D building retrieval. Kim et al. (2006) suggested a new algorithm to produce the true ortho-images from optical images through a co-registration process with topographic LiDAR data of the same coverage. By draping an ortho-image on top of the DSM, a 3D city model can be created.

Some researchers even piloted to integrate multiple data sources for 3D city modeling. Steed et aI., (2004) and Vosselman (2002) applied aerial images, topographic LiDAR data and existing 2D vector maps to create 3D city models in a purpose to make best use of available data, reduce work load and achieve higher level of automation.

As topographic LiDAR technology evolves, it has become reality that 3D city models are created solely from topographic LiDAR raw data without any supporting data, researchers concentrate more on this topic in recent years. Rottensteiner and Briese (2002) proposed a
31

subtraction approach. First DSM and DTM are produced through interpolation, non-ground points are picked by subtraction of DSM and DTM, and then building points are filtered out by proper threshold, in final step buildings are reconstructed geometrically by fine filtering and modeling procedures. Hofmann (2004) introduced TIN structure to establish 3D buildings. Topographic LiDAR raw data are re-formatted by TIN pattern, each triangle is recorded by spherical coordinates and those coordinates are displayed in a Cartesian coordinate system. Through clustering algorithm, small TIN patterns are grouped into several clusters, where these clusters are further assembled to form the roof and wall of the building according to certain thresholds. This algorithm can recover a building roof in more detail. Tarsha-Kurdi et al. (2006) proposed new approach by utilizing first returns of topographic LiDAR data to extract 3D buildings. Points of first return contain ground points, building roof points and vegetation crown points, ground points are filter out by proper height threshold, rest of the points are rasterized. By integrating elevation information of each point and a filtering technique in an optical image, building points are extracted and applied for 3D building recovery.

From above analysis it is can be clearly observed that topographic LiDAR data has proven to be a rather powerful source for a wide range of 3D GIS object tasks (Schwalbe et aI., 2005). According to Hofmann (2004) and Tarsha-Kurdi et al. (2007) two approaches are adapted for 3D city modeling applications by employing topographic LiDAR data. The first approach is
32

model driven, a range of basic building models are established in advance, then 3D building models are recovered by searching the best matching models in the building model library. Haala, and Brenner (1997) and Maas (1999) took this track. But this approach has constraints and is usually limited to simple building models. Complex ground plans may be split into parts, which can be modeled individually (Haala et aI., 1998). The second approach is data driven, in contrary to model driven, the buildings are re-established completely depend on the infonnation from topographic LiDAR data. This approach works on arbitrary shaped building roofs, however, it requires data with a higher sampling rate and more complicated algorithms. Since data driven approach is capable of modeling the 3D cities more faithfully, the majority of researchers focus on this track and most of the literature reviewed in this section belong to this domain.

Though topographic LiDAR is gaining increasing importance over photogrammetry, it does not mean that topographic LiDAR will replace the latter completely in 3D city modeling, because both technologies have their strong and weak aspects. As indicated in Table 2.2, topographic LiDAR is superior in tenns of data collection, direct 3D coordinates acquisition and vertical accuracy. Photogrammetry is predominant in semantic and break line infonnation and planimetric accuracy. In the future the choice of one technique over another will mainly depend on case requirements.

33

Table 2.2 Comparison between topographic LiDAR and photogrammetry (Kim et aL 2006) Topographic LiDAR dense information along homogenous surfaces day or night data collection direct acquisition of 3D coordinates vertical accuracy is better than planimetric accuracy no inherent redundancy positional; difficult to derive semantic information almost no information along break lines planimetric accuracy is worse than vertical accuracy Photogrammetry almost no positional information along homogeneous surfaces day time data collection complicated and sometimes unreliable matching procedures vertical accuracy is worse than planimetric accuracy high redundancy rich in semantic information
'"0
0
'"1
(JJ

!

'"0
0
'"1
(JJ

0

n
i;j
(JJ

i

n 0
i;j
(JJ

dense positional information along object space break lines planimetric accuracy is better than vertical accuracy

Based on the observation of properties of both topographic LiDAR and photogrammetry, Ronnholm et aL (2007) proposed a concept of integration of both methods to achieve optimal outcome. Four levels of integration, object-level integration, photogrammetry aided by LiDAR scanning, LiDAR scanning aided by photogrammetry and tightly integrated LiDAR scanning and optical images are elaborated, which provides general guide lines in choosing most appropriate integration to satisfy project criterions.

2.8. Chapter Summary
In the first part of this chapter, several topics about topographic LiDAR systems including their composition, basic ranging formulas and properties of current systems are discussed,
34

which offers a background for further study_ In the second part, different approaches on building detection, building roof outline extraction and regularization, 3D city modeling from topographic LiDAR data are reviewed. The difficulties and challenges remaining in these areas are examined. The objectives and structure of this thesis are presented.

35

3. DESCRIPTION OF TOPOGRAPHIC LIDAR DATA
In this chapter some important aspects regarding topographic LiDAR data are discussed in detail. They are essential for choice of proper topographic LiDAR data products, algorithm design and data accuracy evaluation.

3.1. Topographic LiDAR Data Standards
Topographic LiDAR systems have been developed through increasing demands for high-accuracy and low cost surface elevation data collection. Each manufacturer adopted its own standard regarding topographic LiDAR data collection, data format, accuracy assessment, etc. This pure commercial behavior, on one hand, makes vendors focus on competing to have larger market share while ignoring cooperation in term of facilitating customers to choose desirable topographic LiDAR system wisely, on the other hand, greatly hinder the interoperatability and post processing of topographic LiDAR data.

As topographic LiDAR implicates a wider array of mappmg and photogrammetry applications, the industry standards are in high priority for geomatics community in order to regulate the development of this comparatively new technology. The American Society for Photogrammetry and Remote Sensing (ASPRS) has established several guidelines and industry standards which have been widely used by various users. The main works include:
\

36

1.

Digital Elevation Model Technologies and Applications: The DEM Users Manual. The second version of this manual was released in 2007. It covers a wide variety of topics about the DEM including an overview of the topographic LiDAR systems, procedures of creating LiDAR-based DEMs, the advantages and limitations of topographic LiDAR, data processing software and LiDAR-derived DEM accuracy assessment (Maune, 2008).

2.

ASPRS LiDAR Guidelines: Vertical Accuracy Reporting for LiDAR Data This document identifies the vertical accuracy reporting requirement when analyzing elevation data generated using airborne light detection and ranging or laser radar (LiDAR) technology. It consists of three parts: first part lists accuracy requirements (horizontal accuracy and vertical accuracy) when specifying the quality of elevation data; second part deals with Accuracy Assessment and Reporting, starting from designing accuracy tests, selecting and collecting and checkpoints, Deriving Dataset Elevations for Checkpoints, to computing errors and analyzing errors; third part is about how to Calculating and Reporting Vertical Accuracy_ Data, 2008). (ASPRS LiDAR Guidelines: Vertical Accuracy Reporting for LiDAR

3.

ASPRS LiDAR Guidelines: Horizontal Accuracy Reporting This is the accomplishment of vertical accuracy reporting, where in some cases horizontal accuracy has to meet certain level. In this document, several popular
37

minimum horizontal accuracy standard including ASPRS 1990 are listed, as well as their differences and. conversion formulas. ASPRS also published Planimetric Accuracy for large scale LiDAR maps. In the last part, cornmon errors and their effect on horizontal accuracy are investigated, correct operation instructions are provided as well (ASPRS LiDAR Guidelines: Horizontal Accuracy Reporting, 2008).

3.2. Data Format
Comparing with other imagery widely applied in remote sensing and mapping industries, the information included in the topographic LiDAR data is relatively simple. There are millions of points in one dataset, each point is georeferenced in a geographic coordinate system like Universal Transverse Mercator (UTM) system and assigned with an elevation value. Optionally each point can be associated with intensity value, time tag or colour (red, green and blue) value.

At the initial stage of topographie LiDAR advancement, each manufacture adopted its own data delivery format out of hardware and software properties and requirements from clients. As a result there are many different data formats and they are company-dependent.

Table 3.1 lists major topographic LiDAR formats available in technical reports and academic
\

38

literatures. Except for a few exceptions (index file, project file or DTM file), two data formats, ASCII and binary are widely applied. ASCII is abbreviation for American Standard Code for Information Interchange, it is numerical representation of English alphabet and symbols .. ASC, .DAT, .PTS, .PTX, .RAW, .TXT, .WRL, .XYZ are all generic forms of ASCII format, they are plain text files and can be edited by any text file editors. Binary format takes another path, where all the contents in the file are represented in binary numbers (0 and 1), extra information needed to be provided on how to interpret binary number correctly in order to apply vanous functions on , dataset. Formats such

as .3DD, .BIN, .LAS, .LDA, .TEW, .TS, .ZFC and .ZFX all belong to this group.

39

Table 3.1 Existing common LiDAR data file formats (Samberg, 2007)
I

Format

Type binary ASCII binary propriety propriety ASCII propriety propriety binary binary propriety propriety ASCII ASCII propriety propriety ASCII binary binary ASCII ASCII worksheet ASCII binary binary Riegl text file TerraScan

Notes

1.3DD : .ASC

: .BIN
.CMP .CSD .DAT .DVZ

Optech's REALM, comprehensive format Optech's REALM text file project file in FUSIONILDV Optech's ILRlS parser ASPRS LAS FUSIONILDV index file in FUSIONILDV index file in FUSION/LDV TerraScan classification file Leica Geosystems Leica Geosystems QT Modeler, approximation ungridded point clouds, no interpolation or

.IXF
.LAS .LDA .LDI .LDX .PTC .PTS .PTX .QTC .QTT .RAW .TEW .TS .TXT .WRL ..XML
I
i i

QT Modeler, surface model, gridded data set raw topographic LiDAR points TopEye Mark II TerraScan text file used in 3D range imaging Microsoft Excel DTM file text file Zoller+Frohlich Zoller+Frohlich

.xLS

. .xYZ .ZFC .ZFS

Topographic LiDAR data file in ASCII format looks a like a giant table, each tuple delineates a sampled point, specifying its geospatiallocation (x and y value), elevation value (z value) and intensity value, etc. Figure 3.1 shows part of sample data in ASCII format.
40

538794.161962905550 538794.756933608670 538795.560644546170 538796.155615249300 538796.750585952420

4810036.491672001800 4810035.687900029100 4810036.282809697100 4810035.479037724400 4810034.675204716600

349.615998804569 350.090983927250 349.279453366995 349.753313004971 351.313596546650

58 58 59 59 59

geospatiallocation

elevation

intensity

Figure 3.1 Sample topographic LiDAR data in ASCII format

Under this format, topographic LiDAR dataset can be edited on almost any computer without any special software, it also convenient to
segmen~

one dataset or combine multiple datasets.

This format also widely accepted as input file format by science or engineering computation software like SAS or Matlab.

Figure 3.2 shows the generalized structure of binary file. The header contains general information about the file and information to process the data sections. The relocation table contains records used by the link editor to update pointers in combining binary files. The symbol table holds records used by the link editor to cross reference the addresses of named variables and function between binary files (Inside Mac Media, Inc., 2008). Sections 1 to n hold the raw data.

41

Header Relocation Table Symbol Table Section I Section 2

I

... ...
Section n Figure 3.2 Generalized structure of binary file (Ung, 1996)

As topographic LiDAR technology advances, it is necessary to have a standard data format that can be integrated by various processing software to simplify the distribution and manipulation of datasets. In 2003, ASPRS published LiDAR Data Exchange Format Standard 1.0, which is referred to as "LAS" format. In 2005, LAS 1.1 was released, while LAS 2.0 is under development. LAS format applies binary format, with file extension ".las". According to ASPRS (LAS format, 2008), the following reasons contribute to the birth of LAS format. 1.

lnteroperatability. Data cannot be easily taken from one system or process flow to
another with proprietary systems.

2.

Performance. Processing performance

IS

degraded because the reading and

interpretation of ASCII elevation data can be very slow and the file size can be extremely large.

3.
\

Accuracy. All raw data and information specific to the LiDAR data collection is lost.
This can inhibit troubleshooting and debugging of problem data sets and limit
42

third-party analysis of data integrity

Figure 3.3 illustrates the structure of the LAS format. A complete topographic LiDAR dataset in LAS format 1.1 should carry three parts, public header block, variable length records and point data. In the public header block, general system information like unique file number, type of scanner involved and software information are clarified and data information is also included. Variable length records is developer defined project information, it varies from individual developer. Point data part is the critical , part of dataset, x, y and z values, colour and classification of each point are recorded. The full version of LAS 1.1 is accessible through http://www.asprs.org/society/divisions/ppd/standards/asprs_las_ format_v II.pdf.

Example data Basic structure

System Information
IOE---~

Public header block

Total number of records Minimax values

Variable length

L-------r-~--~

1---+l~1

Developer defined

Figure 3.3 LAS format 1.1 (Barber, 2006)

LAS format has be widely accepted both in the USA and internationally so far. Major

43

photogrammetric software and topographic LiDAR providers (e.g., Z/I Imaging, Leica Geosystems and Optech), and the US Army Corps of Engineers Topographic Engineering Center (TEC) have adopted the LAS data format. According to Samberg (2007), some professional organizations including American National Standards Institute (ANSI), The International Organization for Standardization (ISO), ISPRS, The IEEE Committee on Earth Observations Standards Working Group (ISWG) have also started to look over ASPRS LAS. Commercial GIS and image processing software packages including ArcGIS 9.2 Workstation, ENVI 4.3, ERDAS Imagine 9.1, GIS Global Mapper 8.0, Leica Photogrammetry Suite 9.1, QT Modeler 6.0, PCI Geomatica 10.0 all use LAS as the standard input file format. Therefore, LAS format is also used in this study in this study.

3.3. Data Products
Collected topographic LiDAR data can be customized or post-processed by a commercial data provider to generate data products with different level of complexity. Flood (2002) defined a series of data products which are commonly accepted by the industry and can be used as guidelines when choosing the best matching topographic LiDAR product from market.

Table 3.2 lists five different levels of products available in general, with costs arranged from the l~west to the highest. Level 1 products contain all the sampled points and have a large data

44

Table 3.2Product definitions for topographic LiDAR data (Flood, 2002)
Level Name Description

1

Basic or All of the post-processed topographic LiDAR data properly geo-referenced "All but with no additional filtering or analysis. Suitable for those organizations Points" with in-house data processing tools and capabilities or who work with a third-party data processing service bureau. Cheapest and fastest product. Using either proprietary algorithms or third-party software tools, the data provider will automatically filter the point cloud in to points on the ground, the "bare earth", and points that are not ground. There is generally no classification of the non-ground points in to separate features types (buildings, trees, etc.) and the ground points generally include some percentage of residual features not extracted by the automated classification algorithms. Suitable for those organizations with in-house data processing tools and capabilities or who work with a third-part data processing service bureau.' Common
r

2

Low Fidelity or "First Pass"

deliverable.

Usually

same

cost/schedule as All-Points 3 High Fidelity or "Cleaned A fully edited data set that has been extensively reviewed by an experienced data analyst to remove any artifacts created by the automatic classification routine and provide a "99%" clean terrain model. The low fidelity data are analyzed and classified manually, usually with supporting imagery. Labor-intensive product. Moderate cost but with longer delivery schedules, especially on larger projects.
4

"
Feature Layers

Further processing using a combination of automated and manual classification to identifY features of interest such as power lines or building footprints. Generally completed in-house or using a service bureau or third-party data processor that specializes in the desired application and has experience or has developed customized tools for the specific type of feature extraction. Usually more expensive product than high fidelity terrain model.

5

Fused

A further refinement of the topographic LiDAR data product achieved by the fusion of the topographic LiDAR-derived elevation data set with information from other sensors. This can include digital imagery, hyperspectral data, thermal imagery, planimetric data or similar data sources. Generally the most information-rich product with the highest cost.

volume and the richest information content. Clients must have the ability to extract information desired. In Level 2 products, automatic algorithm is applied to separate ground

45

points and non-ground points into layer's structure. The accuracy is limited and cost is same as Level I products. Manual involvement is required for Level 3 products to improve the accuracy of Level 2 products, with reference images and trained personnel, high accuracy DEM can be achieved. In Level 4 products, features of interest (trees, buildings, roads, etc) are extracted from non-ground points of Level 3 products, it may employ both automatic and manual classification or tailored software. Level 5 products integrate topographic LiDAR product with information of other sources, it carries abundant information and is the priciest.

3.4. Error Sources
Topographic LiDAR system is a complex system, its data file is the fusion of several data sources, errors occur in each sub-system will deteriorate the overall positioning accuracy. Crombaghs et al. (2000) categorized data errors into four components: error per point, error per GPS-observation, error per strip, error per block. Figure 3.4 illustrates the components.

Figure 3.4 Error components of topographic LiDAR data (Crombaghs et aL, 2000) Error per point is introduced by the measuring uncertainty of LiDAR scanner. The cause of error\per GPS-observation is similar to error per point, because the GPS time interval is

46

larger than the pulse ranging interval, so multiple sampled points within one GPS interval will be influenced. Error per strip happens when integrating both GPS data and inertial navigation system (INS) data, which causes the vertical offsets on every strip during flying operation. Error per block occurs when ground control points are utilized to calibrate the topographic LiDAR dataset, inaccuracies in measuring control points will affect the whole block of dataset which has multiple strips.

Potential error sources contribute to the quality of topographic LiDAR data are examined by Alharthy et al. (2004), Mass (2003), Schenk (2001), Sithole and Vosselman (2003) and Zhang and Liu (2004). They can be grouped into three aspects: systematic errors, random errors and other errors. All types of errors are explained in the following:

Systematic errors can happen in each part of topographic LiDAR system, they are results of deficiencies of equipments or mistakes happened during operation.

1.

Ranging Unit and Scanner These errors include the alignment failure of the emitted LiDAR beam and its echo, the counter's inaccuracy in timing the LiDAR beam's traveling time, scanner mirror vibration and swath angle errors, etc. Total elimination of errors is difficult, but they can be minimized through calibration.

2.

GPS errors
47

Accurate positioning from the GPS device requires the availability of properly positioned GPS satellite constellation at the time of flying operation, otherwise it might be insufficient to geo-reference sampled data precisely. GPS signal from ground station is applied to correct the distortion of GPS data from satellites, this distance from aircraft in mission to GPS ground stations in another factor, usually the shorter the distance, the better the improvement effect. 3. INS Errors INS consists of IMU and auxiliary computers and it constantly generates the position, orientation and velocity of the aircraft. Initialization errors, misalignment (boresight error), and gyro drifts contribute to systematic errors (Schenk, 200 I). The misalignment between the INS system and the scanner is the largest source of systematic error (Morin and Sheimy, 2002) and it is necessary to be addressed in more detail.

9or9illl/'t rol ""Of·

~
G', \
:1 \

I \\ . . . . . . . ,
\ \,
\ '"

I -., " ,.'.·..

".

..··...~..,

Trut· ground

(a)

(b)

(e)

Figure 3.5 Illustrations of the results of misalignments (ASPRS LiDAR Guidelines: Horizontal Accuracy Reporting, 2008)
\

48

Pilch e.:rrm cau~cs illClilwu recoruing of naulr (Figure 1.5a), roll error cause," wrong

range registratron (I igurc J .Sh). lhe heauing error causes the distOrLlOn scanning line
(1Igun~

or

each

35c). ue\ iation scalc correlates witl anglcapositi\ely. Borcsight

clTor skc\\ s each pomt \\ ith 111 a strip anu i," rCIllO\ able \\ i til reference to the ground control
4.
rOlllt~.

Time Bias Iorographic LiDAR
sy~tcllls con~ist

or (jP ~ .

IN. and ranging components. each

component lAorks independentl) ant! theIr sampl ing rate are distim:t. ('PS has the ,,10\\ est rate, rangin!2 unit has the fastest rate. f::rror occurs \\ he.: 11 matching three datascts precisely . Sche.:nk (2001) summarized it as time bias. IAhich includes synchroni/ation error anu interpolation error. Figure 3.6 uemonstralcs both types of elTors. ynchroninlion error (Figure .3 on) occurs \\ hen ranging data i available. but

the GP ' and I 'S data are absent. Interpo latIon error (Figure.: 3.6h) arise' when 1 data is present, but ranging data processing algorithms .
IS

missing . Time bras can be corrected througb po t

GPS INS

--t---i------'-~~~ --r-~-'--~--r-....,.......~

I

t

INS

-~;="-'--~---'---:

L S --'--:'--i--f.,..;-:--i~ri-i-----<.~ t

LS

--'-!-i-:-~~~!"i I+1-

.. ~

Figure 3.6 Time bias (Schenk. 200 I)

Pitch error causes inclined recording of nadir (Figure 3.Sa), roll error causes wrong range registration (Figure 3.Sb), the heading error causes the distortion of each scanning line (Figure 3.Sc), deviation scale correlates with angleapositively. Boresight error skews each point within a strip and is removable with reference to the ground control points. 4. Time Bias Topographic LiDAR systems consist of GPS, INS and ranging components, each component works independently and their sampling rate are distinct, GPS has the slowest rate, ranging unit has the fastest rate. Error occurs when matching three datasets precisely. Schenk (2001) summarized it as time bias, which includes synchronization error and interpolation error. Figure 3.6 demonstrates both types of errors. Synchronization error (Figure 3.6a) occurs when ranging data is available, but the GPS and INS data are absent. Interpolation error (Figure 3.6b) arises when INS data is present, but ranging data is missing. Time bias can be corrected through post processing algorithms.

1? I
CPS
INS LS

synchronizalion error interpolation error

I

I
I

I

.ot

I

I IiI I I I i 1.. 1
I

INsl~1
LS

i 1I1I111111111111
(a)

.. 1

II11I1 i I! 11I11111
(b)

I

.. t

Figure 3.6 Time bias (Schenk, 2001)

49

Random errors arise from topographic LiDAR system designed accuracy limits (vertical accuracy, horizontal accuracy, etc). They cannot be totally eliminated from the system and statistical analysis can minimize these types of errors.

Other errors do not belong to systematic errors or random errors, but they occur and have impact on the data accuracy. 1. Outliers. Outliers develop when LiDAR beam hit the objects which does belong the topographical features of the earth surface. These objects could include airborne objects like birds or low flying aircraft, or ground objects like pedestrian, cars and animals. Outliers can be easily removed from dataset if their elevations are quite distinct from neighboring features. 2. Atmosphere As discussed
10

Section 2.1, emitted LiDAR beam interacts with atmosphere

(mainly in troposphere) first before reaching ground. Under unfavorable conditions, air pressure, temperature and humidity may influence the accuracy beyond an acceptable level. These errors can be alleviated by careful mission planning, aircraft maneuver and interpolation in the lab. 3. Human errors Raw data generation or high level products developing require extensive human
\

50

involvement, which may introduce human errors.

3.5. Data Ground Processing
Ground processing can be regarded as generation of a data product. The choice of working procedures and software tools varies from different data providers, but three main objectives (data assembly, data calibration and data customization) must be achieved in this stage. An example from Optech is used to illustrate this process, which will offer snapshot on how data will be manufactured.

Figure 3.7 demonstrates the processing flow of airborne LiDAR terrain mapper (ALTM). First, data stored in hard drives are downloaded to a PC/laptop by the Disk Extraction software. Then range file is decoded into range data and POS data by DashMap software. In stage three, POSPac software is applied to extract both IMU data and air GPS data from POS data, together with basic data processing and adjustment. POSGPS software can create centimeter-level, inertial-aided differential GPS data through combining air GPS data and ground! virtual reference stations (VRS) GPS data. POSProc function from POSPac decodes and reprocesses inertial data using inertial-aided differential GPS information, a Smoother and more accurate (up tol00 times more detailed) Smoothed Best Estimate Trajectory (SBET) is generated. In the last stage, the original point cloud is produced, usually in WGS84

51

coordinate system, DashMap can transform XYZ data to local coordinate systcm decimate and output in desired formats (binary, ASCII, LAS,etc.) and product is ready to be delivered to client.

ALTM Disk Extraction

I Range file

I

Base\VRS GPS

DashMap Decode

Data

I Range data

II

POS data

I

1
POSPac Extract

I IMU data I I Air GPS I
Inertially Aided KARGPS

POSGPS

POSProc

I SBET I LAS out put I I

I

DashMap XYZI Laser Points

Figure 3.7 ALTM data processing flow (Optech, 2008)

3.6. Chapter Summary
Topographic LiDAR developed purely from market demands, which caused confusion and complexity in tcrm of choosing data products. This chapter provides knowledge for topographic LiDAR data standards and formats, which are critical for the design ofLiDAR
\

52

data processing algorithms. Main error sources, data ground processing procedures and various data products are also introduced. This background information is beneficial in terms of choosing proper LiDAR products satisfying the requirements of the applications.

53

4. METHODOLOGY RECONSTRUCTION

FOR

BlTILDING

This chapter consists of three sections. First a new topographic LiDAR raw data segmentation algorithm for building coverage detection based on Gaussian Markov Random Field (GMRF) and Markov Chain Monte Carlo (MCMC) is introduced. Then modified convex hull algorithm and a hierarchical regularization algorithm are applied to extract and regularize building roof outlines respectively. Finally, extracted building roof outline points are exported to the ArcGIS to generate 3D building models.

4.1. Segnlentation Algorithm for Building Roof Detection
This algorithm is applicable for segmenting topographic LiDAR point clouds and can be further divided into two integrated portions. By utilizing GMRF, a mathematical model simulating the distribution of topographic LiDAR point cloud is established and then MCMC is employed to acquire optimal segmentation solution.

4.1.1. l\lathematical Model
Gaussian distribution, also referred as normal distribution, is one of the basic forms of distribution in statistics and its general formula for the probability density function is expressed as

54

y

(4.1)

where

J..I

is the mean and

if is the variance.

MRFs are stochastic models which describe the spatial relationship among the subset of the data. During the past decades its applications have been extended from mathematical analysis to physics, artificial intelligence and computer vision. Several researchers (Bouman 1995, Perez 1998, Pieczynski and Tebbache 2000, Heesch and Petrou 2007) have applied MRF as a
,

tool for image processing because it provides an efficient and convenient way to model context-dependent features like pixels (Zhang, 2000). In MRF, the correlated relationships among the elements in set T are achieved through neighboring system, which can be defined as

N = {Ni.i En, where N j, is neighboring set of element i OE1), ill Nj, and i E~ ~ j EM. A
random field X is MRF within T with respect to defined N if and only if

p(X»O,'v'XEX

(4.2)
(4.3)

Segmentation is the process of subdividing raw topographic LiDAR data (point cloud) into homogeneous regions, generally as a prelude to further analyses. What should be regarded as homogeneous depends on the context. However, in this study only the elevations are considered. A regression model is specified with a piecewise constant mean function (i.e., a step function) for elevations distributed on an area of interest (AOI) D.

55

Before going further, concepts of two sets, which are essential during modeling process, need to be set up. The measurements of ~levations acquired can be modeled as a random data field Y
=

{YI, ... ,Yn } and a raw topographic LiDAR data on D can be considered as a incomplete

random sample of the random field, y = {Y" ... ,Yn}. A label indicating the group number to which the corresponding point belongs is represented as a random variable Xi. For the topographic LiDAR data set with n points and k groups, the collection of all label,
J, Xi E J} where J = {1, .. . ,k},I {1, .. . ,n}, can be viewed as label field, while x

{ Xi ,

{Xi, i

E

J} is

one realization of X Figure 4.1 indicates the relationship between label field and data field, for each Y value in dataset, there is one and only one X value associating to it.

Label Field

Data Field

X2--~------------r.

X3-+-----------r. Y3

Figure 4.1 Relationship between label field and data field

Given Y (elevations of each point) in a topographic LiDAR raw data set, value of

x: needs to

be optimized such that the all points with similar elevation values are grouped together through finite cycle of computations. The parameter vector s is defined, and s = {X, O}" where

ois a parameter vector to be estimated, the optimum is achieved by maximizingp(s I Y). Using
56

Bayes' Theorem, the following equation is obtained:

p(sl 1') = P(X,BI 1') oc P(X,B)P(YI X,B)

(4.4)

Assuming X and 0 are statistically independent, therefore

p(X,B) =p(X)p(B)

(4.5)

Combining Eqs. 4.4 and 4.5, then

p(sl 1')oc P(x)p(YI X,B)p(B)

(4.6)

Through Eq. 4.6 the maximum ofp(s / Y) can be calculated by multiplyingp(X),p(Y/ X, B) and

p( 0), once the values of above three parts are optimized, p(X, 0 / 1) can be obtained. Set X,
which holds the labels for each point is fixed, thus the whole dataset is segmented according to the labels attached to each point. In the following context, equations to calculate the p(X),p(Y/
X, 0) and p( 0) will be elaborated.

In a topographic LiDAR raw data set, the distances among points vary in contrast to the

regularized distance among pixels in optical images, which introduces extra steps in processing topographic LiDAR data. For label field X, it is assumed that the distribution of Xi satisfies MRF( i.e., for each independent point of the data set, its elevation is dependent of the elevations of its neighboring points). Since points are randomly scattered, reasonable radium r is designated such that each point has at least one neighboring point and r is determined by the

57

intensity of data. As shown in Figure 4.2, the elevation of Point 1 is closely related to the elevations of Points 2, 3, 4 and 5 within square window delineating neighboring zone .

·
··
·

·
I·

~·3
.5 4

·

··
·

·

·

·

·

· · · ·

·

·

Figure 4.2 MRF property of topographic LiDAR data

P (Xi) is expressed by:

(4.7)

where t(x,y)

{I, ifx=y N; 0, otherwise'
I

{i', dei, i')

~ r}, d(i,

i') is the Euclidian distance between

points i and i', exp{

L I( Xi' Xi')}

is the potential power function of Xi,

By multiplication of P(Xi), p(X) can be obtained by:

(4.8)

Topographic LiDAR raw data sets can also be viewed as the integration of multiple subsets of points with different z values, points share same label field within each subset. It is rational to assume that these points satisfy Gaussian distribution with proper mean and variance. For each

58

given Xi.

the distribution of subset ofy sharing the same label Xi satisfy Gaussian distribution
{Jih

with mean Jij and variance rih we define OJ

c1j }.

Thus the probability density function

p(Yi I Xj, OJ) with reference to Eq. 4.lcan be defined as:

(4.9)

Through Eq. 4.9 p(Y I X, 0) accomplished as:

(4.1 0)

For the parameter the vector OJ = {Jij,

c1j }, Jij and i j are assumed to be independent, the joint

distribution probability p(Oj) can be rewritten as: (4.11)

Assume that mean Jij follows uniform distribution between minimum and maximum z values, i. e., Jij - U(hmin, hmax ), variance (ij follows normal distribution, i. e., (ij - N(O, l), where hmin ,

hmax and r2 are constants. For each Oi,
(4.12)

Through Eq. 4.12,p(O) can be expressed as

59

p( 0)

=Il p(OJ) = (
JEJ
hmax.

~

Jk (
h min

"1/ 2ITr

~ Jk Il exp{- 2r a~2}
JEJ

(4.13)

Through the above inference p(X), p( Y IX, 0) and p( 8) are mathematically formulated by Eqs. 4.8,4.10 and 4.13 respectively, by Eq. 4.6 pes complete GMRF model can be obtained:

I Y)

is solvable by multiplication. Thus the

(4.14) where h max
,

hmin , ~ and k

need to be fed in manually according the properties of the

topographic LiDAR data set.

Figure 4.3 depicts the parameters and their relationships with different parts in Eq. 4.14. h max and hmin are applied to determine the distribution of mean (p) of each group,

,2 controls the

jumping step of variance (0-2) for each group, k confines the scope of X With a proper combination of these parameters, optimum values of X could be reached. Thus the meaningful segmentation of topographic LiDAR raw data can be achieved.

60

Figure 4.3 GMRF parameters and their interrelationships

4.1.2. l\lCl\lC for Segmentation
MCMC is essentially Monte Carlo integration using Markov Chains and it mainly focuses on simulation, estimation and optimization and it consists of set of sampling algorithms as long as the distributions satisfy Markov chain properties. In Section 4.1.1 the mathematical model for segmenting topographic LiDAR point clouds set is established by Eq. 4.14. In order to solve this equation, a dependent sampler is required to capture the optimum values of X. In this study the MCMC algorithm is chosen based on the following considerations: 1. It is mature and stable theory and has been widely applied in statistical inference. 2. Its main applications involves in Bayesian inference, namely from prior distribution or likelihood established in joint distribution to predict posterior distribution, as described in Eq.4.4. 3. It works better on complicated high-dimensional distributions. A topographic LiDAR

61

raw data set has millions of points and it is very difficult simulate its distribution under other type of sampling method like independent sampling.

A standard MCMC algorithm called Metropolis-Hastings algorithm is employed to calculate the optimal value of X. Figure 4.4 shows the flowchart of this algorithm and it contains the following six steps:

62

Initialize iteration counter u =1 Initialize parameter vector so= vi, (ci)o,Xo}={}ib ... ,}ik ' ( 0'-)0 1. ... , (0'-)0 k, X0 1, .·. , X0n}={S !, .. . ,S02k+n}

°

Initialize component counter v = 1

Figure 4.4 Flowchart illustrating Metropolis-Hastings algorithm
P;~GF;;,.ri'rY Cf J;';;'i~;f.t.rrY U:'~,\r~

63

1. Initialize the iteration counter u

= 1 and set the initial value of the chain SO = {sJ 0,
E

.·. ,

smo}, where p/,j

E

J, are dTawn from U(hmin, h max ), (a/)o, j

J, are drawn from N(O,
{i, Xjo =j}, V j
E

l), and Xjo , i E I, are uniformly drawn from {I, ... , k} and satisfy Sj =
J.

2. Initialize the component counter v = 1.
3. Move the vth component Sy of s to a new value Sy * generated from the density qs(S}u-I), h Sy *),were pv * constants. 4. Calculate
a(s
v
~

N(" IjA-v(u-l) ,

6) ) ,

(J

2 y* ~

N((J2v(u-l),

62 )

) and N(Xy(u-I),63,

6), 62, 63

are

the

acceptance
U

probability
1

of

the

move,

U-ll,s

*)=min{l, p(sv*ly)q(sv*,sv - )) }.LetwbedrawnfrOmU(O'l).Ifa~ v *) P( Sv (j-I) I Y) q (}-I) Sv 'Sv
Sv *.

w, the move is' accepted, then s}11 =

If a < w, the move is rejected, then s}il

= sy-Il.

5. Change the counter from v to v+ 1 and return to step 3 until v = m. When v step 6.

m, go to

6. Change the counter from u to u+ 1 and return to step 2 until convergence is reached.

4.2. Building Outline Extraction and Regularization Algorithms
4.2.1. Building Outline Extraction Algorithm
After the segmentation process introduced in Section 4.1 along with a possible filtering

64

procedure, building roof points with similar elevation values can be successfully classified. In order to reconstruct the shape of the building roof, building roof edge points need to be further separated from non-edge points. Building roof point determination is a crucial and difficult step in the building reconstruction task (Rottensteiner and Briese, 2002). In this study, the modified convex hull (MCH) algorithm introduced by Sampath and Shan (2007) is adapted to delineate building roof points.

Given a set of points, convex hull is the smallest convex polygon containing all the points, it also can be visualize by wrapping rubber band around the boundary points. Figure 4.5 displays the convex hull of a set of points, it is a closed convex polygon formed by the border points.
y

x
Figure 4.5 Convex hull of a point set

There are different algorithms available to compute convex hull of a set of points like Graham's Scan, Jarvis' March or Quick-Hull. Sampath and Shan (2007) proposed the least clockwise angle algorithm to obtain convex hull. This algorithm is further modified to calculate building roof edge points.
65

Figure 4.6 illustrates how this algorithm works. Starting at leftmost point P, edges are created with rest of the points within the set. After sorting edges according to their clockwise angles, the edge with the least clockwise angle is chosen to be the boundary edge. Then starting with the other end point of selected edge, the above step is repeated until start point P is reached. The generated set of edges is the convex hull of the point set.
Steps in convex hull formation ( calculate the clockwise angles and select the one with minimum angle)

Selected edge

A
;,0

pA

pA
B
I I I

B

I

I)

-:._----0
p ---,

;;

;

;

;

;

;

jA
C D
P
A
"OS

OB oC OD

C D
P

P -----

Coordinate A'(es

Coordinate Axes

2)

B

Jt~B
P \ C Db

P

/::"
p

DO

B
3)

P

P

(;f"
D
B

B
4)

Figure 4.6 Convex hull computation procedure (Sampath and Shan, 2007)
66

No matter what shapes the point sets form, the convex hull algorithm computes the convex polygon, which is not always the case in delineating building edge points. Figure 4.7 shows some of commonly seen concave shaped building roofs and their outlines cannot be accurately recovered by the convex hull algorithm.

(a)

(11)

Ie)

Figure 4.7 Regular concave shaped buildings

In order to trace concave the shaped building roof outline points, MCH is proposed, which can be regarded as a localized convex hull method. The algorithm creates a moving window for each edge point and correct edge point is traced out within the moving window. After starting point is reached, all edge points are selected successfully regardless of the shape of the building. Figure 4.8 demonstrates the tracing process. At the beginning, a comer edge point is picked, within its neighboring window next edge point is chosen. Starting from the newly selected edge point, the same steps are repeated until the original edge point is encountered. The fourth row in Figure 4.8 shows the distinct results of two algorithms where the building outline recovered from convex hull algorithm is far coarser than the outline from MCH algorithm and cannot be applied as the base building shape in 3D city modeling. The radius of the moving window should be adjusted according the point density. In general, it is
67

slightly larger than twice of the point spacing in the along and across scan directions.

Steps in boundary \nIdng ( calculate the clockwise angles for points within Ihe neighborhood of Ihe circle and seleclthe one wilh minimum angle) Selected edge

/:'\ ···
"

''-<.,:. · · · · · · ·

... . ...... . . ..
,
I

~}J ······

~

~,)
~

I

o ·······

··· ···
~'

··· ···

..... . ...... .
···

···

··· ···

··· · ·· 0-",) · · · · · · · ······· · ·· · ··
· ·· · ··
,)--{)-o · · · · ·

2

--.~l ~:) · ...Q~ · · · · · ·

... .....
···

··· ···

··· · ·· eC'~) ····· · · C ····· · ·· · ··
· (/~, c · · · ·

· ·· ··· .~o

·

~

..... ...... ···
···
· ··

· ·······
· ·· · ··
· ··

3

-.-¢

··..· .... · ·S· ···
);.

· ·· C ··

··· 0 ··
·

c',····

···

,

· · · ··

0 ·····

· ··
'

· · ···

{:;/-:c~':' ···· o · ····

· · ····· · ······· · ·· · ··
O'C'

4

··· ··· · · ······ ···· · · ·· ···

· ·· ... · ·······
· ··
Convex hull

···

····· ··· · ··
Boundary

Raw points

Figure 4.8 Modified convex hull algorithm (Sampath and Shan, 2007)

4.2.2. Building Outline Regularization Algorithm
The first step of the algorithm is to locate the line segments framing the shape of building. According to Sampath and Shan (2007), this is done by sequentially following each building edge point and looking for positions where the slopes of two consecutive edges are

68

significantly different. The points on subsequent edges with similar slopes are gathered in one line segment. At the end of this step, the building roof outline points are subdivided into a number of sets of points, the number of sets equals to the number of the building outline segments.

Next step is building roof outline reconstruction. In this study, it is assumed that building edges are straight, so they can be expressed by Eq. y=ax+b. The extracted points corresponding to the building outline can be used to estimate the lines. Figure 4.9 demonstrates the process. Given the edge point set {A,B,C ... ,Hj, let d be the distance from a point to the line, the line is regressed by Minimum Mean Square Estimate (MMSE), that minimizes the sum of distance, d l + d2 + d3 + ... +ds.

H
~

\

\ ds

D

\.

·

\:'
E
f

G

c

Figure 4.9 Line replacement of multiple points In the final step, the comer points of a building outline are computed by solving the linear

69

equation pairs of adjacent edges. By connecting these points with straight lines, the building roof can be retrieved and are ready to be exported to a geo-database.

4.3. 3D Building Generation
Several software packages are commercially available in the market to produce 3D city models including Fusion or LP360, ArcGIS is employed in this study.

Figure 4.10 exhibits the key steps in 3D building generation. First, points are converted to a line coverage. A coverage is an intermediate file required by the following function. A polygon shapefile is created based on line coverage. Spatial references of shapefiles are defined, so they can be overlaid on other spatial data. A building polygon shapefile accepts various functions offered by software and can be exported to other geo-databases. During the last step, 3D buildings are generated in ArcScene-3D simulation modular in ArcGIS.

70

l
I I I I

Building edge points set

J

Convert to line coverage

I

Convert to polygon shapefile

I
I

Specify spatial reference

3D building generation

I

Figure 4.10 Process of 3D building generation in ArcGIS

4.4. Chapter Summary
In this chapter, the proposed methodology for 3D building reconstruction from topographic LiDAR point clouds is described. The complete workflow comprises of three critical parts: building detection, building outline extraction and regularization, 3D building model generation. In the first part, a new segmentation algorithm utilizing GMRF and MCMC is presented. Compared with other algorithms, the advantage of this algorithm is that it works on topographic LiDAR data directly without other supporting data. In the second part, MCH

71

and MMSE are applied to obtain the final edge point set that symbolizes planar shape of the building. In the last step, the point set is exported to AreGIS to generate 3D building models.

\

72

5. RESULTS AND DISCUSSIONS
5.1. Study Area and Data
Ihe
~tudy

area is a part ufthe Uni\l'rsity o f\Vat I.' rl 00 (U\\') Lumpus. cO\l'n.:d by a single strip . kxhihits the image and its Il'gcnd . Difrerent

tnpngraplllc LiDAR pOInt clouds. Figure

colour" arc utili/cd to symboli/c the clevatlon
ek\'ation~

or eaLh

pt)int The numbers arc the

ah~ollltc

in metres.

Figure 5.1 Topographic LiDAR point clouds of the Uni\ersity of Waterloo campus and surrounding an.:a

Figure 5.2 demonstrates a reference map from Google map, th region in black rectangle is

the proximate area co ercd by topographic LiDAR data.

73

5. RESULTS AND DISCUSSIONS
5.1. Study Area and Data
The study area is a part of the University of Waterloo (UW) campus, covered by a single strip topographic LiDAR point clouds. Figure 5.1exhibits the image and its legend. Different colours are utilized to symbolize the elevation of each point. The numbers are the absolute elevations in metres.

Figure 5.1 Topographic LiDAR point clouds of the University of Waterloo campus and surrounding area

Figure 5.2 demonstrates a reference map from Google map, the region in black rectangle is the proximate area covered by topographic LiDAR data.

73

Figure :.2

R~j~n;ncc

map to lOpoLTfuphic LiDAR image (Ciooglc map)

Table 5. 1 lists rdatin; topognphlc LI AR data infom1,llion am! hardwLln.! . dtings \\ hen uaw
\\C1S

collected . Table 5. 1 I >pographic LiDAR uata spccilications CO\eragc cquisltion date Nu . or point::. Scanner POS system Flying height (m ASL)
Speed (m s) UVl Campus and neighboring area

March II. 2006 7.9 million AL T"vl GEMINI Applanix-POS,AV
1200

66.9

Scan fre'-!ucncy (H/) Swath (m) Desired rt:solulion (m) 2 Pomt density ( per 01 ) Data lo m1al Source

35
~73.53

o 90X
1.1 LAS

Optech 1m:

igurc "'.3 di .· plays part of header file from topographic LiDAR data where essential facls

74

!'

1I~''''
~.

-

~

..

6~'
-~.., ~-,

)~-s,~

<';:0 ...... "

~_/..· '
~.

...~.'"

\ ....
Kifchener
, -~J".".'t

t:l

'mJt: 1f

I
,

,

Figure 5.2 Reference map to topographic LiDAR image (Google map)

Table 5.1 lists relative topographic LiDAR data information and hardware settings when data was collected. Table 5.1 Topographic LiDAR data specifications Coverage Acquisition date No. of points Scanner POS system Flying height (m ASL) Speed (m/s) Scan frequency (Hz) Swath (m) Desired resolution (m) Point density ( per m2) Data format Source UW Campus and neighboring area March 11, 2006 7.9 million ALTMGEMINI Applanix-POS/AV 1200 66.9 35 873.53 0.908 1.1 LAS Optech Inc
I

Figure 5.3' displays part of header file from topographic LiDAR data where essential facts

74

about the dataset, including number of returned recorded, margin values, offsets and scale factors of X, Y, Z variables are recorded. They are critical when format conversion or filter operations are required.
FILE_SIG LASF RESERVED o VERSIONj1AJOR 1 VERSIONj1INOR o SYSTEM_IDENTIFIER ALTM system (c) optech GENERATING_SOFTWARE Realm survey Suite 3.5 FLIGHT _DATE o YEAR o HEADER_SIZE 227 OFFSET _ TO_DATA 759 NUM_VAR_RECORDS 3 POINT_DATA-FORMAT 1 POINT_DATA-RECORD_LEN 28 NUM_POINT_RECORDS 7997153 points by Return [ 1] 6483242 points by Return [ 2] 1185015 points by Return [ 3] 304469 points by Return [ 4] 24427 Poi nts by Ret ur n [ 5] o X-SCALE_FACTOR Y_SCALE_FACTOR Z_SCALE_FACTOR X-OFFSET Y_OFFSET Z_OFFSET
MAX-><

MIN-X MAX-Y MIN_Y
MAX-Z

MIN2

0.010000000 0.010000000 0.0010000000 531700.00 4808200.0 356.17338 539497.30 534618. 70 4816069.9 4810033.5 476.12729 219.19705

Figure 5.3 Part of header file

Figure 5.4 is aerial image ofUW campus, which acts as reference image during the processing. Buildings in coloured squares are candidates chosen to demonstrate the 3D building reconstruction process elaborated in previous chapter. In Table 5.2 the main properties of aerial image are listed.

75

Figure 5A A.crial image o/" UW (amp LIS

Table 5._ Al:rial imagc spt!cdicalion
CO \

eragc

Fonnat
Resolution

Unl\'Crsily ofWalcrloo ( U \~' ) cumru'" GcoTIFF 1m
1369

DimensIOn
Source

* XXI

UW library

The study area is the UW northeast campu .. The detailed description of indi, idual building:

lS

given in Table 5.3. Buiklll1gs are aligned b) complexity scal-: in increasing order. The common

practices in 3D building reconstruction including convex polygon ', concave polygons. curved edges, non-perpendicular edges, preliminary noise filler ing techniques are examined in the study.

71t

Figure 5,4 Aerial image ofUW campus

Table 5.2 Aerial image specification Coverage Format Resolution Dimension Source University of Waterloo (UW) campus I I GeoTIFF 1m 1369 * 881 UW library

The study area is the UW northeast campus. The detailed description of individual building is given in Table 5.3. Buildings are aligned by complexity scale in increasing order. The common practices in 3D building reconstruction including convex polygons, concave polygons, curved edges, non-perpendicular edges, preliminary noise filtering techniques are examined in the study.

76

Table 5..3 Sample building

prop~rLJCS

r Building l1am~

I RIM -=-- ----jl--,;;;;;;;;;;;==:-==~=;;;..t-h:-J:-· g :h -- ri Sl: b uiIdin g. con \'c x po Iygnn
shape c\cept ror one curved edge. \ eg~tation around.
~parse

Building properties

HI(j

low-rise building, irregular concave polygon shape. medium vegetation presence close to building.

Optomctry

multi-level budding complex. strong appearance of vegetation.

The original topographic I iDAR point clouds contain 7.9 million points. In order to extract building roof 1Ullines listed in Table - .J. pOlnls cO\'ering the building areas need to be separated. As discussed in Chapter Two. each point in the topographic LiDAR point 'IOUlls is geo-referenced. usually in the TM syskm. Two steps arc invohed to achieve the goal. First.

. palial relCrences f comer points need to be po,>itioned. fh reference image in Figure 5.4, provides dc -ired spalial locdtions of comer point. (lower left and upper right points}.Next, points external Lo comer poinls are filtered out. LA. tool (Iscnburg and Shewchuk. _DOH) contains basic function handling topographic LiDAR data in LA fonnat and filtering and

77

Table 5.3 Sample building properties Building name RIM Building properties high-rise building, convex polygon shape except for one curved edge, sparse vegetation around.

BFG

low-rise building, irregular concave polygon shape, medium vegetation presence close to building.

Optometry

multi-level building complex, strong appearance of vegetation.

The original topographic LiDAR point clouds contain 7.9 million points. In order to extract building roof outlines listed in Table 5.3, points covering the building areas need to be separated. As discussed in Chapter Two, each point in the topographic LiDAR point clouds is geo-referenced, usually in the UTM system. Two steps arc involved to achieve the goal. First, spatial references of comer points need to be positioned. The reference image in Figure 5.4, provides desired spatial locations of comer points (lower left and upper right points).Next, points external to comer points are filtered out. LAS tool (Isenburg and Shewchuk, 2008) contains basic functions handling topographic LiDAR data in LAS format and filtering and

77

format conversion functions are utilized in this study.

Figure 5.5 displays part of pre-processed topographic LiDAR data in ASCII format, there are three columns separated by space, first two columns (x and y) offer spatial reference of the point, and the third column (z) indicates its elevation.
537056.56 4813658.28 336.371385 537057.43 4813658.82 336.412385 537058.34 4813659.37 336.377385 537059.4 4813659.72 336.430385 537058.51 4813659.17 336.436385

Figure 5.5 RlM.txt file

Figure 5.6 demonstrates the topographic LiDAR point clouds of sample buildings in an aerial view (Figures 5.6 (a), (c) and (e)) and 3D view (Figures 5.6 (b), (d) and (f)), respectively. The
RlM building (Figures 5.6 (a) and (b)) has one level of flat roof, with Low Rise Vegetation

(LRV) in the north part and low gradient ground. The BFG building (Figures 5.6 (c) and (d)) also has one level of flat roof, with close High Rise Vegetation (HRV) in the west and south part of the building and low topographic ground. The Optometry Building (Figures 5.6 (e) and (f)) has three levels of flat roofs of distinct altitude, there are heavy HRV surrounding the building except for north part, the ground surface is undulating.

\

78

(a)

(b)

(c)

(d)

(e)

(f)

Figure 5.6 Topographic LID R Image::. of. ampl buildings

5.2. Experiments
5.2.1. Segmentation
Table 5.4 lists all constants for the segmentation algorithm presented in Section 4.1. Thl: value k is the number of groups into which a given topographic LiDAR data set is segmented,
79

(a)

(b)

(c)

(d)

(e)

(f)

Figure 5.6 Topographic LiDAR Images of sample buildings

5.2. Experiments
5.2.1. Segmentation
Table 5.4 lists all constants for the segmentation algorithm presented in Section 4.1. The value k is the number of groups into which a given topographic LiDAR data set is segmented,
79

prior knowledge about the scene

cov~red

by dataset is helpful. The variable i represents the

computing cycles. And r is the size of neighbouring window for each point, the rule for selecting window is that there must be at least one neighbouring point in the window. The parameter cr2is the variance of the normal distribution corresponding to the elevations of points in each group and it controls the extent to which the elevations fluctuate around their means. Finally, i governs the span ofthe samples of the mean in successive iterations. Table 5.4 Input constants Name · Radius Number of groups Variance of each group Variance of mean Number of iterations Abbreviation r k cr2

i
i

Table 5.5 lists constants of the three scenes. The value of r is related to the desired resolution in Table 5.1 and it should be slightly larger than the value of desired resolution to ensure that each point has at least one neighbouring point. The parameter k symbolizes the segment number that the data is divided into. Scene 1 contains ground and building roof and 2 is picked. Scene 2 consists of ground, HRV and building roof and 3 is selected. Scene 3 includes three levels of building roofs and three levels of ground surfaces, so 6 is chosen. The 2 choice of cr and

i

requires some prior knowledge about the scene. For instance, RIM

building \has low rise vegetation around so larger cr2 (2m2) is selected, in order to reduce computing time, move mean of each group its stable value, 2m2 is chosen for
80

£/ so its mean

values will move faster to their stable values. The experiment shows that as k increases, both
a and
2

i

should be reduced to achieve optimal solution. The choice of i is linked with the k decreases, larger i value is expected. The selection of i in this

and

i, as k increases and i

case is based on the step-wised experiment. Table 5.5 Parameters of sample buildings Constants r k a2 Scene 1 l.Im 2 2m2 2 m2 200,000 Scene 2 l.lm 3 15m2 1.5 m2 150,000 Scene 3 1.1m 6 1 m2 I m2 850,000

i
i

Figure 5.7 shows the process of segmentation of Scene 1. Figure 5.7 (a) demonstrates the initial state, where each point is assigned a group value randomly. After 50,000 iterations, points with similar elevation value (z value) start to cluster together, which is shown in Figure 5.7 (b). The majority of points are segmented successfully after 100,000 iterations as in Figure 5.7 (c). Figure 5.7 (d) exhibits shows the final results of the segmentation procedure, all the points are divided into two groups, ground points (blue colour) and building points (green colour). It is noticed that there are a few blue points mixed into green points. This is caused by the ground returns when LiDAR beams go through building windows. Those noise points can be deleted by post-processing method and will not have effect for building boundary extraction.

81

(a)

( h)

(c)

(d)

hgure 5.7 SegmentatIon of' 'icene one

Figure 5X demonstrate::; the Acccrtanl'e Rate tAR) lli" k: one means k i-; accepted. zero
othern IS~. FIgure S.H (a) no!\ ettls
l)\

crall AR Lillnn~ complete compu tlllg cycle FIgures S,X

._.
,
"

'I]
~

' 10
,

'

f ll>

I ..

~ l !,

,,"
II";'

[I '
\ I

1 ·
II .

1 1 ·

,,1
"
O.
, 14

""

... ..,
(a)

"I
1.\
, J

, t,

'>I
l'

"

"

I

,

~

;"

,;

.
I

,

, ..

·

...
"
·t_+~

(h)

,
"
"e
' 11
" I
J '
I"

'.lffl _

.· ..-+ .·1f ..... . ... .

... -+.

" 01, .
I)'>
J·
8 ')
,~

".,
",
n ..
11 ,

'"

)

.
.'
,
I
~

~,

h

" .,

'"

u

.. "

"" ,

I

.
1

'J.

I.,

I i

,,,

".
"

(c)

(d)

figure - .X AccCplanCi.: rate of II. (b). (c) and (d) offer AR in tirst 50,000 repetitIOns. 50.000 to 100.000 repetitions anLi 100,000
82

(a)

(b)

(c)

(d)

Figure 5.7 Segmentation of scene one

Figure 5.8 demonstrates the Acceptance Rate (AR) of k: one means k

IS

accepted, zero

otherwise. Figure 5.8 (a) reveals overall AR during complete computing cycle. Figures 5.8
1

0.9

0.9

De
0.7
0.6
0.5 0.4

De

r

107
06
0.5
0.4

0.3
0.2
0.1

03 0.2 0.1
o.~

0

l.J4

0_b

O.B

1

1.2

1.4

L6

1.0
)( 10$

0

u.~

1

1.5

L

",.5

:;

3"

4

45
)( 10'"

(a)
1

(b)
1111
j ·

II

illlIor+e

0.9

P9
p.e
P7

0.9 0.7
06 05

pe p.5
p.4

0.4
0.3

P3
p.2
p.l
5.5

02
0.1

0

.,

65

'"
(c)

B

85

S

95

1

1.1

1.2

1.3

1.4

15

1.6

1.7

I';

)( 10·

.'"

)( 10"

(d)

Figure 5.8 Acceptance rate of k (b), (c) and (d) offer AR in first 50,000 repetitions, 50,000 to 100,000 repetitions and 100,000
82

to 200,000 repetitions, respectively. AR in Figures 5.8 (b) and (c) are higher because of frequent label shifting rate and Figure 5.7 (b) and (c) show the same tendency. As most points are correctly labeled, new labels tend to be rejected and AR drops significantly, which is explained in Figure 5.8 (d).

Figure 5.9 shows the change of means for two groups during complete iterations, respectively. Figure 5.9 (a) shows mean shift of ground points. At the beginning a value is assigned arbitrarily between the minimum and maximum heights, as point labels switch, its mean value alters accordingly. Because a large portion of points are ground points and big elevation difference between ground points and building roof points, the mean value fluctuates dramatically before it stabilizes. Figure 5.9 (b) reflects the mean change of building roof points, which share similarities with Figure 5.9 (a).

Ill.'1.618

(a)

(b)

Figure 5.9 Jl Values against iteration Figure 5.10 discloses the AR of mean for ground points, one means value is accepted and zero otherwise. Figure 5.10 (a) gives overall AR during whole computing procedure. Two
83

thousand iterations are extracted from beginning, middle and end respectively to deliver better view of tendency, which are shown in Figures 5.10 (b), (c) and (d). With reference to Figure 5.9 (a), at the beginning AR is high, from the middle of iterations and thereafter, /11 decreases and becomes stable, only values close to its current mean are accept, which are reflected in Figures 5.10 (c) and (d).
---~

(a)
~,

.
,
"

(b)

(c)

(d)

Figure 5.10 Acceptance rate of /11

Figure 5.11 depicts the AR of mean for building roof points, which shows similar situation as in Figure 5.10 except that stability occurs after passing the middle of iterations. In Figure 5.11 (c), the mean is stilling changing (values shown in Figure 5.9 (b», the stabilized situation is shown Figure 5.11 (d).

84

--

(a)
i

I

I
(c)

I I

(b)

( d)

Figure

~

II '\cceplancc rate orp_'

Figure 5.12

illu~lralc"

the

~cgmt:ntatinn

operatIon

or Scene

2. At beginning each point is
cxhiblt~

assigned a label as shown in Figure 5. 12 (a). Figure 5.12 (b) after :O,O()O
itcratJOn~.

hm\ points arc

group~d

mo. "t pllints have aggregateu properly I·igures 5.12 (c) and (d) display
it~ration~

the results after I DO,OOO and 150.00()

rcspt:cti\cly By the .:nd of operation. dataset IS

scgmentedmto builJing ronf layer (red). ground layer (blul:) and vegetation layer (green and minor red points).

(a)

(b)

(c)

(d)

figun: 5.12 Segmentation ofseenc two

R5

(a)

"

(b)

(c)

(d)

Figure 5.11 Acceptance rate of /12

Figure 5.12 illustrates the segmentation operation of Scene 2. At beginning each point is assigned a label as shown in Figure 5.12 (a). Figure 5.12 (b) exhibits how points are grouped after 50,000 iterations, most points have aggregated properly. Figures 5.12 (c) and (d) display the results after 100,000 and 150,000 iterations respectively. By the end of operation, dataset is segmented into building roof layer (red), ground layer (blue) and vegetation layer (green and minor red points).

(a)

(b)

(c)

(d)

Figure 5.12 Segmentation of scene two

85

Figure 5.l3 shows the AR of k, one .means label is accepted, zero otherwise. Figure 5.l3 (a) offers AR in overall view. Figure 5.l3 (b) shows AR during first 50,000 iterations, whose AR is the highest among three stages. AR declines gradually as computing advances to the 100,000 and 150,000 iterations, the tendency is revealed in Figures 5.l3 (c) and (d), respectively. Because the majority of points are correctly labeled, new labels to these points are more likely to be rejected.
0.9

09 08
0.7
0.6

OB
0.7 0.6

05

05
04
0.3

p4
03 0.2
01

D.2
0.1 L 4

0

b

!l

hJ

I..:

14
lIC

0

0.5

1

L5

.2

25

.3

3.5

A

A5
)( 10"

10"

(a)
1
0.9

(b)
09
0.8 0.7 0.6

08

fJ·7

p6 p5
fJ4

0.5
0."

p3 p2 p.l
0

0.3
0.2 0.1

""

I>

1>5

I

75

8

85

9

1 "" .. 10"

0

1.05

11

110

L"

1.25

1 .3

1,215

14

lAS
X

1

10

6

(c)

(d)

Figure 5.l3 Acceptance rate of k

Figure 5.14 shows the mutation of means. Figure 5.14 (a) is for ground points, Figures 5.14 \ (b) and (c) are for vegetation and building roof points, respectively. Values in Figures 5.14 (a)
86

and (c) become constant before 50,000 computing cycles, which is echoed by Figure 5.12 (b). Values in Figure 5.14 (b) oscillate in a wider range, because some points can be classified as either ground points or LRV points. Only a small portion of points are vegetation points, so the label changes have bigger impact on mean values.
341
, ....~

I

3405

, ............ , ...... til.' ' 14M V

,

3::!l5

l;ll5

(a)

(b)

(c)

Figure 5.14 p. Values against iteration

Figure 5.15 shows mean AR for ground points; one symbolizes acceptance and zero means
~~
I-o~

1-0.,...
p"~

-

r .'"

r=

(a)

::t" "
"' ,.
~~~~==~====~L-

______________
(c)

~'~'~'~

______________
. uO£ '"

~

~'~'

·

(b)

(d)

Figure 5.15 Acceptance rate of P.I

87

rejection. Figure 5.15 (a) shows overall AR. Figures 5.15 (b), (c) and (d) magnify two thousand iteration intervals from the beginning, middle and end part, respectively. It is clearly shown that AR declines as the calculation continues.

Figure 5.16 displays the mean AR for vegetation points. In contrary to what is shown in Figure 5.15, its value does not drop significantly as iteration develops, this is because label switches between ground points and LRV points happen frequently throughout the whole cycle, Figure 5.14 (b) indicates the same situation.

(a)
,
"

(b)

(c)

(d)

Figure 5.16 Acceptance rate of P.2

Figure 5.17 demonstrates the mean AR for building roof points. Its change shares similarities with that of ground points (shown in Figure 5.15).
\

88

(a)

I"
"

.
(c

,

(11 )

(u)

Figurc 517 Acccptancc rate
~ igurc

or ,ii,
At the initial stage. each point is

5 I X cxhibih the ,>cgmeI1lation rroc~s,>

or Scene 3

allocatcd to olle urthe si.- labels ranuornly. l..\hlCh is :-.[)O\vn in I-tgurc '- . IX (a). After 150,000 iteration'>. thl.: aprroximate share of budding anu its surrounding area bU:llllle clear as in Figure 5. IX (b). J\t the Illl)mcnt v\hen 550,000 r'petitions arc compktcu (indicaleu in

(a)

(b)

(c)

(d)

hgurc 5 I X SegmentatIon of scene three Figure
I X(c»), si

layers arc clearly separated except for minor points \\hich need label

adjustment. Figure -. 1R (u) depicts the final result after R50,OOO iterations. I he data et is divided into t\\O categorie : ground and building roDe bTfOund category contain points in red

...

_

"1L..J-"

(a)
)9

···

J'··

·

~

·

·

··

(b)

(c)

(d)

Figure 5.17 Acceptance rate of P3 Figure 5.1S exhibits the segmentation process of Scene 3. At the initial stage, each point is allocated to one of the six labels randomly, which is shown in Figure 5.1S (a). After 150,000 iterations, the approximate shape of building and its surrounding area become clear as in Figure 5.1S (b). At the moment when 550,000 repetitions are completed (indicated in

(a)

(b)

(c)

(d)

Figure 5.1S Segmentation of scene three Figure 5.lS(c)), six layers are clearly separated except for minor points which need label adjustment. Figure 5.1S (d) depicts the final result after S50,000 iterations. The dataset is divided into two categories: ground and building roof, ground category contains points in red
89

cyan and green colours, building roof category holds points in yellow, blue and black colours. Points within each category are arranged in ascending order of elevations.

Figure 5.19 shows the AR of k; one means k is accepted, zero otherwise. Figure 5.19 (a) offers overall AR, because of high iteration number, it is not clear to demonstrate switch tendency. Figures 5.19 (b), (c) and (d) extract 5,000 repetitions from the beginning, start of second of computing stage (150,000 to 550,000 iterations) and last phase towards end of calculation. It is clearly observable that AR declines steadily during the whole computing process.
1
1

P9

0.9

P8

08 0.7 0.6 0.5 04
0.3 02 01
I
~

P7
p.6 p.5

p.4 p.3 p.2 pI
0
.;l

4

to

b

1

" )( 10'"

0

5W

iOUG

15(JO

20UO

b:

:;.:;00

JSOO

4cOO

45011

5L000

(a)

(b)
1
.9

10;
106 0 .7 1 106
0.5

6
7

6 5
4

0.4
03 0.2

3
2 .1

0.1
0

1.505
\

151

1,615

1.5~

1.525

153

15~5

154

15;: 1.545 x 10tl

0

"-4;'"

8Ab

0.400

BAr

5,475

648

64"t.

8.49

" ""x ".

.

5 10

(c)

(d)

Figure 5.19 Acceptance rate of k
90

Figure 5.20 depicts the alteration of means. With reference to Figure 5.18 (d), Table 5.6 lists point set that each mean belongs to in the geographic distribution sense. The property of each point set is identified in the third row.

5

6

(a)

(b)

(c)

(d)

(e)

(f)

Figure 5.20 p Values against iteration

Table 5.6 Means and their colour representations
Image name
Colour Category

(a)
red ground

(b)
cyan ground

(c)
green ground

(d)
yellow building roof

(e)
blue building roof

(1)
black building roof

Due to the range reduction of d and r/ and increase of k, a couple of changes are noticeable

91

in Figure 5.20. First, mean stabilizing times are greatly postponed and in Figure 5.20 (f), the mean becomes constant after 700,000 iterations. Second, it becomes harder to differentiate means, each mean experiences a period where its value sways heavily, as the calculation progresses, the value stabilizes at certain cycle.

Figure 5.21 shows the AR of PI with value changes in Figure 5.20 (a) where one indicates that mean value is accepted and zero otherwise. Figure 5.21 (a) represents comprehensive AR during whole computing cycle. In Figures 5.21 (b), (c) and (d) 2,000 iterations are extracted from the beginning, middle and end parts, respectively to describe changing trends in more detail. At the initial stage, AR is high because of frequent label switch of points and, then it keeps decreasing until the end of computation.

-

--.. ..............

-

(a)

j ·

(c)

(d)

Figure 5.21 Acceptance rate of PI
\

Figure 5.22 pictures the AR of Pl, whose value change is shown in Figure 5.20 (b), its shift
92

trend is similar to PI.

(a)

(b)

(c) ,

(d)

Figure 5.22 Acceptance rate of P2

Figure 5.23 indicates AR of P3, whose value mutation is shown image (c) of Figure 5.20 (c). Its AR follows the same rule as PI.
-

(a)

0'
02

o

0'

'f
(b) (c) (d)

Figure 5.23 Acceptance rate of P3

Figure 5.24 depicts AR of P4, its value change are shown in Figure 5.20 (d), still same order
93

as for #1 governs its alternation tendency.

(a)

Figure 5.24 Acceptance rate of #4 Figure 5.25 shows the AR of #5, its value change are displayed in Figure 5.20 (e), its AR experiences single decreasing period, which is identical with AR of #1.

-

(a)

(b)

(c)

(d)

Figure 5.25 Acceptance rate of #5 Figure 5.26 displays the AR of #6 with its value changes shown in Figure 5.20 (£). Observing from Figure 5.26 (b), (c) and (d) it is obvious that its AR complies with the same rule with #1.

94

-

-

-

(a)

t..::::=:;::~=~:C::==::::::i:i:::::;±J L....-_ _ _ _ _ "_'_._'_'"_''--,' '.!lW,u· 1....-_ _ ° _ '_'

_ H_ _ _ _ _ _ _ _

w:l

(b)

(c)

(d)

Figure 5.26 Acceptance rate of J16

5.2.2. Filtering
It is quite common that building roof points are accompanied by HRV points. In the study,

both the BFG building and the Optometry building are surrounded by HRV, which can be clearly observed in Figure 5.12 (d) and 5.18 (d). These points are noise and have to be removed. In this section, the Optometry building is chosen to demonstrate the approach.

The Optometry building roof consists of three layers (yellow blue and black colours in Figure 5.27 (a)) with distinct heights. The adjacent area has strong presence of HRV and these regions are square-marked in Figure 5.27 (a). In Figure 5.27 (b) and (c), two building roof layers are obtained which offer a detailed view of HRV points. Points in black colour have no involvement in building roof outline acquisition and will be treated separately in 3D building reconstruction.

95

(a)

(b)

(c)

Figure 5.27 Optometry building and it neighboring HRV

Traditional image filtering appr ach is borrow d to remove HRV points by applying dilation and ero ion tilt rs repeatedly. The process, which consist of tw ) phases,
~tart

by converting

point to grayscale image by predelined conver. ion rules. After the noi e is removed, image is con erted back t points .

r igure S.2R

demon. !Tates refining meLhod of building r of point · in blue colour. In Figure
La

5.28 (b). points are transfonlled

black and white image. A 3-pixel dilation fi lter is applied

to eliminate black pixels witbin building roof uLlinc with re ult display d in Figure S.28(c).

A II-pi el erosion filler delete HRV pixels, only building r of pixels are · hown in Figure
5.28 (d). By dilating back 11 pixels Figure 5.28 (e) i achieved. Figure 5.28 (t) exhibits pi 1

diITerencc between Figure 5.28 (c) and ( ), which bold lIRV pi cis pIli minor building pixels. After HRV pixel are deleted, remaining building pixels are converted back to points, the outcome i hown in figure 5.28 (g).

96

(a)

(b)

(c)

(d)

(e)

(f)

(g)

Figure .2 HRV pint removal (phase one)

Figure 5.29 demonstrates filtering method of building roof points in yellO\ c lour. Pint in blu colour from the previou . tep are integrated with point in yello\! colour as . hOWD

in Figure 5.29 (a). Point to image conversion is accompli hed resulting in Figure 5.29 (b). In Figur 5.29 (c) black pixels withi n building oullin are deducted by a 3-pixel dilation filter. Most HRV pixels arc eliminated by a lO-pi el ero i n filter a indicated in Figure 5.29 (d). Because a small chunk of building area i lost (area in the white polygon) an I8-pixel dilation filler i empl yed to recover part of mi ing pace indicat d by white area co ered by polygon in Figure 5.29 (e). An -pixel ro ion filter i applied to shrink the building area ba k, the result is exhibited in Figure 5.29 (t) . Figure 5.29 (g) h ws difference between Figures 5.29 ( ) and (t). [mage (h) indicate Enal building points et u
97

ived after filtering.

Figure 5.29 HRV point remo a l (pbase two)

Table 5.7 demon trates the proces' of building roof outline point

extraction and

rcgularization operation:. Imagc in the ftr t row how the re ulL from the IRFM-M M algorithm. In the e and row, building point sets are withdrawn together HRV points. By applying the above mentioned filtering techmqu , HRV points are removed, the remainjng building point el ar diu traled in the tl ird r w. Roof outline points are further extracted from building point sets through MH algorithm with re ultants shown in the fourth row. in the last row, roof outbne point algorithm. are regularized by modified hierarchi al regularization

(a)

(b)

(c)

(d)

Figure 5.29 HRV points removal (phase two)

Table 5.7 demonstrates the process of building roof outline points extraction and regularization operations. Images in the first row show the results from the GRFM-MCMC algorithm. In the second row, building point sets are withdrawn together HRV points. By applying the above mentioned filtering tecr.nique, HRV points are removed, the remaining building point sets are illustrated in the third row. Roof outline points are further extracted from building points sets through MCH algorithm with resultants shown in the fourth row. In the last row, roof outline points are regularized by modified hierarchical regularization algorithm.
\

98

Table 5.7 Building roof outline extraction and regularization
Building name

BFG

Optometry

egmcnlcd image

Building layer(s)
wilh
11

i e

Bui lding la er(s)
after fi llering

Building roof outline

Regu larizcd

build ing roof outline

*No filtering proces i needed for RIM building, building ro b fore and after filtering.

99

Table 5.7 Building roof outline extraction and regularization
Building name

BFG

Optometry

Segmented image

Building layer( s) with noise

Building layer( s) after filtering

Building roof outline

//

/-~.

\

\

\/
-,

\ ..

Regularized building roof outline

.

*No filtering process is needed for RIM building, building roof points are identical before and after filtering.

99

5.2.3. 3D Building Reconstruction in ArcGIS
After regularization, building edge point sets are ready to be exported to ArcGIS for 3D building reconstruction. The RIM building is taken to demonstrate how to convert geo-referenced point dataset to a polygon shapefile where four steps are involved.

The first step is file re-formatting. Figure 5.30 displays re-formatted border points of the RIM building required by ArcGIS where each row is the spatial reference of one point. The first row and last row must be identical and include a header and end of file mark.
1

537111.12.4813635.71 537124.17.4813610.52 537086.36.4813592.13 537067.78.4813628.72 537093.14,4813642.36 537098,4813639.5 537099.91,4813640.5 537105.81,4813638.26 537110.31,4813635.23 537111.12,4813635.71 END

Figure 5.30 File re-formatting of RIM building roof outline points

The second step is creating line coverage. "Generate" function is utilized to convert text file to line coverage file. Figure 5.31 displays the RIM building line coverage file in ArcMap.

\

100

-'/' I- .

::J \ '/

' - ::

.·

.,

.

.." .....·

.

\.

..

~

·

I

U

.0. · ... .

.i-~

·

Figure 5.31

RIM building linc covcrage /ile

111

AreGIS

The thlru stcp

I:"

polygon

sh~pctiJc

gcnnation. "Feature to Polygon" functIOn is applied to

generate pulygon shapelilc in ArcMap . FiPllrc 5.32 . hows the created shapefllc .

of.

I- ·

0

~,

· :: ;;

.

.,.

." · w

·

. ".

- ........ -· ·

·

I

Figure 5.32 RIM building roofshapefile

The last step is aSSigning the geo-reference system. The "Define Projection" function is employed to attach proper coordinat system to polygon shapefile.
10 1

s introduced in Chapter

Figure 5.31 RIM building lin~ coverage file in ArcGIS

The third step is polygon shapefile generation. "Feature to Polygon" function is applied to generate polygon shapefile in ArcMap. Figure 5.32 shows the created shape file.

Figure 5.32 RIM building roof shapefile

The last step is assigning the geo-reference system. The "Define Projection" function is employed to attach proper coordinate system to polygon shapefile. As introduced in Chapter
101

fhrc . topographic LiDAR raw data is usually in the UTM system whcr the UW campus is located in Zone 17N and 'palia selected . rderence system" D 1983 UTM Zone 17 ,. is

fter the abo c four-step operation, a functi nal RIM building shapefile is comrlcled. it can not only be ll.ed to recon. tm t 3D building, but also be shared among variolls ge -databases .

By following identical ruJ,. . hapefile.

of b th BFG and Optometry buildings are r Map. The BFG

generated. Figure 5 .33 exhibi t the shape files of sel eted buildings in

building is in blue, the RIM building in olive and the Opt metry building in rose .

..

.-.

·· -......

·

·

I

11

~.

-. ·

.,t ...

~

...

Figure 5.33 Shapefile of three selected huildings

The height of the building 'an also be estimated u ing topographic LiDAR raw data. Elevation

102

Three, topographic LiDAR raw data is usually in the UTM system where the UW campus is located in Zone 17N and spatial reference system "NAD_1983 UTM_Zone_17N" selected.
IS

After the above four-step operation, a functional RIM building shapefile is completed, it can not only be used to reconstruct 3D buildings, but also be shared among various geo-databases.

By following identical rules, shapefiles of both BFG and Optometry buildings are generated. Figure 5.33 exhibits the shapesfiles of selected buildings in ArcMap. The BFG building is in blue, the RIM building in olive and the Optometry building in rose.

~Jl~~,_~

..........

011' ... ,..

..

~.

o
102

Figure 5.33 Shapefiles of three selected buildings

The height of the building can also be estimated using topographic LiDAR raw data. Elevation

data for each point is recorded as an absolute value, usually above mean sea level (AMSL). By subtraction the height difference of the building roof layer and ground layer is computable, which can be regarded proximately as the height of building. Table 5.8 shows the calculation process. It is assumed that the ground points, in contrary to HRV points with multiple returns, all come from first return in topographic LiDAR raw data set. In the first row, the building roof points and points with multiple returns are removed and the remaining points are ground points. In the second row, points inside buffer zone with rational width along the building roof outline are picked out as reference points to calculate average height of ground. The width of buffer zones varies from 3 to 5 meters and the reason for buffer zone is that ground area within buffer tends to be flatter than the ground far from building, which can better represent the altitude of ground. In the third and fourth rows, the average altitude of ground and buildings are computed, respectively. In the last row, heights of buildings relative to the ground are figured out by subtraction of values in the third row and the fourth row. Height of buildings will be applied for 3D building reconstruction.

103

Table 5.8 Building height estimation Building name

·

·

Ground points

Buffer zone

Altitude of ground (AMSL) Unit: m Altitude of building (AMSL) Unit: m Height of building (AGL) Unit: m

338.08

337.88

344.01 350.06 353.65 (blue) 358.35(black) 6.05 (yellow) 9.64 (blue) 14.34 (black)

353.41

346.27

15.33

8.39

*Optometry building has three parts with different heights.

Based on the elevation data of each building listed in Table 5.8 and shapefiles created before, 3D buildings reconstruction is achievable. Optometry building has three levels of roofs with different altitude, in order to mimic this property in 3D view, its polygon file is split into two parts and another shapefile created from points in black colour is added. A 3D view of building is accomplished in ArcScene. Figure 5.34 provides 3D view of sample buildings, Figure 5.34 (a) is viewed from the North West and Figure 5.34 (b) is from the East.

104

(a)

(b)

Figure 5.34 D \ 11.:\\ of selected buildings

Figure 5.35 offers a

comprehcn~i"c

3D \'ie\\ of the UW campus. The builumg

shapctik:~

an:

acquireu from map lihrary \\ hile their height informatIOn is from planning office.

Figure 5.35 3D view ofUW campus

105

(a)

(b)

Figure 5.34 3D view of selected buildings

Figure 5.35 offers a comprehensive 3D view of the UW campus. The building shapefiles are acquired from map library while their height information is from planning office.

Figure 5.35 3D view ofUW campus

105

5.3. Accuracy Evaluation
In this study, three tools in descriptive statistics, namely overall accuracy (OA), commission error (CE) and omission error (OE) are introduced for accuracy estimation. Measurement of surface area covered by polygon shapefile is used for computation while standard shapefiles from U\V map library are imported as a reference. The inspection is achieved in an ArcGIS environment based on individual building polygon. The formula and brief explanation of each tool is provided as follows: 1. Overall Accuracy (OA) As the name suggests, OA tests how well the building shape according the performance of the algorithm.
IS

recovered

(5.1)

Arefis the area of reference building polygon, Aa/s is the area of building polygon
from topographic LiDAR raw data. 2. Commission Error (CE) CE indieates how much area of the building polygon is recovered where it should not. The designer of the algorithm is more concerned about CE, because it tells the correct interpretation rate building shape. )

(5.2)

106

3.

Omission I:rror (OE) OE
implIc~ hll~

much area or the building polygon fails to be rceo ered v here it

should be round. The user takes more care of the value. because it tells the percentage of the building shape that is correctly restored.
()E =

II r ef - (A (/\ I u ,I ) ref
. "'f

,1

(5.3)

Figure 5.36 exhibits overlay dIect of shapefilc. . Standard shapcfiles ar generated
OI1l.:S

In

solid red line,

are in yellow colour. In all three Images it i, noticeable that some area

controversies exist between two versions of Lhe shapefile ' in each building, by computing area diftcrcnccs. the accuracy rate of proposed algorithm can be estimated.

(a)

(b)

(c)

Figure 5.36 Overlay of shapefiles

Table 5.9 lists the area differences of three buildings in both coloured shapefile and number . Given two versions of shapefiles in

[07

3.

Omission Error (OE) OE implies how much arca of the building polygon fails to be recovered where it should be found. The user takes more care of the value, because it tells the percentage of the building shape that is correctly restored.

DE

Are! - (Aul>
Are!

U

Are!)

(5.3)

Figure 5.36 exhibits overlay effect of shape files. Standard shapefiles are in solid red line, generated ones are in yellow colour. In all three images it is noticeable that some area controversies exist between two versions of the shapefiles in each building, by computing area differences, the accuracy rate of proposed algorithm can be estimated.

\
(a) (b)
(c)

Figure 5.36 Overlay of shapefiles

Table 5.9 lists the area differences of three buildings in both coloured shapefiles and numbers. Given two versions of shape files in

107

created c:\t:l'pl

Lhallhe~

arc dIvided inw three section!'> . I hI.: Jl\:a

III

rose colour I" the

.In:il

IhaL

bnth :hapLlik!'> agree. the area in blue colour is thl.: urea in the sLamJard o.;hapclilc. but absent from generated ..,hapeIile. the area in green clliour but missing from "tandard "hapdik
IS

the an.::a present in generated slwpt:lik,
!Jl

'olourcu ..,hdpL'flles arc presented

tile set:oml column

of rable 5.9. In the thinl column. the mea!'>urCrl1cnt:

Dr

indi\ iuual cnloured areas arc

calculated through geometry computing function in \rc("I.) . Table 5.9 . hapdilcs
8uilding. names
<lrH..I

their arca

CO\

crage

Union

l)f

sharelilcs

Area by colour (Jll ~ )

RIM

-

0 0 0

11S.XO

156R.6H

95 .2.-

8F

J

0
"

63.69
1607.4X

0 0
Optometry

IIXAX
232.X2

0

\
0 345';).07
0
122.32

oA

/1.1

U Arc!

IO~

Figure 5.36, new shape files which carry the union area coverage of both shapefiles are created except that they are divided into three sections. The area in rose colour is the area that both shape files agree, the area in blue colour is the area in the standard shapefile, but absent from generated shapefile, the area in green colour is the area present in generated shapefile, but missing from standard shapefile. Coloured shapefiles are presented in the second column of Table 5.9. In the third column, the measurements of individual coloured areas are calculated through geometry computing function in ArcGIS. Table 5.9 Shapefiles and their area coverage Building names RIM Union of shape files Area by colour (m2)

0 0

115.80 1568.68

0 95.25
BFG

, /~
\\
\\ '
\\
'.

.0 63.69

\:,

\

\

.~

J\~
/;
,,/'

\ \

0 1607.48 0
118.48

<:/

Optometry

:0 232.82
I

0 3459.07 0
·0 Arej- (Aa/s U AretJ
122.32

\

o Aa/s U Arej
108

o Aa/s -(Aa/s U AretJ

In Table 5.10, OA, CE and OE of each building are calculated based on the data in Table 5.9, where the averages of each error are listed in the last row as well. OA ranges from almost 97% to 103% with an average around 100.38%. Regarding CE, an average of 5.34% of the area is mistakenly included the created shapefiles. On the other hand, 5.66% of the average area is overlooked in the created shapefiles as shown by OE. By analyzing above table, two facts are observable: the building areas are proximately fully reconstructed by the algorithm, both CE and OE are less than 6%. As such, the algorithm accomplishes satisfactory results. Table 5.10 Accuracy evaluation

I

RIM BFG Optometry Average

OA 101.24% 96.82% 103.09% 100.38%

CE 5.72% 6.87% 3.42% 5.34%

OE 6.87% 3.81% 6.31% 5.66%

Among the main factors that contribute the inaccuracies of created shapefiles, several aspects need to be examined in more detail.

HRV causes constant obstacle in building roof outline verification, it shadows neighboring buildings partly, which makes it complicated to separate building roof outline points from tree canopies, especially in situations where there is no auxiliary data available like a field map or an aerial image. The east part of the Optometry building suffers distortion of border line and loss of part of border region from strong appearance of HRY. There are some

109

remedies accessible to alleviate the impact of HRV, avoiding flight operation during tree bloom season and seeking verification from another form of data in dense HRV areas.

The scanning rate of dataset is 35 kHz, which is pretty low sampling rate considering the prevailing scanning rate is more than 200 kHz. As a result some elaborate details of building fails to be recorded. Both the BFG and the Optometry buildings have some subtle curves in roof outline design as shown in Figure 5.36. Omission of such information in the original topographic LiDAR dataset leads to the failure to retrieve proper border lines from algorithm.

Building roof outline regularizing algorithm assumes that all roof edge lines are straight, it works well for the BFG and the Optometry buildings, but introduces problem when obvious curve border line is present in the North East part of the RlM building. The linear substitution of curve line causes part of building failed to be recovered and it is exhibited in Figure 5.36 (a).

Standard shapefiles are from map library and there are no descriptions about how they are created. Standard shapefiles are assumed to be accurate in this study, however in Figure 5.36, ,it is observable that all the created shapefiles slide certain extent to south, which leaves gaps between two version of roof outlines in north part for each building. In order to
110

trace the origin of the problem, building roof points of the RIM building are extracted and overlaid with standard shapefile. Figure 5.37 shows overlay image of two datasets, as indicated by arrow, there is clearly down shift of original topographic LiDAR raw data compared to standard shapefile, which contributes to both OE's and CE's in Table 5.10. The cause of discrepancy is difficult to locate for lack of necessary information since it may come from the calibration process after the data is collected or from GPS errors during operation. The accuracy level will be further increased if systematic errors are reduced.

Figure 5.37

Overlay of RIM building roof points from topographic LiDAR data and standard shapefile

5.4. Chapter Summary
In this chapter, a complete case of 3D building reconstruction from topographic LiDAR raw data is implemented. The study area is part of UW campus. The experiment consists of five parts. First, raw data is segmented by GRMF-MCMC algorithm proposed in Chapter 4. Second, filtering process removes HRV points from dataset. Thirdly, building roof edge points are extracted and regularized. In the next step 3D buildings are reconstructed in an

111

ArcGIS environment. Finally, an accuracy assessment is conducted, which shows that the whole process achieves promising outcome with low point density topographic LiDAR data alone.

112

6. CONCLUSIONS AND RECOMMENDATIONS
6.1. Conclusions
Rapid and accurate reconstruction of 3D building models in urban areas remains a challenging task for geomatics community. Topographic LiDAR systems are capable of acquiring 3D information directly over terrain features and become a very active research topic in recent years. In this thesis, a method of 3D building model reconstruction from topographic LiDAR point clouds is presented. Compared with existing approaches, this procedure has two advantages. First, it works on LiDAR point clouds directly without pre-processing or rasterization, which eliminates the loss of spatial information during interpolation step. Second, it functions alone without auxiliary data such as vector maps or GIS data, which makes the approach more versatile.

The proposed approach consists of four steps: building roof detection, roof outline extraction, and regularization, and 3D building model generation. In the segmentation step, mathematical model resembling the distribution of LiDAR data is established by Gaussian distribution and MRF theory. The MCMC algorithm is utilized to obtain the optimal solution. The building outlines are extracted by the MCH algorithm. However, the outlines are distorted due the nature of topographic LiDAR systems and further refinement is required. The regularization of the extracted roof outlines is achieved by a modified hierarchical
113

regularization algorithm. Finally, the regularized the building roof outlines are input to the ArcGIS software to generate 3D building models.

Among the four aforementioned steps, the building detection is the most critical one and determines the quality of the building models. In this study, a new algorithm called GMRF-MCMC is proposed. The contributions of this algorithm lie in following two perspectives: 1. Topographic LiDAR data can be viewed as a large number of points positioned in 3D co-ordinate system, it is relatively easy and obvious to find solutions pursuing spatial geometry path and this is what most other researchers did in processing topographic LiDAR data. The GMRF-MCMC algorithm takes another route by introducing statistics and probability theory to solve geometry problem. This attempt will benefit other researchers in terms of diversifying mind and developing novel solutions. 2. This algorithm provides user with solution quality control that best matches the application intention. If the application requires fine resolution like what is presented in the Optometry building, parameters are adjustable, and more computing time and memory space are needed as a trade off. If a rough solution is acceptable, then a quick result is achievable in a shorter time and with less cost. This function is desirable especially in handling large volume of data like topographic LiDAR data.
114

I

The accuracy assessment is conducted through a comparison with the standard shapefiles of the buildings. The proposed method detected the full building areas with less than 6% of commission and omission errors. The results are satisfactory despite the fact that the sample LiDAR data are low accuracy data and the systematic errors exist during data collection.

The approach demonstrated in this thesis provides an efficient and accurate way to reconstruct 3D building models from topographic LiDAR point clouds. The objectives of this study are fulfilled.

6.2. Recomnlendations for Future Research
Although the proposed approach achieves promising results, several aspects for future research still remain.

The GMRF-MCMC algorithm requires human interaction, expertise is necessary in terms of having clear goal and choice of parameters, which causes inconvenience for non-professional users. A full automation algorithm is more user-friendly where the user only needs to choose the accuracy level and the algorithm can estimate best matching category number and parameter combination. Running time is one of the main concerns for this approach, as dataset becomes larger, time consumption will increase.

115

The proposed algorithm is point-based algorithm, it takes each point into consideration, and then groups points with analogous properties together. This approach is straight forward but not highly time efficient. If dataset is divided into finite portion of subsets based on certain criteria, it would be more time economic when joining these subsets back together after processing. This area-based method will yield a faster outcome than a point-based method.

During building outline regularization, the algorithm assumes that all the building roof edges are straight. This assumption is straight forward but may introduce discrepancies when handling buildings with complicated footprints. The curve roof edge detection algorithm will reduce omission error.

HRV is one of the main sources of artifact and can significantly deteriorate the preciseness of 3D building models. In topographic LiDAR point clouds, HRV points have multiple echoes, larger elevation differences and distinct intensity values compared with building roof and ground pomts. These properties can be utilized to separate HRV points from other points, which will greatly increase the accuracy rate, especially in heavy wooded regions.

116

REFERENCES

Alharthy A., J. Bethel, E. M. Mikhail, 2004. Analysis and accuracy assessment of airborne lasers canning system, Proceedings of the 20th ISPRS Congress, Commission II: 114-149. Arefi, H. and M. Hahn, 2005. A hierarchical procedure for segmentation and classification of airborne LiDAR images, IEEE International,' 7(7): 4950-4953. ASPRS LiDAR Guidelines: Horizontal Accuracy Reporting, 2008. URL:

http://www.asprs.org/ societyI di visions/ppd/standardslHorizontal_Accuracy_Reporting_fo r_ALS Data.pdf (last date accessed: 10 January, 2008). ASPRS LiDAR Guidelines : Vertical Accuracy Reporting for LiDAR Data, 2008. URL: http://www.asprs.org/societyI commi tteeslALS/DownloadsNerti cal_Accuracy_Reporting _for_ALS_Data.pdf (last date accessed: 15 January, 2008). Axelsson, P., 2000. DEM Generation from laser scanner data using TIN adaptive models,
International Archives of Photogrammetry & Remote Sensing, 33(B3): 85-92.

Baltsavias, E. P., 1999a. A comparison between photogrammetry and laser scanning, ISPRS
Journal ofPhotogram metry & Remote Sensing, 54(2-3): 83-94.

Baltsavias, E. P., 1999b. Airborne laser scanning: basic relations and formulas, ISPRS
Journal of Photogrammetry & Remote Sensing, 54(2-3): 199-214.

Baltsavias, E. P., 1999c. Airborne laser scanning: existing systems and firms and other
117

resources, ISPRS Journal ofPhotogrammetry & Remote Sensing, 54(2-3): 164-198. Baltsavias, E.P., E. Favey, A. Bauder, H. Bosch, and M. Pateraki, 2001. Digital surface modelling by airborne laser scanning and digital photogrammetry for glacier monitoring.

The Photogrammetric Record, 17 (98): 243-273.
Barber, D., 2006. The LAS Format, Proceedings of the Heritage 3d Workshop, Newcastle, The United Kingdom. URL: http://www.ceg.ncl.ac.uklheritage3dJdownloads/

workshop2006lbarberl.pdf (last date accessed: 05 February 2008) Bouman, A. C., 1995. Markov Random Fields and Stochastic Image Models, Proceeding of

IEEE International Conference on Image Processing, Washington D.C., USA.
Brovelli, M., M. Cannata, and U. Longoni, 2002. Managing and processing LiDAR data within GRASS. Proceedings of the Open Source GIS-GRASS users conference, Trento, Italy. Charaniya, A., R. Manduchi and S. Lodha, 2004. Supervised parameteric classification of aerial LiDAR data, Proceedings ofIEEE Workshop on Real-Time 3D Sensors, pp. 25-32. Chen, Q., P. Gong, D. Baldocchi, and G. Xie, 2007. Filtering airborne laser scanning data with morphological methods, Photogrammetric Engineering & Remote Sensing, 73(2): 175-185. Crombaghs, M., R. Briigelmann, E. de Min, 2000. On the adjustment of overlapping strips of laser altirpeter height data, International Archive of Photogrammetry and Remote

Sensing, 33 (3A): 230-237.
118

Dash, J., E. Steinle, R. P. Singh and H. P. Bahr, 2004. Automatic building extraction from laser scanning data: an input tool for disaster management, Advances in Space Research, 33(3): 317-322. Deng, F., Z. Zhang and J. Zhang, 2004. Construct 3D city model by multi-sensor data,

Proceeding of ISPRS Workshop on Service and Application ofSpatial Data Infrastructure,
187-190. Dorninger, P. and N. Pfeifer, 2008. A comprehensive automated 3d approach for building extraction, reconstruction, and regularization from airborne laser scanning point clouds,

Sensor, 8(11): 7323-7343.
Douglas, D. H. and T. K. Peucker, 1973. Algorithms for the reduction of the number of points required to represent a digitized line or its caricature. Canadian Cartographer, 10(2): 112-122. Elberink, S. O. and G. Vosselman, 2006. 3D modeling of topographic objects by fusing 2D maps and LiDAR data, International Archives of Photogrammetry and Remote Sensing, 36 (4): 175-184. Fan, T., G. Medioni, and R. Nevatia, 1987. Segmented description of 3-D surfaces, IEEE

Transactions on Robotics and Automation, 3(6): 527-538.
Flood, M, and B. Gutelius, 1997. Commercial implications of topographic terrain mapping using scanning airborne laser radar, photogrammetric engineering & remote sensing,

Photogrammetric Engineering and Remote Sensing, 63(4): 327-329.
119

Flood, M., 2001. Eye safety concerns in ALS mapping, Proceedings of the American Society

for Photogrammetry and Remote Sensing Annual Convention,

pp.23-27.

Flood, M., 2002. Product definitions and guidelines for use in specifying ALS deliverables,

Photogrammetric Engineering & Remote Sensing, 68 (12): 785-791.
Fowler, R., 2001. Topographic LiDAR, in Digital Elevation Model Technologies and Applications: The DEM Users Manual, David F. Maune, Editor, The American Society for Photogrammetry andRemote Sensing, Bethesda, Maryland, USA, 539 pages. GIM International Product Survey: ALS Sensors (2007):21(2).

URL: http://www.gim-international.comlproductsurvey/id 19-Airborne_ ALS_Sensors_Fe bruary _,_Volume_,_Issue.html, (last date accessed: 15 March 2008). Gorte, B., 2002. Segmentation of tin-structured surface models, Symposium on geospatial

theory, Processing and Applications, Ottawa, Canada, pp. 278-281.
Haala, N. and K. Brenner 1997. Generation of 3D city models from airborne laser scanning data. Proceedings EARSEL Workshop on LiDAR Remote Sensing on Land and Sea, Tallinn/Estonia, pp. 145-153. Haala, N., C. Brenner and K.-H. Anders,1998. 3D urban GIS from laser altimeter and 2D map data,

International

Archives

of Photogrammetry

and Remote

Sensing,

32(3/1):339-346.

Han, S. H., J. H. Lee and K. Y. Yu, 2007. An approach for segmentation of airborne laser point clouds utilizing scan-line characteristics, Electronics and Telecommunications
120

Research Institute (ETRI), 29 (5): 641-648.
Han, S. H., J. H. Lee, and K.Y. Yu, 2007. An approach for segmentation of airborne laser point clouds utilizing scan-line characteristics, ETRI Journal, 29 (5): 641-648. Heesch, D and M. Petrou, 2007. Non-Gibbsian Markov random field models for contextmil labeling of structured scenes, Proceedings of British Machine Vision Conference, University of'VVarwick, UK, pp. 183-192. Hofmann, A., 2004. Analysis of TIN-structure ,parameter spaces in airborne laser scanner data for 3-D building model generation, International Archives of Photogrammetry and

Remote Sensing, 35(B3):302-307.
Huber, M., W. Schickler, S. Hinz and A. Baumgartner, 2003. Fusion of LiDAR data and aerial imagery for automatic reconstruction of building surfaces, Remote Sensing and Data

Fusion over Urban Areas, 2nd GRSSIISPRS Joint Workshop on International Conference on Image Processing, Washington, D.C., USA, pp. 82-86.
Inside Mac Media, Inc., 2008. URL: http://www.osxfaq.com/manJ5/a.ouLws (last date accessed: March 5 2008). Isenburg, M. and J. Shewchuk, 2008. LAStools: converting, viewing, and compressing LiDAR data in LAS format, URL:http://www.cs.unc.edul-isenburg/lastools/ (last date accessed: 24 October 2008). Jenks, G. F., 1989. Geographic logic in line generalization, Cartographica, 26 (1): 27-42. Jiang, X. and H. Bunke, 1994. Fast segmentation of range images into planar regions by

121

scanline grouping. Machine Vision and Applications, 7 (2): 115-122. Jonas, D., and P. Byrne, 2003. Airborne laser scanning: beyond its fonnative years, URL: http://www.aamhatch.com.aulresources/pdf/pub lications/technicalyapers/Ssc2003 _Jona s.pdf I (last date accessed: 29 April 2008). Jwa, Y., G. Sohn, V. Tao and W. Cho, 2008. An implicit geometric regularization of 3d building shape using airborne LiDAR data, International Archives of Photogrammetry
and Remote Sensing, 37 (B3a): 69-76.

Kilian, 1., N. Haala, and M. English, 1996. Capture and evaluation of airborne laser scanner data, International Archives ofPhotogrammetry and Remote Sensing, 31 (B3): 383-388. Kim, C., M. Ghanma, and A. Habib, 2006. Integration of Photogrammetric and LiDAR data for realistic 3D model generation, first International Workshop on Mobile Geospatiai
Augmented Reality, Banff, Canada, pp. 135-143.

Kraus, K and N. Pfeifer, 1997. A new method for surface reconstruction from laser scanner data, International Archives ofPhotogrammetry & Remote Sensing, 32(3-2W3): 80-86. Kraus, K. and N. Pfeifer, 1998. Detennination of terrain models in wooded areas with airborne laser scanner data, ISPRS Journal of Photogrammetry & Remote Sensing, 53(4):193-203. LAS fonnat, 2008. URL: http://www.asprs.org/resources/standards/ALS date accbsed: 10 January 2008). Lee, H. Sand N. H. Younan, 2003. DTM extraction of LiDAR returns VIa adaptive
122

fonnat.html (last

processing, IEEE Transactions On Geoscience and Remote Sensing, 41(9): 2063-2069. Lee, I. and T. Schenk, 2001. 3d perceptual organization oflaser altimetry data, International

Archives of Photogrammetry and Remote Sensing, 34:57-65.
Lee, J. H., S. H. Han, Y. G. Byun, K. Y. Yu, and Y. I. Kim, 2007. Building extraction and 3d modeling from airborne laser scanning data, Korean Journal of Remote Sensing, 23(5):

Lin, S. and H. Wu, 2006. Sweep line based. filtering of airborne laser scanning data,

Proceedings of SPIE, the International Society for Optical Engineering, 6419:
64191S-64191S-10. Lohmann, P., 2002. Segmentation and filtering of laser scanner digital surface models,

International Archives of Photogrammetry Remote Sensing, 34(2): 311-316.
Maas, H.-G., 1999. Closed solution for the determination of parametric building models from invariant moments of airborne laser scanner data, International Archives of

Photogrammetry and Remote Sensing ,32(3-2W 5): 193-199.
Mass, H. G., 2003. Planimetric and height accuracy of airborne laser scanner data: user requirement and system performance, URL:http://www.tu-dresden.de/ipf/photo/publikationenl2003IMaas_ PhoWo2003. pdf I (last date accessed: 15 May 2008). Maune, F. D., 2008. Digital Elevation Model Technologies and Applications: The DEM Users Manual, URL: https:lleserv.asprs.org/eseries/staticcontent/staticpages/1 069.htm
123

(last date accessed: 20 March 2008). . Morin, K., and E. N. Sheimy, 2002. Post-mission adjustment methods of airborne laser scanning data, International Federation of Surveyors (FIG) XXII International Congress, Washington, D.C. USA, pp. 235-244. NOAA, 2008. Remote Sensing for Coastal Management, URL:http://www.csc.noaa.gov/crs/rs_apps/sensors/lidar.htm (last date accessed: 14 November 2008). Optech, 2008. Optech: the LiDAR company, PowerPoint presentation on 12 February 2008, University of Waterloo. Perez, P., 1998. Markov Random Fields and Images, CWI Quarterly, 11(4): 413-457. Pfeifer, N., and C. Briese, 2007. Laser scanning - principles and applications, URL: http://publik.tuwien.ac.atlfiles/pub-geo 1951.pdf I (last date accessed: 20 May 2008). Pieczynski, w. and A. N. Tebbache, 2000. Pairwise markov random fields and its application in textured images segmentation, Proceedings of 4th IEEE Southwest Symposium on

Image Analysis and Interpretation, Austin, USA, pp. 106-110.
Roggero, M., 2001. Airborne laser scanning: clustering in raw data, International Archives of

the Photogrammetry and Remote Sensing, 34 (B31W4): 227-232.
Ronnholm , P., E. Honkavaara, P. Litkey, H. Hyyppa and J. Hyyppa, 2007. Integration of laser scanning and photogrammetry, International Archives of Photogrammetry and

Remote Sensing, 36(31W52):355-362.
124

Rottensteiner, F, J. Trinder, S. Clode and K. Kubik, 2003. Building detection using LiDAR data and multi-spectral images, Proceedings of 7th Digital Image Computing: Techniques and

Applications, Sydney, Australia, pp. 673-682.
Rottensteiner, F., and C. Briese, 2002. A new method for building extraction in urban areas from high-resolution LiDAR data, Proceedings of the ISPRS Commission III Symposium, Graz, Austria, pp. 295-30 1. Samberg, A., 2007. An implementation of the ASPRS LAS standard, International Archives

of Photogrammetry and Remote Sensing, 36 (3 I W52):363-372.
Sampath, A and J. Shan, 2007. Building Boundary Tracing and Regularization from Airborne LiDAR Point Clouds, Photogrammetric Engineering and Remote Sensing, 73(7): 805-812. Sampath, A., and J. Shan, 2004. Urban modeling based on segmentation and regularization of ALS point clouds, International Archive of Photogrammetry and Remote Sensing, 35(B3): 937-941. Schenk, T., 2001. Modeling and recovering systematic errors in airborne laser scanners, The

European Organization for Experimental Photogrammetric Research (OEEPE) Workshop on Airborne Laser scanning and Interferometric SAR for Detailed Digital Elevation Model, pp. 40-48.
Schickler, w. and A. Thorpe, 2001. Surface estimation based on LiDAR,

URL:http://www.sanmap.com/Pdfs/Article_SurfaceEstimation.pd£l (last date accessed: 10
125

May 2008). Schwalbe, E., H. Maas and F. Seidel, 2005. 3D building model generation from airborne laser scanner data using 2D GIS data and orthogonal point cloud projections, ISPRS WG III/3,
IIII4, V/3 Workshop "Laser scanning 2005", Enschede, the Netherlands, pp. 209-214.

Sentinel

Archiving,

Inc,

2008.

The

electromagnetic

nature

of

light.

URL:

http://www.sentinelarchiving.comlARTICLES/electromag.htm (last data accessed: 18 January 2008). Shan, J and A. Sampath, 2005. Urban DEM generation from raw LiDAR data: a labeling algorithm and its performance, Photogrammetric Engineering & Remote Sensing, 71 (2): 217-226. Sithole, G. and G, Vosselman, 2004. Experimental companson of filter algorithms for bare-Earth extraction from airborne laser scanning point clouds, ISPRS Journal of
Photogrammetry & Remote Sensing, 59: 85-101.

Sithole, G. and G, Vosselman, 2005. Filtering of airborne laser scanner data based on segmented point clouds, International Society of Photogrammetry and Remote Sensing,
Workshop "Laser scanning 2005", Enschede, the Netherlands, pp. 66-7l.

Sithole, G. and G. Vosselman, 2003. Comparison of filtering algorithms, Proceedings of the
ISPRS working group III/3 workshop '3-D reconstruction from airborne laser scanner and InSAR data', Dresden, Germany, pp. 240-247.

Sithole, G., 2001. Filtering of laser altimetry data using a slope adaptive filter, International
126

Archives of the Photogrammetry and Remote Sensing, 34(3/w4): 203-210.

Sithole, G., 2005. Segmentation and classification of airborne laser scanner data,
Publications on Geodesy 59, NCG, Delft.

Steed, A., S. Spinello, B. Croxford and R. Milton, 2004. Data visualization within urban models, Proceedings Theory and Practice ofComputer Graphics, IEEE Computer Society, Washington D.C, USA, pp. 9-16. Straatsma, M.W., and H. Middelkoop, 2006. Airborne laser scanning as a tool for low land floodplain vegetation monitoring, Hydrobiologia, 565:87-103. Tarsha-Kurdi, F., T. Landes and P. Grussenmeyer, 2007. Joint combination of point cloud and DSM for 3D building reconstruction using airborne laser scanner data, Proceedings of
Urban Remote Sensing Joint Event, Paris, France, pp.I-7.

Tarsha-Kurdi, F., T. Landes, P. Grussenmeyer and E. Smigiel, 2006. New approach for automatic detection of buildings in airborne laser scanner data using first echo only,
International Archives ofPhotogram metry and Remote Sensing, 36(3): 25-30.

ThuyVu, T. and M. Tokunaga, 2002. Designing of wavelet-based processing system for airborne laser scanner segmentation. International Archives of the Photogrammetry and
Remote Sensing, 34(5/W3):1682-1777.

TMSI, 2005. The Global Market for ALS Systems and Services, TMS International Ltd., Houston, Texas, 158 p. Tolt, G., U. Soderman and S. Ahlberg, 2007. 3D Urban models from laser radar data, Urban
127

Remote Sensing Joint Event, 2007, Paris, France, pp.I-5.
Tovari, D. and N. Pfeifer, 2005. Segmentation based robust interpolation a new approach to

laser data filtering, International Archives of Photogrammetry and Remote Sensing,
33(3fWI9): 79-84.

Ung, A., 1996. Retargetable loader, URL:
http://www.itee.uq.edu.au/~cristina/students/david/honoursThesis96lbff.htm

(last date

accessed: 24 January 2008). Vosselman, G. and H. Mass, 2001. Adjustment and filtering of raw laser altimetry data, URL:http://www.tu-dresden.de/ipf/photo/publikationenlaeltereNosselmann_Maas_DEE PEStockholm2001.pdf I (last data accessed: 15 April 2008). Vosselman, G. and S. Dijkman, 2001. 3D building model reconstruction from point clouds and ground plans, International Archives of Photogrammetry and Remote Sensing,
36(3fW4): 37-43.

Vosselman, G., 2000. Slope based filtering of laser altimetry data, International Archives of

Photogrammetry and Remote Sensing, 33(B4): 958-964.
Vosselman, G.,2002. Fusion of laser scanning data, maps, and aerial photographs for building reconstruction, Geoscience and Remote Sensing Symposium, 2002. IGARSS '02. 2002

IEEE International, 1:85-88.
Wang, M. and Y.-H. Tseng, 2004. LiDAR data segmentation and classification based on octree structure. International Archives of the Photogrammetry and Remote Sensing,
128

35(B3): 308-313. Webster, T. L., and G. Dias, 2006. An automated GIS procedure for comparing GPS and proximal ALS elevations, Computers & Geosciences 32: 713-726. Webster, T.L., D. L. Forbes, S. Dickie, 2004. Using topographic ALS to map flood risk from storm-surge events from Charlottetown, Prince Edward Island. Canadian Journal of

Remote Sensing 30 (1): 64-76.
Wehr, A., and U. Lohr, 1999. Airborne laser scanning-an introduction and overview, ISPRS

Journal ofPhotogram metry & Remote Sensing, 54(2-3): 68-82.
Wehr, A., U. Lohr, and E. Baltsavias, 1999. Theme issue on airborne laser scanning, ISPRS

Journal of Photogram metry & Remote Sensing, 54(2-3):.61-63.
Weidner, U. and \V. Forstner, 1995. Towards automatic building extraction from high resolution digital elevation models, ISPRS Journal of Photogrammetry & Remote Sensing, 50(4):38-49. Woo, H., E. Kang, S. Wang and K. H. Lee, 2002. A new segmentation method for point cloud data, International Journal of Machine Tools & Manufacture, 42: 167-178. Zhang, X. and J. Liu, 2004. Analysis of systematic error influences on accuracy of airborne laser scanning altimetry, Geo-spatiaIIriformation, 7(3): 218-224. Zhang; K., S. -C. Chen, D. Whitman, M. -L. Shyu, J. Yan and C. Zhang, 2003. A progressive morphological filter for removing nonground measurements from airborne LiDAR data,

IEEE Transactions on Geoscience and Remote Sensing, 41 (4): 872-882.
129

Zhang, Y., 2000. Markov random field theory. URL:http://www.fmrib.ox.ac.uklanalysis/techrep/trOOyzl/trOOyzl/node4.html (last date accessed: 2 October 2008).

\

130

