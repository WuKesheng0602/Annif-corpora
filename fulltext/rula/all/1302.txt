Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2009

In dialogue with emergence
Timothy David Mitanidis
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Architecture Commons Recommended Citation
Mitanidis, Timothy David, "In dialogue with emergence" (2009). Theses and dissertations. Paper 555.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

IN DIALOGUE WITH EMERGENCE

by

Timothy David Mitanidis B.Arch. Sci. Ryerson University, 2002
Diplm. Staedelschule, 2005

A thesis presented to Ryerson University

in partial fulfilment of the

requirements for the degree of
Master of Architecture

In the Program of Architectural Science

Toronto, Ontario, Canada, 2009
Â©Timothy Mitanidis 2009

Author's Declaration

I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this to other institutions or individuals for the
purpose of scholarly research.

Timothy tvfitanidis

Furthermore I authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of the other institutions or individuals
for the purpose of scholarly research.

Timothy Mitanidis

Dialogue with Emergence
Master of Architecture

2009 Timothy David Mitanidis
Ryerson University, Toronto

Abstract

The following report outlines the conjectural basis for an examination of the existing system of
architectural production, and the imminent changes that are becoming more evident with the
increasing saturation of digital technologies.

Emergence and complexity theory have set the stage for a future of integrated system design.
With many of our current modes of production already being heavily influenced by digital design

and automated fabrication, the question for the building industry becomes not if, but how shall
these systems be integrated in the production of architecture?

Through the execution of an urban design project located at the Alexandra Park housing co

operative, this thesis establishes a commentary based in emergent theory that grounds the speculation of future possibilities in an historical understanding of current changes in

contemporary architectural discourse. The exploration of difference as a generator of urban renewal is central to the proposals ability to induce positive change through dynamic emergent
behaviour.

1 Introduction 1

1.1 Communicating Change 2 1.2 The Interconnected City 4

2 Problem Statement 7

3 Background Research 9 3.1 Emergence 9 3.1.1 Organization 10

3.1.2 Communications 11
3.1.3 Feedback 12

3.1.4 Dialogue 13 3.1.5 Design 14 3.2 Digital Work Flow 16 3.2.1 Collaboration 16 3.2.2 Design 18 3.2.3 Fabrication 20 3.2.4 Assembly 21

3.2.5 Continuity 22

4 Literature Review 25
5 Precedents 33 5.1 City Balcony 34

5.2 Loblolly House 36 5.3 Wein Gutenbeim 38 5.4 Game of Life 40 5.5 Spore - Life simulation 42
5.6 Photosynth 44

6 Site Analysis 47

7 Methodology 55
7.1 Emergence 56
7.2 Digitalization 57

7.3 Language 58 7.4 Algorithmic 59

8 Results 61
8.1 Counter Proposal 61

8.2 Existing Complexities 62 8.3 Points of Interest 63 8.4 Project Conception 65 8.4.1 Responsive Matrix 66 8.4.2 Spatial Variation 69 8.4.3 Emergent Qualities 73 8.4.4 Project Overview 74
9 Conclusions 79 10 References 82

List of Figures

Fig. 8.17 -Addressing Urban Issues, created by author Fig. 8.18 - Along the Carr Axis, created by author Fig. 8.19 - Public Open Space off Queen, created by author Fig. 8.20 - Dundas Garden Gateway, created by author
Fig. 8.21 - Ground Connections, created by author

Fig. 5.1 - Rule Definition, From Text Scheurer, F. (2005)
Fig. 5.2 - Rules of the Game, Retrieved from www.theverymany.com

Fig. 6.1 - Location Map, created by author Fig. 6.2 - Neighbourhood Map, created by author Fig. 6.3 - Figure Ground, created by author
Fig. 6.4 - Land Value, created by author Fig. 6.5 - Land Use, created by author

Fig. 9.1 - Alternative Direction, created by author
Fig, 9.2 - Alternative Constructs, created by author

Fig. 6.6 - Areas of Potential, created by author
Fig. 6.7 - Safety, created by author

List of Images
Image 5.1 City Balcony, Retrieved from www.kcap.eu Image 5.2 Loblolly House, Retrieved from www.treehugger.com Image 5.3 Phases, Retrieved from archrecord,construction.com, photos by Russell Fortmeyer

Fig. 6.8 - Green Space, created by author

Fig. 6.9 - Composite Map, created by author
Fig. 8.1 - Point Towers, created by author
Fig. 8.2 - Midrise, created by author

Fig. 8.3 - Urban Alterations, created by author
Fig. 8.4 - Key Areas, created by author

Image 5.4 Wein Gaetenbaum, Still of video retrieved from www.monocole.com Image 5.5 ROB at Venice, Retrieved from www.treehugger.com, by Alessadra Bello Image 5.6 Game of Life Exhibit, Retrieved from www.ledlightray.com, by Leo Vilareal
Image 5.7 Unique World, Gameplay image. Spore by Electronic Arts. Image 5.8 Unlimited Variation, Retrieved from www.totalspore.com

Fig. 8.5 - Generating Difference, created by author Fig. 8.6 - Default Point Matrix, created by author
Fig. 8.7 - Point Response, created by author

Fig. 8.8 - Deformed Point Matrix, created by author Fig. 8.9 - Hexagonal Typography, created by author
Fig. 8.10 - Spatial Variation, created by author Fig. 8.11 - Abstract Model, created by author

Image 5.9 Photosynth Point Construction. Retrieved from www.photosynth.net Image 5.10 Designer Aguera y Areas, Still of Video retrieved from www.ted.com

Fig. 8.12 - Reactive Envelope, created by author Fig. 8.13 - Body Structure, created by author

Fig. 8.14 - Emergent Relationships, created by author

Fig. 8.15 - Augusta & Grange Gateway, created by author
Fig. 8.16 - Detailed Interactions, created by author

1 Introduction
Over the course of the last century our culture has been witness to a massive rewiring that is

largely the effect of our increasing dependency on electronic technologies. The restructuring of
our social systems has been accelerated in recent years by the onset of the digital revolution, the effect of which infiltrates all aspects of daily life. As digital technologies become increasingly

embedded in the fabric of society, new ideas have begun to emerge about the inner workings of
our universe and the complex systems that make up the world we inhabit. In effect digital tools

are "allowing us to see deeper into existing realities giving us insight into the complex

relationships that exist all around us." (Hensel, 2006, p.32) The power of the digital language of
binary code has given humankind a new grammar with which to describe our surroundings, opening many new avenues in the exploration and pursuit of truth.

The digital explosion, which engulfed the later half of the 20th century, was spawned by the
emergence of the new language of electricity. Binary code in its most simple state is the
dialectic relationship between presence and absence. It is a language that consists of only two discreet components. In the case of computers 1's and 0's represent the presence or absence

of electricity, and from this absolute simplification a language is born that is capable of
describing unlimited complexities. As a language, binary code shares many of the same

characteristics found in our national languages, especially those of the western world, in which
the idea of binary code first flourished. Both binary code and the phonetic alphabet are based on symbols that are semantically meaningless, thus enabling each to describe possibilities not
existing at their inception. The exceptionality of binary code lies in its ability to describe many

other forms of communication beyond writing and speech. Because binary code is an inclusive

technology it has the ability to be a mediator between media that were once thought to be unique and distinct. Texts, pictures, mathematics, manufacturing processes, the growth of a tree
are all capable of being described digitally. Marshal McLuhan, in his prophetic text

Understanding Media: The Extensions of Man (1964) describes binary code as the epitome of
human communication, because it promises the instant translation from any code to another, eliminating the need for translation altogether, in favour of a system which establishes

connection through a general cosmic consciousness.

The study of emergent systems, which are commonly described as systems that produce
entirely novel outcomes, has been a beneficiary of the power and logic of digital technology. The immense computational power of computers has allowed scientists and theorists an

opportunity to explore and test systems that exhibit great complexity. Understanding gained from the study of complex systems is creating a shift away from the notion that development is
the result of a top down controlling apparatus. New evidence implies that most complex systems

entirety of a form through the use of plan, section, and elevation, a tradition that has carried forward onto this day. Luce suggests that with the rediscovery of projective geometry came

great changes in the way we envisioned and represented architecture, a change that is similar in scope and scale to that which is being experienced today, with fundamental changes being a
direct result of the digitalisation of society.

are controlled from the bottom up, and are anarchical structures that rely on the communication

between constituent parts to propel the growth and prosperity of the whole. It is the communication between elements, and the simple rule sets that govern their behaviour, that allow complex systems to thrive. As our civilisation is coming to terms with the vast interconnectedness of the digital realm, revelations about the potential qualities of emergent systems, which are locked in constant communication and subject to perpetual feedback, begin
to shift the focus away from object base study toward the integral design of the very systems

Similarly, we may speculate that the digitisation of architecture will forever change the way we
perceive and construct space. It would also not be far fetched to suggest that binary language

as the emerging standard of communication in our digital age has the potential of eliminating the need for representational drawings altogether. The infiltration of digital technology at key points in the production of architecture is already well under way. As the continuum from conception to completion becomes increasingly integrated and real, in opposition to its current representative nature, the importance of inserting efficiencies at strategic points in the system becomes
amplified.

themselves. It has become apparent to most that architecture can itself be described as a self organizing system, which as Manuel De Landa (1997) explains consists of a complex mixture of geological, biological, social, and linguistic constructions, and therefore could stand to benefit
from the inclusion of emergent processes in their conception and proliferation.

As emergence moves to the forefront of contemporary thought, we may ask ourselves how
theories of complexity and emergence can help us understand the intricacies of our own

Considering that self-organizing

entities are

bound

by natural

laws of optimisation

and

efficiency, are the lessons of emergent system theory transportable to a renewed system of architectural production? If so, where are those efficiencies to be found, and how and where can
they be implemented?

systems of habitation. Can lessons learned from the study of emergence contain the potential
that would allow us to create more efficient and functional communities?
1.1 Communicating Change

As Sanford Kwinter so rightly suggests the scale of the new architecture is infrastructural, it is

an exploration and manipulation of the organizing systems of the grid. (Kwinter, 2007) As
community and patterns of habitation are intrinsically link to their systems of production, or the infrastructure of construction, it is imperative that an architectural response be well versed in, as

Heavily vested in its own language of communication, architectural production has also seen

many new advances, which harness the quickness and agility of systems that are based on the
common language of binary code. However, as with most other digital technologies used in

well as capable of altering, the systems at the very heart of its development. Emerging ideas of productivity, within and without architecture, vested in the ideal of creating better patterns of
habitation for future living.

daily life, architecture's digitalisation is just scratching the surface of established processes that
have taken many hundreds of years to crystallize. Stable systems of production such as

architectural drawing have widely incorporated digital technology. Although computer assisted
drawing (CAD) programs have become the industry standard within architectural offices, they

have only managed to streamline traditional practices, and have not fully explored the holistic

potential made possible by digitisation. Integrated design processes such as building

information modelling (BIM), which are still in their infancy, have started to show signs of promise by taking advantage of the potentially seamless movement of digital design information.
The language of architecture has been relatively stable since the advent of the triadic form

(Luce, 2008) over 500 years ago. Architects of the renaissance described the three dimensional

1.2 The Interconnected City

power of cities and their acute self-organization through bottom up emergent processes.

Recognising the visionary contribution of Jane Jacobs's exposure of the true nature of cities,

The definition of a city as a construct that is specifically design for the transmission and storage

Batty, with the help of digital tools and advanced computer modelling, builds a convincing

of a civilizations good by Lewis Mumford (1961) has help to establish the city's role as a nexus

argument that would have reinforced Jacobs's stark opposition to the conventional wisdom of
her contemporaries. Examples of Modernist city planning throughout our city have recently come under intense

of human innovation. The ability of cities to learn and redistribute knowledge is an essential attribute of what is undoubtedly the most successful form of human settlement on the planet. As

identified by Mumford, the sharing and transfer of information is a key component to a city's
perpetual growth. However, the complexity of the interactions defining a city's growth sustaining energetic flows has been vastly underestimated. Unreceptive to the propositions made by Jane Jacobs through her seminal text, The Death and Life of Great American Cities (1961) the established planning culture failed to recognize, the type of problem a city truly was. Cities, as Jacobs (1961) speculated, happen to be problems of organized complexity, systems that thwart attempts at top down decision making in favour of highly decentralised local interactions that
begin with the individual and enable city growth from the bottom up.

scrutiny for their apparent failure in addressing many of the problems that they were intended to

combat. Community housing projects such as Alexandra Park and Regent Park, both in
Toronto, are facing increasing political pressure, as degenerating social conditions leave the

future of these projects and their built structures in question. As land values increase near the city's core, the city is moving forward with a proposal to level Regent Park, at a significant environmental and social cost, to be replaced with a more diverse capital driven community that
follows tradition city building methodologies. The intention of my study in Alexandra Park is to investigate the possibility of a middle ground that eliminates the need to destroy the existing

However ingenious and effective the form of a city may be it is inconceivable that early humans

building stock, through the strategic deployment of local interventions that act as a catalyst to
restart and encourage a more natural mode of city growth.

set out with the specified goal of creating villages, towns, and cities, considering the simple fact
that they had probably never seen a city to begin with. It is far more likely that cities are a

beneficial by-product of local decision making by residents who "aren't setting out to build bigger settlements," but are rather trying "to solve local problems". (Johnson, 2001 pg.112) The curious

explosion of the city in the early part of the second millennium is one of the most powerful
examples of emergence, connected to human activity, in recorded history. In fact most of the

world's cities are in no way a product of intentional design decisions, but a series of personal interactions that have coalesced in to a model of habitation that is based on a very simple
premise; the inherent need of individual survival achieved through a maximisation of available
energy.

Considering the fact that the majority of cities, including almost all of the cites we find especially
pleasing to be in, are products of systems that are proficient examples of an emergent system,

the progression to exploring emergence as a tool for the design of urban space seems quite
natural.

How can Emergence and Complexity theory change the way we think about and designing settlements? In his book Cities and Complexity, Michael Batty (2007) explores the development of a truly spatial understanding city growth that he suggest, until recently, has not been present in the study of cities and their patterns of growth. Batty has developed a strong case for the

2 Problem Statement
"But look at what we have built with the first several billions: low income projects that have become worse centres of delinquency, vandalism, and general hopelessness than the slums they were

supposed to replace; middleincome housing projects which are truly marvels of dullness and regimentation, sealed against buoyancy or vitality. Or try to, with vapid vulgarity; cultural centres that are unable to support a good bookstore; civic centres that are avoided by everyone but bums, who have fewer choices of loitering place than others; commercial centres that are lack-lustre imitations of standardised suburban chain-store shopping; promenades that go from no place to no-where and have no promenaders; expressways that eviscerate great cities. This is not the rebuilding of cities.

This is the sacking of cities." (Jane Jacobs, 1961, pg. 4)

Jacobs's words are a fitting description of the immense damage we have managed to inflict on our cities. It was, arguably, not malice that has brought these problems to our modern cities but a misguided attempt, through the implementation of modern ideas of planning, to establish a false sense of order on what is inherently a chaotic system. In the development of many social housing projects the implementation of modern planning principles has continued regardless of many promising new theories that propose alternative solutions to the specific problems facing the city. The rigorous separation of functions used in modern city planning places severe limits on a community's ability to adapt to change, effectively eliminating the possibility of truly novel systems to emerge. Curiously, the construction of Alexandra Park coincided with the rise of complexity and chaos theory. Although advanced mathematics and sciences were starting to explore complexity

theory to solve problems that resisted simplification, the

1960's mark a solidification of

modernist planning principles in architecture and planning discourses. Unfortunately, avant-

garde thinkers of the time, such as Jane Jacobs, who understood quite clearly that complexity was entrenched in the constructs of a vibrant city, had difficulty convincing the establish school

of thought, which commonly relied on top down planning methods to assume a false sense of
control. Many existing rules and zoning laws override natural growth patterns and in turn

hamper the development of a city, inhibiting its ability to react to existing pressures and
conditions.

As many of this city's post war building projects have quickly begun to show signs of dysfunction, opponents have arisen to the seemingly inflexible and authoritative construct of
traditional plans. The main issue centres on the failure of the plan to understand the complexity

of the city and an inherent need for its component parts to be in a state of constant flux.
Emergence with the aid of digital technology can help to strike a balance between pre planned systems and chaotic development. The ability to better understand complex systems may help us regain some of the qualities associated with natural city growth without it being uncontrolled. Feedback is a key ingredient that provides the necessary information that the emergent city will

3. Background Research
3.1 Emergence

While the definition of emergence suggest that "as systems acquire increasingly higher degrees of organizational complexity they begin to exhibit novel properties that in some cases transcend the properties of their constituent parts, and behave in ways that cannot be predicted on the basis of the laws that govern their existence" (Kim, 2008 pg. 127), the activity of design suggests the presence of conscious decision-making and absolute control. Given this apparent paradox, how do we resolve the dialectic nature of these opposing techniques of becoming? Emergence itself is not a new phenomenon. As Harold Morowitz suggested in his book The

need to redefine the rules and cope with the ongoing changes on the ground, in what can be
referred to as a type of dynamic planning. Indeed, as the world grows exponentially and as the net of technology exposes us to an ever

greater diet of human misery, the idea of the city and of building as a source of the most
fundamental forms of happiness is something we must return to again and again (Sorkin, 2000,
pg. xii) In truth, the need for the city to be a generator of wealth, and happiness, rather than a constant

Emergence of Everything, (2002) it is a force of the natural world that has created the universe
and all of the nuanced complexity therein. The notion of emergence, although ancient and all
encompassing, has only just recently (at least in the construct of human thought and western

reminder of being cast in a substandard social stratum is crucial to the healthy development of a
community and the well being of its inhabitants. In the case of Alexandra Park, the original attempt at creating physical complexity has been thwarted by a flawed simplification of other
factors, including housing policy, zoning regulations, and building use, as well as the apparent

scientific belief) begun to find a foothold as a leading model of understanding the cosmos in
which we live.

neglect of its connection to its surroundings and its place as a part of a the greater civic fabric.
By considering the lessons of emergence we gain a greater appreciation for the importance of the smallest variable, to the overall success of a community. When seen through the light of

Although the key elements of emergence, such as the holistic interdependency of an infinitely
complex universe, can be found in many human cultures, a valuation of emergence in western culture has been blocked by the oversimplification of variables intrinsic to the tradition of reductionist scientific methods. It has not been until the last 50 years that the scientific

complex systems theory, it is clear that much of the stagnancy found in Alexander Park can be
linked back to specific rules of engagement that have hampered the community's ability to

community, with help from the advanced computational powers of digital computing has begun to engage in the study of complex, multivariable systems.

change. Some of the rules discourage growth, are based on the community's standing as social housing. These include uniformity of use, restrictions on altering physical structure, and the lack of economic variability amongst inhabitants. Many of the issues fall into the realm of policy but
also can be attributed to the reinforcement, through built form, of a particular planning ideology. The problems of Alexander Park are especially clear in light of its favourable location, access to

With the aid of early computers, chaos theorist Edward Lorenz (discussed in Morowitz, 2002)
studied the complex nature of weather patterns and recognized that because of insufficient

knowledge of starting or boundary conditions, some results were rendered insolvable, meaning
that they were so complex that they could not be calculated by any known or imagined
computational device. The conceptualisation of unsolvable conditions lead to the early

amenities, and proximity to powerful flows of capital, which are prevalent in the success and
stability of surrounding neighbourhoods. Its immediate neighbour to the north, Kensington

establishment of was to become known as deterministic chaos.

Market, a vibrant and successful self-organized community, further reinforces the failings of Alexander Park to capitalize on intense energy flows surrounding the city's core. The

With the recognition that problems exist of sufficient complexity such that they have no
conceivable solution, the scientific community looked towards data pruning and probabilities to

substandard performance of the existing plan make Alexander Park an ideal staging ground for
the exploration of complexity, and the implementation of emergent practices.

attempt to gain a better understanding of solutions that reductionist science altogether

dismissed.

Batty (2007 pg.51) describes emergence is best described as a "process whereby unanticipated consequences arise from well defined rules... [and]... that emphasizes local action leading to global patterns whose form cannot be anticipated from a knowledge of the rules that govern the processes of change". Such a Process is essentially at odds with the principles of reductionist

Realignment currently underway in the world of creative design pits a conception of design, which by its very nature suggests the presence of deliberate action and control against an emergent theory which by definition is a process of insolubility and uncertainty. At the heart of this battle is the digital computer, which has allowed us to test ideas of emergence and opened
our eyes to new possibilities of holistic integration. With these newly opened eyes we are developing a design grammar that can describe a more

science because of its core principle that products of a system are often more than the sum of
their parts, and by their very nature resist any attempt at simplification. As advancements in computer technology have allowed us to delve deeper into more and more

accurate

definition

of our contemporary surroundings,

one that favours

integration

and

complex problems, the notion of emergence has "become one of the liveliest areas of research
in both science and philosophy ... which holds great promise for understanding a wide variety of phenomena in ways that are intriguingly different from more traditional approaches" (Bedau,
2008, pg. ix)

inclusiveness over segregation and fragmentation and moves to reconcile the rift that has been

created between people and their holistic place in nature. We should not claim that the computer holds all of the solutions to future problems of design, but it's very existence as an integral part of our society has undeniably lead us to the discovery of the importance of self organizing complex emergent systems and the set of communications which dictate their
behaviour.

Many contemporary fields of research including physics, psychology, and biology, have begun to embrace emergence as a basis from which to view both their respective fields and deep interactions with other fields of study. As an underlying methodology of thought, emergence has far more potential than any singular concept or theory, which suggests a paradigm shift in the
conceptualisation of the rules that govern the universe at its most basic level.
3.1.1 Organizations

3.1.2 Communications Instruction, feedback, and responsive action are the key ingredients a self-organising system

depends on to propel its growth and ensure its survival.

Many systems, such as flocking birds

or ant colonies, had stumped and amazed scientists for years because of their complex uniform
behaviour and their lack of any discernable leader. Steven Johnson explains in Emergence:

As with most other movements or philosophical constructs, architecture and design have begun
to look to emergence as a means not only of inspiration, but also of understanding. A new appreciation of interrelationship of numerous variables helps us formulate our place within a

The connected lives of ants, brains, cities, and software scientists were not able to solve the

puzzle of emergent systems because they had been blinded for many years by what is called
the "myth of the ant queen". (Johnson, 2001, pg. 29) Influenced by our own hierarchical top-down societal structure, past scientists were convinced

holistic vision of nature. Although there has long been a traditional understanding of the intricate complexities of our natural world and the place of man within it, complexity has been long dismissed by western science because of its apparent insolvability and tendency to resist simple
reduction. We may postulate that the re-emergence of holistic understanding may in part be

that there must always be alpha agents or leaders responsible for the organization and direction of the whole. It was not until the 1960's, with the rise of complexity and emergence theories, and the development of computational tools that help to prove such theories, that the truths of selforganizing systems were partially uncovered. As it turns out, it is the simple communication

attributed to electric technologies and the electrical language of binary code. Marshall McLuhan
argues in his book, Understanding Media: The extensions of Man, electric technology effectively works to tribalise on our society by extending the human nervous system and reconnecting humanity to a holistic worldview shared by our preliterate ancestors. (McLuhan, 1969)

between

system

agents

that

govern

the

organization

of the

systems

and

dictate

its

transformations. Very simple rule sets and feedback received from the continuous monitoring of changing conditions allow systems to achieve apparent intelligence even though they consist of
rather simple unintentional elements.

10

11

Extensive testing of these ideas with the help of computers and innovative programmers has strengthened the case and the believability of a theory that describes vast complexities

Traditionally feedback comes in two opposing forms, positive and negative, although their

names have less to do with their outcomes as their behaviours. Essentially, negative feedback
is a system that applies the opposite input to that which it is extracting from its environment. Negative feedback systems are used to achieve equilibrium, and react with opposition to

emerging from the simplest interaction of parts. Artificial systems such as John Conway's Game
of Life (Batty, 2007) and research conducted by scientists trying to understand the complex behaviour of ants give theorist and cognitive scientist Daniel C. Dennett reason to believe that the evolution of complex philosophical constructs, such as consciousness and free will, could have possibly developed from the relatively simple set of deterministic physical laws governing
our own universe. (Dennett, 2004)

changing conditions in order to bring back the system to a state of balance. On the other hand
positive feedback systems read their existing condition and respond in an additive manner increasing the amount of whatever it is that is propelling the dynamic growth of the system. A positive feedback loop is one that will continue to grow until the resources required to fuel its growth are exhausted, usually resulting in a sudden system collapse. Although it seams that positive feedback delivers negative results, while negative feedback

Key to the current shift in the fields of design and research is the recognition that digital processes and advanced computational techniques are now giving designers the ability to track and more importantly record vast amounts of complex interconnected contextual data, while providing a common language with which to explore vast numbers of interrelated variables. Binary code is to architectural design what advanced mathematics was to modern physics, a
common code which allows apparently disparate data sets to be unified. And as the digital

leads to stability and order, both feedback systems are essential and are often seen working
simultaneously when surveyed at a wider scale of interconnectedness. Materialist philosophers

have postulated that it is the dynamic growth of organizations on the verge of collapse that force the compositional elements to suddenly adapt in an effort to prolong their apparently imminent demise. Materialist philosopher Gilles Delueze, whose theories are grounded in a proposition of
difference, are adamant that true innovation and novelty are born on the fringes, in intensities

revolution quickly reprograms our way of thinking about the world, research and design are
being brought closer together. 3.1.3 Feedback

that are far from a state of equilibrium. (Delueze, 1992) Feedback systems have enormous potential for an architecture that has an intrinsic desire to be responsive and context sensitive. The inclusion of both positive and negative feedback into architecture at various stages of development would provide immeasurable benefits in terms of
efficiency and sensitivity to site-specific context.
3.1.4 Dialogue

Feedback is essential to the functioning of systemic holistic processes. It is the driver that allows
for a constant reading of, and the dynamic adaptation to, the changing conditions of the environment. In order for a complex system to become responsive it must rely on information it

gathers from the continual monitoring of its context, in essence a constant conversation
between a system agent, its surroundings, and other agents that share its habitat.

Norbert Wiener, The father of Cybernetics, the interdisciplinary study of the structure of regulatory systems, first postulated the importance of feedback, after he researched the relationship between control and feedback during the Second World War. (Johnson, 2001)
Wiener realised that the complexities of feedback would require intricate equations and an ability to process large amounts of data in order to be fully understood. It was this realisation

Dialogue implies an active form of communication because it exhibits a capacity to both transmit and receive information. Relying on systems of feedback, the notion of dialogue dictates that transmitted data must be adapted to inputs that have been received and understood. Systems incapable of dialogue are limited to broadcasting messages that are not necessarily relevant to
their current situation. Without the invaluable contribution of relevant information, a system

that would lead Wiener to become involved in the development of one of the world's first
modern computers. The development of the ENIAC, at the University of Pennsylvania's Moore School of Electrical Engineering in the 1940's, was in many minds the dawn of the digital era,

ability to produce emergent novelty is severely limited.

In a sense the biggest weakness many forms communication is its inability to allow for the facility of meaningful conversation. As unidirectional constructs construction documents, the endpoint of architectural production, are fundamentally flawed because they lack an integrated

and with it came an understanding and a means to explore the richness of many of science's
still unanswered questions.

12

13

method to react to changing site conditions. The inability of an instructional data set to be engaged in continuous dialogue with builders about the current state of the project inevitably
results in complication and conflict.

To Reynolds the motion of a flock of birds confronted him as a problem

simple in concept yet so visually complex it seems randomly arrayed and yet is magnificently synchronous. Perhaps most puzzling is the strong impression of intentional
centralized control. Yet all evidence indicates that flock motion must be merely the aggregate result of the actions of individual animals, each acting solely on the basis of its local perception of the world. (Reynolds, 2001, p.26)

One of the most promising aspects of digital fabrication processes is the use of the unified
language of binary code. The digitization of the manufacturing process allows it to communicate seamlessly with design processes that have been based in the digital realm for quite some time. Effectively digital design and CNC manufacturing processes are now speaking the same

language, which potentially allows for smother transition of the idea from the virtual space of
possibility to the substantiality of reality. Some firms have taken this notion of digital workflow to an entirely new level. Frank Gehry, one of the leading architects in the move towards a completely digitised work sphere, uses laser-positioning systems to identify and place each component of a building. As the components were brought on site they were scanned and registered by the 3d CATIA model, which was the onsite instruction for the entire process. (The
Economist,2008)

Reynolds set out to prove his hunch by developing the computer simulation BOIDS. Reynolds designed a model of interaction that relies on the simple behaviours of individuals to produce
complex yet organized group behaviour. The component behaviours are inherently nonlinear,

and mixing them gives the emergent group dynamics a chaotic aspect. At the same time, the negative feedback provided by the behavioural controllers tends to keep the group dynamics
ordered. The result is life-like group behaviour.

Coupled with feedback and a bottom up organization, ordered behaviour is a key property of
emergent systems, which display predictability on short time scales yet increasing

According to the website of the engineering firm Ove Arup, the in house software package
known as OASYS was developed for the analysis of a variety of building components that can

unpredictability as the systems progresses through time. This property, unique to complex systems, differentiates it from chaotic systems, which are highly unpredictable at all time scales. This behaviour that supports Christopher Langton's observation that life-like phenomena exist
poised at the edge of chaos. (Langton, 1990)

provide valuable feedback during earlier phases of the design. Integration of mechanical and geotechnical requirements, as well as simulation programs that can calculate wind loading and
other external influences are the first steps in the creation of a digital design environment that can facilitate the seamless flow of information through the ideal diagram of a building. Only

As our understanding of the overwhelming complexity of nature grows, we have begun to shift
our focus from object-oriented design towards the design and manipulation of systems. This creation and manipulation of the system is what may constitute what we call emergent design. In the post-digital age, how we design has become as important as what we design. Never before have there been so many, or so varied, techniques and methods at our disposal, each with the capacity to leap only previously imagined frontiers. Designing has become a

when the architect is capable of receiving and exploiting this valuable information can she
provided a truly optimised and integrated proposal. Digital workflows can play a critical role in the development of such a complex systems, by providing the opportunity to physically test and
interpret the vast amounts of complex design data.
3.1.5 Design

Emergent design may have found it's beginnings in the early ages of computer programming
with many programmers taking advantage of the computational power of early computers to try

liquid discipline pouring into domains that for centuries have been the sole possession of
others, such as mathematicians, neurologists, geneticists, artists and manufacturers.

and simulate life like behaviour. Programmers such as Mitch Resnick (as discussed in Johnson, 2001), exploring the emergent behaviour of slime mould, or Craig Reynolds (2001) simulating the flocking of birds, used simple rule based systems based on local interaction to shed light on
the mysteries of some rather interesting emergent behavioural systems.

Post-digital designers more often design by manipulation than by determinism, and what is designed has become more curious, intuitive, speculative and experimental. (Sheil,
2008, pg.7)

14

15

3.2 Digital Work Flow
Digital technologies are enabling a direct correlation between what can be designed and what can be built, thus bringing to the forefront the issue of the significance of

An example, which can be held as a model of future practice, is the Guggenheim Museum in Bilbao. By understanding and controlling the process of the building's production, as well as the complex relationship between design, fabrication and production, architect Frank Gehry was

able to deliver, what is commonly thought to be, the world's most complicated building within the
allotted time and budget, an accomplishment that is difficult for some architects to achieve on

Information, i.e. the issues of production, communication, application, and control of information in the building industry (Kolarevic, 2003, pg. v) Digital technology, including the use of computer numeric control devices have been used by

substantially less complex projects.

Gehry achieve this miraculous feat by abandoning most

traditional forms of construction in favour of modes of production that understand complexity as relational, and which have emerged out of the challenges of construction itself. described by Annette LeCuyer, the Guggenheim
was built without any tape measures. During fabrication, each structural component was

many industries as a way to explore the process of becoming, while architecture remains fixated
on the production of sets of representational instructions. In fact the idea of producing a 2D

In fact, as

drawing as a perquisite of constructing a building should be just as ridiculous as developing 2D
instructions sets to inform and coordinated the construction of an automobile. In reality a

bar coded and marked with the nodes of intersection with adjacent layers of structure. On site bar codes were swiped to reveal the coordinates of each piece in the CATIA model. Laser surveying equipment linked to CATIA enabled each piece to be precisely placed in its position as defined by the computer model." (Kolarevic, 2003, pg.38)
3.2.1 Collaboration

building is just as complex and demanding as a car, but cannot yet compare in terms of the
intricacy and efficiency of the systems that control its production. It is plausible to assume that because the automobile is a product of the electronic age it has a greater ability to react and
adapt to new systems of production that are free from the long established history associated

with the development of the built world. This reluctance to embrace new technologies is a painfully obvious proof that "many in the profession are finding it difficult to leave behind the security blanket of past working traditions." (Celento, 2005, pg.1) There are many reasons why the traditional methods of translating drawing information into onsite measurements in an attempt to locate building components has not been replaced by
more advanced "digitally-driven technologies, such as electronic surveying and laser

Sadly, relationships between architects and engineers and engineers and each other still tend away from the potentials of emergent organizations. All too familiar is the scenario where the architect designs an envelope based on a space program, and then passes it onto the structural and mechanical engineers. They collage-in their systems without
majorly altering that envelope, as if retrofitting. No one expects the other to sublimate the

positioning." (Kolarevic, 2003, pg.38) The most obvious of these reasons is that the large dollar

demands and behaviours of the systems of the other, or react to them generatively. The result is often a stratified, incoherent mess of infrastructural conflicts. (Wiscombe,2006,
p.3)

values associated with building make architects shy away from differing from the status quo,
while the most sinister cites contractors and development companies who rely on the inevitable

inconsistencies of the construction document to extort extras and deficiencies from clients and
subcontractors.

Originally computer aided design programs have concentrated on producing 2D drawings for the purpose of construction, but have had very little to do with the systems of design. CAD programmes have help increase the speed at which the documents can be edited and shared
with others, but until recently have not given the architect any additional information that could
potentially help with design, improve quality, or reduce the number of errors.

It is understandable that architecture is slower to move on technological advances than the automotive or aerospace industries. It is unfortunate however that reluctance to accept

technologies and production systems proven on some of the world's most complex buildings

would not be considered in an effort to make a more optimized construction process that uses
the lessons learned from holistic emergent systems.

As programming began to evolve and new more powerful computers were made accessible more complex modes of design development began to emerge. Advanced software packages

using building information modelling (BIM) can track a buildings material expenditure, giving real

16

17

time price feedback on decisions made by the architectural team. BIM models are also capable of integrating design information from various consultants, providing they are using the same software, to ensure that all of the building systems are represented in a single model affording the design team the opportunity to see conflicts at an early stage of development. Ideally, the integration of consultants has the potential of being much greater that the sum of their parts. Currently, many BIM programs are limited to a catalogue of available components.

their capacity to generate wildly fascinating forms. The explosion of speculative formal

architectural constructs was only made possible by the performative capabilities of the
computer.

Of course the reaction from most of the architectural field was one of scepticism. The idea that these forms could be built by conventional methods in the existing organisational structure of the construction industry was beyond belief. In fact the sceptics were probably right. The industry as it stood was totally incapable of dealing with such a high level of complexity at any reasonable cost. What wasn't completely apparent was that the construction industry was about
to change, because the intrigue developing from these seductive computer generated

The real excitement lies in the possibility of engaging specialists to develop methods of
integrating systems on a much more fundamental scale.
There is an influx in the variety and sophistication of forms being developed by architects. As

architecture explores the development of novel formal organizations, which have become possible with the help of advanced computational techniques, new insights into the realm of

environments was far too intense to subdue. At this point a shift had occurred and a number of architects went on the lookout for alternative systems of production that could satisfy their fanciful desire for complexity. They looked again outside the world of architecture to auto manufacturing and industrial design to find processes that could satisfy their intent. Computer numeric controlled manufacturing or CNC turned out to be a perfect fit because it too relied on binary code to deliver instruction to machine heads and robots. It was clear to the architects that a seamless flow of information between digital models and their physical manifestations would potentially be able to deal with any significant increase in complexity. Once the routines had been tested and the products delivered, numerous other
architects began a fundamental shift "from highly speculative designs shrouded in seductive

possibility begin to emerge. Until now this change in architecture has been mostly software
driven. As new software packages are inserted into the systems of design, new potentials are made visible, which are limited directly by the code and the inherent capabilities of the software.
Developments such as N.U.R.B.S geometry and parametric modelling have allowed for and

incredible amount of intricacy to be incorporated into architectural design although less attention has been paid to resolving how to get these unrestricted ideas into the real world. Although there are a number of potentially powerful applications available to the architect and
engineering fields, true innovation will not be realised until the various consultants can operate

with a high degree of collaboration, at a point in the design process which is free from the confines and limitations imposed on buildings by the inadequacies and conventions of current
construction documents. 3.2.2 Design practices, which includes the reliance on two dimension representational

glossy graphics of virtual and hypothetical space to highly specified architectural constructions invested with new systems and logics of shared communication, building processes and, of

course, forms foreign to architecture's canonical vocabulary." (Preston, 2008, pg.38)
The nature of architectural design has been forever altered; as the possibilities grow

exponentially the architect becomes more and more a synthesizer of data in search of material organizations that will lead to novel environmental effects, improved structural stability, or the

Contemporary design practice is being rescripted by digital technology. After advances in software engendered visualisation of new building form, followed by a mixture of
scepticism and enthusiasm from the public, designers and builders, architects forged

induction of a sudden emotion. Architectural innovation has been placed back into the realm of
design, giving designers a wealth of new possibilities to research and explore. Collaboration

with material specialist and engineers will become a standard method of practice, creating components and assemblies that are far outside the realm of preconception. The need to
explain design intent will be dissolved by the relentless free flow of information through fully

ahead to materialise speculative design. (Preston, 2008, pg.37)
Design was the first aspect of architecture to be effected by the tools of the digital age. Many forward thinking architects, such as Greg Lynn, (Preston 2008). appropriated software applications from Hollywood animation studios and the aerospace industry to test and exploit

integrated digital processes.

18

19

3.2.3 Fabrication Digital fabrication is a system that has emerged out of the synthesis of industrial production

Digital Fabrication has a strong potential to provide architecture with the means to explore new

possibilities of organization

and

customisation

while

remaining economically competitive.

techniques and the algorithmic qualities of digital computers. It is currently incorporated as a sub-system in many large-scale production processes and has obvious potentials for imbedding
itself into the process of constructing our built environment which is already heavily digitised.

Feature Factory, a Toronto based production house, attests to the notion that "by including and updating the details of all trades related to a project, contracts are simplified, confusion is eliminated and workflow is improved, reducing the number of change orders and extras and cutting costs." (Bowron, 2001, para 5)
3.2.4 Assembly

Digital fabrication had its commercial beginnings in the aerospace and automotive sectors. Renault was one of the first companies to use Computer Numeric Control (CNC) in the production of its automobiles as early as 1971. (Menges, 2005) CNC as well as other Computer
Aided Manufacturing (CAM) techniques have a large role to play in the future of building

As architects begin to think about the possibilities of digital fabrication earlier in the design process, concepts such mass customisation and differentiation among similar components work

systems and in the nature of the architectural profession. The incorporation of such systems will afford building construction the same advantages that other manufacturing industries have been capitalizing on for decades. The benefits of (CAM) include increased accuracy, efficiency, cost effectiveness, and the ability to manufacture more complex differential forms.
"Computer-aided manufacturing (CAM) processes are playing a critical role in a potential paradigm shift from mass production and its inherent standardisation, to the conception and

themselves into a more prominent position.

The strength of digital processes is their ability to

produce a wide range of variation without a large discrepancy in cost. For a computer that has
been properly instructed it makes little difference if components are identical as long as the parameters of production are clearly defined. An ability to produce variation without an

increased

cost allows for a much grater material

efficiency.

Components that can be

manufactured to optimise performance in relation to local demands need not to be sized in accordance to components with greater performance requirements. Differential optimisation

production of differentiated building elements and systems." (Menges, 2005, pg.71) The use of
digital fabrication techniques has had humble beginnings in the world of architecture but has, as of late, seen a substantial increase in use as costs have been reduced and the process of

across an entire building can potentially yield a greater material savings over the production of
equal yet underperforming components.

creating functional data sets has been simplified.

Many leading edge architectural companies

New forms of fabrication will inevitable lead to new forms of assembly. With larger components being digitally manufactured of site the necessity for complex work on site is reduced. In many cases components that are manufactured precisely in a controlled factory environment can be delivered ready to be installed directly on site. This type of assembly can considerably reduce

have begun to exploit the inherent potential of CAM and begun to incorporate it as an integral
part of the design process instead of a way to facilitate the realization of complex computer generated forms. Projects such as the Alliance Arena in Munich, by architects Herzog & de Meuron, (Menges,

the amount of onsite errors and reduce pressures on a building industry suffering from a lack of skilled trades. As with other digitised processes the components can be manufactured precisely
because the precise information of their geometry and their relationship to neighbouring

2005) use digital fabrication technologies to help create and construct complicated building systems. In fact, at any moment, there is a vast array of projects using computer controlled
production techniques to realize projects of ever increasing complexity. Many of the most

components has been figured out ahead of time in the digital incarnation of the project. Kieran and Timberlake Architects are proponents of prefabricated architecture, which they claim can help reduce cost and environmental impact of site work by moving most of assembly off site. They cite other successful industrial process, such as big shipbuilding and the automotive industry, as inspiration for a new type of architectural production that uses a component based methodology. Components take the complexity of assembly off site and into the factory where a

advanced contemporary buildings have taken advantage of digital fabrication techniques,
suggesting that digital fabrication is not only a viable option for use in the building industry, but an invaluable tool that will allow architects to react to ever increasing demands of complexity and specialization in their work.

20

21

greater control over quality is achievable giving the architect the opportunity to regain more

complexity is irreducible, so the aim is to transfer it down the production chain as
smoothly as possible. The design effort shifts from describing the overall geometry to creating and handling the information of production. For new and experimental practices,

design control. (Kieran, 2004) The assembly of architecture has been least effected by the recent changes in technology. In most cases it retains existing methods of information dissemination. The use of two dimensional
construction documents remains a staple of the building industry, where a tipping point has been reached as the complexity of projects continues to increase, in opposition to a declining

the impact of such work is clear: generating the parameters of digital production can be
accomplished post design, but incorporating them, as inputs to the design process will optimise experimental designs for economic production. Expertise in this area

availability of skilled labour. Construction companies are attempting to maintain their productivity with a movement towards modulation and component based construction, as the rest of society
is shifting towards the qualities of individuality and uniqueness. The reluctance to develop more

guarantees the material realisation of experimental designs." (Weinstock, 2008, pg.12) It has become abundantly clear that the control over the flow of design data will be the deciding

factor in the success or failure of future projects. Not only will new forms of production and
assembly change the way we build but also it will indefinitely change the way our communities and our society will be shaped. The effects of a more integrated construction process will have a

advanced systems of production is hampering society's ability to create architecture that is truly
in accordance with the way we live. In order to bring the construction industry closer in line with contemporary values a

fundamental effect on how we live and how we communicate with our surroundings. Increased communications can lead to more efficient material organisations, which will be the cornerstone
of a more sustainable way of life.

reinvestigation of their systems of production, using the tools of modern society and an ideology

of emergent systems, may generate the possibility for truly novel works that are in sync with
contemporary thought. 3.2.5 Continuity As digital technology continues to form key linkages between the ideation process and the reality of production, alternate forms of practice in the design disciplines emerge ... transforming traditional modes of representing ideas into materials that further inform methods of making. As questions that relate to surface, interface and performance begin to emerge in relation to this digital exchange, it is undetermined which principles will

If we are observant and

proactive when dealing with the changes brought on

by the

digitalisation of our systems of production than we have to opportunity to guide the process to a reality that will be most beneficial to all. The challenges faced by our culture concerning the scarcity of energy and the overwhelming pressures that our exponentially expanding population
is placing on our limited resources and our ecosystem, can be best addressed by achieving greater material efficiency in base level production systems.

The emergence of more effective and sustainable modes of production must be developed from the bottom up because the realities of our modern world are far too complex to be understood
and controlled using a top down hierarchical model.

exactly govern the development of the digital model, (Jabi, 2007, pg.1)
Designtoproduction, a company founded by ETH computer scientist Fabian Scheurer and architects Christoph Schindler and Arnold Walz, finds its niche in a part of the discipline that a

decade ago simply did not exist. They are mediators, facilitating the flow of information between
architects, engineers and fabricators. The company is founded on the understanding that all architectural forms are constructed from

components that have to be created from standard materials that are usually supplied as either straight beams or flat sheets. Even 'formless' materials, such as concrete, require formwork that has to be built up from standard materials. All non-standard or

experimental forms require an enormous amount of information to describe them. The

22

23

lu-

r

4 Literature Review

The world around us is in state of constant flux, growth and continual change is the standard in

a world where every fleeting moment is witness to an innumerable multitude of interactions.
Amongst this swirling milieu of complex interactions we have establish the groundwork for a

new way of seeing the incredibly nuanced world we inhabit. Although these interactions have
been present since the beginning of time itself, the new philosophy of complex emergent systems can be considered relatively new. It is the computer and its immense calculating

prowess that have made the testing of such theories conceivable and executable. From the first incarnations of Alan Turing's calculating machine (Johnson, 2001), understanding and control of increasingly complex systems has begun to shift our societies reliance on top down, hierarchical systems in favour of bottom up emergent organisations. In his book, Emergence: The

connected life of ants, brains, cities, and software, Steven Johnson (2001) describes the emergence of complexity theory and speculates on how the use of emergent systems can alter
the processes of our every day existence. Johnson explores how emergence manifests itself in natural systems, such as ant colonies and bird flocks, and connects our new understanding of these systems to advances in science and technology that take advantage of bottom up planning. A systemic approach to design has been the substance of the argument established by theorist Sanford Kwinter. (2007) Kwinter is a steadfast proponent of system design and declares that
any valuable contribution to contemporary architecture must be based in the interconnected

world of infrastructure. The days of pretty pictures and instant visual gratification are coming to an end, and are to be replaced by the intervention of the soft hacker who deals with and manipulates the substance of the grid itself. (Kwinter, 2007) System manipulation as a form of contemporary design is a proposal that aligns itself with commentary from other emergence theorist's including Johnson (2007) who cites new approaches to software programming

developed by games creators such as Will Wright (SIMCITY) and Craig Reynolds (BOIDS) as examples for new possibilities in the fields of science and design. Add to BOIDS

Manual De Landa, another materialist and accomplice of Kwinter's, is also a proponent of
complexity and chaos. Through his book, A Thousand Years of Nonlinear History, De Landa (1997) sheds new light on our common history by re-examining the past millennium through the lens of nonlinearity and self-emergent systems. The revised story that De Landa stitches of our immensely interwoven past, helps lay the groundwork for a greater understanding of the

25

interconnected structure of our society that provides new practitioners a framework in which to
interject their subtle manipulations. Through the exploration of cities, languages, and human

T~
a

teething phase for a paradigm shift towards a systemic approach that will make important
architecture more about integration than aesthetics.

biology, De Landa spins an intricate web of connectivity between the factors, which drive the
evolution of theses three fundamentals of our existence.

The architectural world is beginning to be filled with adamant researches intentioned on creating
setting of seamless integration. As Achim Menges (2005) illustrates in his report,

In the architectural context, Stephen Kieran and James Timberlake are proponents of a systems
approach to architectural production using manufacturing methodologies that are based upon

Manufacturing Complexity, there is an exponential rise in the effectiveness and efficiency of
design and manufacturing when both are controlled under the common language of digital code.

models developed by the automobile and airline industries. Their book entitled Prefabricating
Architecture in a scathing critic of the current practice of building, and a warning to architects

Digital fabrication has emerged out of the synthesis of industrial production techniques and the algorithmic capabilities of digital computers. Digital technologies are currently incorporated as sub-systems in many large-scale production processes and have obvious potentials for imbedding itself into the process of constructing our built environment which is already heavily
digitized. (Menges 2005)

that they evolve their practice or parish. The concepts of Kieran and Timberlake delve deeply into systemic design and the deployment of integrated systems methodology in order to
enhance the efficiency of architectural production, but also trivialize the social and cultural impact of building in comparison to that of automobile or aeroplane manufacturing. Attention to scale develops an intelligent intuition that can help to identify at which scales we should be operate. What is a building but a component of a greater infrastructural system, a

As architects begin to think about the possibilities of digital fabrication earlier in the design
process concepts such mass customisation and differentiation of similar components become

increasingly more feasible. The strength of these processes lies in their ability to produce a wide range of variation without a large discrepancy in cost. For a computer that is properly instructed

city, a government, or a religion? At which scale can we effectively induce change? Should we
operate at a grand scale suggesting sweeping changes to longstanding traditions or are our

it makes very little difference if components are identically different as long as the parameters of
production are clearly defined. An ability to produce variation without cost increase will allow

efforts more fruitful by interjecting a focused proposition at a lower level of influence? These are some of the question that are raised when considering the effect that digital technologies,
coupled with emergent systems, will have on the greater social practice of building. Marshall McLuhan gives us ample warning of the changes that are imitate once our society

production to achieve a much grater material efficiency. When components must be made identical to other like elements regardless of performance requirements, the opportunity for
optimisation and material efficiency is greatly diminished. The implementation of mass

wholly embraces the invention of electronic technology, and by connecting past shifts in human understanding with progressions in tool making, he has drawn a direct correlation between the
tools we chose to use and resultant structuring of our civilisations. McLuhan's suggestion that

optimisation across an entire building can potentially yield a greater savings than the production of equal yet underperforming components ever could. With the achievement of cost equality, variation and difference can be employed to explore a higher degree of architectural complexity

the nature of humanity is defined exclusively by its tools, reinforces his insistence that the human race was first established when we first employed the assistance of our technological
extensions. The underline theme of McLuhan's text Understanding Media: The Extensions of

in the service of other more important, including the social issues that have arisen from the
economically driven uses of uniformity.

However, in order for such a system to truly be optimised, processes of production would have

Man (1964), advocates that the advent of electricity is a event so significant that it will make the industrial revolution look like a mechanical hiccup between the great human epochs of biology
and electricity.

to be matured Enough to incorporate many variables, including construction, material
performance, and site specificity and more. Creating feedback loops that are capable of continuously informing the design, increases opportunity for optimisation, relies on a high
degree of digital integration from conception to completion.

So how will digital technology really affect the way we build? Many leading theorist, including
the aforementioned De Landa (1997) and Kwinter (2008) would insinuate that the vast orgy of digital gymnastics that have occupied architectural thought for the last two decades is merely a

If architecture is to fully engage the potential of emergence into a fully integrated digital
workflow, it must first develop an understanding of the intricacies of the production systems,

26

27

establishing a vocabulary that will allow it to operate on the structure of the system itself.
Innovation, it is clear, can no longer be left to chance but must be rigorously developed and

r

between the inherited taxonomy of pure disciplines in the sciences has yet to find a full
counterpart in the world of architecture." (Weinstock, 2005, pg.12) The approaches to design research found in Morpo-Ecologies attempt to explore new relational structures that take into
account various disciplinary models, and are focused on the convergence of "architecture, industrial design, biology, and computational science. Understanding ecology, the study of the relationship between organisms and their environment,

strategically sought after through every stage of architectures entire process of becoming. As architects are coming to grips with new models thinking about design our repertoire grows more dependent on fields of knowledge outside of our own. Michael Hensel, one of the founding members of the Emergent Design Group is developing a model of thought and architectural production he calls Morpho->-Ecologies (ME). Hensel claims that ME "is an ongoing project that requires a critical rethinking of all central aspects of architectural practice today." (Hensel, 2006,

is especially pertinent to the discipline of architecture, and when combined with the materiality of industrial design, and the performance simulating and generating prowess of computational
science can yield an architecture that better addresses the true nature of the contemporary
social dynamic and will lead to a more socially dynamic architecture.

pg.13)

One of which, is how architects address a rapidly changing society in a way that is

appropriate and sensitive to the type of "existing realities" and "complex relationships that exist
all around us:" (Hensel, 2006, pg.13)

Hensel and co. profess that the ME approach to architecture works to break down traditional
conceptions of architecture and space by working in a "new framework for architectural design that is firmly rooted within the biological paradigm and thus concerned with issues of higher

The ME methodology explores, through architectural research, the interrelations of many existing systems in order to reinterpret but not depart from the type of work architects have always done. Architects as a means of justification have always attempted to understand and

level functionality and performance capacity."(Hensel, 2006, p. 19) Although not all the realms of
study are address by the projects found in Morpho-ecologies they operate in much the same way that a contemporary architectural practitioner should operate, and in the sprit of ecologies is

project

future

social

conditions,

which

currently

include

every

increasing

professional

specialisation.

As the relationships around us become increasingly more complex, and the altering power of telecommunication accelerates our level of interaction and intimacy, the spectre of

involved in processes of natural selection where instances or moments of usefulness should be
combined and multiplied, while deficiencies are left to re-emerge in new configurations. This

specialization shifts to one of opportunity.

People will continue to divest further and further into

acquisition and elimination of unwanted results operates in much the same way as the role of

specialized roles, however they will cease to be focused on specialized outputs, but instead could opportunistically apply their knowledge to any project that can integrate their ideas.

design intelligence outlined by Michael Speaks, which through research can provided a way of
defining plausible truths and seeking opportunities for innovation that cannot be predicted by a
theory or concept. (Speaks, 2006)

This indicates that architecture should position itself as a collaborative enterprise that is a image of the non-hierarchical systems that structure our current society, and are willing to invest our unique knowledge and skills into any project that could benefit from our expertise, rather than trying to assume the roll of master controller in order to exercise a kind of oxymoronically phrased collaborative control (Kieran, 2005) over the vast energized milieu of design

A new model for design could potentially be more akin to systems of emergence, in which outcomes cannot be foreseen, and where control over the process can be considered a
hindrance rather than help.

"Science knows this; industry is learning. Architecture is just beginning to engage the concept."
(Wiscombe 2006, pg.1)

intelligence.

The Emergent Design group views interdisciplinary work as central to the evolution of the architectural profession, and suggest that architecture should follow the lead of biology, which

Many promising architectural practices are keen on the power of emergence systems to enhance their productivity and relevance in a world starving for efficient and integrated design
solutions.

has co-opted many formerly distinct disciplines in a series of exchanges between chemists, mathematicians and physicists. They also claim that the "erosion of the rigid boundaries

28

29

Tom Wiscombe believes passionately about the importance of emergent system theory and

materially efficient solution, an important discovery for a world grappling with the stresses of
limited natural resources.

uses it as the theoretical and practical nucleus of his work. His firm Emergent Architecture believes in a methodology steeped in collaboration and the idea in the that "innovation, whether scientific, technological, or architectural, which is a by-product of artistic chance or a result of singular genius can no longer be sustained in the 21st century" (Wiscombe 2006, pg.1) Instead Wiscombe cites dynamic evolutionary forces, such as multiplicity and feedback as the real generators of innovation. The case for more integrated bottom up processes is empowered by

The development of tools and systems of production are entering a phase that can be likened to
a digital pre Cambrian explosion, with many new possibilities evolving on a daily basis. The unified language of binary code is allowing ideas and processes that at one time could be seen as separate and distinct to synthesise into new novel organisations. "Each of these new techniques vies for dominance in the competitive world of advanced

Wiscombe's argument and prediction of architecture's imminent incorporation of systems of
complexity.

tooling. They battle to outdo one another, predict the unpredictable, promise the unattainable, materialise the immaterial, solve all our problems, and so dazzle the beholder that all previous paths to architectural wonderment pale into the archives."
(Sheil, 2008, pg.7)

Another important proponent of a systems approach to the production of architecture is Fabian

Scheurer who through his post at the ETH Zurich is exploring the topic in a slightly different
manner. Scheurer is exploring the connection between the virtual and physical world and how

digital technologies can be coupled with the real world application to produce novel architectural
effects.

It is in the design of systems of architectural production that bottom up thinking and systems
planning will find its most significant impact on architecture and design in the years to come.

The auxiliary building at the Gantenbeim Winery in Switzerland, design in collaboration with
Bearth & Deplaze Architects is an example of the powerful effects that can be created through the manipulation of the system of production through the insertion of digital technologies. Working with robotic CNC production systems, the team at the ETH in Zurich is heavily vested in the capabilities of robotic labour and has shown with the pavilion for the Gantenbeim vineyard

The fluidity of digital workflow and the integration of ever increasing fields of knowledge will
significantly impact the way in which we approach the problems of design. Top down planning, and creative intuition will not be made extinct by the invasion of a bottom up approach, but the

synthesis of the two can potentially give us a broader understanding of the relationships created by increasingly sensitive architectural interventions. Put into perspective the repertoire of new
techniques will give us a broader range of tools that architects and designers can use in their quest to developed increasingly more sophisticated and integrated solutions to the challenges
our times.

the staunch effectiveness and the sensual qualities of a production process not hampered by
the confines of geometric complexity. The key to the project lies in the realization of how a new technology can be placed in an existing building tradition to create an effect that is by all means
more than the sum of its parts.

"It should be the immediate duty of architects to accept and understand the incredibly high degree of interactivity between the various aspects of our society and work to identify the role our work will play in an increasing complex world. Only with a strong focus on

A second and equally powerful example of Scheurer's work can be found in Northern Holland, in
the city of Groningen. In Groningen Scheurer consulted KCAP architects to create a colonnade

that was meant to replicate the natural efficiency of a forest ecosystem. The concept of the
building as an ecosystem lead Scheurer to design a complex adaptive system, which uses swarm logic and cellular automata theory to define the ideal placement of each column within its
habitat.

collaboration with other disciplines can we truly understand the potential effects of the innumerable number of interrelations that shape our existence. As Mark Wigley rightly explains, architects should shift their focus by trying to locate, identify, and maybe to interfere with the architecture of the systems that actually provide the spaces in which we live, systems that definitely do operate at the scale of the cosmos." (Wigley, 2004)

As in most self organized systems the ecosystem created by Scheurer uses simple predefined
rules to guide the growth of the system in a way that stable end states will return the most

30

31

5 Precedents

33

parametrically variable building components to meet the challenges of highly individualized
architectural responses. A major obstacle to the wide spread implementation of CAM processes
5.1 City Balcony
Date: 2007

in architecture remains a requirement for precise production data, which is capable of defining the exact location, orientation and geometry of the structurally and functionally interdependent
components. (Scheurer, 2005) This shifts the complexity of building from the production phase

Location: Groningen, The Netherlands

to the design phase. Scheurer, dedicated to making virtual processes that have real life material contributions, devised an agent based simulation program that was able to incorporate all
necessary performative attributes required buy the project. Noting that the creation of any agent
Image. 5.1 City Balcony

Project Team: KCAP Architects, Fabian Scheurer

based simulation must strive to define how an agents emerging behaviour fulfils the given task,

The architectural firm KCAP, based in Rotterdam, was commissioned to create a new setting for the recently renovated 19th century main railway station located in the city centre. The concept was based around the notion of a city balcony, a place where travelers and pedestrians could pause and absorb a view of the city from its main gateway. The city balcony would also double as a bike park for up to 4,000 bicycles, with a series of ramps and perforation to create both

Scheurer designed a solution which tried to keep the rules of engagement as simple as possible
while resisting any preconceived notion of what the outcome should be. The system conceived the columns as agents who were member of a specific ecosystem or

habitat of which the structural slab defined the boundaries. The environment as well as many of the other members of the systems, such as bike racks and pathways also had a affect on the growth and placement of the columns. The columns exert an evolutionary pressure on their
neighbours that is based on their carrying capacity, which is a resultant of their diameter and the

physical and visual connections. KCAP decided that the rather large deck of the balcony was to
be supported by what could be described as a forest of columns. Randomization of location,

diameter, and inclination was desired to create a convincing notion of trees, but mostly to increase the lightness of the deck by removing the rigidity and predictability of a regular column grid. The architectural team, Lead by Kees Chistiaanse then enlisted the help of the chair of
CAAD at the ETH Zurich, Fabian Scheurer to devise a process that could define the optimal pattern of columns, while abiding to the following requirements. (Scheurer, 2005) Â· No column should obstruct a predefined walking or cycling path. Â· The diameter of each column had to be sufficient for the portion of the slab it was holding up- depending on the distance to its neighbouring columns.

relationship to their neighbours. As pressure from competing neighbours increases the column
decreases in size until it can no longer survive. The process continues until the system can achieve a stable state, which meets all the necessary requirements initially determined. A

parametric system such as this provides a dynamic and efficient solution to irregular spatial structures that are wonderfully complex and capable of being more materially efficient than their
more static regular counterparts. Each iteration of the project has the possibility of encoding a

virtual genome that may be recorded and compared, to aid in selection based on a measure of
fitness. (Scheurer, 2005p.2XX)
Â·hr.nk.ng

Â· The distance of the columns had to be aligned with the spanning and cantilevering
capacity of the slab.

Â· The number of columns and their diameter should be minimized, saving costs.

Scheurer set off to design a complex adaptive system, which uses swarm logic and cellular
automata theory to define the ideal placement of each column within its habitat.

The rise of irregular spatial structures is an emerging trend in contemporary architecture. Using advanced computational techniques architects are exploring formal and material organizations
that have made a clear brake from the machine aesthetic of the modern era. The development

Fig. 5.1 Rule Definition

of computer aided manufacturing techniques has made it economically feasible to produce

34

35

5.2 Loblolly House
Date: 2006

This house on Chesapeake Bay, although focused on minimal impact on its site, is really a commentary on the way we build and the impact that embracing a newly integrated

methodology of construction may have on a much grater scale of production. Kieran and Timberlake are key proponents of prefabricated architecture as a means to make building a more efficient and sustainable practice. Although the idea of prefabricated homes has been

Location: Taylor's Island, Maryland
Project Team: Kieran Timberlake

around for many years, the idea has not managed to shed its reputation as less solid and
Image. 5.2 Loblolly House reliable than in situ construction.

Named for the loblolly pines that frame the approach to the single family dwelling, the Loblolly house stands for a message and philosophy that places architecture as an elemental part of
nature. Architects Kieran and Timberlake purpose that using prefabricated building techniques

However, Kieran and Timberlake would like to change the negative impression of prefabricated dwellings, by citing the benefits of other high level manufacturing process such as automobile or aeroplane production. Through a detailed explanation of production methodologies the pair attempt to show that efficiencies inherent to the controlled factory assembly of artefacts as complex as a car or plane can provide the building industry with a higher quality more efficient
model for construction.

can create a more efficient and sustainable architecture, which is fabricated off site minimizing
the impact caused by onsite construction activity.

The Loblolly house incorporates many of the ideas expressed by the architects in their book Refabricating Architecture (2004). The project is conceived as a compilation of elements that
are categorized by scale and unified to create a harmonic whole. Starting with the scaffold, the
An integrated systems approach is proposed as a way to gain a greater efficiency in building

construction, and as with the ship building industry, buildings could be sub divided in to various packets that would then be combined at ever increasing scales to form the entire building
assembly. The logic of such an approach removes the complexity encountered when dealing

structural base onto which all of the other prefabricated elements will be bound, the building
being mostly manufactured in factories will only require six weeks of on site construction. Each of the elements once completed will be shipped to site and craned into place. Sandwiches, the first element to arrive on site once the scaffold is in place, are completed floor, roof, or ceiling assemblies which integrate a variety of systems internal systems such as radiant floor heating, ducts or wiring. Spatial units are complex systems within the house such as a kitchen or bathroom and are also shipped to site entirely prefabricated. Other units follow such as closest, built-ins, furniture with very little postproduction necessary for the house to be ready
for occupation.

with the

immense amount of components

required

in

modern

construction.

Instead

all

components would be grouped into different divisions allowing packets consisting of a smaller
amount of components to be assembled by a single hand. This would insure that a higher level of detail and quality could be achieved by placing the responsibility on a single party. It is also evident to both Timberlake and Kieran that a production process that uses

prefabricated components could also be more responsive, translating into quicker construction

times, because various packets are being manufactured simultaneously or possibly stockpiled
for immediate use.

Advances in digital technologies and novel fabrication techniques have recently stabilized

prefabricated architecture's long and often turbulent history. New design and advanced 3D
modelling tools are allowing architects to constantly test and debug proposals in a real time virtual environment. Modelling can eliminate many of the incompatibility issues before hand and allows for a reliable method for creating custom components that have been sorely missed in
Image. 5.3 Loblolly House prefabricated homes of the past.

36

37

5.3 Wein Gantenbeim
Date: 2007 Located in: Bern, Switzerland

reduced cost of computer aided manufacturing (CAM) operations have proved extremely valuable to architects looking to explore spatial complexity in their work.

Project Team: Bearth & Deplaze, ETH Zurich

Image. 5.4 Wein Gantenbeim

A product of architectural research being conducted at the ETH in Zurich, the digitally design and fabricated masonry assembly is an exploration in the realm of Computer aided

manufacturing, with focus on the unmatchable accuracy of robotic assembly. The production
system developed takes advantage of the seamless flow of digital information from inception to

completion allowing the construction of complex geometries that would be unobtainable using
human labour.

Image. 5.5 ROB in Venice

Processes

involving

additive fabrication

are the

most

complex

and

involve

the

largest

An auxiliary service and entertainment structure built for the Gantenbeim family vineyard, the building uses techniques developed at the ETH and was completed as a collaboration between
Bearth & Deplaze architects, the students and faculty at the ETH's Computer Aided

investment, because they deal with the actual systems behind materialisation and assembly of the building. However, it is this same rewiring of the systems of construction that allows this process to be so highly rewarding The team at the ETH in Zurich is heavily vested in the capabilities of robotic labour and shown with the auxiliary pavilion for the Gantenbeim vineyard the staunch effectiveness and the sensual qualities of a production process not hampered by

Architectural Design (CAAD) program, and the masonry association in Switzerland. The complex undulating geometry of the brick facade was devised using 3D modelling software

the confines of geometric complexity. One of the most promising aspects of digital fabrication is
that it uses the unified language of binary code. The digitization of the manufacturing process

that was optimized then translated into digital script that the robotic mason then used to define
the exact location an inclination of every brick. The subtle manipulation of angles creates fascinating lighting and spatial effects that are difficult to achieve using conventional methods. A further development of the production system was on display at this year's architectural

allows it to communicate seamlessly with a design process that has been working in the digital realm for quite some time now. Effectively the two processes are now speaking the same language allowing for a smother transition of the idea from the virtual space of possibility to the
substantiality of reality.

biennale in Venice, as the robot became mobile and constructed the entire exhibit on site. The
end result was astonishing, yet what was more impressive was the fact that the entire exhibition was shipped in one cargo container. The complexity and ingenuity is in the system of production itself and the expression is achieved using a material with which Venice is quite familiar with. Digital Fabrication has become a major point of interest for the architectural field. The accuracy

and variability achievable through the use of Computer Numeric Control (CNC) devices such as
laser cutters and milling machines makes accessible a richness of architectural expression that has not been obtainable for quite some time. The increased use of digital design tools and the

38

39

5.4 Game of Life
Date: 1970
Published in: Scientific America

1. Any live cell with fewer than two live neighbours dies, as if by loneliness. 2. Any live cell with more than three live neighbours dies, as if by overcrowding. 3. Any dead cell with exactly three live neighbours comes to life by reproduction

4. Any live cell with two or three live neighbours lives unchanged, to the next generation.
Loneliness

Project Team: John H. Conway Image. 5.6 Game of Life Exhibit

Overcrowding

Reproduction

Stasis

The game of life is a mathematical construct devised by the British mathematician John Horton Conway in 1970 in a response to the renowned mathematician and Manhattan Project participant John von Neumann's conjectures about the viability of self-replicating machines. In a BBC documentary Conway explains that the game as in life is proof that great complexity can
State 1

u 

DUU
State 2

be derived from a relatively simple set of rules. Although not a game in the traditional sense, for
its lack of any players, the game of life uses a set of simple rules to extrapolate an initial state

pi

n


Fig. 5.2 Rules of the Game

into an infinite number of complex outcomes. The playing is done in the design of the initial seed
configuration that may lead to many different stable organizations. The game of life has been a

rallying cry for complexity theorists, because it so effortlessly is able to exhibit emergent and
self-organizing principles. Life generated incredible interest from a vast numbers of different scientific fields and was praised by Martin Gardner, who first published the work in his column in
Scientific America, by stating that the game itself had the characteristics of a Turing Machine

Although Conway did not invent the notion of the cellular automaton, his game gained a cult
following that would invest an immense effort in devising different initial states that would lead to self replication, oscillating, or stable state behaviour, A vast library of significant initial states has

been developed, with names such as the glider or Gosper's Gun defining the characteristics of
discovered initial states. This notoriety coupled with emerging interest in chaos and complexity

and is capable to compute anything that can be calculated using algebra. (Gardner, 1970) Conway's discovery is also accredited with the generation of a new field of mathematics based on cellular automata, or self replicating complexity systems, and is a model for many who
theorize that all of what we know as life is itself generated from low level interaction of discrete elements resulting in every greater complexity. The games appropriation of the title Life speaks volumes about the immense power locked within the game's simple rule set, and hints at underlying notions and theories of how the great complexity of our world emerged. From flocking birds to the spontaneous development of life from particularly basic building blocks, the game stands as a testament to the dynamic nature of the complex world of interactions that is driven by small-scale bottom up processes. The Game of Life uses cellular automata theory and a simple set of 4 basic rules to define a system that is capable of exhibiting complex behaviour. Each cell surveys its neighbours; the eight cells surrounding it and reacts to the rules to establish its value in the next cycle. The rules to the game are as follows, requiring the player to
make one move, the selection of the initial pattern.

theories, lead to a wider interest in automata and is why many credit Conway as one of the
founding fathers of cellular automata. In fact Conway devised his game in response to a ideas
generated in the early fifties by the great mathematician John von Neumann who also was

interested in automata studying the link between self replicating biological systems and new
advances in computer technologies. (Wolfram)

The most fascinating aspect of the Game of Life is its ability to count. By virtue of this ability the

game is capable of constructing logic gates such as AND, OR and NOT, making it an ideal
Turning Machine and unlimited computational power and memory. It is also capable of creating

patters that can reproduce, even creating copies of themselves, solving von Neumans' notion of
the universal constructor. Most interesting however is the game's knack for answering questions

as philosopher and cognitive scientist Daniel C. Dennett believes about the possible evolution of complex philosophical constructs, such as consciousness and free will, from the relatively
simple set of deterministic physical laws governing our own universe. (Dennett 2004)

40

41

5.5 Spore _ Life Simulation
Date: 2008 Publisher: Electronic Arts / MAXIS

mathematical field of fractal geometry. Procedural generation has proven to be extremely useful
to video game designers, as well as to artist and musicians such as Brian Eno who has explored the effects of randomness and procedure while creating his own brand of generative
music.

Project Team: Will Wright (designer), Brian Eno (composer) Image. 5.7 Unique World

Computers are a natural tool form the logic embedded procedural generation, in light of their uncanny computational prowess, and programmers have been quick to exploit it as a tool to
reduce the demands on the processing and memory capacity of their machines. Released in

Designed by the creator of SimCity, Will Wright, Spore is his latest example of the genuine
novelty that emergent theory can bring to the gaming industry. The game is based around the

1984, Elite is the gaming industry's first examples of true procedural generation, designers Ian Bell and David Braben used a truncated Fibonacci sequence to generate the entirety of each

player's development of a single cell organism from the moment it emerges from the primordial ooze, through to the technological advancements necessary for interstellar exploration. As in SimCity the use of emergent systems protocol, such as procedural generation, brings a high level of complexity and uniqueness to the game. The procedural rule structure allows for the
creation of a limitless number of characters and worlds which are all generated in reaction to inputs and decisions made by the player. The game also takes advantage of a huge online database, which is built up by a vast network of networked players. Although players don't directly play against one another everyone's universe is populated by characters and worlds created by other's making any interaction completely dependent on the characteristics defined by other online players. Essentially all of the worlds or characters found in Spore are created by the players and not predetermined by the designers, making the spore universe an ever
expanding and infinite cosmos. Brian Eno, an artist famous among other things for his generative music, designed the
I

player's universe. The procedural algorithm was an invention of necessity, which allowed the game creators to introduce great variety into the game from a single seed code without using up valuable data storage space, which was extremely limited in early gaming systems. Not only
was the algorithm capable of determining each planet's unique composition, it's position in the

galaxy, the prices of commodities, and even name and local details, it was capable of creating
an astonishing number of galaxies and planets to fill each cosmos. The designs were able to create, from a single source code a universe with 282,000,000,000,000 distinct galaxies.

* o

4V

procedurally generated music for Spore. The music is effected by the editors depending on

-M

.Â·**

r. r
Image. 5.8 Unlimited Variation

which parts limbs, battle items, are placed on the creature, vehicle or building. For example, something dangerous like a battle spike will give the music more of a ferocious feel, while something peaceful like a herbivore's mouth will give the music a more relaxed feel. Users can also create music in the form of a short national anthem for their civilization or empire, (excerpt from Game Trailers, 2008) Procedural generation is a computational function that is defined by infinite growth and random or pseudo-random characteristics. The Fibonacci sequence is an early mathematical descriptive of procedural generation as it relies on the products of its own function to propel its infinite growth. A dramatic example of procedural generation can be found in the in the growing

Spore extensively uses procedural generation, rather than individual objects. Wright mentioned
in an interview given at E3 2006 that the information necessary to generate an entire creature

would be only a couple of kilobytes, according to Wright, who presented the following analogy: "think of it as sharing the DNA template of a creature while the game, like a womb, builds the

'phenotypes' of the animal, which represent a few megabytes of texturing, animation, etc."
(Kasavin, 2006, para 3)

42

43

5.6 Photosynth
Date: 2008
Publisher: Microsoft Corp

photographs as opposed to text tags that other engines such as Google use to find images. As
the program amasses a larger sampling of images it is capable of achieving an ever-greater

accuracy

calculating

the

positions

of detailed

components

of an

image.

The

program

establishes the 3D positions of the source and the target of the image and using that data creates a three dimensional point cloud of the objects in the image. Object with very large

Project Team: Blaise Aguera y Areas, Noah Snavely, Steve Seitz, Richard Szeliski Released in its full version by Microsoft in 2008 Photosynth is itself a merger of two recent innovations in computer programming. The three dimensional computational intelligence of
Noah Snaveiy's Virtual Tourist when combined with the blazing speed and depth of information

images samples have incredibly detailed 3d models that are made up entirely of points.

afforded by Blaise Aguera y Areas' Seadragon have created a new interactive experience that
some have suggested is an entirely new visual medium.

The system uses algorithms, which are based on the model of human sight and our ability to perceive depth. However in comparison Photosynth is at a disadvantage because it is never

100% sure the exact position of the source of two different images, a luxury our brain has
because in knows the exact position of our eyes. The algorithms in Photosynth however must

use other subtle hints imbedded in the image data, such as projective angles, that help the program calculate location and depth. In the end the key to the precision and the success of the program comes down to the quantity of images that it is able to assemble and coordinated.
The second part of the Photosynth equation is the image-viewing program known as
Image. 5.9 Photosynth Point Construction Image 5.10 Designer Aguera y Areas

Aside from the impressive technical aspects of Photosynth the most interesting and emergent

Seadragon. Capable of displaying vast amounts of image data seamlessly Seadragon plays a

qualities of the program are social in nature. The inclusive nature of the program allows everyone to make a contribution and is dependent on an every widening base of data to expand the detail of the worlds available to view. The program is effectively a tool that grows in complexity and increases its capacity and benefit as more people use it. Not only will people be able to uses their own images to access a wider collections of images but could also have access to metadata that could be tagged to other images that have been posted by others online. So not only do you have a record of the images, and a 3D model of the site but data and informative knowledge about the object linked through the visual data of the image. Co-creator Blaise Aguera y Areas describes the work as a "cross modal, cross user social experience with

crucial role in displaying the content consolidated by Photosynth making it available at speeds
limited by online communications. Seadragon works on the premise that the speed is only limited by the amount of pixels displayed on the screen at any one time. For this reason the

program is not limited by the size of any images and is capable of embedding levels of
information within images that was not possible before.

Virtual tourist, the heart of the Photosynth program, works on two distinct yet equally important aspects of photo analysis. First using content geometry found in the image the program calculates the position of the photographer in relation to the object, as well as the focal length
and distance to the object. Secondly the vision algorithms written into Photosynth are able to

the by-product being an immensely detailed model of every interesting part of the earth, which is
collected not only of satellite images or overhead flights but from the collective memory of human civilization", (excerpt Aguera y Areas, 2007) The idea of accessing the collective human memory as the source of data that is essentially describing what the earth looks like is creating something that is truly emergent, and defiantly greater than the sum of its parts.

"extract hundreds of distinctive features, like the corner of a window frame or a door handle",
making connections between images of like object. The program was designed to scour the

internet or any other database, much like a search engine, but searches the pixel content of

44

45

6 Site Analysis
Alexandra Park is affordable housing project located in downtown Toronto, which was built in the by the city 1960's. The community is managed by the Toronto Community Housing

Corporation, an arms length organization of the City of Toronto, in conjunction with the Atkinson

Co-op, a recently established co-operative organized by local residents. After some initial
success created by an enthusiastic board, the problems, which have plague the community
since shortly after its construction, persisted.

Designed by Jerome Markson Architect, the site is located just west of the downtown core and
consists of 263 town homes and 147 apartments in 2 large apartment blocks. With an abundance of green space, the site is a rarity within the densely populated core of the city.

Being ideally situated close to the heart of Toronto, gives the neighbourhood access to a host of civic and cultural institutions, and a plethora of some of the most popular commercial areas in
the city. Alexandra Park is surrounded on its north, west, and south sides by the Kensington Market, Chinatown, and Queen Street West, all of which are well frequented shopping

destinations. It is also within walking distance of many prominent cultural hotspots, including the
Art Gallery of Ontario, Ontario College of Art and Design, and the Chum City building. (Fig. 6.1)

I

Fig. 6.1 Location Map

47

The neighbourhood also has a wealth of amenities in the local area. (Fig 6.2)

through a system of dynamic feedback.

The absence of these players

in the everyday

functioning of a social housing community, such as Alexandra Park is one of the major reasons
that there has been little change or positive growth within the community since it's construction in the late 1960's.
Considering the organizational, architectural, and social-political structures of Alexandra Park

are heavily controlled by governing bodies from the top down, the community would appear to

be an ideal staging ground for the application of a thesis that is based on emergence and self
organizing systems.

Another powerful tool in the study of the failings of Alexandra Park it its proximity to another
well-known downtown community Kensington Market. Between the two neighbourhoods there is

a relative equality in the areas of access and amenity therefore opening each area up to a more
direct comparison of the internal forces at work within. The comparison of Alexandra Park to its northern neighbour Kensington Market, create a rich dialogue about the ability of self

organization to create vibrant communities.

Dundas Street the great divide between the two starkly contrasting communities is a testament
the power of rules, and the effect that they have on the physical construct of a place. Kensington market is understood to be a place of chaos and contradiction. From its early existence as an inner city slum, to the flourishing Jewish Market which was nourished by new immigrants escaping the oppression of 1930's Europe, to its present day eclectic incarnation, it has been widely recognised, if not loved, for its apparent disregard of the city's numerous zoning regulations and by-laws. Kensington Market can be seen as a wonderful example of the

innate power of self-organisation, and its uncanny ability to react to continuous change. By creating communities that reflect true market pressures, a natural relevance is spawned from
the unintended consequences that result from decisions local inhabitants are faced with on a

Fig. 6.2 Neighbourhood Map

day-to-day basis. Local decision-making is an especially relevant dynamic factor that keeps a community current and stands in stark opposition to top down decision-making, which is

The slow demise and social degradation of the community, in spite of favourable location and

severely limited by its inability to predict future possibilities. Understanding the immense connectivity found between each aspect of a project is vital to the
proper interpretation of site, and helps to uncover the complex web of interactions that create the overall context of the project. The site as a physical entity possesses only a part of the information available to us. When we consider that the site itself is merely the outcome of a

generous green space, gives credence to the argument that something in fundamentally wrong
with the systems at work with in Alexandra Park. Existing policy and governing protocol impede Alexander Parks's ability to react to changes which hamper growth by limiting the positive effects produced by local decision making. Local residents and landowners who work to adapt to the changing conditions of the city often control normal neighbourhood growth at a micro level

much more complex set of social, economic, and political forces the importance of what at first

48

49

seems a vague connection between disparate regulation and local decisions suddenly snaps

into focus. Site itself is of utmost importance to architects, because it is the stage in which our physical interventions play out, however by not considering context in much broader strokes we run the risk of misinterpreting the way in which our proposals will resonate in the complex world. An initial analysis of the site shown in figures 6.1 - 6.6 shows a sampling of the data which
investigates the relationships between relevant economic, political, and physical characteristics
of both Alexandra Park and Kensington Market.

The figure ground diagram (fig 6.2) shows the vastly difference between the physical structures

of the two neighbourhoods. The built fabric of the market, although slightly more dense than a typical low density district in the city, is much more coherent that the dispersed structures found
to the south. The open spaces in the market follow systematic hierarchy that establishes a sequence of differential spaces, while the looseness of the organization in Alexandra Park blurs
the boundaries and eliminates preference of any particular place.

The relationship between economy as a natural system and the growth of community and the

livelihoods of locals is explored in Jane Jacobs' book The Nature of Economies (2001). As
describe by Jacobs, success of a settlement is dependent on the energy output provided by the processing of local resources. (Jacobs, 2001) Currently Alexandra Park is removed from the economies that surround it because it does not take part in the active market, (fig. 6.3) The stagnant structure of the single use community, seen in fig. 6.4, hampers the possibility of
growth through an increased energy output. In the absence of a potential for growth other less

desirable enterprises, such as illicit trade, have emerged. In reaction to illegal activity within the site surveillance cameras and fencing, (fig 6.5) have been introduced to make up for the short
comings of the initial planning.

In order to establish a point of departure for a proposed intervention a survey of resources maps

out site potential (fig. 6.6) and existing green spaces (fig 6.7) which comprise one of the site's most valuable commodities. In addition to it's abundance of green space Alexandra Park also
contains an unusually large number of surface parking lots, which is why the community boast a

J n lJft:

relatively low floor space to land area ratio of 0.7, in spite having a two high density residential
buildings within it boarders. The excessive amount of open space leaves Alexandra Park with a density that is almost half that found in Kensington Market, which falls between 1.3 and 1.5

Fig. 6.3 Figure Ground

Fig. 6.4 Land Value

50

51

I OIKl IQIH3
r- 4 liiM
. i e ra Â»!=!

i

iv
Jfi:
commercial mixed use

I residential
Institutional

surveillance coverage v. physical barriers

public v. semi-public

Fig. 6.5 Land Use

Fig. 6.6 Areas of Potential

Fig. 6.7 Safety

Fig. 6.8 Green Space

52

53

7 Methodology
A composite map of site data gives us an alternative reading of the relationship between site
qualities. (Fig 6.8)

By scrutinising the underlying organizations that have brought emergence to the forefront of contemporary thought, the relationship matrix on the facing page compiles a visual summary of
the relationships established during the investigation of emergent systems. The Matrix is a
collection of connections and interrelations, indicating some of the ways that complex systems

are manifest in physical reality. Although not all of the topics where researched in depth, the matrix is a tool to gauge this thesis within the greater context of knowledge that surrounds
emergent theory.

Science, art, technology, and nature create a dense web of relationships that can reveal the core role of the architect as a facilitator of collaborations. Through the detailed exploration and assembly of a wide range of fields and expertise, an architect can position themselves as a hub
of converging ideas allowing for the delicate manipulation of the underlying relational structure. Thus allowing the architect to explore solutions that are reinforced by a wider range of variables, and which more accurately reflect the complexity of contemporary society. From the vast field of interconnected topics four key points were extracted that provide the most
Surveillance coverage

Physical barriers Semi-public open space
Public open space High potential areas

relevant description of the methodology proposed by this thesis. The four terms underline a particular notion of how we perceive contemporary society and appear as common themes
throughout the entire body of research.

Emergence could be described as the underlying system at work throughout the conception of
this thesis and the most prevalent thread throughout most of the research.

Digitalisation is a process which descries the conversion of our entire life experience into digital code, a process which is just begun to be realised and has the inherent ability to
fundamentally change the way we perceive and construct our world.

Language, is effectively the simplest and most universal human language ever created, and
crucial to the processes of digitalisation because of its ability to unify dissimilar variables. Algorithmic, considered as a way of thinking that defines the way we approach problem
solving, which is based on instructions and rule sets.

Fig. 6.9 Composite Map

54

55

7.1 Emergence
How can Emergence and Complexity theory change the way we think about designing

7.2 Digitalisation

Although digitisation has played a prominent role in the reshaping of our physical artefacts that

settlements?

define our world, it has also played an equally important role in the reprogramming of our way of
thinking about the world we inhabit. Digitalisation is an immensely important component to the
emergence of complexity, because it allows us to gain insight into the inner workings of complex

Emergence is of course all around us and is the unveiling of the complex beauty from the growth of the cities and the development of our conscious mind. Emergence itself has emerged
as an important topic in contemporary science and philosophy and in turn has become an area of interest and inspiration for architects and planners.

systems. Every new generation of computers increases our ability to manipulate complex
systems that were considered to be too chaotic to be truly understood. In an ironic way, it is the

intense digitalisation of our society though ever increasing technological advancement that has
brought us closer to understanding the holistic qualities of nature.

In short, Emergence is the process whereby "unanticipated consequences arise from well defined rules. A process that emphasises local action which lead to global patterns whose form cannot be anticipated from a knowledge if the rules that govern the processes of change."
(Batty, 2007, pg.51) More than just a phenomenon, emergence is a methodology of thinking of the complex world we inhabit in a holistic, inclusive manner. Emergence theory has arisen from the advancement of science and the quest for a deeper understanding of our selves and our place in the cosmos.

A significant event in the marriage of complexity theory and digital technology was the development of BOIDS, a computer simulation that effectively proved that bird flocks were self
organized entities that maintained cohesion through the consideration of a few simple

behavioural rules. BOIDS models the interaction between the simple behaviours of individual
members of a community and proves that the accumulation of simple interactions is in fact capable of producing highly organized group behaviour. The component behaviours are

inherently nonlinear, so mixing them gives the emergent group dynamics a chaotic aspect. At
A highly regarded example of emergence is the game of life, developed in the early 70's by
British mathematician John H. Conway. The mathematic construct was developed on a GO

the same time, the negative feedback provided by the behavioural controllers tends to keep the
group dynamics ordered. The result is life-like group behaviour.

board and is structured as a simple set of rules.

The rules, based on basic principles of life,

loneliness, overcrowding, reproduction, and stasis, dictate the state of each cell in each successive generation. Out of these four simple rules emerged a complex instrument that has

Although on a much more complex scale, similar rules also guide the behaviours and organizations of communities and neighbourhoods within the city. In fact contemporary urban

been described as the first Turning Absolute which by virtue of its ability to count can construct logic gates, and has unlimited computational power and memory. Understanding emergent behaviour is essential in developing an accurate reading of systems

planners such as Michael Batty (2007) rely heavily on the lessons learned from the study of cellular automata to explore the patterns of city growth formed by human interaction and
conscious decision-making. Batty uses simple rules devised from an objective review of system conditions and behaviours to set in motion simulations that can predict and or enhance our ability to make informed decisions at early stages of growth. The simulations translate existing growth patterns into algorithmic rule sets that formulize repeated patterns of human behaviour

as complex as a neighbourhood or a city district. The realisation that many issues cannot be directly confronted, but understood as a symptom of a more complex unfolding of events, changes the way one approaches the task of problem solving.

through the analysis of our built record. Naturally the simulations cannot fully anticipate all of the intricate variables at work in vibrant communities, yet they do show us an alternate ways of
thinking about the complexity of communities.

56

57

7.3 Language

7.4 Algorithm

Language is the most powerful emergent force in human society and is a major driving force

Algorithmic methodology modifies our approach to problem solving, thus shedding new light on many of sciences unsolved mysteries. By shifting the focus away from decoding particular behaviours towards defining the rules that govern behaviour itself, scientists such as Aristid Lindenmayer have redefined nature by uncovering the order in what had long appeared to be
random chaos.

shaping how we see and understand the world. Language is also a key aspect of emergence because it defines the way in which we communicate the rules. Contemporary society uses the
digital language of binary code, which is connected to emergence through digitalisation.

Simple rules define the workings of complex self-organising systems that in turn can only be defined through the use of language. In order to consolidate inherently different site

Proposed by Aristid Lindenmayer in 1968, a Lindenmayer or L-system is a system grammar that defines the steps of the iterative process of system growth. Originally used to prove

characteristic, binary code becomes a valuable tool that gives us the capacity to explore site
relationships using a common language.

Lindenmayer's own theory of algae growth and reproduction, the grammar system devised has proven usefully for describing advanced mathematical processes, especially fractal systems.

The study of Alexandra Park translates site variables ranging from the quality of physical

resources, green space, and the effect of surveillance cameras into a common language that
allows for a comparison of variables in a more direct way. The model of comparison is in akin to the algorithms that define common cellular automata, by encoding state, location, and proximity information into simple data sets. Site information is displayed on a grid of cells, which record

The rules themselves are what establish the outcome of L-systems, as every iteration must be acted upon but the established grammar in order to achieve the next set. The L-system itself is
not limited by size or complexity but by their inability to differ from their initial rule set.
Lindenmayer systems are part of a larger group of techniques know as production systems,

the absence or presence of a particular quality and survey the cells in their local neighbourhood
to relate information about the quantitative intensity of each characteristic. Direct comparisons can be made by superimposing the data in a series of composite maps that help to visualise the
relationships created between variables.

which include various classifier systems and Iterated Function Systems. Extended systems are capable of having varied and responsive rule sets that add a larger range of abilities not

available in L-systems. Genetic algorithms are one such system that has received a large
amount of attention in recent years. (Ergen, 2008)

Breaking down site information into simple data types facilitates the combination of information and simplifies the definition of a set of rules, or grammar that can infuse potential interventions
with relevant site data.

A production systems greatest strength is it ability to apply feedback to breakaway from the linear input output command chain found in a wide range of scientific thinking. A defining
element of a production system is the reincorporation of system output in consequent system
cycles.

By using an establish site grammar as a starting point, and controller of future potential, we can

move to eliminate much of the information that is normally lost between analysis and design phases of production. Embedding the data of all site variables into the seed of potential outcomes effectively eliminates the practice of biasing favourable site characteristics, while
relegating less convenient truths. Following a strict algorithm to establish and translate site

Most existing top town planning principles are insufficient to respond to a system as complicated as city growth. The components of a city are in a state of perpetual dynamic flux, making
predetermined plans quickly obsolete as a neighbourhoods change.

information, results in a more relevant solution eliminating pre-conceived solutions on part of the
designer

Production systems, due to their constant appraisal of local conditions, in the form of feedback

loops, have a special ability to maintain relevance to changing neighbourhood dynamics. The challenge of incorporating such a system lies in the formulation of a rule set that keeps the
system dynamic enough to react to change with out compromising establish goals.

58

59

8 Results
8.1 Counter Proposals

Some common solutions for adding density to the neighbourhood were initially examined In
order to set up a counterpoint to a rehabilitation proposal based in the research of this thesis.

One such proposal (fig. 8.1) would involve placing point towers in open spaces, mostly in the
existing parking lots, around the perimeter of the site, which would have the effect of increased

density without reducing green space. Although the proposal manages to preserve one of the sites most valuable resources it fails to address the lack of interactivity and site penetration, and
could very well further alienate the inhabitants.

<

. <:->'

Fig. 8.1 Point Tower

Fig. 8.2 Midrise

The second solution (fig. 8.2), which is similar to the one currently underway at Regent Park,
involves the complete demolition of the existing building stock, re-establishment of the street

grid and the reconstruction of a midrise building fabric which is capable of achieving a much higher density. However, the second model all but eliminates most of the neighbourhood green
space, and completely erases the existing neighbourhood identity, not to mention a significant
loss of embodied energy.

It is obvious that both proposals have a merit and are plausible options to generate increased

density. While both options exhibit certain shortcomings, neither takes advantage of the existing conditions to stimulate positive change. What the proposals do agree upon is the need for
densification, using the assumption that more people will solve the neighbourhood's ailments.

Increased population, although an important ingredient, cannot support significant change without the accompanying desire to create intensification, which can be described as qualitative
increase in active opportunity.

61

In the spirit of emergence theory, this thesis proposal addresses the need,

not only for

8.3 Points of Interest

densification, but the intensification of existing conditions, while retaining the existing building stock as a viable alternative to demolition. Maintain the existing embodied energy by not giving
up on a so-called failed project with a relatively new building stock, should be considered as a

In order to help strengthen a proposal based on the celebration of difference in Alexandra Park,
The proposition of a few key changes at an urban scale are intended to correct some of the failings of the existing plan, and give the proposed intervention a outline of objectives that will

fair strategy for future sustainable urban growth.

help to improve the neighbourhoods connection the rest of the city. The changes can be seen in
Fig. 8.3, and include;

8.2 Existing Complexities
The existing housing project known as Alexander Park was built in an attempt to recreate the
hidden complexities of a medieval town. However, its failure lies in the absence of growth, which

in all intents and proposes in an integral part of what makes the medieval village so interesting and vibrant. By increasing opportunities to facilitate growth the proposal looks to revive the existing neighbourhood, which has long become stagnant due to its inability to grow, and to infuse it with a new layer of use. The introduction of a second layer of activity is intended to react to existing conditions while acting as a catalyst to induce further change. It is the interstitial space between the newly implemented systems and the existing structures that holds the
potential for increasing intensification.

Through the early stages of design development the apparent lack of growth found in Alexandra
Park was the key problem to be resolved, but as further study began to uncover new

relationships, unseen at first, the stagnation witnessed appeared to be only a symptom of the real issue. In fact Alexandra Park as it was originally constructed lacked an essential component that doomed it to failure from the very beginning. Difference, which the plan of Alexandra Park

eliminates in an attempt to create uniformity and social justice, is an essential part of any
neighbourhood's ability to grow and change. Real difference which arises from within the very core of a project goes above and beyond the superficial differences, such as window dressings and door colours, to offer fundamental qualities that have the intensity to generate movement
and growth.

This establishment of difference is essential in the proper function of any self organizing system.

Fig. 8.3 Urban Alterations

A lack of difference similar to that found in Alexandra Park inhibits the accumulation of
community pride because it requires that the inhabitants to leave the neighbourhood as they pull themselves out of a reliance on social assistance. If we accept the fact that difference is paramount to the induction of change, a substantial amount of difference, could insure that a positive neighbourhood identity can growth and prosper for many years to come.

1. The removal of existing structures, indicated in red, to facilitate the following.
2. Re-establishment of Grange Avenue as a pedestrian promenade.
3. Reconnection of Augusta Avenue north to Dundas Street

4. Closure of Vanauley Street to create a public square at Queen Street
5. Creation of clearer connections between linked green courtyards.

62

63

In addition, The Identification of five key areas whose rehabilitation are essential to the overall
success of the project are exhibited by fig. 8.4

8.4 Project Conception

This thesis's main conceptual driver is focused on the use of digital design tools to explore the
emergent qualities made possible by parametric software and algorithmic processes, while

studying the effect of difference as a catalyst to change. The project attempts to integrate the four organizational systems previously noted (emergence, digitalisation, linguistic, and

algorithmic) to test the notion that systems that exhibit a great degree of difference. Those that

are "far from equilibrium, are most likely to produce, radical, productive, and unforeseeable
results" (Kwinter, 2007, pg.16)

The notion of creating difference in Alexandra Park will be developed by initiating the following
techniques on the existing site; (Fig. 8.5)

8.4.1. Reacting to Site specifics. By taking into account local conditions the proposal will
be invariably altered as it reacts to difference already existing on the site.

8.4.2. Creating a proposal that contains in itself a range of spatial conditions will further e
xacerbate site specificity.

8.4.3. Using the age-old adage of 1 + 1 + 3, the notion that the convergence of two systems can create a product that is greater than the sum its part and is central to the
theme of this project.

Reacting to Site Specifics

Fig. 8.4 Key Areas

Spatial Variation

1. Highlight extended Augusta Ave. and Dundas / Denison intersection

2. Establish a Gateway Square and promenade as a draw from Dundas and Spadina
3. Re-establish edge of Cameron Street

4. Emphasize Carr Street Vista, to reinforce the heart of the site.
5. Create new activity square as a draw from Queen Street.
Emergent Properties

64

65

Fig. 8.5 Generating Difference

8.4.1 Responsive Matrix

As seen in Fig. 8.7, Each Input has its own distinct affect on the point matrix that when

combined produce a result that could not be pre determined by observing the characteristics of

A matrix of points, distributed evenly about the site at 20 meter intervals is a starting point for
the development of a reactive network that responds directly to the existing conditions at the

each individual systems. The areas of potential input applies a force of attraction to the matrix,
as well a downward pull, which are a translation of the potential of the areas to be foci or places

site. The matrix begins as a neutral system, which is waiting to accept input from the varied site
characteristics, (fig. 8.6)

to ground any proposed intervention. The intensity of the force correlates to the relative potential
of each area. The second factor considered is the private and pubic open spaces that exert a

repelling, upward force on the grid in an attempt to preserve its existence. The coverage of
surveillance cameras in the site is used to determine the locations which are not naturally
surveyed due to flaws in the building fabric. The presence of the cameras suggest that these

areas lack sufficient eyes on the street to which the system reacts by define an orientation for
each point that will translate to the built form of the proposal.
20 x 20 meter point matrix

Â·

Â·

Â·

Orientation

Fig. 8.7 Point Response

Fig. 8.6 Default Point Matrix

Once all variables are applied to the system the resulting point matrix is embedded with the Three of qualities, determined during the site analyses, are encoded with different values that are intended to act on the grid in relationship to their position and intensity. The site factors that
are being considered for this initial construct are the areas of potential, public and private green
spaces, and the coverage of surveillance cameras.

characteristic information of each site factor. The matrix then becomes an infrastructural element which guides the development of any future intervention, (fig. 8.8) By reacting to the site specific information the deformed matrix controls the new proposal by limiting the number of possible solutions. Only geometries that directly correspond to the gird are possible, thus
insuring that the new proposal is indeed reacting to site specific conditions.

66

67

8.4.2 Spatial Variation
The spatial quality of the project is developed using an abstract construct, which is based on
hexagonal section (fig. 8.9).

Public

Fig. 8.9 Hexagonal Typology

The sectional device, through the use of parametric modeling is capable of creating spatial

variation along its entire length. At each section the systems reads its local conditions and
reacts accordingly. Factors which include the curvature and inclination of the controlling spline,

proximity to existing structures, and the orientation of the grid matrix, all exert formative forces on the default six sided section. This reactive ability shown in figure 8.10 gives the proposed spatial organization a wide range of configurations fulfilling the second proposition for creating difference. It also further reinforces the first proposition of site specificity by working within the
defined point matrix, which is itself a product of site specific data.

Fig. 8.10 Spatial Variation

Fig. 8.8 Deformed Point Matrix
68
69

Figure 8.11 shows the body of the inhabitable space defined by the sectional construct

The envelope is required to serve functions that demand environmental control. It is responsive to the desired orientation dictated by the point matrix, and opens up towards areas where safety is compromised by lack of observation. It is also responds to existing site conditions by reading its relative position and assuming a geometric arrangement that maximises passive solar

consisting of three levels of physical permanence. Each level addresses a specific function of
the space and when combine define the physical manifestation of the project. The

infrastructural layer is thought of as the most permanent, because it carriers the essential
services to the rest of the structure. It also acts as a spine on which the other layers are attached and supported. The infrastructural layer can potentially exist in the absence of the

heating. This responsiveness increases the spatial variety of the proposal depending on its
location and orientation, (fig. 8.12)

other layers, which depend on it for their existence. The intrastructural layer is the bounding
structure which defines the space of use. It is defined as intrastructural because it exhibits the

intensity of the uses within and is reactive to external forces about. The second layer directly supports the activities within the structure, but cannot host all possible functions, without
working in conjunction with the responsive third layer the envelope.

Infrastructural

Body Orientation

opens to except southern
sun to increase solar heat gain

Intrastructural

body orientation opens

towards areas of with questionable
safety to add eyes on the street

Responsive

Fig. 8.12 Reactive Envelope

Fig. 8.11 Abstract Model
70
71

8.4.3 Emergent Qualities

The structure of the spatial systems consists of the support structure, primary and secondary ribs, horizontal floor plates, and the envelope construction. The envelope itself in made up of
three components which include the structural frame, transparent glazing, and opaque insulated

Now that the intervention has substance that is reactive to site conditions, and contains enough spatial variation to create equality and drive change, it ability to intensify the community
depends on the key interactions that exist at the points it comes in contact with the existing built
fabric.

panels. Although the envelope reacts to variation in the form of the internal structure they are each controlled by a separate parametric rule set. The usable space created, although varied in

Fig. 8.14 Emergent Relationship

Figure 8.13 illustrates the moments of collision that allow potentially unforeseen spatial organizations to arise. As the two systems interact in a variety of ways new opportunities unfold.

Although every interaction of the two systems will be slightly different they are classified by
three generic terms, straddle, intersect, and sit, which best describes the ways in which the two
Â·

systems are expected to interact. Conditions such as using previously unused rooftops as
legs ribs skin

balconies, or the commendation of an existing structure as an access point to the new spaces

created above, hold the potential to intensify use and enhance the relationship between the
public and private sphere.

Fig. 8.13 Body Structure

72

73

8.4.4 Project Overview

neighbouring space has
increased exposure

Fig. 8.16 Detailed Interactions

The hybrid space created by the interaction between existing and proposed shown in Fig. 8.17 in indicative of the type of emergent spaces that can be created by the unification of two

systems. The existing structure acts as an access point to the spaces proposed above, and in
Fig. 8.15 Augusta & Grange Gateway

doing so creates a point of increased intensity that will be the benefit of increase in pedestrian traffic and the possibility of chance encounters. These amongst other factors will contribute to an increased potential of neighbouring spaces. For instance, due to increased traffic, the space adjacent to the access point could become a cafe or a small shop, which would then bring more
people further fuelling the potential for growth.

Fig. 8.16 depicts the formal configuration of the project as it interacts with the existing neighbourhood in three distinct situations. At the bottom edge of the image, the intervention frames the newly created public space and then is pushed up into a vertical arrangement by it's interaction with the street edge. The structure directly adjacent to the first intersects with both

the high-rise residential tower and the row houses on its north end effectively creating hybrid
space describe in Fig. 8.15. Along the Grange Ave promenade a third object rest on top of the existing row houses taking advantage of the roof as exterior garden space and commandeering a few of the houses to gain access to the higher levels while creating new spaces that will
benefit from increased pedestrian traffic. This effect is shown in more detail in Fig. 8.17

74

75

A series of gateways created by a built up presence!
along dundas.energizes the street edge while i

mpiovtng access to the site by increasing porosityjf j
establishment of new promenade Increases

connectivity through-site, which is supported by the opennets of <hÂ« building form,

sity est<btohes increased densityÂ«
edge along Cameron St..

building location and orwi

vista along Carr St. througt

"action works to sup
in peopled square

Fig. 8.20 Dundas Garden Gateway

Fig. 8.17 Addressing Urban Issues

Fig. 8.17 revisits the initiatives set out to gage the effectiveness of the proposal on the urban
condition. Fig. 8.18-8.21 visualise some the changes to the key areas in question.

Fig. 8.18 Along the Carr Street Axis

Fig. 8.19 Public Open Space off Queen
Fig. 8.21 Grange Promenade Gateway
76
77

9 Conclusions
In all aspects of society the importance of difference is being understood as a catalyst to

introduce dynamics into stalled systems. Economists understand that difference is instrumental
in the generation of wealth. Rawls' theory of justice implies that utilitarianism fails to protect the social welfare of the lowest levels of society because it does not "generate enough difference to

attract people to certain positions and motivate them to perform". (Riahi-Belkaoui, 2005, pg.256) It could also be argued that without a wide range of wealth certain activities would not be
entertained that could potentially give an opportunity for the transfer of wealth. Difference is only now becoming a viable alternative to sameness and repetition in architecture

because computer technology and digital manufacturing processes have mostly mitigated the cost increases associated with deferring from the status quo. In the field of urban planning the grip of policies dictating monocultures for land use and social groups are being loosened by the recognition that mixed use and diverse populations generate far more dynamic living conditions. However, this does not change the reality of existing neighbourhoods and districts, such as Alexandra Park, where the legacy of modernist planning principles is still responsible for
degrading social conditions.

As this thesis suggests the use of emergent systems as a method for building more dynamic
and nuanced self organised communities has a foundation which is grounded in a wide range of
scientific research. At the very least the proposal put forth in this thesis verifies that the current

exploration of variation and difference in the sciences can be transposed and engaged through
architectural form.

Emergence theory suggests that the minute differences that propel a systems towards growth,
change, and the emergence of the truly novel. (Morowitz, 2002) This thesis sought to create

difference in Alexander Park to help induce change in a community left stagnant by its own
rigidly planned environment.

Seeking the assistance of parametric digital models, the thesis avoids the preconceptions
associated with direct decision making in favour of the manipulation of the underlying systems

of production. The point matrix developed using parametric modeling should be seen as a tool able to read and reflect site specific information. Encoding the matrix using parametric data enables it to create relationships between wide ranges of variables. At this point the variables used in construction of the point matrix are still too limited to be considered an absolute

79

response. However, because of the tools ability to accumulative new data the model can easily assimilate an increasing number of variables without significant alteration of the underlying system. Additionally, the grid is general enough to be deployed on various sites by deferring
specificity until it is exposed to site specific information.

Further exploration into the sectional model could potentially yield more suitable geometries, In

would be logical to assume as the number of faces increases, so to will the initial complexity of
the object.

Because the grid system and the abstract model are mutually exclusive both can be further developed along independent tracks, which could then be brought together again to test new emergent properties of the unified system. Figure 9.2 shows alternative possibilities diverging from the establishment of the point matrix. The point matrix can be a base for other conceptual

The initial state of the point matrix provides an opportunity for further exploration. The initial state used for the current proposal was established in response to particular conditions and the

size requirements for the project. Although predetermined, the points selected for uses in the
proposals are but a sample of infinitesimally small divisions of the matrix itself. Conceptually the matrix has no scale, as any point distribution can be materialized along the matrix's reaction to
forces.

constructs including the definition of a landscape surface, or guidelines in a massing model.

The abstract construction used to establish the spatial qualities of the project were conducive to the generation of difference required by the projects original goals. The hexagonal section is a more flexible and adaptive geometry, than others tested during the design development of the project. Although the quadratic section, seen in figure 9.1, used early in the project development could create internal spaces more in line with traditional dwelling it was less capable of dealing with complex matrix configurations and showed limitations in its interaction with the existing
buildings.
massing model
activity landscape

Fig. 9.2 Alternative Constructs

The building envelope also controlled though parametric modeling was well suited to react to both the changing geometry of the spatial structure, as well as to its orientation and relative position in the environment. At this point the skin holds a great deal of potential for further study
with the increase of controlling variables and performance demands the skin can evolve into an ever more complex system that reacts to increasingly more precise levels of detail.

The three systems employed in this study could only produce the final proposal as a result of
their unification. The results of which can be characterized as an exploration in emergent differentiation. Each layer over is able to exist independently, which dictates that they also have the possibility to evolve independently. From the information that has been gathered during the brief union for the purposes of this project, a genetic record of their existence persists. By

\
Fig. 9.1 Alternative Direction

learning from the prospects and failures of the current model, each subsequent system can be modified to react to shortcomings that will make further recombinations of these particular processes increasingly more effective. The potential for further growth is in the end what this
thesis sought to achieve at its onset.

80

81

References
Aguera y Areas B. (2007). Blaise Aguera y Areas demos Photosynth,
http://www.ted.com/talks/lang/eng/blaise_aguera_y_arcas_demos_photosynth.html

Kieran, S., Timberlake, J. (2004). Prefabricating Architecture. New York: McGraw-Hill. Kim, J. (e.) Bedau, M., Humphreys P. (2008). Emergence: Contemporary Readings in
Philosophy and Science. MIT Press.

Batty, M. (2007). Cities and Complexity: Understanding Cities with Cellular Automata, Agent-Based Models, and Fractals. Boston: MIT Press.

Kolarevic, B. (2003). Architecture in the Digital Age: Design and Manufacturing. London:
Spon.

(e.) Bedau, M., Humphreys P. (2008). Emergence: Contemporary Readings in
Philosophy and Science. Boston: MIT Press.

Kwinter. S. (2007). Far from Equalibrium. New York: Actar. Langton, C (1990). Computation at the edge of chaos. Physica D: Nonlinear
phenomena, No. 42. Elsevier.

Bowron, J.(2004). retrieved from http://www.featurefactory.com/page.asp?pageid=103

Celento, D. (2005). Innovate or Perish: New Technologies and Architecture's Future.

LeCuyer, A. (1997). "Gehry's Reign in Spain," Architecture (December 1997): 64-77. Luce, S. (2008). Revolutions in Parallel: The Rise and Fall of Drawing within
Architectural Design, Ann Arbor: University of Michigan

De Landa, M. (1997). A Thousand Years of Nonlinear History. New York: Zone Books.
Delueze, G. (Conley, T. English Translation) (1992) The Fold: Leibniz and the Baroque.
University of Minnesota Press

McLuhan, M. (1964). Understanding Media: The Extensions of Man. Cambridge, Mass:
MIT Press.

Dennet, D. (2004) Freedom Evolves. London: Penguin.
Ergen, S. (2008) L-System in Computer Graphics Retrieved from http://www.selcukergen.net/ncca_lsystems_research/research.html

Menges, A. (2005). Manufacturing Diversity, AD.

Morowitz, H. (2002). The Emergence of Everything: How the World Became Complex.
Oxford University Press.

Gardner, M. (1970) Scientific America, Mathematical Games. Vol. 223, October 1970:
120-123.

Mumford, L. (1961). The City in History: Its Origins, Its transformation and Its Prospects.
New York.: Hardcourt, Brace, Jovanovich.

GameTrailers E3 2008 Spore Developer Walkthrough Part 1". GameTrailers
retrieved from www.gamespot.com

Scheurer, F. (2005). Turning the Design Process Downside-up: Self-organization in
Realworld Architecture. CAAD Futures 2005.

Hensel, M., Menges, A. (Ed.). (2006). Morpho-Ecologies. London: Architectural
Association Publications.

Sheil, B. (2008) Protoarchitecture: Between the analogue and the digital. Architectural
Design Volume 78 No.4, pg. 6-11.

Hugo, V.M. (1917). Vol. XII. Harvard Classics Shelf of Fiction. New York: P.F. Collier &
Son; Bartleby.com, 2000.

Sorkin, M. Deckker. T. (Ed.). (2000) The Modern City Revisited, E & FN Spon. London
Speaks, M. (After Theory. Perspecta: The Yale Architectural Journal, no. 38:
Architecture After All, p. 103-108.

Jabi, W. (2007). ACADIA Cover image competition retrieved from
http://www.acadia.org/ijac07covers/results.html

Jacobs, J. (1961). The Death and Life of Great American Cities, New York: Random
House.

Preston , J. (2008). "Affecting Data" Architectural Design. Volume 78, No.3, Pg. 36 - 45
John Wiley & Sons, Ltd.

Jacobs, J. (2001). The Nature of Economies, New York, Vintage.

Riahi-Belkaoui, A. (2005). Accounting Theory. London : Thomson.
2006) Intelligence

Johnson. S. (2001). Emergence: The Connected Lives of Ants, Brains, Cities, and
Software. New York: Scribner.

Reynolds, C. W. (1987). Flocks, Herds, and Schools: A Distributed Behavioral Model, in Computer Graphics, 21(4) (SIGGRAPH '87 Conference Proceedings) pages 25-34
The Economist (2008.)"From blueprint to database" The Economist. Farmington Hills,
Michigan: Gale Group.

Kasavin, G. (2006). "E3 06: Spore Creature Editor Hands-On". GameSpot.com

82

83

Weinstock, (2008). Can Architecture Design be Research? Architectural Design. Volume
78, No.3, Pg. 112-115.

Weinstock, M. (2006).

Morpho-Ecologies: Introduction

(M. Hensel, A. Menges, Ed.).

London: AA Publications.

Wigley, Mark (2004). The Critisim of Form [Taped Lecture]. (Available from Stadelscule,
durerstrasse 10, Frankfurt am Main, 60385)

Wiscombe, T. (2006). Emergent Models of Architectural Practice. Yale Perspectiva.

.- (o\ 84


