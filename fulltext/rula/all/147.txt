Ryerson University

Digital Commons @ Ryerson
The Institute for Innovation and Technology Management 4-26-2010 University Institutes and Research Centres

Commutative Prospect Theory and Stopped Behavioral Processes for Fair Gambles
Godfrey Cadogan
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/iitm Part of the Economics Commons Recommended Citation
Cadogan, Godfrey, "Commutative Prospect Theory and Stopped Behavioral Processes for Fair Gambles" (2010). The Institute for Innovation and Technology Management. Paper 1. http://digitalcommons.ryerson.ca/iitm/1

This Working Paper is brought to you for free and open access by the University Institutes and Research Centres at Digital Commons @ Ryerson. It has been accepted for inclusion in The Institute for Innovation and Technology Management by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

Commutative Prospect Theory and Stopped Behavioral Processes For Fair Gambles
Godfrey Cadogan  Working Paper April 26, 2010

address: 3401-B N.W. 72nd Ave, Ste # T-419, Miami, FL 33122; e-mail: gocadog@gmail.com. I thank Richard Gonzales for his incisive comments on an earlier draft of this paper. Any error which may remain are my own. This paper is an expansion of subsection 4.1.2 in "Asymptotic Theory of Stochastic Choice Functionals for Prospects with Embedded Comonotonic Probability Measures," unpublished.

 Corresponding

Abstract We augment Tversky and Khaneman (1992) (TK92) Cumulative Prospect Theory (CPT) function space with a sample space for states of nature, and depict a commutative map of behavior on the augmented space. In particular, we use a homotopy lifting property to mimic behavioral stochastic processes arising from deformation of stochastic choice into outcome. A psychological distance metric (in the class of Dudley-Talagrand inequalities) for stochastic learning, was used to characterize stopping times for behavioral processes. In which case, for a class of nonseparable space-time probability density functions, we find that behavioral processes are uniformly stopped before the goal of fair gamble is attained. Further, we find that when faced with a fair gamble, agents exhibit submartingale [supermartingale] behavior, subjectively, under CPT probability weighting scheme. We show that even when agents have classic von Neuman-Morgenstern preferences over probability distribution, and know that the gamble is a martingale, they exhibit probability weighting to compensate for probability leakage arising from the their stopped behavioral process. Keywords: commutative prospect theory, homotopy, stopping time, behavioral stochastic process JEL Codes: C3, C5 AMS 2010 Subject Classification: 60G20, 60J25, 60J60, 60J65

Contents
1 2 3 Introduction Commutative Map of Prospect Theory's Augmented Function Space Behavioral Stochastic Process 3.1 Behavior mimicking homotopy . . . . . . . . . . . . . . . . . . . 3.2 Psychological distance and stopped behavioral processes . . . . . 3.2.1 Behavioral submartingale processes . . . . . . . . . . . . Applications to Fair Gambles 4.1 Case i. Submartingale behavior for fair gambles . . . . . . . . . . 4.2 Case ii. Supermartingale behavior for fair gambles . . . . . . . . 4.3 Case iii. Probability leakage for fair gambles . . . . . . . . . . . Conclusion 2 4 6 7 9 14 19 21 23 24 26

4

5

List of Figures
1 2 Commutative Map of Prospect Theory's Liftings . . . . . . . . . Prospect Theory's Homotopy Lifting of State Space . . . . . . . . 4 7

1

1

Introduction

This paper is motivated by the following statements from (Tversky and Khaneman, 1992, pg. 300) hereinafter referenced as ("TK92"): Let S be a finite set of states of nature; subsets of S are called events. It is assumed that exactly one state obtains, which is unknown to the decision maker. Let X be a set of consequences also called outcomes. ********** An uncertain prospect f is a function from S into X that assigns to each state s  S a consequence f (s) = x in X . To define the cumulative functional, we arrange the outcomes of each prospect in increasing order. A prospect f is then represented as a sequence of pairs (xi , Ai ) which yields xi if Ai occurs . . . . ********** Cumulative prospect theory [("CPT")] asserts that there exists a strictly increasing value function v : X  Re, satisfying v(x0 ) = v(0) = 0), . . . [Emphasis added]. At a more abstract level, (Luce and Narens, 2008, pg. 1) characterized problems of this type thusly: Most mathematical sciences rest upon quantitative models, and the theory of measurement is devoted to making explicit the qualitative assumptions that underlie them. This is accomplished by first stating the qualitative assumptions empirical laws of the most elementary sort in axiomatic form, and then showing that there are structure preserving mappings, often but not always isomorphisms, from the qualitative structure into a quantitative one. The set of such mappings forms what is called a scale of measurement. [Emphasis added]. Equally important is the following (Nosofsky, 1997, pg. 347) quote of Luce:

". . . we surely do not understand a choice process very thoroughly until we can account for the time required for it to be carried out . . . ".
2

Even though TK92 did not use the words and phrase "topological lifting", the composite mapping they describe­choice function from state space to outcome space, and value function from outcome space to the reals­is, by definition, a topological lifting of a direct map from state space to the reals. Additionally, TK92 did not augment their function space with the prerequisite map from "states of nature", i.e., a sample space, to state space­which gives rise to stochastic choice on state space. Nonetheless, "occurence of an event effects a change of state", (Norman, 1968, pg. 61). In fact, review of the literature on prospect theory failed to find explicit analysis of this commutative prospect space. Thus, this paper fills that void by augmenting TK92 CPT function space with mappings from "states of nature", i.e., a sample space, to state space. By so doing we induce a rich topological space, and show how behavioral stochastic processes are generated from microfoundations of the augmented space1 . Additionally, in accord with Luce's surmise about choice and time, we introduce behavior mimicking  -homotopy sample paths for deformations of stochastic choice into outcome. We show that the sample paths are stopped behavioral processes, and that for fair lotteries they are local martingales 2 under CPT probability weighting scheme.
methodology is distinguished from that popularized in the literature on stochastic models of learning. See Wickens (1982). A qualitative paper by Steinbacher (2009) used "buzz words" and "catch phrases" to discuss related issues, but did not introduce a parametrized model of behavioral stochastic process. 2 Tangentially related papers by Nosofsky (1997) and Nosofsky and Palmeri (1997) deal with subjects' retrieval time from memory for objects that are similar to exemplars. Even though a random walk model fitted their experimental data, their approach is qualitatively different from that in this paper. Recently, Lindquist and McKeague (2009) proposed a logit model with Brownian-like predictors that may be closest to ours. However, their model was adaptive and based on observations in fMRI and other medical experiments. Our model is normative in the context of the augmented CPT function space
1 Our

3

In section 2 we introduce basic definitions, and the commutative map of prospect theory's function space including its sample space augment. In subsection 3.1 we introduce the main result of a behavioral homotopic lifting which serves as the foundation for construction of a behavioral stochastic process in subsection 3.2. In subsection 3.2 we show how behavioral stochastic processes are uniformly stopped just short of reaching a goal in space-time. In section 4 we apply our theory to fair gambles, and report results under various scenarios of probability weighting. Section 5 concludes with perspectives for further research.

2

Commutative Map of Prospect Theory's Augmented Function Space
To keep track of the myriad liftings and composite maps in Prospect Theory's

function space, we modify the old adage "a picture is worth a thousand words" to "a commutative map is worth a thousand words". The diagram in Figure 1 plainly
kW pX O g WWWWWWWWW ppp WWWWW p p W WW p v f p w ~ Y WWWWWWWW pp p WWWWW p p xo p W o o g w P (  ) P S 

R

Figure 1: Commutative Map of Prospect Theory's Liftings

shows that the stochastic choice map f is a lifting of the imputed direct map g = v  f from state space S to the reals R. Further, v is a functional, of f , on X . So any action on v that yields another functional is an operator by definition. Compare Tversky and Khaneman (1992) mapping scheme in the introduction section 1 of
4

this paper. Additionally, the composite direct map g  (w  P) = v  Y , from sample space  to the reals R, is a lifting of Y . In that case, for a given outcome x  X , the map v(Y ( )) is a functional. Thus, any action averaging over that quantity gives rise to an averaging operator. Further, the probability weight function w is a lifting of the direct map w ~ = f  w from P() to S. Perhaps most important, the composite map w  P is a lifting of the direct map Y = f  (w  P) from sample space  to outcome space X . The stochastic choice functions in extant literature, see e.g., Debreu (1958) and McFadden (1974), considers a mapping P :   S. But not the intermittent composite mapping w : P()  S which embeds probability weights in state space S, and indirectly in X through choice function f or directly through the composite w ~ . The commutative map plainly shows that the introduction of probability weighting map w should be incorporated in any stochastic choice map f : S  X to account for probability distortions. In fact, Figure 1 includes the following complimentary space3 that is the sui generis of this paper. Definition 2.1 (Prospect Theory's Complimentary Space). Let A, B, C be the [dense] space bounded by the commutative map­defined respectively by A = |SX RS| B = |SXP()S| C = |P()X |
3 Our

(2.1) (2.2) (2.3)

useage of "complimentary space" is different from common useage in Hilbert space theory. Even though -  one could perhaps treat the commutative map as one that includes vector valued functions. In which case, if |X | is -  orthogonal to |X R|, the complimentary angles subtended at X could be used to "define" the "complimentary space" they subtend.

5

Let M be Prospect Theory's function space such that M = A  B  C. Then B  C=M A is Prospect Theory's complimentary space. Notationally we write Ac

for PT complimentary space. Prospect Theory tends to focus on the space A in (2.1). In this paper, we focus on the space M A or Ac .

The mapping Y in Figure 1 has the following interpretation. Since Y :   X  Y ()  X , there exists a lottery {(x1 , p1 ), (x2 , p2 ), . . . , (xn , pn )} or gamble such that Y ( ) takes the values (x1 , x2 , . . . , xn ) with corresponding joint probability distribution ( p1 , p2 , . . . , pn ). So that for a given realization of outcomes, Yi ( ) = f  (w  pi ) = f (w( pi )) = (xi , pi )  = xi ( pi ), for some index i. Additionally, let FY be the probability distribution function of Y . So that for rank ordered Y we
- + have the relation y = w(FY (y)) - w(FY (y)) as the probability weight assigned

to the simple lottery at the jump of F . In any event, the commutative diagram plainly shows how probabilities and or probability weights are embedded in outcome space X . The rest of this paper constitutes analytic proofs of these facts according as they apply to Cumulative Prospect Theory or otherwise.

3

Behavioral Stochastic Process
In this section we introduce the homotopy concept and use it to identify a

behavioral stochastic process in PT function space.

6

3.1

Behavior mimicking homotopy The following definitions are critical to this paper.

Definition 3.1 (Homotopy, deformation, path). [(Lefshetz, 1942, pg. 39)]. Let A, B be topological spaces and I be the unit interval I = {u|0  u  1}. Two mappings, t1 , t2 : A  B are said to be homotopic whenever there is a mapping T : I × A : B such that T (0, x) = t1 (x), and T (1, x) = t2 (x) for x  A. If t1 = 1A is the identity map, so that A  B, then t2 is a deformation. The set T (I , x) is the path of x. Whenever the spaces are metric, and the paths are all of diameter less than  , we have an  -homotopy, or an  -homotopy as the case may be. Definition 3.2 (Homotopy Lifting Property). (Gray, 1975, pg. 79). ~ : [0, 1] ×   S, and for any map Y lifting  ~ , there exist a For any homotopy  ~ with Y =  ~ |[0,1]× . homotopy  : [0, 1] ×   X lifting  The commutative map in Figure 2 depicts the homotopy lifting property enunciated in 3.2. According to Figure 1 the mapping Y and f  (w  P) are candidates
  × [0, 1]
 i/4 O Y iiii X i i i iii i i iiii

ii

~ 

/*

S

Figure 2: Prospect Theory's Homotopy Lifting of State Space

for homotopy maps from  to X . Specifically, let  (0,  ) = f  (w  P)( ) and  (1,  ) = Y ( ) for some realized sample point  . If the stochastic choice composite map f  (w  P)( ) is a continuous deformation of Y ( ), then  (t ,  ) is
7

an intermediate sample path of the deformation of f  (w  P)( ) into Y ( ) at some intermediate "time" t 4 . In other words, technically, if F = Ft (n)  Ft (n) 
1 2

. . . Ft (n) is a right filtration of the paths in [0, 1] for a dyadic partition of [0, 1],
2n

then there is a progressively measureable [discretized] behavioral path process  = { (t ,  ), Ft ; tk-1  t < tk , k = 1, 2, . . . , 2n } that describes the deformation of stochastic choice function to a random variable in outcome space. That is, for tk = k.2-n fixed, we have the approximate "coordinate mapping"  (t ,  )  Y ( ) which translates to an  -homotopy sample path
(n) (n) (n) (n) (n)

 (tk ,  ) = Y ( ) +  (tk ,  )

(3.1)

where  is an idiosyncratic " " error term. This implies observation that subjects change their mind over time, and that the behavior mimicking deformation  measures Y with error. It also, identifies Luce's conjecture that our understanding of a choice process is enhanced by accounting for the time taken to make it. See also, (Davidson and Marschak, 1958, pg. 1). In fact, we can write  (tk ,  ) = (1 - tk )( f  w  P)( ) + tk Y ( )
(n) (n) (n)

(3.2)

which plainly show that  is an intermediate map5 between stochastic choice f  w  P, and outcome Y ( ) for "time" evolution tk .
we should write f  (w  P)(t ,  ) as the intermediate map at "time" t . However, it is notationally cumbersome. 5 See (Allgower and Georg, 1994, pp. 77-80) for numerical implementation of this algorithm
4 Technically,

(n)

8

3.2

Psychological distance and stopped behavioral processes Due to measurement error or otherwise, the homotopy process is "stopped"

by a subject before the choice deformation process is completed. So we want to measure the closeness of the stopped process to the target Y ( ). According to (Nosofsky, 1997, pg. 348) there exist a psychological distance6 between  and Y which, in our case, can be represented by the metric  ( , Y ) = sup | (tk ,  ) - Y ( )|
1k2n (n)

(3.3)

This gives rise to the stopping time   = inf{t > 0; | (t ,  ) - Y ( )| >  ( (·)}

(3.4)

Nosofsky (1997); Nosofsky and Palmeri (1997) also report that   0 as follows7 . For instance, they show that the similarity or proximity of the two functions8 is an exponential decay of their distance as follows  ( ) = exp(-c )
6 Recall

(3.5)

that f  w  P Y . Nosofsky used a weighted Euclidean distance function which, in the context of our n (n) 2 1 model, is written as  ( , f ) = (2 j=1 w j | (tk ,  ) - f | ) 2 , where w j is the attention weight given to distance. See also, Massa and Simonov (2005) who used a similar metric based on conditional variance from a Kalman filter of agents learning about stock prices. For instance, they posit Xt +1 = AXt + ut and Rt = BXt + vt , where Xt is the state of the economy at time t , Rt is a vector of portfolio returns, and LUt = var[Xt +1 |R1 , · · · , Rt ] is the "learning" metric. Inasmuch as our agents probability weights are included in the composite function f  w  P we exclude w j . Cf. Dawes (1979). Also, in keeping with standard metric in function space we used a sup-norm. 7 (Norman, 1968, pg. 63) describes  as a distance diminishing function. 8 Nosofsky used distance between exemplars i, j and used i j subscript notation. Our distance  is functionally equivalent to their di j distance notation.

9

for some constant c. They let M j be the strength of conviction for a given choice where i, j  { , Y }, so that the degree to which, say, choice j is preferred is

a j ( ) = M j  ( )

(3.6)

They also posit that the probability that the choice j is made at time t is given by

f (t ) = a j ( ) exp(-a j ( )t ) (Baucells and Heukamp, 2009, pg.

(3.7)

3) introduced a probabiliity time depen-

dent model ("PTT") by adding a probability dimension to an outcome space domain. They argue that probability and time are nonseperable such that an expected value function V (x, p, t ) is time dependent through time dependent probability. Further, they characterized the 'total psychological distance" a = z + r(x)t where z = - ln( p), r(x)" is a "fade rate", and t is time. Op. cit. pp. 11, 14. Given a psychological distance function d (·), they proposed a density function f (a) = exp(-d (a)). In the context of out parametrization, their density function is f ( , t ) = exp(- (z + r(x)t ))

(3.8)

where

z = - ln( p), ; r(x) is a "fade rate" and t is time
10

(3.9)

Those parametrizations above seem to be fairly standard in the quantitative psychology literature on learning. See e.g., Norman (1968). In our case, we modify Nosofsky and Palmeri (1997) time based density to space time ( , t ) by adding a space dimension  . Let 0    M < . For the purpose of exposition, let a j ( ) =  . So that f ( , t ) =  exp(- t ). For our Lebesgue density f ( , t ) we need the following normalization
M 0 0 

f ( , t )d  dt = 1 f ( , t ) =

 exp(- t ) M

(3.10)

where 0    M < . Let

 = Pr{| (t ,  ) - Y ( )| >  ( )}  = 1 - Pr{| (t ,  ) - Y ( )| >  ( )}

(3.11) (3.12)

Integration by parts shows that for  ( ) =  > 0, the probability of the intermediate homotopy sample path process being stopped is Pr{| (t ,  ) - Y ( )| >  } =
 1 1-  exp(- t )d  (3.13) M 0 1  1 = 1 + exp(- t ) - 2 (1 - exp(- t ) M t t

(3.14) For small  , after some elementary algebra, that quantity reduces to 1 (1 -  2 ) M
11

Pr{| (t ,  ) - Y ( )| >  } =

(3.15)

Despite our [nonseperable] space-time modification of probability density in Equation 3.10, the probability Pr{| (t ,  ) - Y ( )| >  } = pendent9 . In fact, we have the following Proposition 3.1.  (t ,  ) is well defined for small probabilities. Proof. Dudley (1967) introduced a class of probability metrics that diminishes with distance. For instance, 2 2 Pr{| - µ |   }  2 exp(- 2L2 )  2(1 - 2 ) 2L
1 2 M (1 -  )

is not time de-

(3.16)

where  is a Lipschitz continuous function with Lipschitz constant L, P is a Gaussian measure, and µ is measure of location such as the mean or median of  . See e.g., (Massart, 1998, pg. 1), and Talagrand (2005) for a review and extensions. Since the behavioral process  (t ,  ) must satisfy Kolmmogov's continuity criterion, see (Karatzas and Shreve, 1991, pg. 53), it must satisfy the stronger Lipschitz condition. Thus, after elementary algebra, from Equation 3.16 we get
2 1 2- M 1 L2 1 -M

 =
1

(3.17)

Since  2 > 0 this reduces to L < |M | 2 . Which implies | (t ,  ) -  (s,  )|  |M | 2 |s - t | < M (s - t )2
9 This

1

(3.18)

result implicates Baucells and Heukamp (2009) and our space-time probability density for small probabilities. It implies that our space time probability density function is slow varying in time. In fact, for any small  , that probability is zero only if M  : an absurdity.

12

Thus,  is a well defined process that satisfies Kolmogorov's continuity criterion.

Thus, the probability  of the process being stopped is uniform across time. If  , is large, then the probability of it not being stopped,  = 1 -  , is small. Under CPT, subjects overweigh  with w( ) and underweigh  with w( ) provided  < pe <  . So even though  (t    ,  ) is a stopped stochastic choice process with probability  of being stopped before attaining the goal Y ( ), agents underestimate that process with distorted probability w( ). These de facto statistical inference about stochastic choice functions show that even Type I and Type II error are subject to distortion. For subjects tend to accept a stochastic choice process when they should reject it,, and vice versa. The foregoimg analysis gives rise to the following Proposition 3.2. Let f ( , t ) =
 exp(- t ) M

be a space-time probability density func-

tion, with psychological distance  , where 0    M < ; 0  t  , and   = inf{t > 0; | (t ,  ) - Y ( )| >  ( )} be a stopping time for the stochastic choice process  , where  ( )  0. Then for any small  the process is uniformly stopped with probability  =
1 2 M (1 -  ).

In addition to the foregoing, the following corollary is motivated by (Shao, 2007, pp. 129-131).

13

Corollary 3.3. Let C(Y ( )) = { | | (·) - Y ( )|   } be a confidence set for a sampled lottery Y ( ), and w(·) be a probability weighting function. H0 :  (t ,  ) = Y ( ) be the null hypothesis being tested against the alternative Ha :  (t ,  ) = Y ( ). So that Pr{  / C(Y )}   . Let  small be the objective probability of Type I error­H0 is rejected when it is true, given the realized sample path   . Then the subjective probability of Type I error is given by w( ) >  , and vice versa for Type II error.
3.2.1 Behavioral submartingale processes

In this section we show how the stochastic choice problem evolves by and through intermediate homotopic maps, and construct a behavioral submartingale process for fair lotteries. As a preliminary matter, we have the following Proposition 3.4. The process  = { (tk ,  ), Ft (n) ; 1  k  2n < } is well dek

(n)

fined. Proof. In proposition 3.1 we showed that  is well defined for small probabilities. Now we extend that definition to stopping times. From Equation 3.2, we use the stopped behavioral hypothesis as follows. sup  (tk    ,  ) - Y ( ) = sup(1 - tk    ) | f  w  P - Y ( )|
k k (n) (n)

(3.19) (3.20)

 (1 -   )( +  ) > 

14

for some  > 0 so that  <1  +

 < 1 -

(3.21)

The latter relation is true for all  > 0. Hence the proof is done. Definition 3.3. Let H be the convex hull of homotopic maps in the commutative map in Figure 1. Then H = {  (1 - tk ) f  w  P + tk Y | Y  X , and f  w  P  X }
k=1 2n (n) (n)

(3.22)

At this point we introduce the following Lemma 3.5. If agents rank order outcomes x(1) , x(2) , . . . , x(n) , then they rank order gambles [or lotteries] Y(1) , Y(2) , . . . , Y(n) . Proof. The proof is by induction. Let Y1 (x1 , p1 ; 0, 1 - p1 ) be a simple lottery in

X × P. In what follows we suppress 0, 1 - p. Let
n times n times

Yn

{(x1 , p1 ), (x2 , p2 ), . . . , (xn , pn )}  X × · · · × X × P × · · · × P

(3.23)

be a lottery. Let

Y2

{(x1 , p1 ); (x2 , p2 )}  X × X × P × P

(3.24)

be another lottery. According to CPT agents rank order outcomes when formulating decisions under risk and uncertainty. So that if outcomes in Y2 are ranked
15

we write Y(2)

{(x(1) , p1 ); (x(2) , p2 )}. It is clear that Y(2)

Y(1)  {(x(2) , p2 )}.

Since the recursive ranked outcome-lottery relation holds for Y(1) and Y(2) , it holds for ranked lotteries Y(1) , Y(2) , . . . , Y(n-1)  x(1) , x(2) , . . . , x(n-1) , and by induction Y(n) = Y(n-1)  {(x(n) , pn )}. Remark 3.1. According to this result, a gamble or lottery is an outcome with its own probability of winning or losing. Implicit in that statement is compound invariance by Prelec (1998) or the weaker reduction invariance by Luce (2001). Lemma 3.6. { (tk ,  )}2 k=1 is a monotone [increasing] sequence of homotopic maps. Proof. By definition  (tk ,  ) is in the convex hull H . Since (Prelec, 1998, pg. 498) showed that for any probability measure P, the inverted S-shape of
(n) (n)
n

w(P) intersects the diagonal inclined at 45% to the horizontal at a fixed point
1 approximately p = 3 ; let pe be the fixed point of w( p) = p, and fix f  w  pe =

 ( pe ). So that  (tk ,  ) =  ( pe ) + tk (Y ( ) -  ( pe )) is a parametric curve in tk starting at the fixed point  ( pe ). Let (Y1 , Y2 , . . . , Y2n ) be a sequence of lotteries in Y (). According to Lemma 3.5, if agents rank order outomes, then they rank order lotteries a fortiori. Put  (tk ,  ) in 1-1 correspondence with a rank ordered lottery sequence Y(1) , Y(2) , . . . , Y(2n ) . So that we have a coordinate map  (tk ,  ) = Y(2n -k+1) ( ). By construction  (tk ,  )  H is a parametric curve, i.e., a Peano curve, mapping I into the plane, see (Guggenheimer, 1977, pp. 1,3), so each point on its locus is unique and increasing in k. Thus,  (tk ,  ) is monotone
16
(n) (n) (n) (n) (n)

(n)

(n)

increasing in ranked lotteries. Theorem 3.7 (Doob's Optional Sampling Theorem). (Karlin and Taylor, 1975, pg. 259); (Doob, 1953, pp. 302-303). Let {Yn , Fn ; n  0} be a martingale on the filtered probability space (, F , Fn , P), where F =
n0 Fn .

Let  ( ) be a

stopping time. If Pr{ ( ) < } = 1 and E [supn |Y n |] < , then E [Y ] = E [Y0 ].

Theorem 3.8 (Doob-Meyer Decomposition). (Grimmett and Stirzaker, 2001, pg. 474); (Dellacherie and Meyer, 1982, pg. 7). A submartingale {n , Fn ; n  0} with E [n ] <  may be uniquely expressed in the form: n = Yn + n (3.25)

where {Yn , Fn ; n  0} is a martingale, and {n , Fn ; n  0} is a previsible process.

Theorem 3.9. Let {Yn , Fn ; n  1} be a fair gamble or lottery, i.e., a martingale. Then { (tk ,  ), Fn ; n  1} is a submartingale, and {- (tk ,  )} is a previsible increasing process. Proof. The proof rests on Doob-Meyer decomposition in Theorem 3.8. By hypothesis Yn is a martingale. Additionally by Lemma 3.6  is an increasing sequence. Thus, E [ (tk ,  )| Ft (n) ]   (tk-1 ). However, under Doob's Optional
k-1

(n)

(n)

(n)

(n)

17

Sampling Theorem in Theorem 3.7 and Equation 3.1 above E [ (tk ,  )| Ft (n) ] = E [Y ( )| Ft (n) ] + E [ (tk ,  )| Ft (n) ]
k-1 k-1 k-1

(n)

(n)

(3.26) = Y0 + E [ (tk ,  )| Ft (n) ]   (tk-1 ,  )
k-1

(n)

(n)

(3.27) where Y0 is the fair payoff for the lottery. Subtract  (tk-1 ,  ) from both sides of the inequality to get from equation (3.1) E [ (tk ,  )| Ft (n) ] -  (tk-1 ,  )   (tk-1 ,  ) - Y0 -  (tk-1 ,  )
k-1

(n)

(n)

(n)

(n)

(n)

(3.28) (3.29)

=  (tk-1 ,  ) -  (tk-1 ,  ) = 0 Hence E [ (tk ,  )| Ft (n) ]   (tk-1 ,  )
k-1

(n)

(n)

(n)

(n)

(3.30)

For internal consistency with the stopped process in Proposition 3.2 we must have
(n) (n)

- (tk ,  ) =  (tk ,  ). In which case we have a previsible increasing process.

(3.31)

18

4

Applications to Fair Gambles
In this section we apply some of the results above to subjects' response(s)

~ be the subjective to gambles. Let E be the objective expectations operator, and E expectations operator. The homotopic lifting property posits
(n) (n)

 (tk ,  ) = Y ( ) +  (tk ,  ) and that

(4.1)

 (t ,  )  0 in t

(4.2)

So that
(n) (n)

P - lim ( (tk ,  ) - Y ( )) = P - lim  (tk ,  ) = 0
n,k n,k

(4.3)

So that for fair gambles Y ( ), under Doob's Optional Sampling Theorem

E [ (·,  )] = E [Y ( )] = Y0 Choose  sufficiently large so that the probability
1 2 M (1 -  )

(4.4)

is small. (Berger,

1985, pp. 49-50) and (DeGroot, 1970, pp. 90-91) posited a set of "rationality axioms" for construction of utility functions for preferences over probability distributions, in which probability measures are discrete. Thus, in what follows we

19

use discretized probabilities. Also, Prospect Theory tells us that, generally, subjects overweigh small probabilities and underweigh large probabilities10 . So that for Pr{| (tk ,  ) - Y ( )| >  } = Let
(n) (n)

1 (1 -  2 ) M

(4.5)

Pr{ (tk ,  ) < Y ( ) -  } =  Pr{ (tk ,  ) > Y ( ) +  } =
(n)

(4.6) (4.7)

1 (1 -  2 ) -  M

Since all probabilities are small, the probability weighting function w implies

w( ) >  w( 1 1 (1 -  2 ) -  ) > (1 -  2 ) -  M M

(4.8) (4.9)

By abuse of notation, assume that  (  ,  ) =  (  ). In that setup the [unconditional] subjective expected value for the random variable  (  ,  ) is given by ~ [ (  ,  )] = - (  )w( ) +  (  )w( 1 (1 -  2 ) -  ) (4.10) E M 1 =  (  )[w( (1 -  2 ) -  ) - w( )] (4.11) M
(2008) provided comparative statics of CPT which shows that the probability over[under]weighting feature can be violated.
10 Ingersoll

20

For losses and gains g, let

w( ) =  +  ,  > 0 w( 1 1 (1 -  2 ) -  ) = (1 -  2 ) -  + g , g > 0 M M

(4.12) (4.13)

Upon further reduction we get ~ [ (  ,  )] =  (  )[ 1 (1 -  2 ) + g -  - 2 ] E M

(4.14)

By the same token, the unconditional objective expected value of the same random variable is 1 (1 -  2 )] M

E [ (  ,  )] =  (  )[

(4.15)

Comparison of the expected values in equations (4.14) and (4.15) show that the quantity g -  - 2 is dispositive of a subject's perception of the underlying gamble.

4.1

Case i. Submartingale behavior for fair gambles

Assume that g -  - 2 > 0. Thus, the unconditional subjective expected value is greater than the unconditional objective expected value. ~ [ (  ,  )] > E [ (  ,  )] E

(4.16)

21

So that for any information set Ft (n) we have
k-1

~ [E ~ [ (  ,  )| F (n) ]] > E [E [ (t (n)    ,  )| F (n) ]] E k-1 t t
k-1 k-1

(4.17) (4.18) (4.19)

~ [ (  ,  )| F (n) ] > E [ (t    ,  )| F (n) ] E k-1 t t
k-1 k-1

(n)

=  (tk-1 )

(n)

So that for the stopped behavioral process, by virtue of Doob's Optional Sampling Theorem, we get ~ [ (t (n)    )| F (n) ] = E ~ [Y ( )| F (n) ] + E ~ [ (t (n)    ,  )| F (n) ] E k k t t t
k-1 k-1 k-1

(4.20)

~ [Y ( )| F (n) ] = Y0 under Since subjects know that the gamble Y ( ) is fair, E t
k-1

Doob's Optional Sampling. So that in collaboration with equation (4.19) we get ~ [ (t (n)    )| F (n) ] > Y0 +  (t (n)    ) E k k-1 t
k-1

(4.21) (4.22)

=  (tk-1    )

(n)

Thus, the stopped behavioral process is a [strong] submartingale. The foregoing results are summarized in the following Proposition 4.1. Let (, F , {Ft }, P) b a filtered probability space with discretized right continuous filtration Ft (n)  Ft (n) · · ·  Ft (n) . Let S be state space, and
0 1 2n

Y be a fair gamble defined on Omega and taking values in outcome space X. Let f  w  P be a composite stochastic choice function defined on S × . Let
22

{ (tk ,  ), Ft (n) ; k = 1, 2 · · · , 2n } be a discretized behavior mimicking homotopic
k

(n)

sample path for deformation of stochastic choice into lotteries so that
(n) (n)

 (tk ,  ) = Y ( ) +  (tk ,  )
(n) ~ be the subjective expectations opwhere  (tk ,  ) is measurement error. Let E

erator for a subject taking a gamble Y ( ), and E be the corresponding objective ~ and P defined on expectations operator, respectively, for probability measures P ~ > P. Furthermore, define the stopping time . Let P   = inf{t  0| | (tk ,  ) - Y ( )| >  },
(n)

k = 1, 2, · · · , 2n (4.23)

Then ~ [ (t (n)    ,  )| F (n) ] > E [ (t (n)    ,  )| F (n) ] E k k t t
k-1 k-1

(4.24) (4.25)

=  (tk-1    ,  ) is a submartingale.

(n)

4.2

Case ii. Supermartingale behavior for fair gambles In this scenario, g -  - 2 < 0, i.e. the inequality in equations (4.21) and

(4.22) is reversed, and we have a [strrong] supermartingale situation. Now subjects tend not to gamble for sufficiently large deviations from the fair gamble that occur
23

with small probability. That is the behavior mimicking  -homotopy is the range of admissible behavior. Subjects are risk averse, and evidently have strong loss aversion.

4.3

Case iii. Probability leakage for fair gambles The interesting case here is when g -  - 2 = 0. Presumably there is

1 no probability weighting because now w( M (1 -  2 )) =

1 2 M (1 -  )

we are in a

world of classic von Neuman-Morgenstern utility. Subjects know that the gamble is a martingale. So expectaions for the stopped behavioral process coincide ~ [ (t (n)    ,  )| ·] = E [ (t (n)    ,  )| ·]. However, the behavioral process was E k k stopped with probability
1 2 M (1 -  )

before the behavior mimicking homotopic

sample path was completely deformed into the fair gamble. Additionally, in the space-time density in equation (3.10), max  = M . So for a fair gamble we expect psychological distance  to be uniformly distributed with probability
1 M

over the

interval11 . Since subjects have "martingale beliefs", they arguably assign equal probability to winning or loosing at a given play of the gamble. In that case, the corresponding conditional probability of winning [or losing] is given by Pr{Winner| Fair gamble} =
1 2 2M (1 -  ) 1 M

(4.26) (4.27)

1 = (1 -  2 ) 2
11 This

1 is an heuristic assumption motivated by Equation 3.14. There, as t  , Pr{ (·) >  } = M . Evidently, in the long run, the marginal distribution of the metric  coincides with that of the fair gamble Y ( ). Here "fair" means 1 each player has the same chance of winning. So that instead of 1 2 we assign a "martingale measure" of M uniformly to simplify computation without loss of generality.

24

Thus, the subject's chances of winning [or losing] is less than 1 2 . In fact, the total probability of winning or loosing in this case is 1 -  2 < 1. The probability leakage of  2 induces a subprobability measure on the decision space. To compensate for this probability leakage subjects may have to renormalize the space-time probability density in equation (3.10) by replacing M with M (1 -  2 ). In that case,   0  max  = M . Perhaps most important, the subprobability feature implies that subjects assign asymmetric weights for martingales. To see this, in the scenario just described above, instead of a fair coin for deciding to gamble, let  be the weight assigned to losing, and  be the weight assigned to winning. So that now the conditional probabilities of loosing and winning is, respectively,  (1 -  2 ) and  (1 -  2 ). The total probability associated with this event is ( +  )(1 -  2 ). That quantity is equal to 1 if ( +  ) = (1 -  2 )-1 . Since 0 <  < 1,  +  overweighs probabilities of winning or losing. This result is consistent with Tversky and Khaneman (1992) Cumulative Prospect Theory. However, here it was introduced in a fair gamble in which agents have von Neuman-Morgenstern beliefs12 . Therefore, our behavior mimicking homotopy sample path is able to produce probability weighting for modified Nosofsky and Palmeri (1997) space-time probability densities. We summarize this result with the following Proposition 4.2. Let f ( , t ) be a space-time probability density function for psychological distance  . Let Y ( ) be a fair gamble. Assume that subjects have von
the catalytic relation w( p) = p implies a fixed point instead of a transformation of w( p) into p. In which case the result is an artifact of coincidence.
12 Arguably,

25

Neuman-Morgenstern preferences over probability distributions. Let  (tk    ) be a stopped behavior sample path. Assume that subjects know that Y ( ) is a fair gamble, so that for  > 0 small Pr{| - Y |   } = 1 (1 -  2 ) M

(n)

Then  2 is probability leakage, and (1 -  2 )-1 is the compensating probability weight.

5

Conclusion
In this paper we augment Tversky and Khaneman (1992) Cumulative Prospect

Theory's function space with: 1) a direct mapping from "states of nature", distorted by probability weighting, to state space; and 2) a mapping of lotteries from "states of nature" to outcome space. We show that a commutative map of that augmentation supports an  -homotopy lifting property whereby composite stochastic choice functions are deformed into outcomes [or gambles]. Due to measurement error or otherwise,  -homotopy sample paths are behavior mimicking processes which are uniformly stopped by subjects' behavior before the deformation goal is reached. Moreover, we identify conditions under which subjects exhibit submartingale, supermartingale, and probability leakage in response to fair gambles. Our results show that the commutative prospect space provides a rich topology for further research on construction of abstract behavioral stochastic processes that
26

enhance our understanding of experimental results.

27

References
Allgower, E. and K. Georg (1994, August). Numerical path following. mimeo. Dep't. Math., Colorado State U. Baucells, M. and F. H. Heukamp (2009, June). Probability and time trade-off. http://web.iese.edu/mbaucells/downloads/PTT0622.pdf. Working Paper, IESE Business School, Spain. Berger, J. (1985). Statistical Decision Theory and Bayesian Analysis (2nd ed.). Springer Series in Statistics. New York, N.Y.: Springer-Verlag. Davidson, D. and J. Marschak (1958, July). Experimental tests of stochastic decision theory. Technical Report No. 17, Behavioral Sciences Division, Applied Math and Statistical Laboratory, Stanford Univ. Dawes, R. M. (1979, July). The robust beauty of improper linear models. American Psychologist, 571­582. Debreu, G. (1958). Stochastic choice and cardinal utility. Econometrica 26, 440­ 444. DeGroot, M. (1970). Optimal Statistical Decisions. New York, N.Y.: McGrawHill, Inc. Dellacherie, C. and P. Meyer (1982). Probabilities and Potential B:Theory of Martingales. Number 72 in North-Holland Mathematical Studies. Amsterdam: North-Holland Publishing, Co. Doob, J. L. (1953). Stochastic Processes. New York, N. Y.: John Wiley & Sons. Dudley, R. M. (1967). The sizes of compact subsets of Hilbert space and continuity of Gaussian process. Journal Functional Analysis 1, 290­330. Gray, B. (1975). Homotopy Theory: An Introduction to Algebraic Topology. New York: Academic Press. Grimmett, G. R. and D. R. Stirzaker (2001). Probability and Random Processes (3rd ed.). Oxford Univ. Press. Guggenheimer, H. W. (1977). Differential Geometry. Mineola, New York: Dover Publications, Inc.
28

Ingersoll, J. E. (2008, June). Non-monotonicity of the Khaneman-Tversky probabiility weighting function: A cautionary note. European Financial Management 14(3), 385­390. Karatzas, I. and S. E. Shreve (1991). Brownian Motion and Stochastic Calculus. Graduate Texts in Mathematics. New York, N.Y.: Springer-Verlag. Karlin, S. and H. M. Taylor (1975). A First Course in Stochastic Processes (2nd ed.). Academic Press. Lefshetz, S. (1942). Algebraic Topology, Volume 27 of Colloquium Publications. Providence, R.I.: Amer. Math. Soc. Lindquist, M. A. and I. W. McKeague (2009). Logistic regression with Brownianlike predictors. Journal of the American Statistical Association 104(488), 1575­ 1585. Luce, D. and L. Narens (2008). Theory of measurement. In L. Blume and S. N. Durlauf (Eds.), Palgrave Dictionary of Economics (2nd ed.). Palgrave Macmillan. Preprint. Luce, R. D. (2001). Reduction invariance and Prelec's weighting functions. Journal of Mathematical Psychology 45, 167­179. Massa, M. and A. Simonov (2005). Is learing a dimension of risk? Journal of Banking and Finance 29, 2605­2632. Massart, P. (1998, November). About the constant in Talagrand's concentration inequalities for empirical processes. mimeo. Dep't. Math., Univ. Paris-Sud. McFadden, D. P. (1974). Frontiers in Econometrics, Chapter IV. Conditional Logit Analysis of Qualitative Choice Behavior, pp. 105­142. New York: Academic Press. Norman, M. F. (1968). Some convergence theorems for stochastic learning models with distance diminishing operators. Journal of Mathematical Psychology 5, 61­101. Nosofsky, R. M. (1997). An exemplar based random walk model of speeded categorization and absolute judgment. In A. A. J. Marley (Ed.), Choices, Decisions, and Measurement, pp. 347­365. New Jersey: Lawrence Erlbaum Associates.
29

Nosofsky, R. M. and T. J. Palmeri (1997). An exemplar based random walk model of speeded classification. Psychological Review 104(2), 266­300. Prelec, D. (1998). The probability weighting function. Econometrica 60, 497­ 528. Shao, J. (2007). Mathematical Statistics (2nd ed.). Springer Texts in Statistics. New York, N.Y.: Springer-Verlag. Steinbacher, M. (2009). Stochastic processes in finance and behavioral finance. http://mpra.ub.uni-muenchen.de/13603/. ICFAI Journal of Behavioral Finance 8(4):6-30. Talagrand, M. (2005). The Generic Chaining: Upper and Lower Bounds for Empirical Processes. New York,N.Y.: Springer-Verlag. Tversky, A. and D. Khaneman (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and Uncertainty 5, 297­323. Wickens, T. (1982). Models for Behavior: Stochastic Processes in Psychology. San Francisco, CA: W. H. Freeman & Sons, Inc.

30

