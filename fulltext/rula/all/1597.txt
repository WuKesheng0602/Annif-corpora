Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2004

Study Of Resilient Packet Ring Based On OPNET
Xin Zhang
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Electrical and Computer Engineering Commons Recommended Citation
Zhang, Xin, "Study Of Resilient Packet Ring Based On OPNET" (2004). Theses and dissertations. Paper 1210.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

STUDY OF RESILIENT PACKET RING BASED ON OPNET

by

XinZhang BSc, Beijing United University, Beijing, P.R.China, July 1993

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Applied Science in the Program of Electrical and Computer Engineering

Toronto, Ontario, Canada, 2004
Â© Xin Zhang 2004

PROPlimY OF
RV&RteN U&VfRSlTY L18RARV

AUTHOR'S DECLARATION

I hereby declare that I am the sole author of this thesis.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorized Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

11

BORROWER'S PAGE

Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

111

ABSTRACT
Study of Resilient Packet Ring Based on OPNET Master of Applied Science, 2004 Xin Zhang Department of Electrical and Computer Engineering Ryerson University

Resilient Packet Ring (RPR) is the next generation layer-2 protocol optimized for transporting data traffic rather than circuit-based traffic. In this thesis, we design and evaluate our own RPR simulation model that is fully compliant with the latest proposal promoted by IEEE 802.17 Work Group.

By using this model, we investigate the limitations of the fairness control algorithms proposed by IEEE 802.17 WG. An alternative design, namely, Fuzzy Logic Control, is considered to overcome the shortcomings. Real world scenarios are simulated using this new approach. The simulation results justify the application of this new RPR model, and support its validity.

Furthermore, by using this model we also derived an equation to calculate Fairness Round Trip Time (FRTT), which is a key parameter in designing an appropriated size for Secondary Transit Queue (STQ) in RPR. This equation overcomes the limitations proposed by IEEE 802.17 Work Group.

IV

ACKNOWLEDGEMENTS

I would like to thank my supervisor, Prof. N. W. Ma, for his continuous intellectual support. His teaching on different protocols has immensely helped me in converting IEEE 802.17 proposal into the computer code.

I would like to thank my co-supervisor, Prof. K. Raahemifar, for his encouragement and moral support. His teaching on OPNET has greatly facilitated the new approach presented in this thesis.

I thank their efforts on helping me turning this project from utopian scheme into reality.

I also thank Hossein Ghandehari, whose endless encouragement on the project made the model finally complete. Furthermore, Hossein first proposed to combine Fuzzy Logic Control (FLC) theory with congestion detection and use it as an alternative to the IEEE 802.17 proposed algorithms. Without his 1'hitiation, there won't be FLC algorithm in this model.

I would like to thank Gary Yip for his participation in this project. His help was an integral part of this project. Arseny Taranenko, System Administrator in Network Research Lab, at Ryerson University, was a great facilitator in providing technica~ helps on OPNET.

v

DEDICATION
This thesis is dedicated to my wife, and my parents. Their support in this thesis was without doubt instrumental.

Vl

TABLE OF CONTENTS

Chapter 1: Introduction ....................................................................................................... 1 1.1 An Overview of Resilient Packet Ring ..................................................................... 2 1.1.1 Topology ofRPR ............................................................................................... 2 1.1.2 Resiliency in RPR .............................................................................................. 3 1.1.3 Bandwidth Fairness in RPR ............................................................................... 3 1.1.4 Quality of Service (QoS) in RPR ....................................................................... 4 1.1.5 Classes of Service in RPR .................................................................................. 5 1.1.6 Broadcast or Multicast Traffic in RPR .............................................................. 8 1.1.7 Advantages ofRPR over SONET/SDH and Ethernet ....................................... 8 1.2 Contributions .......................................................................................................... 10 1.2.1 Developing RPR Model in OPNET ................................................................. 11 1.2.2 Developing An Alternative Traffic Control Algorithm - Fuzzy Logic Control ................................................................................................................................... 12 1.2.3 Devised Equations For The Upper Bound Of Minimal STQ Size ................... 12 1.3 Thesis Overview ............................................................................................. ~ ....... 13 Chapter 2: The In-House Version Of RPR Model. ........................................................... 14 2.1 The Design of the In-House RPR Model. ............................................................... 14 2.1.1 The Model: Internal Components and Their Functionality ............................. 15 2.1.2 OPNET Node Attributes .................................................................................. 22 2.2 OPNET Link Model ................................................................................................ 25 2.3 Frame Format .......................................................................................................... 26 2.3.1 Frame Header ................................................................................................... 26 2.3.2 BaseControl Field ............................................................................................ 27 2.3.3 Data Frame Format .......................................................................................... 28 2.3.4 Control Frame Format ...................................................................................... 28 2.3.5 Fairness Frame Format .................................................................................... 29 2.4 RPR Protocol Suite ................................................................................................. 29 2.4.1 Topology Discovery Protocol .......................................................................... 29 2.4.2 Ringlet Selection Protocol ............................................................................... 31 2.4.3 RPR Fairness Algorithm (RPR-fa) .................................................................. 31 2.4.4 Traffic Rate Control Protocol .......................................................................... 34 2.5 Verification ............................................................................................................. 46 2.5.1 Scenario 1- Verify Fairness Algorithm .......................................................... 46 2.5.2 Scenario 2- Verify Spatial Reuse ................................................................... 49 Chapter 3: Fuzzy Logic Control .......................~ .............................................................. 52

Vll

3.1 Introduction ............................................................................................................. 52 3.1.1 The Architecture Of Traffic Control System ................................................... 54 3 .1.2 Oscillation Analysis ......................................................................................... 56 3.1.3 Design Task ..................................................................................................... 56 3.2 Implementation of Fuzzy Logic Control in RPR .................................................... 57 3.2.1 Overview .......................................................................................................... 57 3.2.2 Architecture ofFLC ......................................................................................... 57 3.2.3 Membership Function (MF) ............................................................................. 59 3.2.4 If-Then Rules and Defuzzify ........................................................................... 61 3.3 Case Study .............................................................................................................. 63 3.3.1 Scenario 1- 16 Nodes Simple Sourced Traffic Scenario ................................ 64 3.3 .2 Scenario 2 - Parking Lot Scenario ................................................................... 66 3.3.3 Scenario 3- Multi-Chock Parking Lot Scenario ............................................. 68 3.4 Conclusion .............................................................................................................. 70 Chapter 4: Fairness Round Trip Time (FRTT) And The Size Of STQ ............................ 71 4.1 Bandwidth Reclaimable Characteristic Of ClassA 1 Traffic ................................... 71 4.2 FRTT ....................................................................................................................... 72 4.2.1 The Upper Bound OfFRTT1 ........................................................................... 73 4.2.2 The Upper Bound OfFRTT2 ........................................................................... 74 4.2.3 Upper Bound OfFRTT- MAX(FRTT) .......................................................... 77 4.3 The Minimal Size Of STQ ...................................................................................... 77 4.4 Simulation ............................................................................................................... 79 4.4.1 Scenario 1 -Verify FRTT1 ......................................................................... :... 80 4.4.2 Scenario 2- Verify Tstq With Constant Traffic ................................................ 81 4.4.3 Scenario 3 -Verify Tstq With Bursty Traffic ................................................... 84 4.4.4 Scenario 4- Verify FRTT ............................................................................... 85 4.4.5 Scenario 5 -Verify STQ Size .......................................................................... 86 Chapter 5: Conclusion and Future Work .......................................................................... 89 5.1 Conclusion .............................................................................................................. 89 5 .1.1 Design and Implementation of the Simulation Model. .................................... 89 5.1.2 Fuzzy Logic Control ........................................................................................ 89 5.1.3 FRTT And The Minimal Size Of STQ ............................................................ 90 5.2 Future Work ............................................................................................................ 90 5.2.1 Ring Protection ................................................................................................ 90 5.2.2 Improvement of Fuzzy Logic Control ............................................................. 90 5.2.3 Improvement ofQoS Control .......................................................................... 91 5.2.4 Improvement ofFRTT ..................................................................................... 91 5.2.5 Improvement of Fairness Algorithm ................................................................ 91

viii-

Appendix A: Building Topology Database ....................................................................... 93 Appendix B: Implement ofFLC inC Language .............................................................. 96 B.l Sample C Codes Of Membership Function ........................................................ 96 B.2 Sample C Code Of If-Then Rule ........................................................................ 97 B.3 The Sample C Code OfDefuzzify ..................................................................... 99 B.4 The Sample C Code Of Fuzzy Logic Control .................................................... 99 Reference ........................................................................................................................ 102

IX

LIST OF TABLES

Table 1.1: Service Classes .......................................................................... 7 Table 2.1: Node Configuration Attributes ................... ................................... 23 Table 2.2: Fairness Parameters ................................................................... 24 Table 2.3: Station Address Parameters .......................................................... 25 Table 2.4: RPR Non-Fairness Frame Header Format .......................................... 26 Table 2.5: RPR Fairness Frame Header Format ................................................ 27 Table 2.6: BaseControl Field ..................................................................... 27 Table 2.7: RPR Data Frame Format ............................................................. 28 Table 2.8: RPR Data Frame Format ...... . ...................................................... 28 Table 2.9: RPR Fairness Frame Format ............................................ ............. 29 Table 2.10: A Sample Topology Database ...................................................... 30 Table 2.11: shaperM parameters ............................................................... .40 Table 2.12: shaperAO parameters ............................................................... .41 Table 2.13: shaperA1 parameters .............................................................. .42 Table 2.14: shaperB parameters ....................................... . ........................ .43 Table 2.15: shaperC parameters ................................................................. 44 Table 2.16: shaperD parameters ................................................................ .45 Table 3.1: If-Then Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . 61 Table 4.1: Traffic Generation Pattern .......................................................... 80 Table 4.2: Simulation Result ofFRTT1 ....................................................... 81 Table 4.3: Traffic Generation Pattern ........................................................... 82 Table 4.4: Scenario Result of Constant Traffic In Each STQ ...... . ........................
8~

Table 4.5: Traffic Generation Pattern Of Scenario 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . 84 Table 4.6: Scenario Result of Bursty Traffic In Each STQ .......................... ....... 85 Table 4.7: Maximal STQ Depth In Each Node Of Scenario 5 ............................. 88

X

LIST OF ILLUSTRATIONS

Figure 1.1 : Resilient Packet Ring ................................................................. 2 Figure 1.2: Recovery From a Fiber Cut ......................................................... 3 Figure 2.1: Our RPR OPNET Model ........................................................... 15 Figure 2.2: Magnified Model .................................................................... 16 Figure 2.3: Token Bucket Traffic Shaper ...................................................... 36 Figure 2.4: RPR Token Bucket Traffic Shaper ................................................ 38 Figure 2.5: Enlarged Rate Control Unit ......................................................... 39 Figure 2.6: Verify Fairness Algorithm ......................................................... 46 Figure 2. 7: Simulation Result of SRP Model .................................................. 47 Figure 2.8: Simulation Result of Our Node in Conservative Mode ....................... 48 Figure 2.9: Simulation Result of Our Node in Aggressive Mode .......................... 49 Figure 2.10: Verify Spatial Reuse ............................................................... 50 Figure 2.11: Simulation Result of Our Model in Conservative Mode ..................... 50 Figure 2.12: Simulation Result of Our Model in Aggressive Mode ........................ 51 Figure 3.1: Multi Sourced Traffic ............................................................... 52 Figure 3.2: Throughput of Node 1 at a Constant Rate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . 53 Figure 3.3a: Throughput of Node 1 ............................................................ 54 Figure 3.3b: Throughput of Node 16 ........................................................... 54 Figure 3.4: Simplified Architecture of the Traffic Control System ........................ 55 Figure 3.5: An Outlined Process ofFLC ...................................................... 57 Figure 3.6: Traffic Control System With FLC ................................................. 58 Figure 3.7: Triangle Membership Function (trimf) of add_rate ............................ 59 Figure 3.8 Triangle Membership Function (trimf) of ~add_rate ............................ 61 Figure 3.9: Comparison oflocal_fair_rate ..................................................... 63 Figure 3.10: 16 Nodes Simple Sourced Traffic Scenario ..................................... 64 Figure 3.11: Simulation Results ofNode 1 and Node 16 in Aggressive Mode .......... 64 Figure 3.12: Simulation Result of Node 1 in Conservative Mode ......................... 65 Figure 3.13: Simulation Results of Node 1 and Node 16 in FLC Mode .................. 66

XI

Figure 3.14: Parking Lot Scenario ............................................................... 67 Figure 3.15: Simulation Results of Parking Lot Scenario in Aggressive Mode .......... 67 Figure 3.16: Simulation Results of Parking Lot Scenario in FLC Mode ................... 68 Figure 3.17: Multi-Chock Parking Lot Scenario ............................................. 69 Figure 3.18: Simulation Results ofMulti-Chock Parking Lot Scenario in Aggressive Mode ................................................................................. 69 Figure 3.19: Simulation Results of Multi-Chock Parking Lot Scenario in FLC Mode .... 70 Figure 4.1: Calculate Upper Bound OfFRTT1 ................................................ 73 Figure 4.2: 17 Nodes Simple Sourced Traffic Scenario ...................................... 80 Figure 4.3: 9 Nodes Simple Sourced Traffic Scenario ...................................... 82 Figure 4.4: 2 Nodes Simple Sourced Traffic Scenario ...................................... 87 Figure 5.1: 2 Nodes High-Low Rate Scenario ............................................... 92 Figure 5.2: Simulation Result of High-Low Rate ............................................ 92

xu

Chapter 1: Introduction

The advent of the Internet ushered in an enormous increase in data traffic across networks. Since 1995, the Internet traffic has doubled every six months or one year, due to an increase in the number of users and the growth of per capita usage. This ratio of growth is expected to continue over the next few years, with the Internet traffic growing to 280 Tbps by the year 2005. The optical fiber seems to play a major role as transmission medium in Metropolitan Area Network (MAN) and Wide Area Network (WAN) to facilitate the additional bandwidth and to adapt the growth.

The advances in optical transmission technology have occurred at a rapid rate. Synchronous Optical Network (SONET) in North America and Synchronous Digital Hierarchy (SDH) in Europe have dominated the backbone of the telephone networks as the only standards for fiber optic digital transmission systems. However, with the blooming of Internet, transporting data traffic takes a significant role in communication networks. Because SONET was originally designed for point-to-point, circuit-switched applications (e.g. voice traffic), and there are many well-known disadvantages of using SONET for transmitting packet-based data traffic, for example, inefficiently managed shared resources, waste of protection bandwidth, excess copies of multicast packets, etc., these made SONET not an ideal solution for scaling metro network to meet the demand. Since SONET/SDH is not optimized to transport packet-based data traffic, Resilient Packet Ring (RPR) offers a solution to integrate multiple services, instead of having data, voice and video delivered over separate parallel networks, and has become a hot topic among the industry and research and educational institutions.

Resilient Packet Ring is an emerging network architecture and technology designed to meet the requirements of packet-based metropolitan area networks. By creating a Media Access Control (MAC) layer protocol for ring networks, RPR attempts to find a fundamental solution to solve the metro bottleneck problems. This new technology is

1

developed to take advantage of existing SONET ring architecture. It allows full capacity utilization of bandwidth by statistically multiplexing data. Also, it provides features such as spatial reuse, fairness access in packet transport and intelligent ring protection.

1.1 An Overview of Resilient Packet Ring
1.1.1 Topology of RPR
Resilient Packet Ring uses a bi-directional dual counter-rotating ring topology. The rings are referred to as "Inner Ring" and "Outer Ring". Both rings are concurrently utilized for transporting data and RPR control packets, thus fully utilizing the total available bandwidth of the rings. Data and control packets flow in the opposite direction, for instance, outer ring traffic-control information is transported in the inner ring to the upstream node and inner ring traffic-control information is transported in the outer ring to the upstream node. RPR control packets handle tasks such as topology discovery, protection switching and bandwidth control, etc. Figure 1.1 shows a RPR ring with four nodes. As one can see the data packet and control packet are flowing in opposite direction.

RPRNode

~
Control Packet

/

OuterRing Inner Ring

Data Packet

Â·

Figure 1.1: Resilient Packet Ring

2

1.1.2 Resiliency in RPR
Packet Rings have a natural resiliency advantage [8]. Ring fail-over is often described as "self-healing" or "automatic recovery." In practice, ring-based transport systems have reliably achieved less than 50ms fail-over periods. A Packet Ring protocol can initiate a "ring wrap" at the nodes surrounding the cut (see Figure 1.2) or packet "steering" by causing the sending node to redirect packets. In either case traffic can reach the original destination by going around the ring in the opposite direction in the event of a fiber cut.
Fiber Cut

Packet

1J1-

Figure 1.2: Recovery From a Fiber Cut

1.1.3 Bandwidth Fairness in RPR
Packet Rings have an inherent advantage for implementing fairness algorithms to regulate bandwidth usage. Ring bandwidth is a shared resource, and is vulnerable to exploitation by individual users or nodes. A fairness algorithm is a mechanism that gives every customer on the ring a "fair" share of the ring bandwidth, ideally without the straitjacket of a provisioned circuit. A ring-level fairness algorithm can and should allocate ring bandwidth as one global resource.

3

Bandwidth policies that can allow maximum ring bandwidth to be utilized between any two nodes when there is no congestion can be implemented without the inflexibility of a fixed circuit-based system like SONET, but with greater effectiveness than point-to-point Ethernet. SONET also implements point-to-point circuits that allocate and reserve a fixed amount of bandwidth for each connection, but lack of flexibility is the problem. Adding or subtracting bandwidth requires manual configuration of new circuits, and the reservation of such circuit wastes bandwidth.

In a network with dynamically changing traffic patterns (which is typical in any packet network), the only way to optimize network utilization without discarding traffic is to have a feedback mechanism built into the network. The feedback mechanism informs the traffic sources of the capacity available on the network so that the sources can adjust the rate at which they inject traffic into the network.

The MAC entity on each node monitors the utilization on its immediate links and makes that information available to all the nodes on the ring. Each node can then either send in more data or throttle back. This efficient use of bandwidth enables RPR rings to scale beyond 95% of their total capacity. Ethernet switches or SONET ADMs have no bandwidth management capabilities and, hence, cannot maximize network utilization.

1.1.4 Quality of Service (QoS) in RPR
Quality of Service (QoS) refers to the capability of a network to provide better service to selected network traffic over various technologies, including Frame Relay, Asynchronous Transfer Mode (ATM), Ethernet and 802.1 networks, SONET, and IP-routed networks that may use any or all of these underlying technologies. The primary goal of QoS is to provide priority including dedicated bandwidth, controlled jitter and latency (required by some real-time and interactive traffic), and improved loss characteristics. Also important is making sure that providing priority for one or more flows does not make other flows

4

fail. QoS technologies provide the fundamental building blocks that are used for future business applications in campus, WAN, and service provider networks [7].

RPR implemented some of the QoS technologies. Traffic is categorized into three classes: ClassA, ClassB and ClassC, as proposed by IEEE 802.17 Work Group, which can be differentiated as different priority traffic, the higher the priority the lower the endto-end delay. RPR has the ability to differentiate between low- and high-priority packets. Just like other quality of service (QoS)-aware system, nodes have the ability to transmit high-priority packets before those of low priority. In addition, RPR nodes also have a transit path, through which packets destined to downstream nodes on the ring flow. With a transit buffer capable of holding multiple packets, RPR nodes have the ability to transmit higher-priority packets while temporarily holding other low-priority packets in the transit buffer. Nodes with smaller transit buffers can use bandwidth-control message to ensure that bandwidth reserved for high-priority services stays available.

As RPR needs to maintain QoS guarantee for service classes, each class of traffic is rate controlled by a shaper with which token bucket algorithm is running, so the traffic won't be sent beyond its predefined rate .. (However the transit traffic is not subject to rate control.) This also has the effect of limiting the strict precedence of transmit decisions so that each service class gets its fair share of transmissions.

1.1.5 Classes of Service in RPR
To provide priority to certain traffic, the traffic must first be identified and (if desired) marked. These two tasks are commonly referred to as classification. As shown in Figure 2.1, mac_intf module in LLC layer accepts upper layer traffic and denotes them as three classes of service, ClassA, ClassB and ClassC. The service classes are explained next.

5

1.1.5.1 Service Class ClassA

ClassA service provides an allocated, guaranteed data rate and a low end-to-end delay and jitter bound. It is marked as high priority traffic. Time sensitive traffic falls into this category, for example, the voice traffic. The low delay is the key index to reflect the quality of the service. Therefore, the lesser the delay the better the service.

MAC further divides this class into two sub classes, subclassAO for reserved bandwidth and subclassA1 for reclaimable bandwidth, as described in Table 1.1. ClassA traffic is not subject to the fairness algorithm at ingress to the ring or when transiting through the ring. ClassA traffic moves through the primary transit path in each node as it propagates around the ring.

1.1.5.2 Service Class ClassB

ClassB service provides an allocated, guaranteed data rate, and bounded end-to-end delay and jitter for the traffic within the allocated rate, and access to additional best effort data transmission that is not allocated, guaranteed, or bounded, and is subject to the fairness algorithm. ClassB service has similarities to ClassA service in that frame transmission rates within the allocated rate profile (known as ClassB committed information rate, or ClassB-CIR) are guaranteed a bounded delay and jitter, although with higher bounds than for ClassA frames, and are not marked as fairness eligible. Traffic within the allocated rate profile is not subject to the fairness algorithm at ingress to the ring or when transiting through nodes on the ring.

ClassB traffic also has similarities to ClassC service in that traffic beyond the allocated rate profile (known as ClassB excess information rate, or ClassB-EIR) is subjected to the fairness algorithm. Fairness eligible frames are counted as part of the RPR fairness algorithm both at ingress to the ring, and while transiting nodes on the ring. ClassB traffic

6

moves through the secondary transit path, regardless of whether the frame marked as fairness eligible or not.

ClassB traffic is marked as medium priority traffic. Traffic not too much sensitive to time falls into this category, for example, the video traffic.

1.1.5.3 Service Class ClassC

ClassC service provides a best-effort traffic service with no allocated or guaranteed data rate and no bounds on end-to-end delay or jitter. ClassC traffic is always subject to the fairness algorithm, and is marked by the MAC as such with the fe bit in the RPR header prior to transmission on the ring. ClassC frames are counted as part of the RPR fairness algorithm both at ingress to the ring, and while transiting nodes on the ring through the secondary transit path. ClassC traffic is marked as low priority traffic. Traffic not sensitive to time falls into this category, for example, the data traffic.

Table 1.1 summarized the properties of each service class:

Class of Serive

Quality of Service

Name ClassA

Example Use real time

Subclass SubclassAO SubclassA1 ClassB CIR ClassB EIR

Guaranteed Bandwidth Bandwidth Delay/Jitter Bandwidth Type Subtype Yes Yes No low Bounded Allocated Allocated Reserved

ClassB near real time ClassC best effort

Unreserved

-

Unbounded Opportunistic

Table 1.1: Service Classes On ingress, ClassA traffic has higher precedence, than, ClassB traffic which has higher precedence than ClassC traffic. On transit, ClassA traffic has higher precedence than ClassB or ClassC traffic. No distinction is made between ClassB and ClassC traffic

7

during transit. Strict precedence on ingress and transit is used to ensure that frames are not reordered within a service class, and to provide the bandwidth guarantee with delay and jitter bounds specified for each service class.

1.1.6 Broadcast or Multicast Traffic in RPR
Packet Rings are a natural fit for broadcast and multicast traffic. As detailed above, for unicast traffic, nodes on a Packet Ring generally have the choice of stripping packets from the ring or forwarding them. However, for a multicast, the nodes can simply receive the packet and forward it, until the source node strips the packet. This makes it possible to multicast or broadcast a packet by sending only one copy around the ring.

1.1.7 Advantages ofRPR over SONET/SDH and Ethernet
Data, rather than voice, dominates today's bandwidth requirements. New services such as IP VPN, voice over IP (VoiP) and digital video are no longer confined within the corporate local-area network (LAN). These applications are placing new requirements on metropolitan-area network (MAN) and wide-area network (WAN) transport. RPR is uniquely positioned to fulfill this bandwidth and feature requirements as networks transition from circuit-dominated, like SONET/SDH, to packet-optimized infrastructures.

1.1.7.1 Disadvantages of SONET/SDH and Ethernet

Historically, separate parallel networks have been used to deploy data, voice and video services. However, it has become more efficient to converge the multiple services over a single network. These converged services typically include committed information rate (CIR) services such as virtual private networks and business Internet access; best-effort, consumer-oriented Internet access; voice-over-Internet-Protocol (VoiP); packet video; and time-division multiplexing (TDM) services.

8

Those services have their own network-performance requirements, which put designers under extreme pressure to accommodate widely varying degrees of latency, bandwidth efficiency, quality-of-service (QoS) and overall reliability and manageability. For metro data networks, SONET and Ethernet have garnered much of the attention, with many fiber rings currently deployed as SONET/SDH networks. Neither technology, however, is optimized for MAN data applications. In the case of SONET/SDH, customer data is transported over a TDM infrastructure back to the provider. The legacy SONET/SDH add-drop multiplexer network offers customer access in the form of DS-0, Tl and T3 interfaces, and sometimes Ethernet. The advantages of SONET/SDH are that it offers good jitter and latency performance, and it is a lossless transport in that packets are delivered from source to destination without any QoS decisions in between. In addition, SONET/SDH uses spare fibers or capacity to provide protection in case of fiber cuts or equipment failures.

To better suit data applications, SONET/SDH has implemented improvements such as virtual concatenation and Link Capacity Adjustment Scheme (LCAS). Nonetheless, with roots as a phone network, it's not the most efficient transport as it creates point-to-point circuits. Also, bandwidth is reserved for every source on the ring, meaning other nodes cannot claim unused bandwidth. SONET/SDH networks can also be expensive, due to multiple layers of equipment such as routers and switches.

For its part, Ethernet is both cheap and ubiquitous, but it's not a carrier-class solution as it provides point-to-point connections: At every hop on the ring, a router or switch processes each packet, which can be time-consuming for large rings. As a result, Ethernet would have trouble meeting the jitter and latency requirements for voice and video.

1.1.7.2 Advantages ofRPR over SONET/SDH and Ethernet

RPR technology is a new Layer 2 protocol for the MAN and WAN that appeals to carriers and service providers seeking to quickly deploy the newer, profitable services. Combining the advantages of SONET and Ethernet, RPR allows the support of the newer

9

services while simultaneously supporting traditional carrier-class features such as resiliency, restoration and QoS.

Standout features of the RPR MAC include a transit path to avoid packet switching, as well as express treatment throughout the network of all marked packets to support jitterand latency-sensitive traffic. Resilience on a par with SONET is achieved with 50-ms protection switching, while bandwidth efficiency is achieved by delivering packet services instead of circuits. Bandwidth management gives the flexibility to oversubscribe the total ring bandwidth with a greater number of users for certain (non-guaranteed) services and temporarily reclaim reserved bandwidth from idle nodes.

RPR utilizes bandwidth traditionally set aside for SONET protection and strips data from the ring when it reaches its destination, leaving spare bandwidth to be reused (spatial reuse). This stripping yields a dramatic increase of the effective bandwidth over the equivalent SONET network. For multicast packets, one packet is circulated to multiple nodes. This is more efficient than the flooding with multiple packets by Ethernet. For reduced latency, RPR uses dual counter-rotating rings (Inner Ring and Outer Ring), each carrying working traffic. To transmit, each node has a topology map to help it choose a ring based on the least-hop count to a destination (or some other cost metric such as distance). Unlike Ethernet rings, each RPR node processes only the packets addressed to it. Other packets quickly transit through the RPR MAC.

RPR networks have the ability to carry multiple services, including jitter- and latencysensitive traffic such as voice and video in addition to Ethernet and Internet Protocol (IP) services. RPR combines the best features of legacy SONET/SDH and Ethernet into one layer to maximize functionality while delivering high quality service.

1.2 Contributions
Contributions made in this thesis are: developing an in-house version of RPR model based on OPNET Modeler, developing an alternative traffic control algorithm -Fuzzy

10

Logic Control (FLC), and deriving equations for Fairness Round Trip Time (FRTT) and the upper bound of minimal Second Transit Queue (STQ) size.

1.2.1 Developing RPR Model in OPNET
RPR is an emerging layer-2 protocol that hasn't been standardized yet, it is still in the research and developing phases among communication network industry and institutions, so there are not too many vendors which intend to manufacture RPR equipments. Those who intend to do have the task of compliance with IEEE 802.17's future standard, as this standard is evolving rather fast. At present time, Cisco has made Spatial Reuse Protocol (SRP) as its RPR counterpart. SRP was implemented at least two years ago. Therefore, the protocol may not comply with the latest IEEE 802.17's development. On the other hand, there is no publicly available, tried-and-tested software code that is fully configurable and workable. For the purpose of the research at Ryerson University, one had to start simulating RPR behavior and to study its performance empty handed. Other requirements such as different features needed for research, and the flexibility of the code made it paramount to create an in-house software code, customizable enough so one can use it as a main platform for the further research on PRR. The first major contribution of this thesis is developing a set of RPR simulation model that are fully compliance with IEEE 802.17 Work Group's most-up-to-date proposal. The model set includes node module, packet modules and link module. They all come with many configurable parameters which allow simulating most of the real world scenarios.

The simulation program we developed is based on OPNET Modeler. OPNET Modeler is a powerful network simulation tool that is used to model communication networks and distributed systems [5]. It provides a comprehensive development environment so the behavior and performance of modeled systems can be easily analyzed and studied. Furthermore, it provides a C-styled language, called proto-C, to allow developers write their own programming codes for media access control (MAC) layer, logical link control (LLC) layer, network layer, and so on to suit to their research and analysis purposes.

11

OPNET was originated from a research group in MIT in the early 1980's and was finally commercialized and incorporated as a company in 1986. Modeler is one of the software developed by OPNET, it is now widely used by most major network equipment manufactures, research and educational institutes, service providers, military and defense department and so on, some of the names are Cisco, AT&T, NASA, University of California- Berkeley, etc.

1.2.2 Developing An Alternative Traffic Control Algorithm - Fuzzy Logic Control
One can realize after extensive study of IEEE 802.17 Work proposal that there are some limitations of fairness algorithms: when the node congested, the throughput of the node often oscillates and it causes the throughput of all the upstream nodes to oscillate too. To overcome it, Fuzzy Logic Control is developed and applied as an alternative. The second contribution in this thesis is to apply Fuzzy Logic to RPR technology and to prove that Fuzzy Logic can be used in controlling traffic in RPR.

1.2.3 Devised Equations For The Upper Bound Of Minimal STQ Size
Fairness Round Trip Time (FRTT) is a key parameter to design the size of Second Transit Queue (STQ), which is used to temporarily hold the low priority traffic while the node is processing high priority traffic. The size of STQ can not be set too small, otherwise the STQ can easily overflows; it can not be set too large, neither, otherwise traffic held in STQ would spend longer time to be processed, thus, delaying the transmission and degrading the quality of services. Optimizing the size of STQ is an interesting and challenge work.

IEEE 802.17 Work Ground proposed an equation to estimate the upper bound of FRTT, however the equation doesn't provide a true upper bound. The third contribution of this thesis is to devise a much more effective upper bound equation for FRTT and to estimate the required STQ size. 12

1.3 Thesis Overview
This thesis is organized as follows: Chapter 2 describes the model designed in the lab, its architecture, properties and functionalities. The model consists of a group of modules. They are the link module, node module and packet modules. Attributes of each of them is discussed in details. The Node module has several layers of components. Packet generators locate at the top layer, they are used to generate different classes of traffic, i.e. ClassA, ClassB and ClassC traffic. The traffic can also be generated in different patterns, for example constant traffic, bursty traffic. MAC module locates at the middle layer and RPR protocol suite is at this layer. It is used to control the bandwidth, detect the congestion, direct traffic, and so on. The majority of the code is written inside this module. Receivers and Transmitters are located at the bottom layer, they are in charge of receiving and transmitting packets from and to the node.

The protocols and algorithms implemented in each model, for example, rate control protocol, fairness algorithm, or traffic shaper, are discussed in details

Chapter 3 presents Fuzzy Logic Control as an alternative algorithm to the current IEEE 802.17 proposed algorithm. We discuss Fuzzy Logic Control is discussed in theory. The Chapter demonstrates why and how FLC can overcome the shortcomings of the existing algorithms. Finally, we compare the results of simulation from FLC algorithm with IEEE 802.17 algorithm are compared.

In Chapter 4, FRTT and minimum STQ size are investigated. To avoid STQ overflow caused by ClassA traffic, an upper bound equation for FRTT is derived and used to determine the minimum STQ size required to prevent overflow.

Chapter 5 concludes the thesis and addresses some of the future plan.

13

Chapter 2: The In-House Version Of RPR Model
A major contribution of this thesis is to design and develop an in-house version of the RPR module in OPNET for research purposes in the Department of Electrical and Computer Networking, at Ryerson. This version adopts IEEE P802.17/Dl.l as the blue print. This chapter discusses this model, what properties it comes with, and what functions it can provide.

2.1 The Design of the In-House RPR Model
The challenge is to design a RPR model with different components in it. Such design should comply with OSI layers to better simulate the real world situations, in other words the different components are located inside different layers, not across. Each component of the model would illustrate a clear picture of what functions they can provide. Another advantage of adopting such design is that each component of the model can be independent from each other: the communication between them is only through the flow of packets, which is the fundamental principle of OSI layers.

Based on the above principle, the in-house RPR OPNET model is designed in four layers. Figure 2.1 illustrates these four layers and their corresponding OSI layers. The upper layer 1 consists of four components: three traffic generators and one traffic sink. Traffic generators would generate ClassA, ClassB and ClassC traffics. These traffics are sent to the lower layer, which is Logical Link Control (LLC) layer. The traffic sinks from LLC layer by the Traffic Sink. Module mac_intf is located in Data Link Layer (DLL) of LLC layer. It marks the received upper layer packets as Data frames and puts source address, destination address and service class to the header of the frames, then, sends it to the lower layer, which is Media Access Control (MAC) layer. Module mac is located in MAC Layer. RPR protocol suite is implemented in this module. Main functions of this
The traffic generators and sink are taken directly from OPNET, because it is unnecessary to spend time writing a different version of program that achieves the same functionality. Same holds true for Receiver and Transmitter modules.
1

14

module include Ring Protection, Topology Discovery, Ringlet Selection, Bandwidth Control, Fairness Algorithm, Spatial Reuse, QoS control, OAM, etc. The bottom layer is the Physical layer, which consists of two sets of receivers and transmitters, one per each ring. Module IRx and ITx are the inner ring receiver and transmitter, respectively; module ORx and OTx are those of the outer ring. Figure 2.1 shows that the two sets of receivers and transmitters operate in opposite direction, which is a characteristic of RPR.

Upper Layer

Logic Link Control

Media Access Control

Physical Layer

OSI Layers

Four Layers in Our RPR OPNET Model

Figure 2.1: Our RPR OPNET Model

2.1.1 The Model: Internal Components and Their Functionality
Figure 2.1 shows a general layout of the RPR model. How each component works and what functions they provide are discussed in this Section. Figure 2.2 is the same as Figure 2.1, except that it is magnified for the purpose of discussion. This Figure shows in more details how each component cooperatively works together to fulfill the commitment that

15

2.1.1.1 Upper Layer Components

Traffic Generator and Traffic Sink are located in the top layer. Traffic Generator can generate different traffic patterns, including constant traffic and bursty traffic, in order to better simulate the real world scenarios. It can generate different traffic classes as well, for example, ClassA, ClassB and ClassC traffics. When the traffic is sent to the lower layer, they are encapsulated by RPR header and trailer and are marked as RPR data frames, therefore the format of the traffic is transparent to RPR, in other words, RPR doesn't care what format the traffic in this layer is.

Traffic rate is controlled by generator's on/off time, packet interarrival time and packet size. For example, if generator's ON time follows exponential(10 ms) rule and OFF time follows exponential (20 ms) rule, packet interarrival time follows exponential (0.115 ms) rule and packet size is 12000 bit, then we have the traffic rate of
R=

12000 0.115x10- 3

X

10 10+20

~34.8Mb

'P

s

tn average.

Traffic Sinker sinks the traffic.

2.1.1.2 LLC Layer Components

Encapsulator and decapsulator are located in the LLC layer. Encapsulator can distinguish different classes of traffic received from the upper layer, encapsulates the traffic with RPR header and trailer and marks the Service Class field according to its class. It also fills the Source Address, Destination Address field and other fields then send the traffic to the lower layer. If the traffic is sent to multiple destinations, encapsulator uses Weighted-Round-Ribbon algorithm to decide what destination address to fill in the destination field in the header. For example, suppose a node sends traffic to node A with Weight value of 1 and to node B with Weight value of 2. Then, in any three time units of

17

filling in destination field and sending traffic to the lower layer, node A gets one time unit and node B gets two time units.

Decapsulator receives the traffic from the lower layer, removes the header and trailer, then, sends the traffic to the upper layer.

2.1.1.3 MAC Layer Components

2.1.1.3.1 Ringlet Selection Unit

After packet is encapsulated, it is sent to Ringlet Selection Unit (RSU) in MAC layer. RSU marks the packet with the proper ringlet id, which depends on how the node is configured. As per Table 2.1, ringlet selection is one of the node configurable attributes, we can set Inner Ring, Outer Ring or Auto Selected as the value to this attribute. If we set it to Inner Ring, then the ringlet id field in the header of all the packets received from the upper layer is changed to 0. From then on until it reaches its destination it flows in Inner Ring and is processed only by the Inner Ring Receiver and Transmitter. This way an Inner Ring packet does not mess up with Outer Ring packets or vice versa. However if we set to Auto Select, RSU runs Ringlet Selection Protocol to decide which ringlet id to change to. Ringlet Selection Protocol is explained in details in the next section.

After the ringlet id field in the header is changed, RSU sends the packet to High-Priority Transmit Queue (HP-TmQ), Medium-Priority Transmit Queue (MP-TmQ) or LowPriority Transmit Queue (LP-TmQ), depending on which class of traffic the packet belongs to, and the packet waits there to be served by arbiter.

2.1.1.3.2 Rate Control Unit

A node is not permitted to use more than its fair-shared bandwidth for the insertion of fairness eligible traffic when congestion has been detected on a ringlet. This restriction prevents a node from using a disproportionate share of available capacity by virtue of its

18

relative position on the ring (The rate restriction is enforced by a shaper within the MAC datapath sub layer.). Without the regulated access, upstream node would take advantage of all available capacity during periods of congestion, preventing further downstream nodes from inserting opportunistic traffic. Therefore, in order to implement fair access, it is necessary to use shapers to restrict the occupancy of available capacity during periods of congestion, eliminating the access advantage of upstream nodes.

To allow traffic being transmitted out, the shaper of such traffic must be set to true. The value of shaper is determined by the amount of tokens for such traffic. If the amount of tokens greater than a threshold, it is set to true; otherwise it is set to false. Tokens are increased as the time elapses and decreased as traffic is sent out. When a flow of traffic reaching or exceeding its predefined rate, the amount of tokens for such traffic decreases to below a threshold, and the shaper of it is set to false, thus the traffic is held in the queue and not allowed to be sent out until enough tokens available. RCU uses this way to keep the traffic within the predefined rate in average.

Rate Control Unit (RCU) adapts token bucket traffic shaper algorithm [6] to control different classes of traffics within their predefined rate. Each class of traffic comes with a shaper to regulate its traffic: shaperAO, shaperAl, shaperB, shaperC, shaperD and shaperM. These shapers are explained in detail in the next section.

2.1.1.3.3 Dispatcher

Upon accepting a packet from Receiver (Rx), Dispatcher checks the header of the packet to decide where to forward the packet. If the packet is a topology discovery packet, Dispatcher forwards it to TCU. If the packet is a fairness packet, Dispatcher forwards it to FCU. If the packet is a data packet and the destination is this node, Dispatcher forwards it to Receiving Queue (Rx Queue). If the destination of the packet is not this node, Dispatcher forwards it to Primary Transit Queue (PTQ) or Secondary Transit Queue (STQ) depending on the traffic class the packet belongs to, then the packet stays there and wait to be served by arbiter.

19

2.1.1.3.4 Topology Control Unit

Topology discovery packet is sent to Topology Control Unit by Dispatcher. Source address, hop count and other information of the packet are retrieved by TCU and TCU uses that information to construct Topology Database. With the Topology Database, the node finds out how far it is to another node on the ring. This information is critical in fairness algorithm. Periodically, TCU broadcasts topology discovery packet to inform other nodes in the ring of its existence.

2.1.1.3.5 Fairness Control Unit

The Dispatcher sends fairness packet to the Fairness Control Unit. Upon receiving the fairness packet, FCU retrieves the value from fairness control field in the packet. It then compares this value with the one it got from fairness algorithm and send the lower value of the two to Rate Control Unit. Fairness algorithm is explained in details in the next section of this chapter.

Fairness Control Unit is used to regulate low-priority traffic. It needs to make sure all the nodes participating in the ring could get their fair shared bandwidth while not affecting higher class of traffic. Because the nodes dynamically participate in the ring, we can't assign a fixed rate to each node; on the contrary, the node should dynamically determine the fair rate and limit itself to this rate. Fairness algorithm serves this purpose.

However, fairness algorithm is only activated when FCU detects congestion in the node. Congestion is detected when either packets accumulated in the STQ over a predefined threshold, normally one eighth of the total STQ size, or transmit rate over unreserved rate. When one of these two events happens, FCU runs fairness algorithm and get a fairness value. This value is compared with the one retrieved from fairness packet and the smallest of the two is fed into Rate Control Unit. RCU, then, uses it to limit fairness eligible traffic in the next aging interval. Meanwhile, FCU generates a fairness packet

20

and insert this fairness value as fairness control value and sends it to its upstream neighbor. By repeating the same procedure in each node, the output rate of each node can be limited to the fairness value.

2.1.1.3.6 Queues

For whatever reason, if traffic that cannot be processed by the transmitter after it is received by the node it must be either discarded or temporarily held in a queue waiting to be processed. MAC layer contains three sets of queues: receive queue, transmit queues and transit queues. Each queue serves different purposes. Receive Queue (RxQueue) is used to hold traffic destined to the node itself. Transmit queues are used to hold the traffic generated by the node itself. They are further divided into three sub queues based on the class of the traffic it would hold: High Priority Transmit Queue (HP_ TmQ) hold ClassA traffic, Medium Priority Transmit Queue (MP_ TmQ) hold ClassB traffic and Low Priority Transmit Queue (LP_ TmQ) hold ClassC traffic. Transit queues are used to hold the traffic by-passing the node. They are further divided into Primary Transit Queue (PTQ) and Secondary Transit Queue (STQ). PTQ only holds ClassA traffic, STQ holds ClassB and ClassC traffic.

By dividing queues into different categories and sub queues, higher priority class of traffic gets the chance to be transmitted before lowering priority class of traffic. Therefore, head of line problem is avoided and the delay and jitter bound imposed on higher class of traffic is guaranteed.

2.1.1.3.7 Arbiter

Traffics held in the queues wait to be served by Arbiter and to be sent out. Arbiter uses a priority-based traffic management method to decide which traffic should be served, which is shown in the following sequence:

Â·

If there is a packet in PTQ, send the packet out from PTQ; otherwise,

21

Â·

If packets accumulated in the STQ is more than the size of STQ minus MTU, send the packet out from STQ; otherwise,

Â·

If there is a packet in HP-TmQ and HP-TmQ is online, send the packet out from HP-TmQ; otherwise,

Â·

If there is a packet in MP-TmQ and MP-TmQ is online, send the packet out from MP-TmQ; otherwise,

Â·

If there is a packet in LP-TmQ and LP-TmQ is online, send the packet out from LP-TmQ; otherwise,

Â· Â·

If there is a packet in STQ, send the packet out from STQ; otherwise, If there is no packet in any queue, arbiter goes to idle.

This method guarantees the minimal jitter and latency on high-priority traffic.

2.1.1.4 Physical Layer

Receiver (Rx) and Transmitter (Tx) are located in physical layer. IEEE 802.17 work group proposes SONET and/or Ethernet (Gigabit Ethernet and 10Gigabit Ethernet) as the transmission media for RPR in this layer.

2.1.2 OPNET Node Attributes
Each OPNET node module has its own attributes. The attributes of traffic generator in the upper layer mainly consist of Packet Format, Packet Interval Time, Packet Size, Start and Stop Time. By setting up different values for Packet Interval Time and Packet Size, the system can start and stop generating different rates for different traffic types at different time, which provides great flexibilities for the simulations.

Mac_intf node module has only one attribute associated with it, Weighted Destination Parameters, a compound value. It includes Destination MAC Address and Weight. Destination MAC Address is inserted into the header of the frame before being transmitted to the lower layer. If Weight is taken into account (default is 1), mac_inft

22

node is send the traffic to its destination in the amount based on the Weight value associated with it.

Attributes in the MAC node module can be put into three categories, Node Configuration, Fairness Parameters and Station Address. Node Configuration includes the setup for Two Transit Buffer (2TB) Mode, Double Low Priority Transmit Buffer (DLPTB), Swap Stage Queues, Ringlet Selection and Rate Allocation. By changing the values of these configurable attributes the system can be easily setup to run in different scenarios and the behavior of the RPR protocols can be studied in more details. Table 2.1 shows the values of each attribute and its description.

Attribute

Value

Description

Enable 2TB Mode Disable

The module has two transit buffers in each ring, PTQ and STQ. The module has one transit buffer in each ring, PTQ. The module has two low priority transmit buffers, one for

DLPTB Mode

Enable

holding frames destined before congestion point, one for beyond congestion point.

Disable Swap Stage Queue Disable Auto Ringlet Selection Selected Inner Ring Outer Ring ClassAO Rate Allocation ClassA1 ClassB CIR Enable

The module has only one low priority transmit buffer. Sending traffic from two low priority transmit buffers in Round-Robin fashion. Sending traffic from one low priority transmit buffer. The module sends the traffic based on the close-path-first algorithm. The module sends the traffic to Inner Ring. The module sends the traffic to Outer Ring. User defined traffic rate for ClassAO traffic. User defined traffic rate for ClassA1 traffic. User defined traffic rate for ClassB CIR traffic

Table 2.1: Node Configuration Attributes

23

Fairness Parameters includes Fairness Algorithm Mode, Fairness Message Type, Advanced Fairrate Propagation, age_coef, lp_ coef, ramp_coef and Weight. By changing the values of these parameters the behavior and performance of fairness algorithm can be easily studied. Table 2.2 shows the values of each parameter and its description.

Parameter

Value

Description

Aggressive Conservative Fairness Algorithm Mode Fuzzy in Aggressive Fuzzy in Conservative Fairness Message Type age_coef lp_coef ramp_coef Multi Chock (user defined) (user defined) (user defined) Single Chock

The module runs Aggressive fairness algorithm. The module runs Conservative fairness algorithm. The module runs Aggressive fairness algorithm with Fuzzy Logic Control. The module runs Conservative fairness algorithm with Fuzzy Logic Control. The module only response to the lowest fairness advertising rate it received from downstream nodes. The module response to each fairness advertising rate it received from downstream nodes. Age coefficient Lp coefficient Ramp coefficient The ratio of maxim bandwidth assigned to the module.

Weight

(user defined)

LineSpeed X The ratio is defined as Tota!Modue

We "ght
l

,

default is 1.

Table 2.2: Fairness Parameters

24

Station address is defined in Table 2.3. Auto Assigned Station Address (user defined) The module's MAC address is auto-assigned by the system. The module's MAC address is assigned by the user. In this case, it is user's own responsibility to make sure there is no duplicated address among the nodes.

Table 2.3: Station Address Parameters

2.2 OPNET Link Model
In order to simulate real world optical fiber, RPR OPNET link module is designed to be a simplex point-to-point link, which means it can only accepts one-way traffic. With a pair of bi-directional dual counter-rotating rings connected to its MAC node, the module is able to transmit and receive traffics with its adjacent neighbors. The data transmit rate of the link is set as 622.08 Mbps to simulate OC-12 optical signal. To simplify the calculation, the delay in each link is set to a fixed value, 0.07 ms, to simulate the distance of 15 kilometers between two adjacent neighbors. The link can only accept the Data frame, Control frame and Fairness frame. The next section discusses these formats in details.

The packets are sent from the upper layer in any format, e.g. IP ,or IPX. When packets arrive at the Logic Link Control layer from the upper layer, as illustrated in Figure 2.1, they are encapsulated with RPR header and converted to RPR Data format, then sent to the MAC layer. When frames arrive at the Logic Link Control layer from the MAC layer, the header of frames is deprived and the de-capsulated frames are sent to the upper layer for further processing. Except data frame, other format are generated and stripped in the MAC layer, simply because they are the control frames.

25

2.3 Frame Format
The in-house RPR OPNET model includes three different frame formats, data frame format, control frame format and fairness frame format. The header of all these formats is the same. The following paragraph illustrates the header and the body of the frame in details.

2.3.1 Frame Header
Each frame has a fixed size header. Table 2.4 shows the header format of non-fairness frame. Table 2.5 shows header format of fairness frame.

Header Field

Field Length (bit)

Description

Time-To-Live, a hop count that specifies the TTL 8 maximum number of hops the frame is expected to cover before reaching the destination. BaseControl DA SA TTLBase ExtendedControl HEC 8 48 48 8 8 16 Basic control field Destination Address Local Station Address Initial value of the TTL field upon transmission of a data frame. Additional control field only for Data frames. Header Error Checksum

Table 2.4: RPR Non-Fairness Frame Header Format

26

Header Field

Field Length (bit)
Time-To-Live,

Description
a hop count that specifies the

TTL

8

maximum number of hops the frame is expected to cover before reaching the destination.

BaseControl SaCompact

8 48

Basic control field Source station that provided the values In

fairnessHeader and fairRate fields.

Table 2.5: RPR Fairness Frame Header Format

2.3.2 BaseControl Field
BaseControl field is shown in Table 2.6.

Sub Field

Length (bit)

Description
Ringlet Identifier. Indicates the ringlet onto which the

RI

1

frame was originally transmitted.

0 - Inner Ring, 1 - Outer Ring.
Mark the frame whether fairness eligible subject to the FE

1

RPR fairness algorithm.

0- Not fairness eligible, 1 -fairness eligible.
FT
2

Frame Type. 002 - Idle Frame; 01 2 - Control Frame;

102 - Fairness Frame; 11 2 - Data Frame.
Service class of the frame. 002 - Class C; 01 2 - Class B;
102 - Class A, subclass A 1; 11 2 - Class A, subclass AO.

sc
WE

2

Indicates that the frame is eligible to be wrapped during
1

a wrap condition.

0- Not wrap eligible, 1 -wrap eligible.
reserved
1

Reserved for future use.

Table 2.6: BaseControl Field 27

2.3.3 Data Frame Format
Table 2.7 shows the RPR Data frame format:

Field
header ProtocolType SDU fcs

Length (bit)
144 16

Description
Non-Fairness Frame Header.
>= 1536, MAC client protocol (type interpretation) < 1536, length of frame (length interpretation)

n
32

Service Data Unit provided by the MAC client. Frame Check Sequence, a CRC of the frame.

Table 2.7: RPR Data Frame Format

2.3.4 Control Frame Format
Table 2.8 shows the RPR Control frame format:

Field
header

Length (bit)
144

Description Non-Fairness Frame Header. Type of control frame.
011 6 - Station Configuration Discovery frame;

Control Type

8

021 6 - Topology and Protection frame; 0316- OAM control frame; 04 16 - Vendor specific discovery frame;

other - Reserved ControlVer CDU fcs 8 n
32

Version number of Control Type field. Control Data Unit Frame Check Sequence, a CRC of the frame. Table 2.8: RPR Data Frame Format

28

2.3.5 Fairness Frame Format
Table 2.9 shows the RPR fairness frame format:

Field
header

Length (bit)
48

Description
Fairness Frame Header. Type of fairness frame:

0- Single Chock: Provides the advertisedFairRate of a
station FairnessHeader 16 1 - Multi Chock: Provides the normLocalFairRate of a station to all other stations on the ringlet once per reporting interval. Other - Reserved. F airnessRate fcs 16 32 Normalized rate encoded as a 16-bit quantity. Frame Check Sequence, a CRC of the frame. to the upstream neighbor once per

advertisementlnterval.

Table 2.9: RPR Fairness Frame Format

2.4 RPR Protocol Suite
RPR is a complicated layer-2 protocol stack that comes with many features. Four major protocols are explained next.

2.4.1 Topology Discovery Protocol
The topology discovery protocol provides a reliable and accurate means for all nodes on a ring to discover each other. This includes both the initialization of the topology and any changes to that topology. The protocol provides each node on the ring with knowledge of

29

the number and arrangement of other nodes on the ring. This collection of information is referred to as the topology database. Each node maintains its own local copy of the topology database for the entire ring. The topology database is also used by other protocols such as the RPR ringlet selection protocol and the RPR fairness algorithm.

Initially, the node's topology database contains information only about itself. The information required to create the basic topology database (including, for example, hop counts per ringlet from the local node to all other nodes on the ring) is derivable from the

ttl value from the header of topology frames received from each node on the ring. The
transmission of Topology discovery frames is initiated as needed and periodically. If the topology database is stable, the periodic Topology discovery frame transmissions do not result in any change to the topology database. A sample topology database of a threenode-ring is shown as Table 2.10.

MAC Address

Hop count

Hop count

Data Reachability, Ring/eO

Data Reachability, Ringle]

for RingletO for Ringlet 1

00-10-A497-A8-DE 00-10-A497-A8-AC 00-10-A497-A8-BD 00-10-A497-A8-CE

0

0

Yes

Yes

1

3

Yes

Yes

2

2

Yes

Yes

3

1

Yes

Yes

Table 2.10: A Sample Topology Database

30

2.4.2 Ringlet Selection Protocol
The primary responsibility for ringlet selection protocol is to choose the appropriate ringlet for client add frames. This can be done either by manual configuration or based on short-path-first algorithm. With manual configuration, the frames have to be sent to designated ringlet. With short-path-first algorithm, the choice is made based on the lowest hop count to the destination. The algorithm searches the entry of destination address in the topology database and compares the hop counts of two ringlets. The ringlet with the smaller hop count is chosen and is set in the ri field in the header of the frame. This is stated in Eq. (E 2.1 ):

Ringlet_id =MIN (hop_count(dest_addr, ringletO), hop_count(dest_addr, ringlet!))

(E 2.1)

Consider Table 2.10 as an example. If local node wants to send frames to destination 0010-A4-97-A8-CE, it compares the hop counts of both ringlets in the topology database. Because ringlet1 has lower hop count than ringletO, the ringlet1 is selected.

2.4.3 RPR Fairness Algorithm (RPR-fa)
RPR-fa is a local fairness algorithm that provides a fair access for all nodes on the ring. When congestion happens fairness algorithm decides what the allowed rate for the fairness eligible traffic is in the local node and what the rate it should advertise to its upstream neighbors. RPR-fa is an intelligent algorithm that can dynamically allocate faired bandwidth to all the nodes within the congestion domain 1Â· Ideally, such faired bandwidth should be the total bandwidth divided by total number of nodes within the congestion domain.

Total Bandwidth Fair r a t e = - - - - - - - - - - Total_ Number_ of_ Stations
1

(E2.2)

A congestion domain is a set of contiguous stations that affected by congestion.

31

2.4.3.1 RPR-fa Mechanism

The RPR-fa is a mechanism that enforces fairness among the nodes on the ring. It applies only to ClassC and ClassB Excess Information Rate (EIR) traffic coming from the MAC client. Each node is assigned a weight, which allows the user to allocate more ring bandwidth to certain node in congested situation. The RPR-fa does not need to understand the ring topology, however it utilizes the implicit topology information (i.e. TTL value) passed by the MAC client to perform fairness and policing functions. In RPR-fa, if a node experiences congestion, it advertises a fair rate (e.g. add_rate) to upstream nodes via the opposite ring. The fair rate counter is run through a low pass filter function and divided by a weighting function (e.g. local node weight). The low-pass filter stabilizes the feedback, and the division by weight normalizes the transmitted value to a weight of 1.0. Upon receiving an advertised fair rate, the upstream nodes adjust their traffic speed so as its transmission rates not to exceed the received advertisement rate (adjusted by their weights) if such traffic destined beyond the congestion point. Generally, nodes also propagate the received advertisement rate to their immediate upstream neighbor. Nodes receiving advertised values which are also congested propagate the minimum of their normalized low pass filtered advertised fair rate and the received fair rate. If the traffic destines within the congestion point, the node can take advantage of all the available bandwidth on the ring.

2.4.3.2 RPR Fairness Algorithms

Three types of RPR-fa are implemented in RPR (Aggressive-fa, Conservative-fa and Fuzzy-fa) to calculate fair rate while a node is experiencing congestion. Aggressive-fa and Conservative-fa are the proposed by IEEE 802.17 draft, Fuzzy-fa is proposed here to improve the performance of the other two algorithms.

During each aging_interval, the add_rate is accumulated by the size of frame length whenever there is fairness eligible traffic sent out from the node. At the end of the

32

aging_interval, the add_rate runs through a low pass filter function and divided by a weighting function and represented it as lp_add_rate. The Aggressive-fa takes the value oflp_add_rate as the fair rate ifthe congestion detection unit finds the node is congested; otherwise it takes unreserved rate as fair rate.

Conservative-fa gets its fair rate in two phases: first, when congestion detection unit finds the node is congested, it enters "just enter congestion" state and takes the value of unreserved_rate/active_stations as its fair rate for the period of this state. After this time period elapses, if congestion detection unit finds the node is still congested, it enters "ramping" state. In "ramping" state, congestion state is monitored. If the traffic accumulated in the STQ is less than low threshold, the congestion is looked as "light congest," in this case the node should "ramp up" and send more traffic than previous interval. The fair rate passes a "ramping up" function and increases its value. If the traffic accumulated in the STQ is higher than medium threshold, the congestion is looked as "heavy congest," in this case the node should "ramp down" and send less traffic than previous interval. The fair rate passes a "ramping down" function and decreases its value. If the traffic accumulated in the STQ is between low threshold and medium threshold, the congestion is looked as "normal congest", in this case the node should not "ramp up" or "ramp down" and it should send the traffic the same as previous interval. The fair rate does not pass the ramping function, it keeps the value of it as is.

Both Aggressive-fa and Conservative-fa have pros and cons. Aggressive-fa is fast in convergent to the fair rate. However, when too many nodes are in the ring, it introduces tremendous oscillation and sometime brings the node into starving state. Conservative-fa, on the other hand, is not likely to introduce oscillation, however, it is slow in convergence to the fair rate and has less utilization of the bandwidth than Aggressive-fa. In order to overcome the limitation mentioned above, a new algorithm, Fuzzy-fa, is introduced that has less oscillation with fast convergency time. See [ 1] for detailed explanation on Aggressive-fa and Conservative-fa. Fuzzy-fa is explained in details in Chapter 3.

33

2.4.3.3 Single Chock Fairness Message vs. Multi-Chock Fairness Message

Shaper parameters for fairness eligible traffic are computed using a distributed fairness algorithm. The fairness algorithm relies on fairness messages that are circulated periodically on the ringlet opposing that of the associated data traffic. There are two types of fairness message frame, single chock fairness message frame (SCFF) and multi-chock fairness message frame (MCFF). The SCFF is processed at each node and carries the identity of the most congested node encountered and the time averaged ingress rate, or fair rate, reported by that node. Upon receiving the frame, the node compares its own calculated normalized low pass filtered advertised fair rate with the received fair rate, and insert the lower value of the two into its SCFF and send to the upstream node. The second type of fairness message frame, MCFF, is broadcasted periodically by all nodes. The MCFF is passed to the fairness control unit for processing and the relevant information is passed to the client to support multi choke fairness. Therefore, in a multichoke implementation of the RPR-fa, each client tracks advertised fair rates for congested nodes. A node is allowed to send unlimited traffic to any node between itself and the first congested node (choke point). It can send traffic to nodes between the first and second choke point based on the first choke point's advertised fair rate. In general, a node can send traffic to a particular destination if it has satisfied the fair rate conditions for all choke points between itself and the destination. See [ 1] for detailed explanation on single chock fairness message and multi chock fairness message.

2.4.4 Traffic Rate Control Protocol
A variation of token bucket traffic shaper is implemented in this thesis to control the traffic so as to confine service classes within their allocated rate.

34

2.4.4.1 Token Bucket Traffic Shaper

Figure 2.3 illustrated the theory of Token Bucket Traffic Shaper (TBTS) [6]. Tokens are generated periodically at a constant rate and are stored in a token bucket. If the token bucket is full, arriving tokens are discarded. A packet from the buffer can be taken out only if a token in the token bucket can be drawn. If the token bucket is empty, arriving packets have to wait in the packet buffer. Thus, one can think of a token as a permit to send a packet.

If the buffer has a backlog of packets when the token bucket is empty, these backlogged packets have to wait for new tokens to be generated before they can be transmitted out. Since tokens arrive periodically, these packets are transmitted periodically at the rate the tokens arrive. If the token bucket is not empty, packets are transmitted out as soon as they arrive without having to wait in the buffer, since there is a token to draw for an arriving packet. Thus, the burstiness of the traffic is preserved in this case. However, if packets continue to arrive, eventually the token bucket becomes empty and packets starts to leave periodically. The size of the token bucket essentially limits the traffic burstiness at the output.

35

Packets arrive periodically

Token Bucket

--------.
Token

Size K

Buffer

SizeN Incoming traffic Shaped traffic

Packet

Figure 2.3: Token Bucket Traffic Shaper

2.4.4.2 Token Bucket Traffic Shaper Implemented in RPR

In RPR, a variation of Token Bucket Traffic Shaper 1 is implemented to control different service classes. In this variation, each shaper consists of a token bucket as illustrated in Figure 2.4. The token bucket has a default maximum depth of at least MTU_SIZE bytes. The credits 2 in the token bucket are incremented by incSize at every interval time t and decreased by decSize whenever a packet transmitted out. The value of incSize is the product of interval time t multiplied by allocation rate of the offered traffic. The value of
decSize is the length of packet in byte.

When a packet is waiting for access to the ring at the head of a queue, it is granted ring access only if there are at least low Limit (MTU_SIZE) bytes of credits in the token bucket. The number of credits in the token bucket is then reduced by the length of the packet transmitted, decSize. The credits are reduced as each byte is sent, not all at once. It
1

Although multiple shapers are used within this thesis, the behavior of all shapers can be characterized by a common algorithm with instance-specific parameters. 2 The term "credit" is a substitute of token in this variation.

36

is never possible for the number of credits to become negative after subtracting the number of bytes in the transmitted frame. The maximum number of credits that can accumulate in the token bucket depends on the shaper.

Crossing below the lowLimit threshold shall generate a rate-limiting indication, so that offered traffic can stop before reaching zero credits, where excessive transmissions are rejected. To bound the burst traffic after inactivity intervals, when no packets are ready for transmission, credits are reduced to low Limit (if currently higher than lowLimit) and can accumulate to no more than lowLimit. For all shapers described in this variation,
low Limit is set to MTU SIZE in order to allow the transmission of a full sized frame

without reducing the credits below zero.

The hiLimit threshold limits the positive credits, to avoid overflow. When packets are ready for transmission (and are being blocked by transit traffic), credits can only be accumulated up to hiLimit. The hiLimit value shall be at least MTU_SIZE. If it is set to exactly MTU_SIZE, then no bursts are allowed.

37

hiLimit

decSize

credits

credit limit when packets are waiting

credits withdrawn when no packets are waiting

credits limit when no packets are waiting

towLimit

0 Increasing time

Figure 2.4: RPR Token Bucket Traffic Shaper

RPR variation ofTBTS differs from standard TBTS in the following aspects: Â· Terminology of counter: Standard TBTS uses "token" as the terminology to describe the counter. RPR variation TBTS uses "credit." Â· Prerequisite for sending traffic: Standard TBTS allows packet to be transmitted out as long as there is a token in the token bucket. However, in RPR variation, a packet can be transmitted out only when credits accumulated in the bucket between lowLimit threshold and hiLimit threshold. Â· RPR variation regulates traffic more smoothly than standard TBTS. When there is no packets waiting in the buffer after a few inactivate intervals, RPR variation either withdraws credits to lowLimit threshold if higher than it or accumulates no more than lowLimit if below it. In standard TBTS, the token continues to increase until bucket is full. In the worst case scenario, when two packet with the length of

38

MTU SIZE arrive In the buffer sequentially, RPR variation maximizes transmitting one packet at a time. Standard TBTS, on the other hand, sends two packets if there is enough tokens in the bucket.

2.4.4.3 Inside Rate Control Unit
Recall Figure 2.2. Having explained the overall structure of Rate Control Unit, we are now able to show how this unit works and how it controls the different types of traffic. Figure 2.5 illustrate the architecture of this unit:

-------------------------------------------------,
BM BAO BAI BB BC BD

Rate Control Unit

Control Trafqc ClassAO ClassAl
I

shaperM shaperAO shaperAl

ClassB CIR :
I I

shaperB shaperC shaperD

ClassB _ EIR, flassC

I I I I

~-------------------------------------------------

I

Legend

D

Token Bucket

0

Server

~

Information Path

Figure 2.5: Enlarged Rate Control Unit

39

In this figure, there are six token buckets corresponding to six shapers to regulate five types of traffic. Tokens in bucket BM regulates RPR MAC supplied control traffic and gets the result shaperM, tokens in bucket BAO regulates ClassAO traffic and gets the result shaperAO, and so on. Each type of traffic passes through its own token packet traffic shaper and gets a result for its own type of traffic, meanwhile ClassA 1, ClassB and ClassC traffic need to pass through a additional shaper to constrain the client to sustain the downstream allocated subclassAO traffic. These results are fed into Arbiter for the decision-making process.

2.4.4.4 Shapers

There are five shapers implemented in this thesis: shaperM, shaperA, shaperB, shaperC,

shaperD. ShaperM is the shaper of RPR control traffic, for example, fairness control
packet. ShaperA, shaperB, shaperC are the shapers of the service classes accordingly.

ShaperD is an additional shaper to constrain the client to sustain the downstream
allocated subclassAO traffic.

2.4.4.4.1 Control Shaper- shaperM

The control shaper limits the MAC-supplied control traffic to its allocated limits, it runs in addition to the other shapers through which control packets pass (i.e. shaperA, shaperB, shaperC), therefore, implemention should account for this by setting the rates of shaperA, shaperB and shaperC such that they include enough bandwidth for the anticipated control traffic. The parameters of shaperM are illustrated in Table 2.11.

Parameters
dec Size inc Size hiLimitM lowLimitM

Value
MacA rateM *time

Explanation
Length of MAC supplied control packet. Allowed rate for control packet multiply by the unit of time since the last increment.

2 * sizeMTU sizeMTU

Default value for hiLimitM is two MTU size. Default value for lowLimitM is one MTU size.

Table 2.11: shaperM parameters

40

The MAC-supplied control traffic is allowed to be transmitted out only when the value of shaperM is TRUE, which is defined in Equation 2.3 and Equation 2.4.

creditM = MIN(hiLimitM, creditM + rateM *time) shaperM = (creditM >= lowLimitM)

(E2.3) (E2.4)

Here creditM is the minimum of hiLimitM and last creditM plus inc Size, (rateM * time). ShaperM is TRUE when creditM greater than or equal to lowLimitM; otherwise FALSE.

2.4.4.4.2 ClassA Shaper- shaperAO and shaperA1

The ClassA shaper limits the client-supplied ClassA transmissions. ShaperA is further divided into shaperAO and shaperA1. The parameters of shaperAO and shaperA1 are illustrated in Table 2.12 and Table 2.13 respectively.

Parameters
dec Size inc Size

Value
ClientAO rateAO *time

Explanation
Length of client-supplied subclassAO packet. Allocated rate for subclassAO packet multiply by the unit of time since the last increment. Amount of credits that would be needed to

SizeMTU+ hiLimitAO rateAO*MAX JITTER/2

buffer the amount of traffic that could be generated by MAX_JITTER, plus one MTU to account for lowLimitAO. Default value for lowLimitAO IS one MTU

lowLimitAO

sizeMTU SIZe. Table 2.12: shaperAO parameters

The default value for hiLimitAO is set to preserve the delay and jitter guarantees of subclassAO traffic. The default value is given by Equations 2.5 and 2.6.

41

hiLimitAO = sizeMTU + rateAO * MAX JITTER I 2 MAX_JITTER = (numStations*(sizeMTUILR)) I (l- rateAOILR)

(E2.5) (E2.6)

Here numStations is the number of nodes in the ring, LR is the link rate. MAX JITTER is determined by the possible log jam due to coincidental submission of subclassAO packets by all the nodes in the ring, (numStations*(sizeMTUILR)), and the rate at which the node can recover, (1-rateAOILR).

Table 2.13 shows the parameters ofshaperAl:

Parameters
dec Size inc Size

Value
clientAl rateA 1 * time

Explanation
Length of client-supplied subclassAl packet. Allocated rate for subclassAl packet multiply by the unit of time since the last increment. Amount of credits that would be needed to

sizeMTU+ hiLimitAl rate A 1*MAX JITTER/2

buffer the amount of traffic that could be generated by MAX_JITTER, plus one MTU to account for lowLimitAJ. Default value for lowLimitAJ lS one MTU

lowLimitAl

sizeMTU SIZe. Table 2.13: shaperAl parameters

Parameters of shaperA 1 are similar to those of shaperAO, except transmission rate is replacing with "rateA 1".

The Class A traffic is allowed to transmit out only when the value of shaperA is TRUE, which is defined in Equation 2.7, 2.8 and 2.9.

CreditAO = MIN(hiLimitAO, creditAO + rateAO *time) CreditAl = MIN(hiLimitAl, creditAl + rateAl *time) ShaperA = (creditAO>=lowLimitAO

(E2.7) (E2.8)
&& shaperD)

II (creditAl>=lowLimitAl
42

(E2.9)

Here creditAO is the minimum of hiLimitAO and last creditAO plus incSize, (rateAO * time), creditA1 is the minimum of hiLimitA1 and last creditA1 plus incSize, (rateA1 * time), ShaperA is TRUE when creditAO is greater than or equal to lowLimitAO, or creditA1 greater than or equal to lowLimitA1 and shaperD is TRUE; otherwise shaperA is FALSE. 2.4.4.4.3 ClassB Shaper- shaperB

The ClassB shaper limits the client-supplied ClassB transmissions. The parameters of shaperB are illustrated in Table 2.14.

Parameters dec Size inc Size

Value ClientB rateB *time

Explanation Length of client-supplied ClassB CIR packet. Allocated rate for ClassB CIR packet multiply by the unit of time since the last increment. Amount of credits that would be needed to

sizeMTU + (rate A 1 + hiLimitB rateB) * MAX_JITTER/2

buffer the amount of traffic that could be generated by MAX_JITTER, plus one MTU to account for lowLimitB.

lowLimitB

sizeMTU

Default value for lowLimitB is one MTU size.

Table 2.14: shaperB parameters The Class B traffic is allowed to transmit out only when the value of shaperB is TRUE, which is defined in Equation 2.10 and 2.11.

CreditB = MIN (hiLimitB, creditB + rateB * time) ShaperB = (( creditB >= lowLimitB) && shaperD)

(E2.10) (E2.11)

43

Here creditB is the minimum of hiLimitB and last creditB plus inc Size, (rateB * time), shaperB is TRUE when creditB is greater than or equal to lowLimitB and shaperD is TRUE; otherwise shaperB is FALSE.

2.4.4.4.4 Fairness Eligible Shaper- shaperC

The fairness eligible shaper limits the client-supplied ClassB-EIR and ClassC transmissions. The parameters of shaperC are illustrated in Table 2.15.

Parameters dec Size

Value clientC

Explanation Length of client-supplied ClassB-EIR and ClassC packet.

inc Size

MAX- ALLOWED- RATE *time 2 * sizeMTU sizeMTU

Maximum allowed rate for fairness eligible packet multiply by the unit of time since the last increment.

hiLimitC lowLimitC

Default value for hiLimitC is two MTU size. Default value for lowLimitC is one MTU SIZe.

Table 2.15: shaperC parameters

The ClassB-EIR and ClassC traffic is allowed to transmit out only when the value of shaperC is TRUE, which is defined in Equation 2.12 and 2.13.

creditC = MIN(hiLimitC, creditC + MAX_ALLOWED_RATE *time) (E2.12) shaperC = ((creditC >= lowLimitC) && shaperD) (E2.13)

Here creditB is the minimum of hiLimitB and last creditB plus inc Size, (rateB * time), shaperB is TRUE when creditB is greater than or equal to lowLimitB and shaperD is TRUE; otherwise shaperB is FALSE.

44

Here

creditC

is the minimum of hiLimitC

and last creditC plus

incSize,

(MAX_ALLOWED_RATE * time), this allows fairness eligible traffic to be bursty over the short term, while the fairness algorithm limits it to allowed rate over a longer time periold. ShaperC is TRUE when creditC is greater than or equal to lowLimitC and shaperD is TRUE; otherwise shaperC is FALSE.

2.4.4.4.5 Downstream Shaper- shaperD

The downstream shaper monitors the transit traffic to ensure sufficient levels of sustainable subclassAO traffic for downstream nodes. The parameters of shaperD are illustrated in Table 2.16.

Parameters
dec Size

Value
!ClientAO Length packet. of

Explanation
client-supplied non-sublassAO

Unreserved rate for non-subclassAO packet inc Size

unreserved rate * time

multiply by the unit of time since the last increment.

hiLimitD lowLimitD

2 * sizeMTU sizeMTU

Default value for hiLimitD is two MTU size. Default value for lowLimitD is one MTU size.

Table 2.16: shaperD parameters

Non-subclassAO add traffic is allowed to transmitted out only when the value of shaperD is TRUE, which is defined in Equation 2.14 and 2.15.

CreditD = MIN(hiLimitD, creditD + unreserved_rate *time) ShaperD = (creditD >= lowLimitD)

(E2.14) (E2.15)

Â·Â·-41.

45

Here creditD is the minimum of hiLimitD and last creditD plus inc Size, (unreserved_rate

* time), shaperD is TRUE when creditD is greater than or equal to lowLimitD; otherwise
shaperD is FALSE.

2.5 Verification
In this section, a few testing scenarios are created in OPNET to compare the simulation result of the in-house RPR model with the SRP model that comes with OPNET. In our model, we use OC-12 as link type with the maximum bandwidth up to 622 Mbps, packets generated from each node is in fixed size, 12000 bits. The delay in each link is set at a fixed value, 70 ns, and reserved rate is 2% of total bandwidth, each node carries the same weight.

2.5.1 Scenario 1 -Verify Fairness Algorithm
Let's compare the simulation result generated from Cisco's SRP model and that of the inhouse OPNET Model to verify fairness algorithm implemented. The topology of this scenario is that each node, from Node 1 through Node 3 inclusive, sends traffic at the constant rate of 600 Mbps to Node 4, however each node start generating the traffic at different time as shown in Figure 2.6.

I 0 ms: 600 Mbps

Iiili

!50 ms: 600 Mbps 1111350 ms: 600 Mbps 1111-

Figure 2.6: Verify Fairness Algorithm

46

Theoretically, Node 1 should generate 600 Mbps traffic from 10 ms to 150ms, Node 1 and Node 2 should generate 622 I 2 =311 Mbps traffic from 150 ms to 350 ms and Node 1 through Node 3 should generate 622 I 3 = 207 Mbps traffic from 350 ms and later.

2.5.1.1 Cisco's SRP Model

In this test I adopted Cisco's SRP model in OPNET and sampled 200 values for each node in 450 ms simulation time, the simulation result is shown in Figure 2.7.

Figure 2.7: Simulation Result ofSRP Model

From the result one can see that Node 1 generated 600 Mbps traffic from beginning of the simulation to 150 ms, then generated 300 Mbps in average after Node 2 joined in. Node 2 also generated a little bit more than 300 Mbps traffic until Node 3 joined in, which in tum made each node in the ring to generate 200 Mbps traffic. At the steady state, it provides the desirable fairness to each node. The result meets the theory therefore we can say it is correct.

47

2.5.1.2 Our Model in Conservative Mode

Let's run our model in conservative mode where we sampled 200 values for each node in 450 ms simulation time. The result is shown in Figure 2.8.

Figure 2.8 : Simulation Result of Our Node in Conservative Mode

From the result one can see the bandwidth of the link is fairly shared among the node in their steady state, which meets the theory of RPR, therefore we can say the fairness algorithm implemented in conservative node in our simulation model is correct.

2.5.1.3 Our Model in Aggressive Mode

Let's run our model in aggressive mode where we sampled 200 values for each node in 450 ms simulation time. The result is shown in Figure 2.9.

48

Figure 2.9: Simulation Result of Our Node in Aggressive Mode From the result one can observe the behavior of all the nodes meets the theory.

2.5.2 Scenario 2- Verify Spatial Reuse
Cisco's SRP Model in OPNET can only send traffic to one destination, which does not meet the prerequisites of this scenario. Therefore, let's compare the simulation result generated from our model in OPNET with theoretical result to verify spatial reuse properties implemented in our model. The topology of this scenario is the same as the previous one. Moreover, Node 1 generates 200 Mbps extra amount of traffic to Node 2 starting at 10 ms to take the advantage of the unused bandwidth. The topology is shown in Figure 2.1 0. Theoretically Node 2 and Node 3 should behave the same way as in previous scenario, however, Node 1 utilizes the spatial reuse properties in RPR to use the leftover bandwidth: it generates the faired-share rate allocated for it plus up to whatever leftover in each link, therefore, theoretically it generates full line rate from 10 ms to 150 ms and 500 Mbps from 150 ms to 350 ms and 400 Mbps from 350 ms to the end of the simulation.

49

10 ms 600 Mbps ISO ms: 600 Mbps 10 ms: 200 Mbps

liJa liJa liJa

...

350 ms: 600 Mbps

Figure 2.10: Verify Spatial Reuse

2.5.2.1 Our Model in Conservative Mode

Let's run our model in conservative mode where the total simulation time is 450 ms, the simulation result is shown in Figure 2.11.

Figure 2.11: Simulation Result of Our Model in Conservative Mode

From the result one can see that Node 1 generated 600 Mbps traffic from beginning of the simulation to 150 ms, then generated 500 Mbps in average after Node 2 joined in, from 350 ms to the end of simulation it generated 400 Mbps traffic. Node 2 generated around 300 Mbps traffic in average until Node 3 joined in, which in turn made Node 2 and Node 3 generate 200 Mbps traffic. This result meets the theory.

50

2.5.2.2 Our Model in Aggressive Mode

Let's run our model in aggressive mode where the total simulation time is 450 ms, the simulation result is shown in Figure 2.12.

Figure 2.12: Simulation Result of Our Model in Aggressive Mode

From the result one can observe that the simulation result closely matches the theoretical result.

51

Chapter 3: Fuzzy Logic Control

3.1 Introduction
IEEE 802.17 RPR Darwin Proposal [1] introduced a solution to control the traffic sent from each node participating in the ring. There are two algorithms provided in this solution, Aggressive algorithm and Conservative algorithm. Aggressive algorithm is faster in convergency but introduces higher oscillation. Conservative algorithm, on the other hand, is a little bit slower but has less oscillation. Figure 3.1 illustrates a scenario that node 1 through node 16 send 38 Mbps constant traffic to the destination node, node 0. All the nodes in the ring are running Aggressive algorithm and the bandwidth of each ring is 622Mbps. Because the total traffic sent by the nodes is 38Mbps x 16 = 608Mbps, which is less than the maximum bandwidth of the link, no node is congested. Under this situation, RPR performs well. Essentially, the bandwidth is equally shared among the nodes. That is, each node has a throughput of 38 Mbps. Figure 3.2 shows the throughput of node 1. As can be seen, the throughput is very stable, practically no oscillation occurs.

Traffic to Nod~

Traffic to Nod~

Traffic to Node 0
~

Figure 3.1 : Multi Sourced Traffic

52

Figure 3.2: Throughput of Node 1 at a Constant Rate Under the congestion situation, however, RPR with aggressive or conservative algorithm does not perform well. For example, if traffic generated from each node in the example above is increased from 38 Mbps to 42 Mbps, congestion occurs and it causes the oscillation in throughput. The throughput of each node should be 622 Mbps I 16
~

39

Mbps. However, because of the nature of the RPR fairness algorithm [1], the throughput of the congestion node (Node 1), would have large oscillations as shown in Figure 3.3a, others would have less oscillation as shown in Figure 3.3b. Note that the throughputs presented here are averaged in every 10 aging_interval 1, which is equal to 1 msec. The reason for measuring the throughput over every 10 againg_interval is that it gives a more accurate indication of the oscillation problem.

In aggressive mode, the congestion node (Node 1) and the furthest upstream node (Node 16) in the congestion domain experience more oscillation than any other nodes in the same domain [3]. The large degree of oscillation at the congested node is the nature of the aggressive mode whereas the large degree of oscillation at the furthest upstream node is due to the occasional advertisements of FULL_RATE by the second furthest upstream node. We have modified the mechanism of the fair rate propagation in the original aggressive mode algorithm to eliminate the occasional advertisements of FULL_RATE sent by the second furthest upstream node. As a result, the furthest upstream node has

1

Aging _interval for OC-3 is 400 us, for OC-12 and higher is 100 us.

53

similar behavior as the other nodes in the same congestion domain (except the congestion node) in all of our simulation results. See [3] for more details on the modification .

Figure 3.3a: Throughput ofNode 1

Figure 3.3b: Throughput of Node 16

.

Oscillation brings many drawbacks, for example, the unfair allocation of bandwidth between different nodes, unstable performance of the system, reduced quality of service, etc. It can even bring the system temporarily out of service.

3.1.1 The Architecture Of Traffic Control System
Figure 3.4 illustrates a simplified architecture of the traffic control system 1. According to IEEE 802.17 RPR Darwin Proposal [1], there are two queues holding the traffic in the node, Transmit Queue and Transit Queue. Transmit Queue holds the traffic generated from the node itself, Transit Queue holds the traffic bypassing the node. Add_rate is the counter that counts the amount of data sending out of the Transmit Queue during each aging_interval, fw_rate counts the traffic sending out of the Transit Queue. The value of add_rate and fw_rate are zeros at the beginning of each aging_interval and are reset to zeros at the end of each aging_interval. Also at the end of each aging_interval, they are input to a low pass filter in Rate Control Unit to calculate lp_add_rate and lp_fw_rate, respectively, which, in tum, is used to calculate the loca_fair_rate and shaper_add_rate. Local fair rate is fed into Fairness Control Unit to become a candidate for advertise_rate, which are injected into fairness advertisement packet and are sent to the upstream node by Arbiter. Note that when advertise_rate is received by its upstream
1

To simplify the illustration, only show the low priority queues in the diagram is shown.

54

neighbor, it is then called rcvd_rate and becomes another candidate for advertise_rate. Shaper_add_rate is fed into Arbiter to control the output speed of Transmit Queue and Transit Queue. Rcvd_rate is also fed into Rate Control Unit to participate in calculating shaper_add_rate.
Downstream .-----------, Neighbor Fairness
rcvd rate

Â·
)

Control Unit

~ .--------~
Rate Control Unit

Transmit Queue

local_fair_rate

high_threshold

Legend

D

Control Unit

Traffic Flow Path Internal Information Path

_1.___.__.___.111

Queue

Figure 3.4: Simplified Architecture of the Traffic Control System

This control system is working well in most scenarios, however, 1n some congestion situations, it introduces oscillation as shown in Figure 3.3.

55

3.1.2 Oscillation Analysis
Arbiter uses shaper_add_rate to control the outgoing traffic in Transmit Queue and Transit Queue. Before it sends any packet, the scheduler checks shaper_add_rate and the traffic accumulated in these two queues first, and then decides which queue to send traffic based on the following decision-making steps:

1) If the traffic accumulated in the Transit Queue is higher than STQ SIZE MTU, Arbiter sends a packet from Transit Queue; 2) Otherwise, if there is any packet in the Transmit Queue, Arbiter sends a packet from Transmit Queue; 3) Otherwise, if there is any packet in the Transit Queue, Arbiter sends a from Transit Queue; 4) Otherwise, if there is no packet in Transit Queue, system goes to idle.

When a node is congested, it advertises the advertise_rate to its upstream nodes. This causes the upstream nodes to throttle down their data rates. By doing this, the congestion in the congested node gradually drops down. Once the congestion is temporarily eliminated, the previous congested node advertises a FULL_RATE to its upstream nodes again. This causes the upstream nodes to increase their data rate again and eventually causes another congestion. The above cycle is repeated as illustrated by the large oscillation of throughput in each node.

3.1.3 Design Task
The goal of. this research is to derive a close-to-ideal mechanism that can reduce the oscillation, thus allocate bandwidth fairly among the nodes, stabilizing the traffic and eventually improving the performance of the system. Fuzzy Logic Control (FLC) is used to achieve this goal. In the next section the implementation of fuzzy logic is discussed in details.

56

3.2 Implementation of Fuzzy Logic Control in RPR
3.2.1 Overview
Fuzzy Logic Control (FLC) can be viewed as an alternative, non-conventional way of designing effective feedback control without relying on formal models of the controlled system and control theoretic tools. FLC has been applied successfully to the task of controlling systems for which analytical models are not easily obtainable or the model itself, if available, is too complex and highly nonlinear. Figure 3.5 is an outlined process ofFLC.

Figure 3.5: An Outlined Process ofFLC

3.2.2 Architecture of FLC
In order to minimize the oscillation, one needs to fine-tune the key control value, local fair rate. Therefore, the proposed FLC algorithm concentrates on fine-tuning local_fair_rate. The FLC unit has two groups of inputs, add_rate and iladd_rate is in one group, rcvd_rate and ilrcvd_rate is in another group, and one output, fuzzy_ add_rate. When rcvd_rate is FULL_RATE, FLC uses add_rate and iladd_rate as input parameters, otherwise usees rcvd_rate and ilrcvd_rate as input parameters. Depending on the situation of the traffic accumulated in Transmit Queue and Transit Queue, the system uses FLC to accelerate or decelerate in sending the traffic intelligently, thus, reducing the oscillation and improving the performance of all the nodes in the ring. Figure 3.6 shows

57

the simplified architecture_ofFLC in RPR. It is similar to the one illustrated in Figure 3.4, except a FLC unit is added.
Downstream Neighbor

rcvd_rate

Fairness Control Unit
rcvd rate lp add rate add rate Transmit Queue

local_fair_rate

Fuzzy Logic Control

add_rate/ rcvd_rate

iladd_rate/ Mcvd_rate

Rate Control Unit
Upstream Neighbor

advertise rate

Legend

D

Control Unit

Traffic Flow Path Internal Information Path

_l__.___.___.lll

Queue

Figure 3.6: Traffic Control System With FLC

FLC algorithm is ignited when the system detects the congestion, which must meet at least one of the following two conditions:

Â· Â·

lp_nr_xmit_rate >= unreserved_rate STQ_depth >= low_threshold

(E3.1) (E3 .2)

58

Here lp_nr_xmit_rate = lp_add_rate + lp_fw_rate, STQ_depth is the traffic accumulated in STQ.

Then, FLC processes the inputs and gets the output, fuzzy_ add_rate, which uses the following formula to generate a new result for local_fair_rate:

local_fair_rate = lp_add_rate + fuzzy_add_rate

(E3.3)

3.2.3 Membership Function (MF)
MF is used to determine how much degree the system is on in a given state. There are many MFs available, trapmf, gaussmf, sigmf, etc. Because RPR is a high-speed switching protocol implemented in MAC layer, timing is a critical issue here, therefore selecting a simple but effective MF becomes a major concern to the success of the implementation. In this version, a simple triangle membership function (trimf) is selected. In Figure 3.7, add_rate is used as an example to demonstrate how MF works.
Y(%

--------------------80%

--------------------20%
------~~~~~~~~~--------------~--------~--0%
x=65
add_rate (Mbps)

Figure 3.7: Triangle Membership Function (trimf) ofadd_rate As it can be seen in Figure 3. 7, horizontal axis represents add_rate in Mbps, vertical axis represents the output of membership functions in percentage, a is the ideal rate we are trying to achieve, [a0, a 1] is the range that the fuzzy works within, w is half of the range size. The input of the function, x, is the add_rate in a certain aging_interval.

59

Here a plays a key role in the success of FLC. Node itself doesn't know what rate is the ideal rate without getting the feedback from other nodes. Therefore, we use rcvd_fair_rate as the estimated value of a if rcvd_fair_rate is not FULL_RATE; otherwise last interval's local_fair_rate is used as the estimated value of a.

There are three membership functions, low_mf(), med_ mf() and high_mf() as illustrated in E3.4, E3.5 and E3.6 that correspondes to three states: low_speed state, med_speed state and high_speed state. For a given add_rate x, the output of the three membership functions corresponding to x can be computed. They represent the ratio of x in these states. For example, as illustrated in Figure 3.7, add_rate x of 65 Mbps gives 0% in low_speed state, 20% in high_speed state and 80% in med_speed state.

1' a-x

x < ao
X

w 0,

2 ao

n

X<

a

(E3.4)

x 2a

0,

x

<

ao

U x 2a1

y2

x- ao w a1- x w

x 2 ao
X

n X< a n X< a1

(E3.5)

2 a

0, x-a w 1,

x<a
X

2 a

n

X<

a1

(E3.6)

x 2 a1

Here xis the add_rate at any given time, a0 is a- w/2, a 1 is a+ w/2.

To achieve the best result from FLC, the range must be selected carefully. It should be neither too wide, otherwise a large degree of oscillation likely occurs; nor too narrow, otherwise the system has less chance to correct oscillation. Our results show that there are

60

no significant differences in performance when w is within the range from around 20Mbps to 40Mbps for the 622Mbps ring. In this thesis, 25Mbps for w is used.

The MFs of ~add_rate is illustrated in Figure 3.8, which is similar to that of add_rate.
nochg_mf()

-25

0

25

Figure 3.8 Triangle Membership Function (trimf) of ~add_rate

3.2.4 If- Then Rules and Defuzzify
If-Then rules is used to determine how FLC is defuzzified. There are five If-Then rules applied in FLC, as shown in Table 3.1:

Rule id

Explanation

WEIGHT

AppliedMF

Output Y

If add rate is low, then Transmit Queue 1 fast increase sending traffic. If add- rate is medium and 2 increase sending traffic. If add- rate is medium and 3
~add

1.0

low_mf()

Yt

~add-

rate is 1/4 neg_mf()

negative, then Transmit Queue slowly

y2

-

rate is 0 nochg_mf()

no_change, then Transmit Queue keeps sending traffic as in last aging_interval.

y3

4

If add- rate is medium and

~add-

rate is

positive, then Transmit Queue slowly

-114

pos_mf()

y4

61

decease sending traffic. If add_rate is high, then Transmit Queue
5

-1.0 fast decrease sending traffic.

high_mf()

Ys

Table 3.1: If-Then Rules

The weight assigned to each rule corresponds to the degree of changes in sending rate for the transmit queue. For example, because rule 1 and rule 5 need larger changes, so more weight to Y 1 and Y 5 is assigned.

Defuzzify is a process that uses applicable rule and the results of MF as input to get the output of FLC. First, let's assume the add_rate x
=

65 Mbps and

~add_rate ~ =

-6.25

Mbps, then, one can get the following outputs from different MFs:

Â· Â·

Y 1 = low_mf(x = 65) = 0.0 Y2 = neg_mf1 (~ = -6.25) = 0.25

Â·

Y3 = nochg_mf(~ = -6.25) = 0.75

Â·
Â·

Y4 = pos_mf(~ = -6.25) = 0.0
Y 5 = high_mf(x = 65) = 0.2

Then, the following formula is used to get the result ofFLC:

w XL {Yi X WEIGHTi}
fuzzy_add_rate
= -----=--i=....:....I_ _ n ----

n

(E3.7)

_LYi
i=l

n is the total number of rules, Yi is the output of MF for rule i , WEIGHTi is the weight

for rule i and the fuzzy_ add_rate is the result of FLC. Therefore,

We didn't give the explanation of ~add_rate and its MFs, so here we just use 0.25 to illustrate how defuzzify works. Same for nochg_mf() and pos_mf().
1

62

25Mbps x [O.Ox 1 + 0.25 x - + 0.75 x 0 + O.Ox (--) + 0.2x (-1)] 4 4 fuzzy add rate = 0.0 + 0.25 + 0.75 + 0.0 + 0.2
=

1

1

-2.86 Mbps

From the result, we can see when the add_rate x

=

65 Mbps and

~add_rate ~ =

-6.25

Mbps, add_rate decreases 2.86 Mbps traffic at the next aging_interval according to the FLC.

There are many methods to defuzzify the Fuzzy Logic. The above method is chosen due to its simple method. The result of FLC is used to fine-tune the traffic in the next aging_interval.. A sample output oflocal_fair_rate is shown in Figure 3.9, as one can see the oscillation is alleviated.
Comparison of local_falr_rate
Mbps

600

500

400

300

200

100

1

2

3

4

5

6

1

a

9

10

aglng_l nlaMII

Figure 3.9: Comparison oflocal_fair_rate

3.3 Case Study
In this chapter, a few testing scenarios are created in OPNET to compare the performance of Fuzzy Logic Control with that of Aggressive and Conservative Algorithms. To simplify the system, OC-12 is used as link type with the maximum bandwidth up to 622 Mbps, packets generated from each node with fixed size, 12000 bit. The delay in each link is set at a fixed value, 70 ns, and reserved rate is 2% of total bandwidth, each node

63

carrtes the same weight. In FLC algorithm, A is last interval's local fair rate if rcvd_fair_rate is FULL_RATE; otherwise it is rcvd_fair_rate.

3.3.1 Scenario 1-16 Nodes Simple Sourced Traffic Scenario
In this scenario, each node from Node 1 through Node 16 inclusive sends traffic at the constant rate of 42 Mbps to Node 0 as shown in Figure 3.10.
42 Mbps
I I I

42Mbps

IJII:

Figure 3.10: 16 Nodes Simple Sourced Traffic Scenario

3.3.1.1 Aggressive Mode

In this scenario, all the nodes are set to run in Aggressive mode. The result is shown in Figure 3.11. Only the throughput of Node 1 is shown, the closest node to the destination (Node 0), and Node 16, the farthest node to the destination. The rest of the nodes behave similar to Node 16.

Figure 3.11: Simulation Results of Node 1 and Node 16 in Aggressive Mode

64

From the result one can see that Node 1 has huge oscillation, Node 16 and others have lesser degree of oscillation than Node 1, but it is still considered to be high.

3.3.1.2 Conservative Mode

Cisco's Spatial Reuse Protocol fairness algorithm (SRP-fa) implemented in OPNET DPT model is running in conservative mode. An exactly the same scenario as the one mentioned above is designed using OPNET DPT model to compare the result, which is shown in Figure 3 .12.

Figure 3.12: Simulation Result ofNode 1 in Conservative Mode Figure 3.12 shows that oscillation in the Node 1 is still quite large. Other nodes behave similar to Node 1.

3.3.1.3 Fuzzy Logic Control Mode

In this scenario, everything is kept the same as the previous case except the traffic control algorithm. Here, Fuzzy Logic Control is used to direct the behavior of the system. The result of simulation runs 1OOms and is shown in Figure 3.13.

65

Figure 3.13: Simulation Results ofNode 1 and Node 16 in FLC Mode

As can be seen in Figure 3.13, Node 1 does not create huge oscillation as in the previous scenarios, same thing for Node 16 1Â· After about 50ms self-adjusting, each node in the ring has steady throughput, shares the bandwidth fairly and the oscillation is virtually eliminated.

3.3.2 Scenario 2 - Parking Lot Scenario

In this scenario, Dual Stage Queue [3] is adapted. Node 1 through Node 16 sends 42 Mbps traffic to Node 0. Furthermore, the last node, Node 16, send additional 210 Mbps traffic to its downstream neighbor, Node 15. In such case, Outer Ring between Node 1 and Node 0 forms a chock point and Node 1 advertises its local_fair_rate of 622 Mbps I 16 = 38.875 Mbps to its upstream neighbors. Upon receiving such rate all the upstream neighbors adjust their throughput to comply with Node 1, including Node 16.

1

All the other nodes behave almost the same as Node 39 so we omit the results for them.

66

42 Mbps 42 Mbps 42 Mbps 210 Mbps
~

42 Mbps
~

Figure 3.14: Parking Lot Scenario

However, Node 16 has extra 210 Mbps traffic sending to Node 15, and this traffic should not be affected by the advertisement from Node 1, otherwise Node 16 does not fully utilize the available bandwidth of the link. Therefore the ideal throughput of Node 16 should be 38.875 + 210 = 248.875 Mbps. Let's study the behaviors of the Aggressive Mode and FLC Mode next.

3.3.2.1 Aggressive Mode

In this scenario all the nodes run in Aggressive mode, the simulation runs 200ms and the results are shown in Figure 3.15.

Figure 3.15: Simulation Results of Parking Lot Scenario in Aggressive Mode 67

As shown in Figure 3.15, Node 1 generates huge oscillation. Throughput of Node 2 through Node 15 is very similar. Only Node 2 is shown here. As can be seen in the figure, oscillation occurs and remains in steady state. Node 16 generates about 250 Mbps traffic in average, which complies with the principle of spatial reuse, but oscillation is also occurred.

3.3.2.2 Fuzzy Logic Control Mode

In this scenario all the nodes run in FLC mode. As shown in Figure 3 .16, oscillations in all the nodes are alleviated after about 50ms for self-adjusting. Meanwhile, Node 16 generates around 250Mbps traffic, which complies with the principle of spatial reuse.

Figure 3.16: Simulation Results of Parking Lot Scenario in FLC Mode

3.3.3 Scenario 3 -Multi-Chock Parking Lot Scenario
In this scenario, two chock points are created in the ring. Again, Dual Stage Queue [3] is adapted here. Node 1 through Node 16 send 42Mbps traffic to Node 0, therefore the link between Node 1 and Node 0 forms the first chock point. In addition, Node 9 through Node 16 send additional42Mbps traffic to Node 8, so the link between Node 8 and Node 9 forms second chock point in the ring, as illustrated in Figure 3.17.

68

42 Mhos

42 Mhos 42 Mhos

Figure 3.17: Multi-Chock Parking Lot Scenario

3.3.3.1 Aggressive Mode

In this scenario, all the nodes run in Aggressive mode, the simulation runs 200ms and the result is shown in Figure 3.18.

Figure 3.18: Simulation Results of Multi-Chock Parking Lot Scenario in Aggressive Mode

As can be seen from Figure 3.18, there are huge oscillation in Node 1. Node 9 has less oscillation than Node 1, but still quite large. All the other nodes don't have too much oscillation.

69

3.3.3.2 Fuzzy Logic Control Mode

In this scenario, all the nodes run in FLC mode, the simulation result is shown in Figure 3.19.

Figure 3.19: Simulation Results of Multi-Chock Parking Lot Scenario in FLC Mode

As one can see in Figure 3.19, the throughput in Node 1 settles in a very small degree of oscillation after about 50ms of self-adjusting period and Node 9 has less oscillation comparing with in Aggressive mode.

3.4 Conclusion
From the above analysis and simulation results, one can observe the FLC algorithm is far more stable and reliable than Aggressive algorithm. The oscillation is reduced together with the full utilization of the bandwidth and the RPR system can almost achieve the ideal designed goal. Therefore, one can confidently implement Fuzzy Logic Control in traffic control system in MAC layer of RPR protocol. Although it is a light-weigh algorithm, it dose solve some issues.

70

Chapter 4: Fairness Round Trip Time (FRTT) And The Size Of STQ

The quality of service depends on the size of STQ. If there is not enough space in STQ, the quality of service is degraded. The minimum size of STQ is studied in this Chapter to prevent low priority traffic from being discarded. IEEE 802.17 draft proposed a formula to calculate the minimal STQ size. The formula depends on the Fairness Round Trip Time (FRTT), but the upper bound of FRTT proposed in the draft is not a true upper bound, " ... this calculation for FRTT is both overestimates and underestimates the true

FRTT' [1]. A true upper bound of FRTT is derived in this Chapter. Using the upper
bound ofFRTT, one can find the minimal size ofSTQ to prevent STQ from overflowing even in the worst-case scenario; at the same time, not wasting STQ's space.

4.1 Bandwidth Reclaimable Characteristic Of ClassAl Traffic
In the dual-transit-queue design of RPR, transit queues are divided into two parts: primary transit queue (PTQ), used to hold ClassAO and ClassA1 traffic; and secondary transit queue (STQ), used to hold ClassB and ClassC traffic. Bandwidth for ClassAO traffic is reserved and is not reclaimable by any other type of traffic. Bandwidth for ClassAl traffic, however, is reclaimable by the lower priority traffic. In other words, if the bandwidth allocated for ClassA 1 traffic is not used by ClassA 1 traffic, ClassB and ClassC traffic can claim it.

This bandwidth reclaimable characteristic of ClassA1 traffic brings a fact that when ClassA1 traffic claiming its bandwidth there maybe a period of time the traffic rate of lower priority class exceeds the bandwidth left for that class, that period can last as long as Fairness Round Trip Time (FRTT). STQ is designed to hold these extra traffic during the period like this, but if designed too short, in the worst case scenario the traffic

71

accumulated in STQ overflows; if designed too large, the fairness algorithm may take longer time to react because of increased value in its traffic control threshold (Low_Threshold) and the transit traffic may suffer longer delay. To find an appropriate size ofSTQ becomes an interesting subject in RPR.

4.2 FRTT

FRTT is the time between when congestion is detected to the time the fairness control takes effect and there is no more congestion in the ring. However, because of the unpredictable, bursty and stochastic nature of the traffic flow in the communication network, it is not possible to determine FRTT precisely, thus it is not easy to determine the STQ size precisely. A major contribution of this thesis is to derive a formula of the upper bound of FRTT to determine the minimal STQ size. The upper bound of FRTT is divided into two periods. The first period is starting from the time when the head of congestion domain is aware of the congestion, thus igniting fairness algorithm and sending the fairness advertisement packet to its upstream neighbor to the time when the tail of the congestion domain receives this fairness advertisement packet. This time period is defined as FRTT 1. The second period, FRTT2, is measured from the time when the tail of congestion domain receives a new fairness advertisement packet sent by its downstream neighbor, denoted as t0 , to all the traffic sent by this tail node before t0 has been drained (delivered to the destination). The upper bound ofFRTT would be the sum of the upper bound of FRTTl and the upper bound of FRTT2. Note that after FRTT the number of queued packets in STQ does not increase, the maximum queue length of STQ should occur within FRTT.

72

4.2.1 The Upper Bound Of FRTTl
Figure 4.1 demonstrates how the upper bound of FRTT1, denoted as MAX(FRTT1), is calculated. Here, traffic is generated from node 1 through node N inclusively and destined in outer ring to node N+ 1. When traffic increased to a threshold, congestion point formed between node N and node N+ 1 and node 1 to node N constitutes a congestion domain.

Data Traffic Flow

Congestion Point

Figure 4.1: Calculate Upper Bound OfFRTT1

At this moment, node N starts running fairness algorithm and gets a fair rate. In the worst-case scenario, node N could wait up to one full advertisement interval, Tadv, to send the fairness advertisement packet to its upstream neighbor, node N-1, and the fairness packet takes hop time, Thop, to reach it. Therefore, the maximum time from node N, which is aware of congestion, to node N-1, which receives fairness advertisement packet, is T adv + Thop. If we define the distance between node x and node y is defined as Dx,v, then Thop could be expressed as Equation 4.1:
= 5us X

Thop

Dx,y

(E4.1)

73

Therefore the maximum ofFRTT1 expressed as Equation 4.2:

MAX(FRTT1) = (N -1) * Tadv +Sus*

Dt,N

(E4.2)

4.2.2 The Upper Bound Of FRTT2
To calculate the upper bound ofFRTT2, let's measure the time it takes for the last packet sent out by node 1 before to until this packet reaches its destination, node N+ 1. This packet is marked as tagged packet. Also, to calculate the upper bound, the tagged packet always finds that the STQ depth of node 1 to node N-1 upon arrival is STQLT. Here
STQLT is the low threshold of STQ, if packet accumulated in STQ beyond this threshold,

node reports congestion. The tagged packet which finds the STQ depth of node N upon arrival isS in the worst-case scenario, where Sis the STQ size in a node.

Two steps are taken to calculate the upper bound of FRTT2. First, the sum of STQ drain time within all the nodes in the ring except the tail node\s calculated; second, the total hop time from the tail node to the head node of a congestion domain is calculated. These two values are added together to get FRTT2. Here the STQ drain time of node i,
Tstq.i,

is

defined as the duration of the tagged packet stays in the STQ of node i before being sent out.

Tstq,i

can be expressed in general as:

T .=
stq,z

STQ _ Depth(i) STQ _Output _Rate(i)

(E4.3)

Here STQ_Depth(i) is the length of the packets accumulated in STQ in node i upon the arrival of the tagged packet, STQ_ Output_Rate(i) is the speed of the node i transmitting the packet out of its STQ.

Fairness eligible traffic generated from the tail node is add traffic, which does not go through transit queue.

1

74

Therefore, the total STQ drain time is the sum of each individual STQ drain time in each node within the congestion domain.

MAX(T ) _ ~ T
stq -

~
1=2

_ ~
stq ,i -

~
1=2

STQ _ Depth(i) S'T'.Q 0 ulpu l _ R al e ( z .) .1.
1 _

(E4.4)

Note that the tagged packet doesn't pass through its own transit queue, so the above formula doesn't take node 1 into consideration.

4.2.2.1 Maximum STQ Drain Time in Node i- MAX(Tstq,i)
To find out the upper bound of STQ drain time, let's assume in the worst-case scenario the tagged frame encounters STQ with STQLT length in node 1 through node N-1 and with S length in node N along the way to its destination. Also, let's assume each node in the ring would generate ClassA 1 traffic at the rate of RA 1Â·and ClassB_ CIR traffic at the rate of Rs and such traffics are evenly distributed within the ring, and the maximum number of node sharing the bandwidth is N, then to node i 1 , 2 ~ i ~ N -1 , we have:

MAX(T . ) = "Â·Â·'

STQLT

(i-l)xLS-N~A1

+Rn) +(N-I)xRn

STQLT =------------------------LS N-1 (i-1)x(--R -R +--R ) N Al B i -1 B STQLT =--------------------LS N-i (i-1)x(- -R +--R ) N Al i -1 B =-----------------------LS N-i 8x(i-1)x(--R +--R ) N Al i -1 B

s

(2 ~ i

~

N -1)

(E4.5a)

Because the traffic in tail node is the local add traffic, it doesn't go through its own transit queue, therefore we don't need to count STQ drain time in this node.

1

75

to node i = N, we have:

s
MAX(I:tq ,n) =
(N-l)x

LS
-

N(R
NAJ+

R )
8

+(N-l)xR8

=

s
(N -1)x LS-NRAI N NS (N -1)x (LS- NRA 1 )
(i

=

= N)

(E4.5b)

Here [LS- N(RAJ + Rs)} IN is the fair_rate that allocated for each node in the congestion domain. RA 1 is the output rate of local add ClassA1 1 traffic and Rs is the output rate of local add ClassB traffic per node. According to the IEEE 802.17 draft, STQLT is 1/8 of S.

Traffic sent from tail node before to goes through N - 1 nodes inside the congestion domain to reach its destination, so we have:

N

MAX(Tstq)

= LMAX(Tstq,i)
i=2

=-xL{
8
i=2

s

N-l

NS }+-----(i - 1) X ( LS - R + N - l R ) ( N - 1) X ( LS - NR AI ) N AI i -1 B
1

.

(E4.6)

4.2.2.2 Upper Bound Of FRTT2 - MAX(FRTT2)

Hop time in FRTT2 is the same as in FRTT 1, the total hop time from node N to node 1
lS:
Thop

= Sus x D 1,N

(E4.7)

The equation for the maximum ofFRTT2 is:
1

Bandwidth of ClassAO is reserved, and it doesn't need to be considered here.

76

MAX(FRTT2) = MAX(Tstq) + Thop

s N-l 1 NS =-xi{ . }+----------8 i=2 (i -1) X (LS- R + N - l R ) (N -1) X (LS- NRAI) N AI i -1 B
+5usxD1,N

(E4.8)

4.2.3 Upper Bound Of FRTT- MAX(FRTT)
The upper bound for FRTT is derived from Equations 4.2 and 4.8 as follows.

MAX(FRTT)

= MAX(FRTT1) + MAX(FRTT2)
S

= (N -1) x Tadv + 5us x D 1,N +- x 8
+
NS +5usxD (N -l)x(LS-NRA 1 ) l,N

I {
i=2 (

N-1

1

i - 1) X ( LS - R + N - l R ) N AI i -1 B

. }

= (N -1) x Tadv + 2 x 5us x D 1 N

s N-l 1 NS +-xi{ . }+-----8 i=2 (i _ 1) x (LS _ R + N -z R ) (N -1) x (LS- NRA 1 ) N AI i -1 B

(E4.9)

4.3 The Minimal Size Of STQ

One of the applications of using the upper bound of FRTT is to determine the minimal size of STQ to hold ClassB and ClassC traffic without overflow even in the worst-case scenarios. IEEE 802.17 draft [ 1] gives a formula to describe the relationship between the size of STQ, FRTT and ClassA1 traffic. The formula is shown as follows:

77

s 2:: STQLT + FRTT X (RAt + RB) + (STQHT- STQLT) X LS- (RAt + RB)
LS

(E4.IO)

In this formula, STQHT is high threshold of STQ, according to the draft, it is equal to 'l4

ofSTQ size.

The draft assumes that in the worst-case scenario all the incoming traffic is either ClassB or ClassC, and that the local add traffic is ClassAI, ClassB, and ClassC traffic.

S2::}_S+FRTTx(R +R )+}_SxLS-(RA +Rs) 8 A B 8 LS

2::}_S+}_S_}_Sx RA +Rs 8 8 8 LS

s
+[(N -I)xTadv+2x5usxD1,N +-x 8
NS (N-I)x(LS-NRA 1 )

L{
i=z

N-l

I LS N _. } (i-I)x(--R +--z R ) N A1 i -I B

+

]x (R + R 8 ) A

(E4.II)

Let's consider

D

=

(N -I) x Tadv + 2 x 5us x D 1,N

,

F=

N , (N -I)x (LS- NRA 1 )

then we have:

2 (R +R 8 ) S2::-S- A S+(D+ES+FS)x(RA +R 8 ) 8 8LS

78

S 'C:. 3_S- (RA +Rs) S + (E +F)x (RA +Rs)x S +Dx (RA +Rs) 8 8LS
[1-3_ + (RA + Rs)- (E + F)x (RA + Rs)]x S 'C:. Dx (RA + Rs) 8 8LS

_6L_S_+_R....:..:A_+_R---=s=----_(E_+_F_)_x_(R_;_:__A_+_R~s_)_x_L_S S > D (R ) X X A+ RB 8LS
---....::...:.....-=----------X

6LS + (RA + RB) X [1- 8(E +F) X LS] 8LS

s

'C:_

D X (R A + R B )

S 'C:.

8DxLSx(RA +R8 ) 6LS + (RA + Rs)x[1-8(E + F)x LS] 8Dx(RA+Rs)
(E4.12a)

S'C:.

6 + RA + RB LS

X

[1- 8(E +F)]

If A, = R A + Rs , then equation 4.25a becomes: LS

s 'C:.

8D X (R A + R B) 6 + ..1[1 - 8( E + F)]

(E4.12b)

4.4 Simulation
To verify the correctness of the above equations, a few scenarios are created in OPNET to compare them with the simulation results. FRTT is divided into several parts to create separate scenarios to verify them. This would allow investigating each part separately.

79

4.4.1 Scenario 1- Verify FRTT1
42 Mbps
I
I I

42Mbps

IIJI:

Figure 4.2: 17 Nodes Simple Sourced Traffic Scenario In the scenario illustrated in Figure 4.2, node 1 through node 16 sends 42Mbps ClassC bursty traffic in outer ring to node 17. Each node sends 20Mbps ClassA 1 bursty traffic to every other node in the outer ring as well. (See Table 4.1.) Thus we expect 70Mbps ClassA 1 bursty traffic passing through PTQ in each node. The distance between two adjacent nodes is 14 kilometers and the advertisement interval Tadv is 0.05 ms.

Traffic Type Start Time (ms) ON Time (ms) OFF Time (ms) Interarrival Time (ms) Packet Size (bits) Traffic Rate (mbps)

ClassA1 40 Exponential (1 0) Exponential (1 0) Exponential (0.3) 12000 20

ClassC 1 Exponential (1 0) Exponential (1 0) Exponential (0.14 3) 12000 42

Table 4.1: Traffic Generation Pattern

According to Equation 4.2,

MAX(FRTT1) = (N- 1)*Tadv + 5us*Dt,N = (16-1) * 0.05 + 0.005 * 14 * 15 = 1.80 (ms)

80

Table 4.2 records the time stamped when a node receiving and sending fairness packet in the OPNET simulation program. FRTT1 is counted as the time spent from node 16 send fairness packet to node 1 receiving fairness packet, which is 51.47- 50.0 simulation result is within calculated parameters.
=

1.47 ms. The

Nodeid

16

15
50.1

14
50.2

13
50.3

12
50.4

11
50.5

10
50.6

9
50.7

8

7 50.9

... ...

3
51.3

2
51.4

1
-

Send Fairness PK 50 At (ms) Receive Fairness PK At (ms) FRTT1 (ms)

50.8

- 50.07 50.17 50.27 50.37 50.47 50.57 50.67 50.77 50.87 ... 51.27 51.37 51.47
51.47-50.0 = 1.47

Table 4.2: Simulation Result ofFRTT1

4.4.2 Scenario 2 - Verify Tstq With Constant Traffic
In this scenario, a RPR ring with 9 nodes is creayed as shown in Figure 4.3, each node sends two types of constant traffic in outer ring 1: 20 Mbps of ClassA in constant rate and 80 Mbps of ClassC in constant rate. ClassA traffic's destination is the node's upstream node, (because the traffic is sent in outer ring, this flow of traffic needs to pass through all the nodes in the ring to reach its destination, which is what is needed.) ClassC traffic's destination is node 9 (see Table 4.3). Node 1 through node 8 starts sending ClassC traffic at 1 ms and ClassA1 traffic at 30 ms.

1

Except node 9 which only sends ClassA traffic.

81

80 Mbps
I I I

80Mbps

II-

Figure 4.3: 9 Nodes Simple Sourced Traffic Scenario

ClassAJ Node Rate (Mbps) Dest. Node Start Time (ms) Rate (Mbps)

ClassC Dest. Node Start Time (ms)

1

20 20 20

9
1

30 30 30

80 80 80

9 9 9

1
1 1

2 3

2

...
8 9

...
20 20

...
7

...
30 30

...
80
-

...
9
-

. ..
1

8

-

Table 4.3: Traffic Generation Pattern

In this scenario the size of STQ is 228,000 bit and N is 8, according to Equation 4.6,

s N-l 1 NS MAX(Tstq)=-xL{ . }+-----8 i=2 (i -1) X (LS- R + N - l R ) (N -1) X (LS- NRAI) N AI i -1 B

82

= 228000

X[

8

1 + 1 6 6 622.08 X 106 622.08 X 10 6 - -- - - 20 x 10 2x( -20x10)

8

+

1
6

6x(622.08x10 _ 20 8

8 8x 228000 ]+----------6 6 x 06 ) (8-1)x(622.08x10 -8x20x10 ) 1

= 0.00177 (s) = 1.77 (ms)

The theoretical result of total maximum STQ drain time of all nodes is 1. 77 ms.

Table 4.4 shows the queuing information of STQ in each node while the tagged packet passing through, including STQ drain time and STQ depth (total packets length in STQ).

Node

Receive PKAt (ms)

tl

SendPKAt t2 (ms)

STQ Drain Time t2- t1 (ms)

STQ Depth (bit)

2 3 4 5 6 7 8

30.81 30.93 31.05 31.18 31.43 31.59 31.90
Total

30.82 30.94 31.07 31.32 31.48 31.79 32.13

0.01 0.01 0.02 0.14 0.05 0.2 0.23 0.66

0 0 0 0 3000 7500 10500 21000

Table 4.4: Scenario Result of Constant Traffic In Each STQ

From table 4.4 one can see the tagged packet spent 0.66 ms to pass though 21000 bit of STQ.

From the result we can see when nodes send traffic in constant rate, the STQ depth in each node is maintained in lower level, some even zero; however in theoretical calculation we assume STQ in each node has at least STQLT bit and the congestion head

83

node has S bit, therefore, the difference of STQ depth between real simulation and theoretical assumption causes the STQ drain time in real simulation far less than that in theoretical calculation.

4.4.3 Scenario 3 - Verify Tstq With Bursty Traffic

In this scenano, all the settings are kept as in the previous scenario except nodes generating bursty ClassA and ClassC traffic - the traffic generation pattern is shown in Table 4.5. The information of tagged packet passing through each node is shown in Table 4.6:

Traffic Type Start Time (ms) ON Time (ms) OFF Time (ms) Interarrival Time (ms) Packet Size (bits) Traffic Rate (mbps)

ClassA1 30 Exponential (1 0) Exponential ( 10) Exponential (0.3) 12000 20

ClassC 1 Exponential (1 0) Exponential (1 0) Exponential (0.075) 12000 80

Table 4.5: Traffic Generation Pattern Of Scenario 3

Node

Receive P KAt (ms)

f)

SendPKAt t2 (ms)

STQ Drain Time - t 1 (ms)

t2

STQ Depth (bit)

2 3 4 5 6 7

67.63 67.76 67.88 68.12 68.60 68.88

67.65 67.77 68.01 68.49 68.77 69.02

0.02 0.01 0.13 0.37 0.17 0.14

0 0 4500 10500 6000 7500

84

8

69.13 Total

69.59

0.46 1.3

19500 48000

Table 4.6: Scenario Result of Bursty Traffic In Each STQ From table 4.6 one can see the tagged packet spent 1.3 ms to pass though around 48000 bits ofSTQ.

From the result one can see when nodes send traffic in bursty rate, the STQ depth in each node is kept in higher level, therefore, the STQ drain time is also higher than that of the constant rate.

4.4.4 Scenario 4- Verify FRTT
In this scenario, all the settings are kept as the above. The theoretical result for FRTT is:
S N -1 1 MAX(FRTT)=(N-1)xTadv+2x5usxD1,N+-xL{ LS N-i} 8 '= 2 (i-1)x(--R +--R) N AI i -1 B

NS +------(N -1) X (LS- NRA I)

=(8-1)x5x10- 5 +2x5x10- 6 x14x7+ 1
[ 6

228000 8 1
6

x
Â·Â·Â·

622.08x10 _ x 106 x(622.08x10 _ x 0 6 ) 20 1 2 20 8 8 8x 228000 +-------------(8-1)x(622.08x106 -8x20x10 6)

+

+

1
6

6 x(622.08x10 _ 20 x 10 6 ) 8

= 3.1

(ms)

85

The actual scenario is illustrated as follows: the time of congestion point formed between node 8 and node 9 was at 66.83 ms, node 8 sent the advertisement packet to its upstream node at 66.85 ms, node 1 received such advertisement packet at 67.42 ms, and the tagged packet sent out by node 1 right before receiving fairness information at 67.40 ms, this packet flowing through all the nodes in the ring and eventually sent out by node 8 at 69.59 ms, so the total FRTT was 69.59-66.83 = 2.76 ms.

4.4.5 Scenario 5 - Verify STQ Size
. . According to equation 4.12b, S ~ 8Dx(R +R 8 )

6 + A-[1 - 8(E + F)]

A

Â·

When RA 1=40 Mbps, N = 8, then

A= RA +RB = 0.0643 LS '

D

= (N -1) x Tadv + 2 x Sus x D 1 N = (8 -1) x 5 x 10-5 + 2 x 5 x 10-6 x 14 x 7 = 1.33 x 10-3 ;
1
N-l

E=-xL{
8
i=2

1

.

(i - 1) X ( LS - R + N - l N Al i -1

1 }=-x R ) 8
B

[

1 1 1 + 6 Â·Â·Â· + 6 ] 6 622.08x10 _ 20 x 106 2 x(622.08x10 _ 20 x 06) x(622.08x10 _ x 06) 20 1 1 6 8 8 8 = 8.11 X 10-9
F

=

N (N -1)x(LS-NRA 1 )

=

8 (8-1)x(622.08x10 6 -8x20x10 6)

= 3. 78 X 10- 9 '

therefore,

S ~ 8Dx(RA +R 8 ) 6 + A-[1 - 8(E + F)]
- 6 + 0. 064 3 X [1 - 8 X (8 .11 X 10- 9 + 3. 7 8 X 10- 9 ) ]
~
>----------------------------~

8 X 1. 3 3 X 10-3

X

40 X 10 6

188354 (bit)

86

From the calculation one can see when ClassA1 traffic is 40 Mbps for each node and there are 8 nodes in the congestion domain, if the STQ size set to be more than 188354 bits, the loss of data, theoretically, would not happen even in the worst-case scenario.

In the final scenario, let's setup a worst-case situation, where only node 1 and node 8 generate traffic. The generation rate of node 1 is 500 Mbps in bursty and node 8 is 100 Mbps in bursty. Figure 4.4 illustrates ClassC traffic generation pattern in this scenario. Moreover, each node in the ring is setup to generate 40 Mbps ClassA1 traffic in bursty. STQ's full size is set to 192000 bit in each node.

SOOMbps

...

IOOMbps

...

Figure 4.4: 2 Nodes Simple Sourced Traffic Scenario

Table 4.7 shows the maximal STQ depth occurred in each node. From the result one can see that the maximal STQ depth does not exceed the theoretical calculation.

Node

Maximal STQ Depth (bit)

2 3 4 5

24000 36000 24000 24000

87

6
7 8

36000 36000 96000

Table 4.7: Maximal STQ Depth In Each Node Of Scenario 5

88

Chapter 5: Conclusion and Future Work
5.1 Conclusion
This thesis has presented the architecture and simulation of Resilient Packet Ring, a next generation layer-2 protocol that is implemented in the high-speed switches or routers. The contribution achieved in this thesis are as follows.

5.1.1 Design and Implementation of the Simulation Model
The first contribution of this thesis is the design and development of a simulation model to serve future research purposes. The main requirement on such a model is that the simulation model must be able to accurately follow the protocol from the IEEE 802.17 proposal, otherwise, the simulation results generated from the model would be incorrect. Therefore, great efforts had been put to make sure the accuracy of the architecture and the simulation code in the model.

The model has been designed in four layers, upper layer, LLC layer, MAC layer and Physical layer. Upper layer simulates the IP traffic, LLC and MAC layer is where the RPR resides in, Physical layer simulates sending and receiving the packets. In the MAC layer, there are control units and queues in which major RPR protocols implemented. Topology Discovery, Ringlet Selection, Fairness Algorithms and Rate Control are the main protocols implemented in this in-house simulation bed.

5.1.2 Fuzzy Logic Control
An alternative fairness algorithm, Fuzzy Logic Control, has been designed and

implemented to overcome the limitation of the Aggressive and Conservative algorithms proposed by IEEE 802.1 7 Work Group. Aggressive algorithm is fast in convergent but has large oscillation when high volume traffic is flowing in the ring, Conservative

89

algorithm has less oscillation but is slow in convergent, furthermore it does not utilize the bandwidth efficiently. Fuzzy Logic Control is an intelligent bandwidth control algorithm that reduces the oscillation and has a fast convergent time.

5.1.3 FRTT And The Minimal Size Of STQ
Fairness Round Trip Time reflects the time for the effect of fairness algorithm takes effect on the traffic flow in the congestion domain. The upper bound of FRTT is derived and from it the minimal size of STQ is derived. Simulation results confirm the validity of the derivation.

5.2 Future Work
The future work should concentrate on the following topics.

5.2.1 Ring Protection
One of the outstanding features of RPR, which is similar to SONET/SDH, is that it can monitor the connectivity of the ring. Once it finds the link is broken it automatically uses another ring to transfer the traffic, hence keeping the connectivity for all the nodes in the ring. The performance of RPR during such link failure should be studied.

5.2.2 Improvement of Fuzzy Logic Control
In this thesis we introduced Fuzzy Logic Control as an alternative algorithm for

bandwidth control. However the algorithm in FLC is in its primary stage. Our study concentrated mainly on whether it is possible to reduce the degree of oscillation by applying the concept of Fuzzy Logic. More study is required to derive a better membership functions and Fuzzy Logic Rules for RPR.

90

5.2.3 Improvement of QoS Control
Many areas are still left open for QoS control. The in-house RPR model can act as a research platform to investigate the QoS.

5.2.4 Improvement of FRTT
From the simulation results one can see that the FRTT bound derived here may not by very tight. A tighter bound is certainly more desirable for the estimation of STQ size.

5.2.5 Improvement of Fairness Algorithm
Fairness Algorithm is working well when upstream nodes try to compete for the bandwidth, however, when some of the upstream nodes generate far more less than fair share bandwidth, problem occurs. Figure 5.1 shows one example of such scenario, in which Node 1 generate 580 Mbps traffic to Node 3 and Node 2 only generate 30 Mbps traffic to Node 3. In this case when the link between Node 2 and Node 3 is congested, Fairness Algorithm is ignited in Node 2 and a fair-shared rate are calculated, which is 300 Mbps in this scenario and such rate is advertised out to Node 1. Once Node 1 receives such rate, it adjusts itself to accommodate the change, therefore, Node 1 generates 300 Mbps traffic to Node 3. However, Node 2 still sends the traffic at its original rate, so the total bandwidth of the link between Node 2 and Node 3 is 300 + 30 = 330 Mbps. Because the link is not congested at this moment, fairness algorithm directs Node 2 to advertise full rate to its upstream nodes. When Node 1 receives such advertised rate, it sends the traffic to Node 3 at its original rate, which forms another round of oscillation. Figure 5.2 shows such result.

91

580Mbps IJila 30Mbps ~

Figure 5.1: 2 Nodes High-Low Rate Scenario

Figure 5.2: Simulation Result of High-Low Rate

Currently, this is an unsolved problem among RPR community. An open area for further research is to find a solution for this problem.

92

Appendix A: Building Topology Database
The following is the pseudo code 1 of constructing the topology database.

First, a packet structure and topology database structure are defined and named as
Packet and TopoMap respectively.

struc Packet

{

int int int int char

src address; dest_address; ri; ttl; pk_type[];

II Ringlet id. II TTL, also used as hop count.

} i

struct TopoMap

{

int int int Boolean Boolean

mac - address; hopcount_rO; hopcount_rl; reachable - rO; reachable - rl;

}i

Packet* TopoMap

pkptr; topo_map[255]; II Maximum number of record.

At the startup of the simulation program, each node needs to initialize its own topology database by calling Ini tTopoMap () function.

The code illustrated here is not a duplication of that in the source code of the simulation program. It is only used to demonstrate the functionality of the protocols.

1

93

void InitTopoMap()

II Initialize this node.
topo_rnap[O] .rnac_address topo_rnap[O] .hopcount rO topo_rnap[O] .hopcount rl topo_rnap[O] .reachable rO topo_rnap[O] .reachable rl this node address; 0; 0; TRUE; TRUE;

II Initialize other nodes.
for (int i=l; i<255; i++)

topo_rnap[i] .rnac_address topo_rnap[i] .hopcount rO topo_rnap[i] .hopcount rl topo_rnap[i] .reachable rO topo_rnap[i] .reachable rl

0; 0; 0; FALSE; FALSE;

return 0;

Each node on the ring broadcasts topology discovery packet to both rings at the initial phase of the simulation program and periodically later on. In another word each node on the ring receives topology discovery packet from time to time. When a node received such a packet, it retrieves the information from the packet to build or maintain its topology database. The following code demonstrates this functionality.

Boolean CreateTopoMap (Packet* pkptr)

for

(int i=l; i<255; i++)

94

II foreign node has record in this node.
if (topo_map[i] .mac_address break; pkptr->src address)

II find the first available bland record.
else if (topo_map[i] .mac address == 0) break;

if (i==255)

printf ("Error: Out of space for foreign node.ln"); return 1;

topo_map[i] .mac address

pkptr->src_address;

if (pkptr->ringlet id

0)

topo_map[i] .hopcount rO = pkptr->ttl; topo_map[i] .reachable rO = TRUE;

else

topo_map[i] .hopcount rl = pkptr->ttl; topo_map[i] .reachable rl = TRUE;

return 0;

95

Appendix B: Implement of FLC in C Language
This section explains how C language is used to implement FLC into RPR.

B.l Sample C Codes Of Membership Function
Low Membership function has three arguments, aO, al and x that corresponds to equation E3.4, and the return value y corresponds to Yl. The function prototype of f_low_trimf ()
IS:

double flow trimf (double aO, double al, double x);

The sample C code of low membership function, f_low_trimf (), is given as follows.

I*

Low Triangle MF or Negative Triangle MF.

*I

double f low trimf (double aO, double al, double x)

double y, a, w;

I*
a
=

a is the middle point between aO and al. (al + aO)

*I

I 2;

I*
w
=

w is the half distance between aO and al. (al - aO)

*I

I 2;

I*

Get the return value based on the input.

*I

if (x < aO)

y = 1.0;
else if (x >= aO && x < a)
y
=

(a -

x)

I w;

else y 0.0;

return (y);

96

Here the C code

if (x < aO)
y
=

1.0;

else if (x >= aO && x < a)
y
=

(a - x)

I w;

else y 0.0;

corresponds to E3.4.

Medium Membership function and High Membership function have the same structure as that of Low Membership function except the equation to get the result is different.

Let's use x = 65 Mbps in Figure 3.7 as an example, when we put x into low membership function, the result equals to 0; when we put x into medium membership function, the result equals to 0.8; when we put x into high membership function, the result equals to 0.2. In the Fuzzy Logic's point of view, we no longer refer to 65 Mbps as fast or slow; instead, we consider it to be in the state of 0 percent slow, 80 percent normal and 20 percent high.

B.2 Sample C Code Of If-Then Rule
Once we get the result from Membership Functions, we need to put the result of it into the If-Then Rule. The prototype of If-Then Rule function is:

double get if then_rule (int rule_id, double w, double percentage);

Here, the argument rule_id is described in Table 3.1, w percentage is the return value from Membership Functions.

IS

explained in Figure 3.7,

97

The sample C code is shown below.

double get if_then_rule (int rule id, double w, double percentage)

double y;

switch (rule id)

case 1:

II rule 1.
(double) (w * percentage);

y

=

break;

case 2:

II rule 2.
(double) (w * percentage I 4) ;

y

=

break;

case 3:

II rule 3.

y

= 0.0;

break;

case 4 :

I I rule 4 .

y = (double) -(w *percentage I 4);
break;

case 5:

II rule 5.
(double) -(w *percentage);

y

=

break;

default:

printÂ£ ("Error: Unable to determine rule id.\n");

98

break;

return (y);

Each rule has a membership function associated with it. Their product multiplied by the weight determines the rate that the system should go for in the next step. However there are five rules in the system and the system can only generate one result, therefore we need to defuzzify these five rules so as to get only one result. Defuzzify is explained next.

B.3 The Sample C Code OfDefuzzify
The sample C code ofDefuzzify is deprived from E3.7 and is shown as follows:
* y[OJ [OJ + output [1J * y[1J [OJ + output [2J

result

=

(int)

((output [OJ

* y[1J [1J + output[3J * y[1J [2J + output[4J * y[OJ [2J) I
(y[OJ [OJ + y[1J [OJ + y[1J [1J + y[1J [2J + y[OJ [2J));

Here, the output array contains the return values from get_if_then_rule () function, y array contains the return values from membership functions.

B.4 The Sample C Code Of Fuzzy Logic Control
The following code is a sample of whole piece for Fuzzy Logic Control.
/* Triangle Fuzzy Algorithm

*/

int

fuzzy_trimf

(double

input1,

double

input1_a0,

double

input1_a1,

double input2, double input2_a0, double input2_a1, const double w) double double int y[2J [3J; output[SJ; result;

99

/* 1.1 Low membership function.

*/

y[OJ [OJ =flow trimÂ£ (inputl_aO, inputl al, inputl);

/* 1.2 Medium membership function.

*I

y[OJ [lJ = f med trimÂ£ (inputl aO, inputl_al, inputl);

/* 1.3 High membership function.

*I

y[OJ [2J = f hi trimÂ£

(inputl aO, inputl al, inputl);

/* 2.1 Negative membership function.

*I

y[lJ [OJ = f low trimÂ£ (input2 aO, input2 - al, input2);
/* 2.2 No-change membership function.

*I

y [ lJ [ 1 J = f med trimÂ£ (input2_a0, input2 al, input2);

/* 2.3 Passive membership function.

*I

y[lJ [2J = f hi trimÂ£

(input2 aO, input2 - al, input2);

/* If-Then Rules.

*I

output[OJ output[lJ output[2J output[3J output[4J

get if - then rule ( 1, w, y [OJ [OJ); get if_then_rule ( 2, w, y[lJ [OJ); get if then rule (3, w, y [ 1 J [ 1 J); get if_then_rule ( 4, w, y[lJ [2J); get if - then- rule ( 5, w, y [OJ [2J);
*/

/* Defuzzify.

result

=

(int)

( (output[OJ

*

y[OJ [OJ

+ output[lJ

*

y[lJ [OJ

+

output[2J * y[lJ [lJ + output[3J * y[lJ [2J + output[4J * y[OJ [2J) I (y[OJ [OJ + y[lJ [OJ + y[lJ [lJ + y[lJ [2J + y[OJ [2J));

return (result);

100

Here, input1, input1_a0, input1_a1 are the arguments for add_rate membership functions; input2, input2_ aO, input2_ a1 are the arguments for half of the range FLC fluctuates within.
~add_rate

membership functions; w is

101

Reference
[ 1]. IEEE Standard Department, "IEEE Proposed Draft Standard for Information Technology - Part 17: Resilient packet ring access method and physical layer specification," January 2002. [2].RFC 2892, Cisco System, "The Cisco SRP MAC Layer Protocol", August 2000. [3].K. Yip, N. Ma, H. Ghandehari, X. Zhang, and K. Raahemifar, "Design and Performance Analysis of RPR with Dual Stage Queues", RPR Report 1001 , Ryerson University, Computer Networks, March 2003. [4].Mathworks.com, Fuzzy Logic Tool Box, http://www.ieee802.org/17/documents/drafts/Darwin v1 O.pdf,

http://www.mathworks.com/access/helpdesk/help/toolbox/fuzzy/fuzzy.shtml [5].0PNET Modeler 8.0 Online Documentation, OPNET Technologies, Inc. [6].Alberto Leon-Garcia, Indra Widjaja, "Communication Networks -Fundamental Concepts and Key Architectures", McGraw-Hill, 2000. [7].Internetworking Technology Handbook, Cisco Systems,

http://www.cisco.com/univercd/cc/td/doc/cisintwk/ito doc/qos.htm [8].An Introduction to Resilient Packet Ring Technology, Lantern Communications, http://www .lanterncom.com

102

