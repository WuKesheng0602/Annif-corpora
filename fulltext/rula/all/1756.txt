Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2012

Modelling Hedge Fund Indices Using Levy Processes
Ugochi T. Emenogu
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Mathematics Commons Recommended Citation
Emenogu, Ugochi T., "Modelling Hedge Fund Indices Using Levy Processes" (2012). Theses and dissertations. Paper 1326.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

´ MODELLING HEDGE FUND INDICES USING LEVY PROCESSES

by Ugochi Theresa Emenogu B.Sc. Specialized Honours, Computational Mathematics York University, Toronto, Ontario, Canada, 2009

A Thesis presented to Ryerson University in partial fulfilment of the requirements for the degree of Master of Science in the Program of Applied Mathematics

Toronto, Ontario, Canada, 2012 c Ugochi T. Emenogu 2012

DECLARATION I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my thesis may be made electronically available to the public.

ii

Modelling Hedge Fund indices Using L´ evy Processes Master of Science, 2012 Ugochi Theresa Emenogu Applied Mathematics Ryerson University ABSTRACT In this thesis, the use of L´ evy processes to model the dynamics of Hedge fund indices is proposed. Merton (1976) and Kou (2002) models which differ on the specification of the jump components are employed to model hedge funds in continuous time. Secondly, an alternative to the Maximum Likelihood Estimation (MLE) method, Empirical Characteristic Function (ECF) estimation method, is explored in our analysis and compared to MLE. The Cumulant Matching Method (CMM) is used in getting the starting parameters; and the method that overcomes the major problem associated with this estimation method is outlined. Calibration shows that these two models fit the data well, however, the empirical comparison shows that double exponential jumps are more consistent with the empirical data. Each fund's exposure to risk is calculated using Monte Carlo Value-at-Risk (VaR) estimation method.

iii

ACKNOWLEDGMENTS I would like to express sincere gratitude to my supervisor, Dr. Pablo Olivares for his guidance throughout this project. His suggestions, constructive comments and financial support have been of great value to me. I would also like to thank all my friends, staff and faculty members at Ryerson University who in one way or the other contributed to the realization of this thesis. It is my pleasure to thank my husband, Peter, whose love and persistent confidence in me has helped in successful realization of this thesis. My children, Valentine, Ozzy and Chris, deserve special mention for the sacrifices they made during my study period. Finally, my special gratitude goes to my brothers and sisters and my parents in-law for letting me have this opportunity. This thesis was supported by Ryerson University and Ontario government through Queen Elizabeth II Graduate Scholarship in Science and Technology (QEII-GSST).

iv

DEDICATION Dedicated to the memories of mum, dad and big brother Paul Henry.

v

TABLE OF CONTENTS

1 2

Introduction

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 4 4 5 5 6 6 7 8 20 20 21 21 21 22 23 23 24 27 29 37 37 38

Hedge Funds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1 2.2 Brief History of Hedge Fund Industry . . . . . . . . . . . . . . . . . . . . . Investment Styles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.1 2.2.2 2.2.3 2.2.4 2.2.5 Tactical Trading Investment Style . . . . . . . . . . . . . . . . . . . The equity long/short style . . . . . . . . . . . . . . . . . . . . . . . The event-driven Style . . . . . . . . . . . . . . . . . . . . . . . . . . Relative Value Arbitrage . . . . . . . . . . . . . . . . . . . . . . . . . Statistical Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

Theoretical Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1 L´ evy Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1.1 3.1.2 3.1.3 3.1.4 3.1.5 3.2 Characteristic Function of a L´ evy Process . . . . . . . . . . . . . . . L´ evy Khintchine Theorem . . . . . . . . . . . . . . . . . . . . . . . . Infinitely divisible distributions and the L´ evy-Khintchine formula . . Jump Diffusion Models . . . . . . . . . . . . . . . . . . . . . . . . . Infinite Activity Model . . . . . . . . . . . . . . . . . . . . . . . . . .

Estimation Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 3.2.2 3.2.3 Maximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . Generalized Method of Moments . . . . . . . . . . . . . . . . . . . . Characteristic Function Estimation Method . . . . . . . . . . . . . .

3.3

Monte Carlo Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.1 3.3.2 Principle of the Monte Carlo Simulations . . . . . . . . . . . . . . . Monte Carlo Simulation of L´ evy Processes . . . . . . . . . . . . . . . vi

4

The Models for Hedge Fund 4.1

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

39 39 42 43 43 45 46 47 47

Merton's Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.1.1 4.1.2 4.1.3 The Characteristic Function and Moments of Merton's Model . . . . Transition Density . . . . . . . . . . . . . . . . . . . . . . . . . . . . Simulation of Merton's Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.2

Kou's Model 4.2.1 4.2.2 4.2.3

Kou's Model Specification . . . . . . . . . . . . . . . . . . . . . . . . The Characteristic Function and Moments of Kou's Model . . . . .

Simulation of Kou's Model . . . . . . . . . . . . . . . . . . . . . . .

5

Numerical Implementation and Parameter Estimation Under Merton and Kou Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1 5.2 5.3 5.4 5.5 5.6 5.7 Method of Moments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Maximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . . Generalised Method of Moments (GMM) . . . . . . . . . . . . . . . . . . . 50 50 52 56 57 58 58 70 74 75 76 76 77 78

Characteristic Function Estimation Method . . . . . . . . . . . . . . . . . . Discussion of Results from Parameter Estimation . . . . . . . . . . . . . . . Goodness of Fit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Application to Risk Management . . . . . . . . . . . . . . . . . . . . . . . .

6

Conclusion and Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A The Derivation of The Characteristic Functions . . . . . . . . . . . . . . . . . . A.0.1 Derivation of Characteristic function for Merton's Model . . . . . . . A.0.2 Derivation of Characteristic function for Kou's Model . . . . . . . . B MAPLE codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

vii

C

MATLAB and SAS Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C.1 Matlab Code for Computing the MLE for Merton Model . . . . . . . . . . . C.2 Matlab code for Merton Model PDF . . . . . . . . . . . . . . . . . . . . . . C.3 MATLAB Code for Kou Model PDF . . . . . . . . . . . . . . . . . . . . . . C.4 MATLAB Codes for Cumulant Matching Method . . . . . . . . . . . . . . . C.5 MATLAB Code for Simulating Merton Model . . . . . . . . . . . . . . . . . C.6 MATLAB Code for Simulating Kou Model . . . . . . . . . . . . . . . . . . . C.7 MATLAB Code for ECF estimation method for Kou Model . . . . . . . . . C.8 SAS Code for estimation of Kou Model Parameters using GMM method . .

80 80 81 81 82 83 84 87 88 90 97

D

Tables Showing Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

References

viii

LIST OF TABLES

2.1

Descriptive statistics for HFRX index data from March 2003 to July 2007 taken from HFR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2.2

Descriptive statistics for HFRX index data from August 2007 to December 2008 taken from HFR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2.3

Descriptive statistics for HFRX index data from January 2009 to May 2012 taken from HFR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 12

2.4 2.5 2.6 5.1

Correlation Matrix for HFRX index data from March 2003 to July 2007 . .

Correlation Matrix for HFRX index data from August 2007 to December 2008 12 Correlation Matrix for HFRX index data from January 2009 to May 2012 . KS distance and Probabilities For Pre-Crisis Returns Using MLE Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 12

5.2

KS distance and Probability For Pre-Crisis Return Using ECF Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 71 71 72 72 72 72 91 92 93 94

5.3 5.4 5.5 5.6 5.7 5.8

99% Value-at-Risk Estimates For Pre-Crisis Data Using MLE . . . . . . . . 99% Value-at-Risk Estimates For Pre-Crisis Data Using ECF . . . . . . . . 99% Value-at-Risk Estimates For Crisis Data Using MLE . . . . . . . . . . 99% Value-at-Risk Estimates For Crisis Data Using ECF . . . . . . . . . . 99% Value-at-Risk Estimates For Post-Crisis Data Using MLE . . . . . . . 99% Value-at-Risk Estimates For Post-Crisis Data Using ECF . . . . . . . .

D.1 Parameter Estimates for Merton's Model . . . . . . . . . . . . . . . . . . . . D.2 Parameter Estimates for Merton's Model . . . . . . . . . . . . . . . . . . . . D.3 Parameter Estimates for Merton's Model . . . . . . . . . . . . . . . . . . . . D.4 Parameter Estimates for Kou's Model . . . . . . . . . . . . . . . . . . . . . ix

D.5 Parameter Estimates for Kou's Model . . . . . . . . . . . . . . . . . . . . . D.6 Parameter Estimates for Kou's Model . . . . . . . . . . . . . . . . . . . . .

95 96

x

LIST OF FIGURES

2.1 2.2 2.3 2.4 2.5 2.6

The Time Series of Hedge Fund indices for Period 2003-2012 . . . . . . . . The Log returns of Hedge Fund indices for Period 2003-2012 . . . . . . . . .

9 10 13 14 15

The Time Series of Hedge Fund indices for Pre-crisis returns (2003-2007) The Time Series of Hedge Fund indices for Crisis returns (2007-2008)

. . .

The Time Series of Hedge Fund indices for Post-crisis returns (2009-2012) . The empirical density (histogram) and fitted normal density (red line) for Pre-crisis returns (2003-2007) . . . . . . . . . . . . . . . . . . . . . . . . . .

17

2.7

The empirical density (histogram) and fitted normal density (red line) for Crisis returns (2007-2008) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

2.8

The empirical density (histogram) and fitted normal density (red line) for Post-crisis returns (2009-2012) . . . . . . . . . . . . . . . . . . . . . . . . . 19

4.1

Simulated Merton's Model path, parameters µ = 0,  = 0.2, µj = 0, j = 0.2, and  = 3.45. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.2

Simulated Kou's Model path, parameters µ = 0,  = 0.2, 1 = 0.2, 2 = 0.3, p = 0.5, and  = 4.25. . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 53 54 54 55

5.1 5.2 5.3 5.4 5.5

Mesh Plot of  ,  and Log-likelihood for G. Hedge . . . . . . . . . . . . . . Mesh Plot of  ,  and Log-likelihood for E. Driven . . . . . . . . . . . . . . Mesh Plot of  ,  and Log-likelihood for C. Arbitrage . . . . . . . . . . . . Mesh Plot of  ,  and Log-likelihood for E. Weighted . . . . . . . . . . . . The QQ plot of Kou fitted Global hedge and Event driven strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

60

xi

5.6

The QQ plot of Kou fitted Convertible Arbitrage and Equally weighted strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

5.7

The QQ plot of Merton fitted Global hedge and Event driven strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

5.8

The QQ plot of Merton fitted Convertible Arbitrage and Equally weighted strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 66 66

5.10 Fitted Event Driven Using Kou Model Parameter Estimates . . . . . . . . . 5.9 Fitted Global Hedge Log-return Using Kou Model Parameter Estimates . .

5.11 Fitted Convertible Arbitrage Log-return Using Kou Model Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.12 Fitted Equally Weighted Using Kou Model Parameter Estimates . . . . . . 5.13 Fitted Global Hedge Log-return Using Merton Model Parameter Estimates 5.14 Fitted Event Driven Log-return Using Merton Model Parameter Estimates 5.15 Fitted Convertible Arbitrage Log-return Using Merton Model Parameter Estimates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 67 67 68 68

5.16 Fitted Equally Weighted Log-return Using Merton Model Parameter Estimates 69

xii

LIST OF APPENDICES

Appendix A: The Derivation of The Characteristic Functions . . . . . . . . . . . . . Appendix B: MAPLE codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

76 78 80 90

Appendix C: MATLAB and SAS Codes . . . . . . . . . . . . . . . . . . . . . . . . . Appendix D: Tables Showing Parameter Estimates . . . . . . . . . . . . . . . . . .

xiii

Chapter 1

INTRODUCTION

It has been known that the behaviour of asset returns is not modelled well with Brownian motion because these models are inconsistent with market data, typically in relation to the dynamics of the asset return process. A number of extensions have been proposed. Adding jumps to standard Brownian motion is one of the extensions. Jump diffusion models are used because asset return distributions tend to have heavier tails than those predicted by a normal distribution. This is because asset returns experience occasional discontinuities, causing the returns to be generated by a mixture of both continuous and jump processes. Merton [30] explored jump diffusion models to describe discontinuous changes of stock returns upon arrival of new information. He added Poisson jumps to a standard geometric Brownian motion process to link the changes in asset return to arrival of unanticipated information. His model approximates underlying stock returns generated by a mixture of both continuous and jump processes. Despite the abundance of continuous-time models for stocks, commodities and market indices, in hedge funds, a continuous-time approach has not been followed previously. The first contribution made in this thesis is developing a continuous-time model for hedge fund modelling by using L´ evy process models of log returns of hedge funds, exploiting data from the Hedge Fund Research (HFRX) hedge-fund database for the period 2003-2012. Secondly, since Maximum Likelihood Estimation method (MLE) is difficult to use in some complicated problems, an alternative estimation method - Empirical Characteristic Function (ECF) estimation method which builds on the works done by [19] and [36] is explored in the analysis using Cumulant Matching Method (CMM) and Generalized Method of Moments (GMM) to get and improve on the starting parameters for the models respectively. In the 1

analysis, the MLE estimates are compared to those of ECF and the asymptotic variance of both models are found and used in estimating the standard error of the ECF estimates. Risk analysis based on Kou and Merton rather than Gaussian based model was performed for different period of time and investment style behaviours. The goodness of fit of the models is done by comparing the quantiles and densities of the empirical data and the simulated data from Kou and Merton models. Kolmogorov-Smirnov goodness of fit test is also used to test whether the empirical and fitted distributions are sampled from the same distribution. The dynamics of hedge fund indices are best captured by models that fit the data well. In this thesis, two popular jump diffusion models are compared using historical HFRX indices data for selected hedge fund styles. The models considered are those proposed by Merton [30] and Kou [24] which differ on the specification of the jump component. In the former model, jumps follow a log-normal distribution whereby in the latter the jump component is drawn from a double exponential distribution. Calibration shows that these two models fit the data well, however, our empirical comparison shows that double exponential jumps are more consistent with the empirical data capturing asymmetries. In the next chapter a brief discussion of hedge funds and the main styles of hedge fund strategies in relation to the distribution of the indices, the dynamics of the data and descriptive statistics is outlined. In the third chapter, L´ evy processes are introduced and their major mathematical properties, beginning from Poisson process which is the starting point of jump processes, are presented. Also, the mathematical tools useful for estimating the parameters of the models and the methods used in parameter estimation are presented. In chapter four, the models used in the thesis are specified and discussed; the characteristic functions and distributions of jumps for both models are shown. Numerical implementation and results are presented in chapter five; parameter estimation for both Merton and Kou Models using ECF and MLE methods are outlined and compared, the simulated data from the models are compared to the empirical data using QQ-plots, densities fitting and Kolmogorov-Smirnov (KS) goodness of fit test. Application in risk assessment 2

is presented in chapter six; Monte Carlo Value-at-Risk (VaR) method is used to estimate the VaR of each of the four funds analysed and one way these estimates can be used in risk management is outlined. The final discussion and proposals of a future work are included in the Conclusions. Derivations of theoretical results, tables of parameter estimates and applied program codes in MATLAB 1 , MAPLE 2 and SAS 3 are presented in the Appendix.

1 2

MATLAB is a programming environment for algorithm development,numerical computation,etc. MAPLE is a commercial symbolic mathematical engine that manipulates formulas 3 SAS is system of software products provided by SAS Institute Inc. used for statistical analysis, etc.

3

Chapter 2

HEDGE FUNDS

In this chapter a brief discussion of hedge funds and the main styles of hedge fund strategies in relation to the distribution of the indices, the dynamics of the data and descriptive statistics is outlined.

2.1

Brief History of Hedge Fund Industry

Hedge funds are privately organized and lightly regulated investment partnership that invests in a range of securities that are professionally managed in an attempt to increase expected return while reducing risk. Different types of strategies and techniques can be used to achieve the same investment objectives. Alfred Winslow Jones, who established the first hedge fund as a general partnership in the US in 1949, is considered the father of hedge funds [2]. Since 1966, when Jones's unique and highly successful strategies were made known to the public, the hedge fund industry has grown into a global business at the forefront of investment innovations [2]. Jones merged two speculative tools, short selling and leverage into a conservative strategy for investing in both rising and falling market. In the 1950's and 60's, the hedge fund outperformed equity mutual funds. Many hedge fund managers entered the market due to Jones success but failed to use his model. They used only leverage which led to failure during the bear market of 1970's. The number of hedge funds decreased from up to 200 in the 60's to 68 in 1984 [26]. The decline in stock prices following March 2000 and the need to diversify risk spurred many investors to search for alternative investments less correlated with traditional markets [3] which have led to a rapid growth in hedge fund in recent years. Based on estimate, there are more than 6000 hedge funds now around the world managing over 1 trillion US dollars. 4

Around 80% of the hedge funds are smaller than $100 million and around 50% are smaller than $25 million, which reflects the high number of recent new entries [20].

2.2

Investment Styles

Hedge fund investment strategies tend to be quite different from the strategies followed by traditional money managers. Moreover, in principle every fund follows its own proprietary strategy. Although the term "hedge fund" is often used generically, in reality hedge funds are not all alike; they are a very heterogeneous group. Hedge funds managers, consultants, and investors often segregate the hedge fund market into a range of investment styles in order to develop a coherent plan to exploit the opportunity offered by hedge funds. For the sake of simplicity the classification by [26] which groups hedge funds into four main strategies is used in this thesis. The four main strategies are tactical trading investment style, equity long/short style, event driven Style and relative value arbitrage. The fifth classification comprises funds that follow more than one strategy as well as funds of funds. 2.2.1 Tactical Trading Investment Style

This style speculates on the direction of market prices of currencies, commodities, equities or bonds on a systematic or discretionary basis. Two styles in this category are: Global Macro Managers These managers carry long and short positions in any of the world's major capital or derivative markets. They usually rely on a top-down global approach and base their trading views on overall market direction as influenced by major economic trends and events. Due to their discretionary approach, the quality of the manager is the sole key to a fund's success. Commodity Trading Advisors and Managed Futures Managers These Managers trade listed financial and commodity futures markets and currency markets on behalf of their clients. The managers are usually referred to as Commodity Trading

5

Advisors, or CTAs. They are split into two groups, systematic and discretionary traders. Systematic traders tend to analyse historical price movement to anticipate future prices and make trading decisions, while discretionary managers use a more fundamental approach. 2.2.2 The equity long/short style

Long/short equity managers invest in equities, and combine long investments with short sales to reduce but not eliminate market exposure. In an equity hedge (long/short equity) strategy, the managers investment decisions depend on the degree to which individual stocks are undervalued or overvalued relative to current market prices. This strategy is heavily reliant on manager's skill in discerning a stock's fair value. Styles in this category are: Regionally or industry focused managers These managers specialize in a particular region. Dedicated short managers These managers only use short positions. Emerging market funds These managers invest in all types of securities in emerging markets around the world. Market timers These managers vary their long/short exposure in response to market factors within a short period of time. 2.2.3 The event-driven Style

An event-driven strategy is designed to capture price movements generated by a significant pending corporate event, such as a merger, corporate restructuring, liquidation, bankruptcy, or reorganization. Distressed securities and risk arbitrage are the predominant styles in this category. Distressed Securities Distressed securities managers trade the securities of companies that are, or are expected to 6

be in financial or operational difficulty such as bankruptcy, reorganizations, distressed sale and other corporate restructuring. Distressed or high-yield securities are generally below investment grade, and require extensive due diligence to take advantage of the low prices at which they trade. Distressed securities managers analyze and buy these securities when they perceive a turnaround. Risk (Merger) arbitrage Merger arbitrage managers exploit merger activity to capture the spread between the current market values of securities and their values in the event of a merger, restructuring, or other corporate transaction. Managers generally consider a transaction once an announcement is publicly made. A typical trade within this style is to buy the stock of the company being acquired while shorting the stocks of the acquirer. The most important risk to this style is deal breakage after the announcement.

2.2.4

Relative Value Arbitrage

When using relative value arbitrage strategies, a manager generally seeks to profit from a relative pricing discrepancies between related instruments, including equities, debt, options and futures. The general theme among these strategies is a bet that two securities or market prices will converge over time. Predominant styles in this category are: The Convertible Arbitrage Managers seek to exploit pricing anomalies between convertible bonds and their underlying equities. A typical investment is to short the common stock and take a long position on the convertible bond1 of the same company. The Fixed Income Arbitrage The managers aim to profit from price anomalies within and across global fixed income markets. Typical strategies include but are not limited to interest rate swap arbitrage, forward
1

A convertible bond is a bond with an embedded call option on the company's stock.

7

yield curve arbitrage, sovereign debt arbitrage and mortgage-backed securities arbitrage. The Equity Market Neutral This strategy also referred to as statistical arbitrage is designed to exploit pricing inefficiencies between related securities and usually involves being simultaneously long in overvalued equities and short in undervalued equities in as risk-free a manner as possible. 2.2.5 Statistical Data

The data used in this thesis are taken from Hedge Fund Research Inc.(HFR), www.hfr.com. HFR is is a hedge fund research and consulting firm which specializes in the areas of indexation and analysis of hedge funds. It is considered the global leader in the alternative investment industry and HFR database, is also considered the most comprehensive resource available for hedge fund investors. The four indices analysed are Global Hedge, Event Driven, Convertible Arbitrage and Equally Weighted hedge funds and the time series and daily log returns of each of the indices from March 2003 to May 2012 are shown in figures 2.1 and 2.2 respectively.

8

GH Data 1400 1350 1500 1300 1400 1250 1200 1150 1200 1100 1100 1050 1000 1000 1300 1600

ED Data

0

500

1000

1500

2000

2500

0

500

1000

1500

2000

2500

(a) Global Hedge
CA Data 1200 1100 1000 900 800 700 600 500 400 1350 1300 1250 1200 1150 1100 1050 1000 950

(b) Event Driven
EW Data

0

500

1000

1500

2000

2500

0

500

1000

1500

2000

2500

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.1: The Time Series of Hedge Fund indices for Period 2003-2012

9

GH log-returns 0.02 0.015 0.01 0.005 0 0 -0.01 -0.005 -0.01 -0.015 -0.02 -0.02 0.03

ED Log-returns

0.02

0.01

-0.03

0

500

1000

1500

2000

2500

-0.04

0

500

1000

1500

2000

2500

(a) Global Hedge
CA Log-returns 0.04 0.02 0.015 0.02 0.01 0 0.005 -0.02 0 -0.005 -0.04 -0.01 -0.06 -0.015 -0.08 -0.02

(b) Event Driven
EW Log-returns

0

500

1000

1500

2000

2500

0

500

1000

1500

2000

2500

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.2: The Log returns of Hedge Fund indices for Period 2003-2012

The histograms of hedge fund data display asymmetric heavy tails and high peak. The kurtosis of the distributions is too large (leptokurtic distribution). To get a clear picture 10

of what happened at different periods, we divided our data into three - before the financial crisis, during the major financial crisis and after the crisis. The periods were determined empirically . For the four styles analyzed, the kurtosis are much larger than three, as seen in tables 2.1, 2.2 and 2.3 and the skewness seems to be significant. Models with jumps are proposed to incorporate these features. The descriptive statistics for different hedge fund styles are shown in tables 2.1, 2.2 and 2.3.
G. Hedge 0.00027 0.0021 -1.0174 7.6095 E. Driven 0.00039 0.00248 -0.54532 6.24571 C. Arbitrage 0.00007 0.00207 -0.38753 4.78365 E. Weighted 0.00023 0.00143 -1.01584 9.33362

Mean Std. dev. Skewness Kurtosis

Table 2.1: Descriptive statistics for HFRX index data from March 2003 to July 2007 taken from HFR

Mean Std. dev. Skewness Kurtosis

G. Hedge -0.00011 0.00261 -1.54815 16.10559

E. Driven -0.00012 0.00326 -1.57947 21.96825

C. Arbitrage -0.00069 0.00555 -4.78229 43.89047

E. Weighted -0.0007 0.00332 -1.00435 8.91403

Table 2.2: Descriptive statistics for HFRX index data from August 2007 to December 2008 taken from HFR

Mean Std. dev. Skewness Kurtosis

G. Hedge 0.00013 0.00203 -1.06321 8.28435

E. Driven 0.000205 0.00236 -0.85277 7.5743

C. Arbitrage 0.00053 0.00261 0.48208 6.05142

E. Weighted 0.00014 0.00154 -1.32607 11.11451

Table 2.3: Descriptive statistics for HFRX index data from January 2009 to May 2012 taken from HFR The correlation matrices between the indices for the different periods are shown in tables 11

2.4, 2.5, and 2.6. The correlation matrices show that all the funds are correlated and the correlation between the indices for the crisis period is close to 1 where as there are variations for the pre-crisis and post-crisis data. The correlation of the Convertible Arbitrage Style to other styles is higher in crisis and post-crisis periods.
G. Hedge 1.0000 E. Driven 0.9875 1.0000 C. Arbitrage 0.5652 0.4665 1.0000 E. Weighted 0.9976 0.9871 0.5894 1.0000

G.hedge E. Driven C. Arbitrage E. Weighted

Table 2.4: Correlation Matrix for HFRX index data from March 2003 to July 2007

G.hedge E. Driven C. Arbitrage E. Weighted

G. Hedge 1.0000

E. Driven 0.9817 1.0000

C. Arbitrage 0.9832 0.9744 1.0000

E. Weighted 0.9974 0.9715 0.9859 1.0000

Table 2.5: Correlation Matrix for HFRX index data from August 2007 to December 2008

G.hedge E. Driven C. Arbitrage E. Weighted

G. Hedge 1.0000

E. Driven 0.9527 1.0000

C. Arbitrage 0.8764 0.9346 1.0000

E. Weighted 0.9772 0.9616 0.9413 1.0000

Table 2.6: Correlation Matrix for HFRX index data from January 2009 to May 2012

The time series for the different periods are shown in figures 2.3, 2.4 and 2.5. The index values have an upward trend in the pre-crisis period, downward trend in the crisis period and upward trend in the post-crisis period.

12

1400 1350

1600

1500 1300 1400 1250 1200 1150 1200 1100 1100 1050 1000 1000 1300

0

200

400

600 800 Global Hedge Fund

1000

1200

0

200

400

600 800 Event Driven

1000

1200

(a) Global Hedge
1100 1080 1060 1250 1040 1020 1000 980 1100 960 940 920 1050 1200 1350

(b) Event Driven

1300

1150

0

200

400 600 800 Convertible Arbitrage

1000

1200

1000

0

200

400 600 800 Equally Weighted Strategy

1000

1200

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.3: The Time Series of Hedge Fund indices for Pre-crisis returns (2003-2007)

13

1400 1350 1300 1250

1550 1500 1450 1400 1350

1200 1300 1150 1250 1100 1050 1000 1200 1150 1100

0

50

100

150

200 250 Global Hedge

300

350

400

0

50

100

150

200 250 Event Driven

300

350

400

(a) Global Hedge
1200 1100 1000 900 800 700 600 500 400 1350 1300 1250 1200 1150 1100 1050 1000 950

(b) Event Driven

0

50

100

150 200 250 Convertible Arbitrage

300

350

400

0

50

100

150 200 250 Equally Weighted

300

350

400

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.4: The Time Series of Hedge Fund indices for Crisis returns (2007-2008)

14

1250

1450

1200

1400

1350 1150 1300 1100 1250 1050

1200

1000

0

100

200

300

400 500 600 Global Hedge

700

800

900

1150

0

100

200

300

400 500 600 Event Driven

700

800

900

(a) Global Hedge
750 1200

(b) Event Driven

700 1150 650 1100

600

550

1050

500 1000 450

400

0

100

200

300 400 500 600 Convertible Arbitrage

700

800

900

950

0

100

200

300

400 500 600 Equally Weighted

700

800

900

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.5: The Time Series of Hedge Fund indices for Post-crisis returns (2009-2012)

Hedge fund returns empirical distribution and fitted normal distribution (the red line) for different periods are shown in figures 2.6, 2.7 and 2.8. These figures show the presence 15

of high peaks, heavy tails and asymmetries and that the returns are non-Gaussian. The peakness are much more prominent during the crisis period. The distributions of convertible arbitrage style for different periods differ from the distributions of the other styles with lower peak in the pre-crisis period and higher peak in crisis and post-crisis periods.

16

200

180

180

160

160

140

140 120 120 100 100 80 80 60 60 40

40

20

20

0 -0.015

-0.01

-0.005 0 Log-returns Global Hedge Fund

0.005

0.01

0 -0.02

-0.015

-0.01

-0.005 0 Log-returns Event Driven Strategy

0.005

0.01

0.015

(a) Global Hedge
140 250

(b) Event Driven

120 200

100

150 80

60 100

40

50 20

0 -0.01

-0.008

-0.006

-0.004

-0.002 0 0.002 Log-returns Convertible Arbitrage

0.004

0.006

0.008

0.01

0 -12

-10

-8

-6

-4

-2 0 2 Log-returns Equally Weighted Strategy

4

6 x 10

8
-3

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.6: The empirical density (histogram) and fitted normal density (red line) for Precrisis returns (2003-2007)

17

400

450

350

400

350 300 300 250 250 200 200 150 150 100 100

50

50

0 -0.02

-0.015

-0.01

-0.005

0 0.005 Log-returns Global Hedge Fund

0.01

0.015

0.02

0 -0.04

-0.03

-0.02

-0.01 0 Log returns Event Driven Strategy

0.01

0.02

0.03

(a) Global Hedge
500 120

(b) Event Driven

450 100 400

350 80 300

250

60

200 40 150

100 20 50

0 -0.08

-0.06

-0.04

-0.02 Log-returns Convertible Arbitrage

0

0.02

0.04

0 -0.02

-0.015

-0.01

-0.005 0 0.005 Log-returns Equally Weighted Strategy

0.01

0.015

0.02

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.7: The empirical density (histogram) and fitted normal density (red line) for Crisis returns (2007-2008)

18

160

160

140

140

120

120

100

100

80

80

60

60

40

40

20

20

0 -0.02

-0.015

-0.01

-0.005 Log- returns Global Hedge Strategy

0

0.005

0.01

0 -0.02

-0.015

-0.01

-0.005 0 Log-returns Event Driven Strategy

0.005

0.01

0.015

(a) Global Hedge
160 200

(b) Event Driven

180 140 160 120 140 100 120

80

100

80 60 60 40 40 20 20

0 -0.015

-0.01

-0.005

0 0.005 Log-returns Convertible Arbitrage

0.01

0.015

0.02

0 -14

-12

-10

-8

-6 -4 -2 Log-returns Equally Weighted Strategy

0

2

4 x 10

6
-3

(c) Convertible Arbitrage

(d) Equally Weighted

Figure 2.8: The empirical density (histogram) and fitted normal density (red line) for Postcrisis returns (2009-2012)

19

Chapter 3

THEORETICAL BACKGROUND

A mathematical model that can reproduce the non-smoothness of the trajectories of hedge fund indices data is what is intended to be developed in this thesis. It is therefore reasonable to model the dynamics of index returns with L´ evy processes which are processes with stationary independent increments that can not only generate continuous movements via a Brownian motion and rare and large events via a compound Poisson process, but can also generate frequent jumps of different sizes [39]. In this chapter, L´ evy processes are introduced and their major mathematical properties, are presented. Also, the mathematical tools useful for estimating the parameters of the models and the methods used in parameter estimation are explained in detail. For additional details on L´ evy processes see [8].

3.1

L´ evy Processes

Definition 3.1. [8] A cadlag1 stochastic process (Xt )(t0) on (, P, F , (Ft0 )2 with values in Rd such that X0 = 0, is called a L´ evy process if it possesses the following properties: (1) Independent Increments: for every increasing sequence of times t0 < t1 < . . . < tn , the random variables Xt0 , Xt1 - Xt0 , . . . , Xtn - Xtn-1 are independent. (2) Stationary Increment: for every t, h > 0 the law of Xt+h - Xt does not depend on t. By condition one, the future increment Xt+h - Xt is independent of the past history (Fs : s  t). The stationarity of increments implies that changes in the underlying variable Xt+h -
cadlag means right-continuity and left limits and it should be noted that some authors do not impose this property in the definition of L´ evy process 2 F is a  -algebra which is a collection of set of events, where each event is a set containing zero or more outcomes while (Ft0 ) is a filtration or flow of  -algebras
1

20

Xt have the same distribution at all the times t. The simplest L´ evy process is the linear drift, a deterministic process. The Brownian motion is the only (non-deterministic) L´ evy process with continuous sample paths [8]. The Poisson and compound Poisson processes are other examples of L´ evy processes. Also, the sum of a linear drift, a Brownian motion and a compound Poisson process is a L´ evy process called a jump-diffusion process. 3.1.1 Characteristic Function of a L´ evy Process

It is possible to characterize all L´ evy processes by looking at their characteristic function. 3.1.2 L´ evy Khintchine Theorem

Theorem 3.2. Let (Xt )(t0) be a L´ evy process on R with characteristic triplet (A, ,  ), by the L´ evy-Khintchine Theorem, the characteristic function of Xt satisfies the following relation: Xt (u) = et(u) , u  Rd where  (u) known as the characteristic exponent is given by: 1  (u) = iu - Au2 + 2 (eiux - 1 - iux1|x|1 ) (dx)

Rd

where A is the diffusion component,   Rd is the drift component and  is a positive Radon measure on Rd - {0} verifying: |x|2  (dx) < 
|x|1 |x|1

 (dx) < .

 is called the L´ evy measure of the distribution. 3.1.3 Infinitely divisible distributions and the L´ evy-Khintchine formula

There is a strong interplay between L´ evy processes and infinitely divisible distribution. 21

Definition 3.3. [8] A probability distribution F on Rd is said to be infinitely divisible if for any integer n  2, there exist n independent and identically distributed random variables Y1 , Y2 , . . . , Yn such that Y1 + . . . + Yn has distribution F . Proposition 3.4. [8] Let (Xt )t0 be a L´ evy process. Then for every t, Xt has an infinitely divisible distribution. Conversely, if F is an infinitely divisible distribution then there exists a Le ´vy process (Xt ) such that the distribution of X1 is given by F. Any infinitely divisible distribution is the distribution at time t = 1 of some L´ evy process. The characteristic function is represented as follows: Theorem 3.5. [8] Let F be an infinitely divisible distribution on Rd . Its characteristic function can be represented as: F (u) = e(u) , u  Rd 1  (u) = iu - u2 A + 2
Rd

(eiux - 1 - 1ux1|x|1 ) (dx)

Financial models with jumps fall into two categories. The first category is given by a diffusion process, punctuated by jumps at random intervals. The second category consists of models with infinite number of jumps in every interval and is called infinite activity model [8]. 3.1.4 Jump Diffusion Models

In jump-diffusion processes, jumps are considered rare events, and in any given finite interval there are only a finite number of jumps. In the jump-diffusion models, jumps disturb the standard diffusion structure at random times. Such a property can be described by constructing the log-return of hedge fund indices as a L´ evy process with a non-zero Gaussian part and a jump component, which is assumed to be a compound Poisson process with finitely many jumps in every time interval . A L´ evy process of a jump-diffusion type is 22

given by the expression:
Nt

Xt = µt + Bt +
i=1

Yi

where µ is a drift rate,  > 0 is a stock return volatility, (Bt )t0 is the standard Brownian process, (Nt )t0 is the Poisson jump process and Yi are the distributions of the jumps magnitudes. It is assumed that there is no dependency between the Brownian process, the Poisson process and the random jumps sizes. To define the model completely, it is necessary to determine the distribution of the jump sizes [8]. The jump diffusion models considered in this thesis are Merton's and Kou's models. 3.1.5 Infinite Activity Model

A pure jump process is defined to be one of infinite activity if the number of jumps in any finite interval of time is infinite. Some recent researchers have considered some pure jump processes with infinite activity. Two examples of these infinite-activity pure jump processes are the variance gamma model and the hyperbolic model. Given the ability of infinite activity jump processes to capture both frequent small moves and rare large moves, the question arises as to whether it is necessary to employ a diffusion component when modeling asset returns. To answer this question, a continuous time model that allows for both diffusions and for jumps of both finite and infinite activity was developed [7]. The model is called the CGMY model, after the researchers who developed it.

3.2

Estimation Methods

The estimation methods used in this thesis are Maximum Likelihood Estimation, Empirical Characteristic Function, Generalized Method of Moments, and Cumulant Matching Method. The Empirical Characteristic Function (ECF) estimation method will be used to model log-returns as independent and identically distributed (i.i.d) random variables using Merton's and Kou's models. This method builds on the works done by Jiang and Knight 23

(2000) and Semenova and Rockinger (2005) to estimate the parameters of jump diffusion models. Jiang and Knight used ECF method to estimate the parameters of affine jump diffusion models with latent variables while Semenova and Rockinger used the method to estimate the parameters of affine jump diffusion models with stochastic volatility. ECF method for i.i.d random variables proposed by Heatcote (1977) is used in this thesis. In this section, an overview of the different estimation methods is presented. 3.2.1 Maximum Likelihood Estimation

Maximum likelihood estimation begins with expressing the likelihood function of the sample data; "the likelihood of a set of data is the probability of obtaining that particular set of data, given the chosen probability distribution model. This expression contains the unknown model parameters. The values of these parameters that maximize the sample likelihood are known as the Maximum Likelihood Estimates" [31]. MLE method produces better estimation of the parameters because of its desirable optimality and mathematical properties. It can be used in a large variety of optimization situations which makes it a consistent approach to parameter estimation problems. The choice of starting values affect the estimation and optimality properties may not apply for small samples [31]. In finance, alternatives to MLE approach has been used by practitioners. Despite its generality and well known asymptotic properties, such as consistency, normality and efficiency, the likelihood function may not be tractable in many situations due to its boundlessness over the parametric space, instabilities or the existence of many local maxima [32]. Another problem with the MLE approach is that some families of distribution do not have a closed form density function and therefore the MLE method will be computationally expensive when applied. Let S = [S0 , S1 . . . Sn ] denote the hedge fund index values at equally-spaced times t = 0, 1, 2, . . . , n, the one period rate of return Xt = lnS (t) - lnS (t - 1) is I.I.D. Let X = (X1 , X2 , · · · , Xn ) denote the observed return vector, where  is the length of the

24

interval of equally spaced observations, then the probability density function is:

f (X, )

(3.1)

where  = 1 , 2 , 3 , . . . , k are k unknown parameters that need to be estimated. Likelihood and Log-likelihood Functions The likelihood function is given by the following product:
n

L(X |) =
i=1

f (Xi , )

In writing the right hand side as the product of the density function we have assumed that the random sample variables are independent and identically distributed. The log likelihood function is given by:
n

ln L(X |) =
i=1

ln f (Xi , )

(3.2)

The maximum likelihood estimators of  are obtained by maximizing the likelihood function. Since the maxima of the likelihood function are the same with that of the log-likelihood as the natural logarithm function is monotonic in , we can maximize log-likelihood which is much simpler to work with than likelihood function. Asymptotic Properties ^ and Let the maximum likelihood estimator of the parameter vector  be represented by  the true value by 0 . Consistency Under some regularity conditions on the form of the density, all maximum likelihood estimators are consistent. Consistency means that having a sufficiently large number of observations n, it is possible to find the value of 0 with arbitrary precision. In mathematical terms, this means that the sequence of estimators, will converge in probability to 0 as n

25

goes to infinity. This is formally represented as
P ^ -  0

Under slightly stronger conditions, the estimator converges almost surely to the true value
a.s. ^ -  0

Asymptotic Normality MLE is asymptotically normally distributed. As the sample size grows without limit,the distribution of a MLE converges to a normal distribution. Even for moderately large samples, the distribution of MLE is approximately normal. Under suitable regularity conditions, it holds that  ^ - 0 ) - N (0, I (0 )-1 ) n(
d

where I (0 ) is the Fisher information matrix is the negative of the expectation of the Hessian which is the amount of information that an observable random variable X carries about an unobservable parameter  upon which the probability distribution of X depends. It is the variance of the score and a measure of the best precision with which a parameter can be estimated from statistical data. It may be written as:  log f (X ; ) 
2

I (0 ) = -E

and the variance-covariance matrix is the inverse of the Information matrix. The square roots of the diagonal elements of I (0 )-1 represent the standard errors. Asymptotic Efficiency MLE is asymptotically efficient. This means that as the sample size grows without limit, the ratio of the variance of a MLE to the Cramer-Rao Lower Bound tends to 1. The

26

Cramer-Rao Lower Bound provides a bound on the possible efficiency of an estimator. For ^, the asymptotic variance of  ^ is therefore V = I (0 )-1 . the maximum likelihood estimator  [31] Finding the Variance-Covariance Matrix The variance-covariance matrix is: [I ()]-1 = (-E[H ()])-1

where H () is the Hessian of the log-likelihood function, the matrix of second derivatives with respect to our parameters. Thus, the first thing we do is find the Hessian, i.e. the second derivative of the log-likelihood function with respect to the parameter vector . It is given by the symmetric square matrix     2 ln L()   =    
 ln L() 1 1  ln L() 2 1  ln L() 1 2  ln L() 2 2

··· ··· . . . ···

 ln L() 1 k  ln L() 2 k

        

. . .
 ln L() k 1

. . .
 ln L() k 2

. . .

 ln L() k k

The importance of Hessian in the Maximum Likelihood framework is two fold: to establish that a maximum for the log-likelihood function has been achieved and to determine the precision of the maximum likelihood estimator in numerical methods to compute the MLE [16]. 3.2.2 Generalized Method of Moments

Generalized Method of Moments (GMM) is a generalization of the classical Method of Moments (MOM) estimation technique. MOM procedure equates population moments to sample moments in order to estimate population parameters. Since the introduction of GMM in 1982 by Lars Hansen, it has been widely applied to analyze economic and financial 27

data. Even though MLE is a more efficient estimator than GMM, the dependence of MLE on probability distribution can be a weakness. Some of these problems are sensitivity of statistical properties to the distributional assumption and computational burden [13]. In the GMM framework, the probability density function is not specified and this makes GMM a more computationally convenient method for parameter estimation. To use the generalized method of moment to estimate parameters, the estimators are derived from socalled moment conditions. A moment condition is a statement involving the data and the parameters [38]. For a set of data Xt where t = 1 . . . n drawn from a probability distribution P and we know that the parameter vector 0   satisfies the following moment condition

E [g (Xt , 0 )] = 0

for some known function g . In GMM, the basic idea is to construct the function g to form a valid moment condition and the sample data is used to form a sample analog of E [g (.)] ^ is chosen to solve using the Law of Large Numbers [38]. A parameter  1 Mt () = n
n

g (Xt , ) = 0
t=1

This allows us to consider the quadratic form

Qt () = Mt () Wt Mt ()

(3.3)

where Wt is a symmetric, positive semi-definite matrix which may depend on the data but it is required to converge in probability to a positive definite matrix for the estimator to be ^ is obtained well defined. If Mt () is a q x 1 matrix, W is a q x q matrix. The estimate  by minimizing Qt (). The main problem for GMM is which moments to match and how many moments to include in the estimation. Andersen and Sorensen (1996) showed that the inclusion of an excessive number of moments results in more pronounced biases and larger 28

root mean square error. Thus, the use of additional information can be harmful. We can conveniently derive all the moments via the characteristic function by taking advantage of the relationship between moments and cumulants. Denoting x as a characteristic function of a random variable X and assuming that E|X |n <  then x has n continuous derivative at u = 0, we obtain for all k = 1, · · · , n mk = E[X k ] = 1  k x (0) ik uk

and Ck = 1  k ln x (0) ik uk

where mk and ck are the k th moment and k th cumulant respectively. 3.2.3 Characteristic Function Estimation Method

Characteristic function (CF) estimation method is applied in situations when the likelihood is of a considerably more complicated form than the characteristic function because "the characteristic function (CF) is always bounded and is available in a simpler form than the density in some important cases" [32]. Empirical characteristic function (ECF) retains all information in the sample because there is a one to one correspondence between the CF and cumulative distribution function (CDF) due to the fact that CF is the Fourier Stietjes transform of the CDF and this justifies the use of the ECF estimation method [40]; and therefore inference based on ECF can outperform that based on generalized method of moments. Under some regularity conditions, the resulting estimators are shown to be consistent and asymptotically normal. In L´ evy models, the CF is know via L´ evy Khintchine theorem see Theorem 3.2.

29

3.2.3.1

The independent and Identical Distribution (I.I.D) case

Suppose that the PDF of X is defined as in (3.1), and  = (1 , 2 , 3 , · · · , k ) are k unknown parameters that need to be estimated and let X = (X1 , X2 , . . . , Xn ) denote independent and identically distributed random variables, then the CF is defined by

(u, ) = E [exp (iuX )]

and the ECF is the sample counterpart of the CF defined by ^(u) = 1  n where u is the transform variable, and i =
n

exp (iuXj )
j =1



-1. By the Law of Large Numbers (u) is a

^(u). The general idea for ECF estimation is to minimize various consistent estimator of  distance measures between the ECF and CF; The method finds ^ = min  ^(u) - (u, ) 


where . is usually a L or Lr weighted norm. In this thesis the L2 norm will be used. One can minimize


h() =
-

^(u) - (u, )|2 g (u)du |

with g (u) being a continuous weighting function. The choice of the weighting function g (u) is often a concern. The optimal weight function obtained by Feuerverger and McDunnough [10] using the Parseval identity is the inverse Fourier transform of the score function given by g (u) = 1 2 exp (-iux)  log f (x) dx 

30

which depends on the density function. The resulting estimator attains maximum likelihood efficiency. Since, in this thesis, the density function of Kou's model is not known in closed form, an arbitrary weight function that assigns more weight to an interval around the origin and whose increments vanish outside some finite interval [15] will be used. Specifically, an exponential weighting function exp (-bu2 ) will be used. Although the exponential weight guarantees consistency and has the numerical advantage associated with quadratures, in general, the resulting ECF estimator from the exponential weight is less efficient than the Maximum Likelihood estimator [40]. In the exponential weighting function the choice of b is very important in the efficiency of the estimators. In most of the literature b is set to be 1, resulting in w(t) = exp(-u2 ). For computational simplicity, b = 1 is used in this thesis, however, b that minimizes the trace or determinant of the covariance matrix gives a more efficient estimator [22]. 3.2.3.2 Consistency and Asymptotic Normality

Consistency and asymptotic normality of the ECF estimators presented here follow from Heathcote (1977). The assumption here is that h() can be differentiated under the integral sign. h =  ^ minimizes The statistics 
  -

d ^ |(u) - (u, )|2 g (u)du d

(3.4)

h() =
- 

^(u) - (u, )|2 g (u)du | ^(u) - Re(u, )]2 + [Im ^(u) - Im(u, )]2 g (u)du [Re

(3.5) (3.6)

=
-

31

^(u) = Re ^(u) + iIm ^(u) and (u, ) = Re(u, ) + iIm(u, ). The estimating Here,  equation becomes h = -2  ^(u) - Im(u, )] Im(u, ) ^(u) - Re(u, )] Re(u, ) + [Im  i i

g (u)du (3.7)

Since exp (iuXj ) = cos (uXj ) + i sin (uXj ), this implies that 1 n
n

exp (iuXj ) =
j =1

1 n

n

(cos (uXj ) + i sin (uXj ))
j =1

^(u) = This means that Re

1 n

n j =1 cos (uXj )

^(u) = and Im

1 n

n j =1 sin (uXj )

Equation (3.7) can be written as, h  -2 n


=

[cos (uXj - Re(u, ))]
-

Re(u, ) i

(3.8)

+ [sin (uXj ) - Im(u, )]

Im(u, ) g (u)du i

^ is the root of (3.8) for which h () ^ > 0. The estimator  The ECF estimator is consistent, i.e
a.s ^ -  

and asymptotically normally distributed,  d ^ - ) - n( N (0, B -1 ()A()B -1 ())

n

(3.9)

32

where d in equation (3.9) stands for convergence in distribution, A() is the covariance matrix of the random variables K (i) () = Re(u, ) i - Im(u, ) + [sin (uXj ) - Im(u, )] g (u)du i cos (uXj ) - Re(u, )]


for i = 1, · · · , k , given by  A() = E  1 n
n n

 Kj (i )Kh (i )

j =1 h=1

Since X is a vector of i. i.d observations, the above expression is given by: Rec(u; ) Rec(s; ) cov (cos(u, X ), cos(s, X )) i j Rec(u; ) Imc(s; ) + 2× cov (cos(u, X ), sin(s, X )) i j Imc(u; ) Imc(s; ) cov (sin(u, X ), sin(s, X )) exp(-u2 ) exp(-s2 )duds + i j 1 n

Ai,j () =

where, from elementary trigonometric identities, for real numbers u, s 1 [Rec(u - s; ) + Rec(u + s; ) - 2Rec(u; )Rec(s; )] 2 1 [Imc(u + s; ) - Imc(u - s; ) - 2Rec(u; )Imc(s; )] 2 1 [Rec(u - s; ) - Rec(u + s; ) - 2Imc(u; )Imc(s; )] 2

cov (cos(u, X ), cos(s, X )) = cov (cos(u, X ), sin(s, X )) = cov (sin(u, X ), sin(s, X )) =

i and j correspond to the ith or j th element in the vector  = (1 , · · · , k ) and B () is the k x k symmetric matrix whose (i, j )th entry is Rec(u, ) Rec(u, ) Imc(u, ) Imc(u, ) + exp(-u2 )du i j i j

Bi,j () =

33

The method used for approximating the integrals above is adaptive Gauss-Kronrod quadrature using MATLAB 'quadgk' built-in function which attempts to approximate the integral of a scalar-valued function from a to b using high-order global adaptive quadrature. The limits a and b can be - or . A function handle of user-defined 'quadgk' is used as a method in MATLAB 'dblquad' to approximate the double integrals. 3.2.3.3 Non-I.I.D Stationary Case

The estimation procedure is similar to the i.i.d. case, i.e., to match some distance between the Empirical Characteristic Function and the theoretical Characteristic Function, however, Estimation of a strictly stationary stochastic process using the ECF is not exactly the same as that of an iid sequence, because the dependence must be taken into account [40]. The ECF method for i.i.d case is well understood, but the ECF method for non-i.i.d case has not received much attention and consequently there is great scope for research. In the non-i.i.d case, using marginal ECF may result in a loss in efficiency. Approaches based on joint ECF and conditional ECF have been used in literature [40].

Joint Empirical Characteristic Function Method One way of describing a stochastic process {Xt , t  T } is to specify the joint probability law of n random variables Xt1 · · · Xtn for all integers n and n points t1 , t2 , · · · tn in T [33]. The joint distribution function or the joint characteristic function may be used to specify the joint probability law of the random variables and given all real numbers u1 , u2 , · · · , un the joint characteristic function is given by

Xt1 ,Xt2 ,···Xtn (u1 , u2 , · · · , un ) = E[exp i(u1 Xt1 + · · · + un Xtn )] The approach via joint CF described here is culled from Knight and Yu (2002). It involves moving blocks of data. Let {Xj } j =- be a univariate, stationary time series whose

34

distribution depends upon a vector of unknown parameters , to estimate  from a finite realization,X1 , X2 · · · XT . Denote the moving blocks for X1 , X2 · · · XT as Zj = (Xj , · · · Xj +p ), j = 1 . . . T - p. Thus each block has p + 1 observations and p overlapping periods with its adjacent blocks. The CF of each block is defined as

c(u; ) = E[exp (iu Zj )] where u = (u1 , u2 · · · up+1 ) and hence the transform variable is of p + 1 dimensions. The joint ECF is defined as 1 cn (u) = n where n = T - p. To estimate the parameter via the joint ECF one can minimize a distance measure between the joint CF and joint ECF, |c(u; ) - cn (u)|2 g (u)du
n

exp (iu Zj )
i=1

...

(3.10)

or ... or solve the following equation |c(u; ) - cn (u)|2 w(u)du = 0 |c(u; ) - cn (u)|2 dG(u) (3.11)

...

(3.12)

where g (u), G(u) and w(u) are weighting functions. Equations (3.10), (3.11) and (3.12) are equivalent under suitable regularity conditions [40]. Since the transform variable u is a vector, the moment conditions include both marginal and joint moments. The procedure is to match the joint CF and joint ECF continuously. In this continuous ECF procedure the weighting function is a continuous function and hence the transform variable is integrated 35

out [40]. The choice of weight function is very important in ECF method, to obtain an optimal weight, Parseval theorem, which gives the weight in terms of  is used. The method with optimal weight is referred to GLS-ECF as in Yu (2004), and the weight is specified as follows  log f (xj +p |xj , . . . , xj +p-1 ) dxj . . . dxj +p-1 

w(u; ) =

...

exp (-iu zj )

(3.13)

where f (xj +p |xj , . . . , xj +p-1 ) is the conditional score function. This weight is optimal in the sense that the asymptotic variance of the GLS-ECF estimator can be made arbitrarily close to the Cram´ er-Rao lower bound when p is large enough. To use the GLS-CECF method, however, the conditional score function must have an analytical expression. When this is not the case, this weight function has to be approximated. Exponential weighting function, which in general does not result in the efficient estimator because the exponential weight is not optimal, can be used and this method is referred to as WLS-ECF. Using het WLS-ECF method has two major advantages. First, it puts more weight on the interval around the origin, consistent with the recognition that the CF contains the most information around the origin. The second reason is for computational convenience. With an exponential weight, the integral in (3.10) can be numerically calculated by Hermitian quadrature or Monte Carlo integration [22]. According to Knight and Yu, the choice of p can have an impact on the efficiency of the ECF estimator, as the moving blocks with a different p may contain different amounts of information in the sample. Ideally an optimal p is selected to minimize the mean square error (MSE) of the ECF estimator [40]. It was pointed out by Knight and Yu (2002) that the choice of p is related to the dimension of the minimal sufficient statistics. In particular, the overlapping moving blocks with block size of 2 form a set of sufficient statistics for a Markov process of order 1, and hence p = 1 is enough for Markov processes and it is reasonable to believe that when a non-Markov process can be well approximated by a Markov process of order l, p = l should work well [40]. For more

36

detail on the ECF method for non-i.i.d observations, see [22].

3.3

Monte Carlo Simulation

Monte Carlo simulation is a method for iteratively evaluating a deterministic model using sets of random numbers as inputs. This method is often used when the model is complex, non-linear, or involves more than just a couple uncertain parameters. Monte Carlo methods are based on analogy between probability and volume and simulation can typically involve over 10,000 evaluations of the model [12]. 3.3.1 Principle of the Monte Carlo Simulations

The idea is as follows, suppose we are considering a random variable X on a probability space, which records an outcome of an experiment. The repetitions of the experiments can be modelled by introducing a sequence of random variables X1 , . . . , Xn , each of which has the same probability information as X. Assuming that X1 , . . . , Xn are independent, the sequence can be regarded as a model for repeated and independent runs for the experiment [4]. The Strong Law of Large Numbers shows that with probability one, we can deduce the common expected values of the random variables. The Strong Law of Large Numbers Theorem 3.6. Let X1 , · · · , Xn be a sequence of independent, identically distributed, integrable random variables defined on the same probability space, such that for i = 1, · · · , n, let x = E [Xi ], then P
n

lim

X1 + X2 + · · · + Xn =x n

=1

The Strong Law of Large Numbers says that for almost every sample point   , X1 ( ) + X2 ( ) + . . . + Xn ( ) x n

as

n

37

Therefore, if X1 , · · · , Xn is a sequence of random variables each of which has the same probability information as X and E[X ] < , then 1 n
n

Xi - E(X )
i=1

a.s

Monte Carlo simulation has an advantage of being flexible compared to other numerical methods. Moreover, it serves as the only method of simulation in higher dimensions. 3.3.2 Monte Carlo Simulation of L´ evy Processes

The simulation of L´ evy processes depends on the type of process you want to simulate. In this thesis, the simulation of jump diffusion models ( Kou's and Merton's models) are outlined in the next chapter.

38

Chapter 4

THE MODELS FOR HEDGE FUND

In this chapter the discussion is concentrated on Merton and Kou models because they are deemed capable of describing the observed behaviour of hedge fund log-returns data.

4.1

Merton's Model

Let St denote the hedge fund index value at time t, in Merton's model, changes in index value consists of continuous diffusion component that is modeled by a Brownian motion with drift process and discontinuous (jump) component that is modeled by a compound Poisson process. The jumps follow a Gaussian distribution and are assumed to occur independently and to be identically distributed [28]. Suppose that, in a small time interval dt the index value jumps from St to yt St , the percentage change in the index value caused by the jump is: dSt yt St - St = = yt - 1 St St where yt is called the absolute index value jump size which Merton assumes is a non-negative random variables drawn from log-normal distribution. Merton Jump Diffusion dynamics of index values which incorporates the above properties takes the stochastic differential equation (SDE) of the form:

dSt = (µ - k )St dt + St dBt + St dZt

(4.1)

where µ : Instantaneous Expected Return on the Asset

39

 : Instantaneous Volatility Bt : Standard Brownian Motion process Zt :
Nt j =1 (yj

- 1) or dZt = (yt - 1)dNt

Nt : A Poisson process with intensity  k : E[yt - 1], where (yt - 1) is the random variable percentage change in index value if the Poisson event occurs. The standard assumption is that Nt , yt and Bt are independent Ito's formula for a jump- diffusion process given in Cont and Tankov (2004) is as follows: Proposition 4.1. Let Xt be a diffusion process with jumps defined as a sum of drift term, a Brownian stochastic integral and a compound Poisson process
t t Nt

Xt = X0 +
0

as ds +
0

bs dBs +
i=1

Xi

(4.2)

where at corresponds to the drift term and bt corresponds to the volatility term. Then f (Xt , t) f (Xt , t) dt + at dt t x 2 b2 f (Xt , t) t  f (Xt , t) dt + bt dBt 2 2 x x

df (Xt , t) = +

+ [f (Xt- + Xt ) - f (Xt- )]

Apply It^ o's integral formula above on the interval [t, t+t] on the process f (St , t) = ln St

40

to get:
2 1 1  2 St 1 dt - dt + St dBt + [ln(St- + (yt - 1)St- ) - ln St- ] 2 St 2 St St 2 2 1  St 1 1 (µ - k )St dt - dt + St dBt + [ln St- (1 + yt - 1) - ln St- ] 2 St 2 St St 2 2 1  St 1 1 (µ - k )St dt - 2 dt + St S dBt + [ln yt St- - ln St- ] St 2 St t 2 (µ - k )dt - dt + dBt + [ln yt + ln St- - ln St- ] 2 2 (µ - - k )dt + dBt + ln yt 2

d ln St = (µ - k )St = = = =

Which gives the following equations when integrated on the interval [t, t + t] 2 = (µ - - k )(t) + Bt + 2
Nt

ln St+t - ln St

ln yi
i=1 Nt

ln St+t = ln St + (µ -

 2 - k )(t) +  t + 2

ln yi
i=1 Nt

 2 - k )(t) +  t + exp (ln St+t ) = exp (ln St + (µ - 2 St+t = St exp ((µ -  2 - k )(t) +  t + 2
Nt

ln yi )
i=1

Yi ),
i=1

where

is the standard normal distribution, ln yt  Yt , and ln yt is i.i.d Normal(µj , j ).

This means that the index value is modelled as an exponential L´ evy model of the form: St+t = St eXt ,

where Xt is a L´ evy process which is categorized as a Brownian motion with drift (continuous part) plus a compound Poisson process (jump part). In other words, log-return

41

ln(

St+t St )

= Xt is modeled as a L´ evy process such that:  2 St+t ) = Xt = (µ - - k )(t) +  t + St 2
Nt

ln(

Yi
i=1

4.1.1

The Characteristic Function and Moments of Merton's Model

Using L´ evy Kintchine theorem, the characteristic function is found to be

xt (u) = E eiuXt = exp (t(iu(µ - 2 2 - k ) -  2 u2 2 + {exp (iµj u -
2 u2 j

(4.3) 2 ) - 1})) (4.4)

The log-characteristic function  (u) = ln ( (u)) is used in generating the cumulant of the function [8]. The nth cumulant is defined by 1  n  (0) in un

cn =

(4.5)

Applying (4.5) to the log-characteristic function gives the following cumulants for Merton's model 1 c1 = t µ -  2 + k + µj 2
2 c2 = t( 2 + j +  µ2 j) 2 c3 = tµj 3j + µ2 j 4 2 2 c4 = t 3j + 6 j µj + µ 4 j 4 2 2 c5 = tµj 15j + 10j µj + µ4 j 6 4 2 2 4 c6 = t(15j + 45j µj + 15j µj + µ6 j)

42

See Appendix for MAPLE codes used for deriving these equations. The moments of the log-returns are computed using the cumulants. The first and second cummulants equals the mean and variance of the return respectively. The two higher order moments that are of particular interest are the skewness and the kurtosis. The skewness S measures the asymmetry of the distribution and is given by:
2 + µ2 t 3j j 2 +  µ2 )) 2 (t( 2 + j j
3

S=

c3
3 2 c2

=

.

And the excess kurtosis, K, which measures the fatness of the tails of the disribution is:
4 + 6  2 µ 2 + µ4  t 3j j j j c4 K= 2 = . 2 2 2 c2 (t( + j +  µj ))2

4.1.2

Transition Density

The transition density between any two instants t and t + t, with t > 0 can be computed from the above characteristic function through the inverse Fourier transform. It is the sum of the conditional probability density weighted by the probability of the conditioning variable i.e. the number of jumps. It is a quickly converging series which satisfies:


ft (x) =
n=0

e-t (t)n
2) n! 2 (t 2 + nj

exp

2 -(x - t(µ -  2 - k ) - nµj ) 2) 2(t 2 + nj

2

(4.6)

4.1.3

Simulation of Merton's Model

The method used in this paper is simulation at fixed set of dates 0 = t0 < t1 < · · · < tn without explicitly distinguishing the effects of the jump and diffusion terms, as specified by Glasserman (2004) [12]. If we set X (t) = log S (t), the algorithm for the steps in a sequential Monte Carlo procedure for Merton's model is as follows: 1. Generate Z  N (0, 1). 43

2. Generate N  P (t) 3. If N = 0 Generate log Y1 , . . . , log YN and set Jump = log Y1 + . . . + log YN else if
2 ) then log Y  N = 0, set Jump = 0. Since Yj has log-normal distribution LN (µj , j j  2 ) and log Y + . . . + log Y 2 N (µj , j 1 N  N (N µj , N j ) = N µj + j N N (0, 1). So,  generate Z2  N (0, 1) and set Jump = N µj + j N Z2 .

4. Set  X (ti+1 ) = X (ti ) + (µ - 0.5 2 - k )t +  Z + Jump  Xt = (µ - 0.5 2 - k )t +  Z + Jump

A sample path for simulated Merton's Model is shown in figure 4.1

44

Merton jump-diffusion 20

15

10

5

0

-5

-10

-15

0

200

400

600

800

1000

1200

Figure 4.1: Simulated Merton's Model path, parameters µ = 0,  = 0.2, µj = 0, j = 0.2, and  = 3.45. 4.2 Kou's Model

The double exponential jump-diffusion (DEJD) model called Kou model, was introduced by Kou in 1999 [23]. As opposed to Merton's, it generates a highly skewed and leptokurtic distribution and is capable of matching key features of hedge fund index returns. Like Merton's model, Kou model is an improvement of Black-Scholes model with respect to the modelling of empirical phenomena, while still having a simple analytical approach. Numerous variations of the jump diffusion model has been proposed, and the DEJD model has gained wide acceptance. There are two interesting properties of the double exponential distribution that are crucial for the model-the leptokurtic feature inherited from the jump size distribution and the memoryless property inherited from the exponential distribution [25]. These special properties explain why the closed-form solutions(or approximations) for various option pricing problems, including barrier, lookback, and perpetual American options, are feasible under the double exponential jump-diffusion model. In this paper

45

Kou model will be used to model hedge fund indices as an alternative to Merton's and Black-Scholes models. 4.2.1 Kou's Model Specification

Let St be the hedge fund index value at time t and assume that under the probability measure P, the index value process follows:
Nt

dSt = µSt- dt + St- t + St- d
i=1

(Yi - 1)

(4.7)

where µ and  are the drift and volatility terms, Bt is a standard Brownian process, St- denotes the value of the process just before a potential jump, Nt is a Poisson process with intensity parameter , and {Yi } is a sequence of independent identically distributed nonnegative random variables. In the model, all sources of randomness Nt , Bt and  = log Y are assumed to be independent. It is assumed that µ and  are constants, while the Brownian process and the jumps are one-dimensional [24]. Solving the stochastic differential equation using Ito's formula as in (4.7) gives the dynamics of the index return: 1 = St exp µ - (  2 )t + Bt 2
Nt

St+t

Yi
i=1

(4.8)

 = log(Y ) has an asymmetric double exponential distribution with the density: f (y ) = p.1 e-1 y 1{y0} + q.2 e2 y 1{y<0}

1 > 1, 2 > 0

where p, q  0, p + q = 1 represent the probabilities of upward and downward jumps, respectively. The requirement 1 > 1 is needed to ensure that E(Y ) <  and E(St ) < . It essentially means that the average upward jump cannot exceed 100%, which is quite reasonable [25]. The means of the two exponential distributions have parameters
1 1

and

46

1 2 ,

respectively. The Characteristic Function and Moments of Kou's Model

4.2.2

The double exponential jump diffusion process is a special case of L´ evy processes with two-sided jumps, whose characteristic exponent admits the (unique) representation: xt (u) = E eiuXt = exp (t(iuµ -  2 u2 2 + { p1 q2 + - 1})) 1 - iu 2 + iu

(4.9) (4.10)

Applying the formula given in (4.5) to log-characteristic function gives the following population cumulants for Kou model p 1-p 1 ) c1 = t µ -  2 +  ( - 2 1 2 p 1-p c2 = t  2 + 2 t  ( 2 + ) 1 2 2 1-p p ) c3 = 6 t  ( 3 - 1 2 3 p 1-p c4 = 24 t  ( 4 + ) 1 2 4 p 1-p c5 = 120 t  ( 5 - ) 1 2 5 p 1-p c6 = 720 t  ( 6 + ) 1 2 6 See Appendix for derivation of Characteristic function and MAPLE code used for deriving the cumulants. 4.2.3 Simulation of Kou's Model

The method used is the same as the method used in simulating Merton's Model i.e. simulation at fixed set of dates 0 = t0 < t1 < · · · < tn without explicitly distinguishing the effects of the jump and diffusion terms, as specified by Glasserman (2004) [12]. If we set 47

X (t) = log S (t), the algorithm for the steps in a sequential Monte Carlo procedure for Kou's model is as follows: 1. Generate Z  N (0, 1). 2. Generate N  P (t) 3. If N = 0 Generate log Y1 , . . . , log YN and set Jump = log Y1 + . . . + log YN else if N = 0, set Jump = 0. Since an exponential distribution is a gamma distribution with shape parameter 1 and scale parameter  , then log Y1 + . . . + log YN has the gamma distribution with shape parameter N and scale parameter  and the sign of log Yj is positive with probability p and negative with probability 1 - p. Conditional on the Poisson random variable N taking the value n , the number of log Yj with positive sign has binomial distribution with parameters n and p, so 3a. Generate B  Binomial(N,p) 3b. Generate G1  Gamma(B, ) and G2  Gamma((N-B), ) and set Jump = G1 - G2 4. Set  X (ti+1 ) = X (ti ) + (µ - 0.5 2 )t +  Z + Jump  Xt = (µ - 0.5 2 )t +  Z + Jump

In 3b, interpret a gamma random variable with shape parameter zero as the constant 0 in case B = 0 or B = N . Sample path for simulated Kou's model is shown in figure 4.2

48

double exponential 2 1.5 1 0.5 0 -0.5 -1 -1.5 -2 -2.5 -3 0 0.5 1 1.5 2 2.5 3

Figure 4.2: Simulated Kou's Model path, parameters µ = 0,  = 0.2, 1 = 0.2, 2 = 0.3, p = 0.5, and  = 4.25.

49

Chapter 5

NUMERICAL IMPLEMENTATION AND PARAMETER ESTIMATION UNDER MERTON AND KOU MODELS

In this chapter, L´ evy models are applied to hedge fund data and the parameters are estimated using the estimation methods described in section 3.2. The density of Kou model is not known in closed form, inverse Fourier transform method is used to get the density.

5.1

Method of Moments

The method of moment is used to estimate the parameters of the models and theses parameters are used as the starting point in the subsequent estimation methods. The procedure used in this thesis is a variant of the method of moments and is called "cumulant matching". The Cumulant Matching method is based on the relationship between the population cumulant and the distribution parameters. Population cumulants are not known,the sample cumulants are used to estimate the parameters. Parameter estimation by cumulant matching is known to yield consistent estimators but estimators are not always efficient Press(1967). The cumulants are matched with the sample central moments because of the relationship that exists between them. The log-characteristic function  (u) = ln ( (u)) is used in generating the population cumulant ck of the function [8]. Using the relationship between the central moment mk and ck , the first six sample cumulants of the models can

50

be computed from the sample moments in the following way [21]:

c ¯ 1 = m1 c ¯ 2 = m2 c ¯ 3 = m3
2 c ¯ 4 = m4 - 3m2

c ¯ 5 = m5 - 10m3 m2
2 3 c ¯ 6 = m6 - 15m4 m2 - 10m3 + 30m2

where m1 is the mean and m2 the second central moment is the variance of the sample. In this thesis, the approach used by Beckers (1981) is used to estimate the parameters of the Merton model using cumulant matching method. This estimation method has been proven to generate sensible parameter values for stocks with high sample kurtosis. The procedure involves setting the mean logarithmic jump size equal to zero, i.e µj = 0, the odd cumulants except the first one all vanish giving the following estimates of the Parameters: µj = 0, µ =
1 t (c1

+1 2 (c2 -

5c2 4 3c6 )

-

25c3 4k ), 3c2 6

and j =

c6 5c4 ,

=

25c3 4 , t3c2 6

=

1 t (c2

-

5c2 4 3c6 ).

For Kou's model, equating the population cumulants of the models to the sample cumulants gives the parameter estimates for the models. As stated above the parameters estimated using this method are consistent but not always efficient but provide a good initial parameter for GMM and ECF algorithms. However, the cumulant estimates may not exist or may have the wrong sign. In this thesis, the method proposed involves setting the population cumulants ck = c ¯ k the sample cumulants, k = 1, · · · , 6. Solving these set of equations without constraints might lead to getting values outside the range that is desired, for instance one could get a negative value for  or value greater than 1 or less than 0 for p. So, we set

fk = ck - c ¯ k

(5.1)

51

2 + f 2 + . . . + f 2 ; MATLAB constrained optimization and Sum of Squared Error, SSE = f1 2 6

function fmincon is used to minimize SSE subject to the constraints that  > 0, 1 > 1, 2 > 0 and 0  p  1. SSE is minimum when ck  c ¯ k . Specifically Kou model is done this way 1 1-p p f1 = t µ -  2 +  ( - ) - m1 2 1 2 p 1-p f2 = t  2 + 2 t  ( 2 + ) - m2 1 2 2 p 1-p f3 = 6 t  ( 3 - ) - m3 1 2 3 p 1-p f4 = 24 t  ( 4 + ) - m4 - 3m2 2 1 2 4 1-p p ) - (m5 - 10m3 m2 ) f5 = 120 t  ( 5 - 1 2 5 p 1-p 3 f6 = 720 t  ( 6 + ) - m6 - 15m4 m2 - 10m2 3 + 30m2 1 2 6 This method can also be applied to Merton model. The parameter estimates are shown in the tables in the appendix.

5.2

Maximum Likelihood Estimation

The transition density ft (X ) Merton model is shown in equation (4.6) and using MATLAB 'fmincon', and parameter estimates from CMM as initial parameter, negative of the log-likelihood specified in (3.2) can be minimized which is equivalent to maximizing the log-likelihood function and the parameters that maximize the log-likelihood function also maximize the likelihood function and are the MLE estimates for Merton model. For kou model, the density is not known in closed form, therefore the density is approximated using inverse Fourier transform of the characteristic function shown in (4.9) using this formula: 1 2
 -

fXt (X ) =

e-iuX Xt (u) du =

1 

 0

e-iuX Xt (u) du

(5.2)

52

The integral is evaluated using MATLAB built-in function 'quadgk'. In this thesis MATLAB built-in function 'mle' is used to estimate the parameters for both Merton and Kou models and 'mlecov' is used to get the covariance matrix using the parameter estimates and square roots of the diagonal elements of the covariance matrix give the standard error of the estimation. Parameter estimates for the models are also shown in the tables in appendix C and the 3-D plot of ,  and Log-likelihood are shown in figures 5.1 ,5.2, 5.3, and 5.4 for the pre-crisis period and for the four styles analysed. The figures show that the parameters that maximize the likelihood functions are consistent with the parameter estimates i.e. the value for the likelihood function is highest where  and  are equal to the parameter estimates in table D.1. For instance, in figure 5.1, the maximum value for the log-likelihood is 5289 and the corresponding values for  and  are 0.4586 and 0.00127 which correspond to the parameter estimates for pre-crisis global hedge fund data. The figures for the other periods show similar information and are not included in this thesis.
5400 5200 5000
Log-likelihood

X: 0.001273 Y: 0.4586 Z: 5289

4800 4600 4400 4200 4000 3800 0.5 0.45  0.4 0 0.002  0.004 0.006 0.008 0.01

Figure 5.1: Mesh Plot of  ,  and Log-likelihood for G. Hedge

53

5200 5000 4800
Log-likelihood

X: 0.001483 Y: 0.5297 Z: 5058

4600 4400 4200 4000 3800 0.6 0.5 0.4  0 0.002 0.004  0.006 0.008 0.01

Figure 5.2: Mesh Plot of  ,  and Log-likelihood for E. Driven

5400 5200 5000
Log-likelihood

X: 0.001818 Y: 0.1005 Z: 5228

4800 4600 4400 4200 4000 3800 0.2 0.1 0  0 0.002  0.004 0.006 0.008 0.01

Figure 5.3: Mesh Plot of  ,  and Log-likelihood for C. Arbitrage

54

6000

5500
Log-likelihood

X: 0.0008772 Y: 0.3232 Z: 5706

5000

4500

4000 0.5 0.4 0.3 0.2  0.1 0 0.002  0.004 0.006 0.008 0.01

Figure 5.4: Mesh Plot of  ,  and Log-likelihood for E. Weighted

55

5.3

Generalised Method of Moments (GMM)

To use this method, we need to specify the moment conditions. The number of moment conditions should be greater than the number of parameters to be estimated. Since we are estimating five parameter, we will use at least six moment conditions in the GMM method. Usually, the moments are generated using the moment generating function; however for our models, it is easier to get the cumulants than the moments and therefore we specify our moments in terms of cumulants [21] using the following recursive formula:
n-1

µn = cn +
m=1

n-1 cm µn-m m-1

which gives the nth moments µn as an nth degree polynomial in the first n cumulants:

µ1 = c1 µ2 = c2 + c2 1 µ3 = c3 + 3c2 c1 + c3 1
2 4 µ4 = c4 + 4c3 c1 + 3c2 2 + 6c2 c1 + c1 2 3 5 µ5 = c5 + 5c4 c1 + 10c3 c2 + 10c3 c2 1 + 15c2 c1 + 10c2 c1 + c1 2 3 3 2 2 4 6 µ6 = c6 + 6c5 c1 + 15c4 c2 + 15c4 c2 1 + 10c3 + 60c3 c2 c1 + 20c3 c1 + 15c2 + 45c2 c1 + 15c2 c1 + c1 4 5 2 3 2 3 2 2 µ7 = c7 + 35c4 c3 1 + 35c3 c1 + 21c2 c1 + 21c5 c1 + 105c1 c2 + 105c1 c2 + 70c1 c3 + 21c2 c5 + 105c2 c3 7 + 35c3 c4 + 7c6 c1 + 105c1 c2 c4 + 210c2 1 c2 c3 + c1 .

SAS program is used to get the GMM estimates using these moment conditions (see appendix B for the algorithm).

56

5.4

Characteristic Function Estimation Method

For Merton's Model, the characteristic function is (, u) is as defined in equation (4.3). Real part of the Characteristic function is Re = exp t -0.5  2 u2 +  e-0.5 j
2 u2

cos (µj u) - 1
2 u2

× sin t uµ - 0.5 u 2 - u k +  e-0.5 j

sin (µj u)

The Imaginary Part is given by Im = exp t -0.5  2 u2 +  e-0.5 j
2 u2

cos (µj u) - 1
2 u2

× sin t uµ - 0.5 u 2 - u k +  e-0.5 j

sin (µj u)

For Kou model, the characteristic function is (, u) is as defined in equation (4.9). The real part of the characteristic function is : p1 2 q2 2 + -1 1 2 + u2 2 2 + u2 p1 u q2 u uµ - 1/2 u 2 +  - 2 2 2 1 + u 2 + u2 -1/2  2 u2 + 

Re = exp t × cos t

The Imaginary part is: q2 2 p1 2 + -1 1 2 + u2 2 2 + u2 p1 u q2 u - 2 uµ - 1/2 u 2 +  2 2 1 + u 2 + u2 -1/2  2 u2 + 

Im = exp t × sin t

For both models minimize equation (3.5) using parameters from GMM as initial parameters.

57

5.5

Discussion of Results from Parameter Estimation

From the parameter estimates, shown in Tables D.1, D.2, D.3, D.4, D.5 and D.6, the values for the parameters depend on the style and the estimation method used. The mean µ and standard deviation  did not differ so much across styles. In the pre-crisis period, the jump intensity of Event driven style is the largest for both ECF and MLE methods across styles. This trend changed in the crisis period; convertible arbitrage style has the highest jump intensity in this period. This change is probably due to effect of the market situation on the strategy employed by different styles. Also, the mean of the jump process µj is significantly lower for the convertible arbitrage style. For MLE estimates based on Merton model in Tables D.1, D.2 and D.3, the standard deviation of the jump distribution are higher for all styles in the crisis period than in other periods. For estimates based on Kou model in Tables D.4, D.5 and D.6, the p values are higher in the pre-crisis and post-crisis periods than in the crisis period. For Kou Model, estimation based on ECF saves time because of Fourier inversion involved in using the MLE estimation method, however, for Merton model the MLE method is better than the ECF method because the distribution of Merton model is known in closed form and less time is used in the parameter estimation.

5.6

Goodness of Fit

In order to assess the goodness of fit of the Merton and Kou distributions to the Hedge fund data, we use the quantile-quantile (Q-Q)-plot. A Q-Q plot is a plot of the quantiles of two distributions against each other, or a plot based on estimates of the quantiles. The pattern of points in the plot is used to compare the two distributions. If the plotted points lie roughly on the line y = x, then the compared distribution fits the data well. In order to show the goodness of fit using Q-Q plot, the Parameters from MLE from pre-crisis logreturns are used to simulate the distributions of the models and then the quantiles of the distributions are compared to the quantiles of historical log-return data sets. Q-Q plots for 58

our models are shown in figures 5.5, 5.6, 5.7 and 5.8. The styles from the other periods, show similar fit but are not shown. For the model based on the normal distribution, the deviation from the straight line is clearly seen (right panel) for all the styles. The Q-Q plots of the simulated returns against the historical returns show that both Merton and Kou models do significantly better job when compared to the models based on normal distribution. The quantiles of the simulated distributions are much more aligned with the quantiles of the historical return distribution than was the case for the plain normal distribution.

59

Simulated vs Empirical Data QQ-Plot for Kou's Model 0.01
0.01

QQ Plot of Sample Data versus Standard Normal

0.005
Simulated Quantiles

0.005

0

Quantiles of Input Sample

0

-0.005

-0.005

-0.01

-0.01

-0.015 -0.015

-0.01

-0.005 0 GH Data Quantiles

0.005

0.01

-0.015 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(a) Fitted Global Hedge
0.015

(b) Global Hedge vs Normal
QQ Plot of Sample Data versus Standard Normal 0.015

0.01

0.01

Simulated Data Quantiles

0.005
Quantiles of Input Sample

0.005

0

0

-0.005

-0.005

-0.01

-0.01

-0.015

-0.015

-0.02 -0.02

-0.015

-0.01 -0.005 0 0.005 0.01 Event Driven Strategy Log-returns Quantiles

0.015

-0.02 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(c) Fitted Convertible Arbitrage

(d) C. Arbitrage vs Normal

Figure 5.5: The QQ plot of Kou fitted Global hedge and Event driven strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data

60

0.015

QQ Plot of Sample Data versus Standard Normal 0.01

0.008

0.01
0.006
Simulated Data Quantiles

0.005
Quantiles of Input Sample

0.004

0

0.002

0

-0.005

-0.002

-0.01

-0.004

-0.006

-0.015
-0.008

-0.02 -0.02

-0.015

-0.01 -0.005 0 0.005 0.01 Convertible Arbitrage Log-returns Quantiles

0.015

-0.01 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(a) Fitted C. Arbitrage
6 4 2
Simulated Data Quantiles

(b) C. Arbitrage vs Normal
x 10
-3

x 10

-3
QQ Plot of Sample Data versus Standard Normal 8

6

4

2

0
Quantiles of Input Sample

0

-2 -4 -6

-2

-4

-6

-8 -10 -12 -14 -12 -10

-8

-10

-8 -6 -4 -2 0 2 Equally Weighted Strategy Quantiles

4 x 10
-3

-12 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(c) Fitted Equally Weighted

(d) Equally Weighted vs Normal

Figure 5.6: The QQ plot of Kou fitted Convertible Arbitrage and Equally weighted strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data

61

0.01

QQ Plot of Sample Data versus Standard Normal 0.01

0.005

0.005

Y Quantiles

0

Quantiles of Input Sample

0

-0.005

-0.005

-0.01

-0.01

-0.015 -0.015

-0.01

-0.005 0 X Quantiles

0.005

0.01

-0.015 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(a) Fitted Global Hedge
0.015

(b) Global Hedge vs Normal
QQ Plot of Sample Data versus Standard Normal 0.015

0.01

0.01

0.005
Quantiles of Input Sample

0.005

Y Quantiles

0

0

-0.005

-0.005

-0.01

-0.01

-0.015

-0.015

-0.02 -0.02

-0.015

-0.01

-0.005 0 X Quantiles

0.005

0.01

0.015

-0.02 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(c) Fitted Convertible Arbitrage

(d) C. Arbitrage vs Normal

Figure 5.7: The QQ plot of Merton fitted Global hedge and Event driven strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data

62

0.01 0.008 0.006 0.004
Y Quantiles

QQ Plot of Sample Data versus Standard Normal 0.01

0.008

0.006

0.004
Quantiles of Input Sample

0.002 0 -0.002 -0.004 -0.006 -0.008 -0.01 -0.01 -0.005 0 X Quantiles 0.005 0.01

0.002

0

-0.002

-0.004

-0.006

-0.008

-0.01 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(a) Fitted C. Arbitrage
8 6 4 2
Y Quantiles

(b) C. Arbitrage vs Normal
x 10
-3

x 10

-3
QQ Plot of Sample Data versus Standard Normal 8

6

4

2
Quantiles of Input Sample

0 -2 -4 -6 -8 -10 -12 -12 -10 -8 -6 -4 -2 0 X Quantiles 2 4 6 x 10
-3

0

-2

-4

-6

-8

-10

-12 -4

-3

-2

-1

0 Standard Normal Quantiles

1

2

3

4

(c) Fitted Equally Weighted

(d) Equally Weighted vs Normal

Figure 5.8: The QQ plot of Merton fitted Convertible Arbitrage and Equally weighted strategy vs Data (left panel) and QQ plot of data vs normal density (right panel) For Pre-crisis Data

63

One sample and Two sample Kolmogorov-Smirnov (KS) statistic goodness of fit tests are also used to test the null hypothesis that the log-returns are normally distributed and to test whether the empirical distribution Femp and the fitted distribution Ff it are sampled from the same distribution respectively. MATLAB one-sample Kolmogorov-Smirnov test, `[h,p,ksstat,cv] = kstest(x)', is used to compare the empirical data x to the standard normal distribution. The null hypothesis is that x has standard normal distribution. The alternative hypothesis is that x does not have that distribution. The result h is 1 if the test rejects the null hypothesis at the 5% significance level, 0 otherwise. The null hypothesis is accepted if p is greater than 5% and rejected otherwise. As shown in columns 1 and 2 in tables 5.1 and 5.2, the null hypothesis is rejected. The two-sample Kolmogorov-Smirnov test to compare the distributions of the values in the two data vectors, the empirical data x1 and the fitted data x2 is also used to whether the empirical distribution Femp and the fitted distribution Ff it are sampled from the same distribution. The null hypothesis is that x1 and x2 are from the same continuous distribution. The alternative hypothesis is that they are from different continuous distributions. The result h is 1 if the test rejects the null hypothesis at the 5% significance level; 0 otherwise. The test statistic is:

KS = max |Femp (y ) - Ff it (y )|
y R

The compared values of the KS test at  = 5% for normal, Merton and Kou distributions are reported in tables 5.1 and 5.2, the null hypothesis is accepted if the distance is too large and p value is greater than  and otherwise rejected. From the tables we can see that the KS distances for the different styles are smaller for Kou model than for Merton model.

64

G.H E. D C. A E. W

Normal KS 0.49675 0.49584 0.49678 0.49691

P 8.19e-236 6.49e-235 7.7e-236 5.78e-236

Merton KS 0.02838 0.02001 0.02747 0.02106

P 0.76542 0.97989 0.79915 0.96718

Kou KS 0.02071 0.01739 0.02242 0.01783

P 0.97177 0.99619 0.94414 0.99468

Table 5.1: KS distance and Probabilities For Pre-Crisis Returns Using MLE Parameter Estimates

G. H E. D C. A E. W

Normal KS 0.49675 0.49584 0.49678 0.49691

P 8.19e-236 6.49e-235 7.7e-236 5.78e-236

Merton KS 0.02960 0.02388 0.02838 0.02296

P 0.78623 0.91074 0.76542 0.88623

Kou KS 0.02529 0.02394 0.02674 0.02200

P 0.87154 0.90967 0.89954 0.951897

Table 5.2: KS distance and Probability For Pre-Crisis Return Using ECF Parameter Estimates

Also, The densities of the empirical data, the fitted data and normal random variables with the same mean and variance are compared using MATLAB `dfittool'. Non-parametric fit with normal kernel is used in fitting the densities. Comparing the densities of the logreturns to the densities of the simulated data from both models shows that the models provide good fit for the data as shown in the graphs of the densities in figures 5.9, 5.10, 5.11, 5.12, 5.13, 5.14, 5.15 and 5.16.

65

200 ED Data Normal Kou

180

160

140

120
Density

100

80

60

40

20

-0.015

-0.01

-0.005 Data

0

0.005

0.01

Figure 5.10: Fitted Event Driven Using Kou Model Parameter Estimates

250

Normal GH Kou

200

150
Density

100

50

-10

-5 Global Hedge Fund Log-returns

0

5 x 10
-3

Figure 5.9: Fitted Global Hedge Log-return Using Kou Model Parameter Estimates

66

200 180 160 140 120 100 80 60 40 20

CA Data Kou Normal

Density

-10

-8

-6

-4

-2 Data

0

2

4

6

8 x 10
-3

Figure 5.11: Fitted Convertible Arbitrage Log-return Using Kou Model Parameter Estimates

350 EW Data Kou Normal

300

250

Density

200

150

100

50

-10

-8

-6

-4

-2 Data

0

2

4

6 x 10
-3

Figure 5.12: Fitted Equally Weighted Using Kou Model Parameter Estimates

67

250

Normal Merton GH Data

200

150
Density

100

50

-10

-5 Data

0

5 x 10
-3

Figure 5.13: Fitted Global Hedge Log-return Using Merton Model Parameter Estimates

200 180 160 140 120
Density

Merton Normal ED Data

100 80 60 40 20

-0.015

-0.01

-0.005 Data

0

0.005

0.01

Figure 5.14: Fitted Event Driven Log-return Using Merton Model Parameter Estimates

68

200 180 160 140 120 100 80 60 40 20

Normal CA Data Merton

Density

-10

-8

-6

-4

-2 Data

0

2

4

6

8 x 10
-3

Figure 5.15: Fitted Convertible Arbitrage Log-return Using Merton Model Parameter Estimates

350

Normal Merton EW Data

300

250

Density

200

150

100

50

-10

-8

-6

-4

-2 Data

0

2

4

6 x 10
-3

Figure 5.16: Fitted Equally Weighted Log-return Using Merton Model Parameter Estimates

69

5.7

Application to Risk Management

The results obtained from the parameter estimation can be used in estimating the Value-atRisk (VaR) of an index which in turn could be used in portfolio management to determine an efficient portfolio. Definition of Value-at-Risk Hyunh, Lai and Soumar´ e (2011) defined VaR as the expected extreme loss emerging from the ownership of a risky portfolio or an asset during a specific period of time given a specific confidence level. VaR models try to measure the maximum potential loss for a fixed probability on a given time frame [17]. It tries to answer the question on the most one can lose in an investment within a reasonable bound. The VaR can be specified for an entire firm , a portfolio of assets or an individual asset. Monte Carlo Simulation VaR Estimation Method In Monte Carlo Simulation VaR Estimation Method (MCVaR), the risk factors are simulated through mathematical modelling of a stochastic process for each of the risk factors [17]. The freedom to choose distributions other than normal distribution for the variables, the flexibility in estimating VaR of any type of portfolio and ones ability to bring in subjective judgements to modify these distributions make MCVaR appealing. Unrealistic assumptions about normality in returns is avoided. The simulation process starts when a distribution is specified. Methodology Since the distributions of Kou and Merton models provide good fit for the log returns, these distributions are used to estimate the VaR of the hedge fund Strategies analysed using Monte Carlo Value-at-Risk Estimation method. The method used in this thesis is adopted from J.P. Morgan Investment Analytics & Consulting (www.jpmorgan.com) and is as follows: (1) Determine the length T of the analysis horizon and divide it equally into a large 70

number N of small time increments t (i.e. t = T /N ). (2) Simulate the distribution of the log-returns using the parameter estimates from Kou and Merton models walking along the N time intervals. (3) Repeat the run in (2) a large L number of times (1000 times is used) (4) Rank the L simulated log-return from the smallest to the largest, read the simulated value in this series that corresponds to the desired (1 - )% confidence level (95% or 99% generally) and deduce the relevant VaR, which is the difference between the expected value of the log-return and the th lowest terminal log-return. The VaR estimates for each fund are shown in the tables 5.3, 5.4, 5.5, 5.6, 5.7 and 5.8 .
Normal 0.00451 0.00540 0.00477 0.00309 Merton 0.00771 0.00913 0.00734 0.00556 Kou 0.00828 0.00923 0.00835 0.00633

Global Hedge E. Driven C. Arbitrage E. Weighted

Table 5.3: 99% Value-at-Risk Estimates For Pre-Crisis Data Using MLE

Global Hedge E. Driven C. Arbitrage E. Weighted

Normal 0.00451 0.00540 0.00477 0.00309

Merton 0.00887 0.00850 0.00665 0.00562

Kou 0.00897 0.00929 0.00824 0.00594

Table 5.4: 99% Value-at-Risk Estimates For Pre-Crisis Data Using ECF

71

Global Hedge E. Driven C. Arbitrage E. Weighted

Normal 0.01051 0.01338 0.02421 0.00843

Merton 0.01523 0.02428 0.04456 0.01529

Kou 0.01617 0.02569 0.05515 0.015389

Table 5.5: 99% Value-at-Risk Estimates For Crisis Data Using MLE

Global Hedge E. Driven C. Arbitrage E. Weighted

Normal 0.01051 0.01338 0.02421 0.00843

Merton 0.01079 0.02141 0.03572 0.01011

Kou 0.01497 0.02126 0.04187 0.01289

Table 5.6: 99% Value-at-Risk Estimates For Crisis Data Using ECF

Global Hedge E. Driven C. Arbitrage E. Weighted

Normal 0.00461 0.00528 0.00554 0.00344

Merton 0.00718 0.00979 0.00816 0.00557

Kou 0.00740 0.00995 0.00811 0.00615

Table 5.7: 99% Value-at-Risk Estimates For Post-Crisis Data Using MLE

Global Hedge E. Driven C. Arbitrage E. Weighted

Normal 0.00461 0.00528 0.00554 0.00344

Merton 0.00860 0.00986 0.00822 0.00530

Kou 0.00818 0.01070 0.00810 0.00594

Table 5.8: 99% Value-at-Risk Estimates For Post-Crisis Data Using ECF

The estimated VaR are based on log-returns which correspond approximately to percentage change in the value of the indices, the dollar amount of the VaR is the expected 72

value of the indices times the VaR of log returns. That is if the Value-at-Risk of the index is denoted by V aRi and that of the log-return is denoted by V aRr , then: V aRi = E(Ri ) × V aRr where E(Ri ) is expected value of the index. One can also use the approximation: V aRi = E(Ri ) × (exp (V aRr ) - 1). From the tables, we can see that VaR estimates based on normal distribution are lower than the estimates based on Kou and Merton Models. Estimates based on Kou and Merton Models are slightly different but the differences are not significant. Another thing worth pointing out is that the VaR estimates for Convertible arbitrage is higher than the estimates for the other style during the crisis period probably because the style was affected most during the period as could be seen from the time series plot in figure 2.4. In general, there are differences in the VaR estimates across styles and for different periods.

73

Chapter 6

CONCLUSION AND EXTENSIONS

This thesis examined the application of L´ evy processes of finite activity, in particular Kou and Merton models are introduced to model the jump that occurs in hedge fund indices caused by the over reaction or under reaction to outside news. The numerical results on four hedge fund styles show that Kou and Merton distributions capture the skewness and the tail behaviour of the distribution of hedge fund log-returns better than the normal distribution. The simulation of the indices under both models using the estimated parameters shows that these processes reproduce the dynamics of the indices. Kolmorov-Smirnov goodness of fit test results shown in tables 5.1 and 5.2 show that Kou model does a slightly better job at replicating the distribution of log-returns than Merton model. The parameter estimates from both ECF and MLE methods give similar results in terms of providing good fit for the data, however, the distribution from parameter estimates using MLE have slightly lower KS statistics values compared to those from parameters estimated using ECF method. The differences between the VaR estimates using parameters from both estimation methods are not much and therefore, when it is not possible to estimate parameters using MLE method, ECF method is a viable alternative. This study is based on an individual dataset, HFRX index values; thus, the conclusion may be different for other datasets. The performance of the two models needs to be checked on other data sets as well as against models with stochastic volatility; this is a possible extension to this thesis. Univariate models and constant parameters are used in the thesis; using multi-variable models and time-dependent parameters in analysing hedge fund indices are other possible extensions. Also, with the value at risk for each fund known, if the portfolio VaR is known we can use these in risk management. As an example, we can use a 74

simple ad hoc risk-aggregation formula suggested by [27] to get the portfolio VaR. Based on the formula, the VaR of a portfolio of N funds is easily obtained from the individual VaR of the funds as follows:
N N

V aRp =
i=1 j =1

i,j wi V aRi wj V aRj

(6.1)

Where wi is the weight of the ith fund and i,j is the correlation between the ith and j th fund. We can now use this method to choose the optimal weights of the fund to include in a portfolio in order to maximize return while keeping loss at a specified value by solving the following linear programming problem:

N

max E[Rp ] =
i=1

wi E[Ri ]

S.t V aRp  value 1 = w1 + · · · + wN wi  0

Where E[Rp ] is the expected return on the portfolio, E[Ri ] is the expected return of the fund or in our case index, 'value' is the maximum loss allowable in the portfolio.

75

Appendix A

THE DERIVATION OF THE CHARACTERISTIC FUNCTIONS

A.0.1

Derivation of Characteristic function for Merton's Model

The jump size in the Merton's model has a normal distribution with the density given by (4.6) and the following L´ evy density defined in [8] as: 
2 2j

f (x) =  (x) =

exp -

(x - µj )2 2 2j

The L´ evy triplet is given as (, , f (x)) ,  = µ -

2 2

- k . By the L´ evy-Khintchine

Theorem, the characteristic function of Xt satisfies the following relation: Xt (u) = et(u) , u  Rd

where  (u) known as the characteristic exponent is given by: 1  (u) = iu - u2 + 2 (eiux - 1 - iux1|x|1 ) (dx)

Rd

Since in the case of Merton's Model, the process has finite activity then 1 (eiux - 1) (dx)  (u) = iu - u2 + 2 d R 1 2 = iu - u + (eiux - 1)f (dx) 2 d R  1 2 = iu - u +  eiux f (dx) - 2 -
j u 1 = iu - u2 +  eiuµj - 2 - 1 2 2 2



f (dx)
-

76

A.0.2

Derivation of Characteristic function for Kou's Model

The jump size in the Kou's model has double exponential distribution with the density given by (4.6) and the following L´ evy density defined as f (y ) =  (y ) = p.1 e-1 y 1{y0} + q.2 e2 y 1{y<0} The L´ evy triplet is given as (, , f (y )) ,  = µ -
2 2 .

1 > 1, 2 > 0

By the L´ evy-Khintchine Theorem,

the characteristic function of Xt satisfies the following relation: Xt (u) = et(u) , u  Rd

where  (u) known as the characteristic exponent is given by: 1  (u) = iu - u2 + 2 (eiux - 1 - iux1|x|1 ) (dx)

Rd

Since in the case of Kou Model, the process has finite activity, i.e. in a finite period of time, it has a finite number of jumps, then 1  (u) = iu - u2 + 2 1 = iu - u2 + 2 (eiux - 1) (dx)
Rd  0

(eiux - 1)p.1 e-1 y dy +

0

(eiux - 1)q.2 e2 y
- 

1 1 -1 -(1 -iu)y = iu - u2 + p1 e + e-1 y 2 1 - iu 1 1 p1 q2 = iu - u2 + - p + - q 2 1 - iu 2 + iu 1 p1 q2 = iu - u2 +  + -1 2 1 - iu 2 + iu

+ q2
0

1 1 e(2 +iu)y + e2 y 2 + iu 2

0 -

77

Appendix B

MAPLE CODES

MAPLE Commands for Getting the Cumulants of Merton Model from Characteristic Function

  k1 k1 (0) I k2 k2 (0) I2 k3 k3 (0) I3 k4 k4 (0) I4 k5 k5 (0) I5 k6 k6 (0) I6

:= := := := := := := := := := := := := :=

u - e

t

Iu(µ-1/2  2 - k)-1/2  2 u2 +

2 2 eIµj u-1/2 j u -1

:

#  is the characteristic function

u - ln((u)) : # I is



-1
2 2

dif f ( (u), u$1) = u - t I µ - 1/2  2 -  k -  2 u +  Iµj - uj 2 eIµj u-1/2 j (µ - (1/2)   2 -   k +   µj )  t
2

u

# This is the first cumulant c1
2 2

dif f ( (u), u$2) = u - t - -  j 2 eIµj u-1/2 j t  2 +  j 2 +  µj 2

u

+  Iµj - uj 2

2 Iµj u-1/2 j 2 u2

e

# This is the second cumulant c2
2 2

dif f ( (u), u$3) = u - t -3  j 2 Iµj - uj 2 eIµj u-1/2 j t  µj 3 j 2 + µj 2 dif f ( (u), u$4) : t 3  j 4 + 6  j 2 µj 2 +  µj 4 dif f ( (u), u$5) : t  µj 15 j 4 + 10 j 2 µj 2 + µj 4 dif f ( (u), u$6) : t  15 j 6 + 45 j 4 µj 2 + 15 j 2 µj 4 + µj 6 # This is the third cumulant c3

u

+  Iµj - uj 2

3 Iµj u-1/2 j 2 u2

e

# This is the fourth cumulant c4

# This is the fifth cumulant c5

# This is the sixth cumulant c6

78

The cumulants for Kou model are derived in the same way. MAPLE Commands for Getting the Moment Conditions from Cumulants

µ(1) µ(2) µ(3)

:= := :=

c(1) : c(2) + c(1)2 :
3-1

c(3) +
m=1 4-1

3-1  (c(m)  µ(3 - m)) m-1 4-1  (c(m)  µ(4 - m)) m-1 5-1  (c(m)  µ(5 - m)) m-1 6-1  (c(m)  µ(c - m)) m-1 7-1  (c(m)  µ(7 - m)) m-1

:

µ(4)

:=

c(4) +
m=1 5-1

:

µ(5)

:=

c(5) +
m=1 6-1

:

µ(6)

:=

c(6) +
m=1 7-1

:

µ(7)

:=

c(7) +
m=1

:

79

Appendix C

MATLAB AND SAS CODES

C.1

Matlab Code for Computing the MLE for Merton Model

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %% This Script calls the function 'pdfmerton' which is the pdf of Merton %% built-in functions 'mle' model and MATLAB error estimates %% %%

and 'mlecov' and outputs the MLE and standard

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% format long; M = xlsread('hfrsprecrisisvalue.xls'); %read the data from excel file X = M(1:end,1); N = length(X); %% Get the log-returns for i = 1: N-1 P1(i) = log(X(i)/X(i+1)); end x = P1(end:-1:1)'; pdf_m = @pdfmerton % This the function handle calling the pdf %Input the initial values of the parameters mustart = 0.00027; sigmastart = 0.001671126388601; mujstart = 0; sigmajstart = 0.004388806529903; lambdastart = 0.073036563163645; start = [mustart,sigmastart,mujstart,sigmajstart,lambdastart]; %% Specify the upper and lower bounds for the parameters lb = [-Inf 1e-6 -inf 1e-6 1e-6]; ub = [inf Inf Inf Inf inf];

options = statset('MaxIter',10000, 'MaxFunEvals',10000); pEsts=mle(x,'pdf',pdf_m,'start',start,'lower',lb,'upper',ub,'options',options) acov = mlecov(pEsts, x, 'pdf',pdf_m); stderr = sqrt(diag(acov)) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

80

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

C.2

Matlab code for Merton Model PDF

function Q = pdfmerton(x,mu1,sigma1,muj,sigmaj,lambda) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This function takes the random variables x and the parameters and Merton's model. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% dt=1; Max_jumps = 10;%This is the maximum number of jumps fac = factorial(0:Max_jumps); for t = 1:length(x) transdens = 0;% transdens is the transition density for jumps = 0:Max_jumps-1 probjump =(exp(-lambda.* dt).*((lambda.*dt).^jumps))./fac(jumps+1);%the Poison distribution condmu = -(mu1 -((sigma1.^2)./2)-lambda.*(exp(muj + ((sigmaj.^2).*0.5)) -1)).*dt- jumps.*muj; condsigma = 2.*(((sigma1.^2).*dt) + jumps.*(sigmaj.^2)); cond_dens = (exp((-(x(t) + condmu).^2)./(condsigma))).* (1./sqrt(pi.*condsigma)); transdens = end S(t) = transdens; end Q = S'; end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% transdens + probjump.*cond_dens; outputs the PDF of

C.3

MATLAB Code for Kou Model PDF

function Q = pdfkou1(x,mu1,sigma1,eta1,eta2,p,lambda1) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This function takes the random variables x and the parameters and outputs the PDF of Kou model. I(n) is the inverse Fourier transform of the characteristic function. The Script for calling 'pdfmerton' is modified to call this function to get the MLE estimates

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

81

dt = 1; for n = 1:length(x) I(n) = (1/pi)*real( quadgk(@(u)exp(dt .* ((1i) .* u .* (mu1 - sigma1 .^ 2 ./ 0.2e1) - ... ((sigma1 .^ 2) .* u .^ 2) ./ 2 + lambda1 .* (p .* eta1./(eta1 + (-1.*1i) * u) + ... ((1-p).* eta2)./(eta2 + (1i).* u) - 1))) .*exp(-1i.*u*x(n)),0,inf,'RelTol',1e-8,... 'AbsTol',1e-12,'MaxIntervalCount',100000 )); end Q =I'; end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

C.4

MATLAB Codes for Cumulant Matching Method

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% This script calls the function Cumul_kou to estimate the parameters of Kou model by Cumulant Matching method %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% clear all; format long; init_param =[0.00027 0.002 1 1 0.5 1];

options= optimset('LargeScale','on','MaxFunEval',100000,'MaxIter',100000,'TolFun',1e-12,... 'TolCon',1e-12); [Para,xter,exit1]= fmincon('paranlekou',init_param, [],[],[],[],[],[],'confun2',options)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function SSE = Cumul_kou(Param) format long; M = xlsread('hfrxpostcrisisvalues.xls'); X = M(1:end,3); N = length(X); P = X(end:-1:1); P1(1) = 0; for i = 2: N P1(i) = log(P(i)/P(i-1)); end R = P1'; dt=1;

82

length(R); K1=mean(R); K2 = moment(R,2); K3=moment(R,3); K4=moment(R,4)-3*moment(R,2)^2; K5=moment(R,5)-10*moment(R,3)*moment(R,2); K6 =moment(R,6)-15*moment(R,4)*moment(R,2) -10*moment(R,3)^2+30*moment(R,2)^3; mu = Param(1); sigma = Param(2); eta1 = Param(3); eta2 =Param(4); p= Param(5); lambda= Param(6); f(1) = dt*(mu -0.5.*(sigma^2)+ lambda.*p./eta1 - lambda.*(1-p)./eta2)- K1; f(2) = dt *( sigma^2 + 2*lambda*((p./eta1^2) + (1-p)./eta2^2))-K2;

f(3) = 6*dt*lambda*((p./eta1^3) - (1-p)./eta2^3)- K3; f(4) = 24*dt*lambda*((p./eta1^4) + (1-p)./eta2^4)-K4; f(5) = 120*dt*lambda*((p./eta1^5) - (1-p)./eta2^5)-K5; f(6) = 720*dt*lambda*((p./eta1^6) + (1-p)./eta2^6)-K6;

SSE = (f(1)^2 +f(2)^2 +f(3)^2 + f(4)^2 +f(5)^2 +f(6)^2); end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function [c, ceq] = confun2(param) % Nonlinear inequality constraints c = [-param(5)+ 10^(-6);-param(2)+ 10^(-6);param(5)-1;-param(4)+ 10^(-6);... -param(6)+ 10^(-6);-param(3)+1]; % Nonlinear equality constraints ceq = []; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

C.5

MATLAB Code for Simulating Merton Model
Eulermrjd_sim (tf,dt,Params,S0)

function

%Param = (mu1,sigma1,muj,sigmaj,lambda) mu1 = Params(1); sigma1 = Params(2); muj= Params(3); sigmaj = Params(4); lambda= Params(5);

t0 = 1; t = t0:1:tf; N = length(t);% N is the number of simulation S = zeros(N,1);% Intialize S

83

S(1) = S0; k = exp(muj + ((sigmaj.^2).*0.5)) -1; z1 = randn(1,N-1); dw = sqrt(dt).*z1; Nt = poissrnd(lambda.*dt,1,N-1); for i =2:length(S)

if Nt(i-1) == 0 jump = 0; else jump = normrnd(muj*(Nt(i-1)) ,sqrt(Nt(i-1))*sigmaj); end S (i) = (mu1-(0.5.*(sigma1.^2))-(lambda.*k)).*dt + sigma1.*dw(i-1) end + jump;

save('eulersim.txt', 'S',

'-ASCII')

plot(t,S) end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

C.6

MATLAB Code for Simulating Kou Model

function Eulermrjd_simkou2(Params) % It requires the functions pssrnd1.m and Gamma1.m mu1 = Params(1); sigma1 = Params(2); eta1= Params(3); eta2 = Params(4); p = Params(5);lambda1= Params(6); t0 = 1; N = 1092; dt =1; t = (0:dt:N); length(t) %t2 =(0:1:N-1); % N is the number of simulation S = zeros(N+1,1);% Intialize S J = zeros(N+1,1); X = zeros(N,1); Nt =zeros(N,1);

84

S(1) =0.001428978523691; for i = 1:N Nt(i) = pssrnd1(dt*lambda1); if Nt(i) == 0; J(i) = 0; else K = binornd(Nt(i),p); R1 = Gamma1(K,eta1); R2 = Gamma1((Nt(i)-K),eta2); J(i) = R1 - R2; end S(i+1) = (mu1-(0.5.*(sigma1.^2))).*dt end save('eulersimkou2.txt', 'S', plot(t,S) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function y = Gamma1(a,b) if a == 0; y1 = 0; elseif a <= 1 y1 = gamma11(a); else y1 = gamma2(a); end y = y1/b; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function X1 = pssrnd1(lambda) X = 0;Sum = 0;flag = 0; while flag == 0 E = -log(rand); Sum = Sum + E; if Sum < lambda X = X + 1; else flag = 1; end end X1 = X; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% '-ASCII') + sigma1*sqrt(dt)*randn + J(i);

85

function y = gamma2(a) a2 = a-1; c = (a-(1/(6*a)))/a2; m = 2/a2; d = m+2; flag = 0; while flag == 0 W1 = rand; W2 = rand; V = c*W2/W1; if m*W1-d+V+(1/V)<=0 flag = 1; elseif m*log(W1)-log(V)+V-1<=0 flag = 1; end end y = a2*V; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function x = gamma11(a) e = exp(1);c = (a+e)/e;flag = 0; while flag == 0 W1 = rand;W2 = rand;Y = c*W1; if Y<=1 Z = Y^(1/a); if W2<exp(-Z) flag = 1; end else Z = -log((c-Y)/a); if W2<=Z^(a-1) flag = 1; end end end x = Z; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

86

C.7

MATLAB Code for ECF estimation method for Kou Model

% This script calls the function 'charfunkou2' to estimate the parameters of Kou Model format long; init_param = [0.000339, 0.001191,971.0867,623.0382,0.208876,0.126135]; options= optimset('LargeScale','on','MaxFunEval',100000,'MaxIter',100000,'TolFun',1e-12,... 'TolCon',1e-12); [Para,xter,exit1]= fmincon('charfunkou2',init_param, [],[],[],[],[],[],'confun4',options) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% function C = charfunkou2(u, Param) clear all format long; M = xlsread('hfrSprecrisisvalue.xlsx'); P = M(1:end,1); N = length(X); for i = N-1: 1 P1(i) = log(P(i)/P(i+1)); end Dt = 1; x =P1(1:N-1); mu = Param(1); sigma = Param(2); muj= Param(3); sigmaj = Param(4); lambda= Param(5); k = exp(muj + ((sigmaj^2)./2)); sum1 =0; sum2 = 0; for i = 1: length(x) Remchar1 = cos(u*x); sum1 =sum1 + Remchar1; Imemchar1 = sin(u*x); sum2 = sum2 +Imemchar1; end Rempchar = sum1./length(x); %This is the real part of empirical CF

Imempchar =sum2./length(x); % This is the imaginary part of empirical CF A1 = exp(dt .*(-(sigma^2 .*u^2)./2 + lambda.*((p.*eta1^2/eta1^2+u^2)... + (((1-p).*eta2^2)/eta2^2+u^2 )-1)) ); A2 = cos(dt .*(u.*mu-(sigma^2 .*u^2)./2 + lambda.*((p.*u.*eta1^2/eta1^2+u^2)... + (((1-p).*u.*eta2^2)/eta2^2+u^2 )))); A3 = sin(dt .*(u.*mu-(sigma^2 .*u^2)./2 + lambda.*((p.*u.*eta1^2/eta1^2+u^2)...

87

+ (((1-p).*eta2^2)/eta2^2+u^2 )))); RealTheoChar = A1.* A2; %This is the real part of Kou's model xteristic fnc ImagTheoChar = A1.*A3; %This is the Imaginary part of Kou's model xteristic fnc C = (RealTheoChar -Rempchar)^2 + (ImagTheoChar - Imempchar)^2; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

C.8

SAS Code for estimation of Kou Model Parameters using GMM method

/* GMM estimation of the parameters of Kou's Jump-Diffusion Model Author: Ugochi Emenogu /* Import uemenogu@ryerson.ca */ file path below is correct: */

datasets from Excel. One has to make sure that the

PROC IMPORT OUT= WORK.hfrxpostcrisislogrets DATAFILE= "\\Client\C$\Users\ugochi\Documents\hfrxpostcrisislogrets.xls" /*daily returns*/ DBMS= xls REPLACE; SHEET="Sheet1"; GETNAMES=YES; RUN; proc model data = hfrxpostcrisislogrets; endogenous ED; dt = 1; /* Specify initial parameters */ parms mu 0.0002 sigma 0.0018 /* The Cumulant*/ m1 = dt*(mu - 0.5*(sigma**2) + lambda*((p/eta1) - (1-p)/(eta2))); m2 = dt*sigma**2 + dt*lambda*((2*p/(eta1**2)) + 2*(1-p)/(eta2**2)); m3 = 6 * dt*lambda*((p/(eta1**3)) - (1-p)/(eta2**3)); m4 = 24 * dt*lambda*((p/(eta1**4)) + (1-p)/(eta2**4)); m5 = 120 * dt*lambda*((p/(eta1**5)) - (1-p)/(eta2**5)); m6 = 720* dt*lambda*((p/(eta1**6)) + (1-p)/(eta2**6)); m7 = 5040*dt*lambda *((p/(eta1**7)) - (1-p)/(eta2**7)); eta1 415.737 eta2 265.17 p 0.509 lambda 0.09370 ;

/* Moment conditions */ eq.h1 = ED - m1 ; eq.h2 = ED**2 eq.h3 = ED**3 m2-m1**2 ; - (m3 +3*m2*m1 + m1**3);

eq.h4 = ED**4 - (m4 +4*m3*m1 +3*(m2**2) +6*m2*(m1**2) + m1**4); eq.h5 = ED**5 - (m5 +5*m4*m1 +10*m3*m2 +10*m3*(m1**2) +15*(m2**2)*m1 +10*m2*(m1**3) +m1**5);

88

eq.h6 = ED**6 - (m6 +6*m5*m1 +15*m4*m2+15*m4*(m1**2)+10*(m3**2)+ 60*m3*m2*m1 +20*m3*(m1**3)+(15*m2**3) +45*(m2**2)*(m1**2) +15*m2*(m1**4) +(m1**6)); eq.h7 = ED**7 -(m7+7*m6*m1+21*m2*m5+21*m5*(m1**2)+35*m4*(m1**3)+35*m3*(m1**4)+21*m2*(m1**5)+ 105*(m1**3)*(m2**2)+105*m1*(m2**3)+ 70*m1*(m3**2)+105*(m2**2)*m3 +35*m3*m4 +105*m1*m2*m4 + 210*(m1**2)*m2*m3+m1**7); bounds lambda > 0, eta2 > 0, sigma > 0, instruments / intonly; fit h1-h7 / gmm kernel=(parzen, 1, 0); run; %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% eta1 > 1, p > 0, p < 1;

89

Appendix D

TABLES SHOWING PARAMETER ESTIMATES

The tables start from the next page.

90

µ



µj

91

j



G.Hedge MLE ECF GMM MM 0.0003 0.0003 0.0003 0.0003 (0.0000) (0.0000) (0.0001) (-) 0.0013 0.0017 0.0017 0.0017 (0.0001) (0.0001) (5.6E-6) (-) -0.0010 -0.0006 -0.0006 0.0000 (0.0003) (0.0001) (0.0002) (-) 0.0021 0.0038 0.0038 0.0044 (0.0002) (0.0006) (0.0003) (-) 0.4589 0.0730 0.0700 0.0730 (0.1464) (4.0E-5) (0.0236) (-)

E. Driven MLE ECF GMM MM 0.0004 0.0004 9.7E-4 0.0004 (7.5E-5) (2.2e-6) (2.3E-4) (-) 0.0015 0.0013 0.0013 0.0020 (1.3E-4) (3.1E-6) (0.0005) (-) -0.0005 -0004 -0.0004 0.0000 (0.0002) (6.2E-9) (0.0002) (-) 0.0026 0.0024 0.0024 0.0043 (0.0003) (2.2E-6) (0.0005) (-) 0.5297 0.7297 0.7297 0.1202 (0.1720) (0.0000) (0.4966 ) (-)

C. Arbitrage MLE ECF GMM MM 7.3 E-5 7.3 E-5 0.0002 -1.1E-6 (6.2E-5) (1.84E-6) (0.0001) (-) 0.0018 0.0016 0.0016 0.0010 (6.1E-5) (1.37E-5) (0.0002) (-) -0.0012 -0.0002 -0.0002 0.0000 (0.0006) (0.0001) (0.0001) (-) 0.0033 0.0022 0.0022 0.0018 (0.0005) (2.0E-5) (0.0003) (-) 0.1005 0.3179 0.3179 0.9553 (0.0422) (2.6E-2) (0.2240 ) (-)

E. Weighted MLE ECF GMM MM 2.36E-4 2.36E-4 0.0006 2.91E-7 (4.2E-5) (1.26E-6) (0.0001) (-) 0.0009 0.0010 0.0010 0.0011 (6.0E-5) (0.0001) (0.0001) (-) -0.0006 -0.0009 -0.0009 0.0000 (0.0002) (0.0007) (0.0004) (-) 0.0018 0.0020 0.0020 0.0035 (0.0002) ( 0.0001) (0.0004) (-) 0.3231 0.1742 0.1742 0.0602 (0.0979) ( 0.0804) (0.1119) (-)

Table D.1: Parameter Estimates for Pre-crisis Hedge Fund Indexes Using Merton's Model

µ



µj

92

j



G.Hedge MLE ECF GMM MM -1.1E-4 -0.0007 0.002 -2.0E-6 ( 7.5E-5) (3.4E-6) (0.0046) (-) 0.0010 0.0004 0.0004 0.0011 (4.6E-5) (0.0000) (0.0271) (-) -0.0013 -0.0009 -0.0010 0.0000 (2.46E-4) (8.8E-6) (0.0018) (-) 0.0037 0.0030 0.0030 0.0060 (0.0003) (4.7E-6) (0.0028) (-) 0.3330 1.4497 1.4497 0.1520 (0.0407) (0.0000) (5.3231) (-)

E. Driven MLE ECF GMM MM -1.15E-4 -0.0007 -1.5E-4 -2.0E-6 (9.1E-5) (4.9E-6) (0.0003) (-) 0.0010 0.0030 0.0030 0.0019 (5.6E-5) ( 0.0033) (0.0009) (-) -0.0011 -0.0010 -0.0010 0.0000 (2.48E-4) (0.0002) (0.0004) (-) 0.0045 0.0087 0.0087 0.0102 (0.0003 ) (0.0046) (0.0008) (-) 0.3839 0.2535 0.2535 0.0672 ( 0.0433) (0.0019) (0.1419) (-)

C. Arbitrage MLE ECF GMM MM -6.8E-4 -0.0025 0.0006 -1.3E-5 (1.5E-4) (2.0E-5) (0.0015) (-) 0.0014 0.0042 0.0042 0.0016 (8.0E-5) (0.0034) (0.0021) (-) -0.0043 -0.0080 -0.0080 0.0000 (8.32E-4) (0.0006) (0.0036) (-) 0.0098 0.0148 0.0148 0.0214 (0.0010) (0.0004) (0.0052) (-) 0.1987 0.1665 0.1665 0.0615 (0.0297) (0.0892) (0.1802) (-)

E. Weighted MLE ECF GMM MM -9.5E-5 -0.0007 0.0006 -1.0E-6 (6.1E-5) (2.61E-6) (0.0013) (-) 0.0009 0.0018 0.0018 0.0011 (5.2E-5) (0.0060) (0.0014) (-) -0.0012 -0.0017 -0.0017 0.0000 (2.34E-4) (0.0056) (0.0026) (-) 0.0029 0.0034 0.0034 0.0056 (0.0003) (0.0111) (0.0022) (-) 0.3203 0.3526 0.3526 0.1108 (0.0531) (0.0873) (0.9040 ) (-)

Table D.2: Parameter Estimates for In-Crisis Hedge Fund Indexes Using Merton's Model

µ



µj

93

j



G.Hedge MLE ECF GMM MM 1.35E-4 0.0001 4.06E-4 0.000001 (6.8E-5) (1.7E-6) (7.0E-5) (-) 0.0013 0.0016 0.0016 0.0017 ( 3.05E-4 ) (2.7E-4) (5.1E-5) (-) -0.0008 -0.0033 -0.0033 0.0000 ( 0.0005) (0.0001) (0.0003 ) (-) 0.0020 0.0040 0.0040 0.0051 (0.0006) (1.7E-5) (0.0004) (-) 0.4576 0.0306 0.0306 0.0436 ( 0.4464 ) (0.0377) (0.0131) (-)

E. Driven MLE ECF GMM MM 2.07E-4 0.0002 5.26E-4 0.0000 (8.0E-5) (9.6E-5) (9.6E-5) (-) 0.0018 0.0018 0.0017 0.0018 (1.25E-4) (0.0001) (9.8E-5) (-) -0.0015 -0.0019 -0.0019 0.0000 ( 0.0007) (0.0007) (0.0007) (-) 0.0037 0.0040 0.0040 0045 (0.0009 ) (0.0008) (0.0006 ) (-) 0.1391 0.0766 0.0765 0.1095 ( 0.0898) (0.0578) ( 0.0453 ) (-)

C. Arbitrage MLE ECF GMM MM 0.0005 0.0005 2.5E-4 1.0E-6 (8.9E-5) (2.1E-6) (0.0001) (-) 0.0013 0.0017 0.0018 0.0020 (1.4E-4 ) (6.8E-6) (0.0001) (-) 0.0004 0.0010 0.0010 0.0000 (0.0002 ) (7.5E-5) (0.0004) (-) 0.0024 0.0040 0.0040 0.0042 (0.0002) (4.3E-6) (0.0004) (-) 0.8541 0.1201 0.1201 0.1504 (0.2068) (0.0000) (0.0377) (-)

E. Weighted MLE ECF GMM MM 1.44E-4 1.44E-4 0.0005 1.0E-6 (5.1E-5) (1.3E-6) (0.0001) (-) 9.67E-4 0.0012 0.0012 0.0013 (1.1E-4) (1.6E-6) (0.0001) (-) -0.0006 -0.0015 -0.0014 0.0000 (0.0003) (0.0000) (0.0006) (-) 0.0017 0.0021 0.0020 0.0048 ( 0.0002 ) (0.0000) (0.0004) (-) 0.4276 0.0937 0.0937 0.0293 ( 0.1922) (0.0000) (0.0567) (-)

Table D.3: Parameter Estimates for Post-Crisis Hedge Fund Indexes Using Merton's Model

µ



1

94

2

p



G.Hedge MLE ECF GMM MM 0.0008 0.0007 0.0007 0.0006 (0.0003) (0.0000) (0.0001) (-) 0.0011 0.0015 0.0015 0.002 (0.0002) (0.0000) (0.0001) (-) 1180.2 785.78 785.26 491.6 (528.64) (10.82) (213.9) (-) 762.45 632.85 633.21 366.70 (130.09) (69.74 ) (83.55) (-) 0.4030 0.1919 0.1915 0.2417 (0.2719) (0.0080 ) (0.2021) (-) 1.0946 0.3706 0.3717 0.4938 (0.7402) (0.0082 ) (0.2315) (-)

E. Driven MLE ECF GMM MM 0.0007 0.0004 0.0004 0.0004 (0.0003 ) (0.0000) (0.0003) (-) 0.0014 0.0015 0.0015 0.0015 (0.0002) (0.0002) (0.0004) (-) 838.64 898.80 898.80 170.22 (203.27) (6.61) (161.6 ) (-) 673.94 591.19 591.19 254.31 (132.24) (13.56) (19) (-) 0.4583 0.6042 0.6042 0.0616 (1516) (0.0001) (0.1188) (-) 1.1677 0.9988 0.9988 0.12 (0.4937) (0.1506) (.6809) (-)

C. Arbitrage MLE ECF GMM MM 0.0002 0.0002 0.0002 0.0002 (0.0002) (0.0000) (0.0006) (-) 0.0017 0.0012 0.0012 0.0010 (0.0001) (0.0000) (0.0006) (-) 849.79 1294.55 1294.51 198.03 (603.87) (5.08) (210.8) (-) 504.56 1264.67 1264.68 390.39 (135) (12.26) (483.5) (-) 0.5381 0.4742 0.4741 0.2914 (0.4889) (0.0001) (0.2456) (-) 0.2907 2.2101 2.2101 0.9553 (0.3537) (0.0000) (2.1461) (-)

E. Weighted MLE ECF GMM MM 0.0005 0.0004 0.0004 0.0007 (0.0001) (0.0000) (0.0001) (-) 0.0008 0.0010 0.0010 0.0010 (0.0002) (0.0000) (0.0001) (-) 1153.45 920.08 920.08 425.65 (361.61) (13.37) (146.3) (-) 902.72 784.09 784.09 654.89 (151.68) (4.10) (158.4) (-) 0.3435 0.3095 0.3095 0.0081 (0.1573 ) (0.0100) (0.1221) (-) 0.6018 0.3500 0.3500 0.3108 (0.2468 ) (0.0125) (0.2219 ) (-)

Table D.4: Parameter Estimates for Pre-Crisis Hedge Fund Indexes Using Kou's Model

µ



1

95

2

p



G.Hedge MLE ECF GMM MM 0.0010 0.0017 0.0018 -0.0001 (0.0005) (0.0001) (0.00129) (-) 0.0023 0.0010 0.0010 0.0010 (0.0003) (0.0005) (0.0000) (-) 149.37 367.45 387.30 146.09 (109.71) (31.58) (48.56) (-) 378.41 572.19 555.50 233.21 (86.60) (20.39) (133.5) (-) 0.0310 0.1221 0.1349 0.2139 (0.0354) (0.3814) (0.1163) (-) 0.7557 2.0570 2.0224 0.3330 ( 0.3452) (1.4341) (0.0023) (-)

E. Driven MLE ECF GMM MM 0.00005 0.00035 0.0004 -0.0001 (0.0004) (0.0000) (0.0013) (-) 0.0037 1E-6 1E-8 0.0033 (0.0003) (0.0002) (0.0000) (-) 287.46 143.22 287.47 142.94 (92.24) (29.53) (26.20) (-) 182.12 305.40 305.40 148.43 (57.36) (25.46) (79.18) (-) 0.1708 0.3523 0.3523 0.2570 (0.1717) (0.0014) (0.2006) (-) 0.2401 1.2487 1.2494 0.1987 (0.1341) (0.1364) (0.4294) (-)

C. Arbitrage MLE ECF GMM MM -0.0006 -0.0006 -0.0001 -0.0006 (0.0003) (0.0001) (0.0007) (-) 0.0036 0.0036 9.9E-9 0.0014 (0.0003) (0.0001) (0.0000) (-) 157.95 210.81 210.81 50.41 (67.89) (25.00) (40.88) (-) 75.18 138.88 138.88 70.71 (14.35) (57.99) (11.05) (-) 0.3469 0.3971 0.3971 0.1340 (0.1798) (0.0784) (0.1140) (-) 0.2991 0.7585 0.7585 0.1987 (0.1024) (0.0972) (0.1252) (-)

E. Weighted MLE ECF GMM MM 0.0003 0.0007 0.0008 -0.0007 (0.0003) (0.0002) (0.0008) (-) 0.0018 0.0018 1E-8 0.0033 (0.0002) (0.0002) (0.0000) (-) 156.54 391.46 391.46 476.88 (110.05) (15.98) (26.69) (-) 346.96 559.84 559.84 615.42 (80.51) (108.68) (158.00) (-) 0.0405 0.1466 0.1466 0.4444 (0.0392) (0.0122) (0.1288) (-) 0.4055 1.2307 1.2307 0.3203 (0.1641) (0.3565) (0.6019) (-)

Table D.5: Parameter Estimates for In-Crisis Hedge Fund Indexes Using Kou's Model

µ



1

96

2

p



G.Hedge MLE ECF GMM MM -0.00110 0.00027 0.00034 0.00027 (0.0000) (0.0000) (0.0004) (-) 1E-6 0.0014 0.0014 0.0018 (0.0000) (0.0000) (0.0005) (-) 2687.23 1272.69 1272.69 476.88 (332.10) (460.52) (670.6) (-) 948.20 602.47 602.47 615.42 (133.77) (151.27) (240.1) (-) 0.8592 0.5369 0.5369 0.4444 (0.0186) (0.0003) (0.0494) (-) 7.3213 0.3938 0.3938 0.3108 (1.3124) (0.3380) (0.4006) (-)

E. Driven MLE ECF GMM MM 0.0006 0.0004 0.0004 0.0003 (0.0002) (0.0003) (0.0002) (-) 0.0017 0.0014 0.0014 0.0018 (0.0002) (0.0001) (0.0003) (-) 513.46 794.52 794.52 280.00 (270.78) (128.32) (145.4) (-) 517.02 581.16 581.16 305.17 (146.56) (108.49) (137.3) (-) 0.1989 0.4822 0.4822 0.4111 ( 0.1828) (0.1001) (0.1276) (-) 0.3407 0.5246 0.5256 0.1397 (0.2326) (0.2110) (0.3802) (-)

C. Arbitrage MLE ECF GMM MM 0.0002 0.0002 0.0002 0.0002 (0.0004) (0.0000) (0.0001) (-) 0.0011 0.0015 0.0015 0.0016 (0.0002) (0.0001) (0.0001) (-) 722.30 594.42 594.42 759.70 (123.05) (76.45) (88.13) (-) 922.01 616.56 616.56 244.47 ( 216.24) (50.51) (85.75) (-) 0.5107 0.6243 0.6243 0.8677 (0.1478) (0.0802) (0.1018) (-) 1.8015 0.5831 0.5831 0.5932 (0.6351) (0.1065) (0.2097) (-)

E. Weighted MLE ECF GMM MM -0.0008 0.0003 0.0003 0.0002 (0.0005) (0.0001) (0.0000) (-) 0.0004 0.0012 0.0012 0.0018 (0.0002) (0.0001) (0.0000) (-) 3498.54 971.09 971.09 415.73 ( 813.75) (180.54) (719.0) (-) 1005.77 623.04 623.04 265.18 (154.09) (87.71) (96.74) (-) 0.9007 0.2089 0.2089 0.5089 (0.0566) (0.2957) (0.5001) (-) 6.1694 0.1261 0.1261 0.0937 (3.2623) (0.0473) (0.1498) (-)

Table D.6: Parameter Estimates for Post-Crisis Hedge Fund Indexes Using Kou's Model

REFERENCES

[1] Abramowitz, M. and Stegun, I. A. (1972), Handbook of Mathematical Functions, 10th printing with corrections, Dover, ISBN 978 - 0 - 486 - 61272 - 0. Equation 25.4.46. [2] Alternative Investment Management Association (2004) AIMA Hedge Fund Primer. [3] Alvarez, M., and Levinson, M. (2007), Hedge Fund Risk Modeling, MSCI Barra Model Insight, April 2007. [4] Briani, M. (2004), Numerical methods for option pricing in jump-diffusion markets, Ph.D. Thesis. [5] Andersen, T.G. and Sorensen, B. E. (1996), GMM Estimation of SVM:A Monte Carlo study. Journal of Business & Economic Statistics; 14(3). [6] Beckers, S. (1981), A note on estimating the parameters of the diffusion-jump model of stock returns, Journal of Financial and Quantitative Analysis 16(1), 127-40. [7] Carr, P., Gemman, H., Madan, D., and Yor, M. (2002), The Fine Structure of

Asset Returns: An Empirical Investigation, Journal of Business, vol. 75, no. 2. [8] Cont, R., and Tankov, P. (2004), Financial Modelling with Jump Processes, Chapman & Hall/CRC Financial Mathematics Series. [9] Eberlein, E. (2007), Jump-type L´ evy processes, Handbook of Financial Time Series, Springer (forthcoming). [10] Feuerverger, A., McDunnough, P. (1981b) On some Fourier methods for inference, J. Am. Statist. Assoc. 76:379387.

97

[11] Geman, H. (2002), Pure Jump L´ evy Processes for Asset Price Modelling, Journal of Banking and Finance, 26 (2002), pp. 1297-1316. [12] Glasserman, P.(2004)Monte Carlo Methods in Financial Engineering, Stochastic Modelling and Applied Probability Series, Springer. [13] Hall, A. R. (2005), Generalized Method of Moments, (Advanced Texts in Econometrics). Oxford University Press. ISBN 0-19-877520-2. [14] Hall, B. H.(1999), Notes on Generalized Method of Moments Estimation, [15] Heathcote, C. R. (1977), The integrated squared error estimation of parameters, Biometrika, 64, 255-264. [16] Hurn, S. (2009) Likelihood Methods in Financial Econometrics, Economic Research Southern Africa University of Stellenbosch [17] Huynh, H. T., Lai, V. Soumare, I. (2011), The Wiley Finance Series : Stochastic Simulation and Applications in Finance with MATLAB Programs. Hoboken, NJ, USA: Wiley, 2011. p 315. [18] Jiang, G. J. (1998), Jump-Diffusion Model of Exchange Rate Dynamics Estimation via Indirect Inference, University of Groningen Research Institute Research Report, No. 98A40. [19] Jiang, G. J. and Knight, J. L (2002), Estimation of continuous-time processes via the empirical characteristic function, Journal of Business and Economic Statistics, 20(2), 198 - 212. [20] Kat, M and Brooks, C. (2001), The Statistical Properties of Hedge Fund Index Returns and their Implications for Investors, Cass Business School Research Papers.

98

[21] Kenney, J. F. and Keeping, E. S.,(1951), Cumulants and the Cumulant-Generating Function, Additive Property of Cumulants, and Sheppard's Correction. 4.10 - 4.12 in Mathematics of Statistics, Pt. 2, 2nd ed. Princeton, NJ: Van Nostrand, pp. 77-82. [22] Knight, J. L., Yu, J.(2002), Empirical Characteristic Function in Time Series Estimation, Econometric Theory Vol. 18, No. 3 (Jun., 2002), pp. 691-721 Published by: Cambridge University Press [23] Kou, S. G. (1999),A Jump Diffusion Model for Option Pricing with Three Properties: Leptokurtic Feature, Volatility Smile, and Analytical Tractability, Econometric Society World Congress 2000 Contributed Papers. [24] Kou. S. G. (2002),A Jump-Diffusion Model for Option Pricing. Management Science 48 (8), 1086 - 1101 [25] Kou. S. G. (2008),Jump-Diffusion Models for Asset Pricing in Financial Engineering, Handbooks in OR & MS, Vol. 15 [26] Lhabitant, F. (2004), Hedge Funds Quantitative Insights, The Wiley Finance Series. [27] Longin, F.M. (2000), From value at risk to stress testing: the extreme value approach, Journal of Banking and Finance, 24, 1097-1130. [28] Matsuda, K. (2004),Introduction to Merton Jump Diffusion Model, The Graduate Center, Department of Economics, The City University of New York [29] Matsuda, K. (2006), Le ´vy Option Pricing Models: Theory and Application, The Graduate Center, Department of Economics, The City University of New York [30] Merton, R. H. (1976), Option pricing when underlying stock returns are discontinuous, journal of finance Vol. 57, Springer-Verlag, [31] (2011)NIST e-Handbook of Statistical Methods, http://www.itl.nist.gov/div898/handbook/ 99

[32] Olivares, P., Seco, L.(2003), Stable Distributions: a survey on simulation and calibration methodologies, Technical report Risk Lab University of Toronto. [33] Parzen, E. (1999), Stochastic Processes, SlAM's Classics in Applied Mathematics Series. [34] Press, S. J. (1967), A Compound Events Model for Security The Journal of Business, Vol. 40, No. 3 , pp. 317-335 [35] Rice, J. A.(1988), Mathematical Statistics and Data Analysis, Duxbury Press: California . [36] Rockinger, M. and Semenova, M. (2005), Estimation of Jump-Diffusion Processes via Empirical Characteristic Functions, Swiss Finance Institute, Research paper 150 [37] Schoutens, W.(2003), L´ evy Processes in Finance: Pricing Financial Derivatives, Wiley Series in Probability and Statistics [38] Thurk, J.(2004), Notes on Generalized Method of Moments [39] Wu, L. (2005), Modeling Financial Security Returns Using L´ evy Processes, City University of New York, CUNY Baruch College - Zicklin School of Business, Working paper series. [40] Yu, J. (2004), Empirical Characteristic Function Estimation and Its Applications, Econometric Reviews Vol. 23, No. 2, pp. 93123 [41] Zongwu, C. (2010), Econometric Analysis of Financial Market Data, Financial Engineering Notes.

100


