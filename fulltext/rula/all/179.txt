Ryerson University

Digital Commons @ Ryerson
Economics Publications and Research Economics

10-1-2009

Evolution of the Week
Amy Peng
Ryerson University

Francis McKenna
Ontario Ministry of Finance

Follow this and additional works at: http://digitalcommons.ryerson.ca/economics Part of the Economics Commons Recommended Citation
Peng, Amy and McKenna, Francis, "Evolution of the Week" (2009). Economics Publications and Research. Paper 45. http://digitalcommons.ryerson.ca/economics/45

This Working Paper is brought to you for free and open access by the Economics at Digital Commons @ Ryerson. It has been accepted for inclusion in Economics Publications and Research by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

Evolution of the Week
Amy Peng1 Department of Economics Ryerson University 350 Victoria Street Toronto, Ontario apeng@ryerson.ca Francis McKenna Ontario Ministry of Finance 7 Queen's Park Crescent Toronto, Ontario Francis.Mckenna@ontario.ca

October 2009

Abstract The purpose of this paper is to provide an intuitive explanation of the emergence and evolution of the week based on a historical precedent draw from ancient Egypt. In this paper, we view the week as a coordinating social institution that was created to resolve a fundamental problem of society - coordinating market exchange. Artificial adaptive agents are used to simulate the interactions among farmers going to market. The results show that the length of the week that emerges depends on the chosen cost and benefit specifications and random interactions. Keywords: social institution, coordination games, agent based models JEL Classification: D02 B52 C63

1

Corresponding author, Phone: (416) 979 ­ 5000 ext. 4795. Fax: (416) 598 ­ 5916.

I. Introduction The 7-day week has been in continuous use for at least the last 34 centuries (see http://webexhibits.org/calendars/index.html for details.) Although, at different times and in different places, weeks of differing lengths have been used: the ancient Egyptians used 10-day weeks (an idea briefly revived during the French Revolution), the Mayan calendar contained both 13-day and 20-day weeks, the former Soviet Union experimented with both 5 and 6-day weeks before returning to the 7-day standard and, until the 14th century, Lithuanians used a 9-day week. From these few examples, it is apparent that various local standards must have existed throughout the ages and that it is only when interaction between individuals from different locales became more frequent that certain standards became more than just local standards. Although people can only speculate as to where, when and why the 7-day week was first used, it is precisely because it became common place that it has continued to enjoy such longevity. Andrew Schotter (Schotter 1981) provides an intuitively plausible explanation of why time is arbitrarily divided into weeks. Schotter views the week as a coordinating social institution that emerges to resolve a fundamental problem of society, namely market exchange. Individual farmers need to coordinate on specific dates to exchange their produce although the coordination depends on the growing season. More specifically, Schotter uses a super-game approach, since any choice by any individual agent has an impact on the available choices and potential outcomes of every other agent. Endowed with perfect knowledge, agents are all well informed about the structure of the game, potential choices available and their ramifications as well as the behaviour of every

2

other agent around them so the only rational choices available lead to a set of common length weeks. To further develop Schotter's original idea, we employ an agent-based modelling approach - the artificial adaptive agents of Holland and Miller (1991). Our method differs from a game theory approach for the following reasons: firstly, as in the game theory approach, we are interested in the equilibria of the game; however we are also interested in agents' selections among multiple equilibria as well as their transition to an equilibrium. Agents (or players) in the game make somewhat rational choices due to learning through experimentation and positive and negative feedbacks. Our research focuses on creating an apparatus for individual agents to interact in the environment and learn to choose optimal solutions through their trail and error. Secondly, in the case of the occurrence of a large number of multiple equilibria, we differ from the game theory approach by choosing a synchronizing event to allow effectively reduce the number of equilibria under considerations as an equilibrium to occur. For example, the week doesn't correspond to anything in nature (whereas the day corresponds to the rotation of the earth and the month roughly corresponds to the cycle of the moon). If we do not place a limit on the possible choices, it will be impossible for any converge to equilibrium to occur. We borrow a precedent from ancient Egypt to define the necessary synchronizing event1 the coming of the New Year. This event acts as a pre-existing point of reference for the

The creation of one of the world's first calendars by the ancient Egyptians, around 5000 years ago, was intimately tied to astronomical observations. Once people realized that the reappearance of the star Sirius, above the horizon after its 70-day absence, was a reliable indicator of the start of the flood season (the inundation lasted from late June to October, in the Gregorian calendar, with the harvest occurring in late February, in the Gregorian calendar), the first new moon after that event was declared to be the first day of the New Year. Eventually the Egyptians adopted a 10-day week, making the year 36-weeks long with 5 "extra" days at the end. Actually, the year is a bit longer than this but it didn't matter to the Egyptians since it was the reappearance of Sirius and not the length of the year that determined when the New Year began.

1

3

individual farmers allowing them to synchronize their behaviour. Thus an individual farmer can choose to visit town up to 365 times per year2. Since Tomas Schelling's original work, which has been republished in the book Micromotives and Macrobehavior (Schelling 1978), a number of studies have been focused on modelling the emergence of institutions. A majority of the past studies have emphasised endogenous development of trade networks, socially acceptable regulation and welfare outcomes. This research is inspired by a few influential studies which focus on the causal connection relating structure, behaviour and economic outcomes with bounded rational agents (Sargent 1990; Arthur 1994; Young 1998; Cross 1978 and Epstein 2001). Attempts to simulate the emergence of economic institutions are fraught with difficulties, and the experiments reported in this study are no different in that respect. There are so few successful results in this area since investigators have little agreement on how best to model the genesis and evolutions of this process. With this research, we would like to make the following contributions: 1) explore the evolutionary behaviour of relatively simple agents in a complex enough environment. 2) Establish a common agentbased modelling framework that could be applied to study prototypical cases of the emergence of economic institutions. 3) Test the characteristics of the institution and study the stability of the entrenched institutions.

There is also an obvious secondary synchronizing event, the coming of the new moon that we can also choose to take into account which would further reduce the number of possible equilibria. However, later our result shows since the concept of the month is based on the cycle of the moon, including this secondary event may make certain week lengths more likely to occur than others.

2

4

The structure of the paper is as follows: section two provides an explanation of the model, section three introduces the learning techniques used in the paper, section four reviews simulation results from three different scenarios and section five concludes.

II. The Model Suppose there are n farmers each of which grows a distinct crop on an individual parcel of land. The farms, equidistant from a central town, are arrayed on a circle. Each farmer has a preference for all other kinds of produce and gains no satisfaction from consuming his own crop or leisure. Each farmer must bear a transportation cost, TCi, each time he decides to carry his produce to market in town. The crop is extremely perishable and cannot be stored. The crops can be considered to ripen on the vine, as it were, with the removal of the first ripe fruit allowing less mature fruit additional time to develop. The amount of the crop that the farmer can take to market on any given day is determined by a function of time since the last harvest which is also the time of the last visit to town:
c  2 c - 2 (t - g ) , 0  t  g  (t ) =  g  c, otherwise 
i

Thus,

2c 2c  = - 2 t + g t g

Parameter g is a growing parameter and c is the maximum quantity of the crop that a farmer can carry. Both g and c are allowed to vary between parcels of land and from crop to crop. Function (t) informs the farmers that there may be a relationship between their visit to the market and the growing parameters. If they wait too long between visits, some of the crop will rot on the vine and cannot be taken to the market. Similarly, if the

5

farmers wait too short of the time between their visits, the amount of the crop ready to take to the market will be reduced. Departing from Schotter's treatment, we will assume that positive utility is obtained from trade even if fewer than n farmers come to market (this is important since none of the agents are directly aware of the choices that will be made by the other agents.) We assume that utility is a function of both variety and quantity. Suppose that m farmers come to market on a particular day, where 1 m n, each bringing the quantity, xi, of their own individual good. Although there are m types of produce that have been brought to market, individual farmers only care about m - 1 of those types. Thus, variety can be represented by the number m - 1. We define M to be the set of farmer index numbers representing the m farmers that have come to market, and we assume that the goods are equally distributed among the farmers that have a preference for them. We could just as easily have assumed that a market institution has evolved previously and that a general equilibrium set of prices can be calculated and trade take place. However, this is not necessary since the fundamental problem is for the farmers to coordinate on the number of days to elapse before returning to market and not the development of efficient resource allocation. The quantity each farmer receives can be written as qi = and, thus, utility is given by
U i = Avi qi = A(m - 1)  ( 1 x j )  = A(m - 1)  - (  x j )   m - 1 jM  j i jM  j  i

1 xj m - 1 jM  j i

Furthermore, we will assume that the only choice available to farmers is the number of days to wait between visits to town.

6

The set up of the model can be illustrated in the figure below. Without defining a synchronizing event, agents (farmers) can play unlimited number of strategies since they can come to town at any time of their choice. Therefore the game has unlimited number of pure strategy Nash equilibria as long as there is another agent plays the same strategy to coordinate their exchange.
Table 1: The Market Coordinate Game Agent J's Choice
Day 1 2 3 4 1 2 3 4 5 6 7 ··· 29 30 ··· 363 364 365 ···

Agent I's Choice

5 6 7 ... 29 30 ... 363 364 365 ...

To refine the equilibria, we can define a reference point: for example, the start of year will limit the choice of equilibria to 365. If we choose the month as an additional reference point, we can further reduce the number of equilibria to 30. However, in order to for the game to converge to a common length of the week, using a standard game

7

theory approach is difficult. A possible solution of this problem is to derive the stochastically stable equilibria (Young, 1993 and 1998) by finding a path of least resistance from every equilibrium to every other and then finding the equilibrium that has lowest over all resistance. However, this method will only work if agents have limited numbers of strategies to play and the game has to have a strict payoff structure. When agents have three or more strategies, not all of the payoff structure of this game can have a stochastically stable equilibrium. For example, if all agents of the game play a 5-day, 6day or a 7-day strategy and the payoffs from the game are close to each other, we could have the case where there is no risk dominate equilibrium. As we increase the number of agents in the game with a more complex payoff structure, hand refining equilibrium becomes more and more difficult. Agent based modelling approach can be a very effective tool to study such a problem. First, it allows a flexible structure in which artificial agents can play the game with their rational choice. Second, we can observe the path or the dynamics of the game and its equilibrium process more closely. However, as can be seen from the next section, it is very important to choose a reasonable learning technique so that the evolution process is well defined and close to reality.

III. Learning Algorithm

The choice mechanism of model agents can be constructed using any one of a number of different techniques such as artificial neural networks (Margarita, Beltratti and Terna, 1995) or classifier systems (Holland, Holyoak, Nisbett and Thagard, 1989.) For simplicity and illustrative purposes, the farmer agents in this model will employ

8

reinforcement comparison learning (Sutton and Barto, 1998) to choose their next response. If action, a, is understood to mean skip a days (actually, to go to town on days of the year d = ja; j = 1, 2, 3, ...) and ri represents the reward, net utility, accrued on the i-th play of action a. Each agent chooses their next action according to a set of preferences over actions that evolves based on the history of rewards received. Initially, there is almost equal probability that any action will be chosen regardless of the pattern of rewards earned. However, with more experience, the probabilities come to favour high reward actions alone. A mathematical description of the agent learning technique follows. Suppose there are n distinct actions {a i }i -1 . The probability of selecting action ait
n

at time t is it. The probabilities are constructed from the relative preferences held for each action, with the preferences themselves being a weighted average of the rewards experienced:
1  = ; i = 1, 2," , n;  ti = n
i 0

e pt -1

1

e
j

pti -1

At time t, action ait is selected according to the probabilities it-1; i=1,2, ..., n, then a reward rt = rt(at ; ) is received. The preferences are updated as follows: 1  at  Pt -1 +  [rt - r t -1 ][1 - u ( - ) ta-t1 if i = ai Pt =  2 i  P otherwise  t -1
i

where  is an exogenous preference adjustment weight. Preference for actions that have a large probability advantage adjust more slowly if the exogenous parameter =1. u is a type of indicator function,
0 if x < 0 u ( x) =  1 if x  0

9

This learning rule above adjusts the preference for a selected action instead of adjusting all of the probabilities directly. Good rewards are rewards that are above an endogenously predicted reward (or aspiration level, r t ) and not simply rewards that are above zero. The aspiration level ( r t ) is similarly adjusted according to the following procedure.
 r t -1 +  (rt - r t -1 ) rt =   max 0 , r t -1 +  (rt - r t -1 )  1 if u ( - ) = 0 2 1 if u ( - ) = 1 2

{

}

Where  is an exogenous aspiration adjustment weight. The aspiration level remains nonnegative, regardless of reward history, if the parameter =1.

IV. Results

All of the following simulations are based on an ensemble of 100 agents under a synchronized event - the setting of the year. Constant Contribution We start our simulations with a simplified version of the model described in section two. We assume farmers will make their choice based on their evaluations of transportation costs and rewards only. Let transportation costs be TCi and Rewards be TBi (TBi = m-1, m is the number of farmers come to the market on the ith day), therefore, if TBi>TCi, farmers will have positive returns by coming to the market on the ith day and a farmer will update this information through the learning algorithm. Figure 1 represents a market census conducted on each and every day of the month over 1000 period. The figure shows results for period 0, period 120 (equivalent to 10 years) as well as period 1000. At the start of the simulation, agents randomly select their week length choice. By period 1000, there are strong spikes apparent at 12 and 24 10

days, which actually depict the emergence of a 12-day week. When interpreting Figure 1, care should be taken since the census figure includes the effects of "harmonics." An agent that comes to town on the ith day will also come to town on the k(ith) day. As we observe, the distribution of census results appears to increase throughout the month due to the harmonics. To take this into account, we produce Figure 2, which shows the actual distribution of week-length choices. At the end of period 1000, 2 agents have chosen to visit town every 6 days during the month, 81 agents have decided to visit town every 12 days during the month and 17 agents have chosen to visit town every 24 days after the start of the month. In order to investigate the dynamic path of the choices, we plot two farmers' choices in Figure 3. These farmer agents initially experiment a great deal until around period 150 in their attempt to learn the best choice. Agent "A" focuses on a 24day week for much of the simulation with only brief periods of experimentation with other choices. For example, choosing a 12-day week six times during the first stable period, a 26-day week once, a 29-day week once, a 20-day week once and 9-day week once. Then around period 550, the agent alternated back and forth between a 12-day and a 24-day week. After period 650, the agent chooses a 12-day week almost exclusively, reverting to a 24-day week on only four occasions. Agent "B" demonstrates a very different story. After period 180, this agent has essentially fixed the choice on a 6-day week, except for choosing a 12-day week twice, a 19-day and 23-day week once. Figure 3 indicates two interesting facts: 1) social norms can be created in a customary, selfreinforcing manner but agents are cognitively limited and a number of agents may well not learn the optimal solution to a given problem. The results show agents can converge to a social norm rather quickly, but they are still experimenting with other choices from

11

time to time. 2) The alternate choices are usually the harmonics. This is reasonable since if a choice is a good one, so will its harmonics be. Agents not only learn about a good choice but they also learn that harmonics are good choices as well. Although there are tuning factors in the learning algorithms that may well affect the rate of convergence and robustness to an uncertain environment, they have not been considered systematically here. Externality In this scenario, we take into account a positive externality. Since a bigger market can accommodate more varieties of goods and services and under a barter system, we assume there is a far greater chance to satisfy the double coincidence of wants, it is reasonable for us to suppose that bigger markets have advantages over smaller markets. To model this positive externality, we introduced an externality function, which takes the following form.
 m  m-m  ( m) =   e m - m m
m m-m

x  -1e x Here (m) is related to the standard gamma distribution, which is given by f ( x) = ( )

and modified so that its maximum value is unity. m and m are used to control the shape of the externality function. m is the number of the farmers for which the aggregate reward is maximized and m is the number of the farmers for which the average reward would be maximized - although, we don't use average reward in the set of simulations presented in the paper. Therefore if a farmer comes to the market on the ith day, the reward can be presented as TBi = b(n) where b is the maximum reward. 12

The simulation starts using (see Figure 4) to encourage the formation of a large market. Note that (m) can model the negative externality as well by simply adjusting and . Figure 4 shows two examples of the externality function with different parameter values. Figure 5 shows the distribution of farmers' choices over 1000 periods. At the end of the 1000 periods, 70 farmers choose a 6-day week, 24 farmers choose a 12-day week, 1 farmer chooses a 21-day week , 3 farmers choose a 24-day week and 2 farmers choose a three-day week. Therefore, a 6-day week norm has emerged, but one should be aware of the fact that the maximum reward (parameter b) has a big impact on the length of the week. When the maximum reward increases, the length of the week typically shortens. Farmers can afford to go to the market more frequently if the reward is high enough. Our results indicate that, when b = 95, 70 percent of farmers' choices are concentrated on a 2day week or a 4-day week; when b = 85 as shown in Figure 5, farmers' choices are predominantly a 6-day week; and when b = 75, 77 percent of the farmers choose a 12-day week. We also want to point out another interesting fact: when including the positive externality, agents learn to converge much quicker. Compared to Figure 2, at period 120, 90 percent of agents have already fixed their choice on a 6-day or 12-day week. In terms of other characteristics of the norm, the results are very similar to the previous section, therefore we won't duplicate them here. Contact with Established Norm The two prior sets of simulations have shown that agents can evolve to their social norms in simple environments. In this section, we try to test what factors can change the evolution of the norm and how norms can be evolved over time.

13

In order to test the convergence of the norm, we introduce to the model a group of agents with an established norm. First of all, we want to test how this group of agents with an established norm can help the other agents to evolve. We specify a percentage of agents that will not change their choice of week-length, which we set arbitrarily at seven days. Figure 6 shows the actual distribution of farmers' choices when 7 percent of agents start with a fixed choice of a seven-day week. This particular case is an extension of the results from Figure 5, where their original choices of week length are six days. With a large enough group of agents with a fixed choice of a 7-day week, the model quickly converges to a seven-day week. At period 120, 91 percent of the agents have already converged to a 7-day week or one of its harmonics. By period 1000, 96 percent of agents choose a 7-day or 14-day week. Therefore, existence of a pre-established norm can influence agents' behaviour and attract agents to a different equilibrium. It is also important to point out that adjusting the reward level (parameter b) can also alter the percentage of 7-day week farmers' required in the game. If we increase the maximum reward, for example, b = 95, it will take 12 percent of agents starting with a fixed length of seven days to persuade other agents to change their behaviour. However, if we decrease the maximum reward, a seven-day week can converged with a smaller percentage of fixed length agents (When b = 75, only 6 percent of fixed length agents are required.) The second question we attempt to answer is whether or not, after the establishment of a social norm, the system is susceptible to invasion by other norms. To test this, we used a similar method as above except for the fact that the seven day agents are introduced at a later period. Our result shows, if contact with the established norm

14

group occurs during the intense learning period, then the other agents will come to emulate the new group. However, if contact occurs at a point in time when the agents have an entrenched norm, experimentation will not occur at a high enough rate to dislodge the established norm. Although past studies (such as Epstein (2001)) have indicated that the presence of a continuous source of noise, in the form of agents' random actions, can lead to punctuated equilibria and the shift from an established norm. In our model, there is no such source of internal noise and outside forces alone are insufficient to change the norm or breakdown an existing norm. Our results tend to confirm a widely held belief--once a social norm is established, it is very hard to break it by application of outside forces.

V. Summary and Conclusion

In this paper, we used an agent-based modelling approach to study one of the oldest institutional problems: the evolution of the week. We constructed a simulation model based on a description provided by Schotter (1981) and conducted a number of experiments based on this framework. Our approach provides a plausible explanation for the evolution of the week. The norm of the week can emerge in a market coordination game with simple settings which highlight the supposed customary and self-enforcing characteristics of the norm. An agent-based modelling approach provides a much more realistic set of assumptions and works with a set of boundedly rational agents. Agents can converge to a social norm by making choices which may not be optimal; agents continue experimenting with their choices even after the establishment of equilibrium. Furthermore, experiments

15

with this model reveal two key points: 1) there must be some focal point, such as the beginning of the year or the month, for the agents to synchronize their behaviour otherwise no convergence will occur at all and 2) we must be prepared to deal with the problem of "harmonics"­if an agent visits town every d-days, the agent will visit town a total of times during the month. Reinforcement learning techniques adopted in this study have proven their robustness. With different game settings and different parameters, the algorithms ensure the convergence of the model and demonstrate the learning behaviour of the agents. It is very interesting to see how agents not only learn to converge to their norm but also make reasonable choices concerning harmonics. Other reinforcement learning structures should also be explored in future work on modelling the emergence of institutions in agent-based modelling frameworks. Further work can be developed along this line of research. First of all, it will be useful to see how agents can learn not only through experimentation but also through imitation. Modelling communication among agents may improve the speed and quality of convergence and allow established norms to change with only a few experimenting agents. Second, the model can be modified so that there is always a large enough positive probability for the agents to choose what would otherwise appear to be inferior choices. At the very last, an agent-based approach has opened the door to study problems where we are concerned about how a solution is arrived at as much as what the solution is, as indicated by this study, the evolutionary process is as important as the norm itself.

16

References

Arthur B (1994) Inductive Reasoning and Bounded Rationality: The El Farol Bar Problem. American Economic Review, vol. 84, no. 2, pp 406-411. Cross J G (1973) A Stochastic Learning Model of Economic Behaviour. Quarterly Journal of Economics, vol. 87, no. 2, pp 239-266. Eaton B C, Morrison W G (2003) Evolutionary Stability in the Investment-OpportunismRetailiation Game. Journal of Bioeconomics, vol. 5, no. 1, pp 27-45. Epstein J M (2001) Learning to Be Thoughtless: Social Norms and Individual Computation. Computational Economics, vol 18, pp 9-24. Holland J H and Miller J H (1991) Artificial Adaptive Agents in Economic Theory. American Economic Review, pp 365-70. Schelling T C (1978) Micromotives and Macrobehaviour. New York: Norton. Schotter A (1981) The Economic Theory of Social Institutions. New York: Cambridge University Press. Sutton R S and Barto A G (1998) Reinforcement Learning: An Introduction. MIT Press. Young H P (1993) The Evolution of Conventions, Econometrica, vol. 61, No.1, pp 57 ­ 84. Young H P (1998) Individual Strategy and Social Structure: An Evolutionary Theory of Institutions. Princeton University Press.

17

Figure 1: Market Census
100

80

Farmers in Town

60

40

20

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Period 0 Period 120 Period 1000

Figure 2: Distribution of Choices
100

80 Farmers Choosing Week Length

60

40

20

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Period 0 Period 120 Period 1000

Figure 3: Farmer Choices Over Time
30

24

Week Length Choice

18

12

6

0 150

250

350

450

550 Time Agent 'A'

650

750

850

950

Agent 'B'

Figure 4: Farmer Externality Function
1

0.8 Fraction of Maximum Reward

0.6

0.4

0.2

0 0 10 20 30 40 50 60 70 80 90 100 Number of Farmers Present

Figure 5: Distribution of Choices
80

Farmers Choosing Week Length

60

40

20

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Period 0 Period 120 Period 1000

Figure 6: Distribution of Farmer Choices
60

50

40 Farmers in Town

30

20

10

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Period 0 Period 120 Period 1000

