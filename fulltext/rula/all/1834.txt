Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2008

Image Processing Techniques For Improved Sun Sensor Performance
Christopher. Li
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Mechanical Engineering Commons Recommended Citation
Li, Christopher., "Image Processing Techniques For Improved Sun Sensor Performance" (2008). Theses and dissertations. Paper 1149.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

Image Processing Techniques for Improved Sun Sensor Performance
by

Christopher Li
Bachelor of Engineering, Aerospace Engineering, Ryerson University, 2006

A thesis presented to Ryerson University

in partial fulfillment of the requirements for the degree of Master of Applied Science in the program of Mechanical Engineering
PROPERlY OF ni"ERSON Ui~lvtRSrTY UBRARY

Toronto, Ontario, Canada, 2008 @Christopher Li 2008

Declaration
I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part , at the request of other institutions or individuals for the purpose of scholarly research.

Ill

Image Processing Techniques for Improved Sun Sensor Performance

Christopher Li
Master of Applied Science Program of Mechanical Engineering, Ryerson University, 2008

Abstract
The behaviour of digital sun-sensors and associated super-resolution algorithms was explored. Using calibration data, a method was proposed to Using this with model the peak width of peaks across the image array.

the non-linear least square algorithm gave improved performance across the field-of-view. A test was proposed that would measure precision for small sensor motions. Also, a method of accounting for local bias error was given. The small motion test defined limits at which the sensor detects motion, and the precision test gave metrics to measure how well the sensor renders motion. Finally, an extended kalman filter was develped that used sun-vector measurements, in addition to a new relative measurement. This was tested using a well-defined sensor as well as a generic sensor for which few error data were known. Results indicate that relative measurements only improve performance if random noise is low.

v

Acknowledgements
I would first like to thank my thesis supervisor, Dr. John Enright, for giving me the opportunity to pursue this research. His guidance and encouragement have given me the means to investigate these topics. I would also like to thank Mr. Doug Sinclair from Sinclair Interplanetary for providing the SS-256 and SS-411 sun sensors; also, for the technical assistance he has given our research group thorughout the last two years. A thank you also goes out to Dr. Don McTavish for his assistance in helping tackle the issues in building a dynamics simulator. I would also like to thank Albert Yam for his help throughout the past two years. He helped me understand signal processing. I would like to thank my father , Tony Li, and my mother, Lynda Meandro, for their unwavering support of my academic career, and their words of encouragement whenever I felt overwhelmed. Finally, I would like to thank Sinah Lee. Thank you for your love and support. You've stood by me throughout my entire university career, and without you I don't belive I could ever have dreamed of getting this far.

Vll

Contents
Declaration Abstract Acknowledgements Table of Contents List of Figures List of Tables Nomenclature
1

iii v vii xii xiv
XV

XVI

Introduction
1.1 Attitude Estimation Methods 1.1.1 1.1.2 1.1.3 1.1.4 1.1.5 1.1.6 1.2 1.2.1 Gyros and Accelerometers Horizon Sensors Magnetometers Star Trackers Sun Sensors Comparison of Systems . Analog Sun Sensors .
IX

1

2 2 3 3 3 4 4 5 5

Sun Sensor Basics . . . . . .

1.2.2 1.2.3 1.3 1.3.1

Digital Sun Sensors . . . . . . . . Digital Sun Sensor Improvement . . . . Thesis Outline .

5
6

Work Objectives

7

8
9
9

2 Background 2.1 Sun Sensor Optics . . . . . . . . . . .
2.2 2.3 Identifying the Image Characteristics Super-Resolution . . . . . . . .. 2.3.1 2.3.2 2.3.3 2.4 2.4.1 2.4.2 2.4.3 2.4.4 First-Order Centroiding . Non-Linear Least Squares Linear-Phase . . . . . . .

14 16
17 17
20

Algorithm Testing and Sensor Calibration Calibration Approach . . . . The Sun Sensor Test Setup Calibration Image Sets Calibration Procedure

22
22

23 23
26

3 Peak Width Correction
3.1 Peak Shape Theory and Data Collection 3.1.1 3.1.2 3.2 3.2.1 3.2.2 3.3 3.3.1 3.3.2 3.3.3 3.4 3.5 Theory Development . . . . . . Width Data Collection . . . . . Fit Equation Development Curve Fit Results . Index of Refraction Longitudinal Gap . Transverse Gap . .

29

29 29
30 32 32 34 35 35 35

Relating Peak Width to Array Position

Calibration Revision . . .

Effects on Algorithm Performance . Summary . . . . . . . . .
X

36 36 39

4

Precision Testing

41

4.1

Motion Limit 4.1.1 4.1.2

..... .

42 43 45 45 46 48 50 51 52 55 57 58 60 62 63 65 66 66
67 . . . . . . .

Motion Limit Theory Motion Limit Results . Quaternion Mapping Theory . Applying the Quaternion . . . Definitions in the Precision Test Precision Test Results . . . . . .

4.2

Calibration Offsets and the Best Rotation Quaternion . 4.2.1 4.2.2

4.3

Precision . . . . . . . . . . . . . . . . 4.3.1 4.3.2

4.4
5

Summary

Filtering for Rate Sensing

5.1 5.2

Filter Formulation Defining the System 5.2.1 5.2.2 5.2.3 5.2.4 5.2.5 Derivation of the Expected Observation . Deriving F and H Sensor Noise Modelling . . . . . . Planned Measurement Simulation Initialization Values . . . . . .

5.3 5.4

Exact Solution 5.4.1 5.4.2

Generic Sensor Simulation Sun-Vector Observation Only Relative Observation Sun-Vector Observation Only Relative Observation

68 68

69
71 71
72

5.5

SS-411 Simulation . . . . . . 5.5.1 5.5.2

5.6
6

EKF Remarks .

74
75
.................. 75

Conclusions

6.1

Summary

xi

6.1.1 6.1.2 6.1.3 6.1.4 6.2 6.2.1 6.3

Calibration Work Width Correction Precision Testing . Extended Kalman Filter Field-of-View Precision .

76 76 77 78 79 79

Future Work . . . . . . . . . . . 6.2.2 EKF / Precision Model Unification Closing Remarks

80 80
81

Bibliography

xii

List of Figures
2.1 2.2 2.3 2.4 2.5 3.1 3.2 3.3 3.4 3.5 3.6 4.1 4.2 4.3 4.4 4.5 4.6 4.7 Geometric Model of Sensor Showing Aperature and Image Planes.[Enright, 2008] . . . . . . . . 11 12 12 15 24 31 32 34 36 37 38 46 Geometric Model of the Image Plane. . . . . . . Image of the Central Array Gap.(Enright, 2008] Four-Peak versus Three-Peak Image. Experimental Setup. . . . .

Image Peak with Curve Fit. Fitted Peak Width by Array Position. Peak Width by Array Position with Curve Fit. . Definition of Longitudinal and Transverse Gaps. FOV Error Plot with No Width Correction (in Radians). FOV Error Plot with Width Correction (in Radians). Confidence that Motion has Occurred. . . . . . . . .

Difference Between Estimated and True Sun Vectors Before Bias Reduction. . . . . . . . . . . . . . . . . . . . . . . . . . . 47 Difference Between Estimated and True Sun Vectors After Bias Removal. . . . Typical FOV Error Plot (in Radians) .. Local Region RMS Error. Far Field RMS Error. . . . Local Region Normalized RMS Error.
Xlll

50 51 53 53 54

4.8
5.1

Normalized RMS Error to 1°0ffset. . . . . . . . . . . . . . . . 55 Error Vector Magnitude in

s for Generic Sensor,

No Relative

Observation. . . . . . . . . . . . . . . . .

5.2
5.3 5.4 5.5 5.6

X-axis relative observation Comparison .. Error Vector Magnitude in Error Vector Magnitude in

69 70

s for Generic Sensor with Relative s for
SS-411, No Relative Obser72 73

Observation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 vation. . . . . . . . . . . . . . . . . . . . X-axis relative observation Comparison. . Error Vector Magnitude in

s for SS-411 with Relative Obser-

vation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

xiv

List of Tables
1.1 2.1 3.1 3.2 ADCS Sensor Comparison(Adapted from [Wertz, 1999]) . Physical Sensor Paramaterization . . Fourth-Order Curve Fit Parameters . Calibration Summary . . . . . . . . . 4 27 34 39

XV

Nomenclature
Symbol Description Sun Vector

¢
D
I

Array-Mask Offset Slit Width of x-axis Slits Pixel Length Array Position (in pixels) Pixel-0 x-Location Image-Array Angle Index of Refraction of Mask Array-Mask Distance Subtended Area Annular Offset Image on Array Platform Center of Rotation to Sun Platform Center of Rotation to Sensor Origin Array Location Standard Deviation Error Longitudinal Gap Length Transverse Gap Length Angle Between Two Vectors xvn

m
Px
nglass

h

0
(

I[n]

T

a

G

Gr

e

f-l

Mean Value Degrees of Freedom Confidence Level Quaternion System Equations of Motion Observation Expected Observation Filter Gain Matrix Covariance Matrix State Matrix Angular Velocity about x-axis x-axis Moment of Inertia

v
a

if
!() Z() h() K() P() X()
Wx f xx

xviii

Chapter 1 Introduction
Attitude determination and control systems (ADCS) is a critical part of space vehicle design. A number of disturbance torques act on any space vehicle, and many of these are unpredicatable and change with time. The responsibility of the ADCS is to observe the effects of these disturbances and align the space vehicle as desired , rejecting the external effects that attempt to change the orientation away from this desired state. Attitude determination is made using various different types of sensors. Although many different phenomena can be observed to determine the attitude of the spacecraft, sensors and associated information processing will return one of two things. Some sensors yield an inertial measurement, namely, the current alignment of the space vehicle with respect to some external reference. Another class of sensors returns relative measurements, such as the angular momentum of the vehicle or the rate of change of the orientation. Some sensors, such as star trackers, can operate in both modes , and often multiple types of sensors are used for situational redundancy. In this section, a general comparison of different attitude determination sensors will be performed. These different sensor classes can be used in conjunction with sun sensors in different determination systems to deliver better overall performance. Once the role of sun sensors with respect to
1

1. INTRODUCTION

other sensor types is understood, a more in-depth description of how sun sensors work will be given. Finally, the objectives of this thesis regarding sun sensor improvement will be defined.

1.1

Attitude Estimation Methods

A number of different types of sensors are available that yield a measure of the space vehicle's orientation. There are a number of ways in which these sensors differ. Selection of the appropriate sensor requires an analysis of the accuracy requirements of the mission, the cost, mass, and power budgets allotted to the system, and the conditions in which the sensors are expected to operate. In many cases, multiple attitude sensing devices can be used so that attitude observability is maintained when certain attitude sensors aren 't usable. For example, a sun-sensor cannot be used when the sun is outside the fieldof-view, or when the sun is eclipsed - usually by the earth. In this case, another sensing method must be available to receive attitude information.

1.1.1

Gyros and Accelerometers

Gyros and accelerometers measure the speed of rotation about a particular axis. When an initial reference point is given, or is found using other sensor types , accelerometer data can be used to update the estimate through time. Because no absolute position measurements can be taken, the attitude estimates will eventually drift away from the true value in absence of other measurement types. Depending on the type of sensor used, this drift can vary from 0.003° up to 1o every hour[Wertz, 1999].
2

1.1. Attitude Estimation Methods

1.1.2

Horizon Sensors

Horizon sensors are infrared sensors that detect the heat given off by the earth 's atmosphere. This allows the spacecraft to know its orientation relative to the earth-disc. Accuracy for these systems runs from 0.1 o to 0.25°. Generally, the use of horizon sesors requires unobstructed view of the earth through the field-of-view cone.

1.1.3

Magnetometers

Magnetometers are very simple and lightweight devices that yield crude attitude estimates by detecting the surrounding magnetic field. When this is compared with the known earth 's magnetic field, some attitude information can be found. Magnetometers are often used in conjunction with higherprecision sensors, such as star or sun sensors, for increased accuracy.

1.1.4

Star Trackers

Star sensors are high-precision devices that work by looking at star positions within the field-of-view. They can be used for differential tracking, where the relative movement of the bright spots in the field of view can be used to derive a rotational speed. If uploaded with a star catalogue and more sophisticated software, a star sensor can provide a high-accuracy measurement of absolute orientations by comparing the picture taken with known star patterns. Although they are very high-precision devices, star sensors suffer a number of drawbacks. They are generally heavier than many other sensor types , use more power, and are of higher cost. They also can be blinded by a number of things , including the sun, the earth, and other planets - since they often cause star pattern identification failures. Nonetheless, star sensors are often used when high-precision applications are considered.
3

1. INTRODUCTION

1.1.5

Sun Sensors

Sun sensors are lightweight, low-cost, low-power devices that offer fairly good resolution. Typically, they return the instantaneous sun-vector direction relative to the camera center. This allows us to determine two components of the spacecraft orientation. Determination of the third requires another detector. Highly accurate observations require that the sun sensor have an unobstructed view of the sun. Since they are generally low mass, low cost devices , multiple sensors are often mounted around the spacecraft so that observation data can be returned regardless of the spacecraft orientation. However, prolonged eclipse periods (usually due to the earth) require that some other form of attitude recognition be present.

1.1.6

Comparison of Systems

A comparison of the different attitude determination systems is shown in Table(1.1). This is designed to give a general overview only - The actual accuracy depends on the design of the sensor.

Table 1.1: ADCS Sensor Comparison(Adapted from [Wertz, 1999]) Sensor Gyros & Accelerometers Sun Sensors Star Sensors Horizon Sensors Magnetometers Accuracy High Med. High Med. Low Cost High Low High Med. Low

4

1. 2. Sun Sensor Basics

1.2

Sun Sensor Basics

Since the sun itself is easy to distinguish from other stellar objects, it is a useful tool for determining orientation. Some sun sensors take single angular measurements, others are capable of two. Because the rotations about the observed sun-vector are not observable, some other method is required to achieve full attitude observability[Godard, 2006). Sun sensors themselves are further categorized as analog or digital.

1.2.1

Analog Sun Sensors

Analog sun sensors work by comparing the relative signal obtained by relatively few cells on a two-dimensional matrix. The amount of light intensity received by the cells will be proportional to the off-boresight angle of the sun. Digital sensors use a larger number of photosensitive cells in conjunction with a patterned mask to generate a large amount of intensity data. Because the pattern formed by the mask is known, image processing techniques can be used to extract useful information from the raw image.

1.2.2

Digital Sun Sensors

All digital sun sensors utilize the same basic operational principles. Incoming light from the sun strikes a sensor mask, which will permit some desired light pattern through. The mask may be inscribed with slits or holes, depending on which form of light is most useful for the sensor type. The light that passes through the mask will then fall on a detector, and will be converted to an electrical signal. This constitutes the raw image data. attitude reading. Whereas analog sensors use a small number of photosensitive elements, each individually responding to the light from a large portion of the fieldof-view, digital sun sensors utilize an array of pixels, each responsible for a
5

Processing

algorithms will then be employed which will translate this signal into an

1. INTRODUCTION

very small portion of the field of view. As the incoming lights falls across a number of these pixels, the overall shape of the intensity data can be very well represented when discretized across a larger number of elements. Further, the smaller size of these pixels allows for better seperation between light from the sun and stray light that falls across the entire array. Because a larger amount of intensity data are returned, digital sensors generally require more data space and more processing than their analog counterparts. The image processing is generally comprised of two steps. First, the raw image data are distilled into a small number of important parameters. These parameters, used with the sensor and mounting geometry, are then used to determine the originating sun vector that caused the image. The mathematics required in the latter step are well understood, given some defined geometric sensor model. Improving the algorithms that process the raw data and better identification of the sensor calibration parameters comprise a much more interesting problem.

1.2.3

Digital Sun Sensor Improvement

Digital sun sensors utilize a large number of small pixel elements to give intensity data. Although resolution of the original signal is fairly high, extremely accurate identification of parameters that identify the original signal is desired. Processing algorithms are often susceptible to image noise and calibration errors. A number of different algorithms are available that can process the raw image data. These differ in accuracy, both in common image cases and in which 'special cases' the accuracy may be reduced or the algorithm may fail entirely. Further, depending on the complexity of the algorithm used, the amount of time needed by hardware to process the image may vary. Reducing calibration errors requires a very detailed understanding of the sensor geometry. Further, the errors that can be introduced from sensor mounting must also be accounted for.
6

The calibration procedure is only

1.3. Work Objectives effective when all contributors are identified and correctly represented mathematically. Better representation of the sensor calibration parameters can then improve overall performance when the sensor is in use.

1.3

Work Objectives

The primary objective of this thesis is to derive methods that allow a better understanding of digital sun sensor behaviour. New methods will be presented that will better represent the underlying sensor behaviour. Further, a new way of using the sensor data will be explored that may result in more accurate observations. The thesis will focus on the following objectives: 1. Modelling the behaviour of digital sun sensors. Correct identification of device behaviour yields insights into the limitations of the digital sun sensors, and provides tools which can be used to simulate device behaviour in the future. 2. Identifying important calibration parameters. This involves both identification of the parameters which may lead to calibration error and correctly modelling the parameter. 3. Improving sun sensor calibration. Continuous evaluation of calibration procedures and strategies that incorporates new parameters and sensor models can lead to better performance. Here, the objective is not to define the underlying physics that cause a given image, but instead will rely on empirical models to describe how the sensor will be expected to behave, namely, data sets taken using the sensor will provide the insights into the sensor behaviour. This paper will explore modelling and simulation of the SS-256 and SS-411 class sensors from Sinclair Interplanetary. By improving and implementing calibration parameters, we hope to improve sensor performance. Modelling

7

1. INTRODUCTION the sensor behaviour yields insights into limitations of the sensor, and also gives some benchmarks that can be used to test against in the future.

1.3.1

Thesis Outline

Background information that leads to the investigations mentioned will be presented in Chapter 2. This will include a description of the sensors used in the investigation, as well as a survey of the algorithms used to translate image data into observation results. Changes to the way the peaks are modelled , namely, a new representation of peak width, will be discussed in Chapter 3. A method for defining how well a sensor performs is derived and implemented in Chapter 4. A new method of taking sensor observations is described in Chapter 5. This method will be conducted using both an arbitrary sensor for which specific error data are unknown and a sensor for which error data are intimately known. Finally, Chapter 6 will conclude the research and provide some direction for further research on the topic.

8

Chapter 2 Background
Most of the previous work regarding sun sensors involves two important tasks. First, there is a desire to improve accuracy in the information derived from a sensor image. Second, more accurate calibration is desired so that the physical properties of the sun-sensor can be accurately described. Inaccuracies in either of these areas can contribute to error when the sun-sensor is in use. In order to fully understand the previous work done in these areas, one must first define how the sun-sensor interprets the incoming sun image and how this information is displayed. Then, methods that translate that sensor data into a sun-vector must be explored. Once these basics are known, different methods of varying accuracy will be explored that allow us to find the underlying image data, and different ways of representing sensor unknowns will be presented.

2.1

Sun Sensor Optics

The mathematical models presented here are designed using the physical parameters from the Sinclair Interplanetary SS-256 and SS-411 digital sun sensors. This is a two-axis digital sun sensor that has a 70-degree arc field-ofview. The sensor mask contains two pairs of orthogonal slits. The detector
9

2. BACKGROUND array is a 16 mm-long linear array of 256 pixels, oriented at approximately 45-degrees to the slits in the mask. In order to calculate the incoming sun vector from the displayed image, the position of the image array on the image plane needs to be accurately described. Fig. (2.2) describes the image plane geometry. The sensor works by restricting the incoming light that is able to hit the image array via the slits. Because only the light that passes through the slits reaches the array plane, there will be four strips of light that reach the image plane. Where these intersect with the array itself, they will be resolved into 'peaks' of light. A graphical representation of the mask and image plane is shown in Fig. (2.1). An ideal representation of the image array is shown in Fig. (2.2) , however the actual image array is subdivided into two 128-pixellength arrays, placed lengthwise beside each other. These two arrays have a small gap between them, and the individual pixels near the gap are slightly warped. Fig.(2.3) shows the two arrays side by side, with the slight pixel warping that occurs near the gap. Once peak locations are known , ray tracing can be used to calculate the incident sun vector. This is done using the internal geometry of the sensor, including the relative offset between the array plane and sensor mask , as well as the index of refraction. The originating sun-vector with respect to the platform frame [Enright, 2008] 80 , and the sun-vector with respect to the sensor frame,

s are

related through the sensor parameters. Given the

definition of the incident sun-vector

so= [ :::: ]
So ,z

(2.1)

The components of

s are found individually via:
10

2.1. Sun Sensor Optics

Figure 2.1: Geometric Model of Sensor Showing Aperature and Image Planes.[Enright, 2008]

Sx sy

1 =- (sox cos ¢ + soy sin ¢) ngla s s ' ' 1 - ( - s 0 x sin ¢ + so y cos ¢) =nglass ' ' s = - y'l - s 2 - s 2 y
Z X

(2.2)

Here, the angle ¢corresponds to a right-handed rotation about the positive z-axis between the sensor and mounting platform. Now given the distance between slits of 2Dx and 2Dy for the x- and yaxis slits, respectively, and the distance h between the mask and the center of the image plane, the position of the peaks along the array can be derived
11

2. BACKGROUND

X

z

Px
, ,, ,, ,

,,

,,

,

Figure 2.2: Geometric Model of the Image Plane.

Figure 2.3: Image of the Central Array Gap.[Enright, 2008]

12

2.2. Identifying the Image Characteristics as (Enright, 2008]:

_ m xl -

1
1)

1 , cos If/

,

[-

(sxh+szD x) _ Px ] ,mx2 _
sz

1
,

[-

cos ~

(sxh- S zD x) _ Px ]
sz

(2.3)

m

1 [-(sxh+szDy)-p] ,m2 .1 [-(sxh-szDy)-p] y =r_ sin ~ S z y y = r Sin ~ S z y
1

(2.4) Although this does relate the sun vector and the peak position on the image array, typical sun sensor operation requires that the inverse of these relationships must be computed. This can be done by writing the temporary quantities (Enright , 2008]:

(2.5)

Em=

[L'lTsin'lj; (my! ;my

2

)

+ Pv]

(2.6)

When these are expanded using the definitions in Eq(2.3) and Eq(2.4), the following relation can be found:

S z= The other two components of

(2.7)

s are then:
(2.8)

Am Sx = -hSz

(2.9)
13

2. BACKGROUND

2.2

Identifying the Image Characteristics

Light incident on the pixel array varies in a spatially continuous pattern across the detector. Peaks resulting from direct light through the mask slits are expected to correspond to the high-intensity values on the array, and other areas on the array should receive very little light. However, there will likely be some noise from stray light, noise from internal reflection , and noise from the array itself, all contributing to some variation in the recognized intensity. Because the mask has four slits creating bands of light on the image plane, the expectation is that there will be either three or four seperate peaks that will manifest on the image array. Three peaks will show if there is a lightband overlap that occurs on the image array, otherwise there will be four peaks. An example of these two cases is shown in Fig.(2.4) On the return of image data, the locations of these peaks are found on the image array. At this point, only the locations of these peaks are known , but not which mask slit as contributed to which peak. The peaks as seen on the image array in absence of this extra information are called physical peaks. After the peaks on the image have been found , they need to be matched with an originating slit in the mask. The slits themselves produce logical peaks based on the sun-vector direction. By mapping the logical peaks onto the physical peaks, the calculations in Eq(2.5) and Eq(2.6) can be performed.
It is not enough simply to find the maximum values across the array as

this results in very low accuracy. We would like to find the peak locations to subpixel accuracy. However, because the image peaks are sharply defined , simple methods can be adopted which will allow for mapping between the physical and logical peaks. Many of the subpixel techniques that will be described require that a successful map between peaks has already been done. In order to detect maxima in the image array, a 5-pixel window is used and slides across the array. Here, the central pixel is compared to the two on

14

2.2. Identifying the Image Characteristics

0.9
0 .8

~ -- 4-peak lmag~ ~- - - 3-peak Image

0.7

.!::!

g E al
<ii
0

·;:;;

.2:-

0.6
0.5

I I I I I

E o.4
0.3

z
0.2 0.1 0

·: ,,
I

,.,: ,.,,

,.

,,

,,~ ,, ,,

I
~

\

'· '·
....

'·

'· '·

../
0
50

v ~ ~

It II I

_, .... 250
300

II II

'·

100

150 200 Array Position (pixel)

Figure 2.4: Four-Peak versus Three-Peak Image. either side to see if it is a local maximum. The following relation will define where the peak maxima are:

I[n] > I[n- 2], I[n- 1], I[n + 1], I[n + 2]
Doing this creates a set of physical peaks located at points
ni

(2.10)

along the

image array. At this point , these should be associated with contributions of particular slits in the mask - the logical peaks. The physical peak locations found thus far can be stored in a vector P:
(2.11)

In most cases, P is of length 4, since most sun-vectors result in a 4-peak image. In the overlap case, P will be of length 3, and one of those three detected peaks will correspond to two logical peaks. The expected spacing resulting from corresponding slit pairs, 2Lx and

2Ly, can be pre-calculated from the sensor geometry. Recalling that the
light-bands from the x- and y-axis slits will be perpendicular to those axes

15

2. BACKGROUND as shown in Fig.(2.2), the peak seperation as seen by the image array can be calculated by accounting for the angle

1/J:
Dx
(2.12)

Lx = -

~T

(mx2- mxl) = -:;, 2 cos '+"

Ly = -

~T

2

(my 2

-

my 1 )

=----:;:
cos'+"

Dy

(2.13)

An error term can now be defined, <I>, which will describe the error in matching logical peaks to the physical peaks detected on the array. This can be described mathematically as:

(2.14) By rearranging the peak locations in P and substituting into the relation for <I> , errors can be obtained for the assumed peak matching. The arrangement of peak locations m that minimize the error <I> will correspond to the correct peak matching. Although this will yield the logical peak location to the nearest pixel, there is a strong desire to improve this to sub-pixel accuracy. There are a number of algorithms that can accomplish this to varying degrees of success.

2.3

Super-Resolution
These techniques offer a way of taking

Super-resolution techniques are commonly used when attempting to yield information from digital sensors. the raw image data received and obtaining subpixel estimates. For the sunsensor example, subpixel techniques give the ability to detect the position of the maximum of each peak shape to subpixel accuracy. These techniques are extremely important in pulling accurate attitude data from digital sensors.
16

2.3. Super-Resolution

2.3.1

First-Order Centroiding

First order centroiding is a common method of finding the subpixel point location of an extended light source. This method is used extensively with star-trackers, where a point source of light is deliberately defocussed such that the light gives a 2-d peak shape when it reaches the image plane. The methods behind this technique are described by Liebe[Liebe, 2002] and Rufino[Rufino and Accardo, 2003]. Given a matrix of intensities I( x, y) , a function of the location (x, y) on the image array, the centroid can by performing the following operations:

L:L: xi(x, y)
X

y
X

Xcm=

LLJ(x y)
y

(2.15)

LLYI(x, y)
X

y
X

Y cm=

LLI(x y)
y

(2.16)

Typically, the summations are bounded by a region of interest (ROI) that contains all of the image data[Rufino and Accardo, 2003]. Because this method does not consider the originating image shape or require any additional input beyond the image itself, it can be performed with no previous knowledge of the illumination pattern.

2.3.2

Non-Linear Least Squares

The non-linear least squares (NLSQ) method involves fitting the image data to a parameterized model of expected illumination. In this case, the peak location is the parameter that is of most interest. The NLSQ model will be modified from a Gaussian distribution model of the peak shape [Enright, 2008]. This simplified model will reflect the shape of the peaks as seen in the image. Given a parameterized equation
17
Imdl

that

2. BACKGROUND can aprroximate the shape of one of the peaks, we will build a method by which to describe the whole image. First define the individual peak shape via the equation
(2.17)

In this equation,
T

T

is a coordinate which maximizes the value of

Imdlo

at

= 0. The value of a 2 is closely tied to the width of the peak and will be
Because four peaks are expected across the image array, the illumination

determined outside the error minimization. pattern will be defined as follows:
(2.18)

We will offset the model equation

Imdlo

to match the positions of the

peaks on the image array. This will result in the following definitions:

A= lmdlo(T- m xl) B = 1mdlo ( T - m x1 - ¥:T)

c = Imdlo(T- myl)
D =
Imdlo(T-

(2.19)

myl-

¥f)

The value of

'1fT

is a measure of the distance between slits on the sensor

mask. We expect this to be equal to the distance between the peaks that those slits create on the image array. We only have six parameters that must be fit to the image. Arranged in a vector, these are (2.20) The scaling parameters a 1 through a4 describe the amplitude of the peaks in the image. The parameters mx 1 and my 1 describe the position of the peaks along the image array. The latter are of most interest to us, however we must solve for the former parameters as well.
18

2.3. Super-Resolution In order to find the vector -X, the error between the actual and modelled image must first be found via:

Taking the partial derivatives of the image model with respect to the model parameters yields the following[Enright, 2008]:

H>..=

(2.22)

The elements of H>.. are calculated using the corrent value of the model parameters, and the array position T. From the definition of H>.. , the values of Eq(2.19) become evident:

IT = A (T) !2.!.rrull_ I = B (T ) 8 a2 Ol mdl I = C(T) o b1 r !2.!.rrull_ I = D (T ) 0 b2
!2.!.rrull_ 0a 1
7
T

(2.23)

The remaining two terms are [Enright, 2008]:

a I mdz =- [b1 ( -a a Imdz(u)lu=r-my 1 ) + b2 ( -a a Imdz(u)l _ _ -~ ) -a-Ir ffiyl U U ffiyl flT
U-T

J = b1G(T)+b2H(T)
(2.25)

This simplifies the definition of H>.., which can now be simply written as:
19

2. BACKGROUND

(2.26)
For each iteration, the parameter update step d).. can be shown as[Enright ,

2008):
(2.27)

2.3.3

Linear-Phase

One method of estimating the peak positions involves using phase-correlation. Given a discrete image I 0 [n], it 's frequency domain representation can be obtained by performing a discrete Fourier transform (DFT)[Godard and Enright , 2006):

I[n] DJ;T S[k]

(2.28)

Also used is a D FT property regarding space-domain shifts and their representation in the frequency domain[Mitra, 2006):

(2.29)
Here, the illumination pattern has been shifted by a samples, which is equivalent in the frequency domain to multiplication by a linear-phase term [Enright, 2008). By defining a reference DFT S0 [n] corresponding to a known zero-shift image, it is possible to isolate the exponantial term. Given the DFT of an actual shifted image Sa[n], this extraction can be done through the relation[Godard and Enright, 2006)

w[k] = L (Sa[n]) = L So[n]

(e-i27Ja) = _ 2nka
N

(2.30)

A least-squares fine line of w[k] gives us an estimate of the slope term,
20

a.

2.4. Algorithm Testing and Sensor Calibration This is related to the peak position estimate

m via
(2.31)

In order to perform the linear-phase algorithm, the contributions from the x and y slits need to be seperated, since the shift of each pair will be found seperately using their own reference images, i.e., the image will be considered as a superposition of two sub-images from each peak pair.

I[n]

=

Ix[n] + Iy[n] + Inoise[n]

(2.32)

Here, Ix and Iy are the contributions from the pairs of slits, and will be used to find the shifts via linear-phase. In is the image noise. Further, note that Ix and Iy are shifted reference images. They can be described as:

(2.33)

(2.34)

Given an image, the linear-phase algorithm decomposes the image down into two seperate sub-images corresponding to contributions by both the x- and y-axis sets of peaks(Foroosh, 2002). It does this by estimating the positions of individual peaks on the image array. Because the seperation between each peak pair is known, the image can be decomposed into the two sub-images by considering the approximate locations. Some difficulty arises when there is a superposition of peaks. In this instance, the overlapping peak location is considered belonging to both subsets of images. However, we then use the other non-overlapping peaks to perform the linear-phase algorithm.

21

2. BACKGROUND

2.4

Algorithm Testing and Sensor Calibration

At this point, we need to develop a number of procedures that both test the accuracy of the NLSQ and linear-phase algorithms, as well as calibrates the sun-sensor. A laboratory setup must be devised that simulates the exposure of the sensor to sunlight. Also, a method of finding the calibration parameters using the actual data needs to be found. This yields a method of both verifying the ability of developed algorithms to accurately predict the sun position and creating a repository of images that can be used to test different hybrids and modifications to see if performance can be improved.

2.4.1

Calibration Approach

A calibration approach was developed that enables us to continually update our sensor parameterization and improve our sensor performance. Our approach is comprised of five steps: 1. Examine sensor operation. 2. Develop sensor behaviour models based on parameters regarding sensor or lab setup. 3. Calibrate the parameters based on a suite of test images and associated truth model. Allow parameters to fluctuate as we minimize error between estimates and truth. 4. Examine residual error for structure. Systematic error (any non-white noise error) is suggestive of unmodelled or poorly modelled system behaviour. 5. Repeat. These steps are performed until an acceptable performance level has been reached. 22

2.4. Algorithm Testing and Sensor Calibration

2.4.2

The Sun Sensor Test Setup

A laboratory setup has been devised that can test for sensor accuracy. The sun-sensor itself is mounted onto a three-axis rotary platform. The rotary platform is computer-controlled and can be instructed to move to different angular positions on all three axes in 0.001-degree increments. Mounting offsets can be handled through a calibration procedure, which simplifies the mounting process. The sun is simulated with a xenon arc-lamp. The projected light is constrained via an adjustable iris, which is adjusted such that the lamp appears to have the same angular diameter as the sun. Fig.(2.5) depicts the setup currently used for testing.

2.4.3

Calibration Image Sets

Although physical dimensions for the sun-sensor are often given by the manufacturer, there is an element of uncertainty associated with the actual sensor - often due to manufacturing errors and limitations. Uncertainty in physical parameters can have large error effects in identifying the true orientation of the spacecraft [Enright, 2007). Thus, we would like to measure these parameters accurately so that, when confronted with an image, we can minimize the error contribution due to incorrect parameterization. In order to perform the calibration, we need to all of the parameters we would like to investigate. We then capture a number of images corresponding to various positions in the field-of-view (FOV) of the sensor. Since we define the relative position of the sensor with respect to the incoming sunlight, we know what the true sun vector should be. We compare this to the sun vectors as determined by the inverse sensor model to find the difference, or error, between the two. A set of test images must be generated in order to perform the calibration. In most cases, approximately 400 points throughout the FOV were used for
23

2. BACKGROUND

Rotary Platform

Figure 2.5: Experimental Setup.

calibration, although in some cases 800 points were used. An algorithm was developed so that the desired number of points would be distributed amongst a number of user-defined annuli, such that the sampling across the field of view was relatively even. To do this, consider the total area subtended by the sensor FOV (in
24

2.4. Algorithm Testing and Sensor Calibration steradians). This can be calculated from
f2tot

= 27r (1 -

COS (max)

(2.35)

Here, the value of

(max

is the maximum offset of the image set from the

boresight - usually the FOV limit of 70-degrees. We then divide the total area into m annuli, the value of which is defined by the user. The outer annulus lies at
(max

and an additional sample is taken at ( = 0. Given that

the user has defined m desired annuli, the algorithm subdivided the fieldof-view into a number of circular 'ribbons' with the width of those ribbons remaining constant. Mathematically, the following relation was satisfied:
1

2 ((out er -

(inn er)

+m

((out er -

(inner)

=

(max

(2.36)

Rewritten so that the ribbon width can be explicitly found, this becomes
(max

1 ( outer - '-,inner =

l
2

+m

(2.37)

Because the field of view contains M distributed points, each individual ribbon contains a percentage of those points defined by the ratio of its area to the total area covered by the image set. Given that each ribbon covers an area

ni'

then

ni =

27r (cos (i ,inner

-

cos (i ,outer)

(2.38)

Each individual annulus contains a percentage of the total defined points equivalent to the percentage of the total area occupied by the annulus , i.e.,
_ Oi M
--

Mi

-

tot -

f2tot

_ cos (i ,inner - cos (i ,outer M tot 1 -COS (max

(2.39)

25

2. BACKGROUND

2.4.4

Calibration Procedure

In order to calibrate the sensor parameters so that they are an accurate represention of the physical sensor, we use a minimization routine with regards to the error between the two sets of sun vectors. For each true sun-vector and it's corresponding estimate, we calculate the angle B errbetween the two vectors via:

rr B e
error as follows:

=arccos

Strue · Sest ) ( iistruellil sestll

(2.40)

Given an initial guess of the vector of parameters, we define the overall

Yerr

=

L IBerrl

(2.41)

We then use a Matlab built-in minimization routine to find the minimum value of this error, and return those parameters which generate this minimum value. From the previous parameter definitions regarding the sensor geometry, there are seven parameters which need to be found through calibration. Combined with several others that are fixed, the sensor physical geometry can be adequately described using the values depicted in Table(2.1). There are also a number of parameters which describe the mounting of the sensor to the rotary platform, and describe offsets in the interaction between the xenon lamp sun-simulator and the zero-position of the mounted sensor. Unlike the sensor-physical parameters, the mounting parameters need to be recalculated every time the sensor is re-mounted to the platform. The mounting offset that results can be described using the following equation[Enright, 2008): (2.42)
26

2.4. Algorithm Testing and Sensor Calibration

Table 2.1: Physical Sensor Paramaterization Parameter
¢
1/J

Description Array-Mask Offset Image Array Angle Pixel-0 x-location Pixel-0 y-location Array-Mask Dist. Half-Slit width in x Half-slit width in y Mask Refraction Pixel Width (aka ~T)

Unit radian radian metre metre metre metre metre n/ a metre

Type Calibration Calibration Calibration Calibration Calibration Fixed Fixed Fixed Fixed

Assumed Value 0 7r/4 -5.7 X 10- 3 -5.7 X 10- 3 4.0 X 10- 3 7.5 x 10- 4 2.5 X 10- 4 1.51 63.5 X 10- 6

Px Py h Dx Dy
nglass

'

Here, 77 1 and 772 describe the angular offset (or tip / tilt offset) of the sensor boresight mounting with respect to normal.

r1 is a vector from

the centre-

of-rotation of the rotary platform to the sun (the xenon sun-lamp).

r2

is

a vector from the centre-of-rotation of the rotary platform the the sensor origin. K itself is a transformation matrix based on the sensor platform rotation kinematics. Because the sun-vector is normalized as 80 , the scale of Eq(2.42) can be ignored, simplifying the calibration process. Here, r 1 ,x 1s fixed at unity and the other values are calibrated around this.

27

2. BACKGROUND

28

Chapter 3 Peak Width Correction
An integral part of being able to identify the sun vector is to be able to predict the width of the peaks as they appear on the array. This is important when predicting the overall shape of a logical peak, when comparison with a physical peak is required. Previously, during the implementation of the NLSQ algorithm, the peak width of all logical peaks was assumed constant, irrespective of the array position of those peaks. In order to investigate how peak width varies across the image array, a method of collecting peak width data was required , and a method of prediction was needed based on array position. As the investigation was conducted, a clear correlation between peak width and array position was found.

3.1
3.1.1

Peak Shape Theory and Data Collection
Theory Development

Describing the peak shape requires that an equation be derived that can be used as a model. A Gaussian model was used to fit to the image peaks, similar to the implementation used in the NLSQ algorithm. Here, the mathematical model used will be:
29

3. PEAK WIDTH CORRECTION

(3.1) In the above equation, A is a scaling factor that will represent the amplitude of the peak;

k

is the central value of the peak-shape; the value of

a-

represents the peak width. In this equation, all of these parameters are

unknown. In the local sense, all of these parameters will need to be found for each individual peak. The parameter set will then be rendered as:
P

= {a-, k, A}

(3.2)

To do this, an error between the image as modelled by the parameter set and the true image is defined. This error is written as:
E =

L (I [k] - Imdl [k]) L
2

=

(

I[k] - Ae -~

(k - k)2)

(3.3)

k

k

Values of the parameter set P are then chosen such that this error is minimized.

3.1.2

Width Data Collection

To examine how the width of the image peaks varies across the image array, a calibration image was taken. For each of these images, the physical peaks were associated with slits in the mask , so that the peak width variation could be associated directly with the peaks cast by each slit. Overlapping peaks were removed from the set to improve fitting accuracy. For each non-overlapping peak, an individual curve based on the Gaussian shape was fitted to the image data. An example of this fit done to the curve in Fig.(??) is shown in Fig. (3.1). When the values of

k and a- were compared

from the fit of the model in Eq(3.1), trends emerged in the data. For each of the images in the calibration set, the location and peak width
30

3.2. Relating Peak Width to Array Position

I

I

I

0.9 0.8 0.7
'(j)

A
~
1

- Image Data I - - Fitted Curve

I I

~

.f:
Q.)

Q.) .....

c

0.6 f0.5 0.4
0.3
f-

-

"0

m
E .....
0

.!::::!

z

0.2 0.1

o- -- - -- -150 155 160

I

-- --r-- --

165

170

175

180

185

Array Position (pixel)

Figure 3.1: Image Peak with Curve Fit.

was found for each logical peak. When the peak width was plotted against the location, the size of the peak width term seemed to follow an even function. An example of this behaviour can be seen in the raw data from a sigle logical peak in Fig.(3.2). This indicated that better performance may be acquired by allowing the algorithm to vary the peak shape in accordance with this data. For each sensor then, a curve fit was which described peak width as a as found. function of array location wc
31

3. PEAK WIDTH CORRECTION

1.8 1.7 1.6 1.5 1.4
Q)
X

~

,
:·

·. '"'

...... .
;~.

:§,
0

x

1.3 1.2 1.1

·.. " .·... . .
I · ·

. ..

. .... .. . ··=·
· I

...

: .. ::!·

0.9

0.8 ...___ 40

____,____ 60

__.__ _...___ __.___ __.__ _..____ 100 120 140 160 80 mx 1 (pixel}

___.___ 180

___, 200

Figure 3.2: Fitted Peak Width by Array Position.

3.2
3.2.1

Relating Peak Width to Array Position
Fit Equation Development

Given that the array position has a clear effect on the peak width, a method of describing how these two quantities relate was needed. In this case, a theoretical development of this relationship was not desired, and instead empirical techniques were employed. From trial and error, it was found that an even, fourth-order polynomial was closest to the true behaviour of the peak widths with respect to the array position. It was decided that the trend would be described via the equation:

CJ fit

=A (x- xa) + B (x- x 0 ) + C

4

2

(3.4)

Here, x describes the array position, x 0 is the position of the minimum value of the curve, and A through C are scaling constants to be fitted. After
32

3.2. Relating Peak Width to Array Position doing peak fits for individual peaks in all the images in the set and all peak widths cast by a single logical peak were compared to the array position, a fit was done so that the peak width could later be predicted based on the array position. To do the minimization, the parameter set was defined as the scaling constants and the minimum value position, i.e. , the parameter set was

P ={A, B, C, x 0 }

(3.5)

To perform the minimization, an error function needed to be defined between the actual peak width data and the function that is needed to describe it. Again, a squared-error approach was used, entailing the following error function:

E

=

L (afiti i

atrueJ =

2

L {[A (xi i

xo)

4

+ B (xi - xo) 2 + c]- atruei }
(3.6)

This error function was minimized to find the parameter set P. This curve fit was performed twice - one for each of the x- and y-axis pairs of peaks. We will treat the corresponding second slit of a logical pair as a constant shift from the first, as was done in Eq(2.19). Mathematically, the following relation is expected:

atheo,x1 (k, ko) = atheo,x2 (k, ko + 2Lx)

(3.7)

atheo,y1 (k, ko) = atheo,x2 (k, ko + 2Lx)

(3.8)

Since we only need to perform two curve fits, only two sets of parameters for two of the logical peaks need to be passed to future algorithms.
33

3. PEAK WIDTH CORRECTION

1.8 1.7 1.6 1.5 1.4
Q)

·.

:§: 1.3
t:)

><

x
1.2 1.1

;.. __ .

0.9

. . . .. .. .. . . ... ·····.. .. . . .·.·· . -: ·. . . . . . . . : :. -~::.*( ..
___.L_ _ _ . _ _ _ _ - - - - ' - - - - - - - - - - - - ' - - - - - ' - - - - - '

0.8 c________--'--_ 40 60

_ . l __

80

100

120

140

160

180

200

mx 1 (pixel}

Figure 3.3: Peak Width by Array Position with Curve Fit.

3.2.2

Curve Fit Results

Given the image data, values of peak width as well as the peak position was found. An example of this was shown previously in Fig.(3.2). Given the example peak width set in Fig.(3.2), a curve was fitted to the data. The results for each parameter are summarized in Table(3.1). Plotting the curve in Eq3.4 with these values yields Fig.(3.3).

Table 3.1: Fourth-Order Curve Fit Parameters Parameter Value

A

c
x0

B

1.30 X 10- 8 7.24 X 10- 5 0.974 120.42

34

3.3. Calibration Revision

3.3

Calibration Revision

A number of revisions were made to the calibration parameters presented in Table(2.1). During the width correction work, many revisions were made to the initial parameter set. These changes will be outlined here.

3.3.1

Index of Refraction
This was converted to part of the calibration parameter set

In the initial parameter set, the index of refraction of the mask was assumed to be 1.51. because it is crucial in relating peak position to incident sun-vectors.
If the index of refraction is incorrect, the change in direction of the inci-

dent light passing through the mask will be incorrectly calculated in Eq(2.2). This can be a significant error when we are attempting to convert peak positions on the image array to incident sun vectors.

3.3.2

Longitudinal Gap

The initial parameter set treats the array as a contiguous line of 256 pixels. The array itself is actually comprised of two linear arrays of 128 pixels placed end-to-end, and contains a small gap in between the two. This was shown previously in Fig.(2.3). The calibration set was updated to include a longitudinal gap term. This parameter defines the distance between the two linear arrays, and is taken in line with the two linear arrays, as shown in Fig.(3.4). The presence of a longitudinal gap needs to be accounted for when converting to a measured distance along the array. Given Gas the longitudinal gap length, we update our calculations as follows: m < 127

(3.9)

m > 127

3. PEAK WIDTH CORRECTION A longitudinal gap has effects on pairs of peaks that straddle the gap. We assume that the distance between two peaks is fixed, as shown in Eq(2.19). If a peak pair straddles the gap, we must add G to the distance between those peaks.

3.3.3

Transverse Gap

The transverse gap accounts for the distance between the two linear arrays that is perpendicular to the line of the arrays. The definition of the longitudinal gap is also shown in Fig.(3.4). This has a similar effect on peak positions as the longitudinal gap. When converting to measured distances along the array, we account for the tranverse gap as follows:
m{,
T=

m < 127 m > 128

{ mr+f(G, Gr)

(3.10)

Longitudinal Gap

128-pixellinear array Transverse Gap

j

~----128-p -ixel-lin_e_ ar_ ar_ ra_ y ----~~ -

Figure 3.4: Definition of Longitudinal and Transverse Gaps.

3.4

Effects on Algorithm Performance

Because there is now some accounting for the chages in peak width across the array, it is expected that the results should improve where that quantity
36

3.4. Effects on Algorithm Performance is required, namely, in the NLSQ implementation. From before, the base image model is defined using the peak width in Eq(3.11), i.e., the equation (3.11) When a variable value of CJ is used instead of a static value, it is expected that the overall error should decrease. Given a static value of
CJ,

the sun vector estimates are compared to the

true sun vectors across the field of view. A plot of calibration error across the field-of-view is shown in Fig.(3.5). Here, the error grows as the sun-vector moves towards the outer edge of the field-of-view. Of particular note is a region of extremely high error on the upper right side of the field of view.

4.5 4 3.5

3
2.5 2
1.5

0.5
0

Figure 3.5: FOV Error Plot with No Width Correction (in Radians). Conversely, a FOV error plot after width correction is shown in Fig.(3.6). When peak width correction is used, the error on the upper-right side of the field-of-view is much better resolved. There is also less differentiation in the 37

3. PEAK WIDTH CORRECTION

~

~

4.5 4

/

/

I

I

I I

3.5

Figure 3.6: FOV Error Plot with Width Correction (in Radians).

error profile going from the central region towards the outside. Overall, the algorithm is more consistent in it's ability to compute the sun-vector. Integrating the changes that have been made to the calibration parameterization , we can see the evolution of the calibration error as the parameterization has changed. To illustrate the effects of the changes to calibration, a single calibration image set was used. This image set was used to calibrate an SS-411 sensor using progressively better calibration parameterizations. The effects of these changes to calibration are summarized in Table(3.2). As the index of refraction and the gap parameterizations are added, there is a clear improvement in the mean error across the calibration set. The most notable improvement occurs when attention is given to the gap between the two parts of the linear array. Here , the error decreases by 35%. With the addition of the quartic width fit, the error drops by a small amount - 2.5% - compared to the same calibration routine using a constant value for a.

38

3.5. Summary

Table 3.2: Calibration Summary Params Base Refraction Long. Gap
X X X X X X X X X X

Trans. Gap
X X X X X X X X X X X

Width Fit
X X X X X X X X X X X

Px Py ¢ 7/J h

X X X X X X X X

X X X X X X X X X

r1
f2
tip / tilt
nglass

1.51

G Gr
(J

1.15 20.22

1.15 20.21

1.15 1.304

1.15 1.293

Quartic Fit 1.260

Mean Err. (mrad)

3.5

Summary

A method of relating the width of image peaks to the position of those peaks along the array was given. When this data was plotted, a trend in the data was seen. A fourth-order function was fitted to this data using least-squares error minimization techniques. Using this function with the NLSQ algorithm gave a slightly more consistent error performance. The mean error of the NLSQ calibration using width data was compared to the same calibration with a constant width. There was a drop in mean error in radians of 2.5% when the width correction was included. This indicates that using the width correction step can lead to improved sensor performance.

39

3. PEAK WIDTH CORRECTION

40

Chapter 4 Precision Testing
Given a single sun-vector estimate, the error can be described as coming from two different sources. One source is an image-to-image error, due to limits in the sensor optics. We expect the image-to-image error to be a zero-mean random error. The other is error source is a bias term. Much of this term is due to sensor modelling inaccuracies. The purpose of the precision test is twofold. First, we would like to define the minimum angular motion that must take place before any motion can be recognized. The second goal of this section is to define some metric that describes how well the sensor registers relative motion between two points. When these points are close, much of the slowly-varying spatial bias should be eliminated. Precision test results will be based on the repeatability of the sensor images. This means precision test data is specific to individual sensors susceptibility to outside noise and dark-current noise vary from sensor to sensor, and these factors have a role in the precision test outcome. One error contributor that is particular to the test setup is errors in the motion of the test platform. Because the positioning of the test platform at a given point is also subject to error, this will have an effect on the precision data as well. A number of steps are involved in performing the precision test. The first step in performing the precision test will be to compare a set of defined true
41

4. PRECISION TESTING
sun vectors to a set of estimates in order to find a bias error around a point of interest. By shifting the estimates by this amount, much of the slowlyvarying spatial bias can be seperated out of the error term. This will ensure that, for the remainder of the precision test, the estimation error will be due to sensor noise, algorithm limitations, and high-frequency bias variations. Further, it better allows for the assumption that the expected estimate is equivalent to the true value for sun-vectors where this correction has taken place.
It is expected that a number of images, when taken at a single point ,

will have some differences due to a number of noise sources. When these images are processed and translated into a sun vector, these estimates will differ by some small amount. By accounting for the bias error, the amount of estimation error caused by the random noise alone can be isolated. This will define the limits at which the sensor can resolve motion - and yields a method to find this limit. The precision test also gives a sense of how well the the sensor can track small motions. Both the overall mean error and the relative error are of interest here. While the mean error will give a sense of how well the sensor performs in the absolute sense, the relative error tells how well the sensor tracks the true motion of the sensor, i.e., the smaller the relative error, the better the actual motion of the sensor is tracked.

4.1

Motion Limit

One thing that can limit the ability of the sun sensor to differentiate between two near points is the sensitivity of the detector to motion. Given the same target point, the sensor can return multiple slightly different images. This is due to small limits in the rotation platform, which exists only in the test situation, and slight varying ambient light conditions plus dark-current noise, which can exist in practice. Thus, even with perfect algorithms, a range
42

4.1. Motion Limit of sun vectors would be returned due to uncertainty in the measurement. Detectability of motion implies that a returned estimate offset is due to actual sensor motion, versus an offset caused by internal sensor noise.

4.1.1

Motion Limit Theory

In order to perform the motion limit test, a number of data sets must be gathered so that comparison can be done between the zero-motion set - a set of estimates taken with the same zero-shift true sun vector for all - versus a set where the sun vector has been shifted by some amount. The comparison is done using a 1-sided mean comparison test. To do this, we consider offset angle

e as the random variable.

This angle

between a true sun-vector and it's corresponding estimate is found via:
Strue · Sest ) ( llstrue Sest

e = arccos

II

I

(4.1)

The mean of the central-point set is forced to be an offset angle of zero. This allows for the computation of the following parameters for the two sets:
-

2 B0 = 0 · a 0 = ---'---------'-' No -1

L (Bo,i -

Bo)

2

(4.2)
2

- L:Bk,i 2 L:(ek,i -ek) ek = ~; ak = Nk- 1

(4.3)

The null hypothesis will be that the two mean are equal, namely:

Ho:

J.-Lo = /-lk

(4.4)

In order to perform the hypothesis test - which in this case, requires the student-t distribution - the degrees of freedom of the system needs to be found. This can be done using the following relation:
43

4. PRECISION TESTING

(4.5)
The data-weighted t value can be found using the means and variances pertaining to the two data sets by performing the following calculation:

(4.6)

Then, a confidence level is found ,

a, based on
1

the data-weighted t value

and the system degrees of freedom. This is done via the following relation:

a = F (t Iv) =

_ _ jt r (1/! ( v)
- oo

)

f

2

;,;;;;
y V7f

1

1

(1

2 + ~)

!±l
2

dt

(4.7)

Based on a confidence level at which to reject the null hypothesis, a , a comparison between the corresponding critical t value and the data-weighted
t value from Eq( 4.6) can be made. To find the critical value , the following

calculation is performed - essentially the inverse of Eq (4. 7):

tcrit

=

p - l (aiv)

(4.8)

By comparing the two values of t, the null hypothesis can either be confirmed or rejected:

Accept Ho ~ R ej ect Ho ~

t ~ tcrit t > tcrit

(4.9)

If the null hypothesis is rejected , then changes in the estimates can be
attributed to actual motion of the sensor. If accepted , then the estimate offsets are considered to be caused by noise and image artefacts- not due to actual sensor motion.

44

4.2. Calibration Offsets and the Best Rotation Quaternion

4.1.2

Motion Limit Results

Testing for minimum detectable motion requires that multiple data sets be gathered. The first of these is of a number of images taken at the same point. These will return a number of sun-vector estimates centered around a point. The results from this set will be the reference against which all of the others will be compared. Other data sets will be taken in annular rings surrounding the reference point at a small distance. Each of these data sets will be compared to the reference set to determine whether or not the motion can be recognized , statistically, versus variance due to repeatibility error. For each annulus, a confidence level that motion has occurred was calculated. This value indicates the probability that detected motion is due to actual sensor motion instead of random measurement error. We note that the confidence level increases rapidly, approaching 100% at an offset angle of 4 x 10- 3 radians. The motion limit test was run for the data set shown in Fig.(4.3). For the purposes of this test, we use a confidence level of 95%. The values of

a found

for the data sets in increasing order of angular offset are shown in

Fig. (4.1). From the original data set, the first angular offset at which one can be confident that motion has occurred is at 2.62 x 10- 4 radians. For the sensor, this means that when successive estimates are offset by less than this amount, one cannot be sure whether this is a result of actual sensor motion or simply a result of sensor noise.

4.2

Calibration Offsets and the Best Rotation Quaternion

Before precision testing can be performed, attention must be given to errors due to calibration. In order to perform accurate precision testing, the error must be due to repeatibility error alone, and the estimates should not have
45

4. PRECISION TESTING

0.9 0.8 0.7
Q)
_J

~ 0.6

I
0.2 0.4 0.6 0.8 1.2 Angular Offset (radians) 1.4 1.6
X

g
I.;:

Q) Q)

0.5

-c

§ 0.4
()

0.3 0.2 0.1 0

0

1.8 10-3

Figure 4.1: Confidence that Motion has Occurred. a bias associated with the error term. As calibration error introduces a bias term, a method needs to be developed to remove these errors. An example of the difference between the true sun vectors and the estimates is given in Fig.(4.2). From the figure , we notice that the estimate vectors both have a random noise component as well as an overall bias error relative to the true sun-vectors. In order to eliminate the bias in the small test area, a rotation quaternion will be found that maps the estimate field of points to the true sun vectors.

4.2.1

Quaternion Mapping Theory

The best rotation quaternion is used to relate a group of estimates (i.e., those given by the NLSQ or linear-phase algorithms based on actual sensor data) to those that yield a minimum total angular error when compared to the theoretical results. This is used to remove overall bias error in the data.
46

4.2. Calibration Offsets and the Best Rotation Quaternion

0.3568 0.3567 0.3566 0.3565 0.3564

Sun-Vector Estimates True Sun-Vectors

>-

~
0.3563 0.3562 0.3561 0.356 0.3559

~ -------.. ~~~ ~---

..;:_____

-0.3559 -0 .3558 -0.3557 -0.3556 -0 .3555 -0 .3554 -0 .3553 -0.3552
X

Figure 4.2: Difference Between Estimated and True Sun Vectors Before Bias Reduction. The method used to find the desired quaternion is that suggested by Besl and McKay[Besl and McKay, 1992], which finds a quaternion that maps an altered set of data points onto a second set such that the error is minimized in the least-squares sense. The quaternion is defined as a four-element vector if= [ q8 qx qy qz ]T subject to the constraints q8 2:: 0 and q~ + q; + q; + q;
=

1[Hughes, 2004][Horn, 1987].

The two sets of data points under consideration are the set of N measured sun-vectors P = {Pi} = {Sest}, also known as the estimates, and the set of corresponding true sun vectors X= {xi} = {st}· Given some rotation matrix R defined from the above quaternion, a scalar error (or cost) function can be defined by relating the two data sets[Besl and McKay, 1992]:

f(ij)

=

~ L IIXi - RPdl

(4.10)

The centroids of the data sets P and X can be found using a first-moment averaging of the vector elements across the set - namely, through the two relations
-+ J-Lp

=

1 '"""' N L......t Pi

(4.11)

47

4. PRECISION TESTING

--+ 1 "'""' /-LX= N ~Xi

(4.12)

The cross-covariance matrix L:px can then be defined that relates the estimated and true sun vectors. (4.13) The cross-covariance matrix defined in Eq(4.13) allows us to form a corresponding 3x3 anti-symmetric matrix A via:

A= L:px - L:~x

(4.14)

By extracting three elements from the anti-symmetric matrix A, a column vector Ll. =
[

A23 A31 A 12

JT

can be formed.

This column vector, in

conjunction with the skew-symmetric matrix, L:px, allows us to define a 4x4 matrix Q (L:px )[Besl and McKay, 1992]:

(4.15) The desired rotation quaternion is the eigenvector of the matrix Eq( 4.15) which corresponds to the maximum eigenvalue.

4.2.2

Applying the Quaternion

The purpose in finding the best-rotation quaternion is to eliminate any largescale bias errors in the data set. The method shown here is designed to relate two data sets in such a way that the magnitude of the error between them is minimized[Besl and McKay, 1992]. The quaternion itself is decomposed into angular and vector parts as follows:
48

4.2. Calibration Offsets and the Best Rotation Quaternion

Related to this are two useful quantities, the vector relations: ¢ = 2 arccos( q0 )
if sin( ¢/2)

a and

the angle ¢,

which can be derived directly from the quaternion by using the following

(4.16)

a=---

-+

(4.17)

These two quantities, once known, can be used to construct a rotation matrix that will correct the sun-vector estimates for overall bias. This rotation matrix can be calculated via the following relation:

R

=

cos(¢ )I+ cos(¢ )aar +sin(¢ )ax

(4.18)

In the above equation, ax is the skew-symmetric matrix created using the elements in

a.

This rotation matrix is then used to modify the individual

estimates in the annulus, using the multiplication

Best ' carr = Rsest

(4.19)

These annuli were then individually corrected by using a best-rotation quaternion. The true sun-vectors in each annulus are subjected to a constant offset p. An example of a pre-corrected set of data points is shown in Fig. (4.2) and the corresponding corrected estimates in Fig.(4.3). When this correction is applied on the data set shown in Fig. (4.2), much of the bias that occurs in the area is removed. A corrected version of the data set is shown in Fig.(4.3). Because the calibration bias is no longer an issue, this changes the ways in which the two data sets can be treated.
49

Now, the corrected estimate

4. PRECISION TESTING

x

0.3566 0.3565 0.3564 0.3563

Sun-Vector Estimates True Sun-Vectors

>- 0.3562
0.3561 0.356 0.3559 0.3558 - 0.3557 -0.3556 -0 .3555
X

-0 .3554

- 0.3553

- 0.3552

Figure 4.3: Difference Between Estimated and True Sun Vectors After Bias Removal. offsets can be treated as random variables with a mean of zero, such that the zero-noise result would in fact be equal to the true sun-vector.

4.3

Precision

Once it has been established that true motion has been recognized, it would be useful to define how well the motion itself is detected. Given that motion has occurred between two points, the precision test is designed to give a comparison of the error in motion detection relative to the actual motion of the sensor. The motivation for performing this test is to see how the causes of measurement error relate when the sensor is subject to small motions. Calibration error results indicate that the overall error does change gradually across the field of view, but is relatively constant when the scope is limited to a small area of interest. A typical calibration error level plot is shown in Fig.(4.4). As the region of interest becomes larger, the error due to calibration bias increases.
It is also important to note that relative error regarding the noise-induced
50

4.3. Precision

X

10-3

I I

5

' '/'
/

-10.92 .... '
I

4.5

I

I
I I

' /'

/

ro Bt--, ~
I
~,

'~'

~

4
\

I

- ,+
\
~

I ..J_

'<
I .,
,

-4o-:-~~
I ' \
'I

-~\--~'I'
~

l
I

'

'

3.5
\

\

_,_

3
2.5

~'-I_ ,,
I

T -1

2 1.5
)(

~

~

'A

'<
/

'

I

'
/

--t1

'

Figure 4.4: Typical FOV Error Plot (in Radians). error relative to the actual sensor motion may be quite high when the angle of motion is small, due simply to the relatively small motion. The purpose of the precision test is to find how these two effects relate.

4.3.1

Definitions in the Precision Test

There are many different metrics that can be defined for the purpose of measuring precision. Here, variants of angular error calculations were used for comparing data sets. One of the first tasks required is to find the angular error between the corrected sun vector estimates and the true sun vectors, which can be found via the following relation:
;!I' · S _.est So )

Berr =

acos

(

llsollllse stll

(4.20)

This yields a scalar representation of error for each point. This can be
51

4. PRECISION TESTING used alongside the true sun vectors to get a sense of error magnitudes as well as the variation of those error magnitudes across a field of points. Our study used two different metrics for the calculation of local precision. First, a root-mean squared (RMS) angular error can be calculated for each annulus, which will give a sense of the angular error as the central offset increases. Given a length-n data set of errors X= {x 1, x2 ... Xn}, the RMS value is found via

Erms-

-~ y-:;;, LXi

(4.21)

For our purposes, the data set was a vector of angular errors. This yields a scalar measure of error for a given data group. The second type of metric used was a relative measure of angular error per unit offset, namely, the angular error encountered divided by the actual motion of the sensor. This is expressed as:

Erel

= -;-':,true

Erms

(4.22)

4.3.2

Precision Test Results

A number of data sets were created in annular rings surrounding a central point. The intervals between each of these annular rings was broken down into three sections. The first of these sections was a series of annular rings taken in 2.5 x 10- 3 degree intervals from the centre to a maximum of 0.1 degrees. The second section of rings was taken at 0.1 degree intervals out to a maximum of 1-degree offset, and the third at 1-degree intervals out to a maximum of 10 degrees. Each of these annular rings contained 20 points spread equally around the ring. Plotting the RMS angular error versus the angular offset yields Fig. (4. 5) and Fig. (4.6). From these figures, it is noted that the RMS error increases as the angular offset goes to 0.2 x 10- 3 radians, at which point it levels off.
52

4.3. Precision At an offset of 1.2 x 10- 3 radians , the error begins to rise again. Further, as the angular offset becomes extremely large, the RMS angular error stabilizes at approximately 0.9 x 10- 3 radians, as shown in Fig.(4.6).

1.6

~
'C

14

~ 1.2

g

~
~
:::;;
(/)

1

~ 0.8
0: 0.6

0.2

0.4

1 1.2 0.6 0.8 Annular Radius (radians)

1.4

1.6 x 10

1.8
-3

Figure 4.5: Local Region RMS Error.

0.8

"'i 1i
'0

0.7

~

g

0.6

~ 05
3

g> 0.4

<(
(/)

:::;; 0.3
0:

0.1
a ~~--~--~~--~--~~--~

0

0.02

0.04

0.06 0.08 0.1 Annular Radius (radians)

0.12

0.14

0.16

Figure 4.6: Far Field RMS Error.
It was expected that the RMS angular error would increase as the offset

angle increased. This is because the spatial bias difference increases with the angle between the two vectors. At the intervals where absolute RMS error remains constant, however, the spatial bias error remains constant in those regions of angular offset.
53

4. PRECISION TESTING Dividing the RMS error by the angular offset yields a relative measure of the estimation error. This relative measure is designed to get a sense of how precisely small sensor motions can be registered. From the RMS error plot in Fig. (4.5), it was noted that the RMS error remained relatively constant going from 0.2 x 10- 3 radians to 1.2 x 10- 3 radians, so it is expected that the normalized offset will be seen to decrease through that stage. The plot of the normalized error in Fig. (4. 7) shows a steep drop that minimizes at approximately 1.2 x 10- 3 radians. This is more pronounced when compared against the behaviour as the angular offset grows even larger, shown in Fig.(4.8).

::;
0::

~

e
06

~ 05

i
'f .,
0

04
0 .3

tl!1
0.2 0.1
a ~~~--~~~--~~--~~

0

0.2

0.4

0.6 0.8 1 1.2 Angular Offset (radians )

1.4

1.6 x 10

1.8
-3

Figure 4.7: Local Region Normalized RMS Error. As the offset becomes large , the offset-normalized error decreases simply due to this change. In the small-offset region, however, there is a distinct minimum that occurs. For this particular region of the field-of-view, this range corresponds to a region where the change in calibration bias is still very small, and the ability of the sensor to resolve small motions correctly is fairly high. From the absolute RMS error metric and the normalized error metric , we can draw some important conclusions regarding the error behaviour. Where the normalized error is small, the sensor is good at resolving the sensor motion. This is because the spatially varying bias changes very slowly.
54

4.4. Summary

0.8
0.7

0.6
0.5 0.4 0.3

0.2

0.1 0

y

v-P--·----------- 0.002 0 .004 0.006 0.008 0.01 0.012 0.014 0.016
Angular Offset (radians)

o ~~-~-~~-~~-~~

Figure 4.8: Normalized RMS Error to 1oOffset.

4.4

Summary

The purpose of the prec1s1on test was to provide a method of testing for sensor behaviour when subject to small motions. An algorithm was provided that eliminates calibration bias, which allows for the treatment of error as a zero-mean noise term once the bias correction has been made. After bias correction, two tests were possible. First, a motion limit test was performed which defines the small motion limit at which the sensor is still able to register motion. Second, a number of metrics were developed that can be used to quantify precision at a particular point in the field-ofview. These two methods were demonstrated at a point and results of those tests were shown. The motion limit test indicated that the smallest angular motion that can be observed by the sensor is 2.62 x 10- 4 radians. If the sensor observes a motion less than this amount, we do not know whether the change is due to actual motion or to internal measurement error. The precision test showed that the offset-normalized error minimizes at 1.2 x 10- 3 radians. This indicates that the measurement of relative motion is extremely good here. Even though smaller motion can be recognized,
55

4. PRECISION TESTING
as the motion limit test showed, the sensor measures motion poorly until approximately 1 x 103 radians. As the offset angle grows large, the ability of the sensor to measure relative motion continues to improve.

56

Chapter 5 Filtering for Rate Sensing
In chapter 4, testing and calibration proved that results in a small, defined area had an overall bias, namely, the estimated sun vectors were skewed from the true sun vectors by a near-constant vector - so long as the field-of-view was limited to a small area. The purpose of this section is to explore how this recognition can be used to advantage , i.e., how one can account for this local bias to give better attitude estimation results. By using rate measurements, we hope to improve overall sensor performance. Here, the types of observation are broken up into two parts. First , the classical single sun-vector measurement will be used. This, along with its associated error, will yield some attitude estimates over a period of time using a tumbling satellite. The second type of observation will further include a relative measurement, with its associated relative error. When relative measurements are taken, much of the slow spatially-varying bias error is removed. In this chapter, we use this to attempt to improve our attitude measurements. The attitude dynamics themselves are inherently nonlinear, so an extended kalman filter (EKF) will be used to combine the observations with the expected attitude states. First, we will define the filter terms and the methods used to propagate the filter. Then the system itself will be described
57

5. FILTERING FOR RATE SENSING using these filter terms, and initializations will be discussed. Using different combinations of the two types of observations, the performance of the filter will be analyzed and conclusions will be drawn based on this performance. We will perform these simulations using two classes of sensors. The first of these will be a generic sensor for which no bias data will be used. This sensor will have a higher random error, and no spatially-varying bias. The second type of sensor will be based on the Sinclair Interplanetary sensors used in our calibration work. Here, the random error will be less than that of the generic sensor, but spatially-varying bias will be present. We will test the effects of the two types of observations on both of these sensors, resulting in a total of four simulations.

5.1

Filter Formulation

The EKF is designed to integrate observations made with propagated attitude states. Each observation updates the current state estimate. Based on the current observation and the filter history, a new gain is calculated at each time step that relates the amount of shift toward the observed state. The EKF is designed specifically to handle nonlinear systems. Many of the terms in the filter equations are implicitly a function of the current state. Furthermore, many of the terms inside the filter equations are functions of time and need to be reevaluated at each filter step. The filter itself can be seperated into two different parts - a continuous propagation of the state and covariance estimates with time, and a correction for the state and covariance that occurs with each new observation. First, a number of matrices must be defined that are components of the filter. The first step in doing this is to define the state vector x and the system equation vector true[Stengel, 1994]:
58

f

such that the following continuous time relation is

5.1. Filter Formulation

x(t) = f[x(t), u(t), t] +

~f[x(t), w(t),

t]

(5.1)

Here, u defines the known, applied forces, and w the unknown disturbances. Essentially, f defines those aspects of the system propagation, and
~f

those aspects that aren't known. In addition, another vector h needs to be defined, which is the expected

observation at each observation time step based upon the current state, i.e., the following variable needs to be defined:

Z(t) = h[x(t), t]
where

(5.2)

h[x(t) , t] = Z[f(t) , ~f(t)] = Z[x(t), u(t), w(t), t]

¢:::;>

~f

=0

(5.3)

Defining the system equations allows one to define other terms which will be important to the filter. There are four matrices that we calculate in real-time that depend on the values off and h:

aj F(t) = F[x(t) , u(t), t] = ax aj G(t) = G[x(t), u(t), t] = au aj L(t) = L[x(t) , u(t) , t] = aw
ah H(t) = H[x(t), t] = ax

(5.4)

(5.5)

(5.6)

(5.7)

Having defined these terms, one can now derive the filter equations. To propagate the state estimate and the covariance estimate, the following equa59

5. FILTERING FOR RATE SENSING tions are solved in real-time[Stengel, 1994]:

X[tk(-)]

=

X[tk-1(+)] +

1
tk tk-1

f{ X[r(-)],u(r) , r}dr

(5.8)

P[tk(- )] = P[tk-1(+)] +

1
tk tk-1

[F(r)P(r) + P(r)Fr(r) + L(r)Qc(r)e(r)]dr (5.9)

Here, Qcis a matrix that satisfies the following relation regarding the
nOISe:

E[w(t)wr(t)]

=

Qc(t)b(t - T)

(5.10)

Once new observations are received, the system is able to update the state and covariance estimates to account for the new data.

5.2

Defining the System

The states that have been chosen to be observed using the EKF are the body rotation rates defined as follows:
Wx Wy Wx Wy

w, as well as the sun vector s.

The state vector has been

X=

Wz Sx Sy Sz

==> X=

Wz Sx Sy Sz

(5.11)

The system dynamics themselves will be decribed using Euler's equations for rigid-body motion. The following equations for the body rotations will
60

5.2. Defining the System be used:

(5.12)

(5.13)

. -(fxx-fyy) +Nz WzJ WxWy zz zz

J

(5.14)

The equations above define the first three terms of the vector last three terms, simply use the approximation

f.

For the

(5.15) To represent this purely in terms of state variables, it is important to note another useful approximation:

(5.16) Therefore, one can expand Eq(5.15) to a representation purely in terms of state variables.

s= --

[ s::.x:

l
=

WySz -

WzSy

=wxs=
[

-WxSz

+ WzSx

l

(5.17)

WxSy- WySx

This defines the last three terms of the vector f, satisfying the relation

f

f[X(t), u(t)]

=

[

~]

61

5. FILTERING FOR RATE SENSING

5.2.1

Derivation of the Expected Observation

For this system, two different types of observations will be considered. In typical sun sensor usage, only the single sun vector observation is considered. We will compare the single sun-vector measurement to a velocity type measurement b..sk x b..sk_ 1 . In order to do this, one needs to find a value for the expected observation, h, in terms of the state variables wand s. First, start with the basic relation (5.18) We know from Eq(5.16) that one can express fl.sin terms of state variables and time, so rewrite h as h = [w x sn!:l.t] x [w x Bn-1~t] By expanding this, one can arrive a slightly more useful relation (5.19)

h = (~t)

2

{((

-Sn

X

w) · w] (-sn-1) - (( -Sn

X

w) · (-sn-1)] w}
X

(5.20) per-

Here, two things are noted. First, the terms ( -Sn pendicular by definition, thus
(- Sn

w)

and

w are

X

w) . w =

0

(5.21)

Further, h cannot be expressed in terms of the old observation sn_ 1. Relating this to the current observation can be done simply by using the relation (5.22) Taking into account these changes, Eq(5.20) becomes:
62

5.2. Defining the System

h = -(~t? {( -sn

X

w) · [( -w X

Sn~t)- sn]} w

(5.23)

Again , note two things that allow us to further simplify this equation. The dot product can be simplified partially by recognizing that the vectors

( -Sn

X

w) and -S'n are perpendicular, so that

( -Sn
Further, the vectors ( -Sn usable form
X

X

w) . (-B'n) = 0
and ( -w
X

(5.24)

w)

sn) are parallel, and of the

same magnitude. This allows for the reduction of the equation to the simple

(5.25)

5.2.2

Deriving F and H

Now that the value of h has been found , the values of the other filter parameters can now be derived. For this system, we assume no applied forces. As a result , u = 0 and G = ~~ = 0. In order to derive the value of F , note the values of

f

and X as follows:

(5.26)
WyS z -Wx S z W z Sy

+ W zSx

63

5. FILTERING FOR RATE SENSING

Wx Wy

X=

Wz Sx Sy Sz

(5.27)

In order to derive the value ofF, simply take the Jacobian of the with respect to X , as follows:

f vector

(5.28)

While the derivation of F is fairly simple, the derivation of the H matrix is slightly more complex. Here again , take the Jacobian of the h vector with respect to X as follows:
oh
OWy

oh
OWz

oh
OSx

oh
OSy

OSz

oh

J

(5.29)

The individual column vectors g~ can be found using the product rule on the vector h, yielding the following result:

ah _ __ ( !\ ) - - - 2 ut 3 1 -w axi

X Sn 1

__ a 1-w x axi

sn IW__ -

( !\ ) 3 __ ut 1 -w

X S n 1-

__ aw axi

(5.30)

The solution to g~ is trivial, in that it is either a unit vector (when xi is a component of w) , or a zero vector (when xi is a component of S). A formulaic approach can be made for the solution of down the cross-product as follows:

ol-;:;snlby first breaking

(5.31)

64

5.2. Defining the System The cross-product magnitude can then be written as:

1-W x %1 =

ICI

=

-}ci + c§ + c~

(5.32)

Now the more difficult derivative can be written in the form

aIW X Bnl axi

=

aICI axi

= _1_

(cl 8cl + c2 8c2 + c3 8c3)

I6 I

axi

axi

axi

(5.33)

This allows the algorithm to deal with the simple derivatives ~·

5.2.3

Sensor Noise Modelling

Observation simulation will be conducted using two different sensor models. The first of these will be a generic sensor, and the second sensor model will be based on the SS-411 sensor. These will differ in how the observation error is handled. For both sensor types, the observer estimate model will be expressed as

Sobs

=

Strue

+ Eabs

(5.34)

For the generic sensor, there will be no bias error, and a large value of (]". Here, the magnitude of the error vector will be a function of a normally distributed random variable: (5.35) The direction of Eabs will be determined randomly, and will not follow any distribution. For the observer based on the SS-411, the error vector will be handled using a combination of bias and random noise. The bias will be provided from calibration data, and a smaller value of (]" will be used. The error then becomes 65
Eabs

5. FILTERING FOR RATE SENSING

Eabs

=

Ebias

+ Enorm

(5.36)

Again, the direction of the normally distributed random error will be determined randomly, and the magnitude of the vector will be generated using

IIE'normll = J2 (1 -cos Berr ),
5.2.4

Berr

rv

N (1-L

= 0, a 2 )

(5.37)

Planned Measurement Simulation

For this simulation, we will be comparing the observation results from two modelled sensors. The first of these will be a generic sensor, for which the observation error will be a zero-mean normally-distributed noise. There will be no spatial bias in the observations. The second sensor we will model will be the SS-411 series sensors. In this case, there will be a spatially-varying bias term which we will model using calibration results. There will also be a normally-distributed noise component, however the standard deviation of the distribution will be much less than that of the generic sensor. For each of these sensors, we will run the simulation using two different observation types.First , the standard sun-vector observation will be used. In the second case, the filter observation described by Eq(5.18) will be used in addition to the standard sun-vector measurement. In this case, the filter will use an combination of the current sun-vector measurement plus two taken previously to form the Z vector.

5.2.5

Initialization Values

Initialization parameters for the EKF are part guesswork and part theoretically derived. Although the initialization parameters can have only minimal
66

5.3. Exact Solution effects on the final output of the filter, a reasoned approach should exist for choosing these parameters to ensure correct filter operation. We would like to define a system with an exact solution. This allows us to ensure that the simulation of system dynamics works correctly. In order to simplify the system such that this is the case, moments of inertia are chosen for a precessing satellite: (5.38) Here, the satellite is axiosymmetric. The advantage to this is that the angular displacements and velocities about the x- andy-axis can be described using an exact solution. The z-axis angular velocity should remain constant. For the system presented here, the I vector was given the following value:

I=
[

10.1 10.1 19.8

l

kg· m 2

For the inital rotational velocity, the following values were used: 0.0471 -0.0337 [ 0. 7105

w

=

l

rad/ s

For the initial velocity estimate, the true velocity plus some normallydistributed random initial error with a standard deviation of 0.001 o / s was used.

5.3

Exact Solution

The free motion of an axiosymmetric system can be described using an exact solution. An axiosymmetric system has the following properties:

67

5. FILTERING FOR RATE SENSING

(5.39) Given these definitions of axial and transverse moments of inertia, the motion of the system can be described via[Hughes, 2004]

W3 0

=

W3

=. v = constant

(5.40)

We can then write the relations for the other two angular rates. First we define a term <I> as (5.41) The equations to describe the other angular rates is

W1

=

W1 0

cos (<I>t) + W2 0 sin (<I>t)

(5.42)

w2 = W2 0

cos (<I>t) -

W1 0

sin (<I>t)

(5.43)

5.4

Generic Sensor Simulation

The generic sun sensor is designed such that the observation error is normallydistributed, the mean value being the correct observation. The observation offset is calculated using the error in Eq(5.35). For the standard deviation of a single sun-vector measurement, a value of a= 0.07° was used.

5.4.1

Sun-Vector Observation Only

In this simulated case, we use the single sun-vector measurement only. Here, the observation Z is simply

68

5.4. Generic Sensor Simulation

z=

[ ::

l

(5.44)

Only the standard sun-vector measurement was used in this case. Error vectors between the true sun-vector and the corresponding state estimate were generated. The magnitude plot of this vector over time is shown in Fig.(5.1). Here, a significant amount of time was required for the initialization errors to be removed. The mean error vector magnitude was calculated, taking only values after 60s to account for the time to settle. The mean magnitude result in this case was 1.2 x 10- 3 .

0 .025

0.02
Q)

"0

·c:

.a
E
Cl <1l

u
>
Q)

5

0.01

w

e

-0 .005 0 20 40 Time(s)
60

80

100

Figure 5.1: Error Vector Magnitude in 0 bservation.

s for

Generic Sensor, No Relative

5.4.2

Relative Observation

In this case, we use both the single sun-vector measurement as well as the relative observation expressed in Eq(5.18). In this case, the observation Z becomes
69

5. FILTERING FOR RATE SENSING

(5.39) Given these definitions of axial and transverse moments of inertia, the motion of the system can be described via[Hughes, 2004]

W3 0

=

W3

=. v = constant

(5.40)

We can then write the relations for the other two angular rates. First we define a term <I> as (5.41) The equations to describe the other angular rates is
= W1 0

W1

cos (<I>t) + W2 0 sin (<I>t)

(5.42)

w2 = w2 0

cos (<I>t) -

W1 0

sin (<I>t)

(5.43)

5.4

Generic Sensor Simulation

The generic sun sensor is designed such that the observation error is normallydistributed, the mean value being the correct observation. The observation offset is calculated using the error in Eq(5.35). For the standard deviation of a single sun-vector measurement, a value of a = 0.07° was used.

5.4.1

Sun-Vector Observation Only

In this simulated case, we use the single sun-vector measurement only. Here, the observation Z is simply

68

5.4. Generic Sensor Simulation

(5.44)

Only the standard sun-vector measurement was used in this case. Error vectors between the true sun-vector and the corresponding state estimate were generated. The magnitude plot of this vector over time is shown in Fig.(5.1). Here, a significant amount of time was required for the initialization errors to be removed. The mean error vector magnitude was calculated, taking only values after 60s to account for the time to settle. The mean magnitude result in this case was 1.2 x 10- 3 .

0.025

0.02
Q)

2 ·c:

"0

E 0 t5 Q)

ro

C)

0.01

w
0 -0.005 0 20 40
Time(s)

e

>

60

80

100

Figure 5.1: Error Vector Magnitude in Observation.

s for

Generic Sensor, No Relative

5.4.2

Relative Observation

In this case, we use both the single sun-vector measurement as well as the relative observation expressed in Eq(5.18). In this case, the observation Z becomes
69

5. FILTERING FOR RATE SENSING

Z=

(5.45)

Comparing one element of the true relative observation to the expected relative observation yields Fig.(5.2). Because the measurements in this case are extremely noisy, it is expected that the addition of the relative observation will do very little to improve the state estimates.

3

- - - Expected Relative Observation Actual Relative Observation

2

<::

~

0

..0 0

3l 0

"' -1 ·~
X

-2

-3
35 40 45 50
Time(s)

55

60

65

Figure 5.2: X-axis relative observation Comparison.

Creating the error magnitude term that relates the state estimates to the true sun-vector, and plotting with respect to time yields Fig.(5.3). This plot indicates that the introduction of the relative observation causes an increase in error. This is reflected in the mean error magnitude when taken after 60s - an increase in value to 3.2 x 10- 3 ·

70

5.5. SS-411 Simulation

0.025

0.02
<1)

"0

·c: g> 0.015
E
ti <1)
>

.a
0
0

0.01

Ji
0.005

20

40
Time(s)

60

80

100

Figure 5.3: Error Vector Magnitude in Observation.

s for

Generic Sensor with Relative

5.5

SS-411 Simulation

In these simulations, the SS-411 error term is modelled differently than that of the generic sensor. Here, the error is the sum of a bias term and a normallydistributed noise term. This offset is calculated using Eq(5.36) and Eq(5.37). Here, a is the very small image-to-image noise result from the stationary sensor - 0.005°. The calibration bias will be taken from previous calibration work. An example of the slow calibration bias was across the FOV was shown previously in Fig.(3.5) and Fig.(3.6). Note that, in practice, it is not generally possible to have this error map as it this was generated based on exact knowledge of what the true sun-vector actually is.

5.5.1

Sun-Vector Observation Only

The single sun-vector measurement observation using the SS-411 model is the same as that for the generic sensor. The observation Z is again 71

5. FILTERING FOR RATE SENSING
10-4

X

3.5 3
Q)

.a ·;;:
Cl

"0

2.5 2 1.5 1 0.5 0 0 10 20 30 40 50
Time(s)

E

<11

£i
>

al

w

e

60

70

80

90

Figure 5.4: Error Vector Magnitude in

s for SS-411 , No Relative Observation.

z=

[ ::

l

(5.46)

Generating the error vector magnitude through the use of the state estimate and the true sun vector yields Fig. (5.4). The filter demonstrates that some time is needed to settle. Removing errors from the initialization, the mean error vector magnitude was calculated, ignoring the first 40 seconds of data to account for this settling time. The result here was a mean error magnitude of 7.99 x 10- 6 .

5.5.2

Relative Observation

Again, the observation term Z is calculated the same way as was shown for the generic sensor with relative observation. The observation is found via: 72

5.6. EKF Remarks

-

-

-

1.5 I II II II I

1

-

-

Expected Relative Observation I Actual Relative Observation 1 -

1 11 I

os'~ ~ ~ ~ ~ A~~ ~ ~ ~~~ ~~ ~
1

I II

I

\

· "

-0.5

-1

-1 .5

0

10

20

30

40

50
Time(s)

60

70

80

90

Figure 5.5: X-axis relative observation Comparison.

Z=

(5.47)

Comparing one of the relative elements of the expected observation versus the true observation yields Fig.(5.5). Here, noise in the relative observation is still extremely high; however, the actual observation can be seen to follow a similar shape to the expected observation. Comparing the true sun-vector to that provided by the state estimate, an error magnitude term was created. Plotting the error magnitude term over time yields Fig.(5.6). Again, some time was required for the filter to remove initialization errors .. The mean error vector magnitude was again calculated for 40s and beyond, to account for this settling time. Here, the mean value was 7.70 x 10- 6 .
73

5. FILTERING FOR RATE SENSING
10-4

X

2.5

2
Q)

.a ·c:

"0

E

~ 1.5

~
>
Q)

w

g

1

0.5

0 0 10 20 30 40 50 60 70 80 90

Time(s)

Figure 5.6: Error Vector Magnitude in tion.

s for SS-411 with Relative Observa-

5.6

EKF Remarks

The results from the EKF tests indicate that the use of relative measurements has detrimental effects on the filter behaviour when the random observation error is high. Using the generic sensor model, the introduction of the derived relative observation worsened performance- increasing the steady-state mean error by 166%. The EKF test using the SS-411 observer model showed a slight increase in performance; the steady-state mean error decreased by 3.6%. In this model, the random observation error component was small, but there was a significant spatially-varying bias contribution to error. These simulations indicate that there is the potential to improve sensor performance by introducing a relative observation. For this to work, however, the random error component must be small. contribution of this error component. As long as the bias varies slowly across the FOV, the relative observation should ignore much of the

74

Chapter 6
Conclusions
The purpose of this thesis was to both better model the SS-256 and SS-411 sensor behaviour and understand sensor performance. Improving our sensor models improves sensor performance and yields better calibration results. Understanding sensor behaviour tells us what the limitations of the sensor are , and tells us how the sensor behaves in different conditions. Included in this investigation was the derivation of a model describing the peak-width variation that occurs throughout the field-of-view. Also, the ability of the sensor to resolve motion was explored, including both smallangle detectability limits and a method of defining the precision of the sensor in detecting motion. Last , a new type of relative motion observation was defined and integrated into an extended kalman filter. We explored results for a generic sensor with normally-distributed noise only, as well as a SS-411 model where the error was treated as a combination of bias and random noise.

6.1

Summary

This section will reiterate the objectives of each section of the thesis, with some results obtained throughout the implementation of the developed meth75

6. CONCLUSIONS ods.

6.1.1

Calibration Work

A physical description of the sensor used in the SAIL test facility, including a description of the laboratory setup, as well as a definition of the parameterization that was used for calibration. The calculations that are used to translate mean peak-positions in the image to a sun-vector observation were g1ven. A number of different super-resolution algorithms were suggested. The mathematics that convert raw image data to peak-positions were shown for each. In some cases, the coarse location of the peaks must be known so that the contributions from each slit-pair can be seperated or the peaks can be coarsely bounded. A simple algorithm was shown that can perform this function. An algorithm was also given that can generate image locations such that there is even coverage across the field of view. This is desirable so that calibration is not skewed in favour of particular sections in the field of view. Then, the calibration procedure was outlined , including the calibration parameters that are related to the mounting of the sensor, as well as those which are unique to each individual sensor.

6.1.2

Width Correction

The NLSQ algorithm requires that a Gaussian peak-shape model be matched to peaks in the array to determine the peak locations. Previously, a constant peak-width term was used to do this matching; however, data collected from peaks across the array in an image set show that this description is inadequate. A full Gaussian model was derived that was used to find the peak-width as a function of array position. Given a defined error term, a least-squares

76

6.1. Summary error minimization was used to define the width of the peaks. When the peak width was plotted against array position, a trend was observed when observations were limited to a single logical peak. To describe this trend, a fourth-order even function was defined. Using the peak-width versus array position data obtained during the previous fit, the scaling terms of the function, as well as the minimum position, can be found through a least-squares error minimization. The curve fit for a particular logical peak map was shown to demonstrate this method. Finally, the effects of the width-correction method on the calibration performance of the NLSQ algorithm was shown. Some very poor results observed near the edge of the field-of-view were shown, and the error profile was more consistent across the field-of- view.

6 .1. 3

Precision Testing

A method of testing how capable the sensor is at correctly identifying motion was developed. Although calibration results have been obtained before which describe a single estimation error obtained at points across the field-of-view, there was no previous method of finding the motion limits at which the sensor was usable, and it was unknown how well small sensor motions were tracked. Because the calibration bias varied little when the area of interest was small, removing the bias error from a given point would limit the observed offsets to zero-mean noise. A best rotation quaternion that removes this bias error was derived. The application of this quaternion to the sets of estimates was demonstrated. Because the sensor operation introduces random noise into the image, there will be a small-motion limit at which the sensor is usable, namely, there is a minimum angle at which the difference in two estimates can be attributed to actual sensor motion as opposed to random noise. A method of testing for this small limit was given, and an example of this procedure in use was provided. Using an example data set, a small motion limit of

77

6. CONCLUSIONS 2.62 x 10- 4 radians was found. The ability of the sensor to correctly identify motion was addressed in the precision test. Precision was defined using both an RMS angular error, as well as a normalized RMS angular error. Data sets were compiled using annular rings offset by small amounts from a central point. The RMS angular error generally increased as the offset angle became large; however, the error was relatively constant in the interval [0.2 1.2] x 10- 3 radians and at offsets greater than 0.9 x 10- 3 radians. The offest-normalized error dipped to a local minimum at approximately 1. 2 x 1o- 3 radians and also dropped as the offset angle bacame large.

6.1.4

Extended Kalman Filter

There were two reasons an observation simulator was developed. First, a new type of observation was developed that looks at relative motion in addition to current position, and the extended kalman filter (EKF) would indicate whether or not this does improve sensor performance. Second, the simulator would indicate whether performance can be improved if the error profile of the sensor is well-known. First, an EKF was defined that will propagate the state and covariance matrices continuously and will perform discrete updates to the state and covariance when observation data are available. We define a relative observation using the current sun-vector along with the previous two observed sun-vectors. For each of the two sensor types, we perform two observation simulations. In the first one, we use a single sun-vector measurement. In the second simulation, we use the single measurement as well as the relative measurement. The simulator was first run using a generic sun sensor for which few error data were known as the observer. Using the relative observation in addition to the standard sun-vector observation gave worse results, increasing the steady-state mean error magnitude by 166%.

78

6.2. Future Work When the sensor error profile is well-known, however, better results can be generated from the filter. Taking advantage of the fact that the bias error is relatively constant when consecutive sun-vector movements are small, the filter is able to decrease the mean steady-state error magnitude term by a small amount, namely, 3.6%. The results of this test indicate that relative measurements are only useful when random error is low. The generic sensor, with a large random error but no measurement bias, was unable to improve performance by providing relative measurement data. Simulation results improved with relative measurements provided by the SS-411 model. Although there was a large bias error in the model, the relative measurement removed most of this slow spatial bias. Since the random error of this sensor was small, the relative measurements provided were able to improve performance.

6.2

Future Work

Most of the work covered in the thesis focuses on the development of methods for improving knowledge of sensor parameters and sensor behaviour. Although examples of how to apply each of these methods are given, by no means are these results to be interpreted as representative of all Sinclair Interplanetary sensors. Indeed, the behaviour of each of these sensors is unique.

6.2.1

Field-of-View Precision

Although an example is given of the application of the precision test , the results do not hold even when different segments of the sensor field-of-view are examined. In order to get full understanding of the sensor precision, this test should be conducted at points throughout the field-of-view to get a more comprehensive look at the sensor behaviour.
79

6. CONCLUSIONS Further, results from the precision test are algorithm dependent. Because much of the calibration bias is removed prior to the testing, the differences in estimation are primarily due to image noise. Depending on the ability of algorithms to reject this added noise, different results may occur.

6.2.2

EKF /Precision Model Unification

In order to achieve extremely high accuracy in modelling the sensor observations, one can merge results from a comprehensive precision test in the simulation, namely, performing the precision test throughout the field-ofview will yield expected error results from observation points around the field-of-view. Integrating these results with the simulator would give a more accurate simulation of the sensor behaviour and would yield a more accurate assessment pertaining to the ability of the sensor to track vehicle motion.

6.3

Closing Remarks

Sensor behaviour prediction was improved by introducing a peak-width function that can be utilized in conjunction with the NLSQ algorithm. This change is more consistent with the peak width behaviour across the field-ofview. A method for defining the sensor observation limits regarding small motions was given and demonstrated at a particular point. Metrics defining sensor precision were given, and the ability of the sensor to resolve small motions correctly was explored. Finally, an EKF was developed to simulate sensor observations and was tested utilizing both an arbitrary sensor for which only basic information is given, as well as a sensor for which intimate knowledge of the error profile is available.

80

Bibliography
P. Besl and N. McKay. A method for registration of 3-d shapes. IEEE Trans.
on Pattern Analysis and Machine Intelligence, 14(2):239- 256, 1992.

Yam A. Li C. Enright, J. Modelling and testing of two-dimensional sun sensors. IEEE Aerospace Conference, 1:1- 11, 2007. Yam A. Li C. Enright, J. Parametric processing for two-dimensional digital sun sensors: Algorithms, modeling and testing. AIAA Journal of Spacecraft and Rockets, 45(2) :359- 369, 2008.

Zerubia J. Berthod M. Foroosh, H. Extension of phase-correlation to subpixel registration. IEEE Trans. on Image Processing, 11(3):188- 200, 2002. Godard and J. Enright. Optimization of a sun-sensor illumination pattern using genetic algorithms. IEEE Canadian Conference on Electrical and
Computer Engineering, 1:1437- 1441, 2006.

B. Horn. Closed-form solution of absolute orientation using unit quaternions.
J. Opt. Soc. Am. A., 4(4):629- 642, 1987.

Peter C. Hughes. Spacecraft Attitude Dynamics. Dover Publications, Mineols, New York, 2004. C.C. Liebe. Accuracy performance of star trackers- a tutorial. IEEE Transactions on Aerospace and Electronic Systems, 38(2), 2002.

81

6. CONCLUSIONS S. Mitra. Digital Signal Processing: A Computer Based Approach. McGrawHill, New York, New York., 3 edition, 2006. G. Rufino and D. Accardo. Enhancement of the centroiding algorithm for star tracker measure refinement. Acta Astronautica, 53(2), 2003. R. Stengel. Optimal Control and Estimation. Dover Publications, Mineola, New York, 1994. Larson W. Wertz, J. Space Mission Analysis and Design. Microcosm Press and Kluwer Academic Publishers, 3 edition, 1999.

82

