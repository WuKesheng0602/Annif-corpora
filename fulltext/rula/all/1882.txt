Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2009

Creating Sign Language Web Forms
Norma-Jane E. Thompson
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Electrical and Computer Engineering Commons Recommended Citation
Thompson, Norma-Jane E., "Creating Sign Language Web Forms" (2009). Theses and dissertations. Paper 1200.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

CREATING SIGN LANGUAGE WEB FORMS

by

Norma-Jane Elizabeth Thompson
BASe. University of Toronto, 2005

A thesis presented to Ryerson University in partial fulfillment of the requirement for the degree of Master of Applied Science in the Program of Electrical and Computer Engineering.

Toronto, Ontario, Canada, 2009

©Norma-Jane Elizabeth Thompson, 2009

PROPERTY OF RYERSON UNIVERSITY LIBRARY

Author's Declaration
I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research. Signature

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. Signature -

'-

--"""

ii

Instructions on Borrowers
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

111

Abstract

Creating Sign Language Web Forms
Norma-Jane Elizabeth Thompson Masters of Applied Science Electrical and Computer Engineering Ryerson University, 2009

Currently, the World Wide Web allows web pages to be produced in most written languages. Many deaf people, however, use a visual-spatiallanguage with no written equivalent (e.g. American Sign Language). SignLink Studio, a software tool for designing sign language web pages, allows for hyperlinking within video clips so that sign language only web pages can be created. However, this tool does not allow for other interactive elements such as online forms. In this thesis, a model for an online sign language form is proposed and evaluated. A study consisting of 22 participants was conducted to examine whether there were differences in performance or preferences between sign language forms and text forms, and between two presentation styles (all-at-once versus one-at-a-time). The results showed that there was no clear performance advantage between sign language and text; however, participants were interested in having online questions presented in sign language. Also, there were no advantages in performance or preferences between presentation styles.

iv

Acknowledgments

Many people helped me make this thesis possible. Thank you to my supervisor Deb Pels for guiding me through my research, and providing me with the opportunity to work on this project. To my thesis committee members, Dr. James Smith, Dr. Kathryn Woodcock, Dr. Kristiina McConville, thank you for embracing my goals and helping me reach them. I would like to thank the people at the CLT lab that helped me throughout this project. Thank you JP Udo, Maria Karam, and all the rest who helped support and encourage me through this process. A huge thank you to my mom, Carri Thompson, for helping and encouraging me see the light at the end of the tunnel. Also, to the rest of my family for standing behind me through this whole experience, thank you. Thank you also to Rebecca Mamoch for helping me stay on track until the very end. A thank you to all the participants of the study, especially those from the NTID conference who helped me iron out some of the issues with the study and those first few online participants who emailed me with the problems online. I would like to acknowledge the funding support of Canadian Heritage and Natural Sciences and Engineering Research Council of Canada.

v

Contents

Chapter 1 Introduction................·.................·.............................................................................. 1 1.1 Purpose ....................................................................................................................... 6 1.2 Scope .......................................................................................................................... 6 Chapter 2 Literature Review ...........................................................................................·........... 8 2.1 Computer Interaction Techniques .............................................................................. 8 2.2 Web Interaction Techniques .................................................................................... 15 2.3 Computer-based Representation of Sign Language ................................................. 23 2.4 Survey Design .......................................................................................................... 33 2.5 Online Survey Tools ................................................................................................ 38 2.6 Online Forms Elements ............................................................................................ 43 2.6.1 Form Controls ........................................................................................... 43 2.6.2 Form Controls with Sign Language .......................................................... 48 2. 7 Questionnaire Presentation Style ............................................................................. 49 2.8 Online Sign Language Survey Tools ....................................................................... 51 Chapter 3 Online Sign Language Form ......................................................................·............. 54 3.1 Survey Development and Deployment .................................................................... 55 3.2 Database Design ....................................................................................................... 58 3.2.1 Questions and Answers ............................................................................. 58 3.2.2 User Responses ......................................................................................... 60 3.2.3 XML File and Parser ................................................................................. 61 3.3 User .......................................................................................................................... 62 Chapter 4 Study of Online Sign Language Form .................................................................... 63 4.1 Research Questions .................................................................................................. 63 4.2 Study Design ............................................................................................................ 64 4.3 Method and Data Collection .................................................................................... 66 4.4 Data Analysis ........................................................................................................... 68 4.5 Participants ............................................................................................................... 69
- -~

Chapter 5 Results ........................................................................................................................ 73 5.1 Tests for Order Effects ............................................................................................. 73 5.2 Comprehension Test Scores ..................................................................................... 73 5.3 User Preference Survey ............................................................................................ 75 5.4 Post-study Summative Questionnaire ...................................................................... 87 5.4.1 Signing Speed ............................................................................................ 89 5.4.2 Answer Online in the Future ..................................................................... 90 5.4.3 Open ended questions ................................................................................ 91 Chapter 6 Discussion .................................................................................................................. 92

Vl

6.1

6.2 6.3 6.4 6.5 6.6

Differences in performance and preferences in answering online questions between sign language and text users ..................................................................................... 92 6.1.1 Possible effects of the sign language videos used for comprehension ...... 96 6.1.2 Possible Effects of Technical Delivery Effects: Sign Speed, Video Quality ................................................................................................................... 98 6.1.3 Effects of the Questions and Learning Effect ........................................... 99 Difference in performance or preference for questions presented singly versus all at once ........................................................................................................................ 100 Effect of Individual Differences ............................................................................. 102 Model ..................................................................................................................... 103 Limitations ............................................................................................................. 105 Recommendations .................................................................................................. 109

Chapter 7 Conclusion and Future Work ................................................................................ 110 Appendix A XML File and Parser .......................................................................................... 112 A.1 Xml File ................................................................................................................. 112 A.2 Xml Parser .............................................................................................................. 116 A.3 MySQL Database ................................................................................................... 120 Appendix B Study Questionnaires .......................................................................................... 123 B.1 Pre-Study Questionnaire ........................................................................................ 123 B.2 Comprehension Test............................................................................................... 126 B.2.1 To Air Is Human Comprehension Test ................................................... 126 B.2.2 Bad Vibrations Comprehension Questionnaire ....................................... 127 B.3 User Preference Survey .......................................................................................... 128 B.4 Post Study Summative Questionnaire .................................................................... 129 B.4.1 English Text Questionnaire ..................................................................... 129 B.4.2 ASL Questionnaire .................................................................................. 130 Appendix C Ryerson Research Ethics Board Approval ....................................................... 131 Bibliography .............................................................................................................................. 132

vii

List of Figures
Figure 2-1: Command Prompt ........................................................................................................ 9 Figure 2-2: Menu from Adobe Dreamweaver CS3 ....................................................................... 11 Figure 2-3: Pie Menus in The Sims from Maxis ........................................................................... 12 Figure 2-4: Activation Form for Windows XP ............................................................................. 14 Figure 2-5: Hypertext from Ryerson University webpage ........................................................... 17 Figure 2-6: Navigation on Ryerson University web site. The circles show the top, left, and bottom hypertext navigational links .......................................................................... 18 Figure 2-7: Question of the Day Polls for (a) CityNews [32] and (b) CTV Toronto [33] for February 3, 2009 ........................................................................................................ 20 Figure 2-8: Windows Live Messenger .......................................................................................... 22 Figure 2-9: ASL main page for Deaf Culture Centre ................................................................... 25 Figure 2-1 0: Deaf Culture Centre Community page containing text navigation along the left side and top panels .......................................................................................................... 26 Figure 2-11: SignPost Homepage ................................................................................................. 27 Figure 2-12: Sign Community page .............................................................................................. 27 Figure 2-13: SignLink Studio webpage ........................................................................................ 31 Figure 2-14: SignLink Studio web page with optional text. ......................................................... 31 Figure 2-15: Example SurveyMonkey.com question ................................................................... 39 Figure 2-16: Example SurveyMonkey.com survey results ........................................................... 40 Figure 2-17: Example SurveyPro survey ...................................................................................... 41 Figure 2-18: Example SurveyPro survey web report .................................................................... 42 Figure 2-19: Form input tags: (a) checkbox, (b) text box and password, (c) radio button (d) text box with submit button ............................................................................................ 47 Figure 2-20: Menu created with the select tag ........................................................................ 47 Figure 2-21: Form text area tag ............................................................................................... 48 Figure 3-1: Overview of development and deployment ............................................................... 55 Figure 3-2: SignLink Studio Web Object ..................................................................................... 56 Figure 3-3: SignLink Studio web object as a form question ........................................................ 57 Figure 3-4: Screen view of tables supporting questions and answers .......................................... 59 Figure 3-5: Screen view of user answer tables ............................................................................. 61 Figure 3-6: Model of user information sub-elements ................................................................... 62 Figure 5-1: Bar graph of the scores for comprehension tests ....................................................... 75 Figure 5-2: Bar graph for ratings for user preference survey relating to online survey preferences ................................................................................................................................... 76 Figure 5-3: Bar graph of participant ratings for statement "Layout is difficult to figure out" organized by survey language ................................................................................... 77 Figure 5-4: Bar graph of participant ratings for statement "Rather fill out survey in person" organized by survey language ................................................................................... 78 Figure 5-5: Bar graph of participant ratings for statement "Submitting answers online is difficult" organized by survey language ................................................................................... 79 Figure 5-6: Bar graph of participant ratings for statement "The questions were difficult to answer" categorized by video clip viewed ................................................................ 80

Vlll

Figure 5-7: Bar graph of participant ratings for statement "It was easy to find the answers to the questions" categorized by video clip viewed ............................................................ 80 Figure 5-8: Bar graph of participant ratings for statement "Layout is difficult to figure out" categorized by video clip viewed .............................................................................. 81 Figure 5-9: Bar graph of rating for user preference survey.......................................................... 82 Figure 5-10: Bar graph of participant ratings for statement "Questions were difficult to answer" categorized by online survey usage ......................................................................... 84 Figure 5-11 : Bar graph of participant ratings for statement "It was easy to find the answers to the questions" categorized by online survey usage ....................................................... 84 Figure 5-12: Bar graph of participant ratings for statement "Rather fill out the survey in person" categorized by online survey usage ......................................................................... 85 Figure 5-13: Bar graph of participant ratings for statement "Directions were not detailed enough" categorized by education level ................................................................................. 86 Figure 5-14: Bar graph of participant ratings for statement "Easier to fill out survey on paper" categorized by education level. ................................................................................ 87 Figure 5-15: Bar graph of participant answers to "Rate how difficult it was to understand the level of vocabulary used" based on language .......................................................... 88 Figure 5-16: Bar graph of participant answers to "Rate how much better/worse do you think you would have done if the questions were in [the other language]" based on language .................................................................................................................................. 89 Figure 5-17: Bar graph of participant answers to "Rate how difficult it was to understand the vocabulary used" ...................................................................................................... 89 Figure 5-18: Bar graph of participant answers to "Rate the speed of signing" ............................ 90 Figure 5-19: Bar graph of participants answers to "Rate how likely you would answer questionnaires if they were presented in sign language" based on language .......... 90 Figure 6-1: Adjusted model of user information sub-elements .................................................. 104

ix

List of Tables
Table 2-1 : Values oft ype attributes for input tag ...................................................................... 46 Table 4-1 : Treatments ................................................................................................................... 64 Table 4-2: Database Tables ........................................................................................................... 68 Table 4-3: Descriptive Statistics of Subjects ................................................................................ 70 Table 4-4: Sign languages practiced by participants .................................................................... 71 Table 4-5: Computer application usage ........................................................................................ 71 Table 4-6: Online sign web access ................................................................................................ 72 Table 5-1: MANOVA results for user preference survey ............................................................. 73 Table 5-2: Collapsed Treatments .................................................................................................. 73 Table 5-3: Average comprehension scores ................................................................................... 74 Table 5-4: Chi-square analysis for user preference survey ........................................................... 76 Table 5-5: Mann-Whitney results for user preference survey organized by survey language ..... 77 Table 5-6: Mann-Whitney results for user preference survey organized by video clip ................ 79 Table 5-7: Mann-Whitney results for user preference survey organized by presentation style ... 81 Table 5-8: Chi-square analysis for user preference survey ........................................................... 82 Table 5-9: Mann-Whitney results for user preference survey organized by online survey usage 83 Table 5-10: Mann-Whitney results for user preference survey organized by video clip .............. 86 Table 5-11: Mann-Whitney results for user preference survey organized by video clip .............. 88 Table A-1: Table question populated with To Air is Human data .............................................. 121 Table A-2: Table answer populated with To Air is Human data ................................................ 122

X

Chapter 1 Introduction
Currently, the World Wide Web (WWW) allows web pages to be produced in most written language. Many deaf people, however, use a visual-spatiallanguage with no written equivalent (e.g. American Sign Language (ASL), Langue des sourds du quebec (LSQ)). With these languages, vocabulary and grammar are expressed using hand gestures, facial gestures and body movements (also referred to as gestures). They are not simply a translation between the spoken and non-spoken modes. These languages are complete natural languages with their own syntax, concepts and grammatical structures [ 1]. These languages are one of the bases for Deaf culture. Although some deaf people communicate using lip reading, speech, written language and combinations of these, many members of the deaf community participate in a culture based on sign language. There is a strong emphasis of social and family ties within the community [2]. The cultural values are passed from one member to the next through reinforcement or discouragement of comments and actions. As most of their interaction occurs in sign language, textual languages are a second language for people who were born deaf or became deaf as children. Many deaf people do read, but concerns have risen about the deaf educational system. Deaf schoolleavers have been reported as having an average literacy level that borders functional literacy [3]. We do not know whether this average has improved since the emergence and proliferation of text based technology such as closed-captioned television, text messaging

1

2

and WWW usage but for many deaf people, accessing the textual WWW will be more of a challenge than for their hearing peers. On the WWW, the presence of sign languages is very limited because written text is the foundation of the WWW. For example, text is used for URL specification, much content is provided as written text, and navigation is often provided as text labels or links. The World Wide Web Consortium (W3C), the main international standards organization for the WWW, as part of their Web Accessibility Initiative, has published the Web Content Accessibility Guidelines (WCAG) [4], a series of Web accessibility guidelines. The WCAG consist of a set of guidelines on making content accessible, primarily for disabled users, but also for all user agents, including highly limited devices, such as mobile phones. These specifications prefer text as the alternative method for communication. Images are to be labelled with "alt text", an alternative text description; videos are to be captioned, where a text transcript of the audio track is superimposed over the video. There is little provision for sign language based content. There is a lack of tools available to create web pages that do not contain text. Most tools for the web design, such as Dreamweaver and FrontPage, work on the assumption of using text. Video content is a secondary process, and usually embedded within a text web page. It is thus, difficult for deaf sign language users to have a web presence in their native language and culture, because they are "forced" to work a secondary textual language, such as English. The lack of sign language content on-line also means that Deaf culture has unequal representation in a space that is claimed to be one of the great equalizers of culture and language [5], putting people who are deaf at a disadvantage when using the WWW. Other languages, such as Chinese or Russian, have ASCII character sets that allow for the display of these languages online. There is no equivalent character set for sign languages and thus cannot be displayed in this manner.

3
Most web pages are based on text and static images, which can be beneficial for many accessible modes, such as text-to-speech, and text-to-Braille. However, common practice and guidelines [4] recommend that in order to provide people who are deaf with access to sound and rich media, spoken language and sounds be translated into text. Deaf users are then required to use their second language. Some web sites do provide sign language content [6-9] although many of them are often dictionaries or text-based information sites rather than signed web content. In addition, even if there is signed web content, text is still favoured for navigation elements and hyperlinks [6, 7]. Signers must then constantly switch between their normal language of communication, sign language, and a second language in text form in order to access the information. While this may assist people in developing proficiency in a text-based language, it limits the expression and exposure of Deaf culture online. The online sign language dictionaries and learning tools for sign language typically contain 2D static drawings depicting the signs or short video clips of isolated signs. The most common signs that are illustrated are the characters of manual alphabets that when put together constitutes finger spelling [8, 9]. English can be transliterated letter by letter using fingerspelling with the manual alphabet. Finger spelling is an important part of sign language but it is primarily used for names, places and emphasizing words. Finger spelling complete sentences is awkward and often an inappropriate way of translating spoken language into gestures, and can be likened to speaking letters that spell words in sentences. Complete signs represent concepts similar to how a set of words might represent one concept. Breaking those words down into the letters does not constitute that concept. Most signs require the hands, body and face to understand and not a series of letters spelled out. The face

4

and upper body are important in determining the grammar relating to the sign, through emotional and emphatic elements of the conversation. Sign language communication requires full body expression in order to communicate the concepts fully. One of the key foundations of Deaf culture and the way in which deaf people communicate is sign language. Sign language is a visual-gestural language with no written form and there has been little ability to capture and archive sign language communications. The propagation of Deaf culture follows the traditions of passing down information about the culture and language using a person-to-person process (similar to oral languages) [2]. Attempts to capture and store sign language have used text and static illustrations but these do not capture the fullness of the concepts since sign language requires movement in order to emphasize and clarify signs. An example is sign language dictionaries, which use static images of signs and require text descriptions of the movements and body language associated with the sign. There are signs that would be the same if taken as a static picture, however the motion of the hands and body of the signer as well as the facial expressions while moving convey additional meaning to the signs. With the advent of video technologies and processing techniques (filming, editing, and displaying), the opportunity to capture and archive sign language communications has emerged. However, working with video including filming, editing, archiving and retrieving is still a new process that is complex. As a result, video archiving, indexing and retrieving of sign language film and-video often uses text-based processes (e.g., using text-based tags to describe video content for future retrieval). This use of text-based processes for manipulation, storage, searching and retrieval of multimedia content including video is dominant, particularly in the online environment. Because of this reliance on written language or text, there are many barriers for deaf people with lower

5

reading fluency. The lack of content-related images in pages of full text, captions or transcripts of online audio material such as webcasts, and music, alternatives for voice input on some web sites can slow comprehension for people whose most effective communication mode is sign language, as can the lack of clear and simple language [4]. A common method of including sign language on a web site is to embed a sign language video within a text webpage [6-8, 10, 11]. The sign language video contains an interpretation of the text content, or more often, the video is of a single sign out of context in order to illustrate that sign to learners. In these cases, users must still switch between sign for content and text for navigation. A proposed solution by [12] is the Signing Web and SignLink Studio, a tool to create sign language web pages. In the Signing Web, the main web content is a sign language video and the navigation elements or hyperlinks are areas of that video marked as sign language links (signlinks). The deaf web user then sees the links as static image thumbnails that can play a description of the link in sign language and the visualization of the grouping and quantity of links. Using SignLink studio, a content creator/web designer is able to create content by recording a video of the information they wish to present. Users are able to add navigational hyperlinks in the video and create web pages that are easily uploaded to the web using common software tools. User studies have shown that all participants were able to grasp the concept of signlinking and navigate the various signlinks. They were also able to navigate signed Web sites with no specialized technical knowledge or skills [13]. As a tool to help design web pages that do not require text for navigation, SignLink Studio has begun to allow for the web presence of Deaf Culture in its primary language, sign language. However, it is limited to signlinking or hyperlinking structures. Web interaction is not

6

limited to hyperlinking between pages of content; it also includes menus, forms, forums, games, and many other forms of content interaction. Web forms are a method of interaction that is common on textual websites. They allow users to submit information to the web site.

1.1 Purpose
The purpose of this thesis is to explore the design and evaluation of online sign language forms, created in a manner similar to that of a SignLink Studio web page. The online forms will be implemented using sign language to create the form content, as well as, using sign language . for the responses. An important question arises about how a form can be created without having to use text. In this work, I am investigating effective ways of implementing the form elements that typically require textual components using signlinks to indicate their relationship to the questions.

1.2 Scope
The scope of this thesis relates to the usage of a sign language web form. The assumption is that the creation of the form is already complete, based on existing systems in place to generate signlinks. In addition, the underlying database is text-based, which is sufficient to demonstrate the concepts investigated in this thesis. Pattern matching in video, database manipulation of video materials and video retrieval are not considered at this time. A simple web database interface, similar to textual web survey tools, was created to view answer counts and averages in order to study results.

7 Because of the difficulties still being encountered with sign language recognition in video, I developed a hybrid system that uses sign videos for questions that could be contained in a form, a forced-choice answer system comprised of signed answers, and then text based database in order to store responses. The database interface masked the text nature of the database and displayed the responses in a non-textual fashion. Chapter 2 reviews literature related to text based forms as well as other technology based representations of sign language. Chapter 3 provides the details of the system I developed. Chapter 4, 5, and 6 report and discuss my study of this system.

Chapter 2 Literature Review
In this chapter, I will present a review of current published literature on web interaction techniques, and survey design. I will cover the creation of online forms, and the use of online survey tools, as well as online sign language survey tools. In addition, I will discuss Deaf culture with respect to sign language and online presence. In addition, a discussion on how this literature is relevant to my thesis is presented.

2.1 Computer Interaction Techniques
Interactivity for this thesis is defined as the extent to which an exchange between users and computers can occur [14-16]. Numerous techniques and styles can be used to provide interactions between computers and humans. Some major interaction techniques suggested by [14] include command entry, menus, form-fills, natural language dialogue (speech or typed), query language and direct manipulation. Each interaction technique has advantages and disadvantages, and can support different types of user tasks and users. Interface designers often employ mO'fe than one technique in order to support a range of users from novice to expert. Command entry is one of the original interaction techniques between humans and computers [14, 17]. A user would enter commands in order to perform all possible actions with the computer. Commands are short text-based "words" or sets of characters that tell the computer which operation to perform. Commands can be entered in directly using an interface similar to

8

9 the Microsoft Windows Command Prompt (see Figure 2-1). Users enter commands in order for the computer to perform operations, from simple file access to complex database query. Typically, this type of interactivity is limited to expert users as they are more likely to persevere in learning the complex protocols needed in order to have a dialogue with a computer [14], as the dialogue tends to be limited to obscure commands that do not always make common sense. Novice or intermittent users often use the wrong words and fail to get the actions or information they want [17]. For example, in order to clear the screen for a computer using a DOS operating system, the command "cls" is issued. Another example is in order to change the folder or directory that you are in the command cd foldername is used and cd .. is used to change to the parent directory.

Figure 2-1: Command Prompt

A second common type of interface is the direct manipulation interface commonly implemented as a graphical user interface (GUI). Direct manipulation uses icons to represent objects, which can be moved around the screen and manipulated by controlling a pointing device such as a cursor with a mouse. First seen in interactive graphic systems, direct manipulation is

10

now proving effective in user interfaces for applications that are not inherently graphical [18]. With direct manipulation, users seem to be operating directly on the objects in the computer instead of carrying on a dialogue about them [18]. Well-designed direct manipulation systems are easy and even pleasant to use [19]. This can be owing to a number of factors. Novices can learn the basic functionality quickly. Experienced users can work extremely rapidly to carry out a wide range of tasks. Knowledgeable intermittent users can retain operational concepts. Users can immediately see if their actions are furthering their goals and can simply change the direction of their activity if needed. Users experience less anxiety because the system is comprehensible and actions can be easily reversible. In addition, users gain confidence and mastery because they initiate an action, feel in control and can predict system responses [14]. This helps users accomplish their tasks easily and with little cognitive effort, improving the computer-human interaction. Some of the most common types of interaction elements in the GUI are menus, and forms-fills. Menus consist of a set of commands, grouped by tasks, displayed on the screen from which the user can select, listing the operations available for the computer to perform [20]. This type of interaction has an advantage over command entry in that users do not need to memorize and recall a large functionally disparate group of commands to perform and their actions; they only need to recognize the commands among the small-related set of selections presented to them in the menu [20]. Well-written menus offer novice users familiar terminology and a systematic process for retrieving information or specifying procedures [21]. Figure 2-2 shows the Edit menu for Dreamweaver CS3. As shown, there are some commands, such as Undo and Redo, that cannot be executed at this time and these commands are "greyed" out to prevent the user from trying to use the commands. Executing the Undo and Redo functions would cause an error

11

if selected in this example. Figure 2-3 shows an example of a pie menu from the game The Sims from Maxis. Pie menus use radial rather than linear selection, which enables the user to learn directional gestures so selection can be made without needing to look at the menu items.[22]

R~do

(hh¥
{.td·X
C~1hC

Cut
C!!!py
p~

(td·V
Ctrl· S.~ift· V

P.1'0tt! S~<~aL..

CktM
StltdAII

Ctd+A Cttt+( Cut+}
Ctn+F

Sdtd P·te~ Ttg
SeledCto.Hd
~

Find lf\d Rtpl-act."

00
·!

m

Find Selection

&1

~

findNect
Gc· te·hnt:
S-h-t:r"'*' (.;>~ Hi:nt{.

Shilt.-Fl f3
Oti~G

~ ttl
l
l

ctr~"'Sra<~

Rdte$11 Cock Hints
Code Hint Tools
~d'entCcdt v\rtdrJ1~ C~·d~":
B.~l~h(t $ t4(-::'t\

Ctrl+.

.J

1

!

·
Ctff·Shrrt· :.

Ct:I .. Shift>-<

CH ·

~Entries

Code Coli·pse
Edit with bteful Editor
T19 Ubt~Ms.. · .CC)if>oltd Shottcuts....

· ·

Pmtn!nces...

Ctrt.U

Figure 2-2: Menu from Adobe Dreamweaver CS3

12

Figure 2-3: Pie Menus in The Sims from Maxis

Form-fills are used to submit data to a computer database using a keyboard. A form provides a series of questions and answer fields that a user can complete or fill in. The form has roots in paper-based interactions of questionnaires and surveys. The advantage of this type of interaction is that it helps the user position the data in the correct place (see Figure 2-4) and provides a complete set of information as required by the designer of the form and user of the information provided. Input fields are available for each piece of data required, and generally presented in a question-answer style, similar to the look and feel of paper forms.
~~ -~hown

in Figure 2-4, a user would complete/fill in all of the required information in

this form to activate Windows. The form is organized using different steps. Each step pertains to related information that is needed to activate Windows. Some of the information is free form (email, phone number, credit card number, etc.) while other information must fit preselected data (location, expiry month, year).The drop-down menus for the location and expiry date ensure that

13

valid information is obtained. The program can only be installed if the user is at a valid location and the credit card can only be processed with a valid expiry date. The expiry date being a drop down menu also ensures there is no confusion of which values relate to the month and which relate to the year, thereby disambiguating the date. Once entered, the information is then processed through a database system and appropriate actions are taken (e.g., the user's Windows program is activated). The advantage of this type of form is that the information required by the company will always be submitted and typically, in a manner in which they are expecting, thus the company can access and direct the information as needed. A disadvantage is that users may want to provide additional information or their information does not fit naturally in the cells provided by the company. There are no alternative methods for communication. If the information does not fit, it cannot be sent. An example is that a telephone number is often a mandatory field, yet forms virtually never provide the option to indicate "TTY only" or "no telephone". Thus, forms will be rejected as having invalid information without this data.

14

Figure 2-4: Activation Form for Windows XP

Natural language dialogues, as a method of communication with computers, is highly desirable because it tries to emulate the way in which people communicate with each other using spoken or signed language. For the computer to be able to accomplish this would improve computer human interactions. However, to accomplish this the computer needs to be able to cope with vagueness, ambiguity, and ungrammatical constructions associated with speech. N aturallanguage can be used by a user to communicate with the computer as spoken dialogue (speech recognition) or as typed entries. Spoken dialogue allows users to communicate with the computer as if it were another person, but adds problems with speech recognition as computers must then be able to correctly interpret different accents and intonation associated

15 with speech. For speech recognition to be reliable, the computer must be trained to the voice of the user, though there is some reliability with untrained systems when the vocabulary is restricted or the words are uttered discretely. This makes it difficult for a system that needs to understand multiple users, as each must be trained individually, or short-term users, as training would be impractical for a system that would be used a limited number of times. Typing removes accent and intonation, but adds problems with spelling variations, mistakes and keying errors. N aturallanguage interaction is rare, except in the case where specific structured subset of natural language, a query language, is used. The rarity is due to the vagueness and ambiguity of natural language, and the computer's inability to interpret the natural language into the correct command. None of the interaction techniques offers one absolute solution to all user needs and abilities. As a result, often a hybrid of these techniques is required to suit users of all levels. For example, some users may find it easier to carry out selecting operations with a mouse and editing operations with a keyboard rather than through selecting a command from a menu.

2.2 Web Interaction Techniques
The Internet provides a method through which we can disseminate and manipulate information on any topic that can be located in different locations and shared remotely. More and more people want to interact with the information that is available through the Internet. For example, users want to ask questions, give more details, interact with others on the Internet, and manipulate the content in some way.

16

Interactivity is an important addition to a static website because it engages the user. A good web design includes a minimum of three interactive objects (e.g., search button, text box, or pull down menu) per web page [23].
An interactive web page uses many different mechanisms to enable that interactivity. For

example, the most basic level of interactivity is provided through hypermedia, which allows elements of the document to be linked together in a multitude of ways rather than the traditional linear layout [ 14]. Although hypermedia can appear as text, video, sound, or animation, the most prevalent form of hypermedia is hypertext, which commonly appear as the blue underlined clickable text, though other colours are becoming popular (see Figure 2-5). These links allow · users to advance to another web page containing the information related to that link by clicking, rather than by scrolling or entering a the new location as a command. There can be many links on a single page, each advancing the user to a different location within the web page, the web site, or a new site; the path through the site is chosen by the user, not the site designer. The power to pursue or ignore information is transferred to the user of the text or information from the text designer or author [24].

-·-""""

17
The Academics section has ft·o~ e quick-links that take you to the most commonly used academic activities:

o Search- to search for classes. Using this link, you can search for and select classes to add to your
Shopping Cart. }} See the How to Search for Classes job aid for details.
1 '1 The Search for Classes button on the right links to the same page.

o Shopping Cart -to build a class schedule that you can validate or "test-drive"' before enrollment. VVhen all
the classes validate, you can proceed to enroll in them.
:i> This is the easiest way to enroll in classes.

:: See the How to En ron (with validation) and How to Enroll from My Classes Offered job aids for details. o Enroll- another \V ay to build your class schedule and enroll in classes directly without validating the schedule and requisites beforehand. For students returning this year. this v;ill look similar to the RAMSS system that you used last year. See the following job aids for details: ot> How to Enroll (without vahdattonl
>'I

How to Drop a Class

}) How to Swap a Class

o My Academics- to go to the My .A.cademics page v.there you will
your academic record. Thes.e are d escribed in more detail belo w.

find more links that you can use to view

o Grades/ Standing- to view your grades standing and term GPA on the same page.

Figure 2-5: Hypertext from Ryerson University webpage

Menus, form-fills, direct manipulation, and query language are also very common types of interactivity present on web pages. Menus often appear as navigational aids, using hyperlink:s, as either text or images, to allow users to "jump" to different areas of the web site. These menus can be seen on web pages as left navigation, right navigation, top navigation, or bottom navigation (see Figure 2-6). The simplest is bottom navigation and it tends to be an inline list of hypertext. The top and side navigation often occur as hypermedia, where images are used as navigation indicators or hyperlinks.

18

Naviga

fh~sHarth

News fJ
Uncover

nwratiue offemale
.uthors
16A)1 /:)9 .. i~b¥~~ ,b;.';;.·;i_
be~~~ f<W'~l!.!ll<:l ~·xp!';'nn;,;
¢! ::.,i~-.... . . ·::tO\'¥f:; T<.~(0('!1W.
r..: ~~ ;~:'~:

om · fkn

::S..(~

,;::;

:f.~' -:.~~'x?r:~j;t::n:t.~-~:. .

:.

tot+..~w ¥.t¢~r~b~{~~ P~~~.:t~~·)~~~~yy (..«(rt.~ ~r~tr\~
dc~.Ct?~.;·;e~· y

Faculties &Programs
l> f ufl l..it\. i
l- F~.iC\~'i O! Art\1

2> Chtlr~ ~·.~(.'tl(~'J

lr:'!.WV Cc.'X'jrdfv..t::;Y.

~:'i:l~

TRlfC!l'"-''lliJ

> :S!u,1en: ti!m ~~l:r~$ at ~r-.ce Film

l>

Fe,w""''

l> f~y of Cc..nm~y
~OC,;t1>

F&.tu!!'!' wf Cti'lltrMric~k-:Jn 3. PM1.J!'l Service£'

> f~:;;;l(y (';f f:l'lgil)l.~""t\,, AICtlit<\'.;;t,J!I,· ;~·;d
> 1~4 R<>;:W<) 5d~{¢f M-~·<l>t'li
l>

lJn!IMq,f.ld!ft.ite PN:;r--('lm S~M¢h

Campus Ewnts ~
) fN:vJ. f.>fl Pui'AV; (; (O!ll!Ol.iM.y f><J;yj(;"~
C~¥. ~.~!:

> Sct'I'X-" t:f ~·;r~.> :'>!u&es > Cori!itr,,,..,, f:)J<.~<."Mfum > ih<e (1;6,')9 Sc~l CotP.~!! C:\V~ier

F,:,lr

Top Searches
> OPAiOr<"octe Poirt Avertoge

r~)l £~y~3

""The Moveable hast

, for colaboretive .n~J.

n e e

> (~1\Y.WI· C:'>it;nd!l!
> NVf'::.\i!'p)1
) f·toi;'-l;li()!',

~~(ltilqf). ft~1~

) ff;ttS;
l> lt~'l'-~:rir;tt<

·· ·· ·· ·
IH()tt4[)m

alon

> l.lhrury
~ !:':~1\:"..it·~, M~..il

> ~ar.tOtlie t

> E!ootd,;:;re

Navigation

Figure 2-6: Navigation on Ryerson University web site. The circles show the top, left, and bottom hypertext navigational links.

Query languages are used to search out web content, allowing users to find the information they require without moving linearly or using hyperlinks to search through the sites content. An example would be how searches are carried out in Google where a user would enter in keywords as text. Form-fills are used for many different applications, from requesting information from the user to the user requesting information from the site owner. An example would be when a user

19

must register on a website to gain access to web content such as pricing information, discussions or e-commerce activities.
An important interactive component of form-fills is the ability for web site owners to

request data from site visitors, for site visitors to enter that data, and then process it into meaningful information that can be feedback to visitors or used to activate services. This includes asking and answering questions of visitors, providing feedback regarding status of data entered by visitors, and retrieving and manipulating the entered data for other purposes such as to process orders and payments. This is the focus of this thesis.
An email link on the web site is one method of asking visitors for feedback and

information. However, one problem with this method is that users will provide any type of feedback and it may not be the desired information or have enough specific details that would make it useful to the site owner or visitor. Also, when users want to ask questions of the site owner, the initial communication will often be vague and require follow up communication which tends to result in a back and forth question/answer dialogue through email. This can cause frustration for the site owner and the site visitor, as the visitor's questions are not answered in a timely manner, and the owner may be required to spend a large amount of time asking for further information and clarification of the question asked by the visitor. The owner will be frustrated in that they do not know what the user wants and cannot provide the correct information quickly, and the user will be frustrated because the site owner is not answering the question in a timely manner. A better method of communication in order for the owner to solicit specific information from users would be a simple form that allows the owner to request detailed information, such as specifics about a problem. In this way, the communication is more direct and causes less

20 confusion for the site owner and the user, as the information required by the site owner is listed for the user to include. For example, the users' information (e.g. name and contact information) and information to help direct the query to the correct department (technical support, billing, customer service, etc.) can improve the timeliness of a site owner's response. Web polls are a form of entertaining web survey. The primary goal of these polls is as a forum for exchanging opinions [25]. These polls often produce running tallies of results, as they are collected. Web polls will often appear as a question of the day, such as CTV Toronto's Talk Back Toronto (http://toronto.ctv.ca) or CityNews' Latest Poll (http://www.citynews.ca) (see Figure 2-7). These simple forms allow visitors to become involves in the content of the site.
LA.TE::n Pt]LL
archive »

Is
·

th~ o:itol

rnamt~in

doing enough tc· fi:~; and the infr .::s:::tr··Jctute?

POLL

Yes, t.he·;~'re doing their best

· · · ·

No, Toronto is f~llin9 ap .::srt Onl·1 in some p.stts of T.O. Theo.,· ~~ .::s:::te money on other thing5 Othet'

When have you most depended on Dave Devall's weather forecasts?

O 0

Winter Summer

&mill
See Results Email us your comments at talkbacktoronto@ctv .ca Read/leave comments

CityNews Latest Poll

CTV Toronto Talk Back Toronto

Figure 2-7: Question of the Day Polls for (a) CityNews [26] and (b) CTV Toronto [27] for February 3, 2009
Another common type of form is user registration. Web sites often require users to register in order to access certain content. Web site registration restricts access to some of the content of the site to control access to the information. The web site asks for some information from the user, generally name, email and other demographic information that may relate to the usage of the site, and then the user can access the additional information.

21 Question and answer bulletin boards are another example of interactive use of forms. Bulletin boards are repositories of questions posed by users and the answers provided by the site owner or other site users. Bulletin boards allow users to find solutions to problems that they are encountering by posing publicly available questions to the general population of users of that site and receiving publicly published responses [24]. Individuals send messages to a single computer address and the bulletin board software then posts these individual messages so that visitors can access and read them at their discretion. In this way, a bulletin board functions like the kiosks or wall-mounted bulletin boards you see covered with public announcements. Unlike these cluttered presentations, electronic bulletin boards organize incoming materials so that subsequent messages responding to previous messages are ordered one right after another, in a thread. Each thread can continue to extend for as long as contributors send in submissions. These threads practice hypertext in that contributions layer on and reflect back on one another [24] . Communication tools, such as MSN, email, Skype, provide other important interactive techniques for the Internet and Web that enable users to communicate with its owners using asynchronous and synchronous methods. Synchronous communication occurs when all parties involved are present at the same time. The message tends to be more conversational in nature [24]. Examples include chat boards where all parties are communicating with each other usually through typing or audio/video (webcam and microphone) at the same time, and instant messaging where parties are chatting one on one. Figure 2-8 shows two example windows for Windows Live Messenger, an instant messaging program where two parties can connect through the messaging service. One party can type and send a message to the other party, who is then notified of the message. This service is more immediate than email, as all parties are aware of the communication and are connected to the service at the same time. The flow of messages is

22
similar to a face-to-face conversation, as opposed to email where there is time difference between the time of messages being sent and received. Asynchronous communication does not require that all parties involved in the communication be present and available at the same time; messages are sent at one time and responses can be sent at some later time. Examples include email where the receiver is not required to be logged on when the sender sends the e-mail, and discussion boards where users leave messages that are answered later by other users. This form of communication allows conversations to evolve and community to develop over time [24].
An online form is an example of an asynchronous communication structure because the

user can enter information in various fields in order to make a comment, ask a question or place an order. Some fields are required in order for the information collected to be emailed to the web page owner.

Figure 2-8: Windows Live Messenger

Interaction is an important part of the Internet experience. However, many of these interactions are less or not accessible to those with disabilities for many different reasons. While some interaction techniques allow use of video (e.g., some instant messengers applications allow video conferencing and messaging), many require text use or a combination of text and other media. For sign language users, the text-based interactions can be less accessible because it is

23 experienced as a second language by those users. For the most part then, we suggest that sign language is generally limited as a language for communication.

2.3 Computer-based Representation of Sign Language
Since the beginnings of the WWW, people have used the hyperlink and multimedia tools available for web development to display sign language online. Much of the sign language online, however, consists of text descriptions and lexicon style pages with static graphics showing various elements of sign language (e.g., hand position, facial expressions, etc.) with written language definitions of the signs, similar in appearance and presentation to a paper-based sign language dictionary [28]. With the advent of high-speed Internet capabilities, good quality animation and video content has become a reality and, as a result, sign language video or animation has populated the WWW. On YouTube (http://www.youtube.com) there are currently over 43,000 videos with sign language as part of the title, description or tags ranging from sign language lessons to songs performed in sign language. Online sign language materials are often surrounded by text-based interactivity such as navigation, forms, forums, and blogs. Even Y ouTube, which is a site for housing video materials, is only searchable using text labels. The links for feedback and comments as well as the comments themselves can only appear in text form. While captions are a good visual representation of sound content, a better alternative for many deaf individuals is a sign language interpretation. Much information is lost in captioning: tone and pitch of voice, background music, environmental sounds, noticeable pauses, etc. (CNICE Guidelines [29]). This textual representation of the sound provides an incomplete

24
representation of the message that is being presented, which leaves people who are deaf at a disadvantage. Not only is there a need to read text to be successful in conventional online settings, but also there is often a need to respond using text input. Various types of interactivity such as surveys, feedback forms, forums, chat and blogs require text input. In order to answer questions for surveys or web polls, deaf individuals may be required to concentrate harder to interpret the information requested by a web form, and then respond appropriately in written form. Often, their written communication can come across as simplistic or uneducated which can result in their communication attempts to be misdirected, misunderstood, or ignored [3]. Currently, the move to make websites more accessible for deaf and hard of hearing people is focused on increasing the amount of text, in the form of captioning and description of sound events. There are several examples, however, of web sites that attempt to feature sign language as the dominant language, including the Deaf Culture Centre website, where information is presented in ASL/English and LSQ/French [30]; SignPost BSL, where the English text is translated into British Sign Language (BSL) [6]; and Sign Community, the British Deaf Associations (BDA) official site, where information is presented in English/BSL [7]. In all of these sites, the information is presented in text with a video of the sign version. The Deaf Culture Centre's website does have an introduction page that is flash based and contains sign with no textual content; the content is a series of actors who sign the content on mouse roll over (see Figure 2-9). However, when you follow the link you are returned to a textual site with the same video clip and the navigation being in text (see Figure 2-10). The BDA site is predominantly text with a sign video off to the side that translates the contents of the site (see Figure 2-11). The

25 SignPost site takes a slightly different approach; the sign video is more prominent than the text content, however the navigation features are still predominantly textual (see Figure 2-12).

This site requires ,Adobe Flash Player.

fJ

f) Canadian Cultural Society of the Deaf, Inc. 2008

Figure 2-9: ASL main page for Deaf Culture Centre

26

I've gathered aH the best Deaf links for you - Deaf school, sites, clubs, sports, organizations and more. Take a look and let me know if I missed
any!

Terms of use ) Disclaimer

! Contact Us

Figure 2-10: Deaf Culture Centre Community page containing text navigation along the left side and top panels.

27

Figure 2-11: SignPost Homepage

. . =

t

'

~

8riiJsh Delf Association
Brilllh Sign language
~

Welcome to the British Deaf Association
You've found your way to the BOA's ollicial website and to thP. home of th" larg.,st UK Deaf organisation run by Deaf people for Deaf people. You11 find all the lat..st news and information her.,, along with a list of the BOA Board of Trust.,es and a regular monthly feature from our Chair, Francis Murphy. Click the menu buttons on the left to lind out what the BOA can do for you and how you can access the

BSL Acildemy
Learn 10 Sign Week

Campaigns

Services and Projects Youth end Family
Members login

latest news, information and servlce5.
To find out more about becoming a member of the BOA ~li.<;;kt!~{~

Regialnlllon
Join us

Latest News

(for R.ewioDaf.._·, srl~-~~~.-'-1!£ k..~~ tlaea

..._ct the .,..to· on lite &.ft..,.,..}
Sponsored Unks
~iw.t:.i9.l.!l.l.i~.l!li.JoJ~rv..~:~:.ti!l!ii..III..Jr.~iu.i.ng
l\(.;l, ,.tY..OLPr~~1lol1~

R.-rces
Training I Events British Deaf News
BoardofTruSIBel
l..~~nLtQ.. S.km ..W~.ek. 2Q09.. ~ii.~J.mJ!~~

Area Deal Asaociati<>ns
Donations

·

During thts year's nat10nalleam to Sign Week camp . a . ogn, which tak"s place 5th- 11th OCtober, we hope to get ev"n more people involvad in learning Bntosh Sign Language, with raising funds for the British Deaf Assoc~at:IOn . 08 .20~J9

Good t"ijfb Cntofggue

Vacancies
Web Directory

National BSI. (: barter ConferP..nce at Bristol City Council
Bristol City Council hosted the BSL Charter Conference on Tuesday 17 March 2009 to celebrate the Government's ree<>gnition of British Sign Language as a language in its own nght. t)B ~l;::r ?:r·o~·j

Feedbac.
Contact Us

·

W.l:!i!t:5... Y.Q.II.r...£b4.r.i1¥. .QLt.I:!~.. Y..e#.r..?.
If you're a school or organisation, why not adopt the Bntish Deaf Association as ynur Charity of the
Year?

·

'
.

. CHARITY ">-l:tl~i':4

Fat Well and KMP llfi'lthv .... lf..the ..thouah.t.of ..oroe.mo[e.dlo..:.olit.te..Eilster.. eoo.. miill.'il:a ..~au.Ieel .ill.alld ..llou\t.e.. ay_ erif.lduloed.. lhis ..EilsteL .....

Figure 2-12: Sign Community page

28

Researchers and users have begun to explore new ways to take advantage of the increased capacity and more sophisticated WWW and Web 2.0 technologies and tools to create more representative and realistic sign language materials. For example, to create a teaching tool that improves on the 2D drawings typically found on HTML websites, [31] used Virtual Reality Modeling Language (VRML) to display 3-D models of manual alphabet hand shapes on the web. This allows the user to view the hand shapes from many different angles, making it easier to learn the manual alphabet than from the 2D drawings. The images created however, are still static, which causes some problems in the display of letters, such as J and Z because they are dynamic movements in the North American one handed manual alphabet. In this case, the sign can be viewed as a series of static images for the different positions of the sign. The user can see what the final shape should look like, but cannot see the dynamic nature of the sign. The limitations of this system are recognized by [31]; it does not allow for both hands nor allow their movement with respect to the body, posture, and facial expressions. This method may make learning the manual alphabet easier, but does not allow for content that is more complex as is required in for web content. The work in [32] expands on the work of [31] by creating an algorithm that combines the different static VRML images to produce dynamic gestures. The VRML images of the hand shapes were used as key frames in the animation. The signs were still limited to the manual alphabet; ti<Jwever, users were able to view the finger spelling of strings of letters. The authors have indicated that they will be looking into including the second hand as well as face and body of the signer in the VRML world to allow for more signs [32]. The work of [31] and [32] was limited to the single gestures of the manual alphabet. In addition, this work required the CyberGlove, which is a specialize technology that records the

29
positioning of the hand. The CyberGlove is expensive and requires additional software in order to translate the measurements into VRML files so it would be costly for individual users or web designers to make web content using this process. Furthermore, this requires a text based navigation system. A system to generate sign language from simple 3D models of the upper body and present signs as line drawings was designed and implemented by [33]. The system used sets of static gestures of both hands, the upper body and facial expressions to act as key frames. The specifications of the static gestures were applied to the underlying skeleton of the 3D model. In this way, they were able to create a wide range of signs. The system has received encouraging remarks from teachers of sign language. However, they did not allow for additional signs as defined by a user, nor for sign based navigation. Thus, the vocabulary is limited at this time, as each sign must be encoded manually. In addition, to navigate, users must switch to a textual language. While the use of the 3D modeling increases the possibility that full signs could be available on the web because facial expressions and body postures can be included, the programs and tools required to produce 3D sign content for the web are highly complex. Novice users may have considerable difficulty creating personal content for the web, not to mention getting access to such programs. In addition, it is still necessary to switch to a textual language in order to navigate the web. Learning these modelling tools also would require reading written reference materials and using concepts above the typical education level of the deaf population.
In order to generate an avatar representation for more than a single sign, we would need

to digitize full SL including handshape, orientation, movement location, speed and repetitions, and grammatical inflection via facial expressions, where a live performer and substantial motion

30

capture capability would be required. A simpler and perhaps more realistic method of creating sign language webpages is to video record real people signing the web content. This way all of the components of the language are completely captured and can be adjusted and embedded online using video editing software and standard or specially developed webpage design tools. SignLink Studio (SLS) is an example of a tool designed to create web content in sign language without the need for text [12]. This tool allows web page designers and owners to create web content and links in sign language. Sign language content in SLS is processed as video material. Currently, the only web interactivity that can be added to the sign language video material is video-based linking mechanisms. Video links, called signlinks, can be created within the sign content using SLS so that there is no need for text-based links (see Figure 2-13). The content can then be published as a sign language webpage (see signlinkstudio.ca for an example). The main content of the site is played through the video. All of the links to other information, within the site or external, are listed below the video content as signlinks. An optional text editor is included but the intention is to have this complement the sign language rather than dominate it (see Figure 2-14). This allows non-signers to be able to access the webpage without emphasizing the text material. The text material is an interpretation of the signed content, and any links within the text material must be signlinks. In this way, the text complements the sign content, as opposed to forcing the switching between languages. Because all navigation is now through the signlinks, no text navigation is required. All navigation is now embedded within the sign language video.

31

Figure 2-13: SignLink Studio webpage

Welcome to the community section of ASLpah.ca. Ths is where you can view signed web ~that other people have uploaded. You can also upload your own web pages if you become a member of ASLpah.ca. Becoming a member is free. You can register to become a member here.

i

!

Webpages

Figure 2-14: SignLink Studio web page with optional text

32 Though SignLink Studio gives sign language users a tool to create web content in sign language, it still requires much work before it enables novice web programmers to create fully functional web pages that applications such as Dreamweaver or FrontPage allow. Further work is needed to allow for more dynamic elements such as menus and forms, and style elements, such as colour and additional pictures in order for web users to have a complete web experience in sign language. One of the challenges that has been identified by the SignLink Studio researchers is the ability to incorporate levels of vividness and interactivity that traditional media cannot. This is considered a vital component of any modem website [34]. A common mechanism to allow this type of interactivity is forms (see Section 2.6 for further description). Surveys, signup or login mechanisms, and search mechanisms are a few of the different implementations of form functionality. All of these mechanisms require a way of requesting information from users, storing the responses in a searchable database and then generating reports of responses so that they can be acted upon either by site owners or by some automatic reply system. Currently, in order to do this, a text-based system is required as there is no simple method for the capture, storage and retrieval of information from the web user in sign language. Studies have also shown that the ASL Web was innovative and enjoyable experience [12]. Studies of the task of creating sign language web pages using SignLink Studio have shown positive results. By the end of the study, all participants were able to successfully create a
_,- ~

signlink, save a project and export a web page, indicating that the software will most likely be accepted by the community [35]. Users, in general, seemed to like the functionality ofSignLink Studio and were able to understand the purpose of the authoring elements.

33

The research on sign language has shown that the Signlink Studio design of sign language web sites is acceptable for the deaf community [ 18]. One natural extension for SignLink Studio would be to incorporate sign language form design, creation and deployment for allowing visitors to interact with the website content. This functionality would allow designers to make questions in sign language and then receive answers in return in sign language. The answers should be searchable and archivable.

2.4 Survey Design
A survey is a tool for eliciting information from people, which you can tabulate and discuss [36]. It can help obtain information about what people do, what they have, what they think, know, feel, or want [36] through a set of questions that can be answered by a person or respondent. Questions in a survey generally fall into two category types: open-ended or forcedchoice. Open-ended questions allow respondents to provide their own answers in free form either written or spoken/signed. This gives people the opportunity to express their own thoughts, but also requires more effort because they must compose and write an answer in some form of sentence structure. Open-ended questions tend to produce large varieties of answers and as a result can be more difficult to analyse [36]. Forced-choice questions provide a set of possible responses and respondents select either one or multiple responses from the set. These questions produce more uniform answers than open-ended questions, but depend on the author's knowledge and inclusion of all relevant and possible responses in a way that is not biased or skewed to one answer or another. Responses must be as complete as possible and mutually exclusive in providing for the selection of a single

34 response as prescribed by [36]. Examples of forced-choice questions include dichotomous choice questions (yes/no, male/female), check lists, and scales. Scales ask the respondent to rank some trait or ability on a continuum of possible responses. The most common types of scales are Likert scales, Guttman scales, and visual analog scales. The Likert scale presents a set of attitude statements, and respondents are asked to express agreement or disagreement on a five-, seven- or nine- point scale. Each degree of agreement is given a numerical value and thus a total numerical value can be calculated from all the responses. [3 7] The Guttman scale presents a set of items on a continuum or may use statements ranging from one extreme to the other. When a person agrees with a statement, it can be assumed that he or she agrees with all previous questions in the scale. The scale is cumulative. So a score of 5 would indicate an agreement with statements 1 though 5 [38]. The visual analog scale is designed to present the respondent with a rating scale that has few constraints and is easy to use. Respondents mark the location of their response on a continuum corresponding to their perceptions of the phenomenon.[38] There are a number of methods for deploying surveys: person-to-person interview, paper, and online. In person-to-person interviews, the researcher or an assistant asks the respondent the questions and records the answers. These interviews tend to be more conversational, with the interviewer directing the respondent towards the information required. For a paper survey, the respondent is given a set of questions and fills out the appropriate answers. Paper surveys have an advantage in that they can be mailed to the respondents who then return them to the researcher. In this way a broader population can be reached. Online surveys are relatively new. They started out similar to paper survey as emails sent to respondents with the questions in the body of the email or attached as a file that are answered and emailed back to the researcher.

35 Online HTML forms have allowed for internet surveys where respondents visit a web site in order to complete the survey. Currently, surveys tend to be administered to deaf participants by using an interpreter in a person-to-person interview or by paper survey. There is no method available to create sign language surveys online or to understand preferences and needs for this population of users. Difficulties in creating sign language only websites make it difficult to incorporate a method for asking and answering questions in sign language on the web. In addition, there are important technical difficulties that constrain the methods that can be used to store, retrieve, search, and present the sign language data. My focus is on online surveys that are sign language accessible. There is a considerable quantity of research on paper-based questionnaire/survey design but relatively little on the design of online questionnaires. In addition, most of the work and resulting design criteria for paper-based and online surveys has focused on using text for the questions and possible responses although there are some tools that allow moving icons for responses (e.g. Quask.com). There has been a dearth of research on the use of sign language in questionnaires. Because of the lack of research on using sign language for questionnaires, I will present the research and resultant guidelines for text-based questionnaires. In order to produce a set of online questionnaire guidelines, [39] summarized existing guidelines for paper-based questionnaire design and website design, paying particular attention to issues of accessibility and usability. In addition, [39] examined the existing onlinequestionnaire design guidelines. From their analysis, they proposed a set of guidelines for online questionnaire design, where approximately 33% of the guidelines are derived from paper-based survey design principles. However, the current design of online surveys typically replicates the

36

look-and-feel of paper-based questionnaires, thus failing to harness the available interactivity of the electronic survey medium [39]. Web based surveys allow automatic verification and survey response capture in databases. Other advantages over paper-based questionnaires include cost, speed, appearance, flexibility, functionality, and usability. They can also use pop-up instructions and error messages, incorporate links, and encode difficult skip patterns making such patterns virtually invisible to the respondents [39]. This creates a more dynamic survey environment for a respondent. There are seven forms of online surveying as reported by [40]: (1) e-mail (text), (2) bulletin boards, (3) web HTML, (4) web fixed-form interactive, (5) web customized interactive, (6) downloadable surveys, and (7) web-moderated interviewing. E-mail was one of the earliest methods for conducting surveys over the internet [40]. Similar to traditional mail survey, there are few, if any, interactive controls or logic testing. This method of data collection has difficulties in that data entry is not automated and participants are able to change the questions in order to tailor the question to the answer they wish to give [41]. Surveys may be administrated on bulletin board by inviting respondents to a web site where a discussion topic is posted. As people respond to the questions, others can eventually see commentary and then respond to the original responses. In this way, the thread of the conversation weaves back and forth like a slow-motion focus group. Bulletin board surveys are not difficult to begin, but they require more skills on behalf of researchers in order to control the flow of the thread to obtain the necessary information from respondents than creating an e-mail survey. Unlike other online forms, there is no automated data accumulation.
Conseque~tly,

5
I

1: "

~

c i

· r i

.

the cost of this technique is somewhat higher than e-mail, but it is

37 still beneficial for certain cases, such as bringing together a panel of experts to post reactions and discuss impressions with others. The most common form of on-line surveying is web HTML, in which the survey is presented as a standard HTML form. Almost 80% of all survey data being collected online uses these forms [40]. These surveys often take the shape of a long, single page on which the respondent clicks buttons and boxes, fills in text boxes, and eventually submits the information all at once. Although these surveys have no true interactive controls (no true skipping, no way to limit answer choices, no real-time error checking, etc.) there is tremendous flexibility for designing questionnaires. Graphic, audio and video clips, animation and other multimedia forms of stimuli can be used. For simple studies that do not require complex logic, the HTML formbased survey can be faster, lower-cost alternative to more sophisticated techniques. Web fixed-form interactive authoring tools have been developed from previous generations of software used to conduct computer-assisted telephone interviews or mailed studies [40]. They have been adapted to "play" questions on the web the same way they would play for an interviewer during a telephone interview. Using these tools to create the survey does not always mean that the researcher can control the whole research process. Web customized interactive programming is the most powerful and flexible of all online surveying options [40]. These involve custom programming that is more time-consuming thus tend to be the most expensive option. They provide all the modem technical controls (screening, skip-patterns, logic, error checking, etc.) and offer many other options that allow the researcher the highest level of flexibility for design and functionality. Web moderated interviewing is a form of qualitative, real-time chat interview. These are sometimes referred to as "online focus groups". The key benefit of chat interviews is that it is

38
highly related to the non-physical nature of the medium. By conducting discussions online, respondents from different regions can be brought together quickly with no facility or travel expense. Session moderation fees are generally higher than those for traditional focus groups are though the fees are usually offset by the previous cost savings.

2.5 Online Survey Tools
Web based instruments are available to create online surveys (Survey Wiz, Survey Monkey, Zoomerang, QUIS, SurveyPro, Quask, etc.). There are two main types of web-based instruments: online and combination online and offline. Online tools (e.g. Survey Monkey) allow for the creation, distribution and data collection of a survey using an online tool that is accessed through a web site. Combination tools (e.g. SurveyPro) require that you download a software suite in order to design and distribute surveys, and to analyse the data resulting from deploying the survey. These types of tools tend to be more costly than the online tools, which often have a free version that can handle small surveys. Survey Monkey (http://www.surveymonkey.com) is an example of an online survey tool.

It allows users to create professional online surveys without any programming knowledge or
skills. Using just the web browser, surveys can be created using a survey editor, which allows for different types of questions such as multiple choice, rating scales, and drop-down menus (see Figure 2-15). Options allow survey designers to require answers to any question, validate the answers entered, control the flow with custom skip logic, and to randomize answer choices to eliminate bias. It is possible to change the colour, size and style of any element of the survey, as well as include customized graphics. Surveys can be distributed using an email link, adding a link to a blog, or sending survey invitations using the list management tool. The list management

39

tool allows users to track who responds, send follow-up reminders to those who do not, and manage opt-outs automatically. Survey Monkey also gives users the option to save their survey as a PDF for offline distribution. Survey Monkey also has reporting tools that allow users to view graphs and charts of results and explore individual responses (see Figure 2-16). Results can also be shared with others. Filtering and cross tabulation allows the results to be displayed using simple descriptive analyses. Results can also be downloaded in multiple formats such as spreadsheet, HTML, XML, PDF or just the raw data.

Please let us know what you think about our web site.

*

1. How did you first learn about SurveyMonkey?
. ...) Took someone else's survey

J J ,J
.J

Banner Advertisement
Search Engine
Referral/Link from another site

Magazine/Print Advertisement

~J Other {please specify)

Figure 2-15: Example SurveyMonkey.com question

40

Took someone else's survey

l :>tC>tVtiW:.Jw1<·~l ~
f"~·i®:~irt\AA)

3l.OS
5.3%

70912 11409
33499 31595

Banner Arlvertisement
Search Engine

15.6%
14.7l!b

ReferralJiink from another site

J!m::Mlixt¥11
~

Magazine/Print Advertisement other (please specifY)

5.4%

11625

26.141(,

56135

Figure 2-16: Example SurveyMonkey.com survey results SurveyPro (http://apian.com/software/surveypro/) is a comprehensive survey software suite. It includes questionnaire design, an integrated database, and a sophisticated reporting and analysis engine (see Figure 2-17). SurveyPro allows users to distribute surveys on the web on a local area network (LAN) at a kiosk, or on paper. Web surveys can be hosted using a Windows ASP server, or the SurveyPro server. Web features include skips and branching, bringing in data from an outside database or from responses into later question text, and for required questions. It has diffe:tet!! password/login choices, progress bars, and the ability to pause/resume (respondents can leave and return with answers saved). SurveyPro can randomize of questions within a grid and checkboxes within a scale. Data can be archived daily, weekly or manually as required.

41

Hello, Joe Smith. Please Answer the questions below.
How often do you participate in alumni events in your area?
More than once a month

r

More than once a year Less than once a year Never

When was the last time you attended an alumni event?
Select One

What type of alumni events are currently held in your area? (Sele.ct all that apply)

u
LJ

Social gatherings Continuing education/seminars Volunteering/ community involv ement

u
LJ Cl

L~J Fundraising

Family events
· ······· ·· ·· ·········· ··· ·· · ··· ···· · ·········· · ···· ··· H · ························· · ············ ··· · · H · · ························ ·· ·· ··········· ··· ··· ·· ··· · ·········· ·H·o0ooo·oooo······· ·· ·····················o ··oo·· o··oo·ooo·oooo···o·· ···· ··· ········ ········ · ···········,

Other:

How interested would you be in attending the following types of events?
Very Not Interested Interested Interested Uncertain

Social gatherings Continuing education/seminars

f)
()
£.~~)

Ci
C~:J

0
()
e~:::

C)

c:::
("~)

Volunteering/community involvement
Fund raising

(~>

()

Family events

e;

t)

What one suggestion would you make for improving the alumni assodation in your area?

Figure 2-17: Example SurveyPro survey SurveyPro has an emailer that sends email invitations, reminders and thank you messages. Results can be viewed as charts and tables (see Figure 2-18). Results can be published to the web using HTML or PDF. SurveyPro can filter results, perform cross-tabulations, and subgroup analysis.

42
Percents Counts

8.8 More than once a month t-1ore than once a year 28.8 22.5 18 Less than once a year Never 40.0 32 100.0% SO o 10 20 30 40 5o Totals Figure 1: Q2: How often do you participate in alumni events in your area?

23;;;~

758.7 30.7 14.7

Percents Counts Social gatherings Continuing education/seminars Volunteering/community involvement Fundraising Family events Other Totals 44 : : : : : · - - · 23 1161 2I ----------

81.3 2.7 25.3

1911!~~!.....-............,.-~...,........,-..,......,.
;;;
20

60

80

100

'" Multiple answer question so totals not meaningful. Figure 2: Q3: What type of alumni events are currently held in your area?

Percents Very Interested Not Uncertain interested interested Social gatherings Continuing education/seminars Volunteering/community involvement Fundraising Figure 3: QG 1: event interest 20.8

Counts Very Interested Not Uncertain interested interested

36.1 16.7 17.6
40.3

45.8
27.8

1.4
25 .0

15 22 10
23

26 12 12 29

33 20 18

30.6
14.7

64.7 22.2

2.9
5.6

44
16

2
4

31.9

Figure 2-18: Example SurveyPro survey web report

Survey tools also remove a lot of the manual construction and administrative challenges. The forms are already created for you and the underlying scripts to collect and verify data are written. Time and money associated with feedback publishing, and survey collection is saved [42].Web based surveys eliminate the time and expense of data entry by the research because when a person responds to a question, the data is automatically entered into an electronic database/spreadsheet [42, 43]. Time consuming data entry errors can be eliminated through automated data checking at the time of data collection and administrators have immediate access to data as it is received, allowing for the tracking of data as it is received [42]. Programming a web-based survey can be costly, particularly if the instrument involves complex skip patterns or elaborate design elements, as more time and possibly further software are needed to program and test the survey. However, web-based surveys reduce the cost of

43 running the survey because it is independent of the number of respondents, so does not increase with the number of respondents. In addition, the cost for entering data is removed, as the data is entered automatically as the respondent moves through the survey. In order to design online tools for creating the forms upon which surveys are based, it is important to understand the various components and controls that comprise them. In this next section, all of the various elements of online forms are outlined.

2.6 Online Forms Elements
Online forms are used to ask visitors about their experiences, to receive feedback and to allow for the interaction between site owners and visitors. With online forms, instead of going to a survey site, the form fields are embedded into the actual website. In order to incorporate online forms onto web sites, standard HTML form elements are required [44]. An HTML form is a section of a document containing three elements: content, markup, and controls (checkboxes, radio buttons, menus, etc.). Users "complete" a form by modifying its control elements (entering text, selecting menu items, etc.), before submitting the form to an agent for processing [44]. In textual languages, these are relatively straightforward tasks because of the ease of creating a character set based on the alphabet; the controls can be labelled in a similar way as the text questionnaire labels, check boxes and selection mechanisms. The character sets are mapped in such a way that the information can be sent easily.

2.6.1

Form Controls

Users interact with forms through named control elements. These elements are named through their name attributes. Control elements can only be accessed within the form with which they are associated.

44 HTML defines eight control types: buttons, checkboxes, radio buttons, menus, text input, file select, hidden controls, and object controls [44]. Most controls are implemented with the
input element/tag.

There are three types of buttons: submit buttons, reset buttons and push buttons. Activating a submit buttons submits the form responses to the database. A reset button resets all controls to their initial values. Push buttons have no default behaviour. Each push button may have a script associated with the element's event attribute to be triggered when the event occurs (e.g., the user pressed the button, releases it, etc.). Checkboxes are on/off switches that may be toggled by the user. A switch is "on" when the control element's checked attribute is set. When a form is submitted, only "on" checkbox controls can become successful. Several checkboxes in a form may share the same control name. This allows the users to select several values for the same property. Radio buttons are like checkboxes except that when several share the same control name, they are mutually exclusive: when one is switched "on", all others with the same name are switched "off'. Menus offer users options from which to choose. The select element creates a menu, in combination with the optgroup and option elements. Authors may create two types of controls that allow users to input text. The input element cfe1ttes a single-line input control and the textarea element creates a multi-line input control. In both cases, the input text becomes the control's current value. File select controls allow the user to select files so that the contents of the file may be submitted ~ith a form. Hidden controls are controls that are not rendered, but whose values are submitted with a form. Authors generally use this control type to store information between

! :
i
I

e

i

~

45 client/server exchanges that would otherwise be lost due to the stateless nature of HTTP (e.g. ip address). The object control is a generic control that allows for additional information to be submitted with the other controls. Examples of object controls are images, audio clips, videos, Flash and ActiveX. These objects require additional parameters in order to operate and can append additional data that which is submitted.

The Form Tag
An HTML form requires a form tag. This wrapper tag tells the web browser where the form starts and ends. It acts as a container for the form holding the text and markup (paragraphs, lists, etc.) in addition to the form controls that make up the content of the form. To let the browser know how and where to send the completed and submitted form there are two attributes of the form tag are specified: action and method.
Action

is the URI (universal resource identifier) or address of the script to which the

content is directed. The method specifies which HTTP method will be used to submit the form data set. There are two methods available: post and get. With the post method, the form data set is included in the body of the form and sent for processing whereas the get method appends the form data set to the URI specified by the action attribute, and this new URI is sent to the processing agent. If processing of the form causes side effects (for example, if the form modifies a database or subscription to a service) the post method is used, otherwise the get method is used. The get method restricts the form data set values to ASCII characters. Only the post method allows the entire character set. Since for sign languages there is no ASCII character set, there is no simple method for transmitting sign language responses using the existing form implementation.

46 The Input Tag The input tag creates a variety of different form controls. This tag is used to create different input controls based on the value of the type attribute (see Table 2-1). Different input types are displayed in Figure 2-19. For input tags, there are a number of attributes that are needed including name, value, size, maxlength, checked, and src. The name attribute gives the control a name and is required. The value attribute provides the initial value for the control. This attribute is necessary for the types radio and checkbox. It is optional for all other types. The initial width of the control is provided by the size attribute. The width is given in pixels except when the type attribute had the value text or password. In that case, its value refers to the number of characters. When the type is text or password, maxlength attribute is used to specify the maximum number of characters the user may enter. This number may exceed the specified size, in which case the text will scroll. The Boolean attribute checked specifies that the button is on (selected) when the type is checkbox or radio. When the type attribute is
image, src specifies the location of the image used for the graphical submit button.

I
I

l

Value of type attribute
:.·,~ext

Control Creates a single-line text input control ($¢e Fig(Jfe l~'19{f>l~ncf(d1) Creates a single-line text input control where the input text is rendered in such a way as to hide the characters (e.g., a series of asterisks). The current value is the text entered by the user, not the text rendered (see Figure 2-19(b)). Creates a checkbox (see Figure 2-19(a)). Creates a radio button. (see Figure 2-19(c)). Creates a submit button. (see Figure 2-19(d}). Creates a graphical submit button. The value of the src attribute specifies the URI of the image that will decorate the button. Creates a resetbutton. Creates a push button. Creates a hidden control. Creates a file select control. The value of the value attribute is the file name.

password

'.. ·

i .,

'

t

,

I

checkbox
radio ' Submit image

~·.reset
button
N~idden

file

Table 2-1: Values of type attributes for input tag

47

I nave a bike: D I have a car: C:J I have an airplane:

(a) Usemame: username

Password: ········
(b)
Male Female

(c)
Username:

(d)

Figure 2-19: Form input tags: (a) checkbox, (b) text box and password, (c) radio button (d) text box with submit button

The Select, Optgroup and Option Tags
The select tag creates a menu (see Figure 2-20). Each choice offered by the menu is represented by an option tag. A select tag must contain at least one option tag. The optgroup tag allows authors to group choices logically. This is particularly helpful when the user must choose from a long list of options; groups of related choices are easier to grasp and remember than a single long list of options [45].
Here are some Related Responses:

'i

l

I

'I·

1[9i?.::Y.i?.:~:F~Y.~:: ~n::I6~~r6:~6IP.::P.i:9.:9:~:~:~?.:::::::::::::::::::::::: : ::: : : : :::::::J:,.~: · 1.. ok .I
~~

v

~

-

~

~-

~

-

-

~

~

-

~-

y

~

~~

-

Do ·v·ou ha· ..'e en mternsh1 J _~roqrarn·;· !Do you offer exchange programs? ~How do I apply? [What are the Admission Requirements? 1Where can I find program calendars? , Where can I ask program questions? 1 When are Ryerson's on campus events? :When can I learn more about part-time programs? :Where can I learn more about graduate studies? ' When is Discover R erson?

[QtJ

Figure 2-20: Menu created with the select tag

48

The Textarea Tag The textarea tag creates a multi-line text input control (see Figure 2-21). The number of visible text lines is specified by the rows attribute and the visible width in average character widths is specified by the cols attribute. Users are able to enter more or longer lines than specified, by scrolling. Lines are often wrapped in order to keep long lines visible without the need for scrolling. The textarea tag requires a start and end tag in order to contain the control value. Setting the readonly attribute allows authors to display unmodifiable text in a textarea. This differs from using standard marked-up text in a document because the value of text area is submitted with the form.
Tell us about your computer experience:

Figure 2-21: Form textarea tag

2.6.2 Form Controls with Sign Language
Due to the textual nature of most of the input controls, there are considerable challenges in considering sign language versions. To begin to explore how sign language forms can be
--~- ,

designed in light of these challenges, I have focused on radio buttons and check boxes, as these elements allow for non-text content. It is not necessary to switch between text and sign language as the labels and controls for these elements can be images. Text entry and lists were not considered in this these because the textual nature of the current controls. New methods of input and control for these elements, such as video capture of sign language responses in place of text

49 boxes or areas, are required in order to allow this type of interaction. While allowing video capture of user input may not be that complex, the storage, manipulation and retrieval of such data is very complicated. Much more research on video indexing and retrieval algorithms and techniques is required in order to automatically process and ''understand" the full temporalspatial properties of sign language.

2. 7 Questionnaire Presentation Style
There are a number of different ways that the questions for a questionnaire can be presented online. One of the main features to consider when choosing the presentation style involves presenting questionnaires in windows that can be either scrolled or paged. Questions can be presented all on the same page, requiring scrolling, or on multiple pages, requiring paging. Questions can also be grouped together into meaningful sections and, in this way, combine the two features: each section is a page that may need to be scrolled in order to view all the questions. There are a number of different methods of presenting questionnaires, [46] describes a study comparing different ways of partitioning surveys for online presentation. The study consisted of 76 items that were presented in four different ways: 1) one long, scrollable form; 2) divided into meaningful partitions that required scrolling; 3) further sub-divided into screensized pages; and 4) presented by single items (one at a time). In addition, the use of an index to sections and/or single items was investigated. With each of the four styles being presented with and without an index, there were eight different versions of the questionnaire. Once the participants had completed the questionnaire, they were presented with a ten-item questionnaire on the interface.

PROPERTY OF
RYERSON UNIVERSITY UBRARY

50
Advantages and disadvantages for each of the different presentation styles was found by [46], but there was no overall significant difference in the performance of respondents between the different styles. Form-based design that presents questionnaires as one long form in a scrollable window has the advantage in that it shows the whole questionnaire, and as such it helps to preserve the context of items within the questionnaire and fosters a sense ofbeginning, linear order and end of the questionnaire. The disadvantage of this type of design is the need for scrolling, which may present problems for some respondents (e.g. confusion, loss ofpostion, etc.). In [46], however, scrolling did not seem to pose a problem for the computer literate respondents. At the other end of the design continuum are item-based questionnaires that present only a single item at a time. This design has the advantage of focusing on single questions, but this advantage may be outweighed by the loss of context and the operations require navigating to single items. When the task of filling out a questionnaire is linear, the interface should support a smooth transition from one item to the next with minimal action on the part of the respondent. The eight versions of the questionnaires used by [46] did not differ substantially in this regard. Consequently, no significant differences were found due to scrolling versus jumping to the next page or the next item in the questionnaire. When the task is non-linear, the interface needs to support this type of access to items so that the respondent does not need to scroll or page through all of the items to get to the required item. In this regard, results showed that scrolling one long form may be superior to jumping through many pages in the item-based versions. Respondents could scroll more effectively than paging with series of clicks on links.
t

I ,

I -

=

c:

...

~

i·

·

51
It was found by [46] that indexes were of little use when respondents were navigating in a

purely linear manner. In fact, indexes may have been somewhat of a distraction and a hindrance at times when respondents only needed to go to the next item. On the other hand, for non-linear access of items when numbers were given, the numeric idexes were highly efficient and task completion times were significantly shorter than all other versions. Item numbers provide a straight forward way to access items in the survey. The index may help the responsent see the scope and content of the survey and may be helpful in organizing information retrieval from memory. Other tasks that directly require navigation to sections will clearly be added by the index. The results of [46] study suggest that long scrolling forms are acceptable for at least some users and that an index to sections is not always helpful as one might think. This research has been limited to text questionnaires. I will be looking at whether similar results will be found when the questionnaire is presented in sign language. Will long scrolling
j

forms be as acceptable for sign language forms, or would item based forms be preferred, and does the proficiency of respondents change given the different presentation style.

, ·

I ..

=

2.8 Online Sign Language Survey Tools
One advantage of an online electronic survey is that it can be made more accessible than paper-based surveys, particularly to respect the privacy and anonymity needs of individuals. For example, an online survey can be made screen-reader friendly so that someone who is blind can complete the survey independently and privately instead of having a paper-based survey read aloud by a researcher or an assistant. An online sign language survey can make use of video for questions and responses so that people can use sign language rather than text required for a

... c: c=

i· ...

52 paper-based survey. However, once video is introduced as a means for asking and capturing the responses to online surveys the survey tool and engine becomes much more complex. With signed web surveys or forms, however, there is a lack of textual elements and the processing requirements are much more complex. The content of the survey or form requires video in order to maintain the time and space nature of sign. This also means that the responses given are in sign language and not in a traditional textual character set. This in tum makes it necessary to send and receive video content and then store the video responses in order for retrieval at a future time. Sign language responses would be able to be captured using a web camera attached to the visitor's computer. The response would then need to be uploaded to the site and stored in a video database for retrieval at a future time. Because of the nature of sign language, the need for video responses would necessitate that the site have a large amount of storage capacity. This is a hindrance for implementing sign language forms. However, forms could be incorporated into a
I

signed web site. The video content of a signed site would necessitate a large storage capacity for the existing signed content. Because of this, and the fact that the responses would be short, a few seconds in length, the extra storage required for the signed responses would most likely be easily accommodated. Storage space could be minimized using efficient file type and compression parameters. Although storage and capture of sign language video is possible, retrieval of sign videos at this time would be more problematic because there is no complete and accurate method for identifying and analyzing sign video content in databases. There is some research on identifying sign within videos, however it is incomplete [4 7, 48] . Current methods of video analysis and indexing are complex processes based on sound, colour, and pattern recognition for scene

I .

· ..
t

I

...

53 analysis [49-51]. Sign language video contains no useful sound, and does not normally change scenery or colour, all of which is necessary in current video analysis and indexing strategies [49]. Combining design concepts for question wording from the questionnaire design literature with the SignLink Studio web object I have created and evaluated an online sign language survey interface structure that would act as the basis for online forms based on sign language.

I ..

· .
I

I

...

Chapter 3 Online Sign Language Form
This section describes the online sign language form construction. It begins with a description of the system used to create a form followed by a more detailed description of the SignLink Studio web object to describe the creation of web pages without the need for text. Finally, I describe the changes made to the web object in order to use the form elements. In order to create an online sign language form, I have taken the SignLink Studio web object and modified it to allow for the form controls. An underlying database structure was set up to allow for the storage of the question, answer and response data. Currently, the database is textual. Because of this, a web based database viewer was created to view the contents of the database in a non-textual manner using PHP. An overview of software and the database supporting the form system is shown in Figure 3-1. The survey, created by the form system, is deployed using a modified version of the SignLink Studio web object, which is served by an Apache web server. The web site designer uses their local browser to connect to the Apache web server to access the survey development and deployment system. This system allows the site designer to populate the database with the relevant information about the questions and answers. Users can then connect through the Internet to access the survey on the web designer's web site. The information submitted by the users is then stored in the database on the site. The site designer can then access the database
t
I

I ..
4

54

55 through their local browser in order to view simple statistics related to the survey including counts, means and a simple graph.

Survey Development and Deployment

Apache Web Server

Developer

Figure 3-1: Overview of development and deployment
The database system used is MySQL. The question and answer information is stored as described in Section 3 .2.1 and the users responses are recorded as described in Section 3.2.2.

3.1 Survey Development and Deployment
The SignLink Studio web object shown in Figure 3-2 illustrates the three main parts: the video content, the optional text area, and the signlinks. The number of signlink locations can be determined from the density bar, where the number of links and their relative location within the video content are shown. The signlink area contains the different links for the page. There are controls available to play/pause the video and controls to move between signlinks. In addition, a control is available to reduce the speed of the video, so that users who have trouble with fast

I

.. ..

56

signing can slow it down in order to understand the content. This object was the starting point for the creation of a sign language question element.

Next Signlink Previous Signlink Slow/Normal Speed

Optional Text Area

Video Controls

Signlinks

Figure 3-2: SignLink Studio Web Object
This thesis developed and tested sign language versions of radio button and check box input elements. Development of sign language versions for other elements such as text boxes and drop-down lists was deferred until the usability of simpler input elements was determined. As described in Section 2.6.1, radio buttons create exclusive choice questions (only one valid selection) and check boxes create multiple-choice questions (more than one valid selection is possible).

I ..

;

....

;.-"'·

Questions can be developed that allow only radio button or check box input from users. The answers are provided to the user and the user may choose their response from these answers. As seen in Figure 3-3, the modified SLS web object now becomes one that contains a question (as the video content) and a series of forced-choice responses (as the signlinks and optional text). The signlinks, which are represented in the SLS web object as hyperlinks, are now the possible

57
responses to the question and are represented by input fields of type radio or checkbox. As in the SLS web object implementation, the optional text area must contain all of the links or "response choices" as signlinks. There can be no response choice in the optional text that does not appear as a signlink.
Next Signlink Previous Signlink Slow/Normal Speed

Question 2. What ate Max, Kendra, and Wilma?

0 Afish 0 Afrog

0

Aplant

Video Controls

I

I I

Optional Text Area

I I
I

I
I

I

L--~ ···-·~---·~--~·-~~·-----·~·· ·~-~

Signlinks
....................

~-·- ---~··~·-----·-""'---"·~--·-·-· """"'_._. . .,.

....<

l. . .,. . ~. -._. ___. _ . . . ____. . . . _ . __. ., . . ._ ._ _ _ ~--·-------~-·----1
I

I

Radio buttons connected

Figure 3-3: SignLink Studio web object as a form question
'

In the optional text area, the "links" are now limited to the form elements representing the available answers. If desired, the user can include the question and the available answers. The answers are then connected to the signlink answers through JavaScript, so that if the user selects an answer in the text area, the signlink answer is selected and vice versa. Answers can be replayed by clicking on the thumbnail image associated with the answer, and can be chosen by selecting the input field of the signlink or the answer within the optional text area. This is made apparent to the user through usage. There are also rollover "alt text" descriptions on the thumbnail images that indicate that clicking will replay the clip and selecting the input field of either the thumbnail or the text will cause the other to be selected also.

!
;

...

i ,.

58

3.2 Database Design
The database system uses MySQL as a database program language. MySQL is used because it can perform the necessary functions, it is open source, and I am familiar with the language. The database tables are divided into two groups, supporting (a) questions and answers, and (b) user responses.

3.2.1 Questions and Answers
Questions and answers are stored in two tables (see Figure 3-4), one for information about the questions (Table question) and one for the information about the answers (Table
answer).

Table question contains information about the question video. This includes the path of the movie file (labelled src in Figure 3-4), and timescale and duration of the movie file containing the sign language video of a question. Information about the question type (qtype) as either being radio button or check boxes, the number of answers available (ans ), the optional text portion {transcript) and a path to the thumbnail images to represent the answers for the question {sign_image) is also stored in the database. There are two id numbers associated with a question that is also stored in the database, a unique id ( id) for relating a specific question with its set of answer, and a question id ( qi d) to indicate the order of the questions.

;:

...

I r·

:ll

59

Field id qid qtype src timescale duration ans transcript sign image

Type int (11) int(11) tinyint(4) varchar(80) int(11) int(11) int(11) text text

Table question; Null Key NO PRI NO NO NO NO NO NO NO NO Table answer; Null Key NO PRI NO NO NO NO NO NO NO

Default NULL 0 0 0 0 0 NULL
NULL

Extra auto increment

Field id qid aid image label start time end time framtime

Type int ( 11) int(11) int(11) varchar(80) varchar(80) int(11) int(11) int(11)

Default NULL 0 0

Extra auto increment

0 0 0

Figure 3-4: Screen view of tables supporting questions and answers

Table answer records the information about the answers for all the questions. Each question is given a unique id {id) that is used for recording the user's response. Each answer is then given a unique pair of ids (qid, aid) that indicate the question to which the answer is associated (qid) and the order that the answer appears in the question (aid). Additional information about the answer, including the file name of the thumbnail image for the answer
(image) and the optional text associated with the answer {label), is also stored in this table.

Information about the location of the answer within the movie is stored {start time, endtime,
frarnetime) for use by the javascript code in order to replay the answer when selected.

When numerical values are needed to be stored, the type int of default display width 11 is used, allowing for values of 4 bytes. For text information, when the information is a set

60 amount {src, image, label), the varchar or variable length string is used with a maximum length of 80, otherwise the type text is used to allow for more content. The unique id for relating to a specific question is defined when the data is inserted by the auto_increment function, which ensures each question is given a unique number. It is also the primary key for the table question and it is used to identify the entry in the table answer.
qtype is defined as a tinyint of default length 4, as this stores one byte and qtype is currently

limited to the values 1 or 2 and is unlikely to exceed 256 values. src is a varchar or variable length string or maximum length 80 characters.

3.2.2 User Responses
There are two tables used to record user responses (see Figure 3-5), one for information about the user {Table user), and one for the user's selected answer to a specific question {Table
result).

Table user records a unique id for the user as well as the IP address of the user ( ip) and a date and time stamp (d). This information allows the website owner to know when the forms are being completed and where the user is located. This could be useful to the website owner to get an idea of their users' location. The owner can then focus the content and information on the appropriate audience. Table result records the user's id {uid) and the answer id of her answer {aid) from the
..,,-"""

table answer. For radio button questions a single pair {uid, aid) is stored and for multiple answer questions (check boxes) a pair (uid, aid) is saved for each checked selection, storing the response of the user. This information can then be used to identify how different users are answering the different questions.

61
Table user; Null Key NO PRI NO NO Table result; Key PRI

Field id ip d

Type int(ll) varchar ( 15 ) datetime

Default
NULL

Extra auto increment

Field id aid uid

Type int(ll) int(ll) int(ll)

NULL

Default
NULL 0 0

NO NO NO

Extra auto increment

Figure 3-5: Screen view of user answer tables

3.2.3 XML File and Parser
The information about the questions and their answers is stored in an XML file. XML is a markup language for documents containing structured information. An XML file contains a set of information in a schema individualized for the data stored. In order to input the data about the questions and their answers into the database, an XML parser is used to identify the information within an XML file. Each parser much be individualized for the XML schema used. My XML parser is used to determine the form element information from the XML file. The information retrieved from the file includes the movie, signlinks, and timing information about the answers to the questions. The result of the parsed XML file is an array of question data that contains information about the question including an array of answers for the question. This information is then stepped through in order to populate the tables question and answer. An example of the XML file, parser and the populated tables can be seen in Appendix A.

..

II

;:

r·

~

62

3.3 User
An important aspect of online forms is the input and feedback information requirements

of the users. In this thesis, it is assumed that users will employ an input device(s) that fits their particular abilities and needs (e.g., keyboard/mouse, speech recognition, single switch key entry, etc.) in order to make selections. Feedback or information output (what the user sees), however, in the form of sign language or text and the presentation style of the form/multiple-choice question information is considered in this thesis. Figure 3-6 shows an expansion of Figure 3-1 to account for the user feedback sub-elements. It is possible for form information to contain multiple types of requests for information as detailed in Section 2.6. As previously noted, in this demonstration the information request type is limited to multiple-choice questions using either radio buttons or check boxes. Questions can be presented one at a time or all at once, and in one of two languages: ASL or text.

Internet Form

.,

Multiple Choice

Question Type

..

;: It j

Presentation Style

Language

Figure 3-6: Model of user information sub-elements

Chapter 4 Study of Online Sign Language Form
In my research, I focus on one mechanism; sign language based questions and two types
of response categories. Not only is this a user interface issue but also an issue of storing, searching, retrieving and presenting the questions and responses in video and summary form. The approach described in Chapter 3 is a first attempt at explore an alternative mechanism. Because the proposed approach is only the first attempt at an alternative mechanism, user testing and user involvement at all stages of the development process is important. This chapter provides the methodology used to carry out the user study to assess the impact on sign language users of the question/response technique developed in this thesis.
\

4.1 Research Questions
In this study, the design and implementation of online sign language forms are compared with conventional text forms. In addition, building on the research of [46], where no difference in preference between single and "all at once" questionnaire styles for text-based questionnaires was found, I will examine the impact on response performance and preferences of sign language users between textual and sign language displays of questions using these two presentations styles.

63

64
The research questions following from this are: 1. Is there a difference in the ability to answer questions accurately when questions and responses are presented in ASL versus text? 2. Is there a preference for questions to be presented in ASL versus text? 3. Is there a difference in the ability to answer questions when presented singly versus all at once? 4. Is there a preference to having questions presented singly versus all at once?

4.2 Study Design
The study design will be a 2x2x2 mixed factorial design with the between-subjects factor being language; the two language factors are text and ASL. The within-subjects factors are display style and video episode. The two display factors are "one at a time" and "all at once". The two video episodes are "To Air is Human" (TA) and "Bad Vibrations" (BV) from the Deaf Planet television series (see www.deafplanet.com). Each participant watches the two sign language-based video clips and completes one of the eight treatments. Each clip is approximately 2 minutes in length. Table 4-1 shows the eight treatment options for the study. Treatments are randomly assigned to participants once they agreed to participate.
Treatment
Text
\

First Video
To Air is Human
]"()Airl~Hum~n

Second Video
Bad Vibrations All at once
.>Oo..~ .ata tifl\e. One at a time

One at a time
, ~liJ~t·qn~' All at once

.. ASL:
4 5
6 Text

·~~,·.: ~i~r~it.9l'ls
Bad Vibrations

ASL
Text

7 8

ASL
Text

To Air is Human Bad Vibrations Bad Vibrations Bad Vibrations Bad Vibrations

To Air is .~ulllan
To Air is Human To Air is Human To Air is Human

All at once
All at once One ·at a time One at a time

.One ~t.a tim~
One at a time

AU at once
All at once

Table 4-1: Treatments

65
The dependent measures are user performance, collected using a five- or six-question online comprehension "test", and a nine-question survey for user preferences of question and display styles. Both measures are gathered using an online survey that is completed after each viewing. Participants are asked to complete a pre-study questionnaire (PRE), two comprehension tests (CT), two user preference surveys (UP), and a post-study summative questionnaire (PS). The purpose of the PRE is to gather demographic information and determine the user's comfort level with computers and the internet. The PRE consists of ten questions in total with four questions on demographics, two questions on the user's comfort level with computers, two questions on the user's comfort level with sign language, one question on the user's use of online sign language and one on the use of online forms (see Appendix B.l ). The CT used to evaluate the participant's understanding of the video content (see Appendix B.2). The CT for T A consisted of five questions in total with one multiple selection (check box) question and four single answer (radio button) questions. The questions related to where the characters were and what the characters were saying. The CT for BV consisted of six questions in total, with one multiple selection (check box) question and five single answer (radio
If

button) questions. The questions related to character dialogue and costumes. Questions on this test were presented either in sign language or in text, and the questions were displayed either one at a time or all together on one screen. The UP gathers data on the preferred style and interest in answering online questions (see Appendix B.3). It consists of nine questions relating to the difficulty of answering questions, the layout of the survey, and preference of answering questions online, on paper, or in person. Questions on this survey are presented in the same fashion as the preceding comprehension test (sign language/text and all at a time or all together).

· !

II

~

IC

~

66
The PS gathers data on the overall preferred style and interest in answering signed versus text-based questions (see Appendix B.4). There are two versions of the post-study questionnaire: one for those who answered ASL questions and one for those who answered English text questions. There were six questions with two questions relating to the overall difficulty answering questions: one asking whether participant's would improve their performance if the they were able to answer questions in the other language, one asking the likelihood participants would answer online sign language questions, and two open ended questions on the likes and dislikes of using online forms. The ASL version had an additional question regarding the speed of the signer for the questions. Consent to participate in the study was obtained using a click through consent process. The consent form could be viewed in English text or ASL. This study was approved by the Ryerson Research Ethics Board (see Appendix C for the approval letter).

4.3 Method and Data Collection
After giving consent online, participants were linked to a pre-study questionnaire (PRE) that took approximately ten minutes to complete. At this point participants were randomly assigned to one of the eight treatments in order to complete the remaining components of the study. Next, participants watched two video clips of Deaf Planet (average time of two minutes each), delivered in succession. After watching each video clip, participants were presented with the comprehension test (CT) and user preference survey (UP) (for a total of two questionnaires, one set for each clip) in either English text or sign language (see Appendix B for the study questionnaires). For both languages, the questions were either presented one at a time or all at

\

r

l

r
·

Cl

~

~

Ill

67 once, depending on the video watched based on the treatment assigned. Finally, a post-study summative questionnaire (PS) was presented. The study was conducted online in order to maximize the number of deaf participants who could participate in this study. In addition, using an online format allowed access to a wider range of participants in different geographic locations who can complete the study when and where they prefer. The study was attempted by over 100 participants, but due to the technical difficulties encountered within the first few days, only 22 participants were able to successfully complete the study. All data collected from the online questionnaires were automatically recorded in a MySQL database. The database contained 24 tables (see Table 4-2 for a list of the tables and their uses). Two tables were used to store study variables, and one stored participant information relating to progress through the study. There was one table to store the PRE information, as this was solely presented in text. Four tables were used to store the results from the text participants, one each for the BV "test" (BVCT), the T A "test" (TACT), the UP, and the PS. Seventeen tables were used to store the information for the sign language questionnaires:
I

the BVCT, the TACT, the first video UP, the second video UP, and the PS. Each sign language questionnaire used three tables: question, answer and result. An additional table was used to store the responses to the open-ended answers from the post-study questionnaire. The question and answer tables held the information about the type of question and the answers to use for the display of the question and the result table held the answers from the participants (see Appendix A for a sample database set). Originally, the PS was to be presented in sign language, but due to difficulties in including the text box for the open-ended answers, it was presented in text.

~·

~·

68
Table Purpose Text results for the SVCT Information for the sign version of the BVCT questions and answers Sign results for d1~ Text results for the UP Information for the sign version of th~· UPJorthe first ·{1) and second (2) dip·viewed

]:)advibe badvibe_question, badvibe_answer b_ a dvibe.....:resul t postclip '·pos tclip_1_questioJJ.,
- po~Jtclip_l.__answe:r,

:aver

postclip_2_question, postclip_2_.answer postclip_l_result, postclip_2_result poststudy post_question, post_answer ,; post_re~:~ult, other participant
l pt-estucly

Sign results for the UP for the first (1) and second (2) clip viewed Text results for the PS Information for the sign ve~sion of the PS . Sign results for the PS Information about the participant (IP address, treatment) and timing for completing the different parts of the study Results of the PRE Study variables and treatment information Results for the TACT Information for the sign version of the TACT questions and answers Sign results for the TACT

study_variables, treatment ,. toair toair_question, toair answer ·toair result

Table 4-2: Database Tables

4.4 Data Analysis
The data was first analysed using a series of repeated measures MANOVAs to examine order effects for the order that the video clips were viewed and the order in which the style for questions (one at a time or all at once) was used to answer the questions. As the number of subjects in each group of the study was low the non-parametric tests,

'

;.-,

Kruskal Wallis, and Mann Whitney were used to assess differences between answers given in the CT, the UP, and the PS, based on the language used, the style the questions were presented, and the video clip viewed. The CT questions and scores were tested with the Kruskal Wallis test between the collapsed treatments. A Mann-Whitney analysis was used to examine differences in the ratings for the UP statements between languages used, style of presentation used, and video

69
clip viewed. A Mann-Whitney analysis was also used for the PS questions based on the language used. The five-point Likert scales for the UP and PS were reduced to three-point Likert scales, by collapsing 1-2 (negative categories) into 1, 4-5 (positive categories) into 3 and recoding the midpoint as 2, to ensure that the assumptions for the statistical tests could be met. A conversion to a trichotomous measure was demonstrated by [52] to not result in any significant decrement in reliability or validity, regardless of the number of categories originally used to collect the data.

4.5 Participants
Twenty-two people (14 female, 7 male) participated in the study. Participants were recruited through the Technology Conference at National Technical Institute for the Deaf at Rochester Institute of Technology, a Deaf Culture listserve and word of mouth. Some of the participants (nine) recruited from the technology conference completed the study in person using computers that were setup at this conference. Table 4-3 contains the descriptive statistics of the sample.

'·
r.· ,
·'

tl

·

f

I

70
Gender
Mal~
,.;,-.,

,···;-;.

"'-'

7·?:. }·:'1-~·;ff>) . ~
'l4 ' .(6l~.) 3 (14%)
8 6 5 (36%) (27%) (23%)

Age

Education

F~rnale 18-29 years old 30-39 years old 40-49 years old 50-59 years old Less than High School Diploma . High School Diploma
Coll~ge ~evel D,iploma

1 4
1

·(5%) (18%)

(· S%)

·· Hearing Status

Computer Experience

.; ~qhelor-~r. U ?9ergr~(ifu~~e.:pesr~e .· ·· >. -._·.· . : \. · Rost.;.Gradua~e Q~gree (e;~g., J"1aster~ o~ ;~hl:>) _; hearing hard of hearing deaf deafened cochlear implant Novice
_ Intermediate
Advanced Never Rarely (once a year) Sometimes (3-4 times a year) Often (monthly) Frequently (weekly) Regularly (daily)

4- :\·:i(~·P~>.. 12 ..- . J:S,~) .
3
2

(14%)
(9%)

11 1
5

(SO%) (5%)
(23%)

5 14

2
2 7 7 6

(24%) (67%) (lOOA>)
(9%) (32%) (32%) (27%)

Online Survey Usage

0 0
\

Table 4-3: Descriptive Statistics of Subjects All participants were over the age of 18, with the median age falling between 30-39 years old. Most participants 55% (12 of22) held a post-graduate degree, though the average is at least a bachelor or undergraduate degree. All participants reported having more than 10 years of experience using sign language. However, when asked about which sign languages they practice, 91% (20 of 22) of participants indicated ASL as one of the languages. Table 4-4 shows the other signed languages that participants practiced.

· ·
t

·

I

71

ASL (AO,erican $i*~;ta~luage}
LSQ (Langue de Signes Quebecois) ISL (lnte~national Sign,Linguagt!) CASE (Context accurate signed English)* Signed English** Other

20 1

'(9i%)
(5%) (18%) '
(18%)

4
4

(14%) * CASE refers to "Conceptually Accurate Signed English" and is not a language per se. It uses ASL signs with English grammar. **Signed English is also not considered a language. It is a sign system that retains grammar from English, uses ASL signs with grammatical embellishments needed for English e.g. suffixes like -ness, -ment, and -ing and

7 3

(32%)

Table 4-4: Sign languages practiced by participants Fourteen participants indicated they were intermediate computer users, five indicated that they were advanced users and two were novice users. Table 4-5 shows the computer application usage. All users use office productivity applications.

Office productivity (wo&t :processing,'spreadsheets; etc;, Internet (Firefox, Opera, Skype, Facebook, etc.) Programming (C, Java, etc.) Web Programming (Dreamweaver, FrontPage, etc.) Multimedia (Photoshop, MovieMaker, iMovie, Sound editing, etc.) Video games Other

('100%)
19 7 10
(86%)

(32%)
(46%) (68%) (46%)

15
10

:a,, , (as%)

Table 4-5: Computer application usage Ninety-one percent of participants (20 of 22) indicated that they had used online surveys. Usage ranged from often (monthly) to rarely (once a year), with the average being a rating of sometimes (3-4 times a year). No participant indicated that they used online surveys frequently (weekly) or regularly (daily). Of the 22 participants, 15 indicated different types of web sites that they currently used that included sign language content (see Table 4-6). The most common type of sign language website visited was for deaf organizations with 62% (13 of 22) of participants visiting these sites. Three participants indicated they visited other sign language websites than those listed, including Y ouTube, eBay and SignLink Studio.

72

Do oot use online sign language websites News websites Personal websites Deaf Organizations Dictionary .websites Other

7 6 7 13

{33%) (29%) (33%) (62%)

5
3

(24%)
(14%)

Table 4-6: Online sign web access

Fifty percent (11 of 22) the participants were deaf, 5% (1 of 22) was deafened, and 23% (5 of22) participants were deaf, deafened or hard of hearing and had cochlear implants. Of the remaining participants, 14% (3 of 22) were hearing and 9% (2 of 22) were hard of hearing. Participants were assigned randomly to treatment conditions, which determined the version of the form they would see and the order the videos were presented. As more participants were included in the study, a sorting algorithm was used to ensure that the treatments did not become too saturated, allowing for an even distribution across the different treatments. The algorithm examined the number of participants who had completed each treatment and selected a treatment from an array of treatments with the fewest participants. This allowed participants to be assigned the same treatment in succession, as long as the next participant started before the previous participant had completed, but also ensured that treatments did not become too oversubscribed as participants typically only took 30 minutes to complete the study.

Chapter 5 Results
5.1 Tests for Order Effects
A repeated measures MANOVA was conducted to determine whether the order in which participants were exposed to the different video clips affected their comprehension and attitudes. None of the analyses showed any significant effect for order (see Table 5-1). Thus, all data were collapsed across order (see Table 5-2).
Effect df

Video·clip * Lang~age ·
Video clip * Video order

Language * Video order
Video clip* Language* Video order

1.286 .1.771 1.735

11 11

0.300
\

0.137

.;··

Table 5-1: MANOVA results for user preference survey

.

Treatment

Language

To Air is Human Style

1
2

ASL Sign Langu()g~
English text

3
4

'ASt.:sfiil tanguage
English text

atone, · All at once oo eai ~-tim~ :
All
One at a time

Bad Vibrations Style

. · ; . ;·;,:P·@t.:~~',@ ;,li!i!. ,: . ·, ~one at a time All at once

Table 5-2: Collapsed Treatments

5.2 Comprehension Test Scores
The scores for the comprehension tests (CT) were normalized (as a percentage), as there were five questions for "To Air is Human" {TA) and six questions for "Bad Vibrations" (BV). In

73

74
addition, scores were normalized based on the number of answers recorded by each participant. Some participants did not answer all questions, so if a participant answered four questions, the percentage was based on those four questions. One participant answered only one question for the BV test, their result was not included in the statistical analysis. Table 5-3 shows the average test scores and the score ranges. B V scores ranged from 33% to 100% and TA scores ranged from 20% to 80%. There was no significance found in the comprehension scores between clips for all participants. However, the comprehension score for the second movie, regardless of which one was seen second, was higher than the first one. Also, the average scores forT A (38% for first viewing and 48% for second viewing) were lower than the average scores for BV (51% for first viewing and 63% for second viewing). Scores for BV, in general, are higher than the scores forT A.

Bad Vibrations score
ASL

To Air is Human score

Text
First Video Second Video All at once One at a time Range
51% 60% 38% 48%
45%

53%
60% 33%- 100%

... i

42% 20%-80%

Table 5-3: Average comprehension scores
There was no significant difference for comprehension scores between different presentation styles. For TA, the average score when presented all at once is higher (45%) than when presented one at a time (42%), but for BV it is reversed, the average when presented one at a time is higher (60%) than when presented all at once (53%). There was also no significant difference for comprehension scores based on the language used. The average score for BV was the same for both languages, 59%, and the average score for TA was very close with ASL participants receiving 42% and text participants receiving 45%.

,. ,

.

~ ..

75

Figure 5-1 shows the average comprehension scores by video clipped comparing the order viewed and the presentation style.
70% 60% 50%

· Viewed first

V)

u

... 0

Cll

40% 30% 20% 10% 0%

mViewed second

· Questions all at once

· Questions one at a time To Air is Human Bad Vibrations

Figure 5-1: Bar graph of the scores for comprehension tests

5.3 User Preference Survey
The user preference survey (UP) consisted of nine statements to which the participant indicated their agreement or disagreement using a five-point scale, with 1 being strongly disagree and 5 strongly agree to each statement. The responses were adjusted from a five-point scale to a three-point scale, where 1 was disagree and 3 was agree in order to ensure that the assumptions for the statistical tests could be met as discussed in Section 4.4. Figure 5-2 shows the frequencies for the three statements related to using online questionnaires for all participants (n = 44). A chi square analysis was performed on these statements to determine whether the answers were different from chance (specified as equal number of ratings per response category). As shown in Table 5-4, there was a significant difference for these three statements relating to using online questionnaires.

76
X2 df N Mean SD .. . .. 3..·77 ..···· ,. . .·. 2 .. : .··;.,.,...;.t· · ·.ALA >> ..>< · ·1 ···:· 4 ·~·· . 0 . .... ·· ..· .· .6 ·. ·. ·2 ,· .·.··.':;;:·;2 '~ .. ~ ·. ·,· .··.~· . 2 40 36.05 1.28 0.55
1 ·. . ·.·.· .. ..

Statement

tb;ther_fin·ou.~ sllfY~Virt ·rson
Submitting answers online is difficult

Easier to fill out Sllrvey on paper

27.65

2

40

1~40

0.71

Table 5-4: Chi-square analysis for user preference survey

Sixty-six percent (29 of 44) disagreed with the statement "would rather fill out the survey in person", 27% (12 of 44) were neutral, and 7% (3 of 44) agreed (M = 1.41, SD = 0.62). Seventy-eight percent (31 of 40) disagreed with the statement "submitting answers online is difficult", 18% (7 of 40) neither agreed nor disagreed, and 5% (2 of 40) agreed (M = 1.28, SD = 0.55). For the statement "it is easier to fill out survey on paper", 73% (29 of 40) disagreed, 15% (6 of 40) were neutral, and 13% (5 of 40) agreed (M = 1.40, SD = 0.71) (see Figure 5-2).
35 ~--------------------------30 -1-----·-----·---- -- - 25 -+-- - -..- - - - - - - - -

20 +--

---------

· Rather fill out in person Submitting answers online is difficult

15
10 - + - - - - - - IW

5 +--0 +' ___ ,""""
Agree Neither Disagree nor Agree Disagree

· Easier to fill out survey on paper

Figure 5-2: Bar graph for ratings for user preference survey relating to online survey preferences
The-majority of participants did not prefer using offline/paper-based questionnaires regardless of language, which video they watched first or the style of presenting the questions, indicating that the subjects were comfortable with completing online questionnaires. The remainder of this section reports differences in responses for three experimental conditions (text vs. ASL conditions, between the two clips used, and presentation style) and two participant characteristics (prior online survey usage and educational attainment).

77 Subheading: comparison of text and ASL conditions A Mann-Whitney non-parametric analysis between the English text and ASL video groups was carried out for all nine UP statements. As shown in Table 5-5, there was a significant difference between text and ASL groups for the responses to three statements.
Statement
The questions were difficult to answer It was easy to find the answers to the questions Layout is difficult to figure out

u
Mean

ASL

Text

so
0.79 0.66 0.70

Mean

so
0.67 0.50 0.00

150 146 99

2.05 1.64 1.61

1.50 1.18 1.00

Table 5-5: Mann-Whitney results for user preference survey organized by survey language For "layout was difficult to figure out", 41% (9 of22) of ASL participants answered neutral, 32% (7 of22) agreed and 27% (6 of22) disagreed (M = 2.05 SD = 0.79). For participants who completed the text-based version, 59% (13 of22) disagreed with the layout being difficult to figure out, 32% (7 of 22) were neutral and 9% (2 of 22) agreed (M = 1.5, SD = 0.67) (see Figure 5-3).
14 ...----·---------------------

12

+············································································································· ····························································-···········

1*

Text

2

0
Agree Neither Disagree nor Agree
.

Disagree

[_··-·--·- -·--·-------·--·----·-------

Figure 5-3: Bar graph of participant ratings for statement "Layout is difficult to figure out" organized by survey language.

78 For the statement related to a preference for completing the survey in person, the participants who used the ASL version of the study, 9% (2 of 22) agreed that they would prefer to complete the study in person, 46% (1 0 of 22) were neutral and 46% (1 0 of 22) disagreed (M = 1.64, SD = 0.66). For the participants who used the text-based version, 5% (1 of22) agreed, 9% (2 of 22) were neutral and 86% (19 of 22) disagreed (M = 1.18, SD = 0.50) (see Figure 5-4).
r····--··--·-·;~----------------------·---------·---------------·--···-··----

1

1

18 16

+----------------------+····· ···············..................................................................................................................................................

I
· 1

·o
~ ra
D.

t ~~

+------------10 8 ·+·- .......................................................................... 6 +·----...-.........·------·-4 -+----·---·-..·--- - 2 0
Agree Neither Disagree nor Agree Disagree

im

Text

Figure 5-4: Bar graph of participant ratings for statement "Rather fill out survey in person" organized by survey language. Fifty percent (9 of 18) of ASL-based users disagreed that is was difficult to submit answers online, 39% (7 of 18) were neutral and 11% (2 of 18) agreed (M = 1.61, SD = 0.70). For the participants using text, 100% (22 of 22) disagreed that it was difficult to submit the answers online (M = 1.0, SD = 0) (see Figure 5-5).

! ·

1111

!,.

··

.

79

"i
Q.

·u

~ ns c.

Ill

15 + - - - - - - - - - - - - 10 +-·-···-·---·--·- - - - - · - - - - -·ASL
iM Text

I

o
Agree Neither Disagree
nor Agree

Disagree

I I I I I I
I

l-~·--·· ------~----------------·---------------··-------·-~----~---~--~------·-·--·--·---·J

Figure 5-5: Bar graph of participant ratings for statement "Submitting answers online is difficult" organized by survey language.
Subheading: comparison between video clips A Mann-Whitney non-parametric analysis between the two clips, TA and BV, was carried out for all nine post-clip statements. As shown in Table 5-6 there was a significant difference between clips for the responses for three UP statements.
Statement
The questions were difficult to answer It was easy to find the answers to the questions Layout is difficult to figure out

u
Mean

TA

BV

so
0.83 0.79 0.79

Mean

so
0.75 0.67 0.36

144 177 150

2.1 1.9 2.1

1.6 2.6 1.5

I
r.;
~

~

0:: .,.

..

~
;~~·

Table 5-6: Mann-Whitney results for user preference survey organized by video clip For the statement "the questions were difficult to answer", for TA 38% (8 of21) agreed, 33% (7 of21) were neutral and 27% (6 of21) disagreed (M=2.1, SD=0.83). For BV, 57% (12 of 21) disagreed, 29% (6 of21) were neutral, and 14% (3 of21) agreed (M=1.6, SD=0.75) (see Figure 5-6).

80

12 10

.... c
Ill

·u
~ ns .:a.

D.

ns

8
6
4

· To Air is Human
Wt Bad Vibrations

2 0
Agree Neither Disagree nor Agree Disagree

Figure 5-6: Bar graph of participant ratings for statement "The questions were difficult to answer" categorized by video clip viewed.

When deciding whether it was easy to find the answers to the questions, for TA 38% (8 of21) disagreed, 38% (8 of21) were neutral and 25% (5 of21) agreed(M=l.9, SD=0.79). For BV, 68% (15 of22) agreed that it was easy to find the answers to the questions, 23% (5 of22) were neutral and 9% (2 of22) disagreed (M=2.6, SD=0.67) (see Figure 5-7).

' ! . r.
:

14 +---------

.

I

1

12
I l l -+-·--------------·-------------

· To Air is Human
M

Bad Vibrations

t'

2

0
Agree Neither Disagree nor Agree Disagree

L

-------------------------- - - - - - - - - - - - - - - - -

Figure 5-7: Bar graph of participant ratings for statement "It was easy to find the answers to the questions" categorized by video clip viewed.

81 For TA, 41% (9 of21) were neutral as to the layout being difficult to figure out, 32% (7 of21) agreed and 27% (6 of21) disagreed (M=2.1, SD=0.79). For BV, 59% (13 of22) disagreed, 32% (7 of22) were neutral and 9o/o (2 of22) agreed that the layout was difficult to figure out (M=l.5, SD=0.67) (see Figure 5-8).

12

.... c:
Ill

10
8 6
4

·u
ra a.

c.

ra

'f

·To Air is Human Bad Vibrations

2

0
Agree Neither Disagree nor Agree Disagree

Figure 5-8: Bar graph of participant ratings for statement "Layout is difficult to figure out" categorized by video clip viewed.

Subheading: Comparison between presentation style (all at once, one at a time) A Mann-Whitney non-parametric analysis between the two question presentation styles, all at once and one at a time, was carried out for all nine statements. There was no significant difference between the responses for any of the statements (see Table 5-7).
Statement The questions were difficult to answer It was easy to find the answers to the questions lt. w ... Cl$ ~~w .· ·. · .t() maki mJ$take$ answering ·.~ . 'h~ . · ...·.il. · .· . · . u .n.·.e . ~;. o . . .n . < ·.s . , Directions were not detailed enough
·

u
167.50 231.00 :2~§:·~. 192.00 223.00
239 ~00

p

'

'.

·---·-

___

., ...

·-.·-.···.....·._.,. __ __ .... ...

,·_,·,·

-:;.· -· -:··--.

:- -·: ·

·-.-.-.,.-

''·

......

.

·.

0.164 1.000 Q~8?~ 0.216 0.626

~vq~~··J$ · <~1fflP~'~t~.o. fisllrt.· QYl
Survey is too plain Rather fill outsurv,y.in PE!I"SQn Submitting answers online is difficult Easier te> fill out survey on paper

. o.g:clo
0.890 0.9()2

195.50

196.00

Table 5-7: Mann-Whitney results for user preference survey organized by presentation style

82 A chi square analysis was performed on the statements to determine whether the answers to the UP were different from chance (specified as equal number of ratings per response category). Five statements differed from the expected frequency. Three were reported at the beginning of this section, the remaining two are shown in Table 5.8.
Statement It was easy to make mistakes answering the questions Survey was too plain Mean SO

23.77
7.82 2 44 1.68 0.71

Table 5-8: Chi-square analysis for user preference survey

Sixty-six percent (29 of 44) agreed that it was easy to make mistakes answering the questions, 27% (12 of 44) neither agreed nor disagreed and 7% (3 of 44) disagreed that it was easy to make mistakes answering the questions (M = 2.59, SD = 0.62). Forty-five percent (20 of 44) disagreed that the survey was too plain, 41% ( 18 of 44) neither agreed nor disagreed and 14% (6 of 44) disagreed (M = 1.68, SD = 0.71) (see Figure 5-9).

~

~

E ..

..

Disagree nor Agree

Figure 5-9: Bar graph of rating for user preference survey.

Subheading: differences in prior online survey usage

83 A Kruskal Wallis non-parametric analysis between the different online survey usage responses was carried out for all nine post-clip statements. There was a significant difference among those with different online usage for the responses to three of the statements.
Statement

H

df

Rarely (once a year)

Sometimes (3-4 times a year)

Often (monthly)

Mean The questions were difficult to answer It was easy to find the answers to the questions Rather fill out survey in person

so
0.80 0.77 0.83

Mean

so
0.83 0.84 0.27

Mean

so
0.67 0.67 0.51

7.28 6.38 8.25

2 2 2

2.21 1.86 1.71

1.93 2.36 1.07

1.30 2.64 1.58

Table 5-9: Mann-Whitney results for user preference survey organized by online survey usage

For the statement "the questions were difficult to answer", of the participants who rarely (once a year) participated in online surveys 43% (6 of 14) agreed, 36% (5 of 14) neither agreed nor disagreed, and 21% (3 of 14) disagreed (M = 2.21, SD = 0.80). Of the participants who sometimes (3-4 times a year) participated in online surveys, 36% (5 of 14) disagreed that the "questions were difficult to answer", 36% (5 of 14) neither agreed nor disagreed, and 29% (4 of 14) agreed (M = 1.93, SD
=

0.83). Eighty percent (8 of 10) of participants who participated in

online surveys often (monthly) disagreed that the "questions were difficult to answer", 10% (1 of 10) neither agreed nor disagreed and 10% (1 of 10) agreed (M = 1.30, SD = 0.67) (see Figure 5-1 0).

84

9 8 ., 7 c 6 a. 5 ·;:::; t= 4 a. 3 2 1 0

...
"' "'

· Rarely

wSometimes
· Often

Agree

Neither Disagree nor Agree

Disagree

Figure 5-10: Bar graph of participant ratings for statement "Questions were difficult to answer" categorized by online survey usage.

For the statement "it was easy to find the answers to the questions", of the participants who rarely (once a year) participated in online surveys 43% (6 of 14) neither agree nor disagree, 36% (5 of 14) disagree, and 21% (3 of 14) agree (M = 1.86, SD = 0.77). Fifty-seven percent (8 of 14) of participants who sometimes (3-4 times a year) participated in online surveys agreed that "it was easy to find the answers to the questions", 21% (3 of 14) neither agreed nor disagreed and 21% (3 of 14) disagreed (M = 2.36, SD = 0.84). Seventy-three percent (8 of 11) participants who participated in online surveys often (monthly) agreed that "it was easy to find the answers to the questions", 18% (2 of 11) neither agreed nor disagreed and 9% (1 of 11) disagreed (M = 2.64, SD = 0.67) (see Figure 5-11 ).
10

., c r~ ... a. "'

I

I

8
6
· Rarely
4
2
t%

! !

·;:::;
a.

t=

' I

I

"'

Sometimes

· Often Agree Neither Disagree nor Agree Disagree

0

Figure 5-11: Bar graph of participant ratings for statement "It was easy to find the answers to the questions" categorized by online survey usage.

85 Fifty percent (7 of 14) of participants who participated rarely (once a year) in online surveys disagreed that they would "rather fill out the survey in person", 29% (4 of 14) neither agreed nor disagreed and 21% (3 of 14) agreed (M = 1.71, SD = 0.83). Ninety-three percent (13 of 14) who participated in online surveys sometimes (3-4 times a year) disagreed that they would "rather fill out the survey in person" and 7% (1 of 14) neither agreed nor disagreed (M = 1.07, SD = 0.27). For those who participated in online surveys often (monthly), 58% (7 of 12) neither agreed nor disagreed that they would "rather fill out the survey in person", and 42% (5 of 12) disagreed (M = 1.58, SD = 0.51) (see Figure 5-12).
14 12 10
8 6 · Rarely
~1

"' ·o
"f
~

... "' c
a.

"'

4 2 0
Agree Neither Disagree nor Agree Disagree

Sometimes

· Often

Figure 5-12: Bar graph of participant ratings for statement "Rather fill out the survey in person" categorized by online survey usage. Subheading: differences in educational attainment A Mann-Whitney non-parametric analysis between the education reported by participants with a postgraduate degree and less than postgraduate degree was carried out for all nine postclip statements. There was a significant difference between educational levels for the responses to two of the statements:

86

Statement Directions were not detailed enough Easier to fill out survey on paper

U

Postgraduate Degree SO Mean

Less than Postgraduate Degree so Mean

113.5 121.5

2.38 1.63

0.82 0.82

1.50 1.06

0.76 0.25

Table 5-10: Mann-Whitney results for user preference survey organized by video clip Fifty-eight percent (14 of 24) of participants with a postgraduate degree agreed that the "directions were not detailed enough", 21% (5 of24) neither agreed nor disagreed and 21% (5 of 24) disagreed (M = 2.38, SD = 0.82). Sixty-five percent (13 of20) of participants that reported lower than a post graduate degree disagreed that the "directions were not detailed enough", 20% (4 of20) neither agreed nor disagreed, and 15% (3 of30) agreed (M = 1.50, SD = 0.76).
16 14 12 10
8

:e
a.

"' ·o "'

.... "' c:
a.

6 4 . 2 0
Agree Neither Disagree nor Agree Disagree

· Postgraduate

tw Less than postgraduate

Figure 5-13: Bar graph of participant ratings for statement "Directions were not detailed enough" categorized by education level.
For the statement "easier to fill out survey on paper", postgraduates disagreed 58% (14 of 24), neither agreed nor disagreed 21% (5 of24) and agreed 21% (5 of24) (M = 1.63, SD = 0.82). For those with less than a postgraduate degree, 94% (15 of 16) disagreed and 6% (1 of 16) neither agreed nor disagreed (M = 1.06, SD 0.25).

87

14 ·+---------------------12 +----·------··------------.... ; 10 +----------------·---·---·------·-------------------------------·~ 8 +--------------·-----------·----------··-.f 6 ~----------nl
111
~

· Postgraduate
¥M

4
2 0

!

Less than postgraduate

I

Agree

l

Neither Disagree nor Agree

Disagree

···-·· ····--···----~----- ·~··--···-···

..---·--·-··--------···--··--·-·-·-·-·-··-··----------···-·----·---·-..-.·--·-·-......--..·-·-···---···-···---·----...

Figure 5-14: Bar graph of participant ratings for statement "Easier to fill out survey on paper" categorized by education level.

5.4 Post-study Summative Questionnaire
The post-study summative questionnaire (PS) consisted of four forced-choice questions for text participants and five for sign participants, and two open ended questions each. These questions were designed to gather information about the participants' overall opinion about the study and the sign language online forms. As with the user preference surveys, the rating scales were compressed from a five-point Likert scale to a three-point Likert scale, by combining 1-2 (negative categories) and 4-5 (positive categories) and recoding the middle point as 2, and a Mann-Whitney non-parametric analysis were carried out between languages, and clips. When comparing the responses from the ASL form participants and the text form participants, there was a significant difference between text and ASL conditions in the responses to two of the PS questions.

88

Statement
Rate how difficult it was to understand the level of vocabulary used Rate how much better/worse you would have done if the questions were in [the other language]

u
Mean

ASL

Text
SO Mean SO

27.5 25.5

2.4

0.73 0.73

3.0

0.00 0.70

2.6

1.9

Table 5-11: Mann-Whitney results for user preference survey organized by video clip When rating the difficulty of the vocabulary used, 56% (5 of 11) of the ASL participants rated the vocabulary easy, 33% (3 of 11) neutral, and 11% (1 of 11) difficult (M=2.4, SD=0.73). For the text participants, 100% (11 of 11) rated the vocabulary as easy (M=3.0, SD=O) (see Figure 5-15).

"' ·o
t:
Q.

... c
lit

10
8
6

a.

"'

4
2

0
Easy Neither Easy nor Difficult Difficult

--------·-·---- - - - - - - - - - - - - - - - - -

Figure 5-15: Bar graph of participant answers to "Rate how difficult it was to understand the level of vocabulary used" based on language
When rating how much better/worse the participant thought they would do if the
question~re

in the other language, 67% (6 of 11) ASL participants rated they would do better

in text, 22% (2 of 11) the same, and 11% (1 of 11) worse (M=2.6, SD=0.73). Fifty-five percent (6 of 11) of the text participants said they would do the same as in ASL, 18% (2 of 11) better, and 27% (3 of 11) worse (M=l.9, SD=0.70) (see Figure 5-16).

89

12 ..,. ................................................................................ . ........... ................................................................................ . .. 10 +................- . .·-····-·-·---------·--------.. -- .......____________ _____________
~
rg

8 + ............... ... . . .................................................................................................................................................................................

·~

6 .

:.

~

4
2 0
Better Same Worse

~ Text

Figure 5-16: Bar graph of participant answers to "Rate how much better/worse do you think you would have done if the questions were in [the other language]" based on language

A chi-square was run on the post study questions with one question having significance: "please rate how difficult it was to understand the vocabulary used",

x2(2, N = 20) = 19.90, p <

.05. Eighty percent (16 of20) rated the vocabulary as easy, 15% (3 of20) neither easy nor difficult and 5% (1 of 20) difficult.
20

.... c: 15
Ill

rg

D. 'u 10

~ rg
I:L

5 0
Easy Neither easy nor

Difficult

difficult

Figure 5-17: Bar graph of participant answers to "Rate how difficult it was to understand the vocabulary used"

5.4.1 Signing Speed
The participants of the ASL portion where asked to rate the speed of the signing using a three-point Likert scale with 3 =fast and 1 =slow. Sixty-seven percent (6 of9) answered just right and 33% (3 of9) answered fast (M = 2.33, SD = 0.50).

90

~

6 +------4 +--·············-·········-···-······-·-·····-·-

'f

·8"

1'0

:.

2 +-------·----·

Slow

Just right

Fast

Figure 5-18: Bar graph of participant answers to "Rate the speed of signing"

5.4.2 Answer Online in the Future
The participants were asked to rate how likely they would answer questionnaires if they were presented in sign language using a three-point Likert scale with 3 =likely and 1 =would not answer. Of the text participants, 55% (6 of 11) indicated likely, 27% (3 of 11) did not know, and 18% (2 of 11) indicated they would not answer sign language questionnaires (M = 2.56, SD

= 0.73). Of the ASL participants, 56% (5 of9) did not know if they would answer questions
presented in sign language, 33% (2 of9) answered likely, and 11% (1 of 11) would not answer (M = 2.56, SD = 0.73) (see Figure 5-19).
7
-~---------·--··--·--··--·---··----------------------·-·--

6 . ;.........................................

·u
1'0

... i
Ill

5 ·+---······-···-··--'

I

·· .:;
;··

..· . .

lrt

fr~

::a

~;

Q.

4 --i-i·-·-··-------·-3

'f
D.

2
1

::~ I
Do Not Know Would Not Answer

I

iJ d:

0
likely
-------------~--------

I

. ------------···----------·----------..----·····------------·-·----J

Figure 5-19: Bar graph of participants answers to "Rate how likely you would answer questionnaires if they were presented in sign language" based on language

91

5.4.3 Open ended questions
From the two open-ended questions in the post-study questionnaire, there were a number of positive and negative impressions of the online form. A participant from the sign language group commented that they "thought it was interesting because [they were] able to see facial expressions that helped convey the questions and other things." Another commented that they liked that there were "more visuals and matching texts to signs." There were a number of comments regarding problems with the videos. Five participants from the sign language group and three from the text group mentioned they had difficulties because of the quality of the videos. Participants had trouble viewing the video clips. For example, one participant's comment stated, "I don't know the TV program and was not familiar with the characters. In addition, the actors were signing excessively fast, I had to replay several times just to get the finger spelling of the name of Snowflake Falls. Also, the colour quality of the videos was very bad and blurry, which made it more difficult to try to follow the signing." Also, "Not enough instructions on what it to be expected before watching the video" and "I didn't know what to watch out for in order to be able to answer the questions. If I could have played back the videos after seeing the questions, I probably would have done much better before submitting the answers" Four of the participants from the sign language group commented on the quality of the signing, especially the finger spelling. For example, "It was hard to understand the signs in the videos so I couldn't catch all the information that was given." and "I am not familiar with their variation of sign language. In the survey I was not able to find right answer."

Chapter 6
Discussion
As there is very little research to inform the use of American Sign Language for online interviewing, asking questions or surveying, and therefore it is difficult to anticipate the outcomes of my study. In addition, people in the deaf community live within in a larger hearing community with a text and speech being the dominant methods of communication. Deaf people are constantly exposed to text, particularly in the online environment even though many may prefer to communicate in ASL. However, it is very unclear whether that preference would transfer to preferences and performance outcomes in an online form environment when people are so accustom to working with text. The results from my study indicate some unexpected findings as well as some that seem to agree with other research on survey design.
.

6.1 Differences in performance and preferences in answering online questions between sign language and text users
The results of the analysis of the scores for the comprehension tests did not indicate any
"'~

., .. · .

.

·"'

significant difference, although some interesting differences did appear in the post clip and post study questionnaires. Participants using the sign language form rated their ability to understand the layout (see Figure 5-3) and the difficulty experienced in submitting answers online (see Figure 5-5) as significantly more difficult than those using the text forms. This could have been related to the

92

93

novelty of the web object or the lack of sufficient directions for use. Participants commented that "directions were not clear at the beginning", which would have led to difficulties with their ability to understand the layout and in submitting answers. However, both groups found it relatively easy to understand that layout and to submit the answers online. This result is not that surprising given that the layout used is that of a typical form layout that can be seen on many different websites. Most participants would have been exposed to this layout as 86% of people reported using the Internet. In addition, participants were able to understand the interface by the second video though many had trouble during their first video: "after taking the first survey it became clear for me to take the second survey ... familiarity is necessary to becoming comfortable answering questions". The responses to the statement in the user preference survey (UP) disagreed; in general, participants agreed that it was easy to submit their answers online indicating that some of the interface is usable. Initially though, ASL participants may have experienced more difficulties with this task due to the novelty of having a form in sign language. There may have been some confusion but after the first video, which was likely the first experience most participants had with an online sign language form, it appears that it was easy to understand. Comments indicated that the visible facial expressions, very important in sign language and Deaf culture were appreciated. This is missed when the information is presented in text form. There was also a significant difference between ASL and text participants in their preference for completing the survey in person. The deaf community is very visual in nature and person-to-person contact is a popular method of communication [2]. However, only 9% of ASL responses indicated that they would prefer person-to-person contact. The remaining responses were divided evenly between neutral and disagreement with participants preferring to complete a

. :;

94
survey in person with 46% (see Figure 5-4). The text participants also responded with strong disagreement: 86% responses of did not agree that they preferred in-person survey (see Figure 5-4). A number of participants commented that they had difficulties with the signs in the Deaf Planet videos and could not understand the signs for various reasons including the way the video was shot, the required prior familiarity with the characters, and the Canadian ASL dialect possibly less familiar to American participants. Although these are not attributes of the ASL survey forms developed in my thesis, it could have reduced comprehension scores and could possibly account for the significant difference in the responses to the statement "rather fill out in person". When working with another person, the participants would have been able to ask for clarification and the ASL speaking surveyor or interpreter would have had a similar dialect. From the post-study summative questionnaire (PS), all of the participants who used the text form found that the vocabulary used was simple. Most of the participants who used the ASL form also found it was simple (56%), however, 44% rated the vocabulary as difficult even though the show was aimed at older children (see Figure 5-6). The vocabulary difficulties may have led to perceived difficulties with the interface. In future studies, a measure of literacy level could be considered and then content presented at an appropriate level. From the results in Section 5.4.2, it seems that most participants (54% of participants using the text form and 33% of the participants using the ASL form) were interested in having online questions presented in sign language reported that they would be likely to answer questions if those questions were presented in sign language (see Figure 5-19). Overall, 77% of all participants were interested in the possibility of online questionnaires in sign language despite the some incongruence between the signs used in the questions and video material. Of all the participants, only one indicated that they would not use an online form in sign language. Most

95 comments supported the visual accessibility of ASL and its grammatical nuances and suggested that the presence of ASL helped comprehension of adjacent text. This positive result was indicative of the tendency of deaf people to prefer interaction in sign language. They were willing to overlook the issues due to the novelty of the sign web object, and thought that in the future, with more exposure to a signing web, they would become more comfortable with the interface and would use a similar interface if it were present on the web. Although there is no clear comprehension-performance advantage in having questions presented in sign language versus in text, there does seem to be a strong interest in the presentation of questions in sign language. Conducting the same study with more participants may provide evidence that there are performance differences. In addition, the ASL and text participants found the online forms preferable to paper-based surveys. This seems to indicate that even with the difficulties encountered with the SLS web object, and the quality of the sign language used, the sign language version of the web form is at least comparable to the text version. Further research into implementing sign language forms is warranted. Further studies could explore how to incorporate sign language forms into a sign language-based web. Extensions to this research could also include how open-ended questions could be used and the sign language responses analysed.
It is important to consider factors other than the intended treatment conditions that could

have influenced the responses, and through open-ended comments and analysis of survey results, several such factors became apparent, including the signing in the video clips used as the basis for the comprehension questions, the technical production of the video clips, and the experimental experience and learning effect.

96

6.1.1 Possible effects of the sign language videos used for comprehension
The videos had been chosen as specimens of conceptually simple sign language material that would be amenable to comprehension testing. Mid-lesson clips were extracted. There was not expected to be a significant difference between the two clips in relation to comprehensibility. However, when comparing the results based on the two videos, a difference in performance was noted between the two videos although it was not significant (see Figure 5-1). In addition, from the UP there was a significant difference in the ratings of level of difficulty between the two videos. The difference between the scores and difficulty levels for the two videos could be attibuted to the difficulty of the TACT versus the BVCT. These differences may be attributable to the types of signs used. The name signs used in the questions were different from those in the video clips. The characters were identified by sign name, and not necessarily by finger spelling the full name. The location names were finger spelled but participants commented that the "finger spelling was sloppy" and this made it more difficult to determine the name provided. Participants may have experienced m~re difficulty finding the correct answer for questions that
I

used character and location names because of this issue. The TACT contained more questions related to identifying individual characters whereas the BVCT was more focused on what happened or more generic signs, such as for "What ate the characters? A fish, frog or plant". This could have affected the answers participants gave, as they would be guessing which character was whiclf,'1md which location name was given rather than remembering and trying to choose the correct answer. However, the signs were similar enough that some people could determine the correct response to the questions, as a number of participants did correctly answer the questions.

· t
i

...

97 It seems that in addition to finding the questions difficult, there were difficulties in finding the answers. For TA, participants also found it was more difficult to find the answers than it was for BV (see Figure 5-6). This could also be attributed to the manner in which the answers were signed compared to the content of the video. For example for the question "How often do people get eaten?" the sign for "most of the time" in the answers was very similar to "all the time" in the video. The sign used for "all the time" in the answers was different from the sign used in the video and could have caused participants to incorrectly select "some of the time" as it closely resembled what they had viewed in the video. This could not be adjusted in the analysis by recoding, as it is unclear as to which interpretation the participant would make of the sign. Sign language perhaps does not lend itself well to multiple choice type questions where there must be a consistency between the answers and the content. However, questions that are more open ended or that allow multiple responses such as check box type questions may be better supported in sign language because there is a less direct relationship between the content and the form answers, allowing for the individual differences of signers.
I

In this study, the sign language is translated from a text script. Translation from text to

'

·

·

sign or vice versa may be problematic. A number of different interpretations are valid, as text to sign is not a direct straightforward process; for a given text script there is more than one way it could correct! y be signed. If the questions used in an online form are interpreted from text questions or scripts, rather than produced by a sign language speaker, the interpreter should be familiar with the content of the videos as well. The signing style and speed as well as video quality may also have affected people's ability to understand the content and the questions/answers. This may have caused misunderstandings with content of the questions. One participant commented that their use of

98

online sign language forms "depends on the quality of the signing and the person who signed did not have the best quality." The sign language videos were reviewed by competent signers prior to the start of the study, and they indicated that the signing style was sufficient to be able to understand what was being asked. Personal experience with signing could have made the signing seem to be lower quality for some individuals, which could also be attributed to the many different dialects of ASL and the lack of standards for signing. The videos were from a Canadian source and some participants were American deaf people. Although both use ASL, there are subtle differences. Unfortunately, nationality was not captured as a demographic variable for analysis.

6.1.2 Possible Effects of Technical Delivery Effects: Sign Speed, Video Quality
The speed of signing was, for some, too fast making it difficult to understand the signs, and thus to understand what was being asked. It appears that there is considerable variation on what constitutes good signing and therefore some preference functionality may need to be incorporated into any sign-based video content. As part of the web form interface, there is a "slow down" feature that reduces the playback speed of the video by half. This could have helped some of the participants who thought that the signing was too fast, as they could have slowed the signing speed down in the video to be better able to understand the signs. The "slow down" button is located at the side of the main video content and has "alt text" help available. No instructions were given for the use of this feature as I wanted to represent a realistic/ecologically valid experiment. No special training, other than help documentation, for an interface is usually available for web applications. Providing detailed instructions for this feature would be more than is normally available for a web application or web page.

99
The quality of the video clips, BV and T A, was not as high as that seen on television or high definition video because the original material had to be compressed in order to be viewable online in fairly low bandwidth environment (to fit the lower bandwidths available in most homes (e.g., DSL/cable modem speeds are 100 Mps). The quality of the video clips affected the participants from both groups. The quality of the video needs to be such so that the signs are clear and the download time is not excessive. The quality of the video is an important aspect when looking at designing sign language online forms. Without sufficient quality there will be a lack of responses to the form, as users will be frustrated trying to understand what is being asked of them. Videos need to be recorded at settings that are congruent with being viewed online. Without the need for recompression, these videos tend to be clearer than those that need settings changed in order to be acceptable for online viewing (e.g. file size, frame size, frame rate, etc). When these parameters are already set at the time of recording, the removal of the compression stages allows the videos to be clearer.

6.1.3 Effects of the Questions and Learning Effect
The difficulties with the questions could also have affected the responses given for the layout being difficult. Participants found the layout to be more difficult to understand for T A than for BV (see Figure 5-8). As the layout was the same for both tests, it seems that the difficulties encountered with the questions influenced the rating of the difficulty of the layout. Participants had better comprehension scores in whichever video they viewed second. The novelty of the SignLink Studio web object and interface may have caused this learning effect. Participants were unfamiliar with the interface and required further instructions than those provided. This may also be one reason why participants tended to perform better on the second video regardless of whether it wasTA or BV. In trying to achieve an ecologically valid

.. r.

100 experiment, little instruction was given on how to use the sign web form interface. This is how the form would be presented on a typical website. There was a learning effect, however, it seemed to be short duration as all participants became comfortable using the sign web form by the second video after being exposed to five or six questions for the comprehension test and nine questions for the user preference survey.

6.2 Difference in performance or preference for questions presented singly versus all at once
There is no significant difference for the scores when questions are presented singly versus all at once. This could indicate that there is no difference in the ability to answer questions between the two presentation styles, or more participants are required in order to determine any differences. In addition, no significant difference was found for the preference between the different ways that the questions were presented for any participant grouping (all, language or video). This result is congruent with the results reported by [46]. There does not seem to be a style that lends itself to a higher test score or the ability to
t

I

find correct answers. For TA, the average when questions were presented all at once (45%) was higher than when presented one at a time (42%), but with BV it was reversed, the average when presented one at a time (60%) was higher than when presented all at once (53%). The test that was considered more difficult, TA, had better scores when the questions were presented all at
~,

·

once and the easier test, BV, scored higher when the questions were presented one at a time. The TA test contained more names requiring finger spelling than the BV test and there was a discrepancy between the finger spelling in the video compared with the answers to the questions. Perhaps having all of the questions on display at once allowed participants to disambiguate the names a bit better because there was more context from the other questions. Whereas in BV there

101

was no help from the other questions and answering a question one at a time allowed participants to concentrate on that one question. If then there was no confusion with finger spelled names in the TA video, participants may have also scored better on the test where the questions were presented one at a time. There were no comments about the different styles of question presentation, so it does not seem that the participants were affected in any manner by how the questions were presented, a finding similar to [46] for text surveys. [46] found that there was no general preference to a particular style of presentation, though the different styles may lead themselves to be used in different situations.
It might seem that either method of presenting questions, singly or all at once, is equally

well accepted. A preference for software tools such as Survey Monkey may lead researchers to present the questions one at a time, as this requires less download time where only one video is downloaded at a time. In addition, there would be no conflicts in video download order, i.e., the second question would not load before the first question. However, due to the small number of participants that used the sign language version, a definite conclusion regarding the equality of both presentation styles cannot be made. Further studies with a larger participant base and a larger question set are required to determine whether there are any significant differences when sign language is used. An effort was made to have a larger number of participants, however due to technical difficulties encountered when the survey was first put online, almost 80 participants who attempted the study were unable to complete it. These studies could use one video with similar content and less finger spelling so that issues of finger spelling and differences in video content could be mitigated. In addition, questions where the answers are simple signs could assist in removing the issues with confusion

102 or closeness in answer possibilities. For example, the question from TA "What at the characters?" had the possible answers "fish", "frog", and "plant". All22 participants were able to answer this question correctly. The signs for fish, frog and plant are very straightforward and unambiguous among different signers. The study could investigate the contribution that poor versus high quality signing video and style would have on performance.

6.3 Effect of Individual Differences
The online survey experience of all participants seemed to influence their ratings. There was a significant relationship between online survey experience and the responses to the statements about whether the questions were difficult to answer, it was easy to find the answers, and completing the questions in person or online. Not surprisingly, those who used online surveys more often had less difficulty with the questions, found it easier to find the answers and preferred to answer the questions online, while those who had little or no experience with online surveys found it difficult to answer the questions, difficult to find the answers and preferred answering question in person (see Figure 5-10, Figure 5-11 and Figure 5-12). Difficulties participants experienced with the online questions could thus be due to their comfort with answering questions online regardless of style or language used. Online surveys often employ multiple choice style questions and therefore participants with more online survey experience may have found my online survey that contained multiple-choice questions easy to answer. The education of the participants also showed some effect on the UP responses. When comparing the responses of participants who had a postgraduate degree to those without a postgraduate degree there was a significant difference the level of detail expected for the directions (see Figure 5-13). Those with a post graduate degree tended to think that there was not

103 enough instructions while those without one did not. Those with a postgraduate degree may have had more opportunities to be exposed to test taking and exams containing multiple-choice questions and would be more familiar with how to answer these types of questions, and expected additional information that common in school exams. When responding to the statement regarding whether it was easier to complete a survey on paper, people with and without postgraduate degrees tended to disagree. However, those without a postgraduate disagreed more strongly than those with a post graduate degree (see Figure 5-14). This could be that people with post-graduate degrees were more comfortable with written, paper-tests where multiple-choice question were used. Some of the results found in my study could have been affected by education levels as people who are more highly educated in the North American system would likely be more familiar with test taking and more likely to have a higher literacy level. Having a more diversified representation of people at different education levels may change the results and future studies of the effect of sign language forms on "average" deaf users should deliberate! y sample to match the educational profile of the deaf community. However, this study did show that there are highly educated and literate members of the deaf community who can function as well in a text environment as they can in an ASL environment, and yet supported the availability of ASL components as a means to improve access and usability of web based forms.

6.4 Model
Re-examining the models introduced in Chapter 4 (see Figure 3-1 and Figure 3-6) there was no change to the portion depicted in Figure 3-1 as a result of this study. The implementation

104

of the database, and development and deployment elements of the online form functioned as designed and modelled. However, some precautions must be noted concerning the database. The question and answer tables must be properly populated with the question and answer variables prior to deployment. If the tables are not populated, the user responses are not recorded. Maintaining the database on a single is thus recommended. The sub-element model proposed in Figure 3-6 does require modification as a result of my study (see Figure 7-1). The layer showing presentation style has been modified to consist of one sub-element, called presentation style because there was no difference found in preference or performance for this sub-element. The choice of presentation style can be left to the form designer. The style used can be chosen based on technical requirements or limitations rather than a clear user preference as a presentation of all the questions at once may not be practical due to loads on servers from downloading all the video clips at one time. One-at-a-time information presentation may be more desirable as it spreads the downloading of the video over multiple pages and makes download delays less noticeable.

Internet Form

Multiple Choice

Question Type

Presentation Style

Presentation Style

Language

Language

Figure 6-1: Adjusted model of user information sub-elements

105 In addition, from my study there is also no obvious preference or performance advantage of ASL over English text. The model can be further reduced to a language element that contains ASL and text and that they are not mutually exclusive. However, if a sign language web is produced by web developers using tools such as Signlink Studio, then having ASL form elements is not only desirable but also feasible, as I have shown in this thesis.

6.5 Limitations
There were a number of limitations with my study that may have influenced the results. First, there were a low number of subjects. This did not allow for enough people in each condition. For the original eight treatments, there were three participants per treatment and with only 11 participants in each language group. The low number of participants caused difficulties with the statistical analysis of the data. The statistics carried out were limited to non-parametric analysis. This limited the analysis that could be preformed and the conclusions that can be drawn from the results of the analysis. In addition, there were a number of technical problems with the data system that caused a loss of data at the beginning of the study, thus reducing the number of participants drastically. From the NTID conference, the databases for the sign language portion of the study were not fully set up on two of the three computers used. This resulted in the corruption of data from three participants. Additionally, when the study first went live, there were problems downloading the video clips. As a result, about 80 participants were unable to complete the study. Having this number of participants would have greatly improved the reliability and validity of the results of this study. For future studies, more extensive pilot testing is needed to test the different internet conditions that will be encountered to ensure the functionality of the study.
I

II

..
'I
ll

106
The content of the video was a children's TV show. As all of the participants were adults, the content may have been unappealing to people and their dislike for the show may have influenced their attitudes towards or performance with the survey itself. For example, if people did not like the show then they may have not paid as much attention to it and this resulted in poorer performance on the evaluation questions. Video content that is more reflective of the age of the study participants may have changed these results. If the participants enjoyed the show more, they may have paid more attention to it and performed better. In addition, the show had a considerable amount of finger spelling and this could have caused some people difficulties. In general, finger spelling is fast and is not a native sign. This can cause viewers to miss information because they do not know what is being spelled. Participants commented that they had to replay parts of the video a number of times in order to notice certain names that were finger spelled. Some participants may have not noticed the name and continued without knowing what was being signed, as they did not know what to expect out of the questions. The clips used in the study were relatively short (two minutes) and taken from the middle of the show. If people were exposed to longer clip including the introduction of the characters, they may have been better able to disambiguate the finger spelling and some of the signs that were confusing. In addition, they would have had more opportunities to see the finger spelled words and had more exposure to the show's context. This may have reduced the confusion with some of the names and helped people understand more of the content of the show. As a result, people may have performed better on the comprehension questions and may have had different responses to the questionnaires in general. The attitude towards the questions, both text and sign language, may have been more positive since there would have been less confusion amongst the
II .. lt
'I

107 characters and location names. The short length of videos did not allow for many questions on the content (only five or six). As a result, only a limited number of components in the video could be tested. This did not give the participants much room for errors. Missing two or three questions had a significant impact on a participant's total score. Longer videos would allow for longer questionnaires and for more context from which to draw understanding, which would in tum affect people's opinion of the form language and/or presentation style. Another limitation with the videos was that they were taken from two different shows, thus giving them unrelated content. There could have been confusion with the second video as to which video the questions related, even though the instructions indicated that the questions were for the video preceding. A solution would be to present one show and take questions from different parts of the show to use for the two questionnaires. There would be less opportunity for no confusion as to which video the recollection was referring. The comprehension tests were constructed by a hearing researcher and were based on the audio portion of the videos. The test questions may not have been worded in the most appropriate way reflecting the signs or expression used. A possible solution to this issue would be to have a deaf educator help design the questions for future studies to ensure that the main concepts that are signed are the ones being used for the questions. There were a number of problems with the sign quality and speed for the survey questions. The signer was not familiar with signing in the show and used signs that could have been confusing to the participants. In addition, the overall quality of the video clips was distorted due to the compression needed in order to translate from the DVD quality clip to one that would be suitable for the web. Some of the signs were blurry as a result. This could have greatly affected the performance scores for participants, as they would not have the same comprehension
'I
II

108

of the video content, which in tum would affect the attitude towards the questionnaires on a whole. This might have affected their attitude responses, as they may not have seen it as having difficulties with the questions and may have found the questions easier to answer. The over representation of highly educated participants in the study group did not reflect the education levels of a general population or of the deaf community, which tends to be limited to lower levels of education [53]. Most of the participants (55%) had completed postgraduate degrees and 77% had obtained a university or college degrees. The highly educated population could have skewed the results for the text group, as they would tend to be more comfortable with text and test taking than the average deaf person due to the amount of schooling received. Another limitation in this research is the use of a multiple-choice instrument to evaluate comprehension. Performance on "tests" is not necessarily the most appropriate or ideal method for measuring user's understanding of a piece of content, particularly when it is not an educational setting. Written or signed summaries, focus group discussions and real time assessment (talk aloud or logs) may be more robust methods. However, the purpose of using the multiple-choice format was to present the choices in sign language or text and then examine whether language had any effect on performance. The value of the grade achieved by participants was not important in this study but rather any differences occurring because of language. Future studies may consider using alternative methods such as written or signed summariesi'or measuring performance and for comparing user performance between sign language and text alternatives.
I
I

109

6.6 Recommendations
Sign language online forms can be used to present questionnaires to the sign language community. When creating a sign language form, consideration of the script for the video content should be made. The signer should be familiar with the content of the questions prior to filming and the sign language be checked with a deaf interpreter in order to ensure that the content is accurate. The size of the video files must be taken into consideration. As the download time for questions should be kept to a minimum, to encourage participant usage. However, a minimum quality must be ensured to maintain sign readability. The presentation style is up to the questionnaire designer, however technical limitations of the Internet would suggest that a one-at-a-time style be used, or at least keeping the number of questions per page to a minimum to reduce the download time. Questions that that keep the amount of finger spelling to a minimum would be preferred. The use of signs must be monitored because of the different dialects that have emerged. Signing should be done in a formal way, trying to keep signs to a more general nature (i.e. not use local gen. Additional instructions for the use of the web object should be given. A help link to explain the functionality of the web object to help reduce confusion would be helpful. Participants commented that they were unsure how to use the web object for the first test but by the second test, they understood the workings. Perhaps including sample question in order to ensure user familiarity to the system would be warranted. I would also recommend incorporating form functionality into the SignLink Studio 2.0 tool because SignLink Studio is designed for creating sign language web pages.

Chapter 7 Conclusion and Future Work
There were two major findings from this thesis: there was similar performance and preference results between ASL and text groups; and people had similar performance and preference results with questions presented one at a time and presented all at a time. However, there were a small number of subjects and future research should involve more people with greater diversity. Creating and implementing online sign language forms appears to be feasible. Sign language users were able to successful complete the forms as well as they could with text. They indicated that they would be interested in seeing and using sign language forms online. Having sign language forms seems to fit within peoples' notion of Deaf culture. Designers and web content developers can use other requirements, rather than performance requirements, to determine whether form question would be presented all at a time or one at a time. For example, bandwidth limitations may determine that questions should be presented one at a time. As a result of these findings, the system model for online forms that are inclusive for people who are sign language users had a presentation style layer and a language layer that does not show a preference for either variable. There was some evidence to indicate that preferences are influenced by online form experience and education. Participants that had more experience with online text forms were

110

111 more positive about using online sign language forms and had fewer difficulties in the study. Participants with higher education showed did not show as much difference in preference between online and paper, and between text and ASL. They also wanted more documentation. More research is required with a more diverse group of subjects for education and online experience to determine the influence of these factors. Difficulties were experienced in understanding with the procedure and with the sign language. For future research, more instructions on the use of the web form object are needed to reduce the influence of confusion with the instructions on the outcome of the study. The issues with the sign language quality related to signer inconsistency, bandwidth limitation, and quality reduction due to compression. Greater consistency between the signing in the video clip and the questions is needed. Scripting and careful preparation would help mitigate these issues. Consideration for the technical properties of the user's hardware and connectivity is important. A possible next step would be to add sign language form functionality to a web page design tool such as SignLink Studio, along with appropriate help documentation in sign language. Web developers could then explore how to use sign language forms on web pages. Finally, only multiple-choice interfaces were considered for this study and were successful. This then points to the need to expand the research into other form elements, such as user input fields that would allow video data management for sign language interaction.

Appendix A
XML File and Parser
A.l Xml File
The following is the XML file for the To Air is Human survey. There are five questions in the survey. The form information is contained within a <aslproject> tag. Each question is represented by a <movie> </movie> tag pair. Contained in the <movie> tags are three main tags:
<questiontype>, <signicons>,

and <transcript>. The <questiontype> tag will tell if the

question is checkbox or radio (button). The <signicons> tag contains a set of <signicon> tags that represent each available answer. The <signicon> contains the start and end times for the answer, the frameoverlay information and the optional text label. Finally, the <transcript> tag contains the text for the optional text area. The text in the <transcript> tag within the
< 1 [ CDATA [

1 1 > tag will be outputted as HTML.

<aslproject> <movie src="slsvideo/toair/question_l.mov" ID="l" duration="77400" timescale="2997"> <questiontype>checkbox</questiontype> <signicons path="signlink_images/toair/1/"> <.,Signicon src="l.JPEG" ID="l"> ~ ~movietime start="27609" end="35307" frametime="2. 9409e+4 "/> <frameoverlay left="53" top="21" height="165" width="220" /> <label> </label> </signicon> <signicon src="2.JPEG" ID="2"> <movietime start="39231" end="51929" frametime="4.1031e+4"/> <frameoverlay left="46" top="17" height="179" width="238" /> <label> </label> </signicon> <signicon src="3.JPEG" ID="3">

112

113
<movietirne start="53536" end="62778" frarnetime="5.4736e+4"/> <frarneoverlay left="S3" top="21" height="174" width="232" /> <label> </label> </signicon> <signicon src="4.JPEG" ID="4"> <movietime start="67315" end="72498" frarnetirne="6.9915e+4"/> <frarneoverlay left="48" top="22" height="169" width="225" /> <label> </label> </signicon> </signicons> <transcript title=""> <! [CDATA[<p>Question 1. Which of the following characters were in the boat at the beginning of the scene? Check all that apply.</p> <p> <input type="checkbox" narne="ansl" id="ansl" value="l" onclick="autoSelect(this,document.form.ansl_sign,O)" /> Max<br /> <input type="checkbox" narne="ansl" id="ansl" value="2" onclick="autoSelect(this,document.forrn.ansl_sign,l)" /> Kendra<br /> <input type="checkbox" narne="ansl" id="ansl" value="3" onclick="autoSelect(this,document.forrn.ansl_sign,2)" /> Wilma<br /> <input type="checkbox" narne="ansl" id="ansl" value="4" onclick="autoSelect(this,document.form.ansl_sign,3)" />None of the above</p>
] ] >

</transcript> </movie> <movie src="slsvideo/toair/question_2.mov" ID="2" duration="57000" tirnescale="2997"> <questiontype>radio</questiontype> <signicons path="signlink_irnages/toair/2/"> <signicon src="l.JPEG" ID="l"> <rnovietirne start="37171" end="41869" frarnetirne="4.0371e+4"/> <frarneoverlay left="50" top="23" height="164" width="218" /> <label> </label> </signicon> <signicon src="2.JPEG" ID="2"> <movietime start="44079" end="49977" frarnetime="4.7079e+4"/> <frarneoverlay left="36" top="19" height="167" width="222" /> <label> </label> </signicon> <signicon src="3.JPEG" ID="3"> <movietime start="51567" end="55665" frarnetime="5.3367e+4"/> <frarneoverlay left="33" top="20" height="180" width="240" /> <label> </label> </signicon> </signicons> <transcript title=""> <! [CDATA[<p>Question 2. What ate Max, Kendra, and Wilrna?</p> <p> <input type="radio" name="ans2" id="ans2" value="l" onclick="autoSelect(this,document.form.ans2_sign,O)" />A fish<br />

114
<input type="radio" name="ans2" id="ans2" value="2" onclick="autoSelect(this,document.form.ans2_sign,l)" />A frog<br /> <input type="radio" name="ans2" id="ans2" value="3" onclick="autoSelect(this,document.form.ans2_sign,2)" />A plant</p>
] ] >

</transcript> </movie> <movie src="slsvideo/toair/question_3.mov" ID="3" duration="56000" timescale="2997"> <questiontype>radio</questiontype> <signicons path="signlink_images/toair/3/"> <signicon src="l.JPEG" ID="l"> <movietime start="22493" end="28373" frametime="2.4002e+4"/> <frameoverlay left="47" top="21" height="167" width="222" /> <label> </label> </signicon> <signicon src="2.JPEG" ID="2"> <movietime start="32293" end="38640" frametime="3.4246e+4"/> <frameoverlay left="48" top="18" height="168" width="224" /> <label> </label> </signicon> <signicon src="3.JPEG" ID="3"> <movietime start="40880" end="47040" frametime="4.228e+4"/> <frameoverlay left="38" top="20" height="178" width="237" /> <label> </label> </signicon> <signicon src="4.JPEG" ID="4"> <movietime start="50773" end="54332" frametime="5.2234e+4"/> <frameoverlay left="40" top="15" height="171" width="228" /> <label> </label> </signicon> </signicons> <transcript title=""> <! [CDATA[<p>Question 3. How often do people get eaten?</p> <p> <input type="radio" name="ans3" id="ans3" value="l" onclick="autoSelect(this,document.form.ans3_sign,O)" <input type="radio" name="ans3" id="ans3" value="2" onclick="autoSelect(this,document.form.ans3 sign,l)" /> <input type="radio" name="ans3" id="ans3" value="3" onclick="autoSelect(this,document.form.ans3 sign,2)" <input type="radio" name="ans3" id="ans3" value="4" onclick="autoSelect(this,document.form.ans3_sign,3)"
] ] >

/>All the time<br /> />Once in a while<br

/> Rarely<br /> /> Never</p>

</transcript> </movie> <movie src="slsvideo/toair/question_4.mov" ID="4" duration="56800" timescale="2997"> <questiontype>radio</questiontype> <signicons path="signlink_images/toair/4/"> <signicon src="l.JPEG" ID="l"> <movietime start="20794" end="27405" frametime="2.2707e+4"/>

115
<frameoverlay left="38" top="21" height="178" width="237" /> <label> </label> </signicon> <signicon src="2.JPEG" ID="2"> <movietime start="29546" end="37341" frametime="3.1146e+4"/> <frameoverlay left="33" top="20" height="197" width="262" /> <label> </label> </signicon> <signicon src="3.JPEG" ID="3"> <movietime start="38959" end="47365" frametime="4.0559e+4"/> <frameoverlay left="43" top="19" height="191" width="254" /> <label> </label> </signicon> <signicon src="4.JPEG" ID="4"> <movietime start="49037" end="55285" frametime="5.2803e+4"/> <frameoverlay left="32" top="19" height="183" width="244" /> <label> </label> </signicon> </signicons> <transcript title=""> <! [CDATA[<p>Question 4. Who do the characters say will NOT die?</p> <p> <input type="radio" name="ans4" id="ans4" value="l" onclick="autoSelect(this,docurnent.forrn.ans4 sign,O)" <input type="radio" name="ans4" id="ans4" value="2" onclick="autoSelect(this,docurnent.form.ans4 sign,l)" <input type="radio" name="ans4" id="ans4" value="3" onclick="autoSelect(this,docurnent.form.ans4_sign,2)" <input type="radio" name="ans4" id="ans4" value="4" onclick="autoSelect(this,docurnent.form.ans4 sign,3)" above</p> ] ] >

/> Max<br /> /> Kendra<br /> /> Wilma<br /> />None of the

</transcript> </movie> <movie src="slsvideo/toair/question_S.mov" ID="5" duration="66600" timescale="2997"> <questiontype>radio</questiontype> <signicons path="signlink_images/toair/5/"> <signicon src="l.JPEG" ID="l"> <movietime start="33966" end="38406" frarnetime="3.6877e+4"/> <frarneoverlay left="49" top="29" height="164" width="218" /> <label> </label> </signicon> <signicon src="2.JPEG" ID="2"> <movietime start="42680" end="47578" frarnetime="4.468e+4"/> <frarneoverlay left="48" top="23" height="186" width="248" /> <label> </label> </signicon> <signicon src="3.JPEG" ID="3"> <movietime start="51948" end="57720" frarnetime="5.3349e+4"/> <frarneoverlay left="46" top="18" height="170" width="227" />

116
<label> </label> </signicon> <signicon src="4.JPEG" ID="4"> <movietime start="61315" end="65013" frametime="6.2915e+4"/> <frameoverlay left="42" top="21" height="177" width="236" /> <label> </label> </signicon> </signicons> <transcript title='"'> <! [CDATA[<p>Question 5. What does Max say he will smell like at his funeral?</p> <p> <input type="radio" name="ans5" id="ans5" value="l" onclick="autoSelect(this,document.form.ansS_sign,O)" /> Fish<br /> <input type="radio" name="ans5" id="ansS" value="2" onclick="autoSelect(this,document.form.ansS_sign,l)" /> Flowers<br /> <input type="radio" name="ans5" id="ans5" value="3" onclick="autoSelect(this,document.form.ans5_sign,2)" /> Dirt<br /> <input type="radio" name="ans5" id="ans5" value="4" onclick="autoSelect(this,document.form.ans5_sign,3)" /> Nothing</p>
] ] >

</transcript> </movie> </aslproject>

A.2 Xml Parser
A PHP script is used to receive the XML file as input creating an XML parser:
<?php if (! ($fp=®fopen ($filename, "r"}}} { echo "Couldn't open XML."; return;}; $questioncount=O; $answercount=O; $userdata=array(); $state=''; if (! {jxml_parser = xml_parser_create ())} die"'(~ouldn' t create parser. ") ;

The parser keeps track of the number of questions and the number of answers for each question by setting $questioncount and $answercount to zero at this point. $userdata will later be filled with data for each question and $state is used to keep track of which node the parser is dealing with for each question.

117 The XML parser needs two functions to be declared, one to handle the element data and one to handle the character data within the elements. These functions are tailored to the individual XML schema based on the element and attribute names. Element Handler has two parts, a function to detect the start of real data and a function to detect when an element ends - in this case, to register when more than one answer is specified. Each function is called once for each node - a switch statement is used to decide what action to take depending on which node is being processed. The parser takes care of the $name and $attrib variables.
function global global global global startElementHandler ($parser, $name, $attrib){ $questioncount; $answercount; $userdata; $state;

switch ($name) { case ($name == "MOVIE") : { $userdata[$questioncount] $userdata[$questioncount] $userdata[$questioncount] $userdata[$questioncount] break;

["duration"] = $attrib["DURATION"]; ["src"] = $attrib["SRC"]; ["timescale"] = $attrib["TIMESCALE"]; ["id"] = $attrib["ID"];

case ($name == "MOVIETIME") : { $userdata[$questioncount] ["answer"] [$answercount] ["end"] $attrib ["END"] ; $userdata[$questioncount] ["answer"] [$answercount] ["start"] $attrib["START"]; $userdata[$questioncount] ["answer"] [$answercount] ["frametime"] $attrib [ "FRAMETIME"] ; break; case ($name=="FRAMEOVERLAY") : { $userdata[$questioncount] ["answer"] $attrib["HEIGHT"]; $userdata[$questioncount] ["answer"] $attrib ["LEFT"] ; $userdata[$questioncount] ["answer"] $attrib ["TOP"] ; $userdata[$questioncount] ["answer"] $attrib["WIDTH"]; break; [$answercount] ["height"] [$answercount] ["left"] = [$answercount] ["top"] = [$answercount] ["width"]

}
case ($name=="SIGNICON") : { $userdata[$questioncount] ["answer"] [$answercount] ["src"] $attrib ["SRC"]; $userdata[$questioncount] ["answer"] [$answercount] ["id"] $attrib [ "ID"] ;

118
break; case ($name=="SIGNICONS") $userdata[$questioncount] ["answer"] = array(); $userdata[$questioncount] ["path"] = $attrib["PATH"]; break; default : $state=$narne; break;

}

} II switch II startElementHandler
function global global global global endElementHandler ($parser, $name){ $questioncount; $answercount; $userdata; $state;

$state= ' ' ; if ($name=="MOVIE") {$questioncount++; $answercount=O;} if ($name=="SIGNICON") {$answercount++; } II endElementHandler

Next, a character handler to retrieve the information that is contained between open and close tags:
function global global global global characterDataHandler ($parser, $data) $questioncount; $answercount; $userdata; $state; {

if (!$state) {return;} if ($state=="QUESTIONTYPE") $userdata[$questioncount] ["qtype"]

$data;

if ($state=="LABEL") $userdata[$questioncount] ["answer"] [$answercount] ["label"] if ($state=="TRANSCRIPT") { if (isset($userdata[$questioncount] ["transcript"])) $userdata[$questioncount] ["transcript"] .= $data; else $userdata[$questioncount] ["transcript"] = $data;

$data;

}

II characterDataHandler
Finally, tell the parser which functions to use, read the data from the opened file and parse the contents.

119
xml_set_element_handler( $xml_parser, "startElementHandler", "endElementHandler"); xml_set_character_data_handler( $xml_parser, "characterDataHandler"); while( $data= fread($fp, 4096)) { if(!xml_parse($xml_parser, $data, feof($fp))) break;

{

xml_parser_free($xml_parser);

The data from the XML file is now held in $us erda ta and can be accessed using a standard PHP loop. Once the data is accessed, it is inserted into a MySQL database in order to be used.
echo 1 <br> 1 ; foreach($userdata as $data) { $sql = "INSERT INTO myform_question (qtype,src,qid,timescale,duration,transcript,sign_image,ans) VALUES ( I II; if ($data[ 1 qtype 1 ] == "radio") $sql .= 1; else if ($data [ 1 qtype 1 ] == "checkbox") $sql . - 2; $sql .=" 1 , 1 ".$data["src"] ." 1 , 1 " ; $sql .= $data[ 11 id 11 ] · II I I I II j $sql .= $data["timescale"] ." 1 , 1 " ; $sql . = $data ["duration"] . " 1 , \ " " ; if (isset($data["transcript"])) $sql .= str replace( 1 " 1 ,"&quot;",$data["transcript"]) ."\", else $sql . = 1- ; - \ " , 1 " ; $sql ·- $data ["path II] · II I I I II j $sql . = count ($data [ 1 answer 1 ] ) · " 1 ) " ; $sql = preg_replace( 1 /myform_/ 1 , $_POST[ 1 prefix 1 ] , $sql); echo $sql. 1 <br> 1 ; $result = mysql_query($sql); echo mysql_error(); $qid = mysql_insert_id(); foreach ($data[ 1 answer 1 ] as $ans) { $sql = "INSERT INTO myform_answer (qid,aid,image,endtime,starttime,frametime,label) VALUES ( 1 ".$qid." 1 , 111 ; $sql .- $anS [ 11 id 11 ] . II I 1 I II j $sql .= $ans ["src"]." 1 , 1 " ; $sql .- $ans ["end"]." 1 , 1 " ; $sql .= $ans ["start"]." 1 , 1 " ; $sql .- $ans["frametime"] ." 1 , 111 ; $sql · =II I) II j $sql = preg_replace( 1 /myform_/ 1 echo $sql. 1 <br> 1 ; $result= mysql_query($sql); echo mysql_error();
,

1

";

$_POST[ 1 prefix 1 ] , $sql);

120

?>

A.3 MySQL Database
The following is the MySQL database after being populated by the above XML parser for the To Air is Human survey. The tables question and answer, as described in Section 3.2.1 are populated by parsing the XML file from Section A.1 using the XML parser described in Section A.2. Table A-1 contains the values for table question and Table A-2 contains the values for table answer.

121

id qid qtype src
I I

timescale duration ans transcript

sign_image
signlink_images/toair/ II

2

slsvideo/ toair/ question_l.m ov

2997

77400

4

<p>Question I. Which of the following charaters were in the boat at the beginning of the scene? Check all that apply.</p> <p> <input type=""checkbox"" name=""ansl "" id=""ans 1"" value="" 1"" <p>Question 2. What ate Max, Kendra, and Wilma?</p> <p> <input type=""radio"" name=""ans2"" id='"'ans2"" value=""!"" onclick=""autoSelect(this,document. form.ans2 _sign,O)"" />A fish<br /> <inout tvoe=""radio" 11 name= 11 "ans2" 11 <p>Question 3. How often do people get eaten?</p> <p> <input type=" 11radio" 11 name= 11 "ans3 11 " id=11 "ans3 1111 value="" 1"11 onclick= 1111autoSelect(this,document.form.ans3 _sign,0)" 11 />All the time<br /> <p>Question 4. Who do the characters say will NOT die?</p> <p> <input type=""radio1111 name=""ans4 "11 id=""ans4"" value=""!"" onclick= 11 "autoSelect(this,document.form.ans4 _sign,0) 11 " I> Max<br I> <p>Question 5. What does Max say he will smell like at his funeral?</p> <p> <input type=""radio"" name=""ans5"" id=""ans5"" value=" 11 1"11
nnrlirlr="":mtn~Plf't'tfthi<:

2 2

slsvideo/ toair/ question_2.m ov

2997

57000

3

signlink_images/toair/ 2/

3 3

slsvideo/ toair/ question_3.m ov

2997

56000

4

signlink_images/toair/ 3/

4 4

slsvideo/ toair/ question_4.m ov

2997

56800

4

signlink_images/toair/ 4/

5 5

slsvideo/ toair/ question_5.m ov

2997

66600

4

signlink_images/toair/ 51

rlnrnmPnt fnnn

~n<:'i

Table A-1: Table question populated with To Air is Human data

122

id qid aid 1 1 1 2 1 2 3 1 3 4 1 4 5 2 1 6 2 2 7 2 3 8 3 1 9 3 2 10 3 3 11 3 4 12 4 1 13 4 2 14 4 3 15 4 4 16 5 1 17 5 2 18 5 3 19 5 4

image label starttime endtime frametime 2 35307 27609 l.JPEG 51929 4 39231 2.JPEG 62778 5 53536 3.JPEG 72498 6 67315 4.JPEG 41869 4 37171 l.JPEG 4 49977 44079 2.JPEG 5 55665 51567 3.JPEG 2 28373 22493 l.JPEG 3 38640 32293 2.JPEG 4 47040 40880 3.JPEG 54332 5 50773 4.JPEG 2 27405 20794 l.JPEG 37341 3 29546 2.JPEG 4 47365 38959 3.JPEG 5 55285 49037 4.JPEG 3 38406 33966 l.JPEG 4 47578 42680 2.JPEG 5 57720 51948 3.JPEG 6 65013 61315 4.JPEG

Table A-2: Table answer populated with To Air is Human data

Appendix B Study Questionnaires
The pre-study questionnaire was presented in English all participants. The comprehension questionnaires were presented in ASL for those participants who were in the sign language group and in English for those in the text group. The questionnaires was also presented all at once as shown or one question at a time depending on the style for the treatment. The poststudy questionnaire was presented in text to all.

B.l Pre-Study Questionnaire
The purpose of this questionnaire is to gather information about you and your current usage of computers and online forms. It should take you about ten minutes to complete this questionnaire. Thank you in advance for your time and assistance.
Question 1. Please indicate your age. 0 18-29 0 30-39 0 40-49 0 50-59 0 60+ Question 2. What is your gender? o Male o Female Question 3. What is your hearing status? o hearing o hard of hearing o deaf o deafened o cochlea implant

123

124
Question 4. What is your last completed level of education? o less than High School Diploma o High School Diploma o College Level Diploma o Bachelor or Undergraduate Degree o Post-Graduate Degree (e.g., Masters or PhD) o Other Question 5. Please indicate your level of computer experience where Novice is someone who is just starting to use a computer for basic tasks such as browsing the Internet and Advanced is someone who is a computer programmer. o Novice o Intermediate o Advanced Question 6. D D D What kinds of computer applications do you use? (Select all that apply) Office productivity (word processing, spreadsheet, etc) Internet (Firefox, Opera, Skype, Facebook, etc.) Programming (C, Java, etc) Web Programming (Dreamweaver, Front Page, etc) Multimedia (Photoshop, MovieMaker, iMovie, Sound editing, etc.) Video Games Other How long have you been using sign language? less than 1 year 1-5 years 6- 10 years more than 10 years

D
D D

D
Question 7. o o o o

Question 8. Which sign languages do you use/understand? D American Sign Language (ASL) D Langue des Signes Quebecoise (LSQ) 0 International Sign Language (ISL) 0 CASE 0 Signed English 0 Other Question 9. What type of online sign language web sites do you access? ""I:SI I do not use online sign language websites 0 News websites D Personal websites 0 Deaf Organization websites D Dictionary websites 0 Other, please specify _ _ _ _ _ _ __

125
Question 10. Do you participate in online surveys (web polls, site feedback, product surveys, ecommerce)? o Never o Rarely (once a year) o Sometimes (3-4 times a year) o Often (monthly) o Frequently (weekly) o Regularly (daily)

126

B.2 Comprehension Test
B.2.1 To Air Is Human Comprehension Test
The purpose of this questionnaire is to evaluate your understanding of the show's plot, and characters. There are five questions on this questionnaire and it will take you approximately five minutes to complete. Thank you in advance for your time and assistance. Question 1. Which of the following characters were in the boat at the beginning of the scene? Check all that apply.

D Max

D Kendra D Wilma D None of the above
Question 2. What ate Max, Kendra, and Wilma? o A fish o A frog o Aplant Question 3. How often do people get eaten? o All the time o Once in a while o Rarely o Never Question 4. Who do the characters say will NOT die? o Max o Kendra

o o

Wilma
None of the above

Question 5. What will Max smell like at his funeral? o Fish o Flowers o Dirt o Nothing

127

B.2.2 Bad Vibrations Comprehension Questionnaire
The purpose of this questionnaire is to evaluate your understanding of the show's plot, and characters. There are six questions on this questionnaire and it will take you approximately five minutes to complete. Thank you in advance for your time and assistance. Question 1. What is Kendra's favourite place on Deaf Planet? o Flower Meadow o Rainbow Falls o Snowflake Falls o Horseshoe Fails Question 2. Which character is waiting for the others to arrive? o Hank o Kendra o Wilma o Max o None of the above Question 3. Whose birthday are the characters celebrating? o Hank o Kendra o Wilma o Max o None of the above Question 4. o o o o Where did Max crash his rocket ship? Hank's apartment Kendra's apartment Snow Top Mountain Snowflake Falls

Question 5. What is Kendra wearing? Select all that apply. 0 Flower earrings 0 Long sleeve red shirt 0 Short sleeve green shirt 0 Red dress Question 6. o o o o What happens when Max tries to fly the hovercraft? He crashes into the side of the mountain He shakes the snow loose on top of Kendra He shakes the snow loose on top of Hank He falls over the cliff

128

B.3 User Preference Survey
The purpose of this questionnaire is to gather your opinion of the form style used to present the comprehension questions. There are nine questions on this questionnaire. Thank you in advance for your time and assistance. Please rate how much you agree with the following statements:
strongly agree
1. The questions were difficult to answer 2. It was easy to find the answers to the questions 3. It was easy to make mistakes answering the questions 4. Directions were not detailed enough 5. Layout is difficult to figure out 6. Survey is too plain 7. Rather fill out survey in person 8. Submitting answers online is difficult 9. Easier to fill out survey on paper

agree

neither agree nor disagree

disagree

strongly disagree

129

B.4 Post Study Summative Questionnaire
B.4.1 English Text Questionnaire
The purpose of this questionnaire is to gather your opinion of the forms presented and about sign language online forms. There are six questions in this questionnaire. It should take about ten minutes to complete. Thank you in advance for your time and assistance. Question 1. Please rate how difficult it was to understand the level of English vocabulary used. Very easy Easy Neither easy nor difficult Difficult Very difficult Question 2. Please rate how easy it was it for you to fmd the answers to the questions about Deaf Planet? Very easy Easy Neither easy nor difficult Difficult Very difficult

Question 3. How much better/worse do you think that you would have done if the questions were in sign language? Much better Somewhat better Same Somewhat worse Much worse Question 4. How likely would you answer questionnaires if they were presented in sign language? Very likely Likely Don't know Not likely I would not answer Question 5. What did you like most about your experience using text forms? Question 6. What did you like least about your experience using text forms?

130

B.4.2 ASL Questionnaire
The purpose of this questionnaire is to gather your opinion of sign language forms. There are seven questions on this questionnaire. It should take you about ten minutes. Thank you in advance for your time and assistance. Question 1. Please rate how difficult it was to understand the level of sign language vocabulary used. Very easy Easy Neither easy nor difficult Difficult Very difficult Question 2. How would you rate the speed of the sign language questions and answers? Very fast Fast Just right Slow Very Slow Question 3. Please rate how easy it was for you to find the answers to the questions about Deaf Planet? Very easy Easy Neither easy nor difficult Difficult Very difficult Question 4. How much better/worse do you think that you would have done if the questions were in text? Much better Somewhat better Same Somewhat worse Much worse Question 5. How likely would you answer questionnaires if they were presented in sign language? Very likely Likely Don't know Not likely I would not answer Question 6. What did you like most about your experience using sign language forms? Question 7. What did you like least about your experience using sign language forms?

Appendix C Ryerson Research Ethics Board Approval

RYERSON UNIVERSITY
To: Norma Thompson ELCE Re : REB 2008-166 : Sign language web forms Date: July 7, 2008

Dear Norma Thompson, The revievv of your protocol REB File REB 2008-166 is now complete. The project has been approved for a one year period. Please note that before proceeding with your project, compliance with other required Universicy approvals/certifications, institutional requirements, or govemmental authorizations may be required. This approval may be extended after one year upon request. Please be advised that if the project is not renewed, approval will expire and no more research involving humans may take place. If this is a funded project, access to research funds may also be affected. Please note that REB approval policies require that you adhere strictly to the protocol as last reviewed by the REB and that any modifications must be approved by the Board before they can be implemented. Adverse or unexpected events must be reported to the REB as soon as possible with an indication from the Principal Investigator as to how, in the vie\1\r of the Principal Investigator, these events affect the continuation ofthe protocol. Finally, if research subjects are in the care of a health facility, at a school, or other institution or community organization, it is the responsibility of the Principal Investigator to ensure that the ethical guidelines and approvals of those facilities or institutioos are obtained and filed with the REB prior to the initiation of any research. Please quote your REB file number (REB 2008-166) on future correspondence. Congratulations and best of luck in conducting your research.

Nancy \Valton, Ph.D. Chair, Research Ethics Board

131

Bibliography
[1] W. C. Stokoe, "Sign Language Structure: An Outline of the Visual Communication Systems of the American Deaf," The Journal ofDeaf Studies and DeafEducation, vol. 10, pp. 3-3 7, Winter. 2005. [2] M. Adams, W. J. Blumenfeld, H. W. Hackman, M. L. Peters and X. Zuniga, Readings for Diversity and Social Justice. New York: Routledge, 2000, [3] M. Koutsoubou, R. Herman and B. Woll, "Does Language Input Matter in Bilingual Writing? Translation Versus Direct Composition in Deaf School Students' Written Stories," International Journal ofBilingual Education & Bilingualism, vol. 10, pp. 127-151, 03. 2007. [4] "User agent accessibility guidelines 1.0," I. Jacobs, J. Gunderson, E. Hansen, eds., W3C Recommendation December 2002 [Online] Available: http://www.w3.org/TRIUAAG10/ [5] T. Bemers-Lee, "The World Wide Web: Past, Present, and Future", Computer, vol. 29, no. 10, pp 69-77, Oct 1996 [6] SignPost lTV, "Welcome to SignPost," SignPost BSL, 2006 [Online] Available: http://www.signpostbsl.com/ [7] British Deaf Association, "BDA Sign community: Welcome to the British Deaf Association," Sign Community, 2009. [Online] Available: http://bda.org.uk/

[8] "A basic guide to ASL," April13, 2009 [Online] Available: http://www.masterstechhome.com/ASLDict.html
[9] J. Col, "ASL (American Sign Language)" Enchanted Learning, 2009 [Online] Available: http://www.enchantedleaming.com/themes/asl.shtml [10] W. Vicars, "American Sign Language," ASL University, [Online] Available: http://ww~ifeprint.com/asl1 01/ [11] J. A. Lapiak, "American Sign Language," Handspeak, 2009 [Online] Available: http://www .handspeak.com/ [12] D. I. Pels, J. Richards, J. Hardman, S. Soudian and C. Silverman, "American sign language of the web," in CHI '04: CHI '04 Extended Abstracts on Human Factors in Computing Systems, 2004, pp. 1111-1114.

132

133 [13] D. I. Fels, J. Richards, J. Hardman and D. G. Lee, "Sign Language Web Pages," Am. Ann. Deaf, vol. 151, pp. 423-433, 2006. [14] J. Preece, Y. Rogers, D. Benyon, S. Holland T. Carey, Human-Computer Interaction. Reading, Mass.: Addison-Wesley, 1994, [15] E. J. Downes and S. J. McMillan, "Defining Interactivity: A Qualitative Identification of Key Dimensions," New Media Society, vol. 2, pp. 157-179, June 1. 2000. [ 16] E. Bucy, "Interactivity in Society: Locating an Elusive Concept," Inf. Soc., vol. 20, pp. 373383, 2004. [17] G. W. Furnas, T. K. Landauer, L. M. Gomez and S. T. Dumais, "The vocabulary problem in human-system communication. (human aspects of computing) (technical)," Commun ACM, vol. 30, pp. p964(8), 11/01. 1987. [18] R. J. K. Jacob, "A specification language for direct-manipulation user interfaces," ACM Trans. Graph., vol. 5, pp. 283-317, 1986. [19] B. H. Thomas and P. Calder, "Applying cartoon animation techniques to graphical user interfaces," ACM Trans.Comput.-Hum.Interact., vol. 8, pp. 198-222,2001. [20] N.C. Goodwin, "Functionality and usability," Commun ACM, vol. 30, pp. 229-233, 1987. [21] B. Shneiderman, "The future of interactive systems and the emergence of direct manipulation," in Proc. of the NYU Symposium on User Interfaces on Human Factors and Interactive Computer Systems, 1984, pp. 1-28. [22] F. Guimbretiere and T. Winograd, "FlowMenu: Combining command, text, and data entry," in UIST '00: Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, 2000, pp. 213-216. [23] M. Y. Ivory and M.A. Hearst, "Statistical profiles ofhighly-rated web sites," in CHI '02: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 2002, pp. 367-374. [24] A. F. Wood and M. J. Smith, Online Communication: Linking Technology, Identity, and Culture. Mahwah, NJ: Lawrence Erlbaum, 2005, [25] M. P. Couper, "Web Surveys: A Review of Issues and Approaches," Public Opinion Quarterly, vol. 64, pp. 464-494, December 1. 2000. [26] CityNews, "CityNews.ca- Toronto's news: Polls," Rogers Broadcasting Ltd, Feb. 3 2009 [Online] Available: http://www .citynews.ca/polls.aspx?pollid=4797

134 [27] CTV.ca, "CTV Toronto I CTV news, shows and sports," CTVglobemedia, Feb. 3, 2009 [Online] Available: http://toronto.ctv.ca/ [28] C. S. Bailey and K. Dolby, The Canadian Dictionary ofASL. Edmonton: University of Alberta Press, 2002, [29] "General Guidelines for Inclusive Online Cultural Content". Canadian Network for Inclusive Cultural Exchange, [Online] Available: http://cnice.utoronto.ca/guidelines.php [30] Canadian Cultural Society of the Deaf, "Deaf Culture Centre," Canadian Cultural Society of the Deaf, 2008 [Online] Available: http://www.deafculturecentre.ca [31] S. Geitz, T. Hanson and S. Maher, "Computer generated 3-dimensional models of manual alphabet handshapes for the world wide web," in Assets '96: Proceedings of the Second Annual ACM Conference onAssistive Technologies, 1996, pp. 27-31. [32] S. A. Su and R. K. Furuta, "VRML-based representations of ASL fingerspelling on the world wide web," in Assets '98: Proceedings of the Third International A CM Conference on Assistive Technologies, 1998, pp. 43-45. [33] F. Godenschweger and T. Strothotte, "Modeling and generating sign language as animated line drawings," in Assets '98: Proceedings of the Third International A CM Conference on Assistive Technologies, 1998, pp. 78-84. [34] J. R. Coyle and E. Thorson, "The Effects of Progressive Levels oflnteractivity and Vividness in Web Marketing Sites," Journal ofAdvertising, vol. 30, pp. 65-77, 2001. [35] N. Thompson and D. I. Pels, "Creating Sign Language Webpages," FICCDAT Festival Proceedings 2007, 2007. [36] E. Taylor-Powell, "Questionnaire design: Asking questions with a purpose," Program Development and Evaluation, 1998. [37] P. V. Schaik and J. Ling, "Design parameters of rating scales for web sites," ACM Trans. Comput. -Hum.Interact., vol. 14, pp. 4, 2007. [38] J. Houser, Nursing Research. Mississauga, Ontario: Jones and Bartlett Publishers, Inc., 2008, [39] J. Lumsden, S. Flinn, M. Anderson and W. Morgan, "What difference do guidelines make? an observational study of online-questionnaire design guidelines put to practical use," in Proceedings of the HCI05 Conference on People and Computers XIX, 2005, [40] B. MacElroy, "Comparing seven forms of on-line surveying," Quirk's Marketing Research Review, 1999.

135 [41] D. Andrews, B. Nonnecke and J. Preece, "Electronic Survey Methodology: A Case Study in Reaching Hard-to-Involve Internet Users." Int. J. Hum. -Comput. Interact., vol. 16, pp. p185, 2003-10-01. 2003. [42] W. C. Schmidt, "World-Wide Web Survey Research: Benefits, Potential Problems, and Solutions," Behavior Research Methods, Instruments and Computers, vol. 29, 1997. [43] Pargas Roy P., Witte James C., Jaganathan Kowshik and Davis JohnS., "Database design for dynamic online surveys," in ITCC '03: Proceedings of the International Conference on Information Technology: Computers and Communications, 2003, pp. 665. [44] "Forms in HTML documents," in HTML 4. 01 Specification (W3C Recommendation ed.) D. Raggett, A. Le Hors and I. Jacobs, Eds. Dec. 1999 [Online] Available: http://www.w3.org/TR!html401/interactlforms.html [45] J. Doumont, "Magical numbers: the seven-plus-or-minus-two myth," Professional Communication, IEEE Transactions on, vol. 45, pp. 123-127, 2002. [46] K. L. Norman, Z. Friedman, K. Norman and R. Stevenson, "Navigational issues in the design of online self-administered questionnaires," Behaviour & Information Technology, vol. 20, pp. 37, 2001. [4 7] B. Bauer, H. Hienz and K. -. Kraiss, "Video-based continuous sign language recognition using statistical methods," Pattern Recognition, 2000. Proceedings. 15th International Conference on, vol. 2, pp. 463;..466 vol.2, 2000. [48] H. Brashear, T. Stamer, P. Lukowicz and H. Junker, "Using multiple sensors for mobile sign language recognition," Wearable Computers, 2003. Proceedings. Seventh IEEE International Symposium on, pp. 45-52, 2003. [49] C. G. M. Snoek and M. Worring, "Multimodal Video Indexing&colon; A Review ofthe State-of-the-art," Multimedia Tools and Applications, vol. 25, pp. 5-35, January 2005. 2005. [50] E. B. D. Wang, G. J. Brown and C. Darwin, "Computational Auditory Scene Analysis: Principles, Algorithms and Applications," J. Acoust. Soc. Am., vol. 124, pp. 13, July 2008. 2008. [51] B.-L. Yeo and B. Liu, "Rapid scene analysis on compressed video," Circuits and Systems for Video Technology, IEEE Transactions on, vol. 5, pp. 533-544, 1995. [52] J. Jacoby and M.S. Mattei, "Three-Point Likert Scales Are Good Enough," Journal of Marketing Research (JMR), vol. 8, pp. 495-500, 11. 1971. [53]J. V. Van Cleve, DeafHistory Unveiled: Interpretations from the New Scholarship. Washington D.C: Gallaudet University Press, 1993


