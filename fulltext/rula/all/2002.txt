DYNAMIC BANDWIDTH MANAGEMENT FOR TCP FLOWS IN A DIFFSERV-ENABLED MOBILE WIRELESS ACCESS NETWORK
by

Li Huang B. Eng., Huazhong U niversity o f Science and Technology, China, 1991

A thesis presented to Ryerson U niversity in partial fulfillment o f the requirement for the degree o f M aster o f Applied Science in the Program o f Electrical and Computer Engineering

Toronto, Ontario, Canada, 2005

©Li Huang, 2005

PR O P E R T YO F

...

RYER^ UW W wlTYU B R A R Y

UMI Number: EC53023

All rights reserved
INFORMATION TO USERS

The quality of this reproduction Is dependent upon the quality of the copy submitted. Broken or Indistinct print, colored or poor quality Illustrations and photographs, print bleed-through, substandard margins, and improper alignment can adversely affect reproduction. In the unlikely event that the author did not send a complete manuscript and there are missing pages, these will be noted. Also, If unauthorized copyright material had to be removed, a note will indicate the deletion.

UMI
UMI Microform EC53023 Copyright 2008 by ProQuest LLC All rights reserved. This microform edition Is protected against unauthorized copying under Title 17, United States Code.

ProQuest LLC 789 East Elsenhower Parkway P.O. Box 1346 Ann Arbor, Ml 48106-1346

I hereby declare that I am the sole author o f this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose o f scholarly research.

Signature

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request o f other institutions or individuals for the purpose o f scholarly research.

Signature

u

Borrower's Page
R yerson U niversity requires the signatures o f all persons using or photocopying this thesis. Please sign below, and give address and date.

in

ABSTRACT
Li Huang Master o f Applied Science, 2005 Department o f Electrical and Computer Engineering, Ryerson University

W ith th e soaring dem and to provide global m obility for w ide range o f services, a grow ing trend for w ireless access netw orks is to support m ultiple radio technologies that can be achieved efficiently b y using TC P/IP protocols in the access netw ork. In the thesis, w e consider a m obile w ireless access netw ork w here D iffServ is deployed as the QoS solution and M obile IP is em ployed as the handover protocol. W e first conducted a study on the im pact o f handover on D iffServ flows. T hen w e introduced a transient service level for handover flow s and propose our QoS schem e and adm ission control algorithm s for handover flow s, w hich protect local flows from losing bandw idth to handover flow s b y separating the tw o flow s into different service classes. W e also proposed a service upgrade algorithm to upgrade the service level o f handover flow s b ased on the dynam ic inform ation o f bandw idth utilization and different service upgrade priorities. To guarantee the p ro p er provisioning for each service class, w e proposed a dynam ic bandw idth-provisioning algorithm that allow s dynam ic adjustm ent o f bandw idth allocations to different service classes b y adjusting their respective w eights configured at the scheduler. W e evaluated th e feasibility o f our QoS schem e and algorithm b y sim ulating different handover situations and results show that the proposed schem e is viable under variety o f provisioning scenarios.

IV

Acknowledgements
I w ould like to thank my advisor, Dr. M uhammud Jaseemuddin, for supporting me throughout my time at Ryerson University. His hard working and seriously researching attitude set up role model for all his students including me. I always appreciate his cheerful encouragement during my studies. He always inspired me to pursue active ideas in our research area. He also makes chance for the members o f the W INCORE lab to discuss, exchange ideas and leam from each other so that our knowledge is not only spot on the research area we each focusing on but also broad and include a big picture o f relative areas. I am particularly grateful for his insightful comments on my work and helping me develop many needed soft skills. I would also like to thank the members to my defense committee including Professor Alagan Anpalagan, Professor Bobby Ma for kindly taking time out from their busy schedules to serve. I am so grateful to Ganesha Bhaskara who is now a graduate assistant in the Network Design and Test Lab o f Departm ent o f Electrical Engineering o f University o f South California. He gave me many good suggestions on how to start a simulation on NS2. I am also grateful to all the members o f our W INCORE lab for their friendly encouragement during my hard work on the research. This thesis is dedicated to my parents, my husband and two sons for their love, support, and understanding, without which this thesis would not have been possible.

Table of Contents
Borrower's Page.............................................................................................................................................. iü A bstract............................................................................................................................................................ iv Acknowledgements.......................................................................................................................................... v Table o f Contents............................................................................................................................................ vi List of Tables....................................................................................................................................................ix List of Figures...................................................................................................................................................x List of Abbreviations................... xii

C hapter 1 In tro d u ctio n ..................................................................................................................................1 1.1 Overview.................................................................................................................................................1 1.2 Quality of Service in Mobile Access Network...................................................................................2 1.3 Problems for Providing Service Differentiation in Mobile IP Networks........................................3 1.4 Thesis O utline........................................................................................................................................4 C hapter 2 B ackground.................................................................................................................................. 5 2.1 Mobile IP................................................................................................................................................ 5 2.2 Wireless Access Network..................................................................................................................... 9 2.2.1 Infrustructure.................................................................................................................................. 9 2.2.2 Handover.......................................................................................................................................10 2.3 DiffServ.................................................................................................................................................10 2.3.1 DiffServ Domain and Architecture............................................................................................11 2.3.2 Assured Forwarding.....................................................................................................................13 2.3.3 Buffer Management......................................................................................................................14 2.3.3.1 Overview of RED Algorithm.............................................................................................. 14 2.3.3.2 Multiple RED Mechanism................................................................................................... 15 2.3.4 Queue Management......................................................................................................................17 2.3.5 Policy and Marking Schemes......................................................................................................18 2.4 Quality o f Service Issues.................................................................................................................... 20 2.4.1 Mobility and Q oS .........................................................................................................................20 2.4.2 Traffic Classes and QoS Classes Mapping................................................................................21 2.4.3 QoS Parameters ..........................................................................................................................22 2.4.4 Throughput Assurance Issues..................................................................................................... 24 C hapter 3 Dynamic Bandw idth M anagem ent A lgorithm ...................................................................26 vi

3.1 Im pact o f M obile IP H andover on the Performance o f D iffServ F lo w s

.............................26

3.1.1 O verview ............................................................................................................................................... 26 3.1.2 Problem Simulation and A nalysis................................................................................................... 27 3.2 Dynamic B andw idth M anagem ent A lgorithm ...................................................................................... 33 3.2.1 O verview ............................................................................................................................................... 33 3.2.2 A dm ission Control for H andover F lo w s........................................................................................ 34 3.2.3 D iscussion for Adm ission Control C ase-3.....................................................................................37 3.2.4 Summary o f the Admission Control Algorithm ......................................................................... 42 3.2.5 Service Level U pgrade A lg orith m .................................................................................................. 43 3.3 System O verview ........................................................................................................................................ 46 3.4 P rovisioning..................................................................................................................................................47 3.4.1 W eight A djustm ent A lgorithm ......................................................................................................... 47 C h a p te r 4 S im u latio n S etup a n d R esu lt A n a ly sis...................................................................................... 50 4.1 Simulation S etu p ..........................................................................................................................................50 4.1.1 T o p o lo g y ............................................................................................................................................... 50 4.1.2 Traffic G eneration.................................................................. 51

4.1.3 D iffServ C o n figuration......................................................................................................................52 4.1.3.1 Buffer M an ag em en t................................................................................................................... 52 4.1.3.2 Queue M an ag em en t....................................................................................................................54 4.1.3.3 Core R outers................................................................................................................................. 55 4.1.3.4 Edge R o u ters................................................................................................................................ 55 4.1.4 Statistics and M on ito rin g...................................................................................................................55 4.1.4.1 Flow M o n ito rin g......................................................................................................................... 55 4.1.4.2 T ra c in g ...........................................................................................................................................56 4.1.4.3 A nalysis..........................................................................................................................................56 4.2 Results and A n aly sis...................................................................................................................................56 4.2.1 A dm ission Control Case-1: Scenario 1 ..........................................................................................56 4.2.2 A dm ission Control Case-2: Scenario 2 ......................................................................................... 60 4.2.3 A dm ission Control Case-3: Scenario 3 ......................................................................................... 64 4.2.3.1 Scenario3a.....................................................................................................................................64 4.2.3.2 Scenario3b............................... 66

4.2.3.3 Im pact o f W eight Adjustment on Factor (3.............................................................................68

vii

4.2.4 Service Upgrading: Scenario 4................................

.......69

4.3 Summary............................................................................................................................................ 70 Chapter 5 Conclusion and Future W o rk ................................................................................................ 72 5.1 Concluding Rem arks........................................................................................................................... 72 5.2 Future W ork......................................................................................................................................... 73 References....................................................................................................................................................... 75

vm

List of Tables
2.1 Taxonom y o f RED M ech an ism .................................................................................................................... 16 3.1 Traffic Settings for T e s t l ............................................................................................................................... 37 4.1 Param eters for M RED in the Sim ulation....................................................................................................54 4.2 Traffic...Settings for Scenario 1 .................................................................................................................... 57 4.3 Traffic...Settings for Scenario 2 .................................................................................................................... 61 4.4 Traffic Settings for Scenario 3 a .................................................................................................................... 65 4.5 Traffic Settings for Scenario 4 o f Service U pgrading.............................................................................69

IX

List of Figures
1.1 The DiffServ-enabled Mobile Wireless Access Network..................................................................... 2 2.1 Mobile IP Components.............................................................................................................................. 6 2.2 Mobile IP T unnel....................................................................................................................................... 9 2.3 The Infrastructure of Wireless Network and Handover Process.........................................................10 2.4 Components in a DiffServ Domain........................................................................................................ 11 2.5 Functions of Edge R outers...................................................................................................................... 13 2.6 DiffServ Queues for A F .......................................................................................................................... 15 2.7 Multiple RED Threshold Parameter Settings........................................................................................17 2.8 The Token Bucket Policy........................................................................................................................ 19 2.9 Mapping Between 3G Traffic Classes and DiffServ Classes..............................................................22 3.1 Basic Simulation Scenario with Two CN and Two Mobile N odes....................................................28 3.2 Result of Case 1: Handover and Local Flows Sharing A F l.................................................................29 (a) Interaction of Handover and Local Flows Along the Path to F A l .................................................29 (b) Interaction of Handover and Local Flows Along the Path to F A 2 .................................................30 3.3 Result of Case2: Handover and Local Flows in AF2 and A Fl Respectively....................................31 (a) Interaction of Handover and Local Flows Along the Path to F A l .................................................31 (b) Interaction of Handover and Local Flows Along the Path to F A 2 .................................................32 3.4 Results for T estl....................................................................................................................................... 38 3.5 Effect of Factor p .....................................................................................................................................42

3.6 A dm ission Control Algorithm P seudo-code..............................................................................................43 3.7 Schedule Schem es for Flow U pgrading......................................................................................................44 3.8 Pseudo-code o f Service U pgrade A lgorithm ..............................................................................................45 3.9 Tim er A rrangem ents and H andover T im e ................................................................................................. 46 4.1 N etw ork Topology in O ur S im ulation........................................................................................................ 50 4.2 Queue Structure in Sim ulation...................................................................................................................... 53 4.3 Instantaneous Throughput for Flows in Scenario 1 ............................................................. 58

4.4 Packet Sequence N um bers vs. Time o f flowO in Scenario 1 ................................................................ 59 4.5 Congestion W indow vs. Time o f FlowO in Scenario 1 ............................................................................60 4.6 Instantaneous Throughput for Flows in Scenario 2 ................................................................................. 62 4.7 Packet Sequence N um bers vs. Time o f flowO in Scenario 2 ................................................................ 63 4.8 Congestion W indow vs. Time o f FlowO in Scenario 2 ............................................................................64 ' 4.9 Instantaneous Throughput for flows in Scenario 3a................................................................................. 66 4.10 Instantaneous Throughput for flows in Scenario 3 b .............................................................................. 67 4.11 R esult o f the Service-upgrading Scenario................................................................................................ 70

XI

List of Abbreviations
AF: Assured Forwarding ATM: Asynchronous transfer Mode BA: Behavior Aggregate BE: Best Effort BER: Bit Error Rate BU: Binding Update CBS: Committed Burst Size CBR: Constant Bit Rate CIR: Committed Information Rate CN: Correspondent Node CoA: Care of Address CTR: Committed Target Rate DiffServ: Differentiated Services DSC?: DiffServ Code Points EBS: Excess Burst Size EF: Expedited Forwarding FA: Foreign Agent FIFO: First In First Out GRE: Generic Routing Encapsulation HA: Home Agent ICMP: Internet Control Message Protocol IRDP: ICMP Router Discovery Protocol ISP: Internet Service Provider IntServ: Integrated Services LAN: Local Area Network MAST: Multiple Average Single Threshold MAMT; Multiple Average Multiple Threshold ME: Multi Field MN: Mobile Node MRED: Multiple Random Early Detect PBS: Peak Burst Size PHB: Per Hop Behavior PIR: Peak Information Rate PRI: Priority Queuing PTR: Peak Target Rate QoS: Quality of Service RED: Random Early Detect RER: Radio Edge Router RIO: Random Early Detection with In and Out RIO-C: RIO Coupled Mode RIO-D: RIO Decoupled Mode RR: Round Robin RTT: Round Trip Time SAST: Single Average Single Threshold SAMT: Single Average Multiple Threshold SLA: Service Level Agreement TCA: Traffic Conditioning Agreement TCP: Transmission control Protocol UDP; User Datagram Protocol UMTS: Universal Mobile Telecom. System WIRR: Weighted Interleaved Round Robin WFQ: Weighted Fair Queuing WRED: Weighted Random Early Detect WRR: Weighted Round Robin

XU

Chapter 1 Introduction

1.1 O verview
Increasing dem and for bringing high-speed data and multimedia applications to m obile users pushes Third-generation (3G) W ireless Systems to reality. 3G Systems are intended to provide a global mobility with wide range o f services such as web browsing, e-commerce, interactive games (audio, video and data), etc. To satisfy variety o f user applications, a growing trend for wireless access networks is to support multiple radio technologies by using TCP/IP protocols. M obile IP [1] is the standard mobility m anagem ent protocol in the IP network and it provides the primary framework for mobility in the IP layer. Fast handover enhancements to M obile IP are also proposed and are in the draft stage to reduce latency and packet drops during the handover [2]. Quality o f Service (QoS) is a m ajor concern for mobile wireless users. The wireless access network is evolving towards an All-IP network [3], which we consider in this work. New applications such as audio and video stream ing require high data throughput and low latency. Since traditional IP networks are designed for data applications with a single service class, best effort, where all user packets compete equally for netw ork resources. It is not sufficient to support various requirements o f m ultim edia applications, w hich placed a significant burden on limited network resources, such as bandw idth and buffer space, and caused congestion due to limited resources. Such congestion does not encourage m ass adoption o f IP networks as transport mechanisms for real time and missioncritical applications [3]. Therefore, IP QoS models are developed to offer different levels o f treatment to user packets. D ifferentiated Services [4], or DiffServ, is an IP QoS architecture based on differential treatm ent o f packets that are marked at the network edge for the packets to receive priority according to user requirements. The DiffServ architecture provides QoS by aggregating flows into different traffic classes, marking each packet with a code point that indicates its class, and scheduling packet transm ission according to their code points. Regardless o f how the QoS is set up on the radio link, D iffServ is the most scalable and expected QoS model in the access network. Introducing D iffServ in the m obile wireless access network introduces some unique challenges and issues related to the im pact o f handover on DiffServ QoS assurance.

1.2 Quality of Service in Mobile Access Network
In this thesis, we study a DiffServ enabled mobile wireless network as shown in Figure 1.1.

Intern et

M obile W ireless Access Network (DiffServ-enabled)

coverage area o fR E R l RERl

/

coverage area o fR E R 2 \ .A " RER3

coverage area ofRERS

MN

mobility of MN

Figure 1.1 The DiffServ-enabled Mobile Wireless Access Network The DiffServ-enabled mobile wireless access network is composed of Border Routers, Core routers and Radio Edge Routers (RER). Border Routers provide connectivity with the Internet (Packet Data Network). Core Routers form the wireline network that connects the radio edge with the core routers. The RERs have multiple interfaces: one is a wired interface connected with a core router and the other one is connected to an access point (AP) or base station (BS), which provides radio interface to mobile nodes. Each RER provides connectivity to mobile nodes within its coverage area, thus the

M obile N odes' (M N) m obility is from the coverage area o f a RER to the coverage area o f another RER. In the D iffServ-enabled mobile wireless network, we consider two service levels: Assured Forwarding (AF) and Best Effort (BE). AF is a qualitative service with assured differences, while BE is a service w ithout any QoS guarantee. Therefore, we consider A F a service level higher than BE. W e also consider the priority o f a service to be upgraded from its current service level to a higher service level and called it service upgrade priority. Then the Service Level Agreement (SLA) for a user should include inform ation o f service level, service upgrade priority, etc.

1.3 Problems for Providing Service Differentiation in Mobile IP Networks
In a D iffServ-enabled m obile wireless access network, we consider that all the flows generated and received by mobile nodes are marked with the appropriate DiffServ code points to become DiffServ flows. The im pact o f handover on the performance o f DiffServ flows is a main factor for QoS guarantee. W hen a m obile node moves to a new cell with one or more active DiffServ flows, the flows com pete for bandw idth resources along the new path with those existing active flows. On the other hand, at the time when a mobile node is leaving the old cell it releases the bandwidth resources that were assigned to its DiffServ flows. The handover flows can cause jitter in the performance o f the existing flows, for exam ple it may introduce an uncontrolled packet loss, delay, etc. The situation gets worse when the num ber o f handover flows doesn't follow a predictable distribution. Mechanisms are needed to protect the existing flows from getting performance degradation while at the same time provide some QoS support to the handover flows so that their performance degradation can be controlled. In this thesis we address the issue o f the impact o f handover on DiffServ flows when the bandw idth is not adequate. I f we define the original qualitative service class as A F l, a transient class AF2 is introduced for handover flows, which is a service level low er than A F l but higher than BE. We designed an adm ission control algorithm for handover flows. The algorithm provides schemes for the separation o f handover flows from the existing flows. W hen the bandw idth is not enough to meet all the target rate o f existing and handover A Fl flows, overall performance degradation is compared at the situation w hen the handover flow is marked as A F l with the situation when it is marked as AF2. Our study shows that rem arking the handover flows to the lower service class AF2 results in degradation o f the handover flows but provides protection to the existing flows. We also propose

algorithms o f upgrading the handover flows to achieve the same level o f service as they were receiving before the handover. A scheme for dynamically monitoring the bandwidth utilization and managing the queue for handover AF2 flows is proposed to realize service upgrading. Based on the idea of the above two algorithms, we further propose dynamic bandwidth provisioning schemes by adjusting weights of our scheduler according to the bandwidth utilization o f different service levels. Our algorithms and schemes are presented and verified by different simulation scenarios. Results show that the proposed scheme is viable under variety of provisioning scenarios.

1.4 Thesis Outline
The thesis is organized in five chapters. In Chapter 1, we give an overview o f the problem with some motivations and outline our approach for the proposed solution. The background information about Mobile IP, DiffServ model and mechanisms, and the issues of Quality of service in the mobile wireless access network is given in Chapter 2. In Chapter 3, we first discuss with the help of a simple simulation the impact of handover on DiffServ flows, and then present our proposed scheme and algorithm s for adm ission control o f handover flows to the new cell, dynam ic service level adjustm ent, and adjustm ent o f bandw idth allocation for different service classes. In Chapter 4 w e present the results o f our sim ulations to study the viability o f the proposed schem e in handling different scenarios. Results show our algorithm is efficient and feasible. Finally we conclude the thesis in C hapter 5 w ith directions for future work.

Chapter 2 Background
A w ireless access netw ork is structured as a radio access network connected to PSTN and Internet through a wireline core network. The demand for data applications has pushed the focus o f the thirdgeneration (3G) system s and beyond to optimize the network for data communication. The 3G systems (e.g. U M TS [5] and CDMA2000 [6]) have already introduced IP transport in the core netw ork w ith SIP, M obile IP and other IP protocols. This trend will continue to grow with the advent o f integration o f radio technologies such as WLAN, WPAN and Cellular. In this thesis we consider a D iffServ enabled wireless core network that employs M obile IP handover protocol. We first discuss briefly M obile IP protocol, and then DiffServ QoS model and mechanisms in detail.

2.1 Mobile IP
In an IP network, the location o f a node is identified by its IP address. According to the IP address that is assigned on the network, called home network, the node is reachable through normal IP routing. However, when the node roams away from its home network, it is no longer reachable using norm al IP routing and its active sessions are terminated. M obile IP [7] was designed to enable users to keep the same IP address while moving to a different network (which may even be in a different wireless operator domain), thus ensuring that a roaming individual could continue communication without sessions or connections disruption. Since M obile IP is based on IP, any media that can support IP can support M obile IP. There are three com ponents in M obile IP: M obile Node (M N), Home A gent (HA) and Foreign Agent (FA), as shown in figure 2.1.

In te rn e t

MN V i s i t i n g F o r e i g n N e tw o rk

MN a t Hcflitt

Network
FA MN V i s i t i n g F o r e i g n N e tw o rk

Figure 2.1 Mobile IP Components

A Mobile Node (MN) is an Internet-connected device whose location and point of attachment to the Internet may frequently be changed. This kind of node is often a cellular telephone or handheld or laptop computer, or even a router. A node or device on the Internet that communicates with the mobile node is called a Correspondent Node (CN). Mobile IP defines two IP addresses for mobile nodes that are visiting foreign network domains (networks). The home address identifies the mobile node's location in the home domain, which is known to all correspondent nodes in the Internet. A care-of-address (CoA) is used to identify the mobile node's current location (i.e. subnet) in the foreign network. It is the termination point of the tunnels toward the Mobile Node when it is in a foreign network. The Home Agent (HA) is a device (typically a router) in the home network serving as the anchor point for communication with the mobile node. It maintains an association between the home address of the mobile node and its care-of-address, which is the current location of the mobile node on the foreign or visited network. It intercepts the packets from a CN destined to the M N's home address on the home subnet, and tunnels them to CoA. The Foreign Agent (FA) is a router that provides CoA to the mobile node when the MN roams into its network, and then it detunnels the packets from the home agent and delivers them to the mobile node. In Mobile IP v4 [7], there are three main phases: 1. Agent discovery. During this phase, a mobile node discovers its home agent and foreign agent. Usually this can be done in two ways. One is that the Home Agent and Foreign Agent advertise their services on the network by using the ICMP Router Discovery Protocol (IRDP). The Mobile Node listens to these advertisements to determine if it is connected to its home network or foreign network. The IRDP

advertisements carry M obile IP extensions that specify whether an agent is a Home Agent, Foreign Agent, or both, its care-of address, the types o f services it will provide such as reverse tunneling and generic routing encapsulation (GRE), and the allowed registration lifetime or roaming period for visiting M obile Nodes. A nother way is that a M obile Node can send out an agent solicitation, rather than waiting for agent advertisements. This solicitation forces any agents on the link to send an agent advertisem ent immediately. If a M obile Node determines that it is connected to a foreign network, it acquires a care-of address. There are two types o f care-of addresses: Care-of address acquired from a Foreign Agent, and colocated care-of address. A Foreign Agent care-of address is an IP address o f a Foreign Agent that has an interface on the foreign network being visited by a M obile Node. A M obile Node that acquires this type o f care-of address can share the address with other M obile Nodes. A colocated care-of address is an IP address temporarily assigned to the interface o f the M obile Node itself. A colocated care-of address represents the current position o f the M obile Node on the foreign network and can be used by only one M obile Node at a time. W hen the M obile N ode receives a Foreign Agent advertisement and detects that it has moved outside o f its hom e network, it begins the M obile IP registration process. 2 .Registration In the registration phase, the M obile Node registers its CoA with the Foreign A gent and Home Agent. Usually, a M obile N ode is configured with an IP address and mobility security association (which includes the shared key) o f its Home Agent. It is also configured with either its home IP address, or another user identifier, such as a Netw ork Access Identifier. A ccording to this information and the information it learns from the Foreign Agent advertisements, the M obile N ode generates a M obile IP registration request. It adds the registration request to its pending list and sends the registration request to its Home A gent either through the Foreign Agent or directly depending on which care-of address it is using. Since in our research we use the care-of address acquired from a Foreign Agent, we consider the registration process in which the M obile Node sends the registration request to its Home A gent through the Foreign Agent. The Foreign Agent checks the validity o f the registration request, which includes checking whether the requested lifetime exceeds its limitations, and the requested tunnel encapsulation is available and the reverse tunnel is supported. If the registration request is valid, the Foreign Agent adds the visiting M obile Node to its pending list before relaying

the request to the Home Agent. If the registration request is not valid, the Foreign Agent sends a registration reply with appropriate error code to the Mobile Node. The Home Agent checks the validity o f the registration request, which includes authentication o f the Mobile Node. If the registration request is valid, the Home Agent creates a mobility binding (an association o f the Mobile Node with its care-of address), a tunnel to the care-of address, and a routing entry for forwarding packets to the home address through the tunnel. The Mobile Node renews its registration before the registration lifetime expires. If the registration is denied, the Mobile Node makes the necessary adjustments and attempts to register again. During the renewal of registration, the Home Agent and Foreign Agent update their mobility binding and visitor entry respectively. Thus, a successful Mobile IP registration sets up the routing mechanism for transporting packets to and from the Mobile Node as it roams. 3. Tunneling The Mobile Node's movement is transparent to correspondent nodes. When the Mobile Node sends packets, it uses its home IP address; so that it seems that the Mobile Node is always on its home network. Packets addressed to the Mobile Node are routed to its home agent first. Then the Home Agent intercepts and tunnels them to the care-of address toward the Mobile Node. The tunneling overhead includes the time spent in encapsulation and decapsulation o f the packets and the transmission o f the tunnel header. IPinIP Encapsulation is the default tunnel mode, while GRE and minimal encapsulation within IP are optional.

CN

HA Internet

Tunnel

MN C are o f A d d ress

Figure 2.2 Mobile IP Tunnel

M obile IP packet forwarding is shown in figure 2.2. The M N can send packet directly to the Correspondent N ode (CN), but it receives packets via HA from the CN. This creates a triangle routing M N-CN-HA, w hich can be prevented by the proposed route optimization wherein the M N updates the CN with its CoA and thus packets traverse through the optimal route between MN-CN. In M obile IP v6 [8] the M N can directly send the registration message, called Binding Update (BU), to the HA, hence there is no provision for FA in the network.

2.2 W ireless Access Network 2.2.1 Infrastructure
In a wireless access network, edge routers connected to one or more base stations are called Radio Edge Router (RER). They provide connectivity to mobile nodes. For each RER, there is a certain geographic coverage area within which mobile nodes can communicate to it. We call this coverage area as a cell. U sually neighboring RERs overlap with each other's coverage area so that consistency o f com munications is ensured when mobile nodes move from one cell to another. The infrastructure o f wireless access netw ork and the handover process is illustrated in Fig2.3.

N etw ork

coverage area o f old RER \ new RE]

coverage area o f y / new R ER

MN

handover process

Figure 2.3 The Infrastructure of Wireless Network and Handover Process

2.2.2 Handover
Handover is the transition for a given mobile node from the coverage area o f one RER to the coverage area of a geographically adjacent RER as the mobile node moves around. In this procedure, data transfer session is maintained while mobile nodes moving from one cell to another. Each time a mobile node moves from one cell into another, the network automatically switches coverage responsibility from one RER to another. In a smooth handover process, the communication disruption should be minimal.

2.3 DiffServ
The Integrated Services (IntServ) and Differentiated Services (DiffServ) are two main Quality of Service architectures for the IP network. Since IntServ needs to explicitly signal and dynamically allocate resources at each intermediate node along the path for each flow, it is less scalable and abandoned in ISP networks in favor o f more scalable DiffServ.

10

D iffServ is a class-based QoS system that provides qualitative assurance to aggregate flows [4]. N o per flow state needs to be m aintained in the core routers, neither is there an explicit connection setup phase. It recognizes the boundaries o f Internet Service Providers, and assumes that ISPs define the service classes for their own networks. It defines standard behavior (treatment) o f flows, called Per Hop B ehavior (PHB), w hich is used by the ISPs to construct their own services.

2.3.1 DiffServ Domain and Architecture
A D iffServ dom ain is a set o f DiffServ nodes, which operates with a common service provisioning policy and set o f PHB groups executed on each node. Devices in a DiffServ domain are illustrated in Figure 2.4.



E d g e R o u te

C o re R o u te r

Figure 2.4 Components in a DiffServ Dom ain

D iffServ distinguishes between the edge and the core o f a network. In a DiffServ domain, per flow traffic conditioning is lim ited to the boundaries o f the netw ork (edge routers), whereas the core o f the netw ork provides treatm ent to only aggregate flows. As traffic enters the netw ork it is classified and conditioned at the edge router and assigned to a behavior aggregate. DiffServ defines standard

11

forwarding treatments o f packets inside the network, which are called Per Hop Behavior (PHB). A PHB is a description of the externally observable forwarding behavior of a DiffServ node applied to a particular DiffServ behavior aggregate. It defines a forwarding treatment o f a single packet in a router. These PHBs do not offer any quantitative guarantees e.g. fixed bandwidth, and bounds on packet delay or jitter. They provide qualitative assurance and means to implement service classes. All the edge and core routers perform Per Hop Behavior (PHB) along the path. Packets are identified for a particular treatment (PHB) through DiffServ Code Points (DSCP), which are standard bit combinations of the DSCP in the IP header. Packets marked with the same DSCP are treated the same way. Flows are aggregated based on desired behavior, and marked with the same DSCP at the edge, which in turn get the given differentiated treatment within the network. The DiffServ architecture has three major components. One is the policy and resource manager, which handles the creation of network policies and distribution of those policies to the DiffServ routers. The other components are edge routers and core routers. DiffServ attempts to restrict complexity to only the edge routers of a domain. A policy and resource manager is a necessary component of a DiffServ network that allows an administrator to communicate policies to the edge and core devices. A policy specifies which traffic receives a particular level of service in the network. Edge routers are used between the hosts and the core network. They classify and possibly condition the incoming traffic using Traffic Conditioning Agreement (TCA). Edge routers are responsible for examining incoming packets and classifying them according to policy specified by the network administrator. Figure 2.5 shows the building blocks of an edge router. Its main functions are the following; 1. It classifies packets for appropriate DSCP marking. It performs detailed packet classification, called MF (Multi Field) classification, based on the following IP-header fields: source address, destination address, traffic type or any combination of these. 2. It marks packets with the appropriate DSCP based on the SLA and the policies. 3. It ensures that user traffic adheres to its policy specifications, by shaping and policing traffic. Shaping includes measuring transmission rates of the given traffic aggregation and conforming it to pre-defined values.

12

Meter Incoming P actets Micro Flow Classifier

Outgoing Packets Policcr
Marker

Buffer
M anagem ent

Figure 2.5 Functions o f Edge Routers

Core routers are routers that are only connected to other routers inside the network. They only perform PHB on incom ing packets. Their main responsibilities are; 1. Classifying incoming packets based on the DSCP marking done on the packet by the edge routers, called BA (Behavior Aggregate) classification. 2. Perform ing PHB while forwarding incoming packets according to the DSCP markings. (Core routers' behaviors follow the marking done by edge routers).

2.3.2 Assured Forwarding
A ssured Forwarding (AF) and Expedited Forwarding (EF) are the two D iffServ PHBs that provide different quality assurances. A F [10] PHB is suggested for applications that require a better reliability than the best-effort service. It offers the same delay characteristics as o f the best effort class, however the firmness o f its guarantee on differential treatment depends on how well the individual links are provisioned for bursts o f assured packets. Since AF can provide flexible QoS with relative qualitative assurance, we use this PHB in our research, and discuss it in detail. AF provides differential treatm ent o f traffic by discarding more low priority packets during times o f congestion than high priority packets. AF defines four classes o f service. In each DiffServ node, a certain am ount o f forw arding resources such as buffer space and bandw idth is allocated for each AF class. All packets from a certain class are put into an assured queue and the queue is managed by a queue m anagem ent scheme called Random Early Detection with In and Out (RIO). Within each AF class, there are three drop precedences. The different drop precedence levels are also referred in

terms o f their colors. For example, Green - for the lowest drop precedence level. Yellow - for the medium, and Red - for the highest drop precedence level. During congestion period, the drop precedence o f a packet determines the relative importance o f the packet within each class and packets with lower priority is more likely to be dropped than other packets. In other words. The Assured Forwarding m echanism is a group o f code points that can be used in a DiffServ netw ork to define 13

four classes o f traffic, each of which has three drop precedences. The drop precedence enables differential treatment o f traffic within a single class.

2.3.3 Buffer Management
Packets belonging to different DiffServ classes are enqueued in different queues. Within each queue, buffer management is one o f our main concerns. The basic algorithm for buffer management in routers is Drop Tail. Drop tail queues with FIFO simply accept any packet that arrives when there is sufficient buffer space and drop any packet that arrives when the buffer space is insufficient. This algorithm is simple and easy to implement, but usually causes problems with multiple constant packet flows and global synchronization o f TCP connections.

2.3.3.1 Overview of RED Algorithm
Random Early Detection (RED) [11] is a congestion avoidance algorithm that can be implemented in routers. RED gateways are designed to detect incipient congestion by computing a weighted average queue size because a sustained long queue is a sign of network congestion. When a packet arrives, a RED gateway checks the weighted average queue size and compares it with the specified minimum and maximum thresholds. If there is congestion, it notifies, either by dropping a packet or by setting a bit in a header field of the packet, probabilistically. A RED is in one o f the following three phases in determining about the packet drop: 1. Normal Operation If the average queue size is less than the minimum threshold, no packets are dropped. 2. Congestion Avoidance If the average queue size is between the minimum and maximum thresholds, packets are dropped with a certain probability. The probability is a function of the average queue size. It is increasing linearly as the buffer begins filling up, so that larger queues lead to higher drop probabilities. 3. Congestion Control If the average queue size is greater than the maximum threshold, all incoming packets are dropped.

14

2.3.3 2 Multiple RED Mechanism
As we have discussed before, Assured Forwarding is a group o f code points that can be used to define four classes o f traffic, and each class has three drop precedence that enable differential treatment o f traffic within a single class. Assured Forwarding uses the RED mechanism by enqueuing all packets for a single class o f traffic into a certain physical queue in which there are three virtual queues (one for each drop precedence), shown in Fig 2.6. We call the RED mechanism used by Assured Forwarding as M ultiple RED mechanism (MRED) [12], In MRED, D ifferent virtual queues have different RED param eters thus packets from some virtual queues are dropped more frequently than packets from other virtual queues. A packet assigned a code point that corresponds to a virtual queue with low er drop precedence, in other words, with relatively lenient RED parameters, is given better treatm ent w hen congestion happens.

P h y sical Q ueue 1

P h y sical Q ueue 2 three v irtu al queues in each p h y sical queue P h y sical Q ueue 3

P h y sical Q ueue 4

Figure 2.6 DiffServ Queues for AF In M RED, drop probability for packets with different drop precedence (packet color) have to be calculated independently for each drop precedence, thus multiple sets o f RED thresholds need to be m aintained - one for each drop precedence. There are different schem es applied for calculating the average queue used for the drop decision, which are classified into four categories [12], as showed in Table 2.1:

15

RED Variants

Single Average Single Threshold (SAST) RED No

Single Average Multiple Thresholds (SAMT) WRED Yes

Multiple Average Single Threshold (MAST) No

Multiple Average Multiple Threshold (MAMT) RIO-C, RIO-D Yes

Examples Availability for MRED

Table 2.1 Taxonomy of RED Mechanism

 Single Average Single Threshold (SAST): This RED mechanism does not distinguish between packets of different colors and maintains a single average queue length and the same min th and max th thresholds for the packets of all colors. In fact, SAST is simply plain RED.  Single Average Multiple Thresholds (SAMT): The average queue length is based on total number of packets in the queue regardless of their color, but packets of different color have different drop thresholds.  Multiple Average Single Threshold (MAST): Average queue length for packets of different colors is calculated differently. For example, average queue length for a color can be calculated using number of packets in the queue with same or better color. However, packets of all color have the same min th and max th thresholds.  Multiple Average Multiple Threshold (MAMT): Average queue length for packets of different colors is calculated differently, and packets of different color have different min th and max th thresholds. Among above RED variants, SAMT and MAMT are used to implement MRED. An example of SAMT is Weighted RED, while RIO-C and RIO-D are examples for MAMT. Several popular MRED modes are list below:  RIO Coupled mode (RIO-C) [13]: For one physical queue, the probability of dropping an out-of profile packet is based on the weighted average lengths of all its virtual queues; while the probability of dropping an in-profile packet is based solely on the weighted average length of its virtual queue. Moreover, multiple RED threshold parameters are maintained - one for each color.

16

 RIO D e-coupled m ode (RIO-D) [13]; The probability o f dropping an out-of-profile packet is based on the size o f its virtual queue only, while the probability o f dropping an in-profile packet is the same as RIO-C. M oreover, m ultiple RED threshold parameters are m aintained --one for each color.  W eighted RED m ode (W RED) [14]: A single average queue length that includes packets o f all colors is calculated. For any arrival or departure o f green, yellow or red packets, W RED updates the single average queue length based on the total number o f packets o f green, yellow and red color if they are all applicable. However, multiple RED threshold parameters are maintained - one for each color.  DROP mode: As soon as the queue size reaches the minimum threshold, all packets are dropped regardless o f marking. G enerally, for all RED variants, the threshold parameters for packets o f different colors could be set in three ways: overlapped, partially overlapped and staggered, as showed in figure 2.7. According to the above taxonom y o f RED variants, (a) is only suitable for SAST and M AST because in these mechanisms packets o f all color have the same minT and m axT thresholds, (b) and (c) are suitable for SAM T and M AM T, thus they are used to implement MRED. In fact, (b) is more popular than (c).

D ro p P ro b ab ility

D rop P robability

D ro p P ro b ab ility

A

!
maxPi m axPj maxPr m axPr

m axP^ .« « « .'

Y e llo //i Gre* A verage Q ueue Size

maxPj
maxPf

/iT*"
een / 1
/

m a x P ) ... maxPj A verage : Q ueue Size
w

Q ueue Size m in T r^ ^ m axT ^

'

mmT

maxT

in T r/ t ^ ^ \m a x T g m a i T r V 'axTy m in T y m in lg

/

m a x T r maxTy m in T y m in T g (c) Staggered

(a )O v e rla p p e d

(b) P a rtia lly O v erlap p ed

Figure 2.7 M ultiple RED Threshold Param eter Settings.

2.3.4 Queue Management
The scheduler is a key com ponent in a router that distributes the link capacity to multiple queues. The scheduling m ode can be W eighted Round Robin (WRR) [15], W eighted Interleaved Round Robin (W IRR) [16], Round Robin (RR) [17], Priority Queuing (PRI) [18], and other scheduling modes. Two popular schedulers related to our research are discussed below in details. 17

1. WRR scheduler Weighted Round Robin scheduler is a variant of the Weighted Fair Queuing (WFQ) algorithm [19]. It shares link access circularly, one buffer at a time. Each buffer has a weight that refers to the relative share o f link access time compared to other buffers. Any buffer with 0 weight will be skipped and its link access time will be shared by other buffers according to their weights. By properly configuring the WRR scheduler, we can arrange different link access time for different buffers so that service differentiated from class to class and different portions of bandwidth are assigned to different classes. In contrast with PRI scheduler, high priority traffic doesn't exhaust lower priority traffic in WRR. 2.PRI scheduler Priority queuing scheduler sets different priorities to different buffers. The non-empty buffer with highest priority always gets link access. This scheduler can guarantee small packet delay and jitter, but on the other hand high priority traffic can easily exhaust lower priority traffic. To avoid the starvation, the buffer bandwidth limits are configured properly.

2.3.5 Policy and Marking Schemes
Before traffic enter a DiffServ domain, users have to agree with a certain traffic profile so that there won't be any unforeseen congestion. The profile usually includes a Committed Information Rate (CIR) and allowed Peak Information Rate (PIR). When traffic comes into a DiffServ domain, it is metered, shaped and marked with certain code point. The purpose of metering and policing is to smooth the bursts over time, thus to ensure that there is no violation even though some flows may be misbehaving and violating agreed profile. The purpose of marking is to indicate whether current packet violates the profile or not. For example, in a three color marking scheme, the green indicates that the packet has arrived below CIR, the yellow shows that the packet has exceed committed profile but still falls within the peak rate, and the red shows that the packet has arrived at or above PIR.. Colors are coded by the drop precedence of AF class [10]. Some commonly used policers for AF are discussed below:  Token Bucket: The Token Bucket algorithm is illustrated in fig 2.8. In this algorithm, a token bucket of depth Committed Burst Size (CBS) is filled at the rate of the Committed Information Rate (CIR). CBS and CIR are important parameters in the traffic profile committed by users. When a

18

packet comes, its length is com pared with the occupancy o f the token bucket b. It is marked in if there are enough bytes o f token in the bucket. Otherwise, it is m arked out. I f a packet is marked in, a num ber o f bytes (referred to as tokens) equal to the packet length is subtracted or taken from the bucket. In refers to a lower drop precedence (or green in color), while out refers to a higher one (or red in color) [20].

T o k e n F illing R ate: C IR (bytes^s)

T o k e n B ucket Size: CBS (b y tes)

T o k en Bucket O ccupancy; b (b y tes)

P a c k e tL e n g th : L (bytes)

a
yes

I h=b-L
/ V M a rk e d w ith fM n n --------------- M ark ed w ith

<

>

out
no

7777^

Figure 2.8 The Token Bucket Policy  Single Rate Three Color: According to this policy, incoming packet stream is metered and marked based on a Com m itted Information Rate (CIR) and two associated burst size, a Committed Burst size (CBS) and an Excess Burst Size (EBS). Token bucket C (with maxim um size CBS) and token bucket E (with m axim um size EBS) is filled at the same rate o f CIR and EBS is assumed to be bigger than CBS. A packet is m arked green if there are enough token in token bucket C, yellow if the packet's length exceeds CBS, but not EBS; otherwise it is marked red [21].  Two Rate Three Color: Similar with Single Rate Three Color, this policy has two token bucket. Token bucket C 's m aximum size is CBS and it is filled at the rate o f CIR. Token bucket P 's m axim um size is Peak Burst Size (PBS) and it is filled at the rate o f Peak Information Rate (C IR ).. A packet is m arked green if tokens are enough in token bucket C, yellow if the packet's length exceeds CBS, but not PBS; otherwise it is marked red [22].  Time Sliding window: In this policy, metering and marking is done based on the Committed Target Rate (CTR) and the Peak Target Rate (PTR). A rate estimator provides an estimate o f the traffic stream 's arrival rate, w hich approxim ates the running average bandw idth o f the traffic over a specific 19

period o f time (length o f the sliding window). If the estimated average rate is no more than the CTR, the packets o f the stream are marked as green. If the estimated average rate exceeds CTR but is no more than PTR, packets o f the stream are marked yellow with probability PO and green with probability (1-PO). If the estimated rate exceeds PTR, packets are marked red with probability PI, marked yellow with probability P2 and marked green with probability (1-(P1+P2)) [23].

2.4 Quality of Service Issues
In the 3G wireless systems, all service is carried directly on IP so its QoS model is quite different from traditional models.

2.4.1 Mobility and QoS
Usually, QoS parameters include bandwidth, packet delay, packet loss rate, and jitter. Some o f these parameters are quite different between mobile and fixed worlds. In the mobile environment, bandwidth is usually lower than in the fixed environment, while delay is usually longer. There are some unique challenges to provide and maintain QoS in a mobile environment. Besides the challenges of maintaining wired part network level QoS, handover between access routers, frequent changes of IP address, and competition for resources among mobile users all increase the complexity of QoS provisioning in the mobile environment. In a mobile network environment, a mobile node may change its point of attachment to the network many times during a session. There is also disruption during the handover period. These may lead to changes of routing within the access network and possibly other changes in the end-to-end session. To maintain the active sessions on the mobile nodes, the network should negotiate QoS along the new path during the handover process. After the negotiation with the network, the QoS contract should be maintained if it is possible, or downgraded to a lower service level that is still acceptable by users. As we have mentioned in previous sections that Mobile IP mechanism use tunnels during handover to forward packets between the old and new access routers for the mobile node. The mechanism can help eliminate packet loss, but the packets should be treat very carefully. They must be allocated an appropriate QoS to ensure that they reach the mobile node within the confines of the QoS contract.

20

Considering the issue o f disruption during the handover process, there is a period o f time during which the end-to-end connection data path is incomplete. How m uch this disruption can affect the application perform ance depends in the nature o f the application and the period o f the disruption. For example, a voice application can only tolerate very short disruptions.

2.4.2 Traffic Classes and QoS Classes Mapping
In 3G wireless systems, traffic types are divided into four different service classes based on their individual requirem ent o f bit rate, bit error rate, delay, and etc [24]. The four defined classes are:  Conversational class; The conversational class services are mainly for conversational real-time applications such as voice, videoconference, video gaming and so on. The critical performance requirem ent for this class is consistency in time relations, including low delay and low delay jitter requirements. The m ain idea o f these requirements is to preserve source data rate according to human perception for this kind o f applications. The conversational class services also resemble Constant Bit Rate (CBR) services in Asynchronous Transfer Mode (ATM) and can be supported by fixed resource allocation in the netw ork [25].  Streaming class: The streaming class services include streaming media applications such as streaming audio, stream ing video (video on demand), webcast, etc. They also require low delay and low delay jitter but the requirements is not as strict as those for the conversational class services. Streaming class services can be considered as real-time variable bit rate services or variants o f the constant bit rate services.  Interactive class: Examples o f the interactive class services are web browsing, network gaming, ecommerce, rem ote Local Area Netw ork (LAN) access, etc. They all require high throughput, and low loss rate. Traffic flow prioritization is also considered important within this service class.  Background class; The background class services are for traditional best-effort services such as non real-tim e dow nload o f emails, file transfers and so on. They don't have special requirement for delay, delay jitter or throughput, even though low loss rate is still critical for minimizing retransmissions. Background services have the lowest priorities among services o f all other classes. Considering D iffServ as our QoS model for the core network, we can do some mapping between the traffic classes and the QoS classes, as illustrated in Fig 2.9. In DiffServ, there are three service classes: Expedited Forwarding (EF), Assured Forwarding (AF) and Best Effort (BE). Since EF class

21

can give guarantees on parameters such as delay and throughput, we consider mapping the conversational class to EF. The streaming class services have similar but looser requirements compared to the conversational class services, so that stream class can be mapped to either EF or AF. To ensure that the interactive class services receive assured throughput, it is better to map the interactive class to AF. It is also okay for some researchers to map it to BE [26], if the requirement is not so strict. The background class is usually mapped as BE because it has the lowest priority among all the classes.

Q oS classes in

Traffic C lasses in 3G N etw o rk s C o n v ersatio n al

ff
AF

-----------------* __ _____________ » ------------------- Streaming

In terractive

OE
B ackground

Figure 2.9 Mapping Between 3G Traffic Classes and DiffServ Classes

2.4.3 QoS Parameters
Based on the analysis of traffic classes in former sections, we consider the expected service performance parameters for 3G wireless networks as throughput, delay, delay variation, drop probability, and bit error rate.  Throughput: Throughput is also known as bit rate. The bit rate between two communicating

end-systems is the number o f binary digits that network is capable of accepting and delivering per unit time. Practical bit rate is limited to the capability of the network and the destination in accepting and processing information. Considering our core network as a DiffServ-enabled IP network, then traffic aggregation is an important factor affecting the throughput parameter. We can divide traffic aggregate in an IP network into congestion sensitive TCP flows and congestion insensitive UDP flows because TCP reduce their traffic rate if packets are lost while UDP show no response to losses. Seddigh et al [27] have conducted a detailed experimental study of five different factors that impact throughput assurances for TCP and UDP flows in an AF based DiffServ-capable IP network. The

22

study dem onstrated that the factors could cause different throughput rates for end-users even though they have contracted identical service agreements. We will discuss these factors in detail in following sections.  Delay; D elay can be defined as the time period between the emission o f the first bit o f a data block by the transm itting end system and its reception by the receiving end-system. In the 3G wireless networks, both conversational class and streaming class have strict requirements for transfer delay. To provide guarantees on end-to-end delay in a DiffServ-capable EP network, we consider controlling specification in relative packet forwarding urgency among the classes by appropriate scheduling m echanism among the queues within a particular router.  Delay variation: The variation in delay is defined as delay variation or jitter. W hen a stream o f packets traverses a network, each packet may experience different delay due to buffering in routers. For real-tim e applications, delay variation is an essential performance parameter. An applicable way to overcom e delay variation is to make the receiving system waiting a sufficient time (called delay o f set) before the play out, so that most delayed packets have a chance to act like arrive in time.  Drop probability: In a DiffServ-capable network, drop probability is a critical parameter for

different treatm ent to packets. It is no doubt that certain drop assurance is possible in a single domain. Since the DiffServ framework is intended to operate on bilateral agreements between two neighboring domains, the owner o f a domain can also obtain a service level agreement with its neighbors on drop probability. However, it is still not clear how to ensure the end-to-end drop probabilities specified in the contract for aggregate flows going across multiple domains in the Internet [28].  Bit Error R ate: Bit Error Rate (HER) is defined as the percentage o f bits that have errors to the

total number o f bits received and it is expressed as ten to a negative power. For example, if HER is 10'® in a transm ission process, we know that out o f 1,000,000 transferred bits one bit is not correct. The BER is an indication o f how often a data segment (in packets or other units) has to be retransm itted due to an error. Considering A F PHB as our differentiated drop mechanism to provide IP QoS in the core network, different user traffic classes obtain different treatments based on their requirements, but the AF PHB does not focus on delay. Nevertheless, QoS parameters have inherent relations. For example, if the throughput is sufficient for a certain traffic flow, there will be low loss rate thus we have low

23

retransmission rate and low delay. Therefore, it is probable that end-users use throughput assurance as a measure o f good or bad network performance [21].

2.4.4 Throughput Assurance Issues
Some studies have shown a different list of factors that impact throughput issues for TCP and UDP flows in an AF based DiffServ-capable IP network [27] [29]. These factors can cause different throughput for equal paying end-users who have committed identical service level agreements (SLA), which includes values for target rates (CIR) set for the TCP connections. The main factors of our concern are:  Round Trip Time (RTT): RTT is defined as the time between the transmission of a packet and the receipt of its acknowledgment or reply. TCP uses a self-clocked sliding window based mechanism and adjusts its rate based on RTT. Thus bandwidth assurance can be regarded as a function of RTT. Aggregate TCP flows with different RTTs get different shares of bandwidth in spite of identical target rates. In an over-provisioned network, flow aggregafes will achieve fheir target rate irrespective of their RTTs, but there is an unfair sharing of the excess bandwidth since flows with lower RTT will get more portion of the excess bandwidth than those with higher RTT. In a under-provisioned network, neither of the aggregated flows will achieve their target rate but flows with lower RTT is close to their target rate compared with those with higher RTT. The phenomenon can be explained by the following equation by Mathis et al [30]:

1
RTT

The equation reveals the relationship between TCP bandwidth, BW, and the factors of Round Trip Time (RTT), packet size (MSS) and packet loss rate (p). Flows with different values of any of the three factors will have different distribution o f excess bandwidth in the over-provisioned network and different degrees of degradation in the under-provisioned network. The impact of packet size and packet loss rate on bandwidth is discussed in detail in following passages.  Packet Size: In an over-provisioned network, flows with the same RTT will achieve their target rate in spite of their different packet size. But the there will be an unfair sharing of the excess bandwidth in favor of the target aggregates with larger packet size. Similarly, in an under-provisioned network, no aggregated flow will achieve its target rate but those with larger packet size will be closer to their target rates.

24



Size o f Target Rate; Based on the common sense, in an over-provisioned network, flows with

larger packet size should get more excess bandwidth. But it is not the case according to the detailed study o f [27]. Their results show that the excess bandwidth is distributed almost equally among flows with different values o f target rate. In a under-provisioned network, still no target is achieved, but there is fair degradation o f bandwidth for flows with different target rate.  N u m b e r o f A ctive Flows: The number o f active flows in the core o f the network is an important

factor that impacts the TCP throughput for both individual flows and flow aggregates [31]. As the num ber o f active flows in the core network increases, the queue length is more prone to cross the m aximum threshold thus causes packet drop and retransmission and will further cause unfair sharing o f TCP bandwidth. So the effectiveness o f RED parameters is partially dependant on the number o f active flows in the core network. For a given set o f RED parameters, the end-to end TCP flow behavior will change as the number o f active flows changes with time.  Im p a c t o f N on-responsible flows: If we let the responsive TCP flows and Non-responsible UDP

flows share the same service class with the same drop precedence, non-responsible flow will starve the responsive flows in the under-provisioning case; while both will achieve their target rate in the over-provisioning case. Alternatively, if we let the responsive TCP flows and Non-responsible UDP flows share the same service class with different drop precedence, TCP flows can be protected from the im pact o f the non-responsible UDP flows.  N u m b er o f M icro-flow s in an A ggregate: Study shows that in the over-provisioned scenario,

aggregates with larger number o f micro-flows will get more share o f the excess bandwidth. In the under-provisioned scenario, situation is similar, but the difference is not so obvious.  D ifferen t TCP Stacks: Currently existing TCP stacks such as Reno, new Reno, SACK, etc have

different m echanism s o f handling packet drops, which causes different levels o f aggressiveness to m aintain throughput in case o f packets drop. For example, even though a Reno user and a SACK user have the same drop probability, they still get different throughputs due to the different congestion avoidance m echanism s they use when packet drop happens.

25

Chapter 3

Dynamic Bandwidth Management Aigorithm

3.1 Impact of Mobile IP Handover on the Performance of DiffServ Flows 3.1.1 Overview
Our research is focused on QoS provisioning in a DiffServ-enabled mobile wireless access network. It is well known that DiffServ can provide efficient and scalable service differentiation for the wired Internet infrastructure. However when it is used in the mobile wireless access network, situation becomes dynamic and several challenging issues arise. For example, in a DiffServ network, packets are marked and assigned a DiffServ Code Point (DSCP) at ingress edge routers and get special treatment along the path pointing accordance with the PHB identified by the DSCP. However in a mobile IP network, traffics destined to a mobile node's home address are redirected to the Foreign Agent form the Home Agent through the Mobile IP tunnel. Then the question arises where shall the packets be marked and is there any need for remarking the redirected traffic? Moreover, when a mobile node moves to the coverage area of a new cell competes for resources with the existing users, then bow does the network allocate the resources to achieve the performance objective? In this thesis we study the above issues related to QoS provisioning and management for a DiffServ-enabled Mobile IP network. We consider that all the flows generated and received by mobile nodes are marked with the appropriate DSCPs, which are called DiffServ flows. We first present the impact of Mobile IP handover on the performance of DiffServ flows. Then, we present the proposed admission control algorithms. For the simulation study we present in this thesis we only consider TCP flows because TCP flows constitute majority of the Internet traffic today. To investigate the impact of Mobile IP handover on the performance of DiffServ flows, we simulated a number of TCP connections experiencing variety of handover situations.

26

3.1.2 Problem Simulation and Analysis
W e simulated an all-IP w ireless access network with three base stations forming three cells, as illustrated in Figure 3.1. We assume a base station to be the Radio Edge Router (RER) implementing M obile IP m obility agents. For example, three base stations, HA, F AI and FA2 are edge routers that also serve as Home A gent (HA), and Foreign Agents (FA) respectively. The base stations are connected through a network o f core routers cO, c l, c2, and c i. W e simulated traffic from correspondent nodes CNO, CNI and CN2 to three mobile nodes MHO, M H l and MH2 respectively. The correspondent nodes also act as edge routers and connected to the network through the core router cO, while the mobile nodes MHO, M H l and MH2 are connected to HA, FAl and FA2 respectively. During the simulation, MHIand MH2 remain connected with their respective base station, whereas MHO m oves fi"om HA to F A l and then to FA2. The links 10,11,12,13,16, /7and 18 are configured as links whose bandwidth is 10 Mbps and propagation delay is 5 ms. Links 14 and 15 are configured as links whose bandwidth is 300 Kbps and propagation delay is 5 ms. The links 14 and 15 are the bottleneck links carrying handover traffic and are the focus o f our investigation. In this simulation we want to study the impact o f mobile IP handover on the adaptive TCP connections. Hence, we generated three FTP traffic - one each from CNO to MHO, from CNI to M H l and fi-om CN2 to MH2. The corresponding TCP flows are named as flowO, flow l and flow2, respectively. The rate adjustment algorithm at the TCP sender continuously adjusts the sending rate to the available bandw idth in the network throughout the connection lifetime. Details o f configuration for the access netw ork and the DiffServ domain is given in Chapter 4.

27

C NO

CN2

/

I

t

I

MHl MH2

\

MHO

Figure 3.1 Basic Simuiation Scenario with Two CN and Two Mobile Nodes

When mobile nodes move from one base station to another the traffic load varies on the links in the communication path. We call the flows that experience handover as handover flows, while the flow from a correspondent node to a mobile node that remains connected with its original base station as a local flow of the base station. Since the number of handover flows is usually unpredictable at any given time, the handover flows are expected to cause performance degradation in the existing flows. We organized the simulation into two cases. In case 1, flowl from CNI to M Hl is a local flow in the cell FAl and flow2 from CN2 to MH2 is a local flow in the cell FA2. FlowO from CNO to MHO is a handover flow from the cell HA to the cell FAl and then to FA2. To keep focus on the main issues we only consider A Fl, for the simulation of easel. Hence, the handover flow and the local flows are all marked as A Fl. The bandwidth of each flow on the bottleneck link is show in Figure 3.2; Figure 3.2(a) shows the interaction o f the handover and local flows along the path to FA l, and Figure 3.2(b) shows the interaction of the handover and local flows along the path to FA2. The bandwidth values presented in the above figures are computed as the percentage of the total bandwidth of the bottleneck link. The simulation result shows that the effect on the existing flows in the new cell is in proportion to the bandwidth demand of the handover flows when both flows share the same DiffServ class. We

28

found that the local flow s in the new cell experience bandwidth shortfall due to sharing the available bandw idth on the bottleneck links with the handover flows.
casel(cl c2)
flo w 0 f lo w 1

9 0 .0 0 0 0

8 0 .0 0 0 0 7 5 .0 0 0 0 7 0 .0 0 0 0 6 3 .0 0 0 0

flo w l

5 5 .0 0 0 0 5 0 .0 0 0 0

4 0 .0 0 0 0 3 5 .0 0 0 0 3 0 .0 0 0 0 2 5 .0 0 0 0

flowO

20.0000
1 5 .0 0 0 0

10.0000

0.0000
- 5 .0 0 0 0 1 0 .0 0 0 0 1 5 .0 0 0 0 2 0 .0 0 0 0 2 5 .0 0 0 0 3 0 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0

Figure 3.2(a) Interaction o f Handover and Locai Flows Along the Path to F A l

29

casel(cl-c3)
bindw idth(S > ) flo w 0

100.0000
9 3 .0 0 0 0 9 0 .0 0 0 0 8 5 .0000 8 0 ,0 0 0 0 7 3 .0 0 0 0 7 0 .0 0 0 0

flo w 2

--

\

/

in ""'

8 0 .0 0 0 0 3 3 .0 0 0 0 5 0 .0 0 0 0

flow2

V

3 0 .0 0 0 0 2 3 .0 0 0 0

flowO

20.0000
13.0000

10.0000
3 .0 0 0 0

0.0000
3 3 ,0 0 0 0 4 0 .0 0 0 0 5 0 .0 0 0 0 5 3 .0 0 0 0 6 0 .0 0 0 0

tim eC O

Figure 3.2(b) Interaction of Handover and Local Flows Along the Path to FA2 Figure 3.2 Result of Casel : Handover and Local Flows Sharing A Fl

It is obvious from the simulation that handover flow competes for bandwidth on the bottleneck link with the local flows after the handover in the new cell. This causes the service degradation of the local flows. To avoid this situation, a possible solution is to remark the handover flow to a lower service level to protect the bandwidth share of the local flows. We study the effects of this scheme by simulating case 2 whose result is shown in Figure 3.3. The simulation settings for case 2 are almost the same as those for casel, except that we introduced remarking o f the handover flow as AF2, a lower service level as compared to the local flow. Remarking is done at the home agent. A Weighted Round Robin (WRR) scheduler is used to schedule different services along the bottleneck link between core routers. We assigned twice the bandwidth o f AF2 to AFl by setting the weight of AFl twice as much as that o f AF2. Figure 3.3 shows that the bandwidth assignment for the local flow can 30

be protected if the handover flows are remarked to a different traffic class and the weight for the WRR scheduler is set properly after the handover.

case2(cl-c2)
buidwjdtli(%0
1 0 5 .0 0 0 0 flo w 0

100.0000
9 5 .0 0 0 0 9 0 .0 0 0 0 8 5 .0 0 0 0 8 0 .0 0 0 0 7 5 .0 0 0 0 7 0 .0 0 0 0

B ow 1

in---

flo w l
5 5 .0 0 0 0 5 0 .0 0 0 0

4 0 .0 0 0 0

flowO

30.0000

1 5 .0 0 0 0

5 .0 0 0 0

0.0000
1 0 .0 0 0 0 1 5 .0 0 0 0 2 0 .0 0 0 0 2 5 .0 0 0 0 3 0 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0

Figure 3.3(a) Interaction o f Handover and Local Flows Along the Path to F A l

31

case2(cl-è3)
bindwJdtii(90
100.0000
95 .0 0 0 0 9 0 .0 0 0 0 85.0000 80.0000 7 5 .0 0 0 0 7 0 .0 0 0 0 6 5 .0 0 0 0 60 .0 0 0 0 5 5 .0 0 0 0

flow2

45 .0 0 0 0 4 0 .0 0 0 0 3 5 .0 0 0 0 3 0 .0 0 0 0 2 5 .0 0 0 0

flowO

Vv

20.0000
15.0000

10.0000
5 .0 0 0 0

0.0000
-5 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0 5 0 .0 0 0 0 5 5 .0 0 0 0 6 0 .0 0 0 0

Figure 3.3(b) Interaction o f Handover and Local Flows Along the Path to FA2 Figure 3.3 Result of Case2: Handover and Local Flows In AF2 and A Fl Respectively

This simple simulation illustrates the impact of handover on DiffServ flows and the benefit of employing a protection scheme by isolating handover and local flows in different AF classes. In the following sections we discuss a dynamic bandwidth management scheme based on the above principle.

32

3.2 Dynam ic Bandwidth M anagem ent Algorithm 3.2.1 Overview
W e consider two service classes implemented as A F l and BE in the DiffServ-enabled mobile wireless access network. The reason for considering a single high priority A F l service is to develop the idea that can be extended in the future for multiple service class, in addition A Fl provides qualitative assurance that can be used for a wide variety o f applications and is easy to manage with less stringent requirements. We also assume that AF2 is also implemented as an auxiliary service class for A F l to accommodate A F l handover flows when those flows cannot be marked as A Fl in the new cell. As we have analyzed in the last section, handover flows compete with local flows for bandwidth, which causes the local flows to lose some o f their assigned bandwidth. In this section we develop the bandw idth management algorithms for handover flows to achieve the following two goals. First, an A F l flown should either continue with the same service level after handover, or in case o f lack o f available bandwidth, should receive better than best-effort service. In other words, the A F l service is either continued or downgraded gracefully after the handover. Second, handover flows should not cause huge disruption to the service level o f local flows. The second objective can be achieved to some extent w ith over provisioning because o f unpredictably large number o f flows handover caused by either crowd movement or by the movement o f few users with huge application requirements. The main idea o f our algorithm is to assign traffic to different service classes so that local flows are protected and at the same time handover flows are still admitted in the new cell. The tradeoff o f this idea is that some o f the flows will lose their service guarantee to an affordable extent temporarily. W e developed adm ission control algorithm for handover flows that outlines how to admit handover flows in a new cell with or without remarking to AF2. We also developed a service upgrade algorithm that is periodically invoked to decide about upgrading an AF2 flow. The algorithm selects the flows for service upgrade (restoring A F l marking) by using an AF2 flow. The algorithm selects the flows for service upgrade (restoring A F l marking) by using a priority system. We also propose a weight adjustment algorithm, including weight stealing and weight returning, for dynamic bandwidth assignm ent to AF2 service class by taking bandwidth from BE so that AF2 is assured higher service level than BE. The algorithm is invoked on a larger time scale by following the trend o f AF2 operating under high utilization at lower than BE bandwidth. This algorithm allows the operators to

33

provision smaller bandwidth to AF2 initially and then increase its share as the demand grows over à long period, which indicate higher level of sustained utilization.

3.2.2 Admission Control for Handover Flows
In the mobile wireless access network, admission control includes the admission control for originating flows and the admission control for handover flows. In this thesis we focus on the admission control of handover flows. Admission control for both originating and handover flows deal with both radio and network resources. In our study we assume that radio resource is available for the handover flow. This means that either the radio data rate is significantly more than the bottleneck link data rate (which is the case for WLAN) or the admission control on radio resource precedes the admission control on the network resources. Since we consider two service classes AF and BE here, whereas AF is the qualitative service while BE is not, our admission control algorithm is applicable only for the handover AF flows. In this context handover flows refer to handover AF flows. The aim for admission control is to provide as much as possible the contracted QoS guarantees to handover flows in the new cell; and at the same time maintain QoS guarantees for local flows. Further, in case of lack o f resources along the new path, the handover flow QoS should be degraded gracefully, that is it receives no worse than best-effort service. The algorithm tries to meet the objectives over large time scale, while it makes necessary tradeoff in small time scale. Considering the Mobile IP handover o f the DiffServ flows scenario in Section 3.1, we now introduce a service class AF2 lower than AFl but better than BE. When bandwidth available to AFl flows is not sufficient to meet the demands of handover flow, then the handover AF flows can be assigned to this service class so that local AFl flows can be protected and handover flows can still be admitted even though they get a downgraded service. We initially assign traffic to AFl and BE and during handover assign traffic to AF2 only if AFl lacks the required bandwidth, AF2 serves as a transient class or a backup class for AFl flows. AF2 is configured as a service level lower than A Fl, but higher than BE. Thus we can define the QoS contract for the AF user as: the standard service level is AFl and the bottom line or the worst-case service level is AF2. When enough bandwidth is available for the handover AF flows to a new cell for A Fl, they are marked as AFl and named AFl flows; while when bandwidth provisioning is limited and not enough in the new cell some handover AF flows are marked as AF2 and consigned to AF2 queue. When more bandwidth becomes available for A Fl, one or more handover AF2 flows can be selected for upgrading to A Fl. In that case the

34

chosen AF2 flows are rem arked as A F l. In our algorithm we address the issues that related to the situation o f downgrading and upgrading o f handover flows. For upgrading handover flows we consider two types o f users: those with less tolerance to service downgrade --called as G1 users and the other with more tolerance to service downgrade called as G2 users. W e assume two priority levels. The G1 process than G2 users. Let us review the situation on the bottleneck link along the path to the new cell. Assume that the total bandw idth o f the bottleneck link is and the bandwidth allocation for A F l, AF2 and BE users get higher upgrade priority in the admission

flows are BW^p,, BW^p2 and BWgp respectively, then:

'LqXBWAtotai be the available bandwidth on the bottleneck link, BWA afi, BWA^fi and BWAbe^^ the available bandw idth for A F l, AF2 and BE respectively, then: + In this research we only consider TCP flows that go through traffic conditioning at the entrance to the DiffServ domain. The traffic conditioning process includes m etering and policing using token bucket policer. W e assume that a target rate is defined for each o f the TCP flow as following: Ti- Target rate for the i th A F l flow; Tf. Target rate for the j th AF2 flow; Let the num ber o f A F l and AF2 flows served in the new cell be p and q respectively. Then we can have following expressions o f the available bandwidth for A F l and AF2:

B W A ,,,

-^ T ,
1=1

B W A ,, ^ = B W ,,, - ^ T j

Let us assume that at time to a handover AF flow, fno, makes a request for handover into the new cell. Further assume that the flow fho belongs to G1 user. The marking o f fho in the old cell is out o f concern o f the adm ission control algorithm. If the target rate o f the handover AF flow is denoted by

35

Tho, and the DiffServ marking for the flow is denoted by CPho, then admission control problem can be stated as: Given BWAafi and BWAafj, determine CPf/o when the flow target rate is Tho- We find the following three cases for the admission control algorithm. · Case-1. Handover flow can be marked as A Fl. If Two Then CP,,o = D SC P f o r A F \ and BWA^^^ = B WA^^^ - T,,o (1)

This is the best case where the available bandwidth for AFl is no less than the target rate of the handover AF flow. The handover flow is marked as AFl and the available bandwidth for A Fl is updated with Eq. 1. · Case-2. Handover flow can be marked as AF2. If Two > BWA^p ^ and T^g < BWA^^^ Then CPwo = D SC P f o r A F l and BWA^^^ = B WA^^^ ~ '^ ho (2)

In this case, the available bandwidth for AFl is not enough for the handover flow. If the algorithm marks the handover flow as AFl it will steal bandwidth from the local A Fl flows causing their service level to decrease. Since the available bandwidth for AF2 is enough for the handover flow the algorithm should mark the handover flow as AF2 and update the available bandwidth for AF2 as given in Eq.2. The benefit is quite obvious here. First, local AFl flow is fully protected. Second, local AF2 flows (if there is any) are not affected either. Third, the handover flow has a better chance to achieve its target rate after the handover even though it gets worse service than A Fl during congestion. Case-3: Handover flow can be marked as either AFl or AF2 If TfjQ > BWA^fi and T^q > BWA^p2 Aen the flow can be considered for marking either as AFl orAF2.

36

In this case w e introduce the concept o f penalty to evaluate the relative merit o f marking either as A F l or AF2. W e discuss the penalty and its evaluation in case 3 in the following section.

3.2.3 Discussion for Admission Controi Case-3
Before discussing our solution for case-3, we explain the dynamics o f bandw idth sharing o f TCP flows. In [27], Seddigh et al presented through a performance study they conducted on an experimental testbed that the TCP flows get fair degradation in their target rates in the under provisioned situation. Here fair degradation means proportional degradation. The situation depicted in case 3 resem bles the under-provisioning situation; hence their conclusion is applicable to the flows in this case. We conducted a simulation to understand the nature o f downgrade caused by handover to local flows. The topology for this simulation is similar to that given in Figure3.1. We have three AF flows in the test: two local flows flow l (from CNI to M H l) and fIow2 (from CN2 to M H2) in the cell F A l, and one handover flow - flowO (from CNO to MHO) moving from the cell HA to the cell F A l. Traffic settings are given in TableS.l. Flow num ber 0 1 2 DiffServ marking A Fl A Fl A Fl Target rate (kbps)
X

Source CNO CN I CN2

Destination

Flow Class Handover Local Local

MHO MHl MH2

100 100

Table 3.1 Traffic Settings for T estl. In the test, the total bandwidth o f the link is 300 kbps and the bandwidth allocation for A Fl class is 70% o f the link bandwidth that is 210 kbps. Local flows -flo w l and flow2 have fixed target rate o f 100 kbps each, while handover flow -flowO makes handover to the new cell with a variable target rate % that w e can set to different rates. We call a flow with small target rate as thin flow and a flow w ith large target rate as a fat flow. We set the target rate o f handover flows to 15, 30, 45, 60, 75, 90 and 105 kbps sim ulating from thin to a fat flow situation. The target rates for the handover flow are expressed as 5%, 10%, 15%, 20%, 25%, 30% and 35% o f the bottleneck link bandwidth. For every simulation run, we m onitor and record the average throughput o f each flow (flow 0, 1 and 2) on the

37

bottleneck link between the core routers cl and c2 along the path to FA during the time period when mobile node MHO is registered with the base station F A l. The result is shown in Figure3.4.

Testl(cl-c2)
baiidw idth(Sb] 7 5 .0 0 0 0
i iv e - 1 - 2

7 0 .0 0 0 0 6 5 .0 0 0 0 6 0 .0 0 0 0 5 5 .0 0 0 0 5 0 .0 0 0 0 4 5 .0 0 0 0 4 0 .0 0 0 0 3 5 .0 0 0 0 3 0 .0 0 0 0 c> l-0 flo w 1 flo w 2

flow2 cal-1(cal-2)

25.0000 -0 0 ^1
20.0000
-

1 5 .0000 -

flowO

10.0000
5 .0 0 0 0

0.0000
0.0000

cal-0
20.0000

4 0 .0 0 0 0

6 0 .0 0 0 0

80.0000

100.0000

Figure 3.4 Results for Testl Figures .4 shows the throughput expressed in terms of the percentage of the bottleneck link bandwidth. We use Bo(x), B,(x), and B2 (x) to denote the throughput of flow 0, 1 and 2 respectively when the target rate o f flow 0 is set to x kbps. Ave-1-2 is the average bandwidth for the local flows, which is calculated as:

^av.-l-2W = ^ k W

+ ^2W ]

We also calculate cal-1, cal-2 and cal-0 under the assumption that flows get proportional degradation under the under-provisioning scenarios, using following equations:

100
^ c a l- \ W cal-2 ( ^ ) "

100 + 1 0 0 + x

x70%

38

We can see from Figure 3.4 that except the very thin flow (target rate is set to 15 kbps) that causes extreme bandw idth shortfall o f local flows, other sizes o f flows all go approximately with the assumption. The exceptional case is left for further investigation. Our simulation corroborates the results o f [27] and shows that flows get proportional degradation in the under-provisioning situation. Since neither available bandwidth for API or AF2 is enough to m eet the target rate o f the handover flow in case 3 (an under-provisioning situation), regardless whether the handover flow is assigned to A F l or AF2 all flows including handover and local flows within that class will be penalized by missing their target rates. We define the penalty o f a flow as the amount by which it m isses the target rate, which is calculated as the difference between the target and the estimated bandw idth it is expected to receive based on the calculation o f the proportional bandwidth using above formula. W e calculate the total penalties for both A Fl and AF2 assuming the handover flow is assigned to each o f them respectively. Hence, we decide about the assignment o f the handover flow to either A F l or AF2 based on whichever assignment gives the total minimum penalty. We define the algorithm formally below. Assume P,- is the percentage by which the i-th local A Fl flow misses its target rate, P^o is the percentage by w hich the handover flow misses its target rate, and yf, is the simulated average bandw idth the f-th local A F l flow and Affo were expected to receive if the handover flow was marked as A F l. W e further assume that P afi is the total penalty o f all local A F l flows and the handover flow if the handover flow is marked as A F l. Then we can derive the following formulae if the handover flow is m arked as A F l : (3) 2 l T ,+ T ,, o 1 = 1 P = I L iA = i_ A r, 77 Substituting A; by (3) in (4) and simplifying it, we can get (4)

39

P, =
+ TffQ 1 = 1

(5)

HO ± T , + r^,, i=\

Then Eq.5 can be simplified as /). = 1 - orA F l
T. = -- -------------x BW^p^

Similarly

' ^ T i + TfjQ
i=l

andP,,o=% ~ ^ "°= l - |^ -^ H O ^H O

=

1i=\

So -P^Fl ~ ^
(=1

-^//O" (P  * 

~

)

(^)

Similarly, assume that Pj is the percentage by which they-th local AF2 flow misses its target rate, A] is the estimated average bandwidth the y-th local AF2 flow is expected to receive, and P afi is the total penalty of all local AF2 flows and the handover flow if the handover flow is marked as AF2. Then we can derive the following formulae if the handover flow is marked as AF2:

4 = -^ HO

^ ^^AF2

p .= L z A = i-â i ' Tj Tj

40

=
j=l Let

(7)

AF2

t . T , + r ,o M Then Eq.7 can be simplified as Pj = \ --a AF2 Th = --------------- y. q ^ B ^ W " M

Similarly

HO

AF2

S

>1

'^J '* ' ^H O

So

PaF2 = T , Pj
y=i

+

= fe + iX l -

)

(8)

W e can use Eq.6 and Eq.8 to compute the total penalty if the handover flow is assigned to either A F l or AF2 respectively. To safeguard A Fl flows being penalized with a too close margin to the penalty o f an AF2 flow, we introduce a factor (3 to be the difference between Pafi and Paf 2 . Hence we decide that if < f t P^fj > then the handover flow is assigned to A F l, and the available

bandwidth for A F l is updated to be zero since there is no more bandwidth remains available for A Fl after the assignment. Otherwise it is assigned to AF2 and the available bandwidth for AF2 is updated to be zero since there is no more remaining available bandwidth for AF2 after the assignment. In any case, the local flows are adversely affected by the handover flow and none o f the local and the handover flows could achieve their target rates. However, this approach minimizes the total penalty w ithin a class.

41

Let us discuss the effect o f factor p on the bandwidth distribution. It is an important parameter that provides control in achieving the level of control for afl flows. When p= l, we it is equally likely that the handover flow is assigned to ATI or to AF2. When p<l, it is more likely that the handover flow will be assigned to AF2, which gives more protection to local ATI flows and consequently shift more punishment to AF2 flows. On the other hand, when P>1, it gives more protection to local AF2 flows and shift more punishment to AFl flows. Hence, we suggest that /3 < \ ï o r normal operation. Figure 3.5 shows P*Paf2 curves for different values of p (0.25, 0.5, 1.0, 1.5) when PAF2 varies from 0 to 2.5. The region under the curve are the values of P*Paf2 (Pafi) for which the handover flow will be assigned to API, and the region above the curve is where the handover flow will be assigned to AF2. The Figure shows that as we increase the value of p the region where the handover flow should be marked as AFl expands, which indicates that the protection for AFl will decrease.

1.5
1.0

1=0.25 0.5

0

0.5

1.0

1.5

2.0

2.5

Figure 3.5 Effect of factor p

3.2.4 Summary of the Admission Controi Algorithm
Figures .6 shows the admission control algorithm pseudo code. Admission control algorithm (1) (2) upon the arrival of the handover AF flow IF available bandwidth for AF 1 of the link B WA^pj is no less than the target rate o f the handover AF flow (case-A) (3) (4) (5) mark the handover AF flow as AF 1 use Eq. 1 to update the available bandwidth for AFl ELSE IF available bandwidth for AF2 of the \\n\nBWAjiP2 is no less than the target rate of 42

the (6) (7) (8) (9)

handover AF flow (case-B) m ark the handover flow as AF2 use Eq.2 to update the available bandwidth for AF2 ELSE (case -C ) use Eq.6 to calculate the total penalty for local API flows and the handover

flow if the handover flow is marked as A Fl (10) use Eq.8 to calculate the total penalty for local AF2 flows and the handover

flow if the handover flow is marked as AF2 (11) (12) (13) (14) (15) (16) (17) (18) (19) ENDIF W P ,, ,< P P ,, , m ark the handover AF flow as AF 1 BWA afi~ ^ ELSE m ark the handover AF flow as AF2 BWA^f2 ~ ^ ENDIF ENDIF

(20) RETU RN Figure 3.6 Adm ission Control Algorithm Pseudo code. D uring the adm ission control process, if there are more than one handover A F l flows making request for handover to a cell, then they should get equal chance to be admitted as A Fl flow. However, they are queued in the request buffer and served in FIFO order. W hen bandwidth is limited on the bottleneck link only some o f the flows are assigned to A F l, while others are assigned to AF2. W e provide a m echanism for upgrading a handover flow from AF2 to A Fl whenever A Fl has residual bandw idth available. W e discuss the service-upgrading algorithm in detail in the next section.

3.2.5 Service Level Upgrade Algorithm
Although some handover A F l flows can be admitted at downgraded service level by being assigned to AF2 when congestion happens, they should be able to upgrade to the standard service level

43

whenever there is enough bandwidth available for API on the bottleneck link. We introduce Service Level Upgrade algorithm in this section to achieve the above objective. We need to consider several issues in designing service upgrade algorithm. For example, which flow to select for upgrade, when to check for upgrade, etc. We assume an upgrade priority associated with every flow. Flows with G1 priority level have stricter requirement for their service level than flows with G2 priority. For flows with the same priority but with different target rates, we suggest that the flow with the highest target rate should be considered first. The reason for this is that a flow with high target rate is more likely to wait in the service upgrade queue, which is further discussed below. When some local AFl flows leave a cell, they release their bandwidth, which causes the increase of the available. Assume that the number of AFl flows in the cell at any time t is p, and the target rate of the flow leaving the cell is Tho, then

We consider the flows in AF2 available for service upgrade are arranged in a priority queue. There are two independent First In first Out (FIFO) queues corresponding to LOW and HIGH upgrade priority, which are served by a priority scheduler, as illustrated in Figure 3.7.
FIFO queue for flows with higli upgrade priority

p riority scheduler incom ing flows low upgrade priority

outgoing flows

o

Figure 3.7 Schedule Schemes for Flow Upgrading Let Ti be the target of the i-th outgoing flow o f the priority scheduler where i starts from 1, details of the upgrading process can be expressed as the pseudo-code in FigureS.S:

44

(1)W HILE

> 7]. = BJVA^jr, - 7 } ; i = i + l

(2) DO rem ark flow i as AF l; (3) RETURN

F ig u re 3.8 Pseudo-code of Service U p g rad e A lgorithm A potential problem for the service upgrade algorithm concerns with the different target rates o f the AF2 flows in the cell. W hen a AF2 flow with high upgrade priority goes to the front o f its corresponding queue such that BWA^p, is less than its target rate Ti, then all the AF2 flows are blocked, even though some o f them may have smaller target rates less than BWAafi. This situation can adversly affect the efficiency o f the service upgrade algorithm. In order to avoid this situation, the flows in a FIFO queue are sorted in the ascending order o f their target rates. Thus flows with low target rates having m ore chance for upgrade precede the flows with high target rates having less chance for upgrade. W e need further mechanism to deal with starvation o f high rate flows that is beyond the scope o f this thesis. If the FIFO queue for high upgrade priority is always busy with the flow, then the flows with low upgrade priority never get a chance to be served as A FI. A possible remedy is to also consider sojourn time in the upgrade decision. We define sojourn time o f a flow in a cell as the time elapsed since the flow enters the cell. To avoid the above situation, a threshold for the sojourn time can be set up for the flows in the queue corresponding to LOW upgrade priority. When a flow 's sojourn time exceeds the threshold, its priority is changed from low to high and it is moved to the high upgrade FIFO queue. W e propose a mechanism to periodically invoke the service upgrade algorithm. We set up a timer w ith the time period o f t^ to periodically measure the available bandwidth o f A F I, which can be estimated by m easuring the bandwidth consumed by green packet and subtracting that from the bandw idth provisioned for A F I. We can maintain only a single timer for a cell. Figure 3.9 shows the time line o f service upgrade invocation. The time to is the beginning o f the upgrade process. After every time t^ the service upgrade algorithm is invoked, which computes the available bandwidth o f A FI along the bottleneck links and upgrade the eligible flows from AF2 to A FI following the algorithm given in Figure 3.8. It then resets the timer to expire after t,,. If a handover occurs before the tim er expires, for exam ple at time t, in Figure 3.9, then the service upgrade algorithm can be executed

45

as a part o f the handover process, hence the timer can be reset. This is because the time difference to the next t,, as was originally set may not be enough to create significant change in the bandwidth availability of A F I.
handover time

timerup
tim e

0

tl

U

2tu

3tu

4tu

· · ·

Figure 3.9 Timer Arrangements and Handover Time The trigger for the service upgrade algorithm can be described as follows; Trigger (1) f f (HO_flag) (2) (3) , upgrade ( ) H O flag e =false

(4) ENDIF (5) RETURN

3.3 System Overview
In this section we give an overview of the system implementing that identifies the issues related to the admission control algorithm for handover flows that includes a discussion on relevant issues. When a mobile node comes to a new cell, it first discovers its FA and HA and then registers with them and then the Mobile IP tunnel is established. In the registration process, when MN sends registration to its FA, it also triggers the admission control algorithm that will be performed by the FA. According to the algorithm, FA should keep the information of the available bandwidth for AFI and AF2 along the bottleneck link. To get this information FA needs to know the bandwidth allocation for AFI and AF2 along the bottleneck link and the information of bandwidth utilization of each service class. This information comes from the core network periodically and saves in the FA. The FA can find the bottleneck link that is beyond the scope of this thesis. When MN registers with FA, it also sends information of its traffic source, target rate, etc. The FA performs the proposed admission control algorithm and decides whether the flow needs to be remarked. If it decides for remarking, then it will 46

signal the HA, rem arking D SCP to AF2. On contrast, no remarking is needed and flows remain A FI. Then FA updates the inform ation for available bandwidth according to the marking o f the handover flow. If it is m arked as A F I, then the available bandwidth for A FI is decreased by the target rate o f the handover flow and the available bandwidth for AF2 remains the same. Otherwise, if the handover flow is rem arked as AF2, then the available bandwidth for AF2 is decreased by its target rate and the available bandw idth for A FI remains the same. For the service upgrade algorithm, a timer is installed in FA; every time the timer expires FA sends request to the core network to update the information o f available bandwidth for A FI and AF2. A lternatively, when handover happens, the service upgrade algorithm is also triggered. After the upgrading process, FA also upgrades its information for available bandwidth according to the upgrading information.

3.4 Provisioning
We introduced AF2 as a transient class that accommodates handover flows that cannot be admitted in A FI and tries to provide better than best-effort service for handover flows when bandwidth is not sufficient for A F I. U nder a rightly provisioned system AF2 should have few handover flows. Hence, we suggest that initially AF2 should be provisioned with small amount o f bandwidth, even smaller than BE, so that A FI can be provisioned with adequate amount o f bandwidth. However, when utilization o f AF2 is high and utilization o f BE is low, AF2 flows may get bandwidth much less than their target rate while BE flows may get bandwidth quite close to their target rate. This situation may result in AF2 flows getting worse than best-effort service, which contradicts with the goal o f our dynamic bandw idth management scheme. To avoid this situation, we introduce weight adjustment algorithm to dynam ically adjust bandwidth allocation for different service class according to the bandw idth utilization o f different service class.

3.4.1 Weight Adjustment Algorithm
We use W eighted Round Robin (WRR) scheduler in our simulations to implement the DiffServ classes. Given BW,otoat as the total link bandwidth, Wafi, ^af 2 and Wbe as weights for A FI, AF2 and BE respectively, then the bandwidth allocation for corresponding service is given as:

47

The mobile wireless access network only provides two class of services, AFI and BE. AF2 is a transient class for AFI, which is implemented to accept more handover AFI flows when bandwidth is limited. When a handover AFI flow cannot be admitted as AFI in the new cell, we assign it to AF2. In the DiffServ provisioning scheme AF2 can be allocated a small amount of bandwidth, even lower than BE. Since AF2 is designed to provide better than BE service to handover AFI flows, we need to define a mechanism to enhance bandwidth allocation for AF2 to surpass the BE allocation. Alternatively, AF2 can be allocated higher than BE bandwidth but it makes the bandwidth allocation less efficient because AF2 utilization can be low at the beginning. Furthermore, it does not preclude the need for future enhancement to AF2 bandwidth. In order to understand the need for bandwidth enhancement of AF2 consider the situation when a crowd moves into a cell with AFI flows. In this case a large number of flows may be assigned to AF2 service class, which may bring down the bandwidth available to AF2 flows even lower than BE causing a risk for AF2 flows to receive lower than BE service. This situation can be handled if we define a bandwidth enhancement scheme for AF2 class. However, any bandwidth enhancement scheme for AF2 class, including the one proposed below, must be carefully evaluated for their overhead and should be judiciously invoked to avoid instability in service provisioning. We propose a weight adjustment scheme for AF2 and BE service classes to achieve bandwidth adjustment to those classes. For example, when AF2 is crowded with the handover flows running the risk of AF2 flows getting lower than BE service, then the bandwidth can be stolen from BE and allocated to AF2. This can be achieved by increasing the weight of AF2 and simultaneously decreasing the weight of BE by the same amount. We also need to define a bandwidth return procedure from AF2 to BE whenever the utilization of AF2 bandwidth is significantly lower than the BE utilization. To guarantee basic services for BE and provide some level of protection for AF2, we give AF2 and BE minimum weight limit as WLafi and WLbe respectively. The process here is to take the weight from BE and give it to AF2, until there is

48

enough bandw idth for the handover AP flows or until the minimum weight for BE is reached. In this process AF2 steals bandw idth from BE. On the other hand, when the utilization o f the bandwidth o f AF2 is significantly lower than BE, it returns some weights to BE. For the basic quantum o f weight moved from AF2 to BE and vice versa, we consider a quantum Ô here in our algorithm . Then the weight adjustment algorithm can be expressed as a combination o f the following w eight stealing and weight-returning algorithm: · W eight stealin g alg o rith m (1) (2) IF (W eightStealing _flag) IF W , , > W L , , + b Wb£ - 5; Waf2= Waf2 + 5; ENDIF ENDIF RETU RN

(3) (4) (5) (6) (7)

· W eight re tu rn in g alg o rith m (8) IF (W eightRetum ing _flag)

(9)
(10) (11) (12) (13) (14) WaF2~ WaF2 - Ô; Wbe^ Wb£ + d', ENDIF ENDIF RETU RN

49

Chapter 4 Simulation Setup and Result Analysis
We have developed a simulation model of a mobile wireless access network configured with three base stations. We performed our simulation in network simulator ns-2 [32]. In this chapter we will discuss the results of our simulation of the admission control algorithm, as described in Chapter 3. We will first discuss the simulation setup in Section 4.1, and then we will present the results and their analyses in Section 4.2.

4.1 Simulation Setup 4.1.1 Topology
We used the network topology as shown in Figure 4.1 in our simulation. We used this topology to create four scenarios. In the following we describe main component of the network.
CN5 CN7

CN3

CN l

CNO

MH7

M H l
MH5

HA
MHO

FAl

Figure 4.1 Network Topology in Our Simulation

50

In our sim ulation topology, CNO, C N l, ... , are correspondent nodes. cO, c l, c2 and c3 are core routers in the D iffServ domain. HA, F A l, FA2 are base station nodes and MHO, M H l, ... , are mobile hosts. All the correspondent nodes and the base station nodes are also configured as DiffServ edge nodes. W e have several kinds o f links in this simulation topology, including core links, edge links and other links. To identify the links, we define link (x, y) as the link from node x to node y . Then link (rl, r2) and link ( r l, r3) are our bottleneck links. The bandwidths o f the links are both set as 300k bps and the packet processing delay is 5ms. The queue used for both these links are DiffServ type core queues using RED buffer type. To sim plify our simulation, we set the link from each correspondent node to its access router as a D iffServ-capable edge link. Then there is only one physical queue on the simplex edge link since we only configured one traffic flow from each correspondent node to its related mobile host. The bandw idth o f the link is 10Mbps and the packet processing delay is 5ms. The queues used for the edge link are D iffServ type edge queues using RED buffer type. On the other direction we define a simplex link from the access router to every correspondent node, which is configured to have 10 M bps bandw idth and 5ms packet processing delay and they use drop-tail queues. Similar with the links betw een the base stations and their correspondent access routers, we set the link from each base station to its access router as a DiffServ-capable edge link with the bandwidth set as 10Mbps and the packet processing delay as 5ms and using RED buffer type. On the other direction we define a simplex link from the access router to every base station, which is configured to have 10 Mbps bandw idth and 5ms packet processing delay and they use drop-tail queues. Link (cO, c l) is also a link betw een core routers. However, since it is not the bottleneck link, we simply configure it as a duplex link w ith 10Mbps bandw idth and 5ms packet processing delay and using drop-tail queues.

4.1.2 Traffic Generation
Unlike UDF, TCP is a transport protocol adaptive to the network congestion state. It explores the availability o f bandw idth along the communication path and tries to greedily grab that bandwidth. For this characteristic o f TCP we used it in our simulation to measure how does TCP react to the service upgrade and downgrade. W e selected FTP as a representative o f long flows, because as compared to other traffic types such as HTTP, FTP has larger object size that can be adjusted to generate longer TCP-connections. Further, it spends less time and packets on control and connection management

51

than the time for the transmission o f data. The long data transmission provides TCP's congestion control algorithm enough time to adapt to the available bandwidth in the network. The packet size we used for our simulation is 1040 KB. We establish TCP flows denoted by flowj between CNj and MHj.

4.1.3 DiffServ Configuration
To distinguish traffic with different Per Hop Behaviors (PHB) s, DiffServ code point (DSCP) is used and attached to a packet's IP-header. DiffServ PHBs are designed to provide qualitative service differentiation with no quantitative guarantees. As mentioned before, we have implemented three PHBs: AFI, AF2 and BE. The critical components in implementing these PHBs are scheduler and buffer management schemes, which we discuss in detail below.

4.1.3.1 Buffer Management
In a DiffServ domain, traffic goes to different queues based on their DSCPs within a router. Buffer management decides how to manage packets inside a single queue. Two buffer types used in our simulation are RED and drop-tail. Core queue and edge queue are two DiffServ-capable queue types in our simulation. The core queue is usually deployed at the congestion point in the network. Since congestion only happen in the bottleneck link in our topology, only the bottleneck link is configured as a core queue. The edge queue is capable of performing policing, packet marking, etc. All queues between a host (e.g. CN or MH) and its access router in the direction of host-to-router are edge queues. We implemented MRED [12] scheme for buffer management in AFI and AF2. We implemented only two drop precedences for API anAF2 PHBs. Each drop precedence is identified by a distinct DSCP - the packet with low drop precedence is called the green packet and the one with high drop precedence is called the red packet. Each PHB is implemented using a separate physical queue; while both API and AP2 physical queues consist of two virtual queues each one for the in-profile (green) packets and the other is for the out -file (red) packets, as illustrated in Pigure4.2. Different RED parameters are used for the virtual queues; causing red packets to be dropped more frequently than green packets. Similarly we configure API MRED with higher minimum and maximum thresholds than AF2 MRED to drive AP2 packets to the congestion point before API packets.

52

physical queue for A FI

virtual queue for inprofile packets (green) physical queue forAF2 virtual queue for out-ofprofile packets (red) physical queue for BE

Figure 4.2 Queue Structure in Simulation In M RED, drop probability for packets with different drop precedence (or described as packet color) have to be calculated independently for each drop precedence, thus multiple sets o f RED thresholds need to be maintained - one for each drop precedence. M ultiple Average M ultiple Threshold (M AM T) scheme including RIO Coupled mode (RIO-C) and RIO de-coupled mode (RIOD) is applied for calculating the average queue used for the drop decision. In the MRED scheme we im plem ented threshold param eters for packets o f different colors are set to partially overlap. For example, following param eters are defined for MRED supporting two colored packets: in min, in max and in_prob to be the minimum and maximum thresholds o f average queue length and drop probability o f green packets respectively, out min, out max and out_prob to be the minimum and maxim um thresholds o f average queue length and drop probability o f red packets respectively, and qlimit to be the m axim um buffer size:

53

'' \ S e r v i c e class AFI P a ra m e te r''^ '^ ^ In_min (in packets) In_max (in packets) In_prob Out min (in packets) Out max (in packets) Out_prob qlimit (in packets) 20 40 0.02 10 20 0.10 40 10 20 0.08 5 20 0.15 20 AF2

BE

15 15 1.00 0 0 1.00 15

Table 4.1 Parameters for MRED in the Simulation Except core and edge queues (at edge and bottleneck links) all other queues are configured as simple FIFO queues with drop tail buffer management policy, because they do not experience congestion and do not contribute to the QoS performance of DiffServ flows.

4.1.3.2 Queue Management
Queue Management deals with how to control scheduling between multiple queues. For proportional bandwidth distribution across multiple PHBs, Weighted Fair Queuing (WFQ) is quite popular. It is a flow-based scheduling algorithm that provides fair sharing of bandwidth among multiple flows in proportion to the assigned weights. For example, flows with higher weights will get more bandwidth than flows with lower weights. Similarly, in Weighted Round robin (WRR) scheduling scheme weights are also assigned to buffers to indicate their relative share of link access time, and buffers are given opportunity for link access in a round robin fashion one buffer at a time. Thus, WRR can be regarded as a variant of WFQ. For convenience, we employed WRR as our scheduling mechanism to implement the three PHBs. Each physical queue is assigned a weight determined by the DiffServ provisioning scheme. The WRR scheduler is work-conserving which means that if a queue has no packets to send its turn will be handed over to the next queue. Thus, if a service class lacks packets, then other service classes will share the link capacity according to their weights.

54

4.1.3.3 Core Routers
The core routers in DiffServ are quite simple because the only function they perform is to assign incom ing packets to the relevant virtual queue and physical queue as identified by the DSCP. In each core router, we have three physical queues refer to the A FI, AF2 and BE services and each o f them has two virtual queues for the in-profile (green) packets and the out -profile (red) packets. Each physical queue and virtual queue combination correspond to a unique DSCP, thus we need five DSCP to im plem ent the three PHBs --two each for AFI and AF2 and one for BE. For each virtual queue, RED param eters are properly set, including minimum and maximum thresholds and drop probability.

4.1.3.4 Edge Routers
Edge routers perform more QoS functions than core routers in DiffServ. Besides the implementation o f PHBs using schedulers and buffer management similar to core routers, Edge routers also perform traffic conditioning functions - policing, metering, and marking packets. Edge routers deal with the individual user flows. They classify flows based on: source address, destination address and traffic type or any combination o f them. After classification they mark the packets w ith the appropriate DSCPs. We configured edge routers with Token Bucket policers, which use Com m itted Inform ation Rate (CfR), Committed Burst Size (CBS) and two drop precedences as the param eters. A n arriving packet is marked with the lower drop precedence (green) if the token bucket has enough tokens for the packet; otherwise it is marked for higher drop precedence (red).

4.1.4 Statistics and Monitoring
To m onitor and gather statistics o f our simulation, a number o f different approaches are used including m onitoring parts o f the topology or tracing events as the simulation progresses and writing them to files. The actual simulation scale statistics are collected by post-processing the trace and m onitor files with awk-scripts, perl-scripts, etc.

4.1.4.1 Fiow Monitoring
To observe and analyze the bottleneck links, we created and attached flow monitor to them. A flow monitor is used to collect the statistics o f a flow for packet arrivals, departures and drops in either num ber o f bytes or packets. We collect every second the number o f bytes departs the bottleneck link in our simulation, which is a good estimation o f the number o f bytes transmitted within the

55

measurement window (of 1 second). To track the statistics for each flow that traverses the bottleneck link, a classifier is also defined so that it selects the fiow based on its fiow id. With the statistics of packet departure, it is easy to get the instantaneous throughput for each fiow along the bottleneck link. Details will be given in following sections.

4.1.4.2 Tracing
Tracing is the most basic method of collecting simulation information. We could set tracing on individual links or for all links in the network. However, tracing all links will induce considerable performance penalty and large amounts of output data including some useless data. Therefore, selectively tracing links or sources we can perform simulation more efficiently. For example, we chose to trace some TCP parameters such as congestion window, ssthresh, etc.

4.1.4.3 Analysis
Together statistics from various tracing and monitoring files, we use peri and awk scripts in our post processing process. Xgraph is also a useful graphing tool to present our results. With the help of these tools we have been able to analyze the simulation data that we present below.

4.2 Results and Analysis
We divide our results into three cases for admission control in addition to a service upgrade scenario.

4.2.1 Admission Control Case-1; Scenario 1
Scenario 1 is set as the over-provisioning scenario, whose details of traffic settings are given in Table 4.2. Originally, the mobile node MHO is registered with the base station HA, while M H l, MH3 and MH7 are in the cell of FA l. The local flows in the cell of FA l namely fiowl (from CNl to M Hl) is marked as AFI, fiow3 (from CN3 to MH3) is marked as AF2 and flow? (from CN7 to MH7) is marked as BE. WRR weights for AFI, AF2 and BE is 7, 1 and 2 respectively which indicate that they share the bandwidth of the bottleneck link in proportion to 70%, 10% and 20% respectively.

56

Flow num ber 0 1 3 7

Source

Destination

Flow class HO" local local local

Target rate (kbp) 100

DiffServ marking

W RR weight

Bandwidth*

CNO CNl CN3 CN7

MHO MHl MH3 MH7

AFI 100 100 100 AF2 BE

7 1 2

70% 10% 20%

* Bandwidth refers to the bandwidth o f the bottleneck link in percentages; # HO stands for handover .

Table 4.2 Traffic Settings for Scenario 1

A t sim ulation time 35s MHO starts moving from the cell o f HA to the cell o f F A l, its flowO is subject to adm ission control in the new cell. Since flowO is originally an AFI flow, for the admission control first checks if it can be assigned to the AFI class at the bottleneck link. The bandwidth allocated to A FI is 70% o f 300 kbps, that is 210 kbps. As the target rates o f flow l and flowO are 100 kbps, the available bandw idth for A FI is: = 2 1 0 - 1 0 0 = 1 1 0 > r ^ o =100(kbp) This indicates the over provisioning Case-1 o f the admission control algorithm where bandwidth available to A FI is sufficient to accommodate the handover flow. The handover flow into AFI class and rem ains m arked as A FI after the handover. After running the simulation o f Scenario 1, we get the instantaneous throughput o f each flow in Figure 4.3. W e can see that after handover the handover flow --flowO and the local AFI flow --flowl share the bandw idth allocation o f the AFI class which is 210 kbps, occupying 70% o f the total bandwidth o f the bottleneck link and the local AF2 and BE flows are as usual and share the rest o f the bandw idth as 10% and 20% o f the total bandwidth o f the bottleneck link respectively.

57

ScenaHol(cl.c2)
b jadw idth(S >] B ow 0

100.0000
9 3 .0 0 0 0

Sow1
£hw 3"
flo w 7

7 0 .0000

flo w l

6 0 .0 0 0 0 3 3 .0 0 0 0 3 0 .0 0 0 0

4 0 .0 0 0 0

3 0 .0000 2 5 .0 0 0 0

flow?
-

20.0000
13.0000

-flow3

10.0000
3 .0 0 0 0

0.0000
-3 .0 0 0 0

flowO
2 0 .0 0 0 0 2 5 .0 0 0 0 3 0 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0 3 0 .0 0 0 0

Figure 4.3 Instantaneous Throughput for flows in Scenario 1 We also traced packet numbers and congestion windows for the handover flow at the sender side, which are shown in Figures 4.4 and 4.5.

58

soenarlol
pacicds
1 .9 C 0 0 1 .8 5 0 0 1 .8 0 0 0 1 .7 5 0 0 1 .7 0 0 0 1 .5 5 0 0 1 .6 0 0 0 1 .5 5 0 0 1 .5 C 0 0 1 .4 5 0 0 1 .4 0 0 0 1 .3 5 0 0 1 .3 0 0 0 1 .2 5 0 0
p ic k e ti

1.2000
1 .1 5 0 0

1.1000
1 .0 5 0 0

1.0000 20.0000
2 5 .0 0 0 0 3 0 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0

F ig u re 4.4 P a c k e t Sequence N um bers vs. Tim e of flowO in Scenario 1 In Figure4.4, packet numbers are scaled within the range o f 1.0 - 1.9. During the period o f around 20 - 40s correspondent node CNO is connected to FA l and flowO starts traversing the links along the path to F A l. FlowO has five retransmissions during the period and they happen at 26.1s, 30.9s, 35.3s, 36.7s and 39.8s respectively. Figure 4.5 shows that every retransmission causes the congestion window to be reduced by half. T he reason for this phenom enon is that we use TCP reno as our source.

59

FlowO in Scenariol
cw nd

22.0000
21.0000 20.0000
19.0000 18.0000 17.0000 16.0000 13.0000 14.0000 13.0000

12.0000

11.0000 10.0000
9 .0 0 0 0

8.0000
7 .0000

6.0000
5 .0000 4 .0 0 0 0 3 .0000

2.0000 1.0000 0.0000
2 0 .0 0 0 0 2 5 .0 0 0 0 3 0 .0 0 0 0 3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0

Figure 4.5 Congestion Window vs. Time of FlowO in Scenario 1

4.2.2 Admission Control Case-2: Scenario 2
Traffic settings for Scenario] are given in Table 4.3. The mobile node MHO is originally registered with the base station HA. We have four local flows in the cell of FA l: flowl (fi-om CNl to M H l) and fiow5 (from CN5 to MH5) are both marked as A PI, while fiow3 (fi'om CN3 to MH3) is marked as AF2 and flow? (from CN? to MH?) is marked as BE. WRR weights for AFI, AF2 and BE are set to ?, 2 and 1 respectively which indicates that they share the bandwidth of the bottleneck link in proportion to ?0%, 20% and 10% respectively.

60

Flow num ber 1 5 0 3 7

Source

Destination

Flow class local local HO" local local

Target rate (kbp) 100

DiffServ marking

WRR weight

Bandwidth*

CNl CN5 CNO CN3 CN7

MHl MH5 MHO MH3 MH7

AFI 100 30 AF2 30 100 BE

7

70%

2 1

20% 10%

* Bandwidth refers to the bandwidth of the bottleneck link in percentages; # HO stands for handover .

Table 4.3 Traffic Settings for Scenario 2

In scenariol, bandw idth allocations for AFI and AF2 are 70% and 20% respectively, which correspond to 3 0 0 x 7 0 % = 2 1 0 kbps and 3 0 0 x 2 0 % = 60 kbps respectively. Then available bandw idths for A F I and AF2 are: = 2 1 0 - ( 1 0 0 + 100) = 10 (kbp) = 6 0 - 3 0 = 30 (kbp) Since the target rate for the handover flow in this scenario is T^o ~ 30 kbps, we have the relation: TfjQ > BWA^p^ and <BWA^p^ which goes along with Case-2 o f our admission control

algorithm. Therefore, the algorithm decides to admit the handover flow to AF2 and it is remarked to AF2 when it m akes handover to the new cell. We sim ulated this scenario and the instantaneous throughput for each flow after the handover is showm in Figure 4.6. The figure shows that local AFI flows --flow l and flowS are not affected by the handover flow, while local AF2 flow - flow3 shares the 20% o f the bandwidth o f the bottleneck link w ith the handover flow. Since their target rates are both 30 kbps, they share the bandwidth allocation for AF2 that is 60 kbp. The local BE flow remains the same as before handover.

61

b«Ddw H !h(t)
flo w 0

100.0000 93.0000 90.0000

flo w 1 flo w

3

fio w J f lo w ?

80.0000 73,0000 70.0000 63.0000 60.0000 33.0000 30.0000 flo w l

40.0000 33.0000 30.0000
25.CCCO - f l o w s

20.0000 13.0000 10.0000 3,0000 -

1

-,

'I

I

0.0000 - f l o w 7

-3.0000 13.0000

20.0000

25.0000

30.0000

35.0000

40.0000

45.0000

50.0000

Figure 4.6 Instantaneous Throughput for flows in Scenario 2 We also traced packet numbers and congestion windows for the handover flow at the sender side, which are shown in Figure 4.7 and 4.8.

62

scenario2
pacleetB
1 .9 0 » 1 .8 5 0 0 1 .8 0 0 0 1 .7 5 0 0 1 .7 0 0 0 1 .6 5 0 0 1 .6 0 0 0 1 .5 5 0 0 1 .5 0 0 0 1.4-500 1 .4 0 0 0 1 .3 5 0 0 1 .3 0 0 0

piclO B ii

1.2500 1.2000
1 .1 5 0 0

1.1000
1 .0 5 0 0

1.0000
tim e

20.0000

2 5 .0 0 0 0

3 0 .0 0 0 0

3 5 .0 0 0 0

4 0 .0 0 0 0

4 5 .0 0 0 0

Figure 4.7 Packet Sequence Numbers vs. Time o f flowO in Scenario 2 In Figure 4.7 we don't see any retransmission. In combination with Figure 4.8, we see that during the time w hen the mobile node MHO is registered with F A l, flowO has never reached the congestion avoidance phase since the congestion window remains less than ssthresh for the whole period.

63

FlowO in Scénario!
cw od cw nd

19.0000 18.0000 17.0000 16.0000 15.0000 14.0000 13.0000
12.0000 11.0000 10.0000

9.0000
8.0000

15.0000

20.0000

25.0000

30.0000

35.0000

40.0000

45.0000

Figure4.8 Congestion W indow vs. Time of FlowO in Scenario 2

4.2.3 Admission Controi Case - 3: Scenario 3
When the available bandwidth of neither AFl nor AF2 is sufficient to meet the target rate of the handover flow, the proposed admission control algorithm applies penalty scheme o f Case-3 to determine the assignment of the handover flow to the appropriate class. We simulated this case in the following scenario.

4.2.3.1 Scenario 3a
Traffic settings for this scenario are given in Table 4.4. Before the handover flow comes to the new cell available bandwidth for AFl and AF2 are: = 2 1 0 -(100 + 100) = 10 (kbps) =0

64

So neither o f them is enough to meet the target rate o f the handover flow and this scenario falls into the situation o f case - C o f our admission control algorithm. Flow num ber 0 1 5 3 7 Flow class HO* local local local local Target rate (kbp) 100 100 100 100 100 AF2 BE 1 2 10% 20% A Fl 7 70%

Source

Destination

DiffServ marking

W RR weight

Bandwidth*

CNO CNl CN5 CN3 CN7

MHO MHl MH5 MH3 M H7

* Bandwidth refers to the bandwidth o f the bottleneck link in percentages; # HO stands for handover .

Table 4.4 Traffic Settings for Scenario 3a

L et's calculate the penalty for A F l and AF2 if the handover flow is assigned to the respective class. Since
B W AF\
HO
i=l

=

300x70%

100 + 100 + 100

= 0.7

^AF\ = (P + l) `

" ^AFl ) = 3 X (l -

0 .7

) = 0.9

_
` ^AF2-~
7=1

-

_ 300x10% _ - O .I J 100 + 100

P aFI = f e + l ) - ( l - « ^ 7= -2 ) =

2

x (1 -

0

. 1 5 ) = 1.7 flowO should be marked as A F l according to our

if p = l, we have the relation Pjip^ < P P afi >

adm ission control algorithm. We simulate this scenario and the instantaneous throughput is given in Figure 4.9.

65

Scenario3a(cl-c2)
bandwidtii(Sb)
105.0000 flo w 0 flo w 1

100.0000
9 5 .0 0 0 0 9 0 .0000 85.0000 80.0000 7 5 .0000 7 0 .0000 6 5 .0 0 0 0 6 0 .0000 5 5 .0 0 0 0 5 0 .0 0 0 0 4 5 .0000 4 0 .0000 3 5 .0000 3 0 .0 0 0 0 2 5 .0 0 0

'

\

flo w 3

all

flo w 5 flo w 7 jil

i:

'a A

-

20.0000 W
15.0000

' M

M

' '

'

10.0000
5 .0 0 0 0

0.0000
-5 .0000 15.0000 2 0 .0 0 0 0

flowO
2 5 .0 0 0 0 3 0 .0 0 0 0

_L
3 5 .0 0 0 0 4 0 .0 0 0 0 4 5 .0 0 0 0

I
5 0 .0 0 0 0

Figure 4.9 Instantaneous Throughput for flows in Scenario 3a Figure 4.9 shows that when the handover flow, flowO, is marked as A Fl it competes for bandwidth with local A Fl flows, flowl and flow5, and cause their bandwidth to drop. Local AF2 flow, flowS, and local BE flow, flow?, are not affected by the handover. This scenario presents the situation where AFl and AF2 flows get equal protection, However, if we want to give more protection to local AFl flows, we can increase the value of (3. We discuss this case in the following section.

4.2.S.2 Scenario 3b
In scenario 3b, traffic settings are exactly the same as that of scenario 3a. Thus the penalties are calculated to the same values as for Scenario 3a, which are given below: = 0 .9 and P^^^ = 1-7 if we choose = 0.5,

66

then P ·

= 0.5 x 1.7 = 0.85 <

so the handover flow - flowO should be marked as AF2 according to our admission control algorithm. W e sim ulated this scenario and result is given in Figure 4.10.

bandwxdtii(^)
100.0000
9 5 .0 0 0 0 9 0 .0 0 0 0

Scenario3b(cl-c2)
f lo w 0

8 0 .0 0 0 0 7 5 .0 0 0 0 7 0 .0 0 0 0 6 5 .0 0 0 0 6 0 .0 0 0 0 5 5 .0 0 0 0 5 0 .0 0 0 0 4-5.0000 4 0 .0 0 0 0 3 5 .0 0 0 0 3 0 .0 0 0 0 2 5 .0 0 0 0

flo w s

flo w l

20.0000
1 5 .0 0 0 0

flo w ?

flo w s

flow O

10.0000
5 .0 0 0 0

0.0000
3 0 .0 0 0 0 4 0 .0 0 0 0 5 0 .0 0 0 0

F ig u re 4.10 In stan tan eo u s T h ro u g h p u t fo r flows in Scenario 3b From Figure 4.10, we see that local A Fl flow, flow l and flow5, are well protected and continue receiving the same bandw idth as what they have had before the handover. Local AF2 flow, flow3, shares the bandw idth with the handover flow. Since bandwidth allocation for AF2 is 10% and the two flows have the same target rate o f 100 kbps, each gets 5% of the bandwidth o f the bottleneck link after the handover, w hich is equivalent to 300 x 10% = 30 kbps and much less than their target rates. Local B E flow, flow?, rem ains unaffected.

67

4.2.3.3

Impact of Weight Adjustment on Factor p

In senario3b, we want to give more protection to local AFl flows and assigned the handover flow to AF2, which consequently results in AF2 flows missing their target rates. In this situation we can employ the weight adjustment algorithm, to steal some bandwidth from the lower service class level BE. Assume that we steal 10% on the bandwidth of the bottleneck link from BE and add that to AF2, thus the bandwidth allocation for AF2 will be increased to: BW ap2 = 300 X 20% = 60 (kbp)

and V r x r
y=i

= ---------100 + 100

= 0.3

then

Pap2 = (^ + 1) (l - cXap2 ) - 2 x (l - O.S) = 1.4

Since penalty for the AF2 flows if the handover flow is marked as AF2 decreases as a result of increase in bandwidth allocation through weight adjustment, P should be raised proportionally in order to mark the handover flow as AF2 and give more protection to local AFl flows. Consider the situation in scenario 3b, when 6 > P 0.9 = -- « 0 .5 3 , the handover flow is marked as A Fl, 1.7

otherwise it is marked as AF2. Now when weight is added to AF2, we have the new decision bound as when /? > AF2. Therefore, when AF2 gets more weight, the decision bound (P) for marking of the handover flow also increases to provide the same level of protection to AFl flows as it was receiving before the weight adjustment. Thus, the bandwidth management algorithm needs to be modified to take into consideration the situation that when weight adjustment algorithm is triggered, the P factor should be adjusted accordingly other wise the protection level of AFl flows will be changed. We leave for further research to explore the space of P adjustments. P 0.9 = ----- « 0.64 , the handover flow is marked as A Fl, otherwise it is marked as 1.4

68

4.2.4 Service Upgrading: Scenario 4
To understand the dynamic o f service upgrade algorithm, we still investigate the upgrade situation on the bottleneck link betw een nodes c l and c2. Traffic settings for this scenario are given in Table 4.5. DiffServ Flow num ber Source D esti nation Flow class Target rate Old 5 1 0 3 7
* #

WRR weights Old 7 New -

marking New A Fl A Fl

Bandwidth* Old 70% New 70% 20% 20% 10%

CN5 CNl CNO CN3 CN7

MH5 MHl MHO MH3 MH7

HO" local local local local

100 100

7 2 2 1

100 AF2 100 100 BE AF2

Bandwidth refers to the bandwidth o f the bottleneck link in percentages; HO stands for handover . Old means the value before the handover happens; N ew means the value after the handover happens.

Table 4.5 Traffic Settings for Scenario 4 of Service Upgrading

This scenario presents the dynamic situation in the cell o f F A l. Originally, there are five mobile nodes in the coverage area o f F A l, which are MHO, M H l, MH3, MH5 and MH7. Flow l (from C N l to M H l) and fIow5 (from CN5 to M H5) are local A Fl flows, flowO (from CNO to MHO) and flow3 (from CN3 to M H3) are local AF2 flows, and flow? (from CN7 to MH7) is a local BE flow. The provisioning scheme sets W RR weights to 7, 1 ,2 (corresponding to 70%, 10% and 20% o f the bottleneck link bandw idth) for A F l, AF2 and BE respectively. We assume at simulation time 25s mobile node M H5 m oves from the cell o f F A l to the cell o f FA2. We also assume that flowO (from CNO to MHO) has higher service upgrade priority than flow3 (from CN3 to MH3). Therefore, according to our service upgrade algorithm, flowO is upgraded and remarked as A Fl after the handover o f M H5. Simulation result o f this scenario is shown in Figure 4.11. We can see that as a result o f handover flow5 releases its bandw idth on the link, and flowO is upgraded to A F l and share the A Fl bandwidth

69

(70% o f the bottleneck link bandwidth) with flow3, which is another local A Fl flow on the same link. Since flowO is upgraded to A Fl, there is only one AF2 flow, flow3, along the link after the handover of MH5, which gets the whole 20% allocation for AF2 that it was sharing before handover with flowO. Local BE flow remains unaffected in this scenario.
Scenario4(cl-c2)
bindwidlà(9b)
103.0000 flo w 0

100.0000

H ow1
flo w 3 flo w 5 flo w 7

90 .0 0 0 0 83.0000 80.0000 7 3 .0 0 0 0 7 0 .0000 63 .0 0 0 0 60 .0000 55 .0 0 0 0 30 .0 0 0 0

flows

flo w l
4 5 .0000 40 .0000 3 3 .0000 3 0 .0000

- flows
20.0000

10.0000
3 .0000

\ /

flowO

0.0000 |- flo w 7
-3 .0 0 0 0 13.0000 2 0 .0 0 0 0 2 5 .0 0 0 0 3 0 .0 0 0 0 3 3 .0 0 0 0 4 0 .0 0 0 0 4 3 .0 0 0 0 3 0 .0 0 0 0

Figure 4.11 Result of the Service-upgrading Scenario

4.3 Summary
In this chapter, we setup a simulation model of a mobile wireless access network using the network simulator ns-2. The simulation topology consists of correspondent nodes, core router nodes, mobile nodes and three base stations acting as Radio Edge Routers. We used FTP to generate long TCPconnections. We employed MRED buffer management scheme to implement differential treatment for A Fl, AF2 and BE, and selected the MRED parameters such that A Fl gets lower drop precedence than AF2. WRR scheduler is used to schedule different queues and its weights for A Fl, AF2 and BE are selected to create different provisioning scenarios. 70

B ased on the mobile wireless access model, we first simulated three scenarios for the admission control algorithm for handover flows including one over-provisioning scenario and two under provisioning scenarios. Then the forth scenario is given for the service-upgrading algorithm. In the over-provisioning scenario, when the available bandwidth for A F l service is no less than the target rate o f the handover flow, the handover flow can still be marked as A F l. Results show that both the handover flow and existing A F l flows can meet their target rate in this situation and they also share the excess bandw idth for A F l flows. In the under-provisioned scenarios, we first studied the situation when the target rate o f the handover flow is bigger than the available bandwidth for A Fl service class but less than that for AF2 service class. Then the handover flow is remarked as AF2. Results show that existing A Fl flows are well protected and receive the same bandwidth as before handover, while the handover flow can also meet their target rate at the handover time but may suffer worst treatment in congestion due to the lower service level marking. The situation when the target rate o f the handover flow is bigger than both the available bandw idth for A F l and AF2 service class is studied in Scenario 3. To decide whether to remark the handover flow or not, we calculated the penalty for the situation when the handover flow is marked as A F l and when the handover flow is marked as AF2. We also introduce a factor p to the comparison process. Results in Scenario 3a shows that when p = l, we get equal compare for penalty o f the respective situations w hen the handover flow is marked as A F l and when the handover flow is marked as AF2. On the other hand, when p is less than 1, results in Scenario 3B show that more protection is given to existing A Fl flows. In Scenario 4, we simulated the situation when an existing A F l flow ends and releases bandwidth to A F l flows. Then AF2 flows are considered to be upgraded to A F l. Results show that the flow with the highest upgrade priority is upgraded first and release bandwidth to AF2 flows.

71

Chapter 5 Conclusion and Future Work

5.1 Concluding Remarks
Providing feasible dynamic bandwidth management for TCP flows in a DiffServ-capable mobile wireless access network is a challenging problem. This thesis investigates the problem in some level of detail. In this thesis we focus on the issue of admission control for handover flows. We developed an admission control and a bandwidth management algorithm. Our algorithms contribute to a better understanding of the problem, and provide some possible solutions. We validated the feasibility of our algorithms through a set of simulations. In the thesis, we consider a mobile wireless access network where DiffServ is deployed as the QoS solution and Mobile IP as employed as the handover protocol. We also consider two service classes: AFl and BE, where AFl is used to provide qualitative service assurance and BE to provide the best effort service. We first presented a study on the impact of handover on DiffServ flows by simulating a simple scenario. Results show that handover contributes significantly to the service level degradation to the local AFl flows in a cell. Further, separating the handover and local flows can protect the local AFl flows. This provides motivation for our QoS scheme and admission control algorithms. In this thesis we made four contributions to the QoS management in a DiffServ- enabled mobile wireless access network. First, we propose a QoS scheme that protects local flows from losing bandwidth to handover flows by separating the two flows into different service classes. The separation allows graceful degradation of service level of handover flows. Second, we propose an admission control algorithm for handover flows. Third, we propose a service upgrade algorithm to upgrade the service level of handover flows. Fourth, we propose a dynamic bandwidth-provisioning algorithm that allows dynamic adjustment of bandwidth allocations to AF2 and BE flows by adjusting their respective weights configured at the scheduler. We propose AF2 class to be used as a transient class for handover flows. When a handover flow is expected to cause significant degradation to the bandwidth of local AFl flows then it is assigned to AF2 class. The AF2 flows are expected to receive better than best effort service. Our admission control algorithm contributes mechanisms to protect the service level of local flows, at the same time admit handover flows and gracefully downgrade their service when bandwidth provisioning on the 72

bottleneck link to the new cell is not sufficient. A mechanism is also provided to enable the admission control algorithm to make necessary tradeoff between maintaining the service level o f existing flows and adm itting as m uch incoming handover flows as possible. S e m e e level upgrading algorithm provides an important mechanism for dynamic service level adjustment. The load o f each service class, A Fl and AF2, are monitored periodically. W henever load o f A F l deereases up to a point where it can accommodate some AF2 flows, then the AF2 flows are upgraded to A F l. The selection o f handover flows for upgrade is controlled by their upgrade priority. This algorithm tries to mitigate the effect o f handover on the service o f handover flows. W hen a large num ber o f flows handover to AF2 service class or some fat flows move to the new cell, then the risk for AF2 flows to receive lower than BE bandwidth grows. We proposed a dynamie provisioning scheme whereby new weights are computed for AF2 and BE to move bandwidth from BE to AF2. We also provide a mechanism o f returning the bandwidth to BE when the AF2 utilization goes low. W e evaluated the feasibility o f our QoS scheme and algorithm by simulating different handover situations. Our simulation shows that the weight adjustment has an impact on the P factor we introduced to control algorithm is capable o f protecting local flows under variety o f handover situations.

5.2 Future W ork
QoS Provisioning in DiffServ-capable mobile IP networks is a promising area o f research and there are many issues that warrant further investigation. In this thesis we focus on the bandwidth assurance to TCP flows. In fact in our background analysis, we introduced five factors that in some way or another affect the throughput rates achieved by TCP flows o f end users. These factors include Round Trip time, number o f micro flows, size of target rate, packet size and interaction with non-responsible (UDP) flows. Besides target rate that we have studied in this thesis, other factors could be included in future studies would provide better understanding on the bandw idth assurance issues and may improve our algorithms. Concerning different faetors that affect bandwidth assurance issues for TCP flows in DiffServ networks; another related research area is on DiffServ marking sehemes. Besides the simple Token

73

Bucket policy we used in this thesis, some more complicated intelligent marking scheme could be considered in future studies. Related to our research, there are many interesting problems to be explored. For example, in the core network how to discover the bottleneck link. Will bottleneck link change by the frequent moving of mobile nodes? In the access network, the implementation of dynamic bandwidth provisioning scheme requires provisioning protocol. Moreover, the effect of handover on additional QoS parameters such as delay, packet loss rate, etc is also an interesting topic for future studies.

74

References
[1] c . Perkins, "IP M obility Support", RFC 2002, Internet Engineering Task Force, October 1996. [2] R. Koodli, N okia Research center, "Fast Handovers for Mobile Ipv6", Internet Draft, Oct 2004. [3] Bos, L. and Leroy, S. "Toward an ALL-lP-based UMTS System Architecture". IEEE Network, Vol. 15(1), pp.36-45, 2001. [4] S. Blake, et al, "An Architecture for Differentiated Services", RFC 2475, 1998. [5] The UM TS Forum, "3G/UMTS Towards Mobile Broadband and Personal Internet", White Paper, Feb, 2005. [6] L. M cLoughlin, "cdmaOne TM & cdma2000 White Paper", Dec 2000. [7] C. Perkins, "IP M obility Support for Ipv4", RFC 3344, August 2002. [8] D. John, C. Perkins, J. Arkko, "M obility Support in lpv6", RFC 3775, June 2004. [9] V. Jacobson, et al, "An Expedited Forwarding PHB", RFC 2598, 1999. [10] J. Heinanen, et al, "Assured Forwarding PHB Group", RFC 2597, 1999. [11] S. Floyd and V. Jacobson, "Random Early Detection Gateways for Congestion Avoidance", lEEE/A CM Transactions on Networking, Vol. 1(4), pp.397-413, August 1993. [12] M. Goyal, et al, "Effect o f Number o f Drop Precedences in Assured Forwarding", G LO BECO M 99, Rio De Janeiro, December 99. Conference Record / IEEE Global

Telecom m unications Conference, V 1 (B), pp. 188-193, 1999. [13] D. Clark, et al, "Explicit Allocation o f Best-Effort Packet Delivery Service", 1EEE/ACM Transactions on Networking, Vol. 6(4), pp. 362-373, August 1998. [14] Technical Specification from Cisco, "Distributed weighted Random Early Detection", http://www.cisco.com/univercd/cc/td/doc/product/software/iosl 11/ccl 11/wred.pdf. [15] A. Silberschatz and P. galvin, Operating system Concepts. Reading, MA, USA: AddisonW esley, 5* ed., 1998 [16] H. M. Chaskar and U. Madhow, "Fair Scheduling with Tunable Latency: A Round Robin A pproach", lEEE/A CM Transactions on Networking, Vol. 11(4) pp. 592-601, August 2003. [17] John B. Nagle, "On packet Switches with Infinite Storage", IEEE Transactions On Com m unication, Vol. 35(4), pp.435-438, Apr 1987. [18] Technical Specification from Cisco, "Congestion M anagement Overview",

http://www.cisco.com/univercd/cc/td/doc/product/software/ios J2J/] 2 lcgcr/qos_c/gcprt2/qcdcon mg.pdf.

75

[19] R. Liao, et al, "Dynamic Core Provisioning for Quantitative Differentiated Services", lEEE/ACM Transactions on Networking, Vol. 12( 3), pp.429-442, June 2004. [20] S. Tartarelli, A. Banchs, "Random Early Marking; Improving TCP Performance in DiffServ Assured Forwarding", ICC 2002 -IEEE International Conference on Communications, Vol. 25, No. 1, pp. 970-975, April 2002. [21] J. Heinanen, et al, "A Single Rate Three Color Marker", RFC 2697, 1999. [22] J. Heinanen, et al, "A Two Rate Three Color Marker", RFC 2698, 1999. [23] W. Fang, N. Seddigh, "Time Sliding Window Three Color Marker", RFC 2859, 2000. [24] 3G TS 23.107 v5.3.0 (2002-01), "QoS Concept and Architecture", http://www.3gpp.org. [25] R. Feng, J. Song, "Some QoS Issues in 3G Wireless Networks", TENCON'02, Proceedings. 2002 IEEE Region 10 Conference on Computers, Communications, control and Power Engineering. Vol 2, 28-31 pp.724-727, Oct 2002. [26] Y. Cheng and W. Zhuang, "DiffServ Resource Allocation for Fast Handoff in Wireless Mobile Internet", IEEE Communication Magazine, vol. 40(5), pp. 130-136, May 2002. [27] N. Seddigh, B. Nandy, P. Pieda, "Bandwidth Assurance Issues for TCP flows in a Differentiated Services Network", Proceedings of Global Internet symposium, Globlecom 99, Rio De Janeiro, December 1999. http://www.sce.carleton.ca/~nseddigh/publications/globe9806.pdf [28] B. Nandy, N. Seddigh, P. Pieda, "DiffServ's Assured Forwarding PHB: What Assurance does the Customer Have?" in Proceedings of Network and Operating Systems Support for Digital Audio and Video (NOSSDAV)'99, July 1999. http://www.nossdav.org/1999/papers/82-1232701015 .pdf [29] M.Goyal, et al, "Performance Analysis of Assured Forwarding", Internet Draft, Feb 2000 [30] M. Mathis, et al, "The Macroscopic Behavior of the TCP Congestion Avoidance Algorithm", Computer Communication Review, vol. 27(3), pp. 67-82, July 1997. [31] R. Morris, "TCP Behavior with Many Flows", IEEE International Conference on Network Protocols, Atlanta, October 1997, pp. 205-211. [32] UCB/LBNL/VINT. Network Simulator - ns, DiffServ Module. [On -line]. Available: http://www.isi.edu/nsnam/ns.

76


