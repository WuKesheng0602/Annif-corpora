Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2012

Here's Looking At You: Quantification Of Quotidian Exposure To Faces
Nicole A. Sugden
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Psychology Commons Recommended Citation
Sugden, Nicole A., "Here's Looking At You: Quantification Of Quotidian Exposure To Faces" (2012). Theses and dissertations. Paper 1730.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

HERE`S LOOKING AT YOU: QUANTIFICATION OF QUOTIDIAN EXPOSURE TO FACES

by Nicole Andrea Sugden, Bachelor of Arts, Concordia University, 2003

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Arts in the Program of Psychology

Toronto, Ontario, Canada, 2012 © Nicole Andrea Sugden 2012

Quantifying face exposure in infants and adults

AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A THESIS

I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my thesis may be made electronically available to the public.

ii

Quantifying face exposure in infants and adults

Abstract

Here's looking at you: quantification of quotidian exposure to faces. Master of Arts, 2012. Nicole Andrea Sugden. Department of Psychology, Ryerson University. The majority of adults are face experts, excelling at perceiving, recognizing, and discriminating amongst faces. This expertise begins to develop in infancy, but it is currently unclear whether it develops primarily based on extensive experience or on a genetic predisposition. The amount of face experience typically received in infancy and adulthood has not been quantified previously. Through the use of head-mounted cameras, this study describes the exposure to faces received by 1- and 3-monthold infants and adults in their natural environment. Adults see faces significantly less often (13% of the time) than 1- and 3-month-old infants (37% and 38%, respectively). Infants see more female, homogenous-age, own-race, inverted, and emotional faces than adults. They also view more up-close faces than adults, which reflects the different interactions infants and adults have with faces. These results are discussed in terms of the relations between face exposure and the development of expertise.

iii

Quantifying face exposure in infants and adults Acknowledgements Thank you to Margaret Moulson, Ph.D., for being the best supervisor ever. I couldn`t have completed this without your endless patience, helpful guidance, well-timed advice, and wealth of knowledge. Your encouragement helped me through this giant project and all of the little ones along the way. You were great at knowing when and how to rein me in when I was stretching myself too thin and to refocus me on what mattered. Thank you for all of the little things you do, too numerous to list, that have made this such an amazing experience for me. You provide a great role model as a dedicated researcher, amazing supervisor, inspiring teacher, and really nice person. I really don`t know how you do it all! Thank you to Marwan Mohamed-Ali, project lead, for your dedication to this project. It wouldn`t be half of what it is without your willingness to help, guidance for the RA`s, and exacting standards. Thank you to all of the BEE Lab RA`s (in no particular order: Andreea Andrei, Shara Nauth, Olha Chayka, Rafael Baguinan, Nina Arcon, Mary (Lan) Wei, Angelica Rojas, Pavan Bhardwaj, Yumna Gulzar, Nirosini Thanabalasingam, Andrea Kusec, Bessie Orfanakos, and Zoe Kornhauser) for all of your hard work and wonderful coding. Thank you to Gabi (Doris) Haas for helping me through the rough patches. They were fun for neither of us. It`s incredible how strong you are. Thank you Meagan Alkemede, surrogate mother to all lost children, and the rest of the Joe Rockheads kids who helped to keep me sane, grounded, and maybe a little crazy too. Thank you to Preston Sims ­ if you don`t know why then I really can`t tell you. Ask Ragnar, he`s better at explaining things.

iv

Quantifying face exposure in infants and adults

Dedication

To my Dad.

v

Quantifying face exposure in infants and adults Table of Contents

Introduction.......................................................................................................................... 1 Face Perception in Adults.................................................................................... 1 Face Perception in Infants................................................................................... Theories of Face Perception................................................................................ Quantity of Exposure Necessary for Face-Expertise to Develop........................ Using a Head-Mounted Camera to Document First-Person Perspective............ Method.................................................................................................................................. Participants.......................................................................................................... Procedure............................................................................................................. 4 7 15 21 23 23 25

First Appointment.............................................................................. 25 Recording........................................................................................... 26 Infants.............................................................................. 26

Adults............................................................................... 27 Equipment.......................................................................................... 28 Infant Equipment............................................................. 28

Adult Equipment.............................................................. 28 Second Appointment......................................................................... Infant Stimulus................................................................ Infant Face Discrimination Task..................................... vi 29 29 30

Quantifying face exposure in infants and adults Infant Face Discrimination Task Looking Behaviour Coding Procedure................................ Adult Stimuli................................................................... 32 33

Adult Face Discrimination Task...................................... 34 Video Coding Training Procedure....................................................................... 34 Video Coding Procedure..................................................................................... Results................................................................................................................................... Attempts to Record.............................................................................................. Participants` Awake Hours.................................................................................. 37 40 40 40

Attempted Recording Times................................................................................ 40 Attempted Recording Locations.......................................................................... 41

Number of People Present When Recording Attempt Began.............................. 43 Reasons for Ending a Recording Session............................................................ Participants` Feedback on their Experience........................................................ Video Data Reliability......................................................................................... Video Data Results.............................................................................................. 44 44 47 48

Total Recording Time........................................................................ 48 Tests of Statistical Significance......................................................... 52 Number of Faces................................................................................ 53 Number of Not-Real Faces................................................................ Exposure Time to All Faces and to Real Faces................................. vii 56 59

Quantifying face exposure in infants and adults Exposure to Female Faces................................................................. 64

Exposure to Own-Race Faces............................................................ 66 Exposure to Own-Age Faces............................................................. Exposure to Real Faces Viewed with No Other Faces in the Field of View................................................................ Exposure to Real Faces Viewed in Upright, Not-Upright, and Inverted Orientations........................................................ 72 Exposure to Near Faces..................................................................... Exposure to Real Faces where Lips Are Available for Assessment of Smiling............................................................ 78 Exposure to Real Smiling Faces........................................................ 78 Overall Face Exposure....................................................................... 81 Adult Face Discrimination Task.......................................................................... 81 Results............................................................................................... Exploratory Analyses: Correlations Between Task Performance and Face Exposure............................................. 81 Infant Face Discrimination Task......................................................................... Reliability.......................................................................................... Results............................................................................................... Exploratory Analysis: Correlations between Task Performance and Face Exposure............................................. 83 viii 82 82 82 81 76 70 68

Quantifying face exposure in infants and adults Exploratory Analyses: Exposure to Facial Expressions of Emotion Other Than Smiling.................................................. 84

Discussion.............................................................................................................................. 85 Limitations............................................................................................................................ 100 Future Directions................................................................................................................. 109

Conclusions........................................................................................................................... 114 References............................................................................................................................. 116 Appendices............................................................................................................................ 133

ix

Quantifying face exposure in infants and adults List of Tables

Table 1.

Total Video Run Time and Adjusted Video Run Time For All Participants and For All Age Groups............................................ 51

Table 2.

Number of Faces and Number of Real Faces Seen by 1-Month-Olds, 3-Month-Olds, and Adults......................................... 55

Table 3.

Number and Percent of Static, Media, and Animal Faces Seen by by 1-Month-Olds, 3-Month-Olds, and Adults.................................... 58

Table 4.

Time during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Faces of All Types....................................... 61

Table 5.

Time during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces.................................................... 62

x

Quantifying face exposure in infants and adults List of Figures

Figure 1.

Mean Time in Seconds during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces............................................. 63

Figure 2.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Female Faces........................................................... 65

Figure 3.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Own-Race Faces...................................................... 67

Figure 4.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Adult-Age Faces...................................................... 69

Figure 5.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed Real Faces Viewed with No Other Faces in the the Field of View................................................................................ 71

Figure 6.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Inverted and Side-Ways Faces................................ 74

Figure 7.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Inverted Faces.......................................................... 75

Figure 8.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces within 3 Feet of their Own Face.................... 77

Figure 9.

Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Smiling Faces.......................................................... xi 80

Quantifying face exposure in infants and adults List of Appendices

Appendix A. Appendix B. Appendix C. Appendix D. Appendix E. Appendix F. Appendix G. Appendix H. Appendix I. Appendix J. Appendix K. Appendix L. Appendix M. Appendix N. Appendix O. Appendix P. Appendix Q. Appendix R. Appendix S.

Infant Recruitment Materials..................................................................... Adult Recruitment Materials......................................................................

133 135

Infant Consent Form................................................................................... 136 Adult Consent Form................................................................................... Infant First Appointment Questionnaire.................................................... Adult First Appointment Questionnaire..................................................... Privacy Agreement..................................................................................... Infant Interest Cards................................................................................... Adult Interest Cards................................................................................... Infant Pre/Post-Recording Check-List Questionnaire...................................... Adult Pre/Post-Recording Check-List Questionnaire...................................... 141 145 147 149 152 153 154 156

Directions for the Infant Camera................................................................ 158 Directions for the Adult Camera................................................................ FaceGen Face Stimuli Exemplars.............................................................. Coding Guide............................................................................................. Coding Key................................................................................................ Coder Orientation Agenda......................................................................... Coder Confidentiality Agreement.............................................................. Coder Coding History Sheet...................................................................... xii 159 160 161 197 199 201 202

Quantifying face exposure in infants and adults
Introduction

Face Perception in Adults The majority of adults are face experts. It has been estimated that typical adults are able to recognize and individuate thousands of different faces, even faces of people they have never met in person (Morris, 2002). When real faces are present, adults process them automatically, rapidly, and nonconsciously (for review, see Palermo & Rhodes, 2007). When viewing natural scenes, human faces are detected 10 milliseconds more quickly than are whole animals (Rousselet, Mace, & Fabre-Thorpe, 2003). In addition to being very good at recognizing faces present in their visual world, adults can also see` faces in objects or scenes where no face is actually present (e.g., the Ruben Vase, André Martins de Barros' painting of a pile of vegetables that appears to be a man entitled Le Marchand de Quatre Saisons, and inverted two-tone Mooney faces, Kanwisher, Tong, & Nakayama, 1998). Adults excel at recognizing and discriminating between faces of other individuals despite natural changes of context, pose, expression, and lighting (Davies & Milne, 1982). Although some manipulations in combination, such as inversion and blurring of photographs of faces (Collinshaw & Hole, 2000), can disrupt face recognition and identification, the ability to recognize faces is highly resistant to most large experimental manipulations, such as geometric distortion and Gaussian filtering (Hole, George, Eaves, & Rasek, 2002). Adults typically find identification of people from their face alone effortless, however attempts to program a computer to perform the same task have not yet met with comparable success; this is one area in which humans are far superior to machines (for review, see Chellappa, Wilson, & Sirohey, 1995). In adults, face perception, discrimination, and identification abilities are likely at ceiling (Ally et al., 2008). This expert ability is one of the skills maintained into older adulthood, despite age-related declines in visual processes and other cognitive systems (Grady, 2002). That the majority of adults have this

1

Quantifying face exposure in infants and adults
expertise and that it is maintained throughout the adult lifespan speaks to the importance of this expert ability. As early as Darwin, the ability to recognize, discriminate between, and perceive faces has been recognized as an evolutionarily important skill that facilitates social interaction (Darwin, 1972). The face is the source of many important social signals to which people attend and which are used to direct behaviour. Within 100 milliseconds of seeing a face, adults make judgments about a person`s character, such as trustworthiness, competence, aggressiveness, and likability (Willis & Todorov, 2006). They also use information they glean from faces to direct their interactions with others, for example using someone else`s gaze to direct their own attention (Ristic, Friesen, & Kingstone, 2002). Adults use the information provided by a face flexibly. For example, they use context to direct their visual attention to the most informative areas of the face (e.g., watching the eyes when a singer produces an emotional note versus the mouth when the singer is not delivering affective information, Russo, Sandstorm, & Maksimowski, in press). Facial expressions of emotion, in particular, are powerful signals used to convey and understand what someone is feeling. Our ability to recognize positive and negative emotions is at ceiling in adults and nearly at ceiling in 7-year-old children (Kestenbaum & Nelson, 1992). This ability to use the face to recognize emotion has been argued to be very important to the evolution of social species, such as humans. This is likely why it has been so highly conserved within and between social species, as evidenced by the existence of cross-cultural and cross-species universal facial expressions (Ekman & Friesen, 1971; Tanaka, Keifer, & Bukach, 2004; and see Izard, 1994 for review). The importance of the face as a social signal in our evolutionary history led researchers to investigate whether there was a particular brain area or areas dedicated to processing faces. A wealth of research using functional magnetic resonance imaging (fMRI) has now demonstrated that in most adults` brains an area of the fusiform gyrus seems to be dedicated to processing faces. This fusiform face area`

2

Quantifying face exposure in infants and adults
(FFA) is more active in response to human faces as compared to animal heads (Kanwisher, Stanley, & Harris, 1999), inanimate objects such as cars (Gauthier, Skudlarski, Gore, & Anderson, 2000), or inverted faces (Kanwisher et al., 1998). Based on these findings, researchers have proposed that the FFA is tuned uniquely and specifically to canonical views of upright conspecific (human) faces, to the exclusion of other visual stimuli. Event-related potential (ERP) studies have also revealed a face-specific electrical signature in adults called the N170 (Bentin, Allison, Puce, Perez, & McCarthy, 1996) and a comparable face-specific signal in infants (de Haan, Pascalis, & Johnson, 2002). As with the activation of the FFA, the N170 has been found to be modulated by the type of face presented (Scott, Shannon, & Nelson, 2005) and by whether the face is presented in a typical upright orientation or in an inverted orientation (Jacques, D`Arripe, & Rossion, 2007). Together, the physical and electrical brain markers suggest that the brain is organized for face specificity. Details of the action of specific neurons within the FFA are difficult to obtain and ethically impossible to investigate in healthy human adults. Instead, researchers have investigated the neuroarchitecture of the face area of the brain in monkeys. Although monkeys are not able to recognize human faces and human adults are not able to recognize monkey faces, both groups recognize faces of their own species and non-face objects very well (Pascalis & Bachevalier, 1998). Monkeys exhibit face recognition performance that is similar to adults (Lutz, Lockard, Gunderson, & Grant, 1998), suggesting that the monkey and the human systems are behaviourally comparable. These investigations have demonstrated that, similar to the human FFA, monkeys possess a face-specific area in the brain that is differentially responsive to faces (Gross, Bender, & Rocha-Miranda, 1969). In this area, face-specific neurons (i.e., neurons that respond selectively to faces) have been discovered (Gross et al., 1969). Therefore, it is not implausible that there may be face-specific neurons in the typical adult brain which play a role in face expertise.

3

Quantifying face exposure in infants and adults
It is clear that most typically developing adults display behavioural and neural expertise for faces. This expert ability is flexible, robust, and well supported by other cognitive and perceptual systems in adults. Although it may still be developing, this adaptive expertise makes the mechanisms of face processing difficult to disentangle from other abilities in adults (Karmiloff-Smith, 1998). However, not everyone with typical face-processing abilities has years of experience with faces or adult-level expertise. Specifically, infants begin learning about faces from birth but take years to develop comparable expertise to adults. It is still unclear how infants develop face-processing expertise. Examining how infants experience, respond to, and process the faces in their visual world is necessary for an understanding of the way in which adult expert-level face processing develops and what the underlying mechanisms of face expertise may be. Face Perception in Infants From birth, infants are interested in faces. Infants prefer to look at faces compared to other visual stimuli (Macchi Cassia, Simion, & Ulmita, 2001; Johnson, Dziurawiec, Ellis, & Morton, 1991). Once the infant is looking at a visual stimulus, face-like stimuli will hold the infant`s attention for longer than nonface-like stimuli (Mondloch et al., 1999). Infants will also work harder to maintain face-like visual stimuli in their field of view, as compared to non-face-like stimuli. A mere 9 minutes after birth, infants will track a face-like pattern longer than a non-face-like pattern (Goren, Sarty, & Wu, 1975; Johnson et al., 1991). Increasing the face-ness of a visual stimulus correlates positively with increased infant stimulus-directed looking and smiling (Haaf & Bell, 1967). Along with a face preference, newborns show the ability to discriminate between faces. They can even recognize faces across changes in viewpoint (Turati, Bulf, & Simion, 2008). Infants are also quite good at remembering faces after a delay. Threeday-old infants remembered strangers' faces, with which they had been briefly familiarized, after a 15minute delay (Bushnell, 2003). Four-day-old infants remembered strangers` faces seen during a

4

Quantifying face exposure in infants and adults
habituation task after a 2-minute delay (Pascalis & de Schonen, 1994) and their mother`s face after a 5minute delay (Bushnell & Sai, 1987). Beyond a general preference for faces, newborn infants evidence a preference specifically for their mother's face. This preference for mother`s face has been found both if the face is presented in person (Bushnell, 2001; Pascalis, de Schonen, Morton, De Ruelle, & Fabre-Grenet, 1995) and if it is presented by video, suggesting that peripheral cues such as scent are not driving this preference (Walton, Bower, & Bower, 1992). Similar to adults` preference for attractive faces (Langlois et al., 2000), both newborn and 6-month-old infants also prefer to look at attractive faces compared to unattractive faces (Slater, Quinn, Hayes, & Brown, 2000; Langlois, Ritter, Roggman, & Vaughn, 1991, respectively), a preference that persists when external cues such as hair are removed (Bartrip, Morton, & DeSchonen, 2001). Very young infants even show a preference for attractive faces of types to which they have had little or no exposure, such as faces of other races or faces of other infants (Langlois et al., 1991), whereas adults have difficulty even discriminating between faces of these categories (Yovel et al., 2012). Whent tested only minutes after birth, however, newborns do not show a preference for attractive faces, which has led to the suggestion that this preference for attractive faces may be learned quickly in the first minutes and hours of life (Kalakanis & Langlois, 2000). Beyond preference, the face provides infants with an early ability to communicate with their caregiver. Infants use their own facial gestures to communicate -- at birth, infants can imitate facial gestures produced by the first face they have ever seen (Reissland, 1988) and by 6 months infants will stick their tongue out at a person who, 24 hours earlier, had repeatedly stuck their tongue out at the infant (Meltzoff & Moore, 1994). Infants are also sensitive, at birth, to information from others` faces that signal communicative intent. For example, newborns prefer to look at faces with direct eye gaze -- a signal for interaction -- compared to faces with averted eye gaze (Farroni, Csibra, Simion, & Johnson,

5

Quantifying face exposure in infants and adults
2002) or faces with closed eyes (Batki, Baron-Cohen, Wheelwright, Connellan, & Aluwalia, 2002). Later in development, by 6 months of age, infants can follow the eye-gaze of an adult, allowing infant and adult to focus on the same thing (Scaife & Brunner, 1975). This ability to use the face to guide social congress is important for later development of non-verbal synchronized interaction. Early shared looking, or joint attention, is believed to lie at the developmental heart of infants` later social abilities. Researchers have proposed that joint attention supports the development of theory of mind (infants` understanding of others as intentional and independent agents) and concept of self` (Meltzoff & Moore, 1994). How well synchronized these early interactions are can colour the infant`s later development. Infants who show more positive development and more secure attachment are those who benefited from more synchronized (Tronick, 1989) and more responsive and playful interactions (Blehar, Liberman, & Salter Ainsworth, 1977). Infants are also sensitive to facial expressions of emotion, which are clear social signals. Infants can discriminate between certain facial expressions of emotion only a few days after birth (Farroni, Menon, Rigato, & Johnson, 2007). The ability to discriminate positive expressions of emotion, such as happy from surprised (Young-Browne, Rosenfeld, & Horowitz, 1977), seems to precede the ability to discriminate positive from negative emotions, such as happy from sad (de Haan & Nelson, 1998). Infants also seem to prefer looking at certain expressions over others (Ludemann & Nelson, 1988). At 5 and 7 months of age, infants show differential rates of attention and habituation to fearful versus happy faces, attending more and habituating more slowly to fearful faces as compared to happy faces, suggesting some appreciation of the signal value of these expressions (Nelson, Morse, & Leavitt, 1979). (An alternative explanation, however, is that infants do not see faces expressing negative emotions very often, so they do not habituate to them which then leads to the increased attention to the facial expression of fear without any appreciation, on the part of the infant, of the signal value of this expression (Ludemann & Nelson,

6

Quantifying face exposure in infants and adults
1988).) The ability to recognize facial expressions despite changes in intensity and facial identity also develops by 5 to 7 months of age (Nelson et al., 1979; de Haan, 2001). This basic perceptual ability allows infants to use adults` facial expressions of emotion to regulate their own emotional responses (Serrano, Iglesias, & Loeches, 1995) and determine how to behave in novel situations (Pelaez, ViruesOrtega, & Gerwitz, 2012; Klinnert, 1984). It is clear that infants show sophisticated abilities with faces early in life, with some abilities appearing shortly after birth and showing significant development over the first year of life. However, the development of face expertise is protracted, with adult ability not being fully obtained until either childhood (Crookes & McKone, 2009) or adolescence (de Heering, Rossion, & Maurer, 2012). Different theories have been proposed to explain the early emergence of face perception abilities in infants and the course of development of face expertise. Theories of Face Perception The major theories of face perception all recognize that faces are a common feature of our visual world and that we have a large amount of exposure to faces both daily and over the course of a lifetime. Key differences between theories of how expert-level face processing develops are the amount of experience proposed to be necessary for the development of this ability and whether the development of this ability is domain-specific or domain-general. A domain-general mechanism by which face perception develops would be one that is not specific to faces but is shared with other perceptual or cognitive abilities. In contrast, a domain-specific mechanism by which face perception develops would be one that is specific to faces alone (i.e., a face module`) and that operates independently of other perceptual and cognitive abilities developing concurrently with the face-exclusive system. This distinction between domain-specific and domain-general may not be a strict dichotomy. Karmiloff-Smith (1998) has suggested that domain-specificity can arise from a domain-general mechanism, provided that the domain-

7

Quantifying face exposure in infants and adults
general mechanism is domain-relevant. Domain-relevance occurs when the type of input the mechanism receives and type of processing its cellular structure allows makes it ideal for a particular function. The processing done by the mechanism, given the inputs it receives, would thereby lead to the creation of one or more domain-specific mechanism(s) from a single domain-general mechanism (Karmiloff-Smith, 1995). In the face processing literature, the difference between theories of the development of face processing has been framed in terms of whether the theory argues that face processing is special`, quasispecial` or not special` at all. Special` is taken to mean that face processing develops in a way that is independent of experience and that the underlying mechanism are domain-specific. Not special` is taken to mean that face processing is experience-dependent and the underlying mechanism are domain-general. Far from a stark dichotomy, several theories postulate that face processing falls somewhere in-between special` and not special`. What special` and not special` systems imply is also different. If face processing is not special` and develops in a way that is dependent on amount or type of experience received by newborns, then this would suggest a flexible system, tailored to the environment to which the infant is exposed, that learns about the world quickly and early. If, however, face processing is special` and no experience is necessary to develop adult-level face processing, in that it is innate, genetic, and/or present at birth, then this would suggest an inflexible system uninfluenced by type or amount of exposure received to faces, even if later exposure does change the surrounding systems, such as memory or attention. This special` system, however, would be uninfluenced by early visual deprivation or failure to receive adequate exposure to faces early in life. If adult-level face expertise is domain-general and experience-dependent, then this would suggest that faces are not special (even though they become special or important to adults as an informative part of their visual world). If adult-level face expertise is the result of an experience-independent, domain-specific mechanism, then this would imply that faces are

8

Quantifying face exposure in infants and adults
special, in that face perception operates independently of other cognitive and perceptual mechanisms. McKone, Kanwisher, and Duchaine (2006) propose that face processing is special`. Face processing, according to their theory, is a domain-specific and potentially experience-independent ability. They posit that an innate neural template is present in all infants at birth and acts independently of absolute level of exposure to faces to drive the face processing system. The face-exclusive neural template is heritable and genetic (Zhu et al., 2010); it requires either only a minimum level (McKone et al., 2006) or no exposure to faces (McKone, Crookes, & Kanwisher, 2009) to develop adult-level face expertise. It is proposed that the face-template remains permanently tuned to upright species-specific faces, allowing the visual system to develop one system for faces and a separate system to recognize other non-face objects. Other systems may provide different types of support to face-processing tasks, such as memory and cognitive skills, but these operate separately from the independent face-specific processing mechanism. From this perspective, it would be expected that natural exposure would not influence the face processing system and that exposure to faces at any age would not correlate with performance on a face discrimination task. As support for this theoretical perspective, researchers point to the fMRI findings that demonstrate an area of the brain, the fusiform face area`, that responds more strongly to faces than to other objects (Kanwisher, Mcdermott, & Chun, 1997; McKone et al., 2009). Evidence from neuropsychological studies has also provided support for this theoretical perspective. Some patients who have suffered brain damage lose their ability to recognize faces (prosopagnosia) but retain their ability to recognize objects (Farah, Levinson, & Klein, 1995), whereas others lose their ability to recognize objects but retain their ability to recognize faces (for review, see Farah, 1996). The double dissociation of these two systems is evidence in favor of two independent operating systems, one for faces and the other for objects. At the other end of the continuum, Gauthier and Tarr (2002), whose perspective is derived from

9

Quantifying face exposure in infants and adults
their work on object expertise, suggest that face expertise is an entirely experience-driven ability; faces are not special`. They propose that face expertise develops in the same way as any other type of expertise (Tarr & Cheng, 2003). Adult-level face expertise is expected to arise from the sheer volume of daily face exposure received and the type of exposure to faces people accrue over their lifetime. This domain-general theory presumes that the acquisition of face expertise proceeds in a manner similar to the acquisition of other types of object expertise. It may also be possible that face expertise is acquired in a similar way to which language is acquired, through some domain-general fundamental assumptions made by the infant, salient external contextual cues, and domain-general perceptual constraints present in the newborn system (Tarr & Cheng, 2003). This suggests that although faces are not a priori special (i.e., there is no innate basis for face expertise), they become special as humans acquire experience with faces. From this perspective, it would be expected that natural exposure to faces would influence the face processing system and improve performance on face discrimination tasks in a dose-dependent fashion for infants, children, and adults. Researchers draw on behavioural and neurological evidence to support this theoretical perspective. There is evidence from studies of people who have acquired naturally, through their lifetime, expertise with non-face objects and from studies of people who have been trained to expertise on a set of experimentally purpose-built objects (i.e., Greebles). With objects of expertise, such as cars, birds, and Greebles, the type of processing strategies used by non-face-object experts to perform an object discrimination task are the same as the processing strategies they use when processing faces; in contrast, adults without object expertise use a different, less effective, processing strategy when discriminating objects but the same strategy as is used by object-experts when processing faces (Gauthier, Curran, Curby, & Collins, 2003; Gauthier & Tarr, 2002). Neurologically, whereas the activation of the fusiform gyrus in adults without object expertise is greater when viewing faces than when viewing objects, experts show comparable fusiform gyrus activation when viewing both faces and the object of

10

Quantifying face exposure in infants and adults
expertise (Gauthier et al., 2000). The N170 component of ERP recordings, a purported face-sensitive` component, is of the same magnitude when experts are viewing both faces and objects of expertise whereas adults without object-expertise show a larger magnitude N170 for faces than for objects (Tanaka & Curran, 2001). Because it posits a face processing system that is experience-dependent and domaingeneral, this theory leaves open the possibility to describe the type of exposure that would best facilitate the acquisition of adult-level face expertise. Several theories have postulated intermediate viewpoints that lie along the continuum between domain-specific and domain-general as well as between fully-experience-dependent and fully-experienceindependent. These theories can be conceptualized as arguing that faces are quasi-special`. In Morton and Johnson's (1991) CONSPEC/CONLERN theory and in Nelson's (2001)experience-expectant process, early preferences for faces and face-like objects is expected because the infant is tuned to faces through either a domain-specific orienting mechanism or early domain-general visual constraints. In both models, later specialization for faces relies on infants' visual experience with faces. Johnson and colleagues` (Morton & Johnson, 1991; Johnson & Morton, 1991; and Johnson & de Haan, 2001) CONSPEC/CONLERN theory of the development of face processing proposes that there are two separate mechanisms that lead to adult-level face expertise. CONSPEC, a sub-cortical, domainspecific, innate orienting mechanism, responds selectively to species-specific face-like stimuli. This orients newborns to face-like visual stimuli that appear in their visual field to ensure that they receive exposure to faces. CONSPEC does not require any level of initial experience with faces to operate. However, when faces are present, CONSPEC helps to prime the infant face processing system by creating a preference to orient towards faces. Researchers suggest that CONSPEC explains the preferential face tracking seen in newborn infants. CONSPEC also ensures that, if faces appear in the infant`s visual world, infants receive exposure to those faces by directing their attention to them. At about 2 months of

11

Quantifying face exposure in infants and adults
age, a cortical, experience-driven mechanism, CONLERN, engages and CONSPEC gradually disengages. CONLERN eventually replaces CONSPEC. CONLERN benefits from the exposure to faces that was engaged by CONSPEC and this exposure helps to bias CONLERN to the type of faces present in the infant's environment (presumably the faces of conspecifics). Here, experience is needed to tune the face processing system and allow the infant to eventually develop adult-level face expertise. From this perspective, it would be expected that natural exposure would not influence the face processing system before 2 months of age, while CONSPEC is operating, and that exposure to faces before 2 months of age would not correlate with performance on a face discrimination task. It would also be expected that natural exposure would influence the face processing system after 2 months of age, when CONLERN is operating, and that exposure to faces after 2 months of age would correlate positively with performance on a face discrimination task. As theorized, very young infants do orient preferentially to face-like stimuli as if operating with CONSPEC alone (Johnson et al., 1991). They need not, however, spend more time attending to face stimuli once they have oriented to or tracked them (Morton & Johnson, 1991). There is evidence for a shift from sub-cortical system similar to what is described by CONSEPC to a cortical system similar to what is described by CONLERN. The shift in visual preference for more complex, as compared to more simple, for phase-spectrum over amplitude-spectrum, and for positive-contrast over no preference, that occurs between 6 to 10 weeks after birth is consistent with a behavioural and neurological change from a CONSPEC- to a CONLERN-type mechanism (Mondloch et al., 1999). . A second quasi-special` theory of the development of face processing that is both experiencedependent and domain-general is Nelson`s (2001) experience-expectant theory. This posits that the process by which adult-level face expertise develops is similar to that of word learning. In this model, the ability to develop specialized neurological face-areas and behavioural face-expertise requires experience with faces during a specific time in infancy, the sensitive period. During the sensitive period no innate

12

Quantifying face exposure in infants and adults
mechanism is necessary to provide the infant with exposure to faces. Instead, early visual constraints or other domain-general preferences may serve to orient infants towards faces. As experience accrues, the type of experience infants receive with faces results in perceptual narrowing, whereby infants become less able to recognize types of faces with which they have had less experience. From this perspective, it would be expected that natural exposure would not influence the face processing system before then sensitive period and exposure to faces would not correlate with performance on a face discrimination task if the infant was tested before the sensitive period. It would also be expected that natural exposure would influence the face processing system after the sensitive period and that exposure to faces after the sensitive period would correlate positively with performance on a face discrimination task. Moreover, perceptual narrowing would result in improved performance on face discrimination tasks that use the types of faces with which infants have the greatest experience and decreased performance on face discrimination tasks that use faces that are novel to the infant. There is empirical support both for the early and later properties of the developing face processing system proposed by this theory. Simion and colleagues (Simion, Macchi Cassia, Turati, & Valenza, 2001) have elaborated on the visual system constraints that may be driving the preference for faces seen in young infants. They found that very lowlevel domain-general properties of the visual system, such as lower resolution within the upper visual field, can lead to preferential orienting to faces. Additionally, low-level properties of faces (e.g., rounded contour, more objects in the upper versus the lower visual field, symmetry of the internal features) can drive a visual preference when presented outside or within a face-like arrangement. When combined in non-face arrangements, these properties can result in greater infant preference to experimentally constructed visual stimuli than to face-like visual stimuli. There is also strong empirical support for perceptual narrowing both within the face processing and language development literatures (as reviewed by Nelson, 2001). For example, infants younger than 6 months are able to discriminate between faces

13

Quantifying face exposure in infants and adults
from a broad range of categories, including faces of other species, other races, and other ages (Kelly et al., 2007; Pascalis, de Haan, & Nelson, 2002; Langlois et al., 1991). However, by 9 months of age (and continuing into adulthood), infants are no longer able to discriminate faces from the categories with which they have had little experience (for example, other-race and other-species faces; Heron-Delaney et al., 2011 and Pascalis et al., 2005, respectively). A fifth theory of the development of face processing frames the argument differently, in examining external influences on infants` visual worlds. Bushnell`s (1998) sensory-ecology model of the development of face expertise also takes an experience-dependent view of face processing. As compared to the other theories, however, this model goes one step further by specifying the type of exposure that is expected to result in later face expertise. It proposes that the environment into which an infant is born engages the infant in such a way as to bias infant`s attention towards faces through the behaviour of the people (parents and caregivers) in this environment. No innate module or mechanism on the part of the infant is necessary, in this case, to bias the input received by the infant. The caregiver is highly motivated to interact with the infant. The caregiver captures the infant`s attention through multi-modal stimulation, by placing herself and her face into the center of the infant`s field of view, and by providing interactive stimulation. By contingently interacting with the infant, the caregiver is able to focus the infant`s attention and maintain the infant`s attention on herself, the infant`s social partner. The caregiver is also the primary source of need gratification and comfort for the infant, another mechanism by which caregivers can capture and engage their infant`s attention. From this perspective, it would be expected that natural exposure to faces, per se, would not be sufficient to influence the face processing system or to impact face processing abilities. Engaging, social, interactive exposure to faces, however, would influence the face processing system and improve infants` performance on a face discrimination task. There is evidence that infant attention is effectively captured by caregivers, specifically mothers, using multiple modes of

14

Quantifying face exposure in infants and adults
interaction. Mother`s voice is especially preferred and oriented to by very young infants (Hepper, 1991). Mothers also engage in tactile stimulation of their infants, which can influence the infant`s emotional state (Stack & LePage, 1996). By this account, an innate domain-specific face module is not necessary in infants. However, passive experience with faces is not sufficient to develop adult-level face expertise. Instead, social interactions in which faces are the predominant stimulus are the critical experiences necessary for the development of the face processing system. Quantity of Exposure Necessary for Face-Expertise to Develop Distinguishing between these theories of the development of face perception hinges on determining how little or how much experience is necessary to shape adult-level expertise. Many studies have now investigated the role of experience in face processing. Some studies with newborn infants and monkeys suggest that no experience is necessary for at least rudimentary face processing abilities. For example, Turati and colleagues (2008) have shown that newborn infants are able to recognize faces across changes in viewpoint, which is taken to suggest that infants understand that the identity of the face at which they are looking is not changing despite changes in viewing angle. Additionally, Sugita (2008) has shown that monkeys deprived of early face exposure are able to, upon seeing their first face, discriminate between monkey faces and discriminate between human faces. However, there is some evidence that exposure may drive face preference, even in newborn infants. Bushnell (2001) found that time spent by 1- to 2-day-old infants viewing their mother`s face was associated with stronger visual preference for their mother`s face, whereas less time spent looking at mother`s face resulted in a weaker or no preference for their mother`s face over a stranger`s face. This positive correlation suggests an exposure effect on face preference, however it is unclear what aspect of exposure was driving this effect (i.e., was it the quantity, quality, both, or some other aspect of the mother-infant interactions). Several lines of research with atypically-developing infants and children have also documented

15

Quantifying face exposure in infants and adults
effects of exposure on the development of face perception. For example, institutionalized children display abnormal neural correlates of face perception (Parker, Nelson, & The Bucharest Early Intervention Project Core Group, 2005). This suggests that atypical exposure to faces in early development impairs later face processing abilities in institutionalized children. Despite this, the ability to recognize facial expressions of emotion is not impaired at 3.5 years of age in this same population of children (Jeon, Moulson, Fox, Zeanah, & Nelson, 2010). Although exposure matters, certain faceprocessing abilities may be preserved even in conditions of deprivation. Maurer and colleagues have spent years studying the impact of early visual deprivation on later face perception abilities in infants born with congenital cataracts, a condition that effectively blocks patterned visual input until the cataracts are surgically removed. Her studies demonstrate that infants do require visual input to drive the development of their visual system, including the face processing system (Maurer, Lewis, Brent, & Levin, 1999). Specifically, Maurer and colleagues have shown that congenital cataracts disrupt some components of the face processing system (e.g., configural processing, Maurer, Le Grand, & Mondloch, 2002), but not others (e.g., featural processing, Mondloch, Le Grand, & Maurer, 2002). It is unclear why there might be deficiencies in some abilities when other areas are spared. Cataracts do deprive infants of early experience with faces, but they also deprive infants with other patterned visual inputs and it is not yet known how these other visual inputs influence the developing visual system, including face perception. The ability to quantify the amount of exposure to faces an infant receives and correlate that with a measure of face discrimination ability would allow for a better understanding of how much, if any, exposure is necessary to allow for the development of adult level face-expertise. Exposure also influences face processing in typically-developing infants. The ability to discriminate amongst faces of different races, ages, and genders, among typically-developing infants and adults, varies with natural daily experience. The other-race effect, a common experience-dependent

16

Quantifying face exposure in infants and adults
effect, characterizes the fact that adults and older children are better at discriminating amongst faces of their own race (or the race to which they are exposed most frequently) than those of other races (Hayward, Rhodes, & Schwaninger, 2008). Adults, with their decades of experience with a specific range of face types, are more sensitive to changes in own-race faces than other-race faces, despite attending to own-race and other-race faces equally. This suggests that the differential levels of exposure have fostered the development of a very narrow range of learned expertise (Hirose & Hancock, 2007). Adults also experience improved ability to discriminate amongst other-race faces if their daily exposure to faces includes a high proportion of other-race faces (Michel, Caldara, & Rossion, 2006), and short experimental exposure to other-race faces can also reduce the other-race effect in adults (Rhodes, Watson, Jeffery, & Clifford, 2010). In these cases mere exposure was sufficient to qualitatively change the face processing system. The other-race and similar effects have their origins in infancy. Three-month-old infants prefer looking at faces of races to which they have received the most exposure (usually, own-race faces) but younger children do not exhibit this preference, again indicating how a mere 3 months of exposure can change the way in which infants react to faces (Kelly et al., 2005). By 9 months of age, infants have lost the ability to discriminate faces with which they have little experience (e.g., other-race and other-species faces, Heron-Delaney et al., 2011 and Pascalis et al., 2005, respectively). Additional evidence that the other-race effect is purely experience-driven is that adoption studies have found that the bias is towards the race of people to whom children are exposed, which may or may not be own-race faces, per se. Korean infants who were adopted into French homes with White adoptive parents were found to exhibit poorer discrimination of Korean faces than White faces; by comparison, Korean infants who remained in Korea exhibited poorer discrimination of White faces than Korean faces (Sangrigoli, Pallier, Argenti, Ventureya, & de Schonen, 2004).

17

Quantifying face exposure in infants and adults
Exposure-driven face preference has also been found with gender. Infants who have a female primary caregiver show a spontaneous preference for female faces over male faces and prefer to look at female versus male faces even after having been habituated to a female face; however, infants who have a male primary caregiver show the opposite preference (Quinn et al., 2002). Adults and infants have also been found to show an age bias. Adults are most proficient with faces of their own age (Kuefner, Macchi Cassia, Picozzi, & Bricolo, 2008), presumably because these are the faces to which they receive the most exposure. On the other hand, infants are most proficient with faces of their parents' age (Kuefner, Macchi Cassia, Picozzi, & Bricolo, 2006), which is also hypothesized to be exposure-driven. As mentioned previously, Bushnell (2001) also suggests that infants` early preference for their mother`s face is dosedependent, since infants with more exposure to mother`s face during the first hours of life showed stronger preferences for their mother`s face, as compared to infants with less exposure. Natural exposure to faces is not the only way in which face exposure can be manipulated to change an individual's level of expertise. Training studies, in which participants are provided with experimental exposure to types of faces with which they have little or no natural experience, have revealed that infants up to 9 months of age are able to retain their ability to discriminate amongst otherrace and other-species faces (Heron-Delaney et al., 2011; Pascalis et al., 2005, respectively). Expertise and categorization research with adults provides a more nuanced description of the types of exposure needed for expertise to arise for faces as well as for other objects. Expertise with objects is comparable to expertise with faces neurologically and behaviourally, in that objects of expertise can activate the area of the brain which most typically reacts exclusively to faces ­ the fusiform face area` ­ and are processed in the same way as are faces, even when the expertise has been recently and experimentally acquired (Gauthier, Tarr, Anderson, Skudlarski, & Gore, 1999). If face perception is a type of expertise uninfluenced by genetic or neural templates, then it would require the same types of

18

Quantifying face exposure in infants and adults
exposure necessary to drive other types of expert-level abilities (Farrington-Darby & Wilson, 2006). Specifically, individuation of separate exemplars of the category is necessary for the maintenance of infants` ability to discriminate non-human faces (Scott & Monesson, 2009), adults` ability to acquire expertise with man-made novel objects (Gauthier & Tarr, 1997), and adults` ability to process other-age faces (Yovel et al., 2012). It would be expected that the type of exposure which would allow for the development of face-expertise would require individuation of the faces to which an infant is exposed. In terms of object learning, most successful individuation occurs when the object's name is taught while that object is the sole object in the infants' visual field and the focus of the infant`s visual attention (Yu, Smith, & Pereira, 2008a). This suggests that the types of interactions that would be most important to infants, in terms of learning how to discriminate amongst faces, are interactions where the face to be learned is the most prominent object in the visual field. Unfortunately, no research has, of yet, spoken to if or how often this type of opportunity to learn to individuate faces occurs naturally and how the absolute amount of this type of one-on-one face exposure relates to performance on a face discrimination task. This interpretation of the results of training studies and other-race or other-age effect studies, however, has not gone unopposed. McKone et al. (2006) point out that in-lab training and naturalexposure-based learning may not be influencing expertise, per se. They posit that types of exposure received in these cases may simply be tuning non-face-specific neural mechanisms, such as memory or attention, which appear to be influencing the face-processing system but are instead influencing areas downstream from the face-exclusive face processing system. Indeed, they argue that 'all typically developing humans choose to individuate conspecifics based on face' and that this choice is uninfluenced by types or relative quantity of face exposure received (McKone et al., 2006, pp 12). However, it is unclear when and how this choice is made, how this type of face processing system could be experimentally disentangled from its supporting or downstream cognitive systems, and how this theory

19

Quantifying face exposure in infants and adults
could be either experimentally investigated or falsified. Currently the evidence makes it difficult to determine which theory of the development of face processing is most correct or whether an innate or genetic mechanism is required. Research on the amount and type of exposure necessary for the development of expertise has yet to quantify quotidian face exposure or relate it to face discrimination ability, beyond the first few days of life in a hospital. To date, no study has quantified either infants' or adults' normal daily amount of exposure to faces in their natural environment. The current study, through the use of head-mounted cameras, quantifies daily face exposure in early infancy (at 1- and 3-months of age) as well as adulthood and relates these to performance on a face discrimination task. This quantification of exposure to faces provides clarification on how prevalent faces are in an infant and an adult's normal visual environment, what type of faces infants and adults see, and the relative salience of the face in adults` and infants` visual worlds. If faces are not special` and adult-level face perception abilities are a form of generic expertise, it would be expected that faces would be the object to which infants receives the most exposure, thereby driving infants face perception abilities towards expertise. In this case, it is expected that the amount of exposure received to faces would correlate positively with performance on a face discrimination task in both infancy and adulthood. If experience is related to face preference and discrimination abilities, own-race, own-age, upright, and female gender faces should be more common than other-race, other-age, inverted, and male gender faces in infant video but not in adult video, since these are the faces infants are known to best discriminate. If faces are not special` and face processing ability is driven by social interaction, there should be a strong positive correlation between exposure to socially interactive faces and ability on a face discrimination task. It is also expected, from this perspective, that the way in which faces are presented to infants and adults would differ qualitatively, with infants receiving more social interaction than adults. If faces are quasi-special` as theorized by CONSPEC/CONLERN, then faces should still be

20

Quantifying face exposure in infants and adults
very common in the visual world, however exposure to faces should only correlate positively with performance on a face discrimination task after 2 months of age, when CONLERN is engaged. After 2 months of age, the type of faces to which infants are exposed should mirror what is known about infants` face discrimination abilities, as would be expected with Gauthier and Tarr`s experience-driven theory of face processing. If faces are quasi-special` as theorized by the experience-expectant model, then faces should still be very common in the visual world, however exposure to faces should only correlate positively with performance on a face discrimination task after the sensitive period. Infants should also receive less exposure to the types of faces proposed to be impacted by perceptual narrowing, specifically inverted faces, other-race faces, and non-parent-age faces. If faces are special` and an innate or genetic mechanism is driving infants` face processing system, it would be expected that experience would be unrelated to performance on a face discrimination task at any age and that the faces to which infants are exposed would in no way relate to known improvements or declines in infants` face processing abilities of specific face types. Using a Head-Mounted Camera to Document First-Person Perspective There is an emerging trend in the literature to use head cameras to document the participant's perspective. This has been used to document parent-child interaction during play (see Yoshida & Smith, 2008; or Yu, Smith, Christensen, & Pereira, 2007), an infant`s perspective during particular tasks (Aslin, 2009), and adults` perspectives during familiar tasks (Land & Hayhoe, 2001). The child's perspective has been found to be markedly and unexpectedly different from that of adults. For example, when infants and parents engaged in play with novel objects, infants observe the objects with which they are engaged almost exclusively, while their parent retains the child's face in or near the centre of their visual field for nearly the whole interaction (Smith, Yu, & Pereira, 2007). Interestingly, Smith et al. (2007) suggest that since infants' focus is on their hands and not on the faces of their caregivers during these tasks, gaze

21

Quantifying face exposure in infants and adults
direction and other social signals may not be as well attended by children as previously believed. Within 7 minutes of free play with toys, it was found that toddlers spent, on average, less than 6% of their time looking at their mother's face (Yoshida & Smith, 2008). Whereas children focus their attention nearly exclusively on the objects they are manipulating (Smith et al., 2007), adults are predictive in their eye gaze, observing the next step or consequence of their task instead of the task itself (Land & Hayhoe, 2001). From the ongoing research into the world from a child`s perspective, it is evident that the way in which a child experiences the world is vastly different from the way in which an adult does. How the world of an infant may differ from that of a child and that of an adult is unclear and has not yet been documented. Here we provide a first attempt to characterize how 1- and 3-month-old infants experience their world, in particular the faces in their world, and to compare it to the world from an adult`s perspective. It is hypothesized that the quality and the quantity of face exposure received by adults and infants will differ substantially. Reflecting the way in which adults typically interact with infants as compared to with other adults, infants are expected to receive more overall exposure and more happy, upclose, single-face exposure from multiple face orientations and fewer face types than are adults. This broad description of the differences between adults` and infants` visual worlds will provide a starting point for future research into the relevant aspects of face exposure for face experts and those developing face expertise.

22

Quantifying face exposure in infants and adults
Method Participants To allow for a more accurate characterization of how much experience infants and adults have with faces on a daily basis, 24 adults (13 male and 11 females), 18 1-month-olds (7 males and 12 females), and 19 3-month-olds (9 males and 10 females) were recruited through word of mouth, by posters affixed around Ryerson University`s campus in downtown Toronto, Ontario, and through a database of parents who indicated that they were interested in participating in developmental research at Ryerson University. One month and 3 months were chosen as the infant ages of interest because previous research suggested that we were likely to find effects of exposure on face discrimination abilities in early infancy (Bushnell, 2001). Additionally, CONSPEC and other cortically-mediated face mechanisms are predicted to come online at approximately 2 months of age, potentially creating experience-contingent differences in infants` face discrimination skills before and after 2 months (Morton & Johnson, 1991). We chose an adult comparison group for two reasons: 1) to determine if face discrimination and recognition skills are influenced by natural daily exposure even in adulthood; and 2) to compare the visual world of the adult to that of the infant, since the current theories of face perception are based on information obtained from the adult point-of-view. There were no exclusion criteria for infants. Adult participants were required to be able to either not wear eye-glasses or wear contacts safely for 2 hours per day for 6 days. (See Appendix A for recruitment materials for infants and Appendix B for recruitment materials for adults.) Each participant generated a huge amount of data that were coded second-by-second (as described below). Coding training, required before coders were permitted to code participant video, took between 3 weeks and 2 months per coder. Coding participant video was a time-intensive, iterative process, with each video being watched a minimum of three times to code for faces alone and then at least

23

Quantifying face exposure in infants and adults
twice more to code for houses, cars, birds, and environment. Ten experienced coders estimated that the length of time required to code an average video for faces alone to be approximately eight times the length of the video, provided it was not a difficult video. This means that a 5-minute video of medium difficulty took an average of of 40 minutes to code. One of the more difficult videos, which was almost 20 minutes long, took more than 40 hours to code for faces alone. (Since it represents 20 minutes of a participant`s visual world, this video was included in the analysis.) The coding time estimate does not include the time spent to provide feedback for each video (approximately 15 minutes per spot-check with a minimum of one spot-check per video), re-code after receiving spot-check feedback (approximately half the length of time required to code the video originally), enter the data, spot-check the data. This also does not include the time required to code for houses, cars, birds, and the environment in which the video was recorded. To secure a measure of inter-rater reliability, 20% of the videos were coded by a second coder. Due to the time necessary to code participant video, it was not possible to code all of the returned video for the purposes of this thesis. Here we present the results from all of the video coded to date which has been thoroughly spot-checked for coding accuracy and 20% of which has been coded by a second coder for reliability. These data represent a subset of participants--13 participants from each age group. Due to time constraints, not all of the videos from these included participants have been coded. Thus, these data represent a subset of the videos recorded from each of the 13 participants per age group. Here we present results only from this sub-set of 39 participants. The 1-month-old infant participants were on average 37 days old (range: 27-48 days old) at their first appointment and 56 days old (range: 50-61 days old) at their second appointment. One 1-month-old infant participant was provided with the camera before they were 1 month old; however, the parents did not begin recording until after the infant turned 1 month old. There were six males and seven females. Eleven infants were Caucasian, one infant was Asian, and one infant was South Asian. The 3-month-old

24

Quantifying face exposure in infants and adults
infants were on average 98 days old (ranging from 79-118 days old) at their first appointment and 121 days old (ranging from 101-137 days old) at their second appointment. One 3-month-old infant participant was provided with the camera before they were 3 months old; however, the parents did not begin recording until after the infant turned 3 months old. There were eight males and five females in this group. Twelve infants were Caucasian and one infant was South Asian. The adults` mean age was 31 years old (range: 21-37 years). There were seven males and six females. The majority of adult participants (9 adults) were Caucasian. Two adults were Asian, one adult self-identified as Latin/Argentinian, and one adult was South Asian. Procedure First Appointment. All participants attended a brief interview (at Ryerson or in their home), during which the study was explained and the consent form was reviewed (see Appendix C for the consent form for infant participants and Appendix D for the consent form for adult participants). Participants also completed a brief questionnaire, providing their demographics information, information about their normal waking hours, and descriptions of their normal activities (see Appendix E for First Appointment Questionnaire for infant participants and Appendix F for First Appointment Questionnaire for adult participants). The adult participants and infant participants` parents were informed of privacy issues stemming from the use of a hidden video-camera (see Appendix G for privacy discussion agreement for infants and for adults) and given interest cards` that they were to provide to anyone who was interested in, had questions about, or had concerns about the study (see Appendix H for interest cards for infant participants and Appendix I for interest cards for adult participants). Adult participants and infants` parents were instructed to answer honestly if they were asked about the camera or the study. Infants` parents and adult participants were provided with twelve Pre/Post-Recording Check-List Questionnaires` (see Appendix J for infant

25

Quantifying face exposure in infants and adults
participant questionnaire and Appendix K for adult participant questionnaire) where they documented details about where and when filming began and ended each time they recorded video. Additionally, these questionnaires reminded them of potential privacy concerns related to operating an inconspicuous video camera in public and private spaces. Recording. Infants. The operation of the camera and correct placement of the camera on the infant`s head was explained at the first appointment. Parents were provided with an instruction sheet that contained simplified directions on how to use the camera (available in Appendix L). Although the camera`s battery would last for approximately 2 days of normal use, parents were asked to charge the camera overnight to ensure that it would be ready to record each day (a USB-charger was provided for this purpose). If the infant was awake and the parent felt that they would be co-operative, the researcher demonstrated correct camera placement at the first appointment. If necessary, small pieces of foam were attached to the back of the camera to ensure that the camera angle was in line with the infant`s eyes. If the parents felt that the infant would be more comfortable if the camera was attached to a hat or a different headband, this was encouraged. Parents were instructed to place the camera on their infant`s head whenever the infant was awake and alert and they believed that it was an appropriate time to film. Parents were instructed to remove the camera if the infant fell asleep, became fussy, appeared uncomfortable, or the parent decided that it was no longer an opportune time to film. Parents were encouraged to film in different locations and at different times throughout the day. Parents were encouraged to keep the camera for 14 days, after which they would visit Ryerson University with their infant for their second appointment. Parents were encouraged to view the video as it was recorded to ensure that the camera placement was correct and that there were no other issues with the camera. The parents were not given a schedule or times during which recording was required, nor were they given a minimum amount of time during which they must record,

26

Quantifying face exposure in infants and adults
due to the fact that very young infants' schedules are unlikely to accommodate this. Three to 5 days after receiving the camera, participants were contacted to ensure that the camera was operating well, to answer any questions they had, and to schedule a time for their second appointment. If there were issues with the camera, the researcher would visit the participant a second time to replace the camera. If the participant was unsure about when they would like to schedule their second appointment, the researcher would arrange another time at which to call to schedule it. Once the second appointment was scheduled, the researcher sent an email to the parents directing them to Ryerson University`s Brain and Early Experiences Lab (BEE Lab) and confirming their appointment date and time. Adults. At the first appointment the researcher demonstrated the operation of the camera. The participant was then asked to demonstrate the camera operation to the researcher. Adults were provided with an instruction sheet on how to use the camera (see Appendix M), a semi-rigid camera case, the camera charging cable, and a small cloth with which to clean the sunglasses` lenses. Adults were instructed to film at different times throughout the day, depending on their normal schedule and the hour at which they awoke (e.g. on day 1 film 2 hours after wake-up, on day 2 film 6 hours after wake-up, on day 3 film at wake-up, etc.), for 6 days over the course of 2 weeks. They were asked not to film more than once at the same time (i.e., if they had filmed from 3pm ­ 5pm one day, to not film from 3pm ­ 5pm on another day). The participants were required to re-charge the battery of the camera overnight after each recording session to ensure it would be ready for the next day of filming. Three to five days after receiving the camera, participants were contacted to ensure that the camera was operating well, to answer any questions they had, and to schedule a time for them to return the camera. If the participant was unsure about when a convenient time would be to return the camera or if they had not completed all six video recording sessions, the researcher would arrange another time at which to call. This would repeat until they had completed the video recordings and returned the camera.

27

Quantifying face exposure in infants and adults
For various reasons, the adult face discrimination task was not created until partway through collection of the adult video recordings. Therefore, there was a lag of up to 9 months between returning the camera and completing the task (average delay was 4.58 months). Since adults' face discrimination skills have been developed over the course of many years, this slight delay was not expected to influence adults' performance on the face discrimination task used in the current study. Once the participant had arranged a time to complete the task, they were sent an email confirming their appointment and providing directions to Ryerson University`s BEE Lab. Equipment. Infant Equipment. The infant camera was a commercially-available, yellow, round, 4.7 centimeter diameter happy-face with a 16 gigabyte micro SD memory card. The camera clipped to a fuzzy elasticized head-band that the infant participant wore on their head. When properly applied, the aperture of the infant camera was above the bridge of the infant's nose and in-line with their eyebrows. The infant camera was designed to be inconspicuous and comfortable for the participant, to ensure that all interactions captured were as natural as possible. At 29 frames per second, the frame-capturing capacity of the camera exceeds the visual capacity of infants to detect a face (Gelskov & Kouider, 2010), and provided image resolution of 2048x1536 pixels. The camera recorded to .AVI video format. The infant camera recorded video and audio; only the video was used for the current study. Once the parent had returned the video camera, the videos were stripped of the audio files, per ethics board requirements. Any video files that the parent indicated were in any way inappropriate were deleted upon receipt. Adult Equipment. The adult camera was a commercially-available pair of 'spy camera' sunglasses with a 16 gigabyte micro SD memory card. The lens of the camera was embedded in the frame of the glasses and sat over the bridge of the participant's nose, between the two lenses of the sunglasses. The lenses of the glasses were removable. The camera was designed to be inconspicuous and

28

Quantifying face exposure in infants and adults
comfortable for the participant, to ensure that all interactions captured were as natural as possible. The frame-capturing capacity of the camera was 30 frames per second, slightly more than that required for adults to detect a face (Gelskov & Kouider, 2010). The adult camera`s resolution was 640x480 pixels and recorded to .AVI video format. The adult cameras recorded video and audio; however, only the video was used for the current study. Once the adult had returned the video camera, the videos were stripped of the audio files, per ethics board requirements. Any video files that the participant indicated were in any way inappropriate were deleted upon receipt. Second Appointment Infant Stimuli. The stimuli for the habituation task infants completed at their second appointment consisted of four computer-generated Caucasian female faces. The faces were created using 3D graphics software, FaceGen (FaceGen, Singular Inversions Inc., 2011). This software allowed for the random generation of faces while holding age, gender, race, facial symmetry, face orientation, eye-gaze, facial expression, and attractiveness constant. Faces generated by this software have been used in both adult and infant face discrimination studies (i.e., Balas, Westerlund, Hung, & Nelson, 2011; Russell, Sinha, Biederman, & Nederhouser, 2006; Balas & Nelson, 2010) as well as to test biometric facerecognition systems (Orlans, Piszcz, & Chavez, 2003). Since infants respond similarly to live faces and to photographs or drawings of faces and do not need prior exposure to photographic presentations of faces to acquire this ability (Dirks & Gibson, 1977), it was expected that infants would behave as if the life-like computer-generated FaceGen faces were photographs or real faces. The standardization of faces on the dimensions of age, race, gender, attractiveness, orientation, eye-gaze, and symmetry allowed for a more controlled set of stimuli to present to infants. In addition, the faces generated by FaceGen did not contain extraneous accessories (i.e., glasses or jewelry) or non-facial cues (i.e., hair). All faces were White, female, of approximately 25 years old, exhibiting a neutral facial expression, staring straight ahead,

29

Quantifying face exposure in infants and adults
approximately 22 centimeters high, and presented in 1/3 view against a black background. FaceGen faces were presented with face outline and neck visible (for exemplars, see Appendix N). Of the four computer-generated faces, infants saw one as the habituation stimulus and another as the test stimulus. Which faces were selected as habituation and test faces was counter-balanced across all infants. Infant Face Discrimination Task. Upon arrival at Ryerson University for their second visit, the infant and parent were familiarized to the lab environment while the researcher explained the task to the parent. If the parent felt that the infant was ready for the task, they were taken to the testing room. Infants sat on their mother or father`s lap (determined by the parents and based on infants` comfort), approximately 60 centimeters away from a computer screen, in a darkened room. Parents were blindfolded throughout the task to prevent them from influencing their child`s behaviour. Infants were recorded using a Sony Handicam (DCR-HC52) throughout the task, to allow for later off-line coding of infant looking time. Once the infant oriented towards the computer screen, the researcher would begin the infantcontrolled habituation task. The researcher coded infant looking online, during the task, using Habit 1.0 X infant looking-paradigm software (Cohen, Atkinson, & Chaput, 2004). The program was set up to consider an infant as having had looked at the screen if they attended to the screen for 1 second or more and looked away from the screen if their eyes were not fixated on the screen for 1 second or more. The infant could have looked at the stimulus for up to 30 seconds per trial, up to a maximum of 12 trials, during the habituation phase. During the habituation phase of this task, infants saw one stimulus face presented on each trial until either a) the time spent looking at the face averaged across the last three consecutive trials was less than 60% of the time spent looking at the face averaged across the longest three consecutive trials; or b) the infant had completed all 12 trials. Between trials, a bouncing ball was presented to re-orient the infant to the computer screen. Once infant looking reached at or below 60% of

30

Quantifying face exposure in infants and adults
the average of their three longest looks or they had seen all 12 habituation trials, they were deemed to have habituated and were presented with a single novel face, the 'test face'. The test face was presented for 2 trials, up to a maximum of 30 seconds per trial or until the infant looked away from the screen for 1 full second. The faces that served as the habituation and test stimuli were counterbalanced across infants. An infant-controlled procedure was used to minimize the high attrition rates common in studies with very young infant participants and to allow for the infant him or herself to determine his/her own level of exposure to the stimulus (Horowitz, Paden, Bhana, & Self, 1972). The criteria of 1-second look and look-away times were determined to be optimal for this procedure, ensuring infants' continued attention and decreased attrition that can be caused by look-away or looking criteria that are either too short or too long (Colombo & Horowitz, 1985). A more liberal fixation criterion of decrement to 60% of the maximum looking across the three consecutive longest looks was chosen because previous research has found that seeing more trials (which would have happened if we had used a more stringent habituation criterion) may result in greater rates of attrition (Colombo & Horowitz, 1985), a large potential concern for the two infant age groups in the current study. The decision to present a single face during habituation and test trials was based on previous research suggesting that this made the task easier for 1- and 3-month-old infants (Cashon & Cohen, 2003). Presenting infants with more than one face at a time may make the task more difficult for them. Since infants' ability to perform the task is fragile at best, often influenced by external factors, such as time of last feeding (Morales et al., 2000), and internal factors, such as temperament (Spangler et al., 2011), we had expected that this procedure would allow infants the best opportunity to demonstrate their face discrimination abilities. This is also why a single exemplar of the habituation stimulus was shown, instead of varying the view or orientation of the face; very young infants can best show discrimination when the habituation stimulus remains constant (Kagan & Lewis, 1965; Cornell, 1974).

31

Quantifying face exposure in infants and adults
The decision to use a habituation paradigm with renewed looking at 'test' to test infants' face discrimination abilities was based on parametric studies that found that this procedure may be a more sensitive measure of 1-month-old infants' discrimination abilities, as compared to a visual preference test (Maurer & Barrera, 1981). A second consideration in choosing habituation and renewed looking over visual preference was the ability to interpret the results. It has been argued that a visual preference after habituation is more difficult to interpret, since infants can show either novelty or familiarity preference when presented with two faces; renewed interest in looking after habituation is a much clearer indication of discrimination ability (Hershenson, 1964). At any point before or during the task, if the parent felt that the infant was not ready to complete the task for any reason (e.g., sleepy, hungry, fussy, etc.) a break was taken until the infant was ready. If the infant discontinued the task during the habituation or test phase, they were given the opportunity for a break before attempting to re-do the task. In practice, no infants who discontinued during the test phase completed the task. Infants` looking behaviour was recorded throughout the task and then coded offline, frame by frame, at 30 frames per second. Infants were invited back to repeat the task when they were 8 or 9 months old, at which point the same procedure was followed. Data collection for this portion of the study is still underway. Infants` parents received $25 for their participation in the current study following the face discrimination task. Parents and infants also received a DVD copy of the video that their infant had collected during the time they had the camera. Infant Looking Behaviour Coding. While infants completed the habituation task their looking behaviour was coded online by the researcher using Habit 1.0 X (Cohen, Atkinson, & Chaput, 2004). All videos recorded during the infant habituation task were then coded offline, frame-by-frame at 30 frames/second, for infant looking behaviour in order to confirm the online coding. The primary coder,

32

Quantifying face exposure in infants and adults
who coded 100% of the videos, was highly trained, with more than 100 hours of experience with coding infant looking time behaviour for a similar habituation task in the Ryerson University BEE Lab. Additionally, 20% of the infant looking-time videos were coded offline by a second coder, the researcher, to ensure reliability. (For infant looking behaviour coding reliability results see page 82.) Adult Stimuli. The stimuli for the adult tasks consisted of 60 computer-generated faces and 60 real faces. The computer generated faces were created using 3D graphics software, FaceGen (FaceGen, Singular Inversions Inc.). As with the infant stimuli, all faces generated for the task were female faces, approximately 25 years old, exhibiting a neutral facial expression, staring straight ahead, approximately 22 centimeters high, and presented in 1/3 view against a black background (for exemplars, see Appendix P). Unlike the infant stimuli where only Caucasian faces were used, for the adult task there were equal numbers of Black, Caucasian, East Asian, and South Asian faces programmed into the task. FaceGen faces were presented with face outline and neck visible. The real faces were sourced from two publicly-available databases of faces. The Black, East Asian, and Caucasian faces were sourced from the Tarr Lab (stimulus images courtesy of Michael J. Tarr, Center for the Neural Basis of Cognition and Department of Psychology, Carnegie Mellon University,

http://www.tarrlab.org/) and the South Asian faces were sourced from the Indian Face Database
(Amitabha Mukherjee, 2002), both of which were created and freely distributed for research purposes. These real face databases all appeared to contain young adults of both genders; however, neither database provided demographic information for the photographs. As with the FaceGen faces, all faces were standardized to approximately 22 centimeters high. The real faces were cropped at the neck to remove clothing cues. Hair was not removed from the real faces to maintain good external validity. The choice to use both computer-generated faces and real faces for these tasks was made to exploit the major advantages of each type of face and provide a counter-balance to the disadvantages of

33

Quantifying face exposure in infants and adults
each. The FaceGen faces provided a high degree of standardization that is impossible with real faces. The faces generated by FaceGen had no distinguishing characteristics (e.g. scars, beauty marks, or freckles) outside of the face itself and limited amounts of variability within the faces. This made the FaceGen version of the task more difficult, which was another advantage of using the computer-generated faces. By increasing task difficulty it was more likely that there would be variability in the participants' scores on the face discrimination task. Since it was expected that participants would do quite well on the task with real faces, the higher variability and lower level of performance expected within participants' scores on the FaceGen faces would allow for a more nuanced description of their face discrimination abilities. The use of the real faces in addition to the FaceGen faces allowed the task to retain greater external validity with lower standardization of the stimulus set. The faces in the real face databases belong to real people and there is a high amount of variability among the faces in things such as attractiveness, distinctiveness, and symmetry. This natural variability cannot be controlled when using real faces but can be controlled when creating computer-generated faces. This variability, however, also exists when people are discriminating between faces in the real world, making the task that uses real faces more similar to the task participants are asked to perform naturally on a daily basis. Adult Face Discrimination Task. After returning the camera, adults performed two face discrimination tasks, one with real faces and one with computer-generated faces. The tasks were adapted from the prosopagnosia face test used by Farah et al. (1995). Both tasks were programmed in EPrime 2 (Psychology Software Tools Inc., 2011) and used the same script, with the only difference being the types of faces presented. The order in which participants completed the FaceGen and real face tasks was counter-balanced across participants. The faces used as familiar and those that were used as novel were also counter-balanced between participants.

34

Quantifying face exposure in infants and adults
For the first study block, adults studied 12 faces (3 Black, 3 Caucasian, 3 East Asian, and 3 South Asian) randomly selected from the broader pool of stimuli. These faces were presented consecutively for 5 seconds each, with a 1-second break between faces. After this study block, participants were either asked three demographics questions or had their head measured as a minor distraction between studying and task. Adults then completed a memory task consisting of the 12 previously-presented faces and 12 novel faces. The 12 novel faces consisted of 3 Black, 3 Caucasian, 3 East Asian, and 3 South Asian faces randomly selected from the broader stimulus pool. Participants were instructed to decide if each face was familiar (the face was shown in the study block) or new (the face was not shown in the study block). Using a stimulus-response box, they were instructed to press 1` for familiar faces and 4` for novel faces. Participants were asked to respond as quickly and accurately as possible. In a second study phase, participants studied the 12 faces from the first study phase followed by 12 new faces. The 12 new faces were 3 Black, 3 Caucasian, 3 East Asian, and 3 South Asian faces randomly selected from the broader pool of stimuli. Participants saw each face for 5 seconds with a 1second break between faces. After this study phase, adults completed a second memory task consisting of the 12 faces from the first study block, the 12 new faces from the second study block, and 12 or 24 completely novel faces. As before, there were equal numbers of Black, Caucasian, East Asian, and South Asian faces, all of which were randomly selected from the broader pool of stimuli. Participants saw all 36 or 48 faces in random order and were instructed to press 1` for the familiar faces from the first study block, press 2` for the familiar faces from the second study block, and press 4` for the totally new faces. After the participant completed the face discrimination task, they were compensated $25 for their participation. Video Coding Training Procedure Participant videos were coded for: 1) exposure to faces; 2) exposure to common objects to which

35

Quantifying face exposure in infants and adults
faces are compared in the face perception literature (houses, cars, and birds); and 3) for the environment in which the video was filmed. At or prior to their first visit to the BEE Lab, the video coders for this project all received a coding guide that they were required to study (see Appendix O for the Coding Guide), a coding key that they were required to know and use (see Appendix P for the Coding Key), exemplars for proximity values listed in the coding guide and key to reference (see the back of the Coding Guide in Appendix O for a selection of the Proximity Exemplars), and a one hour in-person lab orientation and coding training (see Appendix Q for Orientation Agenda). During this time, the purpose and goals of the project, coding guide, and coding key were reviewed. Each video coder was then provided with three training videos (taken during study piloting) and was instructed to code them in order from shortest to longest. The training videos were 1, 5, and 32 minutes in length. The coding videos ranged from simple (video one), moderate (video two), to difficult (video three), with the intention of building coders` abilities. Coding these training videos took between 15 ­ 34 hours of total coding time. After each training video, the coders were provided with lengthy and exhaustive feedback on their performance on each video and tips on how to improve coding for the next video. If there were major issues with coding during the first and second videos, coders were asked to re-code the first or second video before they proceeded to the third video. Coders were only offered a single opportunity to code the third (32-minute) video. Only coders who reached 85% inter-rater reliability on the third coding video were permitted to proceed to real participant videos. At this point, coders received a further 45- to 60minute training session to re-review the coding guide, key, and objectives, to ensure confidentiality, to remediate areas in which improvement was still needed, and to understand what to do if video was not appropriate or documented illegal behaviour. Coding of participant video was not permitted until this second training was completed. Coders who successfully completed coding training and achieved at least 85% reliability were randomly assigned to one (or more) participant(s) for whom they would code all of

36

Quantifying face exposure in infants and adults
the available video. Once they had completed their first video, they received a third training session of 30-45 minutes to review how to code for houses, cars, birds, and the environment. Coders who did not reach 85% reliability on the third training video were offered a data entry position on the study, provided they showed proficiency with data entry. Once they had completed data entry of a single file, they received training on how to spot check and how to reliability check their data, per the quick data check sheet in the coding guide (in Appendix O). Video Coding Procedure For each video, prior to coding, all coders completed a confidentiality agreement (see Appendix R), wherein they confirmed their understanding of the confidentiality of the video data, and a coding history sheet (see Appendix S), where they tracked the length of time that it took to code each video. During video coding, coders were encouraged to take small breaks regularly throughout to ensure that they did not become over-tired. A minimum of two 5 minute breaks per hour was required and this requirement was specified on the coding history sheet. Coders coded for one type of stimulus at a time. During coding for faces, coders viewed the video at normal speed to assess what the video contained. After this, coders watched the video at a maximum speed of half normal running speed or less to code for faces. A coding speed of one-quarter or one-third normal running speed was suggested as ideal. The coders assigned each face a unique face number that remained with that face throughout the video. The video was coded second-by-second. In addition to coding for the presence of faces, each face was qualified. The gender and type (real or notreal person viewed in-person, static, or on media) of the face were recorded. Age and ethnicity were estimated. (Coders were aware of the age and ethnicity of the adult participants and of the two primary caregivers of the infant.) If the face was not a real live person, then this was further qualified by documenting whether that face was real and live but not human (e.g., a dog`s face), static (e.g., a face in a

37

Quantifying face exposure in infants and adults
photograph or wall decal), or moving (e.g., a face on television or computer), with descriptive notes provided for each not-real face. How the face was being viewed was also coded for the following attributes: 1) dominant view of the face (i.e., the view in which the face spent the most time, whether front, profile, in-between front and profile, or moving); 2) whether the face appeared to be interacting with the participant; 3) the proximity of the face relative to the participant; 4) how many faces were present at the same time as the face; 5) whether the face was inverted, upright, or side-ways; and 6) whether the face was displaying emotion (e.g., smiling). After coding the video for faces, coders then re-watched the video to code for houses, cars, birds, and the environment in which the video was taken. When coding for environment, coders assigned each area in which the participant traveled with an individual number (e.g., a kitchen was area #3); each time the participant entered that area, the area number was recorded. The type of area (house/home, indoor public area, outdoor public area, or other) was noted and a brief description of the area was provided, along with the time at which the participant entered and exited the area. The time of enter/exit of a particular area was defined as the time at which the area encompassed the whole view of the camera. Each coded video was spot-checked at least once for accuracy. If issues were found with the way in which the video was coded, it was returned to the coder, along with detailed feedback about what the issues were, so that the issues could be resolved. After the coder remedied the issues, it was again spotchecked for accuracy. This process was repeated until no more issues were found with the way in which the video was coded. The data entered for each video were also spot-checked for accuracy. If there were small issues, the project lead would remedy them. If there were major issues, the data sheet(s) would be returned to the person who had entered the data to re-enter the data. To ensure that the video coding continued at the levels of reliability evidenced in the training video, 21% of the videos were independently coded by two coders. The coding data for these videos were

38

Quantifying face exposure in infants and adults
assessed for reliability after they had successfully passed through all of the spot-checks for video coding accuracy and data entry accuracy. Coders were unaware when their video was being reliability coded by another coder or whether they were reliability coding for the video of another coder.

39

Quantifying face exposure in infants and adults
Results Attempts to Record Overall, participants completed 295 Pre/Post recording Questionnaires indicating that they had attempted to record video 295 times, with a mean of 7.56 Pre/Post Questionnaires per participant. Onemonth-old infant participants completed a mean of 13.54 questionnaires per participant (range: 0 ­ 110 questionnaires). Three-month-old infant participants completed a mean of 4.85 questionnaires per participant (range: 0-21 questionnaires). Adults completed a mean of 4.31 questionnaires per participant (range 0 ­ 13 questionnaires). Some participants did not return these questionnaires, suggesting that attempts to record were even higher. Unfortunately, not all of these attempts were captured by the camera due to low battery, user error, a full memory card, or other technical difficulty. Participants' Awake Hours At the initial appointment, participants (or their parents) provided estimates of how long they spend awake in an average day and how long they spend asleep in an average night. One-month-old infants had the least amount of time awake in an average day (M=7 hours, range: 3.5 ­ 12 hours), as compared to 3-month-olds (M= 8.76 hours, range: 4.5 ­ 16 hours) and adults (M=16.19 hours, range: 14.5 ­ 18 hours). One-month-olds also spent the least amount of time asleep at night (M=7.12 hours, range: 4 ­ 12 hours), as compared to 3-month-olds (M=9.38 hours, range: 6.5 ­ 13 hours) and adults (M=7.81 hours, range: 6 ­ 9.5 hours). Although adult participants` time awake and asleep summed to 24 hours, infant participants` times awake during the day and times asleep at night did not, due to daytime napping and night-time wakefulness. Attempted Recording Times The time of day (morning, afternoon, evening) at which participants attempted to record was recorded on the Pre/Post questionnaire. For 1-month-old infants, attempts to record occurred more often

40

Quantifying face exposure in infants and adults
in the evening (M=5.04 attempts, range: 0-33 attempts) than in the morning (M=4.54 attempts, range: 042 attempts), or afternoon (M=3.92 attempts, range 0-35 attempts). For 3-month-olds, however, attempts to record occurred roughly equally in the morning, afternoon, and evening (M=1.54 attempts, range: 0-7 attempts; M=1.85 attempts, range: 0-10 attempts; M=1.46 attempts, range: 0-4 attempts, respectively). For adults, attempts to record occurred more often in the afternoon (M=1.85 attempts, range: 0-7 attempts) than in the morning (M=1.54 attempts, range: 0-3 attempts), or evening (M=0.92 attempts, range: 0-3 attempts). Attempted Recording Locations In addition to providing information about when participants attempted to record, the Pre/Post questionnaire also provided a measure of where participants attempted to record. Overwhelmingly, the majority of recordings began at home (228 of the 295 questionnaires range: 0-88 attempts to record at home per participant). Seventeen recordings began in another location not specified (range: 0-7 attempts to record began in another location per participant), 14 in public indoors (range: 0-2 attempts to record began in an indoor public location per participant), 11 at someone else`s home (range: 0-2 attempts to record began at another person`s home per participant), 10 at work or the office (range: 0-2 attempts to record began at work per participant), 3 in class (range: 0-3 attempts to record began in class per participant), and 3 in public outdoors (range: 0-2 attempts to record began outdoors per participant). Overall, participants identified the location in which they chose to begin to record as a usual location` for themselves more often (260 recording attempts) than as an unusual location` (22 recording attempts). As with the overall sample, the 1-month-old participants began the majority of attempts to record at home, with a mean of 10.92 attempts to record at home (range: 0-88 attempts to record beginning at home per participant). The mean attempts to begin to record at other people`s homes (M=0.62 attempts, range: 0-2 attempts), at work or an office (M=0.08 attempts, range: 0-1 attempts), in class (M=0.23

41

Quantifying face exposure in infants and adults
attempts, range: 0-3 attempts), indoor in public (M=0.23 attempts, range: 0-1 attempts), or at another location (M=0.77 attempts, range 0-7 attempts) were all less than 1. No videos began outdoors in public. As might be expected, the majority of 1-month-old recording attempts began at a location at which infants had been previously (a usual location`, M=11.69 attempts, range: 0-94 attempts) and fewer attempts began at locations at which they had not been previously (not a usual location`, M=0.92 attempts, range: 0-6 attempts). The 3-month-old participants were also primarily at home when recording began (M=3.77 attempts per participant, range: 0-18 attempts). No 3-month-old videos began in a class. The balance of the 3-month-old attempts to video-record began infrequently at others` homes (M=0.23 attempts, range: 0-2 attempts), in an office (M=0.08 attempts, range: 0-1 attempts), in public outdoors (M=0.08 attempts, range: 0-1 attempts), in public indoors (M=0.46 attempts, range: 0-2 attempts), or at another location (M=0.23 attempts, range: 0-1 attempts). As in the 1-month-old infants, 3-month-old infants` recordings began more often in usual locations (M=4.23 attempts, range: 0-20 attempts) than in locations that they did not usually attend (M=0.54 attempts, range: 0-2 attempts). Adults showed the largest variability in location at which they began attempts to record, although there were still more attempts to begin recording at home (M=2.85 attempts, range: 0-10 attempts). In order of frequency, the next most popular locations at which recording began were at an office (M=0.62 attempts, range: 0-2 attempts), indoor in public (M=0.38 attempts, range: 0-2 attempts), at another location (M=0.31 attempts, range : 0-2 attempts) and outdoor in public (M=0.15 attempts, range: 0-2 attempts). No adult videos began in class or at someone else`s home. As with infant videos, adults identified the majority of the locations in which they began recording as locations they usually attend (M=4.08, range: 0-13) and few as locations they do not usually attend (M=0.23 attempts, range: 0-1 attempts).

42

Quantifying face exposure in infants and adults
Number of People Present when Recording Attempt Began On the Pre/Post Questionnaire, participants identified how many people were with them personally (i.e., people who were attending the location with them vs. people who were at the location but not with them) when they began recording. Participants also recorded whether they felt there were many or few other people (who were not with them) at the location at which they began recording. Obviously, neither 1- nor 3-month-old infants attempted to record when they were alone. Onemonth-olds recorded most often with two or more people present (M=11.23, range: 0-110) and less often with only one person present (M=1.38, range: 0-5). Three-month-old infants showed the same trend, with recordings occurring most often when two or more people were present (M=3.38, range: 0-11) and less often with only one person present (M=1.38, range: 0-10). Unlike infants, who were not able to record when they were alone, adults did record when they were alone (M=2.00, range: 0-7). Adults also seemed to record less frequently with more people present, recording a mean of 1.77 times (range: 0-5) with one other person present and 0.54 times (range: 0-2) when two or more people were present. As a second measure of how crowded each location was, the Pre/Post questionnaire asked if there were few` or many` people at the location in which recording began. The answer options for this question, few` and many`, were left undefined for participants. Parents were asked to answer based on their perceptions of how busy the location was, and not on a defined range or number of people. The location at which 1-month-old infants` recordings were attempted usually had few other people outside of those with the infant (M=11.46, range: 0-101) as compared to many other people (M=1.54, range: 0-9). Three-month-olds` attempts to record also occurred most often in locations at which there were few other people present (M=3.92, range: 0-19) as compared to locations at which there were many other people present (M=0.92, range: 0-2). As with infants, adults attempted to record most often in locations at which they stated there were few other people present (M=2.92, range: 0-8) as compared to locations at which

43

Quantifying face exposure in infants and adults
they identified there were many other people present (M=1.38, range: 0-5). Reasons for Ending a Recording Session The reasons why participants ended recording were varied and likely reflected the differences in age groups. One-month-old infants ended recording for three reasons only. Either they became sleepy (M=2.46 times per participant, range 0-9 times per participant), became fussy (M=2.23 times per participant, range: 0-6 times per participant), or became hungry (M=0.23 times per participant, range: 0-1 times per participant). Some participants (M=0.36 times per participant, range: 0-1 times per participant) did not indicate why they stopped recording. Three-month-olds also ended recording because they became fussy (M=1.69 times per participant, range: 0-8 times per participant), became sleepy (M=1.23 times per participant, range: 0-6 times per participant), or became hungry (M=0.38 times per participant, range: 0-4 times per participant). As with 1-month-olds, some 3-month-old participants' parents did not indicate why they ended recording (M=0.38 times per participant, range: 0-2 times per participant). Most adults ended recording because the battery on the camera died (M=2.54 times per participant, range: 0-12 times per participant) or because the 2 hours had elapsed (M=1.08 times per participant, range: 0-4 times per participant). A few adults ended recording to sleep (M=0.17 times per participant, range: 0-2 times per participant) or because they were in an inappropriate location (M=0.08 times per participant, range: 0-1 times per participant). Some adult participants did not indicate why they ended recording (M=0.31 times per participant, range: 0-1 times per participant). Participants' Feedback on their Experience After their time with the camera, all participants provided feedback on their experience with the camera by way of a data return questionnaire. The questionnaire asked them about their experience with the camera, their level of comfort with wearing and operating the camera, and their perceptions of the past

44

Quantifying face exposure in infants and adults
two weeks. Most participants said that their time with the camera was about the same as usual (45.7%), some said it was worse than usual (40.0%), and a small proportion said it was better than usual (14.0%). When asked if they would wear or they would have their infant wear the camera again, the majority (77.1%) said that they would. Only 14.3% said that they would not. The balance answered maybe`. Participants did not, however, find the camera straightforward to use. There was nearly an even split between participants who found the camera easy to use (37.1%), so-so` (34.3%), and difficult to use (28.6%). Participants` opinions on the comfort of the camera indicate that the majority of participants felt that the camera was comfortable (35.5%) or so-so` (47.1%), with only a minority (17.6%) who felt that the camera was uncomfortable. The majority of participants who wore the camera said that they felt comfortable wearing the camera in public (61.8%) and 23.5% said it was so-so`. Only 5.9% (2 participants) said they felt uncomfortable wearing it in public. The remainder, 8.8% stayed at home all week. Participants were asked whether they felt or knew that other people knew about the video camera; most participants said that everyone knew (44.1%), often because they told everyone (23.5% of the 44.1%). No participant answered that no one knew about the camera, 17.6% said some people knew, 26.5% said that half of the people they saw knew, and 8.8% said few people knew. The remainder, 2.9%, said that they stayed at home all week. Of the five participants who said that they would not wear the camera again, 3 found it difficult to use, 2 found it uncomfortable to wear, and none said that they felt uncomfortable wearing it in public. For the 1-month-old participants, as with the whole group, the majority of parents (76.9%) said they would have their infant wear the camera again and, for the balance, equal numbers of participants were not sure or would not (8.3% and 8.3%, respectively). Parents of 1-month-old infants did not find the camera difficult to use; half said it was easy to use and half said it was so-so` to use. Regarding comfort, 41.0% of parents of 1-month-olds perceived the camera to be comfortable, 25.0% perceived it as neither

45

Quantifying face exposure in infants and adults
comfortable nor uncomfortable, and 33.5% felt that their infant found it uncomfortable to wear. In public, most parents of 1-month-olds felt comfortable having their infant wear the camera (66.7% of the total who did not record outside of the home and 80% of those who did record outside of the home). Equal numbers of parents answered that they were neither comfortable nor uncomfortable` (8.3% of all parents who did not record outside of the home and 10% of parents who did record outside of the home) and not comfortable` (8.3% of all parents who did not record outside of the home and 10% of parents who did record outside of the home). A minority (16.7%) of parent-infant pairs did not leave the house all week. Half of 1-month-olds` parents told everyone or stated that everyone knew that infant was wearing a camera (33.3% and 16.7%, respectively). Of the remainder, 41.7% of parents said that about half of people knew and 8.3% responded that some people knew about the camera. Most parents of 1-montholds said that their child`s week was the same as usual (50%). Slightly fewer infants had a worse week than usual (41.7%) and only 8.3% had a better week than usual. Three-month-old infants` parents were least likely to reply that they would wear the camera again (72.7% said they would), and most likely to say that they would not (18.2%), with only 9.1% being unsure. Three-month-olds` parents had a more difficult time with the camera than did 1-month-olds` parents, with equal numbers of 3-month-olds` parents reporting the camera was easy to use versus difficult to use (45.5% for both), with 9.1% falling in the middle (so-so`). The majority of 3-month-old infants` parents did not rate the camera as being either comfortable or uncomfortable for their infant (54.5%). Of the remainder, 27.3% said it was comfortable and 18.2% said it was uncomfortable for their infant to wear. No 3-month-old parents felt uncomfortable having their infant wear the camera in public (although 9.1% did not leave the house all week). Most said they were comfortable (63.6% overall and 70% of those who left the house) and a few said that they were neither comfortable nor uncomfortable having their infant wear the camera in public (27.3% overall or 30% of those who left the house). Almost

46

Quantifying face exposure in infants and adults
half (46.2%) of the 3-month-old parents reported everyone knew that their infant was wearing a camera (36.4% said that it was because they told everyone). A minority of parents said that few people knew (9.1%) or that some people knew and some did not (27.3%). Some 3-month-olds stayed at home, so there was no one else to know about the camera (9.1%). Most 3-month-olds` week with the camera was rated as the same as usual (72.7%). The rest, 27.3%, said it was worse than usual. No 3-month-olds` parent reported a better week than usual. Of adults, 75% said that they would wear the camera again and 16.7% said that they would not (8.3% were unsure). Most adults found the camera difficult to use (41.7%) or neither easy nor difficult (41.7%). The rest, 16.7%, reported it was easy to use. Adults tolerated the camera better than infants, with no adult participants finding the camera to be uncomfortable, a little more than one third finding it comfortable (36.4%) and almost two-thirds finding it to be not comfortable or uncomfortable (63.6%). Most adults who wore the camera said they were comfortable wearing it in public (54.5%) and a few were neither comfortable nor uncomfortable wearing it in public (36.4%). A minority (9.1%) said that they were uncomfortable wearing it in public. No adult reported that they told everyone about the camera. Only 27.3% said that everyone knew about it, 18.2% said that some people knew and some did not, 36.4% said half of the people knew about it, and 18.2% said that few people knew they were wearing a camera. Half of the adult participants said that their week was worse than usual (50%), one third (33.3%) said it was better than usual, and 16.7% said it was the same as usual. Video Data: Reliability Twenty-one percent of the videos were randomly selected to be coded by a second coder to evaluate coder accuracy and reliability. Of the videos in which faces were not present, coders were in perfect agreement as to the absence of faces (which suggests that they were not seeing face-like objects as faces and erroneously coding them). Additionally, in instances where there were no static faces, no faces

47

Quantifying face exposure in infants and adults
on media, or no real faces present in the video, or where there were values that cannot be estimated from the types of faces present (e.g., estimating age from toy dolls, or gender from pet animals was considered impossible` in the coding scheme), reliability was again at 100%. These perfect-agreement scores that resulted from either no faces being present, no faces of the type in question being present, or a value that could not be coded, by definition in the coding scheme, were omitted from the following analysis so as to provide a more accurate characterization of the quality of coding when faces of each type were actually present. In instances where there were faces present, inter-rater reliability for the detection of instances of a face within the camera field of view was 77.2% (range across videos: 43-100%). Inter-rater reliability for the detection of times during which a coder believed that there was sufficient face information available (specifically the lips) to detect a smile was 69.0% (range across videos: 15-100%). The reliability for detection of a smile, however, was 79.4% (range across videos: 63-100%). Gender, age, and race had reliability scores of 70.6% (range: 46-98%), 77.2% (range: 11-100%), and 65.8% (range: 1096%). Inter-rater reliability scores for the detection and classification of faces of different types` (real, static, moving on media, or non-human-but-real) was at 84.0% (range: 52-100%). For measures of the way in which the face was presented, inter-rater reliability for view` (front, profile, three-quarter, or moving) was 66.5% (range: 50-86%), for proximity (of the face in question to the participant: within 3 feet or 4+ feet away) was 71.0% (range: 61-100%), for surround (how many faces were present at the same time as the face in question: none, one, or more than one) was 83.5% (range: 53-100%), and for orientation of the face (upright, on the side, or inverted) was 85.2% (range: 65-100%). A measure of interaction (whether the face in question was interacting with the participant) had a reliability of 50.2% (range: 0-78%). Since the inter-rater reliability for the interaction variable was at 50%, it was omitted from further analysis.

48

Quantifying face exposure in infants and adults
Unfortunately, only one of the randomly selected videos had any facial expressions of emotion other than smiling present, and for only a short period of time. The inter-rater reliability for this variable was 100% (coders were in perfect agreement about the presence of this emotion). However, we suggest that coders` accuracy in identifying and recording facial expressions of emotion other than smiling (specifically surprise) could not be fairly evaluated due to the small sample. Video Data Results Total Recording Time. In the videos that have been coded to date for the 39 participants who are included in this dataset, 32.03 hours of video was recorded over the course of 118 participant-days and 176 videos. Of this, 28.42 hours (88.7% of all video) was appropriate for coding, in that coders were certain that the camera was on the head of the participant and the quality of the video allowed coders to determine when/if a face was present. Each participant recorded for approximately three days (M=3.03 days per participant, SD=2.43 days), generating approximately four videos each (M=4.51 videos per participant, SD=3.80 videos). The mean video run time per participant was 49 minutes of video (M=0.82 hours, SD=0.80 hours), with an adjusted total run time of 43 minutes (M=0.73 hours, SD=0.69 hours). One-month-old infants contributed 15.92 hours of video over the course of 57 participant-days generating 94 videos. One-month-old infant participants recorded, on average, for four days each (M=4.38 days, SD=2.33 days) generating seven videos each (M=7.23 videos, SD=2.98 videos), resulting in an average of 1.23 hours of video (M=4409.54 seconds , SD=2840.27 seconds) per participant. Of this time, 12.85 hours was appropriate for coding, with each participant generating approximately one hour of video (M=3557.15 seconds of video, SD=2086.17 seconds). Three-month-old infants contributed 5.90 hours of video over the course of 40 participant-days generating 46 videos. Participants recorded, on average, for three days each (M=3.08 days, SD=2.87 days) generating three videos each (M=3.54 videos, SD=4.12 videos), resulting in an average of 0.45

49

Quantifying face exposure in infants and adults
hours of video (M=1634.38 seconds of video, SD=2156.35 seconds) per participant. Of this time, 5.42 hours was appropriate for coding, with each participant generating approximately 25 minutes (M=1500.85 seconds, SD=1821.31 seconds) of video. Adult participants contributed 10.21 hours of video over the course of 21 participant-days generating 36 videos. Participants recorded, on average, for 1 day each (M=1.62 days, SD=0.96 days) generating two videos each (M=2.77 videos, SD=2.74 videos), resulting in an average of 47 minutes (M=2826.92 seconds, SD=3058.90 seconds) of video per participant. Of this time, 10.16 hours was appropriate for coding, with each participant generating approximately 46 minutes (M=2813.08 seconds, SD=3059.01 seconds) of video.

50

Quantifying face exposure in infants and adults Table 1 Total Video Run Time and Adjusted Video Run Time For All Participants and For All Age Groups

Age Group

Total Video Run Time

Adjusted Video Run Time

All Participants

32.03 hours

28.42 hours

One-Month-Old Participants

15.92 hours

12.85 hours

Three-Month-Old Participants

5.90 hours

5.42 hours

Adult Participants

10.21 hours

10.16 hours

51

Quantifying face exposure in infants and adults
Here forward the analyses will use adjusted run time instead of actual video run time to ensure that these data fairly reflect only the times during which coding was possible. Both adult and infant videos contained several seconds of time during which the parent or participant was placing the camera on their head after having turned it on, adjusting the camera placement, or removing it from their head to turn the camera off. This time was not considered appropriate for coding since the camera was usually pointed away from the participant`s field of view. In addition, there were times when the participant removed the camera to look at confidential information (e.g., Visa card PIN) or to use the restroom, or when the field of view of the camera was occluded by something (e.g., hair, a hand, a toy). Finally, when the camera switched between different lighting conditions, if the change was large then it would take a few seconds for it to readjust to the new lighting condition. Portions of the video that included any of the above were removed from the run time of the video to generate the adjusted run time. Tests of Statistical Significance. Since there were multiple variables to be analyzed, leading to an increased probability of type 1 error, a multivariate analysis of variance was conducted in addition to follow-up univariate analysis of variance. Since the purpose of this research is descriptive, this analysis is expected to protect against type 1 error (Enders, 2003; Yu & Chick, 2009). The multivariate analysis of variance was conducted to determine whether the following variables differed according to group membership: total number of faces seen (per adjusted run time of the video), total amount of overall face exposure time (per adjusted run time of the video), total amount of real face exposure time (per adjusted run time of the video), proportion of real faces seen that are female, proportion of time real faces are viewed in isolation (with no other faces visible), proportion of own-race real faces seen, proportion of own- or parents`-age real faces seen, proportion of upright faces seen, proportion of inverted faces seen, and total amount of real-face smile exposure (per adjusted run time of the videos). Using Pillai`s Trace, there was a significant difference among groups (V=1.25, F(28, 48)=2.84, p=.001). The univariate

52

Quantifying face exposure in infants and adults
analyses of variance described below clarify where these differences lie. Several of the variables reported below violated the assumption of homogeneity of variance. In these cases, the results of Levene's test are reported and the test reported does not assume equal variances. Levene's tests are not reported where the assumption of homogeneity of variance was not violated by the data. Upon examination of the skewness, kurtosis, and homogeneity of variance for the variables of interest, it was determined that most variables violated the assumptions of parametric tests. Although the most robust of the multivariate analysis of variance tests was used, Pillai's Trace, it was still possible that the violations of the assumptions of the test could have led to spurious results. Accordingly, in addition to parametric tests, non-parametric tests were used; specifically, Kruskal-Wallis tests were used to probe differences between the groups and Mann Whitney tests were used to probe significant Kruskal-Wallis tests. Results from the parametric and the non-parametric tests are reported. Number of Faces. Participants saw a face appear in the field of view of the camera 10797 times, total across all participants. Within these videos, there were 2535 faces seen (a sum of the total number of individual faces seen across videos), with an average of 65 faces per participant (M=65.00, SD=123.10) and 19 faces per video (M=19.44 faces, SD=35.64). Participants had a face appear in the camera field of view a mean of 276 times (M=276.85, SD=355.35) and each video had a face appear in the field of view 81 times (M=81.92, SD=121.50). There were 595 real faces seen in total (a sum of the total number of individual real faces seen across videos). Within the 1-month-old infant videos, there were 1437 faces seen (a sum of the total individual faces seen per video), with an average of 110 faces per participant (M=110.54 faces, SD=141.72 faces) and 19 faces per video (M=19.48 faces, SD=32.98 faces). There were 416 real faces seen in total (a sum of the total individual real faces seen per video), with an average of approximately 32 real faces per participant (M=32.00 faces, SD=47.71 faces) and 4 real faces per video (M=4.51 faces, SD=6.95 faces).

53

Quantifying face exposure in infants and adults
Within the 3-month-old infant videos, there were 238 faces seen, with an average of 18 faces per participant (M=18.31, SD=21.07) and 7 faces per video (M=7.16 faces, SD=7.36). There were 81 real faces seen in total (a sum of the total individual real faces seen per video), with an average of approximately 6 real faces per participant (M=6.23, SD=5.57) and approximately 2 or 3 real faces per video (M=2.52, SD=2.56). Within the adult participant videos, there were 860 faces seen (a sum of the total individual faces seen per video), with an average of 66 faces per participant (M=66.15, SD=151.14) and 31 faces per video (M=31.69 faces, SD=50.55). There were 98 real faces seen, with an average of approximately 7 real faces per participant (M=7.54 faces, SD=7.43). Differential exposure to faces was probed with a one-way ANOVA examining the number of faces seen per participant, adjusted for run time. There was no significant difference in number of faces seen by these groups (F(2, 36)=1.59, p=.218). Transformed into mean ranks, exposure to a greater number of faces seemed to occur in the adult sample of videos, with mean ranks of: 1-month-olds` mean rank: 21.81, 3-month-olds` mean rank: 15.35, adults` mean rank: 22.85, although these differences were not significant according to a Kruskal Wallis test (H(2)=3.30, p=.195).

54

Quantifying face exposure in infants and adults

Table 2 Number of Faces and Number of Real Faces Seen by 1-Month-Olds, 3-Month-Olds, and Adults

Age Group

Total Faces

Mean Number of Faces Per Participant

Total Real Faces

Percent Real Faces

Mean Number of Real Faces Per Participant

All Participants

2535 faces

65.00 (SD=123.10)

595 faces

23.47%

15.26 (SD=29.84)

One-MonthOld Participants

1437 faces

110.54 (SD=141.72)

416 faces

28.94%

32.00 (SD=47.71)

ThreeMonth-Old Participants Adult Participants

238 faces

18.31 (SD=21.07)

81 faces

34.03%

6.23 (SD=5.57)

860 faces

66.15 (SD=151.14)

98 faces

11.39%

7.54 (SD=7.43)

55

Quantifying face exposure in infants and adults

Number of Not-Real Faces. Of the total number of faces seen by all participants (2535), 1940 faces were not-real faces. Of the not-real faces viewed, 1174 were static faces, 656 were faces viewed moving on media (e.g. television or computer), and 16 were animal faces viewed in person. Of the total number of faces seen by 1-month-old infants (1437), 1021 faces were not-real faces. Of the not-real faces viewed, 837 were static faces, averaging 64 (M=64.38 faces, SD=124.90 faces) static faces per participant over all videos. Of the remaining not-real faces, 1-month-old participants experienced 177 media faces across all participants and all videos and an average of 13 moving face shown on media per participant (M=13.62 faces, SD=29.92 faces) and 84 appearances of media faces per participant (M=84.69 faces, SD=215.29 faces). Seven faces captured by 1-month-olds were with animal faces viewed in person, with an average of less than 1 animal face captured per participant (M=0.54 faces, SD=0.97 faces). Of the total number of faces seen by 3-month-old infants (238), 157 faces were not-real faces. Of the not-real faces viewed, 105 were static faces, averaging 8 (M=8.85 faces, SD=13.77 faces) static faces per participant over all videos. Of the remaining not-real faces, 3-month-old participants experienced 45 media faces across all participants and all videos and an average of 3 moving face shown on media per participant (M=3.46 faces, SD=8.84 faces). Seven faces captured by 3-month-olds were with animal faces viewed in person, with an average of less than 1 animal face captured per participant (M=0.54 faces, SD=0.98 faces). Of the total number of faces seen by adults (860), 761 faces were not-real faces. Of the not-real faces viewed, 232 were static faces, averaging 17 (M=17.85 faces, SD=18.93 faces) static faces per participant over all videos. Of the remaining not-real faces, adult participants experienced 527 media faces across all participants and all videos and an average of 40 moving face shown on media per

56

Quantifying face exposure in infants and adults
participant (M=40.54 faces, SD=140.19 faces). Two faces captured by adults were animal faces viewed in person, with an average of less than 1 animal face captured per participant (M=0.69 faces, SD=2.21 faces). This was not tested statistically as this describes the complement of the above-described number of real faces per video above.

57

Quantifying face exposure in infants and adults Table 3 Number and Percent of Static, Media, and Animal Faces Seen by 1-Month-Olds, 3-Month-Olds, and Adults

Age Group

Total Not-Real Faces
1939

Percent Static Faces

Percent Media Faces 33.83% (656 faces)

Percent Animal Faces

All Participants

faces

60.55% (1174 faces)

0.83% (16 faces) 0.69% (7 faces)

One-Month-Old Participants

1021 faces

81.98% (837 faces)

8.23% (84 faces)

Three-Month-Old Participants

157 faces

66.88% (105 faces)

28.66% (45 faces)

4.46% (7 faces)

Adult Participants

761 faces

30.49% (232 faces)

69.25% (527 faces)

0.26% (2 faces)

58

Quantifying face exposure in infants and adults
Exposure Time to All Faces and to Real Faces. Within the 28.42 hours of video, 7.35 hours (M=678.74 seconds per participant, SD=881.55 seconds) of video contained faces of any type, and only 5.12 hours (M=472.74 seconds per participant, SD=707.03 seconds) of video contained real, human, inperson faces. Of the remaining time, 21.07 hours contained no faces of any type and 23.30 hours contained no real faces. In the 1-month-old infant group, the total amount of video that contained faces of any type was 4.52 hours, with each participant having faces in their field of view for approximately 21 minutes (M=1250.77 seconds, SD=1012.74 seconds). The total amount of 1-month-old infant participant video that contained real faces was 3.09 hours, with each participant having real faces in their field of view for approximately 14 minutes (M=857 seconds, SD=742.48 seconds). The total amount 3-month-old participants' of video that contained faces of any type was 1.82 hours, with each participant having faces in their field of view for approximately eight minutes (M=502.62 seconds, SD=846.72 seconds). The total amount of 3-month-old infant participant video that contained real faces was 1.51 hours, with each participant having real faces in their field of view for approximately 7 minutes (M=416.92 seconds, SD=838.14 seconds). The total amount of adult video that contained faces of any type was 1.02 hours, with each participant having faces in their field of view for approximately four minutes (M=282.85 seconds, SD=400.56 seconds). The total amount of adult participant video that contained real faces was approximately 31 minutes (1876 seconds), with each participant having real faces in their field of view for approximately two minutes (M=144.31 seconds, SD=221.45 seconds). Differential exposure to faces was probed with a one-way ANOVA examining the percent time spent with faces in the field of view over the adjusted total video run time. There was a significant difference in exposure to faces received by these groups (F(2, 36)=5.38, p=.009). The effect sizes for this

59

Quantifying face exposure in infants and adults
were
2

=0.23 and r=.48, indicating a medium effect size (Field, 2009). Levene`s test for homogeneity of

variance was significant (F(2, 36)=5.97, p=.006), indicating unequal variances among the groups. Accordingly, a Games-Howell post-hoc test was carried out to investigate the differences between the groups. One-month-olds` and 3-month-olds` exposure to faces were not significantly different (with a mean difference of .01, SE=.10, p=.990); however, adults` exposure to faces was significantly different from 1-month-olds (with a mean difference of -.24, SE=.06, p=.002) and 3-month-olds (with a mean difference of -.25, SE=.09, p=.041). Adults received less exposure to faces than did either 1- or 3-monthold infants. Transformed into mean ranks, infants still had greater exposure to faces (1-month-olds` mean rank: 26.04, 3-month-olds` mean rank: 22.54, adults` mean rank: 11.42), the differences between which a Kruskal Wallis test found to be significant (H(2)=11.65, p=.003). A Mann-Whitney test comparing infants (Mean rank: 24.29) to adults (Mean rank: 11.42) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to faces (U=57.50, r=.53, exact significance p<.001). This is a large effect size. Differential exposure to real faces in the field of view over the adjusted video run time was also examined using a one-way analysis of variance. There was not a significant difference in exposure to faces received by these groups (F(2, 36)=1.63, p=.210). The effect sizes for this, however, were
2

=0.08

and r=.29, indicating a small effect size (Field, 2009). Transformed into mean ranks, infants had greater exposure to real faces (1-month-olds` mean rank: 24.73, 3-month-olds` mean rank: 23.31, adults` mean rank: 11.96), the differences between which a Kruskal Wallis test found to be significant ( H(3)=9.80, p=.006). A Mann-Whitney test comparing infants (Mean rank: 24.02) to adults (Mean rank: 11.96) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to real faces (U=64.50, r=.59, exact significance p=.001).

60

Quantifying face exposure in infants and adults Table 4 Time during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Faces of All Types

Age Group

Total Time with Faces

Mean Time with Faces

Standard Deviation

All Participants

7.35 hours

11.31 minutes

14.69 minutes

One-Month-Old Participants

4.52 hours

20.85 minutes

16.88 minutes

Three-Month-Old Participants

1.82 hours

8.38 minutes

5.78 minutes

Adult Participants

1.02 hours

4.71 minutes

6.68 minutes

61

Quantifying face exposure in infants and adults Table 5 Time during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces

Age Group

Total Time with Real Faces
5.12 hours

Mean Time with Real Faces

Standard Deviation

All Participants

7.88 minutes

11.78 minutes

One-Month-Old Participants

3.09 hours

13.95 minutes

12.37 minutes

Three-Month-Old Participants

1.51 hours

6.95 minutes

13.97 minutes

Adult Participants

0.52 hours

2.41 minutes

3.69 minutes

62

Quantifying face exposure in infants and adults Figure 1 Mean Time in Seconds during which 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces

Time in Seconds

One-Month-Olds

Three-Month-Olds

Adults

Note. Error bars represent standard deviations

63

Quantifying face exposure in infants and adults
Exposure to Female Faces. Female faces constituted the majority of real faces in the videos for all participants, with female faces representing 59% of all real faces seen (M=58.51, SD=25.43). Since all infants had a female primary caregiver, 1-month-old infants were exposed to more female faces than male faces, with 60% of all gendered faces being female faces (M=60.55 percent faces, SD=18.24 percent faces). As with the 1-month-old infants, 3-month-old infants who participated in the current study had female primary caregivers and exposure to female faces was higher than that to male faces, with female faces representing 73% of gendered face exposure for this age group (M=73.63 percent faces, SD=19.86 percent faces). Unlike infants, adult participants were exposed to more male faces than to female faces, with female faces representing only 40% of faces experienced (M=39.93, SD=27.02). Adults` exposure to female faces was tested against a chance level of 50%, and was not significantly different from chance (t(11)=-1.29, p=.223). Infants were exposed to significantly more female faces than were adults (F(2, 35)=7.49, p=.002). This was a large effect ( 2=.30, r=.55). Planned contrasts found infants` exposure was significantly different than adults` exposure (t(35),=3.56, p=.001), but 1-month-olds` exposure was not significantly different than 3-month-olds` exposure (t(35)=1.52, p=.136). It seems, then, that whereas adults received equal exposure to males and females, infants received most exposure to females. Transformed into mean ranks, infants still had greater exposure to female faces (1-month-olds` mean rank: 21.38, 3-month-olds` mean rank: 27.15, adults` mean rank: 11.46), the differences between which a Kruskal Wallis test found to be significant (H(2)=12.60, p=.001). A Mann-Whitney test comparing infants (Mean rank: 24.27) to adults (Mean rank: 11.46) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to faces (U=58.00, r=.53, exact significance p<.001). This is a large effect.

64

Quantifying face exposure in infants and adults Figure 2 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Female Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

65

Quantifying face exposure in infants and adults
Exposure to Own-Race Faces. The participants in the current study were primarily exposed to real faces of their own race, with 84% of all faces in all videos being own-race faces (M=83.73%, SD=30.47) and only 16% of faces being of other races (M=16.27%, SD=30.47.) One-month-old infants were primarily exposed to faces of their own race, with 96% of faces experienced being own-race faces (M=96.76%, SD=5.46). Three-month-old infants were overwhelmingly exposed to faces of their own race, with 93% of faces experienced being own-race faces (M=93.16%, SD=13.98). Adult participants were mostly exposed to faces of their own race, with 61% of faces experienced being own-race faces (M=61.28%, SD=43.46). The difference in own-race face exposures between groups probed with a one-way ANOVA and was found to be statistically significantly different (F(2, 36)=7.04, p=.003), representing a large effect (
2

=.28, r=.53). A planned contrast confirmed that this effect was due to infants` exposure to own-race

faces being significantly higher than adults` exposure to own-race faces (t(12.72)=2.75, p=.017, with equal variances not assumed due to a significant Levene`s test (F(2, 36)=31.79, p<.001)). Transformed into mean ranks, infants still had greater exposure to own-race faces (1-month-olds` mean rank: 22.81, 3month-olds` mean rank: 23.15, adults` mean rank: 14.04), the differences between which a Kruskal Wallis test found to be significant (H(2)=6.96, p=.031). A Mann-Whitney test comparing infants (Mean rank: 22.98) to adults (Mean rank: 14.04) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to faces (U=91.50, r=.42, exact significance p=.007).

66

Quantifying face exposure in infants and adults Figure 3 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Own-Race Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

67

Quantifying face exposure in infants and adults
Exposure to Adult-Age Faces. The majority of real faces to which participants were exposed were of their own age group (for adults) or their parents` age group (for infants), with 71% of faces being of own- or parents`-age (M=70.91%, SD=33.43). The overwhelming majority of real faces to which 1month-old infants were exposed were of their parents` age, with 82% of faces being parents`-age faces (M=82.25%, SD=17.94). Most real faces viewed by 3-month-olds were faces of their parents` age group, representing 74% of all real faces viewed (M=74.13, SD=30.55). Slightly more than half, 56%, of all real faces viewed by adults were faces of their own age group (M=56.37%, SD=43.64). The difference in exposure to own- or parents`-age-group between groups of participants was compared with a one-way analysis of variance. Although there did appear to be substantive differences between the means of the three groups, these differences did not reach statistical significance ( F(2, 36)=2.16, p=.130), despite a medium effect size ( 2=.11, r=.33). Transformed into mean ranks, infants still had greater exposure to own/parents`-age faces (1-month-olds` mean rank: 22.04, 3-month-olds` mean rank: 21.31, adults` mean rank: 16.65), however the differences between age groups, probed with a Kruskal Wallis test, was not statistically significant (H(2)=1.73, p=.431).

68

Quantifying face exposure in infants and adults Figure 4 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Adult-Age Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

69

Quantifying face exposure in infants and adults

Exposure to Faces Viewed with No Other Faces in the Field of View. Slightly more than half of all faces were viewed alone, with no other faces surrounding them in the camera's field of view (M=55.74%, SD=30.77). For the 1-month-old infants, 59% of faces were viewed alone, with no other faces also in the field of view (M=59.03, SD=24.15). An overwhelming majority, 72% (M=72.59%, SD=30.38) of faces viewed by 3-month-old infants were viewed alone, with no other faces present in the field of view. The majority of faces adults viewed had another face present in the field of view, with only 35% (M=35.59%, SD=27.08) being viewed with no other faces present in the field of view. Whether exposure to single faces with no other faces in view was significantly different between the age groups was probed with a one-way analysis of variance. There was a statistically significant difference between the age groups (F(2, 36)=6.10, p=.005), which constitutes a large effect ( 2=.25, r=.50). There was a significant difference, as probed with a planned contrast between infants and adults, was between infants` and adults` exposure to faces viewed in isolation, with infants being exposed to significantly more faces in isolation and adults seeing fewer faces on their own (t(36)=3.26, p=.002). There was no significant difference between the 1- and 3-month-old infants (t(36)=-1.27, p=.214). Transformed into mean ranks, infants still had greater exposure to faces viewed alone, with no other faces in the field of view (1-month-olds` mean rank: 20.96, 3-month-olds` mean rank: 26.31, adults` mean rank: 12.73), the differences between which a Kruskal Wallis test found to be significant (H(2)=9.36, p=.001). A Mann-Whitney test comparing infants (Mean rank: 23.63) to adults (Mean rank: 12.73) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to faces (U=74.50, r=.45, exact significance p=.005)

70

Quantifying face exposure in infants and adults Figure 5 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces Viewed with No Other Faces in the Field of View

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

71

Quantifying face exposure in infants and adults
Exposure to Real Faces Viewed in Upright, Not-Upright, and Inverted Orientations. As would be expected, very few real faces viewed by participants were not upright; side-ways or upsidedown faces represented only 12% (M=11.82%, SD=18.55) of all faces seen. On their own, upside-down faces represented only 6% of all viewed real faces (M=6.00%, SD=12.93). Although most real faces viewed by 1-month-old infant participants were upright, 19% of faces (M=19.09%, SD=22.47) were either upside-down or side-ways. Upside-down faces alone represented 8% (M=8.52%, SD=17.97) of the non-upright faces viewed by 1-month-old infants. Eleven percent (M=11.53, SD=14.54) of all real faces viewed by three-month-old infants were not upright (they were side-ways or upside-down) and of these only 6% were fully upside-down (M=6.37%, SD=8.08). Relative to infants, adults saw the fewest exemplars of upside-down or side-ways faces, as these represented only 5% of the real faces they experienced (M=4.83%, SD=16.20) and more than half of these 3% (M=3.10%, SD=11.19) were fully upside-down. The exposure to not-upright faces across all age groups was not significantly different (F(2, 36)=2.03, p=.146,
2 2

=.10, r=.32) and neither was exposure to inverted faces (F(2, 36)=0.57, p=.573,

=.03, r=.17) despite the medium effect size found for exposure to non-inverted faces. Transformed into

mean ranks, infants still had greater exposure to all non-upright faces (1-month-olds` mean rank: 25.96, 3month-olds` mean rank: 21.92, adults` mean rank: 12.12) and inverted faces (1-month-olds` mean rank: 24.15, 3-month-olds` mean rank: 23.27, adults` mean rank: 12.58), the differences between which a Kruskal Wallis test found to be significant (H(2)=11.06, p=.003 and H(2)=9.59, p=.005, respectively). Mann-Whitney test for all non-upright faces and inverted faces alone, comparing infants (Mean rank: 23.94 and 23.71, respectively) to adults (Mean rank: 12.12 and 12.58, respectively) were used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to non-upright faces (U=66.50, r=.51, exact significance p=.001) and inverted faces (U=72.50, r=.49, exact

72

Quantifying face exposure in infants and adults
significance p=.002). These represent large and medium effects, respectively.

73

Quantifying face exposure in infants and adults Figure 6 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Not-Upright Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

74

Quantifying face exposure in infants and adults Figure 7 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Inverted Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

75

Quantifying face exposure in infants and adults
Exposure to Near Faces. Overall, 58% of all real faces viewed by the participants (M=58.12%, SD=38.11) came within 3 feet of the participant. Faces came within 3 feet of 1-month-old infant participants 75% of the time (M=74.67, SD=26.48). Faces came within 3 feet of 3-month-old infant participants 67% of the time (M=67.48, SD=36.20). Faces came within 3 feet of adult participants 32% of the time (M=32.21, SD=38.31). A one-way analysis of variance was run to determine if adults and infants were exposed, in the videos, to differential amounts of near faces. Exposure to real near faces was significantly different ( F(2, 36)=5.79, p=.007,
2

=.24, r=.49). Planned contrasts found that there was a significant difference between

infants` and adults` exposure to near faces (t(36)=3.36, p=.002), with infants being exposed to more near faces than are adults. One- and 3-month-old infants` exposure to near faces was not significantly different (t(36)=0.54, p=.594). Transformed into mean ranks, infants still had greater exposure to near faces (1month-olds` mean rank: 26.27, 3-month-olds` mean rank: 23.31, adults` mean rank: 10.42), the differences between which a Kruskal Wallis test found to be significant (H(2)=14.28, p=.001). A Mann-Whitney test comparing infants (Mean rank: 24.79) to adults (Mean rank: 10.42) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to faces (U=44.50, r=.60, exact significance p<.001.).

76

Quantifying face exposure in infants and adults Figure 8 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Faces within 3 Feet of their Own Face

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

77

Quantifying face exposure in infants and adults
Exposure to Real Faces where Lips are Available for Assessment of Smiling. Within the total time during which faces appeared in the video, 5.77 hours, (M=532.51 seconds per participant, SD=865.14 seconds per participant) provided a view of the face that allowed the coder to assess whether the face was smiling or not, heretofore lip time`. For 1-month-old infants, the cumulative amount of lip time was 2.92 hours, which represents approximately 13 minutes per participant (M=809.69 seconds per participant, SD=904.84 seconds per participant). For 3-month-old infants, the cumulative amount of lip time was 1.63 hours, which represents approximately 7 minutes per participant (M=451.54 seconds per participant, SD=1101.06 seconds per participant). For adult participants the cumulative amount of lip time was 1.21 hours, which represents approximately 5 to 6 minutes per participant (M=336.31 seconds per participant, SD=454.99 seconds per participant). A one-way analysis of variance was run to determine if adults and infants were exposed, in the videos, to differential amounts of lip time. Exposure to views of the face where coders felt that they could confidently detect a smile, if the person in the video were to smile, were not significantly different between the groups (F(2, 36)=.043, p=.958,
2

=.002, r=.05). Transformed into mean ranks, infants still

had greater lip time (1-month-olds` mean rank: 22.50, 3-month-olds` mean rank: 20.85, adults` mean rank: 16.65), however the differences between the groups, when probed with a Kruskal Wallis test, were found to be not significant (H(2)=1.82, p=.419). Accordingly, since the lip time value reliability scores were low and since there seems to be no significant differences in lip time for adults or infants of either age, smiling values were not adjusted, in subsequent analyses, according to lip time. Exposure to Real Smiling Faces. The cumulative seconds of experience viewing smiles, smile time` in the videos of 1-month-olds was 1.35 hours, with each participant experiencing approximately 6 minutes of smile time (M=374.38 seconds, SD=453.58 seconds). Overall, 1-month-old participants were

78

Quantifying face exposure in infants and adults
exposed to real faces smiling 3% of the time (M=3.14 percent, SD=3.86 percent). The cumulative seconds of experience viewing smiles, smile time` in the videos of 3-month-olds was 4613 seconds (1.28 hours), with each participant experiencing approximately 354 seconds or almost six minutes of smile time (M=354.85 seconds, SD=965.06 seconds). Overall, 3-month-old participants were exposed to real faces smiling 6% of the time (M=6.48 percent, SD=5.48 percent). The cumulative seconds of experience viewing smiles, smile time` in the videos of adult participants was 2828 seconds (0.79 hours), with each participant experiencing 217 seconds or approximately three to four minutes of smile time (M=217.54 seconds or 3.62 minutes, SD=413.22 seconds). Overall, adult participants were exposed to real faces smiling less than 1% of the time (M=0.48 percent, SD=0.95 percent) A one-way ANOVA probing the difference in exposure to smiling across the age groups was significant (F(2, 36)=7.69, p=0.02,
2

=0.30, r=0.54) with a large effect size. Planned contrasts probing

the significant differences found that infants` and adults` exposure was significantly different (t(36)=3.26, p=.002), with infants experiencing more smiles than do adults, and 1- and 3-month-olds exposure to smiles were significantly different, (t(36)=-2.18, p=.036), with 3-month-olds experiencing more smiles than do 1-month-olds. Transformed into mean ranks, infants still had greater exposure to smiles (1month-olds` mean rank: 22.50, 3-month-olds` mean rank: 27.57, adults` mean rank: 9.96), the differences between which a Kruskal Wallis test found to be significant (H(2)=16.59, p<.001). A Mann-Whitney test comparing infants (Mean rank: 25.02) to adults (Mean rank: 9.96) was used to follow up this finding. It found that there was a significant difference between infants and adults` exposure to smiles (U=38.50, r=.63, exact significance p<.001). This was a large effect.

79

Quantifying face exposure in infants and adults Figure 9 Percent Time 1-Month-Olds, 3-Month-Olds, and Adults were Exposed to Real Smiling Faces

Percent Time

One-Month-Olds
Note. Error bars represent standard deviations

Three-Month-Olds

Adults

80

Quantifying face exposure in infants and adults
Overall Face Exposure. One-month-old participants spent 37 percent of their time (M=37.21, SD=18.55) with faces in their field of view. This means that 1-month-olds spend 2.59 hours (37% of their 7 waking hours) with faces in their field of view. Three-month-old participants spent 38 percent of their time (M=38.34, SD=31.85) with faces in their field of view. In terms of waking hours, this means that 3-month-olds spend 3.33 hours (38% of their 8.76 waking hours with faces in their field of view. Adult participants spent 13 percent of their time (M=12.84, SD=12.22) with faces in their field of view. In terms of waking hours, this means that adults spend 2.20 hours (13% of their 16.90 waking hours) with faces in their field of view. Adult Face Discrimination Task Results. Eight adult participants completed both face discrimination tasks. The other seven participants have not yet completed these tasks due to scheduling difficulties. When viewing computergenerated (FaceGen) faces, adults` accuracy on the first part of the task (old vs. new) was 65%, significantly better than a chance level of 50% (t(7)=5.66, p=.001) and their accuracy on the second part of the task (first group vs. second group vs. novel) was 51%, significantly better than a chance level of 33% (t(7)=3.54, p=.009). When viewing real faces, adults` accuracy on the first part of the task (old vs. new) was 90.5%, which was significantly better than chance (t(7)=15.07, p<.001) and their accuracy on the second part of the task (first group vs. second group vs. novel) was 83.5%, also significantly better than chance (t(7)=18.46, p<.001). Exploratory analyses: Correlations between task performance and face exposure. The FaceGen and Real face task scores for each participant were transformed into a single score by averaging the percent correct performance on all parts of both tasks. Pearson`s product-moment correlation coefficients were used to assess the relations between these averaged percent correct scores and 3 measures of overall face exposure, 2 measures of type of face exposure, and 1 measure of variability of

81

Quantifying face exposure in infants and adults
face exposure. A Bonferroni correction for multiple comparisons (6 comparisons) was conducted, resulting in an adjusted p value for significance of p=.008, against which the significance values are to be compared. There were no significant correlations between the average score on the face tasks and either the percent of overall time in which faces were available over the adjusted run time of the video (r=.09, n=8 , p=.828), the percent of overall real face time in which real faces were available over the adjusted run time of the video (r=.60, n=8, p=.114). There was also no significant correlation between performance on the task and the number of media faces (r=-.36, n=8, p=.376) or static faces (r=.07, n=8, p=.875). There was no relationship found between performance on the memory task and number of faces per video (r=.-.52, n=8, p=.189). Since it is was considered possible that there might be a relationship between exposure to multitude different views of real faces (upright, inverted, or side-ways) and performance on the task, a correlation between exposure to not-upright faces and performance on the task was probed. This was found to be significant (r=.92, n=8, p=.001). Due to the small number of participants who completed this task and the few non-upright faces viewed by faces, this finding is to be interpreted with caution. Infant Face Discrimination Task Reliability. Of the 13 videos of infants coded for the infant habituation task, 23% (3 videos) were coded by a second coder to provide a measure of inter-rater reliability. The correlation between coders was evaluated frame by frame. There was a significant correlation between coders` evaluations of infant looking for all three videos (r=0.83, n=2280, p<.001; r=0.93, n=2755, p<.001; r=0.44, n=2104, p<.001) with an average of 86% agreement between coders over all frames and all videos (M=91.30%, SD=28.20; M=96.70%, SD=17.90; and M=70.00%, SD=45.90, respectively). Results. Habituation task data from five 1-month-old infants and eight 3-month-old infants were

82

Quantifying face exposure in infants and adults
available for analysis. Two 1-month-old infants did not complete the task because they were unable to attend their second appointment due to illness and five 1-month-olds did not complete the task due to fussiness at the time of the task (3 infants), sleeping during the task (1 infant), or technical failure of the equipment (1 infant). Three 3-month-old infants did not complete the task because they were unable to attend their second appointment due to illness and two did not complete the task due to fussiness. Of the 13 infants who completed the habituation task, three were removed because of they did not show habituation (i.e., their last look at the habituation stimulus was more than 60% of their three longest looks towards the stimulus). Infants who did habituate showed an average 66.48% reduction in looking towards the stimulus on their last trial, as compared to their three longest trials (M=66.48%, SD=16.32%). Recovery was calculated as the looking time to the novel stimulus averaged across the two test trials over their looking time to the familiar stimulus averaged across the last two habituation trials. Infants showed an average recovery of looking of 2.36 frames (SD=2.00) in the two test looks towards the novel stimulus as compared to their last two looks towards the habituation stimulus. A paired samples t-test was used to compare average looking across the two test trials to the average looking across the last two habituation trials. This difference was marginally significant, t(10)=-1.91, p=.085, indicating marginally greater looking at the novel than towards the habituated face. The choice here to use a habituation paradigm to test infants' face discrimination abilities was based on previous research that has found this procedure to be a more sensitive measure of infants' discrimination abilities than a visual preference test (see Maurer & Barrera, 1981). Exploratory Analyses: Correlations between Task Performance and Face Exposure. Pearson`s correlations were run to determine if infant recovery of looking correlated with the time spent with faces, the time spent with real faces, the time spent with smiling faces, and the time spent with not upright faces. There were no significant correlations (r=0.34, n=11, p=.300; r=0.19, n=11, p=.585; r=-

83

Quantifying face exposure in infants and adults
0.09, n=11, p=.790, r=0.06, n=11, p=.852). Exploratory Analyses: Exposure to Facial Expressions of Emotion Other Than Smiling The seconds of time to which participants were exposed to emotion was very small for all groups, with only slightly less than two minutes of exposure to a surprised facial expression and, outside of smiling, no other facial expressions of emotion captured in any of the videos. For 1-month-olds, the cumulative seconds of experience viewing surprise was 59 seconds, with each participant having a mean emotion time experience of 4 or 5 seconds (M=4.54, SD=9.70). For 3-month-olds, the cumulative seconds of experience viewing surprise was 28 seconds total, with each participant having a mean emotion time experience of two seconds (M=2.15, SD=6.06). For adults, the cumulative seconds of experience viewing surprise was 16 seconds total, with each participant having a mean emotion time experience of1seconds (M=1.23, SD=3.63).

84

Quantifying face exposure in infants and adults Discussion

The goal of the current study was to quantify how much and what kinds of exposure to faces both infants and adults receive, and to relate exposure to performance on a face discrimination task. The first major finding to emerge from the current study was that faces are a huge part of our visual world. Proportionally, faces were present over one third of the time (37% and 38%) for 1- and 3-month-old infants and 13% of the time for adults. Extrapolating from the proportion of time spent with faces and the hours spent awake, this means that 1-month-old participants spent 2.59 hours (37% of their 7 waking hours), 3-month-old participants spent 3.33 hours (38% of their 8.76 waking hours), and adult participants spent 2.20 hours (13% of their 16.90 waking hours) with faces in their field of view. Not unexpectedly, adults spent significantly less time with faces available in their visual world as compared to 1- and 3-monthold infants. At 1 and 3 months of age , infants are still spending much of their time asleep. When they
are 1, 2, and 3 days old, they spend about 16%, 10-13%, and 13%, respectively, of their day awake (Freudigman & Thoman, 1993 and Sadeh, Acebo, Seifer, Aytur, & Carskadon, 1995, respectively). During the first 3 days of life, however, infants spend about 22% of their time with their mother, of which 39% was spent apparently viewing the mother`s face (Bushnell, 2003). Here, we found that 1- and 3month-olds spend 37% and 38%, respectively, of their waking time viewing faces. It seems that the exposure to faces begins very high and remains high through the first three months of infancy. In addition to overall increased exposure to faces, infants also were exposed to more female faces, adults` age faces, own-race faces, up-close faces, faces viewed with no other faces in the field of view, and smiling faces. than were adults Unexpectedly, we found no relationship between exposure to faces and performance on

85

Quantifying face exposure in infants and adults
an infant looking-time face discrimination task or adult face discrimination memory task.

The face exposure that we receive in early infancy, as compared to adulthood, mirrors the early preferences and discrimination abilities that infants show for faces of different genders, races, ages, and orientations. Very early in life, infants show a preference for their mother's face (Pascalis et al., 1995) and for female faces generally (Quinn et al., 2002). The female preference, however, is not seen in infants who have male primary caregivers (Quinn et al., 2002), pointing to an exposure-driven effect. Additionally, infants who receive greater amounts of exposure to mother's face in the first few days of life show a stronger preference for their mother's face, as compared to infants who receive less exposure to their mother`s face (Bushnell, 2001), again implicating experience as a driver of face processing skills. Between 3 and 4 months of age, infants prefer to look at female faces regardless of whether they were habituated to male or female faces, even when external cues (e.g. hair) are removed (Leinback & Fagot, 1993). Not unexpectedly, we found here that infants with female primary caregivers see primarily female faces. Of the time that 1- and 3-month-olds spend with faces in their visual world, 60% and 73% of that time, respectively, is spent with female faces. This leaves only 40% and 28% percent of time with male faces. By comparison, exposure to female faces in adults is approximately half of total gendered face exposure (40%, not significantly different from 50%). Therefore, compared to the adult`s visual world, an infant`s visual world offers disproportionate exposure to female faces. This greater exposure to female faces combined with infants` early preference for the familiar over the novel (Courage & Howe, 1998) suggests that exposure could be driving infants` preference for female faces (Quinn et al., 2002). Infants are also exposed to faces that are primarily the same race as their parents. The 86

Quantifying face exposure in infants and adults race of faces to which infants are exposed at 1 and 3 months of age is nearly homogenous, with own-race faces representing 96% and 93% of all time spent with faces. Similar to the gender preference, 3-month-old infants show a preference for the face race to which they are most exposed (Kelly et al., 2005). This own-race face preference becomes an advantage at 9 months of age, when infants lose the ability to discriminate between faces of other races to which they have not been exposed regularly (Kelly et al., 2007). This own-race advantage persists into adulthood (Balas & Nelson, 2010), although exposure to different race faces in either childhood (Sangrigoli et al., 2005) or adulthood (Hancock & Rhodes, 2008) can improve face discrimination performance with other-race faces. The data presented here provides evidence and quantification of how discrepant exposure to own- versus other-race faces is in early infancy versus adulthood. In contrast to the infant data, own-race faces represented only 61% of time spent with faces for adults, which reflects the broader environmental context (i.e., the Greater Toronto Area, a diverse city where 42.9% of the population are identified as visible minorities in 2006--Ministry of Finance, 2012). Our data supports previous results that suggest that the development of preference for and aptitude with own-race faces is based on differential exposure during infancy to own-race faces. At the moment, it is unclear why there is little recovery of other-race face discrimination in adulthood, when other-race faces make up a larger proportion of all faces seen. Training studies have suggested that this may be due to a lack of individuation (Scott & Monesson, 2009) or a lack of personal one-on-one interaction with other-race faces (Hancock & Rhodes, 2008). It is also possible that the amount of exposure required to gain expertise with a particular face category may change with development. Although the data 87

Quantifying face exposure in infants and adults presented here cannot distinguish between these possibilities, it provides an important validation of previous work suggesting that the own-race face advantage is based on differential exposure to own- and other-race faces during infancy. They are also an important first step towards quantifying exactly how much exposure to different kinds of faces is necessary for the development of expertise. Adults show an advantage for own-age face processing and perform poorly when discriminating faces of other ages (Yovel et al., 2012; Kuefner, Macchi Cassia, Picozzi, & Bricolo, 2008). Infants show an advantage for parent-age faces (Kuefner et al., 2006). The current data shows that infants view faces of approximately their parent's age more often than faces of other ages. One- and 3-month-old infants` exposure to faces of their parents' age represents 82% and 74%, respectively, of infants' total exposure to real faces, whereas adults' exposure to same-age faces is much lower (26%). Infants are sensitive to which faces are most common in their visual world. This is reflected in earlier looking preference and later maintained discrimination ability. The differential exposure documented here provides a quantification of how large the difference in exposure is between the types of faces that are common, relative to those that are uncommon, in infants' visual worlds. The differential face exposure received by adults and infants is not limited to static qualities of faces. The current study documents that the way in which infants experience faces is different from the way in which adults experience faces. First, infants saw more diverse orientations of faces than adults. In the adult world, faces were primarily upright, not side-ways or inverted. For infants, however, faces were upright, side-ways, or inverted. The first-order 88

Quantifying face exposure in infants and adults relational features of the face (two eyes above a nose above a mouth) are invariant (Diamond & Carey, 1986), but only when the face is in its canonical upright orientation. The first-order relational features change when the face is turned on its side (at which point the eyes, nose, and mouth all lie across the same horizontal plane) or when it is turned upside-down. By 3 months, infants are sensitive to first-order relations within a face (Bhatt, Bertin, Hayden, & Reed, 2005) and by 4 or 5.75 months of age infants can no longer discriminate between inverted faces (Turati, Sangrigoli, Ruel, & de Schonen, 2004; Cashon & Cohen, 2004, respectively). Prior to the current study, no study has attempted to document infants' exposure to upright, side-ways, and inverted faces as they occur in the infant's natural environment. We found that faces were viewed upright most often by adults. One-month-old infants saw fewer upright faces (81% of all faces) than 3-month-old infants (89% of all faces) and 3-month-old infants saw fewer upright faces than adults (95% of all faces). Infants also saw more fully inverted faces (representing 8% and 6% of all faces for 1- and 3-month-old infants, respectively) than adults (3% of all faces). Since the majority of faces in all three groups were viewed in their standard upright eyes-abovenose-above-mouth orientation, it is not surprising that infants become 'tuned' to the upright orientation early in life. This early exposure and tuning to upright faces may be the basis of the inversion effect, which describes the difficulty experienced in discriminating inverted faces relative to upright faces. For infants and adults inverted faces are used as a comparator object to experimentally disrupt expert-level face processing strategies or processing strategies for other objects of expertise (for review, see Valentine, 1988). The neural marker that indexes upright faces, the N170, is modulated in amplitude and latency when adults view inverted faces (Eimer, 89

Quantifying face exposure in infants and adults 2000) as well as when infants view familiar faces that have been inverted (Balas et al., 2010). Perhaps the tuning to upright faces represents an early form of perceptual narrowing or the tuning of face expertise to the faces present in the infant's visual world. In addition to differential exposure to face types and orientations, infants also experienced more up-close faces than do adults. These up-close faces likely allow infants, with their limited visual acuity (Levin, 1999), to better resolve the person with whom they are interacting. Up-close faces also cover a large portion of the infant`s field of view, which may allow infants to better focus on the face that is being presented to them. In addition, infants viewed more faces viewed with no other faces in the field of view of the camera than did adults. As with viewing faces up-close, this could be another mechanism that helps to focus infants' attention on the single face being presented. Pereira, Yu, Smith, and Shen (2009) found that the way in which social partners influence toddlers' views of the world and attract their attention to objects in the world is by placing the object in front of the toddler, near to their face. This strategy works and eye gaze does not. Training paradigms that result in successful infant learning present the infant with single exemplars of stimuli near to their face and in the center of their field of view (for an example of training with faces, see Macchi Cassia, Kuefner, Picozzi, & Vescovo, 2009). If parents initially present relevant stimuli, faces, to the part of the visual field in which the infant can best resolve the object, near to the infant, and with no other faces competing for attention, this seems to be a likely mechanism by which parents are teaching their infants about what is important in their visual world and how best to learn about it. Since infants' movements are limited to the eyes and the head alone, a very young infant's lack of ability to 90

Quantifying face exposure in infants and adults explore independently demands that their parents present them with items of interest. It may also be the case that whenever an adult presents an infant with an item (toy, food, or otherwise), the face is also present. If this co-presented face is also engaging, by smiling, speaking, and reacting to the infant, it could be argued that learning about faces is encouraged by exactly these types of early interactions and exposures. Later, infants use the way in which they experienced faces, an up-close one-item-in-the-visual-field strategy when examining and manipulating novel toys themselves. It could be argued that later methods of infants` object exploration simply reflect this early training. Overall, the differences in face type and face presentation documented in these first-person-perspective videos may be the driving factor in infants' rapid learning about faces. The facial expression of the emotion happy, as shown by smiling, was experienced more often by infants and adults, relative to surprise. Infants saw smiles 3% and 13% of the time during which they viewed faces at 1 and 3 months of age, respectively, whereas adults saw smiles less than 1% of the time. Faces expressing surprise were viewed less often than are happy faces, with 1- and 3-month-old infants seeing surprise 4.5% and 2% of the time during which they were interacting with faces. Adults viewed surprise even less, with 1% of face exposure time including surprise. Therefore, it seems that infants see more smiles and potentially more facial expressions of the emotion surprise than adults. That facial expressions of happy and surprise were the only emotions observed in infant video reflects the way in which adults typically interact with very young infants, through up-close, happy, face-to-face interaction. It is also consistent with Malatesta and Haviland (1982), who found that mothers` facial expressions

91

Quantifying face exposure in infants and adults of emotion are limited to positive emotions. Exposure to facial expressions of emotion outside of surprise and happy did not occur at all in the data recorded by participants in the current study. There were no fearful, disgusted, angry, or sad faces in the videos. Exposure to smiling, surprise, and negative facial expressions of emotion were lower than the level of exposure received to other-race faces by infants, but still infants improve in their ability to discriminate smiling from a surprised facial expression at 3 months of age (Young et al., 1977) and smiling from a surprised facial expression at 7 months of age (Nelson, Morse, & Leavin, 1979) whereas they lose their ability to discriminate between faces of other races at approximately 9 months of age (Kelly et al., 2007). Based on experience alone, it would be expected that infants would either not develop or quickly lose the ability to discriminate any facial expression of emotion, especially those to which they are not exposed. Instead, unlike with faces of other races, ages, genders, and orientations, infants gain facility with these faces despite a very low proportion of faces expressing facial expressions of emotion other than happy. It has been suggested that the order in which infants develop the ability to recognize facial expressions of emotion reflects their exposure to them (Pollack & Kistler, 2002). Infants and adults did experience more exposure to happy than to surprise and more exposure to surprise than to any negative emotion, however what aspect of these exposures drive the increase in ability for this type of face over other infrequently-viewed faces is unclear. The type of faces to which infants are exposed are more heterogeneous than are adults` face experiences in some respects and more homogenous in others. Infants` experiences with faces were more single faces viewed with no other competing face stimuli, which could serve to 92

Quantifying face exposure in infants and adults make face processing easier for infants since there are no other faces distracting from the single face in view. Cashon and Cohen (2003) describe how when presented with two faces at one time 3-month-olds process only the features independently and do not integrate the features from different faces into separate wholes. It seems that 3-month-olds do not appear to process whatgoes-with-what` whereas 4-month-old infants do process this information. Therefore, it seems that infants` experience with faces (i.e., seeing single faces with no competing face stimuli) dovetails nicely with their processing abilities at 1 and 3 months of age. Despite the many years of face exposure received prior to the study period for adults, adults` performance on the face discrimination task was unrelated to their exposure to faces, exposure to smiling faces, exposure to real faces, exposure to static faces, or exposure to media faces. Adults` performance was found to be significantly and highly correlated with exposure to not-upright faces. It could be argued that adults exposed to multiple face orientations may have a more flexible representation of a face, resulting in better performance on the task, particularly with the computer-generated faces. Since the sample here is small, however, these results should be interpreted with caution. Ongoing data collection should allow for a more accurate characterization of the relationship between performance on a face discrimination task and exposure to faces in non-upright orientations. With infants there was also no correlation between exposure and performance on the face discrimination task. Since more than half of the infants did not provide habituation data that could be including in the analysis, due to not completing the task or not habituating, and since there was only marginally significant recovery of attention to the test stimulus, it is unclear 93

Quantifying face exposure in infants and adults whether this reflects a true non-relationship between exposure and performance on a face discrimination task. It is expected that a larger sample size may clarify whether a relationship exists. Additionally, all infants who participated in the current study are being invited back at either 8 or 9 months of age to complete a second face discrimination task. Older infants tend to tolerate the task better, which may lead to more infants completing the task. This will, potentially, allow for a more powerful analysis of whether infants` performance on a face discrimination task is related to how many faces, what type of faces, and how they experienced faces at either 1- or 3-months of age. The current study cannot definitively evaluate current theories on the development of face processing and whether faces are special`. That infant participants did not habituate to the visual stimuli and that there was not a correlation between exposure and ability at any age make interpretation of the results of the face discrimination task difficult. It is still unclear if and how exposure may relate to ability in infancy and adulthood. The data from the current study does provide evidence of a pattern of exposure to faces. This pattern of exposure can be considered within the frame of previous studies on infant and adult face processing ability. This combination can provide evidence as to whether exposure to faces and ability with faces is consistent with what is theorized to be necessary for the development of adult-level face expertise. McKone, Crookes, and Kanwisher (2009) argue for a domain-specific experienceindependent genetic or innate face processing mechanism that is not influenced by experience with or exposure to faces. If this theory is correct, we would have expected to find no relationship between experience and exposure at any age. There is also no expectation of 94

Quantifying face exposure in infants and adults differential exposure to specific face types matching the development of infants` preference for or ability to discriminate between specific face types. For example, it would not be expected that faces for which infants show a preference, such as female faces, or faces with which infants show greater face discrimination ability, such as own-race faces, would be the faces to which infants receive proportionally greater exposure. We found infants of both ages more often experiencing the types of faces known to be preferred by infants, with 60% and 73% of all faces viewed by 1- and 3-month-old infant participants being female faces while adults` exposure to female faces was significantly less. Infants of both ages were exposed to faces with which they have been found to show better discrimination ability, e.g. own-race faces constituted 96% and 93% of all faces viewed by 1- and 3-month-old infants. While far from conclusive, the evidence suggests that face processing may not be experience-independent in infancy. The CONSPEC / CONLERN theory of Morton and Johnson (Morton & Johnson, 1991) argues for an early experience-independent domain-specific face orienting mechanism that operates before 2 months of age and an experience-dependent domain-general mechanism that comes online after 2 months of age. This theory argues that face processing is experienceindependent before 2 months of age, while CONSPEC is operating, and experience-dependent face after 2 months of age, when CONLERN comes online. The pattern of results that would be expected if this theory is correct would find performance on the face discrimination task to be unrelated to face exposure at 1 month of age and performance to correlate with face discrimination ability at both 3-months and in adulthood. The results found in the current study did not show any difference in exposure to faces at 1- or 3-months of age and could not assess 95

Quantifying face exposure in infants and adults infants` face discrimination ability at either age. As mentioned previously, however, the results found here did find that the face types to which infants receive proportionally greater exposure at both 1- and 3-months are the face types to which they show preference and greater discrimination ability later in infancy. It is unclear whether exposure at both 1- and 3-months of age is contributing to infants` later preference or ability. If, however, there had been a difference in exposure at 1- and 3-months, with only exposure at 3-months reflecting known infant preferences and abilities in later infancy, this would have provided stronger support for the CONSPEC/CONLERN theory. Nelson`s (2001) experience-expectant process fits nicely with the results of the current study. While the results do not allow for an evaluation of whether there is a sensitive period during which face exposure is required to develop adult level face processing, they are strongly suggestive of experience being the mechanism for perceptual narrowing. Previous studies on infants` ability to discriminate between faces and to prefer certain types of faces provides substantial evidence that infants prefer female faces and show superior discrimination of ownrace, own-age, and upright faces. The current study has found that female faces, own-race faces, own-age faces, and upright faces are the types of faces to which infants receive greatest exposure. Since perceptual narrowing is theorized to be an experience-dependent process and infants` greater abilities are with the types of faces to which they naturally have the most experience, the current study provides support for an experience-dependent process of perceptual narrowing that leads to the increase in face discrimination ability for faces to which infants have greatest experience. 96

Quantifying face exposure in infants and adults While experience is necessary for the development of face processing under Bushnell`s (1998) sensory-ecology model, it is not sufficient. Infants must require engaging face-to-face social interaction to develop face expertise. The current study cannot directly evaluate the level of social engagement infants experienced with faces in their visual world nor can it inform whether social interaction influenced infants` development of face processing. Had these variables been reliably coded, a positive correlation between level of engagement of adult-infant interactions where the interaction partner`s face was visible and infants` ability on a face discrimination task would have provided strong support for this theory. The current findings do provide some evidence that the quality of exposure to faces received by infants is quite different than the exposure received by adults, with infants seeing more up-close faces, more smiling faces, and more faces viewed with no other face in the field of view. This type of exposure would seem to provide a better way in which to focus attention on a single face than would faces viewed far-away, unsmiling, and in a crowd of other faces. Since infants who performed the habituation task did not show habituation and recovery, the current study cannot provide evidence for whether the type of exposure infants` received influenced the development of infants` face processing ability. Gauthier and Tarr`s (2002) experience-dependent theory of face processing predicts that the faces viewed most often in infancy become the faces that infants find easiest to recognize. As previously outlined, the current study has found that infants receive more exposure to some types of faces. Previous research has found that these often-seen face types (female, own-race, parents`-age, and upright faces) are the faces infants can best discriminate. While this does lend 97

Quantifying face exposure in infants and adults support to an experience-dependent process, stronger evidence for a fully experience-dependent process would have been a strong correlation between exposure and ability at all ages. If exposure is necessary for the development of the face processing system, the evidence presented here indicates that infants received quite a lot of exposure to faces, in terms of their stand-alone proportion of day spent with faces and relative to adults. This heightened exposure to faces in infancy could potentially provide a mechanism by which the social world assists the progress of infants` face processing system. Spending more than one third of their day with faces present in their field of view may be an implicit driver for face expertise. It would be hard to imagine spending one third of an adult day with a single category of object that is interactive and engaging without developing expertise with that object. The types of face exposure received by infants were very different than those received by adults. Infants experienced a more homogenous sampling of faces in their visual world whereas adults tended to see more diverse faces. Infants saw primarily female faces of the race and age of their parents, although these faces were presented in diverse orientations. They also viewed more faces alone, not surrounded by other faces in their visual field, and the faces that they did see expressed more positive emotions, than did the faces viewed by adults. By comparison, adults saw fewer faces viewed alone, fewer faces that were not upright, and fewer faces expressing positive facial expressions of emotion. Neither infants nor adults saw negative emotions. Overall, there were significant and substantive differences in the amount and type of face exposure received in infancy versus adulthood. This provides evidence for how exposure may be driving the development of face expertise. 98

Quantifying face exposure in infants and adults The current theories of face exposure provide several possible mechanisms by which expert-level face processing develops. All have been supported by differing lines of evidence and provide vital insight into the way in which the mechanism(s) may operate. The current study provides a line of evidence that has been previously unavailable: the visual world from the infant's perspective. Parents' perspectives, researchers' perspectives, and birds' eye view perspectives have been found to be incapable of fully describing the child's world (Yu, Smith, & Pereira, 2008b). This first step towards fully describing the infant's visual world finds that there are several opportunities that may allow infants to learn rapidly about the faces they experience. Differential rates of exposure seem to be the mechanism by which infants develop preferences and sustain discrimination ability with the face types they see most often. It is not inconceivable, then, that this may also be the way in which infants become 'tuned' to faces themselves: through a wealth of exposure. A genetic face module, CONSPEC mechanism, or other expectant process is not incongruous with the current data; however, the current findings in combination with previous findings support a more experience-driven view of the development of face processing. A parsimonious explanation of the development of face processing, building on that put forward by Gauthier and Tarr (2002), would be that the same mechanism is operating both within the face domain and between objects and faces. This process would use the huge wealth of exposure to the objects in the visual world with which infants spend more than one-third of their waking day--i.e., faces--to broadly tune the visual processing system to faces. Once tuned to faces, the differential rates of exposure to face types would allow for the development of more nuanced face discrimination abilities. 99

Quantifying face exposure in infants and adults Limitations

The major limitation of the current study is that it is unclear whether the video data captured is a completely accurate representation of participants` visual worlds. This limitation was the result of many factors, which are explored in detail here. First, participants indicated that they had made at least 295 recording attempts through the completion of pre/post recording questionnaires. However, not all of the 295 videos were submitted. In some cases, this discrepancy between questionnaires completed and videos returned reflected participants` difficulty in operating the camera. In other cases, the camera itself was faulty and either would not record or the battery would die prematurely. It is also possible that the participants themselves may have accessed the memory card and deleted videos (either accidentally or intentionally). In one instance the participant recorded too often, which filled the memory card to capacity, preventing more video from being recorded. Although there is no way to be certain which videos were successfully recorded and which ones were not successfully recorded, we expect that this data loss was random. Second, not all of the videos that were submitted were appropriate for coding. This reduced the total amount of video provided by each participant. Some videos had only brief periods of unusable data whereas other videos were entirely unusable. Some of the reasons for which videos were not appropriate for coding were that the camera was not on the participant`s head, the camera lens was occluded, or the camera malfunctioned during recording, changing the quality of the video. Adult participants removed the camera only during brief periods where 100

Quantifying face exposure in infants and adults recording was not appropriate (e.g., when viewing confidential personal information or entering a private area such as a restroom). Adult video is not representative of these periods, for privacy reasons, and therefore is systemically under-representing these situations. We speculate that faces are neither frequent nor prominent in these situations, which may have led to a slight overestimation of the number of faces seen through the course of a normal day. For infants, unusable data were primarily recorded when the camera was removed from the infant`s head and not turned off properly or the camera was occluded. Since not turning the camera off and leaving it to capture video of a single unmoving scene is not a part of the infant`s visual world, removing this footage from the pool of video available for coding did not influence the results obtained. During times when the camera was occluded, it was often unclear whether the infant`s eyes were also occluded. Unfortunately, the videos do not provide a measure of whether the infant`s eyes were covered along with the camera lens. Here we chose to err on the side of caution and to exclude these portions of video to be maximally confident that these data actually reflect the infant`s visual world. Third, results from the Pre/Post recording questionnaires suggest that most recordings began at home. This reflects the fact that 1- and 3-month-old infants spend a large proportion of their time at home. This also reflected how parents used the camera. Parents stated that they would put the camera on at home before they left home because it was more convenient than placing the camera on their infant`s head while they were out. In many cases adults did the same thing, placing the camera on their head at home before they left the house. Since we chose to use participants` documentation of where they began recording as an index of where recording

101

Quantifying face exposure in infants and adults occurred, this measure likely underestimates the amount of not-at-home recording time captured in adult and infant videos. Unfortunately, there was low compliance on the second half of the Pre/Post recording checklist questionnaire, where participants indicated where they were when they stopped recording, so this was not included in the study. To more accurately describe the locations in which recording occurred, video is still being re-coded to document the recorded environment. Fourth, the reasons for which adults and infants stopped recording were different. These likely reflect adults` and infants` natural differences. Infants` recording sessions usually ended because they were sleepy, fussy, or hungry. Some mothers chose to record while feeding their infant and some did not. Some mothers stated that they removed the camera while their infant was eating because their infant typically falls asleep while eating. Some mothers continued recording even while their infant was fussy and some did not. All mothers removed the camera when their infant became sleepy. Ideally, this would mean that what was recorded represents the time during which infants are awake, alert, and attending to their environment. It is unclear, however, to what extent when infants` recording sessions were ended may have influenced what part of their visual world was documented. It is likely that being fed and soothed represent times during which infants may receive more face-to-face interaction with their caregiver. If this is true, then these data under-represent the amount of time that infants spend exposed to faces, meaning that the differences between infants` and adults` visual worlds are actually greater than what is captured in the data. With adults, the majority of adults ended recording because the battery in the camera died or the two hours were up. With the cameras whose batteries were 102

Quantifying face exposure in infants and adults faulty, the battery dying appears to be random and this random data loss is unlikely to systemically increase or decrease how representative these data are. Fifth, parents and adults chose when to use the camera. Their selections could have systematically biased the video data. For example, it is possible that parents chose to record primarily at times during which they were interacting with their children, to manage the way in which they presented themselves on camera to the researcher. Although parents had control over the time at which the camera was on the infant`s head, the videos were all taken from the infant`s perspective and still represent the visual world, at that time, of that infant. It is also possible that parents behaved in a non-representative way with their infant, since they were aware they were being recorded. Since this is the first study examining parent-infant interactions from the infant`s perspective in their home environment with their parents, there is no objective measure of parent-infant interaction against which this data can be measured. Despite no 3-month-olds` parents and only 8% of 1-month-olds` parents responding that they were not comfortable with their infant wearing the camera in public, even this measure is not objective and could be the result of parents managing their image. However, many of the videos do show candid moments that could be considered embarrassing to the parent or caregiver featured. From this perspective, it seems as if at least some parents were comfortable enough with the camera to behave, on camera, in ways that seem quite natural. Adults also had the opportunity to select to use the camera only in certain circumstances. In fact, some participants, notably a high school teacher, a kindergarten teacher, an accountant, a funeral director, and a civil servant, could not film during their regular work hours, resulting in a 103

Quantifying face exposure in infants and adults less representative sampling of their normal visual world. It is likely that the teachers` videos contained fewer faces than they would typically experience in the course of a day since they did not record at work, where they see many faces. Conversely, it is also likely that the accountant, funeral director, and civil servant participant videos contained more faces than they would normally see during the course of their day since they recorded only when they were not working. Other participants, notably a journalist, a rock climbing instructor, a researcher, a university professor, and a retail manager, did record while they were at work, meaning that there are some data recorded during a normal work-day for these participants. It is also possible that adults who were less comfortable with the study or the camera simply chose to see fewer people during their participation, whereas adults who were more excited by the study chose to see more people during their participation in the study. However, fewer than 6% of adults said that they were uncomfortable wearing the camera in public. Therefore, although it is possible that the captured video may not fully represent each participant`s typical day, it does still contain segments of the participants' visual world. This is the first study of its kind, and it provides at least a rough estimate of the nature of adults` and infants' visual worlds. Another potential limitation lies in the vastly different lifestyles of the infant and adult participants. It has been suggested that the disparity in experience that adults have relative to infants may be influencing the results of the current study. Instead, however, we believe that precisely these differences that are important when examining the interactions adults and infants have with faces. Specifically, the up-close, smiling, face-to-face, type of interactions that typify 104

Quantifying face exposure in infants and adults adult-infant interactions could potentially be playing a large role in the way in which infants learn about faces, as suggested by Bushnell (1998) in the Sensory-Ecology model. Conversely, it is possible that contextual variables, such as infants recording more often at home, may potentially be leading to the observed differences among age groups. Most infants do spend more time at home than do adults, as evidenced by the fact that no adult participant stayed home during the whole of their time with the camera while some infants did stay at home the whole of their time with the camera. It is possible that the way in which faces are experienced at home or in contexts in which infants tend to see faces is different from the way in which faces are experienced in other contexts. Again, we argue that this is exactly what we intended to document with the current study since these are the contexts in which adults and infants are experiencing faces. We would suggest that constraining the contexts in which adults and infants were asked to record, to create a more comparable recording environment, would no longer be fully representative of adults` and infants` experience of their daily life. Another limitation of the current study is inherent in the first-person perspective methodology that was used and the visual limitations of the participants and the cameras used to capture their visual worlds. Infants` visual fields begin as more limited than that of adults, expanding from 15 degrees to each side to 70 degrees to each side from 2 to 10 weeks after birth (Tronick, 1972). The visual fields of the adult and infant cameras were each 90 degrees. This suggests decreasing representativeness of the participant`s field of view with increased age. Yoshida and Smith (2008), however has found that a head-mounted camera does capture 90% of the visual fixations made by a toddler and the majority of visual fixations made by the toddler`s

105

Quantifying face exposure in infants and adults parent, which suggests that although the camera may not fully capture the field of view of the participant, per se, this methodology captures well the objects of interest to participants, as indicated by their visual fixations. Another limitation of the first-person perspective methodology is that the head camera captures primarily the central visual field. Adults typically do not attend visually to common tasks in which they are engaged (e.g., making a sandwich or pouring water), despite the fact that they must, at some level, attend enough to reach their desired goal (Land & Hayhoe, 2001). Therefore, it is possible that adults in the current study were occasionally directing their attention to objects/faces not captured in the field of view of the head-mounted camera. Previous studies, however, have found that eye gaze direction correlates highly with a head camera's field of view, meaning that the camera does capture what is actually visually attended by the participant; in toddlers, 90% of eye fixations fall within the field of view of the camera (Yoshida & Smith, 2008). Before they turn 2 months, infants have difficulty scanning their environment and visually pursuing visual stimuli (Maurer & Lewis, 1979), which may decrease very young infants` fixations beyond the visual field of the camera. This suggests that more than 90% of infants' visual fixations likely occur within the camera's field of view. Therefore, it is likely that the head-mounted camera used with infants and the sunglasses camera used with adults provided high correspondence between gaze and video captured. There is some suggestion that the head-mounted cameras may have, themselves, influenced the way in which others interacted with the participants. The adult cameras used in the current study were designed to be inconspicuous--they were marketed as spy cameras`-- 106

Quantifying face exposure in infants and adults and they were selected because they were the least conspicuous head-mounted camera technology that we could find. However, there may have been some situations in which the 'spy glasses' were perceived as out of place by individuals being recorded. In turn, this may have changed the types of interactions that the participant had with those individuals. The happy-face cameras worn by the infants were more noticeable, and this too may have influenced the way in which individuals being recorded interacted with the infant participants. With both devices, however, it is unlikely that casual observers would have identified them as cameras. Many parents, when first presented with the infant camera, said that they were surprised that it was a camera and asked the researcher where precisely the camera lens was located on the device. Adult participants were surprised that the adult camera was nearly indistinguishable from a pair of normal sunglasses. Given that participants were aware of the purpose of the two devices and still expressed surprise that the camera was so well hidden, it seems likely that most people that the participants encountered remained unaware of the intent of the head-mounted accessory. Based on the limitations described above, it is difficult to estimate precisely how representative these data, collected in the current study, are. As with any design where participants are requested to collect data about their natural world, it is possible that data collected may have been selected for by the participants. The limitations of the technology used here may have also further reduced how well these data represent participants' visual worlds. However, the questionnaires completed by participants themselves suggests that the participants attempted to provide a highly representative sampling of their visual world; additionally, previous research has found that the head-camera methodology captures participants' visual 107

Quantifying face exposure in infants and adults worlds well (Yoshida & Smith, 2008; Smith, 2012). Even if these data represent only a limited characterization of the adult and infant visual worlds, this changes only the scope of the sample, in that this may be documenting only a specific activities in which adults and infants engage, not its validity. These events constitute participants` experiences in the world and what was captured on video were the events that make up adults` and infants` visual worlds. Characterization of the visual world as experienced by adults and infants was the goal of the current study and this is what participants provided. Despite potential limitations, the current study represents a critical first step in characterizing the natural visual world of adults and infants from a first-person perspective.

108

Quantifying face exposure in infants and adults Future Directions The purpose of the current study was to describe face exposure as experienced by very young infants (1- and 3-month-olds) and by adults. This provides a gross estimate of the amount and type of face exposure received in early infancy versus adulthood. Of course, much of the development of face perception occurs between 3 months of age and adulthood. Over the first year of life, infants' face processing abilities increase with some types of faces, decrease with other types of faces, and show overall refinement. Extending the current study to older infants would allow us to study the relation between our precise measures of face exposure and the development of face processing abilities. How face perception changes over childhood is less well studied. Overall there are gains in face processing expertise over childhood; however, these have yet to be well characterized or parsed from more general cognitive and perceptual development (for review, see Want, Pascalis, Coleman, & Blades, 2003). From infancy to childhood, however, there is a transition to school, a decrease in reliance on parents, an increase in mobility, and a commensurate increase in freedom that may all influence the way in which faces are experienced in the natural world. The first-person perspective methodology used in the current study would be informative in childhood to provide an accurate description of how these large life changes influence the visual world of children and relate to further changes in face processing abilities. The differential exposure infants receive to faces of different genders, ages, races, and orientations provide further supporting evidence that experience may potentially changes the face processing system in early childhood to tune it to the type of faces available in the 109

Quantifying face exposure in infants and adults environment. Training studies have found that small amounts of daily exposure to other types of faces allow infants to retain their ability to discriminate amongst these faces; however, a critical feature of this exposure is that it provides individuation (Scott & Monesson, 2009). And evidence from adults shows that passive experience is not enough; massive passive experience to other-age faces over many years did not modify the other-age effect (Yovel et al., 2012), but specific types of personal interaction with faces of other races did reduce the other-race effect (Hancock & Rhodes, 2008). The current data is of the visual world only; a next step would be to collect data that includes video and audio to provide more evidence as to how faces from nondominant groups (e.g., other-race faces) are experienced by the infant--for example, do faces from these groups tend to be individuated by the parent or is it mostly passive exposure? This approach would offer insight into what aspects of an interaction are necessary to maintain flexibility in the infant system. This data does not include any of the sounds that infants might have experienced. Sound is a very salient cue in the infant`s visual world. Similar to how newborns will track faces present in their visual world, newborn infants will also orient to sound (Muir & Field, 1979) and prefer their mother's voice to the voice of a female stranger (Hepper, 1991). It is likely that including the sounds heard by infants and how they relate to their experience of faces and other objects in the infant`s visual world will provide a more complete picture of the infant`s experience. Since 3-month-old infants can learn, in 45 seconds, the relationship between a stranger`s voice and their face, it has been suggested that these two highly salient cues may together influence how infants learn about faces (Slater, Quinn, Lewkowicz, Hayes, & Brookes, 110

Quantifying face exposure in infants and adults 2003). Infants use the face to detect correspondence between the sounds of speech and the movements made when adults articulate these sounds, which may facilitate early language comprehension and later language development (Kulh & Meltzoff, 1984). Therefore, a valuable extension of the current study would be to include and analyze the relationship between faces and voices experienced by infants and how this relates both to face perception and to language development. As discussed above, the seemingly contradictory findings that a small amount of exposure to facial expressions of emotion (e.g., surprise) may be supporting the maintenance of the ability to discriminate emotions, whereas small amounts of exposure to other types of faces (e.g., other-race faces) may not be sufficient to prevent a decrement in ability, has yet to be fully explored. Perhaps the ability to recognize facial expressions of emotion is experienceindependent, and that is why it does not show an exposure-related decrement. Potentially, the way in which emotional faces are presented to the infant might also be operating to preserve this ability. A more thorough investigation of how infants experience facial expressions of emotion than that presented here might shed light on how infants who seem to receive very little exposure to facial expressions of emotion still develop the ability to discriminate between facial expressions of emotion. One- and 3-month-old infants spend a significant proportion of their waking time with faces available in their field of view (37% and 38% of their time, respectively); the majority of these faces are real faces. This is similar to Bushnell`s (2001) finding that newborn infants only a few days old spend 30% of their time watching their mother`s face. However, it is markedly 111

Quantifying face exposure in infants and adults different than Yoshida and Smith`s (2008) characterization of the visual world of toddlers-- where mother`s face is present only 6% of the time--or the current finding that adults view real faces during only 13% of their waking hours. The differing environments in which these studies were conducted -- mother and infants in hospital (Bushnell, 2001) versus a playroom with novel toys (Yoshida & Smith, 2008) -- may partially explain the difference. It is also worth noting, however, that young infants are not independently mobile. At 1 and 3 months of age, the contents of the infant`s visual world are determined by their caregivers, in terms of what caregivers actively present to their infants and the environment to which caregivers choose to expose their infants. In addition, the face processing system of toddlers is significantly more advanced than that of young infants (Crookes & McKone, 2009), so it is logical that toddlers would be more interested in novel objects than in examining their mother`s face. Since young infants still have the capacity to become face experts with presumably any type of face (HeronDelaney et al., 2011), the large amount of exposure observed in the current and previous studies may facilitate this specialization. The positive correlation between adults` performance on the computerized face task shown and exposure to faces in different orientations may argue for a maintenance of at least some of this early flexibility so that adults too can draw advantages from the quantity and type of face exposure they receive. The low frequency of exposure to nonupright faces and small sample size, however, suggest caution when interpreting this finding. How mobility, face processing ability, and exposure to faces relate is fertile ground for future research. Previous studies have compared face processing to the processing of houses, cars, and 112

Quantifying face exposure in infants and adults birds. We currently have no accurate characterization of adults' or infants' exposure to houses, cars, and birds, nor do we know how this exposure compares to infants' and adults' exposure to faces. An area of further investigation for the current study is in quantifying house, car, and bird exposure and comparing it with face exposure. This quantification and qualification of daily exposure to houses as compared to faces will provide a preliminary baseline level of experience with each. This can be used when considering the suitability of houses as control stimuli in studies of face expertise.

113

Quantifying face exposure in infants and adults Conclusion

Faces are a large part of our visual world and our experience with them changes over development. It is unclear, yet, how this may interact with or influence the development of face expertise. The results presented here show a clear pattern of increased exposure with face types with which infants are most proficient and decreased exposure to face types with which infants lose proficiency. Despite strong support for experience as the driver for change in infants' face processing ability, the possibility that there is a genetic or innate mechanism at work cannot be refuted. It is difficult to imagine, however, that this massive amount of face exposure would not influence face processing. This first attempt to characterize daily exposure in adults and infants is a starting point for future studies characterizing the natural world of adults and infants from a first-person perspective. This novel perspective can provide new insight into the participant`s experience. Ultimately, if the objective is to understand how participants view the world, it only makes sense to capture the world as participants are experiencing it. Are faces special? Although the current study cannot answer the question as to whether or not infants are born with an innate or hereditary neural template or mechanism that drives them to become face experts, it seems that even without these inborn mechanisms, the answer must be: yes, faces are special. Faces are special because they cannot be anything but special. They represent a visual stimulus to which we are exposed for over one third of our waking hours immediately after birth (Bushnell, 2001) and in the first three months of life. Even in adulthood face exposure remains high, with 13% of our time spent with faces present in our field of view. 114

Quantifying face exposure in infants and adults This provides more than two hours per day in which we have the opportunity to experience faces. There is unlikely to be another object that occurs in our visual world with the same frequency as faces. With this mammoth wealth of exposure we receive to faces, how can they not be special? Faces are de facto special because we make them special. The way in which we interact with infants, as compared to the way in which we interact with adults, is necessarily going to attract the infant`s attention to faces. When we interact with infants we come very close (within 3 feet 74% of the time for 1-month-old infants). This close-proximity interaction can overcome the constraints of infants` early visual system and can better attract infants` attention than had we presented the face further away. Faces are also special because we present them one-at-a-time to infants, whereas adults typically see multiple faces at one time. This too could be a mechanism by which we ensure infants` attention to the singular face in their field of view so that they can learn about it. It is highly unlikely that any other object is presented to infants as often, alone, and as near as are faces. How can an infant but learn about faces, under these conditions?

115

Quantifying face exposure in infants and adults
References

Ally, B. A., Waring, J. D., Beth, E. H., McKeever, J. D., Milberg, W. P., & Budson, A. E. (2008). Aging memory for pictures: using high-density event-related potentials to understand the effect of aging on picture superiority effect. Neuropsychologia, 46, 679-689. Amitabha Mukherjee, V. J. (2002). The Indian Face Database. Retrieved from http://viswww.cs.umass.edu/~vidit/IndianFaceDatabase/ Aslin, R. N. (2009). How infants view natural scenes gathered from a head-mounted camera. Optometry and Vision Science, 86(6), 561-565, DOI: 10.1097/OPX.0b013e318a76e96. Balas, B., & Nelson, C. A. (2010). The role of face shape and pigmentation in other-race face perception: an electrophysiological study. Neuropsychologia, 48, 498-506, DOI: 10.1016/j.neuropsychologia.2009.10.007. Balas, B., Nelson, C. A., Westerlund, A., Vogel-Farley, V., Riggins, T., & Kuefner, D. (2010). Personal familiarity influences the processing of upright and inverted faces in infants. Frontiers in Human Neuroscience, 4(1), 1-5. DOI:10.3389/neuro.09.001.2010 Balas, B., Westerlund, A., Hung, K., & Nelson, C. A. (2011). Shape, color and the other-race effect in the infant brain. Developmental Science, 14(4), 892-900. DOI: 10.1111/j.1467-7687.2011.01039.x Bartrip, J., Morton, J., & De Schonen, S. (2001). Responses to mother's face in 3-week to 5-month old infants. British Journal of Developmental Psychology, 19(2), 219-232, DOI: 10.1348/026151001166047. Bakti, A., Baron-Cohen, S., Wheelwright, S., Connellan, J., & Ahluwalia, J. (2000). Is there an innate gaze module? Evidence from human neonates. Infant Behaviour and Development, 23, 223­229. Bednar, J. A. (2003). The role of internally generated neural activity in newborn and infant face

116

Quantifying face exposure in infants and adults
preferences. In A. Slater & O. Pascalis (Eds.), The development of face processing in infancy and early childhood (pp. 133-142). New York: NOVA Science Publishers. Bentin, S., Allison, T., Puce, A., Perez, E., & McCarthy, G. (1996). Electrophysiological studies of face perception in humans. Journal of Cognitive Neuroscience, 8(6), 551-565, DOI: 10.1162/jocn.1996.8.6.551.

Bhatt, R. S., Bertin, E., Hayden, A., & Reed, A. (2005). Face processing in infancy: Developmental changes in the use of different kinds of relational information. Child Development, 76(1), 169-181.
Blass, E. M., & Camp, C. A. (2003). Biological bases of face preference in 6-week-old infants. Developmental Science, 6(5), 524-536, DOI: 10.1111/1467-7687.00310. Blehar, M. C., Liberman, A. F., & Salter Ainsworth, M. (1977). Early face-to-face interaction and its relation to later infant-mother attachment. Child Development, 48(1), 182-194. Bushnell, E. W., & Sai, F. Z. (1987). Neonatal recognition of the mother's face. University of Glasgow Psychological Reports, 87(1). Bushnell, I. W. R. (1998). The origins of face perception. In F. Simion & G. Butterworth (Eds.), The Development of Sensory, Motor and Cognitive Capacities in Early Infancy (pp.69-86). Hove, East Sussex: Psychology Press Bushnell, I. W. R. (2001). Mother's face recognition in newborn infants: learning and memory. Infant and Child Development, 10, 67-74, DOI: 10.1002/icd.248. Bushnell, I. W. R. (2003). Newborn face recognition. In A. Slater & O. Pascalis (Eds.), The development of face processing in infancy and early childhood (pp. 41-53). New York: NOVA Science Publishers. Carey, S., & Diamond, R. (1977). From piecemeal to configural representation of faces. Science, 195,

117

Quantifying face exposure in infants and adults
312­314. Cashon, C. H., & Cohen, L. B. (2004). Beyond U-Shaped Development in Infants' Processing of Faces: An Information Processing Account. Journal of Cognition and Development, 5(1), 59-80, DOI: 10.1207/s15327647jcd0501_4. Cashon, C. H., & Cohen, L. B. (2003). The construction, deconstruction, and reconstruction of infant face perception. In A. Slater & O. Pascalis (Eds.), The development of face processing in infancy and early childhood (pp. 55-68). New York: NOVA Science Publishers. Chellappa, R., Wilson, C. L., & Sirohey, S. (1995). Human and machine recognition of faces: a survey. Proceedings of the Institute of Electrical and Electronics Engineers, 83(5), 705-740. Cohen, L.B., Atkinson, D.J., & Chaput, H.H. (2004). A new program for obtaining and organizing data in infant perception and cognition studies. Austin: University of Texas. Collishaw, S. M., & Hole, G. J. (2000). Featural and configural processes in the recognition of faces of different familiarity. Perception, 29, 893-909. Colombo, J., & Horowitz, F. D. (1985). A parametric study of the infant control procedure. Infant Behavior and Development, 8, 117-121. Cornell, E. H. (1974). Infants` discrimination of photographs of faces following redundant presentations. Journal of Experimental Child Psychology, 18, 98-106. Courage, M. L., & Howe, M. L. (1998). The ebb and flow of infant attentional preferences: Evidence for long-term recognition memory in 3-month-olds. Journal of Experimental Child Psychology, 70(1), 26-53, DOI: 10.1006/jecp.1998.2444. Crookes, K., & McKone, E. (2009). Early maturity of face recognition: no childhood development of holistic processing, novel face encoding, or face-space. Cognition, 111, 219-247, DOI: 10.1016j.conition.2009.02.004.

118

Quantifying face exposure in infants and adults
Darwin, C. (1972). The Expression of the Emotions in Man and Animals. John Murray, London,U.K. Davies, G., & Milne, A. (1982). Recognizing faces in and out of context. Current Psychological Research, 2, 235-246. de Haan, M. (2001). Recognition of individual faces and average face prototypes by 1- and 3-

month-old infants. Cognitive Development, 16, 659 - 678.
de Haan, M., Johnson, M. H., Maurer, D., & Perrett, D. I. (2001). Recognition of individual faces and average face prototypes by 1- and 3-month-old infants. Cognitive Development, 16, 659-678. de Haan, M., & Nelson, C. A. (1998). Discrimination and categorization of facial expressions of emotion during infancy, In A. Slater (Ed.) Perceptual Development: Visual, Auditory, and Language Development in Infancy, (pp. 287-309). London: UCL Press. de Haan, M., Pascalis, O., & Johnson, M. H., (2002). Specialization of neural mechanisms underlying face recognition in human infants. Journal of Cognitive Neuroscience, 14(2), 199-209. de Heering, A. Rossion, B., & Maurer, D. (2012). Developmental changes in face recognition during childhood: evidence from upright and inverted faces. Cognitive Development, 27, 17-27, DOI: 10.1016/j.cogdev.2011.07.011. Dirks, J., & Gibson, E. (1977). Infants` perception of similarity between live people and their photographs. Child Development, 48(1), 124-130. Retrieved from http://www.jstor.org/stable/1128890?origin=JSTOR-pdf Eimer, M. (2000). Effects of face inversion on the structural encoding and recognition of faces Evidence from event-related brain potentials. Cognitive Brain Research, 10, 145-158. Ekman, P., & Friesen, W. V. (1971). Constants across cultures in the face and emotion. Journal of Personality and Social Psychology, 17(2), 124-129. Enders, C. K. (2003). Performing multivariate group comparisons following a statistically significant

119

Quantifying face exposure in infants and adults
MANOVA. Measurement and Evaluation in Counseling and Development, 36, 40-56. Farah, M. J. (1996). Is face recognition 'special'? Evidence from neuropsychology. Behavioural Brain Research, 76, 181-189. Farah, M. J., Levinson, K. L., & Klein K. L. (1995). Face perception and within-category discrimination in prosopagnosia. Neuropsychologia, 33(6), 661-674. Farrington-Darby, T., & Wilson, J. R. (2006). The nature of expertise: A review. Applied Ergonomics, 37(1), 17-32. Farroni, T., Csibra, G., Simion, F., & Johnson, M. H. (2002). Eye contact detection in humans from birth. Proceedings of the National Academy of Sciences, 99(14), 9602-9605, DOI: 10.1073/pnas.152159999. Farroni, T., Menon, E., Rigato, S., & Johnson, M.H. (2007). The perception of facial expressions in in newborns. European Journal of Developmental Psychology, 4, 2-13. Field, A. (2009). Discovering Statistics Using SPSS, 3rd Ed. London: SAGE Publications Ltd. Freudigman, K. A., & Thoman, E. B. (1993). Infant sleep during the first postnatal day: an opportunity for assessment of vulnerability. Pediatrics, 92(3), 373-379. Gauthier, I., Curran, T., Curby, K.M. & Collins, D. (2003). Perceptual interference evidence for a nonmodular account of face processing. Nature Neuroscience, 6: 428-32. Gauthier, I., Skudlarski, P., Gore, J. C., & Anderson, A. W. (2000). Expertise for cars and birds recruits brain areas involved in face recognition. Nature Neuroscience, 3(2), 191-197. Gauthier, I., & Tarr, M. J. (1997). Becoming a 'Greeble' expert: exploring mechanisms for face recognition. Vision Research, 37(12), 1673-1682. Gauthier, I., & Tarr, M. J. (2002). Unraveling mechanisms for expert object recognition: bridging brain activity and behaviour. Journal of Experimental Psychology: Human Perception and

120

Quantifying face exposure in infants and adults
Performance, 28(2), 431-446. Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski, P., & Gore, J. C. (1999). Activation of the middle fusiform 'face area' increases with expertise in recognizing novel objects. Nature Neuroscience, 2(6), 568-573. Gelskov, S., & V., Kouider, S. (2010). Psychophysical thresholds of face visibility during infancy. Cognition, 114, 285-292. Goren, C., Sarty, M., & Wu, R. (1975). Visual following and pattern discrimination of face-like stimuli by newborn infants. Pediatrics, 56, 544-549. Grady, C. L. (2002). Age-related differences in face processing: a meta-analysis of three functional neuroimaging experiments. Canadian Journal of Experimental Psychology, 56(3), 208-220. Gross, C. G., Bender, D. B., & Rocha-Miranda, C. E. (1969). Visual receptive field of neurons in inferotemporal cortex of the monkey. Science, 166, 1303-1306. Haaf, R. A., & Bell, R. Q. (1967). A facial dimension in visual discrimination by human infants. Child Development, 38(3), 893-899. Hancock, K. J., & Rhodes, G. (2008). Contact, configural coding and the other-race effect in face recognition. British Journal of Psychology, 99, 45-56. DOI:10.1348/000712607X199981 Haxby, J. V., Hoffman, E. A., & Gobbini, M. I. (2002). Human neural systems for face recognition and social communication. Biological Psychiatry, 51, 59-67. Hayward, W. G., Rhodes, G., & Schwaninger, A. (2008). An own-race advantage for components as well as configurations in face recognition. Cognition, 106, 1017-1027. Hepper, P. G. (1991). An examination of fetal learning before and after birth. Irish Journal of Psychology, 12, 95-107. Heron-Delaney, M., Anzures, G., Herbert, J. S., Quinn, P. C., Slater, A. M., Tanaka, J. W., Lee, K., &

121

Quantifying face exposure in infants and adults
Pascalis, O. (2011). Perceptual training prevents the emergence of the other race effect during infancy. PloS ONE, 6(5), 1-5. Hershenson, M. (1964). Visual discrimination in the human newborn. Journal of Comparative Physiological Psychology, 58(2), 270 ­ 276. DOI:10.1348/000712607X199981 Hirose, Y., & Hancock, P. J. B. (2007). Equally attending but still not seeing: an eye-tracking study of change detection in own- and other-race faces. Visual Cognition, 15(6), 647-660. Hole, G. J., George, P. A., Eaves, K., & Rasek, A. (2002). Effects of geometric distortions on facerecognition performance. Perception, 31, 1221-1240, DOI: 10.1068/p3252. Horowitz, F. D., Paden, L., Bhana, K., & Self, P. (1972). An infant-control procedure for studying infant visual fixations. Developmental Psychology, 7(1), 90. Izard, C. E. (1994). Innate and universal facial expressions: Evidence from developmental and crosscultural research. Psychological Bulletin, 115, 288-299. Jacques, C., D`Arripe, O., & Rossion, B. (2007). The time course of the inversion effect during individual face discrimination. Journal of Vision, 7(8), 1-9, DOI: 10.1167/7.8.3 Jeon, H., Moulson, M. C., Fox, N., Zeanah, C., & Nelson, C. A. III (2010). The effects of early institutionalization on the discrimination of facial expressions of emotion in young children. Infancy, 15(2), 209-221, DOI: 10.1111/j.1532-7078.2009.00007.x Johnson, M. H., & de Haan, M. (2001). Developing cortical specialization for visual-cognitive function: The case of face recognition. In J. L. McClelland & R. S. Seigler (Eds.). Mechanisms of cognitive development: Behavioural and neural perspectives (pp.253-270). Mahwah, NJ: Erlbaum. Johnson, M. H., Dziurawiec, S., Ellis, H., & Morton, J. (1991). Newborns' preferential tracking of facelike stimuli and its subsequent decline. Cognition, 40, 1-19.

122

Quantifying face exposure in infants and adults
Johnson, M. H., & Morton, J. (1991). Biology and Cognitive Development: The Case of Face Recognition, Blackwell, Oxford. Kagan, J., & Lewis, M. (1965). Studies of attention in the human infant. Merrill-Palmer Quarterly, 11, 95-127. Kalakanis, L., & Langlois, J. H. (2000). Do newborn infants prefer attractive faces? Unpublished manuscript in Hoss, R. A., & Langlois, J. H. (2003). In A. Slater & O. Pascalis (Eds.), The development of face processing in infancy and early childhood (pp. 99-117). New York: NOVA Science Publishers. Kanwisher, N., Mcdermott, J., & Chun, M. (1997). The fusiform face area: A module in human extrastriate cortex specialized for the perception of faces. Journal of Neuroscience, 17, 43024311. Kanwisher, N., Stanley, D., & Harris, A. (1999). The fusiform face area is selective for faces not animals. Neuroreport, 10(1), 183-187. Kanwisher, N., Tong, F., & Nakayama, K. (1998). The effect of face inversion on the human fusiform face area. Cognition, 68, B1-B11. Karmiloff-Smith, A. (1998). Development itself is the key to understanding developmental disorders. TRENDS in Cognitive Sciences, 2(10), 389-398. Karmiloff-Smith, A. (1995). Annotation: The extraordinary cognitive journey from foetus through infancy. Journal of Child Psychology and Psychiatry, 36(8), 1293-1313. Kelly, D. J., Quinn, P. C., Slater, A. M., Lee, K., Ge, L., & Pascalis, O. (2007). The other-race effect develops during infancy: Evidence of perceptual narrowing. Psychological Science, 18, 10841089. Kelly, D. J., Quinn, P. C., Slater, A. M., Lee, K., Gibson, A., Smith, M., Ge, L., & Pascalis, O. (2005).

123

Quantifying face exposure in infants and adults
Three-month-olds, but not newborns, prefer own-race faces. Developmental Science, 8(6), F31F36. Kestenbaum, R., & Nelson, C. A. (1992). Neural and behavioural correlates of emotion recognition in children and adults. Journal of Experimental Child Psychology, 54, 1-18. Klinnert, M. D. (1984). The regulation of infant behaviour by maternal facial expression. Infant Behaviour and Development, 7, 447-465. Kuefner, D., Macchi Cassia, V., Picozzi, M., & Bricolo, E. (2006). The effects of experience on the development of face recognition abilities: the emergence of an 'other-age' effect in infants. Paper presented at the Annual Meeting of the XVth Biennial International Conference on Infant Studies, Kyoto, Japan. Kuefner, D., Macchi Cassia, V., Picozzi, M., & Bricolo, E. (2008). Do all kids look alike? Evidence for an other-age effect in adults. Journal of Experimental Psychology: Human Perception and Performance, 34(4), 811-817, DOI: 10.1037/0096-1523.34.4.811. Kuhl, P. K., & Meltzoff, A. N. (1984). The bimodal development of speech in infancy. Science, 218, 1138-1141. Land, M. F., & Hayhoe, M. (2001). In what way do eye movements contribute to everyday activities? Vision Research, 41, 3559-3565. Langlois, J. H., Kalakanis, L., Rubenstein, A. J., Larson, A., Hallam, M., & Smoot, M. (2000). Maxims or myths of beauty? A meta-analytic and theoretical review. Psychological Bulletin, 126, 390-423 Langlois, J. H., Ritter, J. M., Roggman, L.A., & Vaughn, L.S. (1991). Facial diversity and infant preferences for attractive faces. Developmental Psychology, 27, 79-84. Langlois, J. H., Roggman, L. A., & Musselman, L. (1994). What is average and what is not average about attractive faces? Psychological Science, 5(4), 214-220.

124

Quantifying face exposure in infants and adults
Ludemann, P.M., & Nelson, C.A. (1988). Categorical representation of facial expressions by 7-month-old infants. Developmental Psychology, 24, 492-501 Lutz, C., Lockard, J., Gunderson, V., & Grant, K. (1998). Infant monkeys' visual responses to drawings of normal and distorted faces. American Journal of Primatology, 44, 169-174. Macchi Cassia, V., Kuefner, D., Picozzi, M., & Vescovo, E. (2009). Early experience predicts later plasticity for face processing: Evidence for the reactivation of dormant effects. Psychological Science, 20(7), 853-859. Macchi Cassia, V., Simion, F., & Umilta, C. (2001). Face preference at birth: the role of an orienting mechanism. Developmental Science, 4(1), 101-108. Mareschal D., & Quinn, P. C. (2001). Categorization in infancy. TRENDS in Cognitive Science, 5, 443450. Maurer, D., & Barrera, M. (1981). Infants` perception of natural and distorted arrangements of a schematic face. Child Development, 52(1), 196-202. Retrieved from: http://www.jstor.org/stable/1129230?origin=JSTOR-pdf Maurer, D., Le Grand, R., & Mondloch, C. J. (2002). The many faces of configural processing. TRENDS in Cognitive Science, 6, 255-260. Maurer, D., Lewis, T. L., Brent, H. P., & Levin, A. V. (1999). Rapid improvement in the acuity of infants after visual input. Science, 286, 108 ­ 110. McKone, E., Crookes, K., & Kanwisher, N. (2009). The cognitive and neural development of face recognition in humans. In M. S. Gazzaniga (Ed.), The Cognitive Neurosciences (IV edition), pp. 467-482. Cambridge, MA: Bradford Books. McKone, E., Kanwisher, N., & Duchaine, B. C. (2006). Can generic expertise explain special processing for faces? TRENDS in Cognitive Sciences, 11(1), 8-15

125

Quantifying face exposure in infants and adults
Meltzoff, A. N., & Moore, M. K. (1994). Imitation, memory, and the representation of persons. Infant Behaviour and Development, 17, 83-99. Michel, C., Caldara, R., & Rossion, B. (2006). Same-race faces are perceived mor holistically than otherrace faces. Visual Cognition, 14(1), 55-73. Ministry of Finance (2012, July 12). 2006 Census Highlights: Factsheet 11 Ethnic Origin and Visible Minorities. Retrieved from

http://www.fin.gov.on.ca/en/economy/demographics/census/cenhi06-11.html.
Mondloch, C., Le Grand, R., & Maurer, D. (2002). Configural face processing develops more slowly than featural face processing. Perception, 31, 553-566. Mondloch, C., Le Grand, R., & Maurer, D. (2003). Early visual experience is necessary for the development of some - but not all - aspects of face processing. In A. Slater & O. Pascalis (Eds.), The development of face processing in infancy and early childhood (pp. 99-117). New York: NOVA Science Publishers. Mondloch, C. J., Lewis, T. L., Budreau, D. R., Maurer, D., Dannemiller, J. L., Stephens, B. R., & KleinerGathercoal, K. A. (1999). Face perception during early infancy. Psychological Science, 10, 419422. Morales, M., Mundy, P., Delgado, C. E. F., Yale, M., Neal, R., & Schwartz, H. K. (2000). Gaze following, temperament, and language development in 6-month-olds: A replication and extension. Infant Behavior & Development, 23, 231-236. Morris, D. (2002) Peoplewatching: The Desmond Morris Guide to Body Language. Vintage, New York, USA. Morton, J., & Johnson, M. H. (1991). CONSPEC and CONLERN: a two-process theory of infant face recognition. Psychological Review, 98(2), 164-181.

126

Quantifying face exposure in infants and adults
Muir, D., & Field, J. (1979). Newborn infants orient to sounds. Child Development, 50, 431 ­ 436. Nelson, C. A. (2001). The development and neural bases of face recognition. Infant and Child Development, 10, 3-18. Nelson, C., Morse, P., & Leavitt, L. (1979). Recognition of facial expressions by seven-month-old infants. Child Development, 50, 1239-1242. Orlans, N. M., Piszcz, A. T., & Chavez, R. J. (2003). Parametrically controlled synthetic imagery experiment for face recognition testing. WBMA 2003 Proceedings of the 2003 ACM SIGMM Workshop on Biometrics Methods and Applications, 58-64. DOI: 10.1145/982507.982519 Palermo, R., & Rhodes, G. (2007). Are you always on my mind? A review of how face perception and attention interact. Neuropsychologia, 45, 75-92, DOI: 10.1016/j.neuropsychologia.2006.04.025. Parker, S. W., Nelson, C. W., & The Bucharest Early Intervention Project Core Group (2005). An eventrelated potential study of the impact of institutional rearing on face recognition, Development and Psychopathology, 17, 621-639. Pascalis O., & Bachevalier, J. (1998). Face recognition in Primates: a cross species study.

Behavioural Processes, 43, 87-96
Pascalis, O., de Haan, M., & Nelson, C. A. (2002). Is face processing species-specific during the first year of life? Science, 296, 1321-1323. Pascalis, O., & de Schonen, S. (1994). Recognition memory in 3- to 4-day-old human neonates. Neuroreport, 5(14), 1721-1724. Pascalis, O., de Schonen, S., Morton, J., Deruelle, C., & Fabre-Grenet, M. (1995). Mother`s face recognition by neonates: a replication and an extension. Infant Behaviour and Development, 18, 79-85. Pascalis, O., Scott, L. S., Kelly, D. J., Shannon, R. W., Nicholson, E., Coleman, M., & Nelson, C. A.

127

Quantifying face exposure in infants and adults
(2005). Plasticity of face processing in infancy. Proceedings of the National Academy of Sciences of the United States of America, 102(14), 5297-5300. Pelaez, M., Virues-Ortega, J., & Gerwitz, J. L. (2012). Acquisition of social referencing via discrimination training in infants. Journal of Applied Behaviour Analysis, 45, 23 ­ 36. Pereira, A. F., Yu, C., Smith, L. B., & Shen, H. (2009). A first-person perspective on a parent-child social interaction during object play. Proceedings of the 31st Annual Meeting of the Cognitive Science Society, Amsterdam, Holland. Retreived from http://www.indiana.edu/~dll/pub.html\ Pollack, S. D., & Kislter, D. J. (2002). Early experience is associated with the development of categorical representations for facial expressions of emotion. Child Development, 50(4), 1239-1242. Retreived from: http://www.jstor.org/stable/1129358?origin=JSTOR-pdf Quinn, P. C., Yahr, J., Kuhn, A., Slater, A. M., & Pascalis, O. (2002). Representation of the gender of human faces by infants: a preference for female. Perception, 31, 1109-1121. Reissland, N. (1988). Neonatal imitation in the first hour of life: Observations in rural Nepal. Developmental Psychology, 24, 464-469. Rhodes, G., Watson, T. L., Jeffery, L., & Clifford, C. W. G. (2010). Perceptual adaptation helps us identify faces. Vision Research, 50, 963-968, DOI: 10.1016/j.visres.2010.03.003. Ristic, J., Friesen, C. K., & Kingstone, A. (2002). Are eyes special? It depends on how you look at it. Psychonomic Bulletin & Review, 9(3), 507-513. Rousselet, G. A., Mace, M. J., Thorpe, S. J., & Fabre-Thorpe, M. (2007) Limits of Event-related Potential Differences in Tracking Object Processing Speed. Journal of Cognitive Neuroscience, 19(8), 1241-58. Russell, R., Sinha, P., Biederman, & Nederhouser, M. (2006). Is pigmentation important for face recognition? Evidence from contrast negation. Perception, 35, 749-759. DOI: 10.1068/p5490

128

Quantifying face exposure in infants and adults
Russo, F.A., Sandstorm, G.M. & Maksimowski, M. (in press) Mouth versus eyes: Gaze fixation during perception of sung interval size. Psychomusicology: Music, Mind & Brain. Sadeh, A., Acebo, C., Seifer, R., Aytur, S., & Carskadon, M. A. (1995). Activity-based assessment of sleep-wake patterns during the 1st year of life. Infant Behavior and Development, 18, 329-337. Retrieved from: http://www.sleepforscience.org/contentmgr/showdetails.php/id/215 Sangrigoli, S., Pallier, C., Argenti, A.-M., Ventureyra, V. A. G., & deSchonen, S. (2005). Reversibility of the other-race effect in face recognition during childhood. Psychological Science, 16(6), 440444. Scaife, M., & Bruner, J. S. (1975). The capacity for joint visual attention in the infant. Nature, 253, 265266. Scott, L. S., & Monesson, A. (2009). The origin of biases in face perception. Psychological Science, 20, 676-680, DOI: 10.1111/j.1467-9280.2009.02348.x. Scott, L. S., Shannon, R. W., & Nelson, C. A. (2005). Behavioural and electrophysiological evidence of species-specific face processing. Cognitive, Affective, & Behavioural Neuroscience, 5(4), 405416. Serrano, J. M., Iglesias, J., & Loeches, A. (1995). Infants` responses to adult static facial expressions. Infant Behaviour and Development, 18, 477-482. Simion, F., Macchi Cassia, V., Turati, C., & Valenza, E. (2001). The origins of face perception: Specific versus non-specific mechanisms. Infant and Child Development, 10, 59-65, DOI: 10.1002/icd.247. Slater, A., Quinn, P. C., Hayes, R., & Brown, E. (2000). The role of facial orientation in newborn infants' preference for attractive faces. Developmental Science, 3(2), 181-185. Slater, A., Quinn, P. C., Lewkowicz, D. J., Hayes, R., & Brookes, H. (2003). Learning of arbitrary adult

129

Quantifying face exposure in infants and adults
voice-face pairings at three months of age. In O. Pascalis, & A. Slater (Eds.), The development of face processing in infancy and early childhood (pp. 133-142). New York: NOVA Science Publishers. Smith, L. B. (2012). The sensory-motor dynamics of early word learning. Proceedings of the 42nd Annual Meeting of the Jean Piaget Society, 55. Retrieved from http://www.indiana.edu/~dll/pub.html Smith, L. B., Yu, C., & Pereira, A. F. (2011). Not your mother's view: the dynamics of toddler visual experience. Developmental Science, 14(1), 9-17. DOI: 10.1111/j.1467-7687.2009.00947.x Smith, L. B., Yu, C., & Pereira, A. (2007). From the outside-in: Embodied attention in toddlers. Proceedings of the European Conference on Artificial Life, Lisbon, Portugal. Retrieved from http://www.indiana.edu/~dll/pub.html Spangler, S. M., Freitag, C., Schwartzer, G., Vierhaus, M., Teubert, M., Lamm, B., Kolling, T., Graf, F., Goertz, C., Fassbender, I., Lohaus, A., Knopf, M, & Keller, H. (2011). Recognition of faces and Greebles in 3-month-old infants: Influence of temperament and cognitive abilities. International Journal of Behavioral Development, 35, 432-440. DOI: 10.1177/0165025411406565 Stack, D. M., & LePage, D. E. (1996). Infants' sensitivity to manipulations of maternal touch during faceto-face interactions. Social Development, 5(1), 41-55. Sugita, Y. (2008). Face perception in monkeys reared with no exposure to faces. Proceedings of the National Academy of Sciences, 105(1), 394-398. DOI: 10.1073pnas.0706079105 Tanaka, J. W., & Curran, T. (2001). A neural basis for expert object recognition. Psychological Science, 12, 43-47. Tanaka, J. W., Kiefer, M., & Bukach, C. (2004). A holistic account of the own-race effect in face recognition: evidence from a cross-cultural study. Cognition, 93, B1-B9, DOI:

130

Quantifying face exposure in infants and adults
10.1016/j.cognition.2003.09.011. Tarr, M. J. (2012). Stimulus Images. Center for the Neural Basis of Cognition and Department of Psychology, Carnegie Mellon University, http://www.tarrlab.org/ Tarr, M. J., & Cheng, Y. D. (2003). Learning to see faces and objects. TRENDS in Cognitive Sciences, 7(1), 23-30. Tronick, E. Z. (1989). Emotions and emotional communication in infants. American Psychologist, 44(2), 112-119. Tronick, E. Z. (1972). Stimulus control and the growth of the infant`s effective visual field. Perception & Psychophysics, 11(5), 373-376. Turati, C., Bulf, H., & Simion, F. (2008). Newborns' face recognition over changes in viewpoint. Cognition, 106, 1300-1321, DOI: 10.1016/j.cognition.207.06.005. Turati, C., Sangrigoli, S., Ruel, J., & de Schonen, S. (2004). Evidence of the face inversion effect in 4month-old infants. Infancy, 6(2), 275-297. Valentine, T. (1988). Upside-down faces: A review of the effect of inversion upon face recognition. British Journal of Psychology, 79, 471-491. Walton. G. E., & Bower, T. G. R. (1993). Newborns form prototypes in less than 1 minute. Psychological Science, 4(3), 203-205, DOI: 10.1111/j.1467-9280.1993.tb00488.x Walton, G. E., Bower, N. J. A., & Bower, T. G. R. (1992). Recognition of familiar faces by newborns. Infant. Behaviour and Development, 15, 265-269. Want, S. C., Pascalis, O., Coleman, M, & Blades, M. (2003). Face facts: Is the development of face recognition in early and middle childhood really so special? In O. Pascalis, & A. Slater (Eds.), The development of face processing in infancy and early childhood (pp. 133-142). New York: NOVA Science Publishers.

131

Quantifying face exposure in infants and adults
Willis, J., & Todorov, A. (2006). First impressions: Making up your mind after a 100-ms exposure to a face. Psychological Science, 17, 592-598, DOI: 10.1111/j.1467-9280.2006.01750.x Yoshida, H., & Smith, L. B. (2008). What's in view for toddlers? Using a head camera to study visual experience. Infancy, 13(3), 229 ­ 248. Retrieved from http://www.indiana.edu/~dll/pub.html Young-Browne, G., Rosenfeld, H. M., & Horowitz, F. D. (1977). Infant discrimination of facial expressions. Child Development, 48(2), 555-562. Yovel, G., Halsband, K., Pellig, M., Farkash, N., Gal, B., & Goshen-Gottstein, Y. (2012). Can massive but passive exposure to faces contribute to face recognition abilities Journal of Experimental Psychology: Human Perception and Performance, advance online publication, DOI: 10.1037/a0027077. Yu, C., Smith, L. B., Christensen, M., & Pereira, A. (2007). Two views of the world: Active vision in real-world interaction. Proceedings of the 29th Annual Meeting of the Cognitive Science Society, Nashville, TN, USA. Retrieved from http://www.indiana.edu/~dll/pub.html Yu, C., Smith, L. B., & Pereira, A. F. (2008). Embodied solution: The world from a toddler's point of view. in Proceedings of the IEEE 7th International Conference on Development and Learning, Monterey, CA, 97-102. Retrieved from http://www.indiana.edu/~dll/pub.html Yu, C., Smith, L. B., & Pereira, A. F. (2008). Grounding word learning in multimodal sensorimotor interaction. Proceedings of the 30th Annual Conference of the Cognitive Science Society, Washington, DC, 1017-1022. Retrieved from http://www.indiana.edu/~dll/pub.html Zhu Q, Song Y, Hu S, Li X, Tian M, Zhen Z, Dong Q, Kanwisher N, & Liu J. (2009). Heretability of the specific cognitive ability of face perception. Current Biology, 20(2), 137-142, DOI: 10.1016/j.cub.2009.11.067 .

132

Quantifying face exposure in infants and adults Appendices Appendix A. Infant Recruitment Materials

133

Quantifying face exposure in infants and adults

134

Quantifying face exposure in infants and adults

Participants Wanted:

Adults over the age of 18 wanted

BeeLab@Ryerson.ca

to participate in a research study

(416) 979 5000 ext 2189
BeeLab@Ryerson.ca

looking at what you see

(416) 979 5000 ext 2189
If interested, please contact the BEE Lab:
BeeLab@Ryerson.ca BeeLab@Ryerson.ca

on a normal day.

(416) 979 5000 ext 2189
or (416) 979 5000 ext. 2189
BEELab@ryerson.ca

(416) 979 5000 ext 2189
BeeLab@Ryerson.ca BeeLab@Ryerson.ca BeeLab@Ryerson.ca BeeLab@Ryerson.ca BeeLab@Ryerson.ca BeeLab@Ryerson.ca BeeLab@Ryerson.ca

(416) 979 5000 ext 2189

(416) 979 5000 ext 2189

(416) 979 5000 ext 2189

(416) 979 5000 ext 2189

Adult Recruitment Materials

(416) 979 5000 ext 2189

(416) 979 5000 ext 2189

Appendix B.

(416) 979 5000 ext 2189

135

Quantifying face exposure in infants and adults Appendix C. Infant Consent Form

DEPARTMENT OF PSYCHOLOGY FACULTY OF ARTS

Ryerson University Consent Agreement for participation in the study: Here's looking at you: quantification of quotidian exposure to faces. You and your infant are being asked to participate in a research study. Before you give your consent to be a volunteer, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do. Investigators: Dr. Margaret Moulson, PhD, department of Psychology, Ryerson University and Nicole Sugden, BA Psychology, first year, Masters' Student, department of Psychology, Ryerson University. Purpose of the Study: Twenty 1-month old infants, and twenty 3-month old infants are being recruited to participate in this study. This study is designed to look at what infants see in their daily lives. We are particularly interested in examining what classes of objects (faces, houses, cars, birds, for example) to which infants have the most exposure. Description of the Study: If your child is a participant in this study, you and your infant will be asked to do the following: Attend Ryerson University or have an investigator visit your home for twenty minutes to:  complete a five-minute one-page questionnaire about yourself, the activities of a normal day, and the hours your infant spends awake,  receive a five-minute training on the operation of a small smiley-face video-camera on a headband,  receive a five-minute explanation of how to use a booklet of pre- and post-recording questionnaires (including the pre-recording check-list),  take the video-camera-headband and their accessories home with you, if you are at Ryerson.

136

Quantifying face exposure in infants and adults Place the video-camera headband on your infant's head to record while your infant is awake, over the course of one week. This requires you to:  complete the one-minute pre-recording questionnaire (about your infant's location, the time, the date, and the people with you) and check-list which reminds you of areas in which video-recording should not occur,  keep the video-camera headband on your infant's child until your child falls asleep, becomes fussy, or you feel you should stop recording,  watch your infant to ensure that the headband is not uncomfortable for them,  complete the one-minute post-recording questionnaire (about your location and the time),  re-charge the video-cameras' battery overnight. Attend Ryerson University at the end of the week with your infant for one hour to:  complete a single-page five-minute questionnaire about your experience using the videocamera and your comfort with camera,  return the video-camera and it's accessories,  have your infant complete a twenty-minute (maximum) computer-based face discrimination task. During this task your infant will remain on your lap, but you will be blindfolded, so that you do not influence your infant's reactions to the faces. (You may view the faces your child was shown after the task.) Your infant will be shown images of faces of different ages, genders, and sexes, either one- or two-at-a-time and we will measure how much time your infant looks at each face as well, when presented two faces, if your infant looks more at one face than the other face. Your infant's eyes will be videorecorded during this time so that we can review, more precisely, how much time your infant spent looking at each face. This will help us determine if your infant can tell the difference between the faces.  receive a copy of the video of your infant's perspective from the week,  receive an honorarium of $25 for your infant's participation. If the camera malfunctions or you experience any difficulties with it, you may be asked to return the the Ryerson University Campus or have an investigator visit your home once for ten minutes or twice for five minutes per visit to have them repaired or exchanged. When your infant is 8- or 9- months-old, we will contact you again to see if you would be interested in attending Ryerson University again with your infant for one hour to have your infant complete the computer-based face discrimination task a second time. You may choose, at the later time, to participate or not participate in this second portion of the study. Your choice to participate or not participate in the second portion of the study will not impact your participation in this study. 137

Quantifying face exposure in infants and adults

What is Experimental in this Study: None of the procedures or questionnaires used in this study are experimental in nature. The only experimental aspect of this study is the gathering of information for the purpose of analysis. Risks or Discomforts: There is no risk to your infant from the act of video-taping. The headband they will be asked to wear is designed to be comfortable and fuzzy. If your infant does not enjoy wearing the headband, you may clip the video-camera to a different headband or other headwear or discontinue your child's participation in the study. Since your child is video-taping, there is a risk that you may be uncomfortable with the act of video-taping during the course of a normal day. If, for any reason, you feel uncomfortable video-recording, stop recording. The people who you are video-recording may object to your recording or request that they not be recorded. If at any time you are requested not to record, you must stop recording. If you begin to feel uncomfortable, you may discontinue participation in the study either temporarily or permanently. With the computer-based task in which your child will participate at the end of the study, your child may become bored or fussy. If you feel that your child is no longer interested in participating in the computer-based task, you may take a break or discontinue your child's participation in the task or the study. Benefits of the Study: We currently have no measurement of the amount of time people spend looking at other people, faces, and ordinary objects; this study is designed to provide an estimation of the amount of time people spend looking at different objects in their environment. The goal of this research is to quantify the everyday exposure received by adults to faces, people, cars, birds, and other objects. These findings will have important implications for existing theories of development of face expertise and provide a foundation for examining similar questions in infants and children. Although it is expected that this study will add to the body of knowledge of face perception and expertise, it is not expected that you will receive any benefits from participating in this study. Confidentiality: Any information obtained in connection with this study will remain confidential. All participants in this study will have their information protected using a participant ID number. Any written notes (including questionnaires, check-lists, and surveys) and video recordings will be identified only by this participant ID number, will be stored separately from the participant consent forms, and will be accessed only by those individuals directly involved in the study. Hard copies of the data will be stored in locked filing cabinets in the BEE Lab; electronic video and data files will be stored on password-protected media in the BEE Lab. The BEE Lab is locked and only accessible to members of the lab. All data will be pooled and published in aggregate form only. 138

Quantifying face exposure in infants and adults Since most journals require data to be stored for five years post-publication, this data will be stored for this period of time prior to being destroyed. No video from your participation in this study will be released to anyone outside of the BEE Lab. Incentives to Participate: A twenty-five-dollar honorarium is offered for your participation in this research. If you decide that you do not wish to participate prior to your first attempt to record, you will receive no compensation. If, after you begin any of your recording sessions, you choose to discontinue recording at any time, you will still receive the full honorarium upon return of the video-camera and it's accessories. In addition, you will receive a DVD copy of the video recorded from your infant's perspective during the week of video-recording. Costs and/or Compensation for Participation: There are no anticipated costs associated with your participation in this research. You will be receive a $25 honorarium upon completion of this research, in addition to a DVD copy of the video footage recorded from your child's perspective.. Voluntary Nature of Participation: Participation in this study is voluntary. Your choice of whether or not to participate will not influence your future relations with Ryerson University. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time without penalty or loss of benefits to which you are allowed. At any particular point in the study, you may refuse to answer any particular question or stop participation altogether. Questions about the Study: If you have any questions about the research now, please ask. If you have questions later about the research, you may contact. Principal Investigator: Nicole Sugden Telephone Number: (416) 979 5000 ext. 2189 E-mail Address: BeeLab@ryerson.ca

Research Supervisor: Margaret Moulson, PhD Telephone Number: (416) 979 5000 ext. 2661 E-mail Address: mmoulson@psych.ryerson.ca If you have questions regarding your rights as a human subject and participant in this study, you may contact the Ryerson University Research Ethics Board for information. Research Ethics Board c/o Office of the Vice President, Research and Innovation 139

Quantifying face exposure in infants and adults Ryerson University 350 Victoria Street Toronto, ON M5B 2K3 416-979-5042 Agreement: Your signature below indicates that you have read the information in this agreement and have had a chance to ask any questions you have about the study. Your signature also indicates that you agree to be in the study and have been told that you can change your mind and withdraw your consent to participate at any time. You have been given a copy of this agreement. You have been told that by signing this consent agreement you are not giving up any of your legal rights. ____________________________________ Name of Infant Participant (please print)

____________________________________ Name of Parent Participant (please print)

_____________________________________ Signature of Parent

__________________ Date

_____________________________________ Signature of Investigator

__________________ Date

140

Quantifying face exposure in infants and adults Appendix D. Adult Consent Form

DEPARTMENT OF PSYCHOLOGY FACULTY OF ARTS

Consent Agreement for participation in the study: Here's looking at you: quantification of quotidian exposure to faces. You are being asked to participate in a research study. Before you give your consent to be a volunteer, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do. Investigators: Nicole Sugden, BA, first year Masters' Student, Department of Psychology, Ryerson University Dr. Margaret Moulson, PhD, Assistant Professor, Department of Psychology, Ryerson University Purpose of the Study: This study is designed to look at what people see in their daily lives. We are particularly interested in examining what classes of objects (faces, houses, cars, birds, for example) people have the most exposure to. Thirty-two adults, over the age of 18, who do not wear glasses or can wear contacts for at least two hours per day, 20 1-month old infants, and 20 3-month old infants are being recruited to participate in this study. Description of the Study: As a participant in this study, you will be asked to do the following: Come to the Brain and Early Experiences Lab at Ryerson University for an initial 30-minute appointment. During this initial appointment you will:  complete a one-page questionnaire about yourself, the activities of a normal day, and the hours you spend awake;  have a discussion with the principal investigator about privacy concerns and learn about areas in which video-recording is appropriate and areas in which video-recording is not appropriate;  receive a five-minute training on the operation of a pair of video-camera glasses;  receive a one-minute explanation of how to use a booklet of pre- and post-recording questionnaires;  take the video-camera glasses and their accessories home with you. 141

Quantifying face exposure in infants and adults Record six 2-hour randomly-selected periods over the course of two weeks. Each 2-hour recording session requires you to:  complete the one-minute pre-recording questionnaire (about your location, the time, the date, and the number of people with you) and check-list which reminds you of areas in which video-recording should not occur;  video-record your surroundings for two hours with the video-camera glasses;  complete the one-minute post-recording questionnaire (about your location and the time);  re-charge the video-camera glasses' battery overnight. Return to the Brain and Early Experiences Lab at Ryerson University at the end of the two weeks for a final 60-minute appointment. During this final appointment you will:  complete a single-page questionnaire about your experience using the video-camera glasses;  return the video-camera glasses and their accessories;  complete a 20-minute computer-based face discrimination task;  receive an honorarium of $25 for your participation. If the glasses malfunction or you experience any difficulties with them, you may be asked to return the Ryerson University Campus to have them repaired or exchanged. What is Experimental in this Study: None of the procedures or questionnaires used in this study are experimental in nature. This is an observational study in which we gather information for the purpose of analysis. Risks or Discomforts: Since you are video-recording, there is a risk that you may be uncomfortable with the act of video-recording during the course of your normal day. If, for any reason, you feel uncomfortable video-recording, stop recording. The people who you are video-recording may object to your recording or request that they not be recorded. If at any time you are requested not to record, you must stop recording. If you begin to feel uncomfortable, you may discontinue participation in the study either temporarily or permanently. During the face discrimination task you may become bored. You may take a break or discontinue your participation in the study if you become bored. Benefits of the Study: We currently have no measurement of the amount of time people spend looking at other people, faces, and ordinary objects; this study is designed to provide an estimation of the amount of time people spend looking at different objects in their environment. The goal of this research is to quantify the everyday exposure received by adults to faces, people, cars, birds, and other objects. These findings will have important implications for existing theories of development of face expertise and provide a foundation for examining similar questions in infants and children. Although it is expected that this study will add to the body of knowledge of face perception and 142

Quantifying face exposure in infants and adults expertise, it is not expected that you will receive any direct benefits from participating in this study. Confidentiality: Any information obtained in connection with this study will remain confidential. All participants in this study will have their information protected using a participant ID number. Any written notes (including questionnaires, check-lists, and surveys) and video recordings will be identified only by this participant ID number, will be stored separately from the participant consent forms, and will be accessed only by those individuals directly involved in the study. The video recordings will have audio information removed upon receipt by the BEE Lab. A maximum of four BEE Lab members will view each video-recording session, for coding purposes only. Hard copies of the data will be stored in locked filing cabinets in the BEE Lab; electronic video and data files will be stored on password-protected media in the BEE Lab. The BEE Lab is locked and only accessible to members of the lab. All data will be pooled and published in aggregate form only. Since most journals require data to be stored for five years post-publication, this data will be stored for this period of time prior to being destroyed. No video from your participation in this study will be released to anyone outside of the BEE Lab. Incentives to Participate: A $25 honorarium is offered for your participation in this research. If you decide that you do not wish to participate prior to your first attempt to record, you will receive no compensation. If, after you begin any of your recording sessions, you choose to discontinue recording at any time, you will still receive the full honorarium upon return of the video-camera glasses and their accessories. Costs and/or Compensation for Participation: There are no anticipated costs associated with your participation in this research. You will receive a $25 honorarium upon completion of this research. Voluntary Nature of Participation: Participation in this study is voluntary. Your choice of whether or not to participate will not influence your future relations with Ryerson University. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time without penalty or loss of benefits to which you are allowed. At any particular point in the study, you may refuse to answer any particular question or stop participation altogether. Questions about the Study: If you have any questions about the research now, please ask. If you have questions later about the research, you may contact: Principal Investigator: Nicole Sugden Telephone Number: (416) 979 5000 ext. 2189 E-mail Address: BeeLab@ryerson.ca Research Supervisor: Margaret Moulson, PhD Telephone Number: (416) 979 5000 ext. 2661 143

Quantifying face exposure in infants and adults E-mail Address: mmoulson@psych.ryerson.ca

If you have questions regarding your rights as a human subject and participant in this study, you may contact the Ryerson University Research Ethics Board for information. Research Ethics Board c/o Office of the Vice President, Research and Innovation Ryerson University 350 Victoria Street Toronto, ON M5B 2K3 416-979-5042 Agreement: Your signature below indicates that you have read the information in this agreement and have had a chance to ask any questions you have about the study. Your signature also indicates that you agree to be in the study and have been told that you can change your mind and withdraw your consent to participate at any time. You have been given a copy of this agreement. You have been told that by signing this consent agreement you are not giving up any of your legal rights. ____________________________________ Name of Participant (please print)

_____________________________________ Signature of Participant

__________________ Date

_____________________________________ Signature of Investigator

__________________ Date

144

Quantifying face exposure in infants and adults Appendix E. Infant First Appointment Questionnaire
Age: Gender: Ethnic group(s):

How many hours do you spend awake in an average day? How many hours do you sleep per night, in an average night? With whom do you spend most of your time? (Please describe relationship to you, not name.) What gender is this person? Approximately how old is this person? (Example: 20's, 30's, 40's) To what ethnic group(s) does this person belong? With whom do you spend most of the rest of your time? What gender is this person? Approximately how old is this person? To what ethnic group(s) does this person belong? To what ethnic group(s) do your parents belong? How old are your parents (approximately)? What language(s) are spoken in your home? With how many people do you live? Do you attend any mommy-and-me or other types of classes? Yes / No

If you attend mommy-and-me-type classes, how many of these classes do you attend in an average week? What type of class(es) do you attend? Do you go anywhere else at least once per week, during an average week? Yes / Example: grandparents', play-date, doctor's... If yes, where do you go? (Please describe type of location.) No

145

Quantifying face exposure in infants and adults
What are your favorite toys, currently? Do these toys have faces? Yes / No

How many pets do you live with and spend time interacting? With what type of pet(s) do you spend the most time? How many hours per day or per week do you spend watching tv/pc/media? What is your temperament? Easy / Difficult / Shy at first / Very Calm / No consistent temperament

146

Quantifying face exposure in infants and adults Appendix F. Adult First Appointment Questionnaire Age: Gender: With what ethnic group(s) do you identify? What language(s) do you speak? Do you work? Yes / No

How many other people do you live with? a) 0 b) 1 c) 2 d) 3 e) 4 or more Were you born in Canada? Yes / No

If no, when did you come to Canada to live? Do you attend school? Yes / No

If you work and/or attend school, how do you get to and from work and/or school? a) drive b) transit/subway/bus/streetcar/train c) bicycle d) walk e) other: ______________________ How/where did you hear about this study? How many hours, per day, on average, do you spend interacting with people in person on weekdays? How many hours, per day, on average, do you spend interacting with people, in person, on weekends? 147

Quantifying face exposure in infants and adults At what time do you usually wake up on weekdays? At what time do you usually go to bed on weekdays? At what time do you usually wake up on weekends? At what time do you usually go to bed on weekends? Are you a collector of or expert at something (example: car expert, stamp collector, bird watcher, model train builder...)? Yes / No If yes, what is your area of expertise? How many hours, per week, do you spend with your area of expertise? Please rate the following questions on a scale of 1 ­ 5 (1 being strongly disagree and 5 being strongly agree): My ability to recognize people by their face is equal to that of other people. 1 2 3 4 5 My ability to recognize people by their face is worse than that of other people. 1 2 3 4 5 If I meet someone once, I will recognize them if I see them again one or two days later. 1 2 3 4 5 I remember people by characteristics of their face (e.g., small nose, big eyes, etc). 1 2 3 4 5 I am better at remembering faces of people who look like me. 1 2 3 4 5 Recognizing people by their face is important to me. 1 2 3 4 5 If I meet someone in one context (e.g., at work) and then see them in another context (e.g., at the gym) I will not recognize them. 1 2 3 4 5 I am not required to recognize people in my day-to-day interactions 1 2 3 4 5 148

Quantifying face exposure in infants and adults Appendix G. Privacy Agreement Agreement to Respect Privacy While Video-Recording While video-recording, there are privacy concerns of which you must be aware at all times. You must be vigilant to ensure that you are not violating the privacy of the people you record. What this means is that you cannot record when the person you are recording has a reasonable expectation of privacy. In other words, if the person being recorded is in a situation where they reasonably should expect not to be recorded, you cannot record. In some public places, like in the street or a transit station, for example, there is no reasonable expectation of privacy. In others, however, like in a change-room, rest-room, medical office, or dental office, recording is forbidden since people in these places have a reasonable expectation of privacy. What are the situations in which you anticipate being this week where you should not record? ______________________________________________________________________________ [Feedback provided by researcher] What are the situations in which you anticipate being this week where you can record? ______________________________________________________________________________ [Feedback provided by researcher] Are you comfortable with this? _________________________________________________________ There is a third, less clear situation, in which you are entering a private area (for example, a private office or someone`s home) or will be interacting face-to-face with people in close proximity (for example, going out to dinner with a group of friends). In these situations, we ask that you provide the people with whom you will be interacting or whose home or office you will be visiting with an inquiry card` and ask them if they are comfortable with you recording while you are there. If they say yes`, you may continue recording. If they say no`, you must turn the camera off. If they have questions, you may answer the questions or you may direct them to the BEE Lab, whose contact information is on the back of the card. What are the situations in which you anticipate being this week where you will offer the inquiry card`? 149

Quantifying face exposure in infants and adults ______________________________________________________________________________ [Feedback provided by researcher] Are you comfortable with this? _________________________________________________________ Understandably, there may be some situations in which you may not be sure whether or not recording is appropriate. In these situations, please do not record. If you record in a situation and then, afterwards, are unsure as to whether recording was appropriate, please advise the BEE Lab by telephone or email and we will happily discuss the situation with you. Alternatively, if contacting the BEE Lab is not possible, please note on your post-recording questionnaire that you were not sure about the recording and why you were unsure. Any inappropriate recordings will be deleted without anyone ever watching the video. What are situations in which you are not clear whether recording is appropriate? ______________________________________________________________________________ [Feedback provided by researcher] What do you think you should do in these situations? ______________________________________________________________________________ [Feedback provided by researcher] Do you have any questions? ______________________________________________________________________________ [Feedback provided by researcher] I understand where I can film and I cannot film. I agree only to film in areas in which I believe filming is appropriate and to stop filming where I enter an area where I believe filming is inappropriate. I understand that I can discontinue filming when I feel uncomfortable, that there is no penalty for this, and that I am encouraged only to film when I am comfortable filming. I agree to stop filming when I feel uncomfortable.

150

Quantifying face exposure in infants and adults I understand that I must provide an inquiry card` to people who have questions about filming, the project, or the glasses I am wearing. If they have questions I do not feel comfortable answering or cannot answer, I will direct them to contact the BEE Lab. If they are not comfortable with me filming I agree to stop filming and/or leave the area. I will call the BEE Lab and ask if I have any questions or concerns.

______________________________________________ Signature of Participant

_______________________ Date

______________________________________________ Signature of Investigator

_______________________ Date

151

Quantifying face exposure in infants and adults Appendix H. Infant Interest Cards
What am I doing? My infant is participating in a research project for Ryerson University, trying to find out how many faces people see in the course of a normal day. They are video-recording (with the smiley face) their normal day. Who will see this video? Only researchers at Ryerson. Will there be sound when the video is viewed? No. What do you do if you do not want me to record? Please let me know and I will happily turn the camera off. Do you have more questions? Please contact the BEELab.

The BEE Lab
Ryerson University
BEELab@Ryerson.ca

www.Ryerson.ca/BeeLab (416)979-5000 ext. 2189

152

Quantifying face exposure in infants and adults Appendix I. Adult Interest Cards
What am I doing? I am participating in a research project for Ryerson University, trying to find out how many faces people see in the course of a normal day. I am videorecording (with my sunglasses) my normal day. Who will see this video? Only researchers at Ryerson. Will there be sound when the video is viewed? No. What do you do if you do not want me to record? Please let me know and I will happily turn the camera off. Do you have more questions? Please contact the BEELab.

The BEE Lab
Ryerson University
BEELab@Ryerson.ca

www.Ryerson.ca/BeeLab (416)979-5000 ext. 2189

153

Quantifying face exposure in infants and adults Appendix J. Infant Pre/Post-Recording Check-List Questionnaire Date: Time: ____________________ am / pm

Location (where am I)?*

How many people am I with? ______

Do I usually come to this location? Y / N Are there a lot of people at this location? Y / N

How am I being transported? (carried in arms, pram, car seat...)

Can I see the person (or people) that I came here with?

Y / N / Sometimes

I believe I am allowed to video-record in this location. I believe that this is a location with no expectation of privacy by the people here. I agree to stop recording if I feel continuing to record will violate privacy.

No No No

Yes Yes Yes Yes Yes

I agree to stop recording and/or leave if someone asks me to stop recording and/or No leave. I agree to stop recording if I enter any area in which recording is not allowed. No

I agree to stop recording if I feel uncomfortable continuing to record No Yes *** If you answered 'No' to any of the questions in the table, do not video-record.

Post-recording questions: Time: _________________ am / pm Location (where am I)?*

Do I usually come to this location? Y / N

Are there are a lot of people at this location? Y / N

154

Quantifying face exposure in infants and adults How many people am I with? _________ Why did I stop recording? a) fell asleep, b) became fussy, c) other_________ If yes`, what were they?

Were there any issues with recording? Y / N

Do I believe that recording was appropriate in this location? Y / N If no`, why do I believe recording was not appropriate in this location?

If no`, do I feel I should contact the BEE Lab? Y / N If yes`, please email: BEELab@ryerson.ca or call: (416) 979-5000 ext. 2189 *For your location, please do not include addresses, only a general description of where you are. For example: business office, classroom, in the street, in a car, at home...

155

Quantifying face exposure in infants and adults Appendix K. Adult Pre/Post-Recording Check-List Questionnaire Date: Time: ____________________ am / pm

Location (where am I)?*

How many people am I with? ______

Do I usually come to this location? Y / N

Are there a lot of people at this location? Y / N

I believe I am allowed to video-record in this location. I believe that this is a location with no expectation of privacy by the people here. I agree to stop recording if I feel continuing to record will violate privacy.

No No No

Yes Yes Yes Yes Yes

I agree to stop recording and/or leave if someone asks me to stop recording and/or No leave. I agree to stop recording if I enter any area in which recording is not allowed. No

I agree to stop recording if I feel uncomfortable continuing to record No Yes *** If you answered 'No' to any of the questions in the table, do not video-record.

Post-recording questions: Time: ____________ am / pm Location (where am I)?*

Do I usually come to this location? Y / N

Are there are a lot of people at this location? Y / N

How many people am I with? _________

Why did I stop recording? a) 2 hours were up b) battery died c) other: _______

156

Quantifying face exposure in infants and adults Were there any issues with recording? Y / N If yes`, what were they?

Do I believe that recording was appropriate in this location? Y / N If no`, why do I believe recording was not appropriate in this location?

If no`, do I feel I should contact the BEE Lab? Y / N If yes`, please email: BEELab@ryerson.ca or call: (416) 979-5000 ext. 2189

*For your location, please do not include addresses, only a general description of where you are. For example: business office, classroom, in the street, in a car, at home...

157

Quantifying face exposure in infants and adults Appendix L. Directions for the Infant Camera

To start recording: - Press and hold power button for 3 seconds o Lights will blink and turn on - Press and hold record button for 3 seconds o Lights will blink and turn off To stop recording: - Press and hold record button for 3 seconds o Lights will blink and turn on - Press and hold power button for 3 seconds o Lights will blink and turn off Power button Record button Don't use button

158

Quantifying face exposure in infants and adults Appendix M. Directions for the Adult Camera

To Turn On: 1) Press and hold the Power` button until the red light blinks and goes on. 2) Press and hold the Record` button for a count of two-Mississippi 3) Check to ensure the GREEN light is blinking 4) Check to ensure the RED light is NOT blinking If the RED light is blinking: a. Hold the record button to stop recording b. Repeat steps 2 ­ 4 until ONLY the GREEN light is blinking To Turn Off: 1) Press and hold the Record` button for a count of two-Mississippi 2) Check to ensure the GREEN light is OFF and the RED light is ON 3) Press and hold the Power` button until the red light blinks and goes off 4) Re-charge the battery overnight

159

Quantifying face exposure in infants and adults Appendix N. FaceGen Face Stimuli Exemplars

160

Quantifying face exposure in infants and adults Appendix O. Coding Guide

SPY GOGGLES STUDY
Video Coding 101: Coding and Data Entry Guide

The goal of video coding is to quantify the regular exposure both adults and infants receive to faces as part of their normal day. As a video coder for this project, it is your job to make sure that the videos are coded as accurately as possible. This coded data then has to be entered into SPSS so that it can be analyzed. The goal of this guide is to help to make these tasks easier.

161

Quantifying face exposure in infants and adults What this guide will explain:
Coding Speed Coding Methods What are faces? What has a face? How to code second-by-second? How to use the coding scheme? Subject & Video # Coder Name & Date Coding Sheet & Viewer Video Length Face # Start & End Time Sex Age Race Type Medium View Interaction Proximity Surround Invert Smile Other emotion Notes Coding Issues (Ruined, Inappropriate, or Faceless Video) Quick Tips (Repeating Faces and Objects, Reflections) Frequently Asked Questions Environment, Houses, Cars, and Birds Finishing a Video 5 5-6 6 6 6 7 7 8 8 8 9 9 9 10 11 11 12 13 14 15 16 17 ­ 18 19 ­ 21 22

Page
3 3 4 4 5

162

Quantifying face exposure in infants and adults
Data Entry SPSS Data Quality Checks Data Saving Proximity Exemplar Exemplars 23 ­ 25 26 ­ 27 28 29 - 32

Getting Started: Coding Speed: Coding should occur at 0.25 or 0.3 viewing speed. Coding at 0.5 speed is the MAXIMUM speed at which to code video. Coding 0.5 speed is only for instances where the video has been determined to, upon initial viewing, contain no faces. How: In windows media player, right click the screen; select 'video enhancements', select 'play speed', move the slider to 0.5 or less. Sometimes the slider will not move to speeds slower than 0.5. In this case, please use the mouse to toggle play/pause, which will slow down the progression of the video. Why? 'Faces are fast. When the head movement of a participant is going in the opposite direction of a person that comes into their field of view, the face of that person can fly by, making it hard to even see the face. For this reason, coding has to be done at 0.5 speed of the video, at maximum. Coding Methods: There are many ways to code. The transitional way is to code by watching the video second-bysecond and coding for each face as you see it, until the end of the video. This tactic works well when there are not many faces in a video (as when a participant is at home alone) or when there are a lot of non-repeating faces (as when a participant is walking down a crowded street). The coding sheet does not need to be organized by time. You could choose one face and follow it to the end of the video and then re-start the video, selecting a second face to follow to the end. This process would be repeated for each face (or several faces) until all faces are coded. This tactic may work better if there are multiple repeating faces in a video (as when the participant is 163

Quantifying face exposure in infants and adults having dinner with a group of friends or in a store where the same shoppers are seen multiple times). Choose a method of coding that best suits the video you're watching and what is easiest for you. Preview your video: Previewing isn't cheating, it's testing the waters before you jump in! To have a feel for the video you are about to code. Watch the video at normal speed (viewing not coding) to understand what the video is about and what to expect when later coding. This can give an idea of both how long coding should take and which coding method is best. Now that you're ready to code what are you looking for?

Faces: What are faces? The eyebrows, eyes, nose, and mouth are the part of the face in which we are interested since these are the internal features of the face. These internal facial features are what is typically use to identify a visual stimulus as a face by both adults (Berisha, Johnston, & McOwan, 2010) and infants (Humphreys, Gosselin, Schyns, & Johnson, 2006). Additionally, the eyes and mouth areas are especially diagnostic of facial expressions of emotion (Gerhardstein, Hipp, Corbet, Zhang, & Yin, 2010). Please pay special attention to the eye and mouth areas in the face when coding facial expressions of emotion Essentially, if you can see any or all of the eyebrows, eyes, nose, and/or mouth (and thereby know it is a face) code it as a face. In addition to the fact that these are areas diagnostic of faces, if only a single part of the face (for example an eye) is in the field of view of the camera, the rest of the face (the eyebrows, other eye, nose, and mouth, for example) is still available in the field of view of the participant. Using the eyebrows, eyes, nose, and mouth as the face area`, if you see something that you identify as 'face', then the participant has likely also identified it as a face. What has a face? Many things have faces and we code for all of them. Understandably, when people consider 164

Quantifying face exposure in infants and adults faces they usually think of real, live, peoples' faces. People, however, are not the only faces present in our visual world. Animals have faces and we will be coding for these. Stuffed animals, rubber ducks, photos, statues, and art can have faces, and we will be coding for these. T-shirts, blankets, and wall art sometimes has faces, and we will be coding for these. Skull faces, book sleeves, posters, cartoon faces, artistic renderings of faces, and other not-quite-real-faces are all considered to be 'faces' and we'll be looking for these to code for them. Code for anything that has a face (any or all of eyebrow(s), eye(s), nose, or mouth(s)). Do not code for people generally. The backs of peoples' heads do not (usually) have faces, and don't count as faces. We are coding for faces alone. This also means that if someone's feet, legs, hips, stomach, chest, and neck are all on film but there is no visible face, we can't code this as a face. Yes, it is logical to expect that the thing that the participant was seeing probably did have a head and face, but if it's not visible at all, don't code for it. Caution: mannequins and other display items do not always have faces, even though it seems like they should have faces. How do I code second-by-second? When coding second-by-second, this means that essentially each second is 'owned' by one or more faces. Many faces can own the same second, but a single face cannot own the same second twice. Correct coding:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

1 1

204 206 207 210

Not-quite-correct coding:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

1 1

204 206 206 210 If face 1 is already present at second 6, it cannot be present twice in second 6!

How to use the coding scheme: Subject #: The subjects are organized by age and by participant numbers. The letters that precede the numbers tell you the age of the participant whose video you're coding. FVP or P are adult 165

Quantifying face exposure in infants and adults videos. IO and IT are infant videos. IO are Infant One month while IT are Infant Three month videos. The numbers that come after the letters are the number of the participant of that age group. Please include both the alpha- and numeric portions of the participant numbers, since this is the whole of the participant number and without the whole participant number it would be difficult or impossible to determine the participant to which the coded video belongs. Video #: The video are numbered by day (D - - ) and video of that day (V - -). The subject number and the video number together constitute the name of the video. Please write the last six characters of the video name in the video number box. Example: name of the video file: io04d04v04.avi record this as: Subject#: i o 0 4 Video #: d04v04

Example: name of the video file: fvp04d04v04.avi OR p04d04v04.avi Record this as: Subject#: p 0 4 Video#: d 0 4 v 0 4

Coder name: Please print your initials (the first letter of your first name and first letter of your last name). Date: Please print the date on which the video was coded. Coding sheet updated: Please check or 'x' this if you have updated the video coding sheet and completed a confidentiality agreement. Viewer number: Each video viewer will place their initials at the end of the file name. Please ensure that you are coding only videos that have not been coded or have only been coded by Nicole. Double check for the end-of-file initials (which will look like: io04d04v04ns.avi, which indicates Nicole has already watched the video, while io04d04v04.avi indicates no one has watched the video) and 166

Quantifying face exposure in infants and adults circle whether you are the first or second video viewer. Video Length: Please record how long the video you're coding is in seconds. If the video has any 'ruined' sections or starts or ends early, please adjust the length to reflect these issues. Face #: Each individual face gets a number. This means that if there are three people with whom the participant is interacting, persons X, Y, and Z, each of these people gets their own number, let's say 1, 2, and 3. Example: Person X walks into the field of view and stays there from 0 to 7 seconds. Person Y then walks into the field of view at 2 seconds and then covers their face at 4 seconds. Person Y uncovers their face at 6 seconds and then walks out of the field of view of the participant at 10 seconds. Person Z pops into the film at 5 seconds, briefly looks away from 8 ­ 9 seconds, and then looks back at the participant at 10 ­ 11 seconds, after which they leave the scene. In terms of face numbering, this scenario would be coded as: If X=1, Y=2, and Z=3 (these are arbitrary numbers you assign as a coder) then: Face Number 1 2 3 2 3 Start and end times for faces: The start second is the first second at which the face appears in the video. The end second is the last second during which the face is present in the video. If a face disappears at one second and then reappears during the next second, please code this as two `face interactions`, placing each on separate rows in the spreadsheet. If a face disappears and then reappears during the same second, please do not code this face as disappearing and the reappearing in the same second on the spreadsheet. Continue to code as if the face did not disappear and reappear within the same second. 167 Start Time 0 00 0 02 0 05 0 06 0 10 End Time 0 07 0 04 0 08 0 10 0 11

Quantifying face exposure in infants and adults Coding second-by-second means that each second is 'owned' by one or more faces. Many faces can own the same second, but a single face cannot own the same second twice. This is why we cannot double-count a face as disappearing and then reappearing within the same second. Correct coding:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

1 1

204 206 207 210

Not-quite-correct coding:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

1 1

204 206 206 210 If face 1 is already present at second 6, it cannot be present twice in second 6!

Sex: Select the gender of the face and in the 'sex' box write with either an 'M' for male or an 'F' for female. If what is being coded is a real live person, there is really no reason why 'gender' cannot be coded. Research has shown that we're quite good at guessing gender from body movement alone. Even if the person is very far away or moving really quickly, it may be a little more challenging, but it should still be possible to make a fairly good assessment of their gender. If, later in the video, the face becomes available again and it turns out that it is either not the gender initially assessed, please go back and change what was previously indicated for this person. Sometimes the first view of a person is not as good as later views. There is absolutely nothing wrong with revising estimates as more information becomes available. There is, however, a problem if estimates are not revised when it is found out that they were not accurate. If what is being coded is not a real live person, it may have a gender, in that Barbie could be coded as 'female' and Ken as 'male'. It may not have a gender, in that teddy bears don't usually have genders and it's impossible to code the gender of a pet dog or cat in most situations. In these cases, please strike through the box ( \ ) and put a note in the notes section describing, in three words or less, what it was that didn't have a gender. Examples: dog, plush toy bear &c. Age Range: Select the age range of the face to be coded and write the number that corresponds to that age range in the 'age' box. Please code only with the age range codes listed in the coding key, even if 168

Quantifying face exposure in infants and adults you know the exact age of the person in the video, As with sex, if a reasonable estimate of age can be made, please indicate the age. If it is impossible to make any assessment of age (because the person is moving too quickly, is wearing a mask, is too far away, is cloaked in shadows, and/or some other reason) please indicate that this was not available (n/a) in the 'age' box. As with sex, please revise retroactively if more information about the age of the person in the video becomes available. There is absolutely nothing wrong with increasing the accuracy of coding! If the person in the video is known to you (because you know them personally or because they are famous), please do not estimate their age. Instead, use Google to find out their exact age (or exact age at the time at which the film or other media being watched was made). As with sex, if what's being coded doesn't have an age (example: teddy bears, cartoon characters, &c.) or has an age that can't be determined (example: pet dogs), please strike through the box (\) Race: Select the race of the face to be coded and place the letter that corresponds to that race in the 'race' box. If the face seems to be of a race not listed, please put a star (*) in the box and note the race in the notes section. Unlike sex and age, people are not very good at estimating races based on faces. Please do your best here. As with age, if the face one you recognize, use Google to find out their exact race. If the face being coded doesn't have a race (such as teddy bears and dogs), please place a slash (\) through the box. If it is truly impossible to estimate race, please place 'n/a' in the box and explain, in the notes section, why it was impossible to assess the race of the face being coded. Type: R = real people. The only things that should be coded as 'R' are real, alive, human people who are present in person (not on tv or in pictures). Anything that is not a real alive person who is physically present in the participant's environment gets coded as 'N'. If something is not a real alive person, please note, in the notes section, what type of face the 169

Quantifying face exposure in infants and adults participant is looking at. Medium: R = is moving and in person. This applies to all things that have faces and move that are not on a screen or other media. This means that while a dog would be 'N' type, they would still be coded as 'R' in medium. T = this is for anything that is viewed moving on television, pc, or other media. This includes all real and not-real faces seen on media. To be considered 'T', the face must be moving. This means that a photograph being waved around on television would not be considered to be 'T'. S = static. This means that the face isn't moving at all. Pictures would fall in this category. Even pictures of real alive people. This also means that not moving pictures on TV or other media would be considered to be 'S', static.' View: Please code the DOMINANT view. The dominant view is the view in which the face spends the most time. For example: If a face is in profile view for 2 seconds, moves to frontal view for 3 seconds, it would be coded as 'F', for frontal view. 'F', frontal views need both eyes and ears visible. 'B', between views have only one ear but most of two eyes visible. This is an intermediate view between 'F', frontal and 'P', profile. 'P', profile views have only one ear and one eye showing. 'M' category, for moving, only applies to faces that never stop in a single view. M` coded faces have no dominant view, they just pass through all different views. An example of this would be someone shaking their head 'no'. Please only use this when there is no dominant view for the face. Interaction: Is the face being coded interacting with the participant? This is not coding for whether the participant is interacting with the face. Interacting, in this case, means eye contact (the face seems to be looking at the camera), mouth 170

Quantifying face exposure in infants and adults moving while facing the participant (the face seems to be talking to the camera), moving their hands towards the participant (this often happens with infants, where the owner of the face being coded is playing with the infant somehow), or having the face being coded re-appear more than once in a frontal (or between) view in the participant's field of view. If the face cannot interact (in the case of inanimate objects), please code as 'n/a'. Proximity: How close is the face to the participant? Please code the AVERAGE distance between the participant and the face. For very long interactions, please code in 3-second blocks, continuing down line by line (indicating only the time and an arrow indicating it is the same face) until the face stops at a single distance or leaves the field of view. 0 means that the face takes up 80 - 100% of the field of view. This happens most frequently with infants, but may also occur when adults are standing very close to each other, as in an obscenely crowded streetcar or if they`re kissing. 1 means that the face is within two feet of the participant. As a guideline, this means that the participant could easily reach out and touch the face, since the face would be half an arm's length away. 2 means that the face is about 2 ­ 3 feet away from the participant. This would be about a full arm's length away from an adult participant. This would mean that the participant could theoretically reach out and touch the face, but they would need to fully extend their arm (and the face couldn't move back!). 3 means that the face is 4 ­ 5 feet away. This would be more than an arm's reach away from the participant. 4 means that the face is 6 ­ 10 feet away from the participant. This would mean that a person could lie down comfortably in the space between the participant and the face. 5 means that the face is 10 to 20 feet away from the participant. Faces at this distance will be blurry in the glasses. Please revise coding when they come nearer to the participant. 6 would mean that the face is more than 20 feet away from the participant. At this range, it is probably going to be difficult to see the faces at all. Please revise coding estimates (age, gender, race, &c.) when the face comes nearer. 171

Quantifying face exposure in infants and adults

For all of these values, please see the exemplars of Proximity Exemplar photos which are located at the end of this guide and the full set of proximity exemplars located at: BEELab/Studies/Study 03 ­ SpyGoggles/training/Proximity Exemplars Proximity is the hardest value for most coders to code accurately. These proximity exemplars should make coding proximity a little bit easier. The proximity exemplars folder should ALWAYS be open while videos are being coded. While coding, keep the proximity exemplar photos readily available so that they can be used to best estimate proximity. Surround: On average, how many other faces are in the field of view of the camera during the time that the face in question is in the camera's view. If faces drop in and out of the camera`s field of view while the face in question is being coded, average the number of faces per second that were in frame with the face being coded. This average value will be the surround and can be translated into one of the surround coding values listed on the coding key (and below). For real faces, please only include other real faces in the surround. For not real faces, please include all faces in the surround. Please note that the first three coding values represent absolute numbers of faces: 0 = no faces other than the face being coded 1 = only one other face in the field of view 2 = 2 other faces in the field of view From here, the numbers represent categories, not individual faces. Please be sure to use only these categories (not numbers of individual faces) when coding for surround. 3 = 3 ­ 5 other faces in the field of view 4 = 6 ­ 10 other faces in the field of view 5 = 11 ­ 20 other faces in the field of view 6 = more than 20 faces in the field of view. Invert: 172

Quantifying face exposure in infants and adults This category is asking whether the face is upright (right-side up), on it's side (sideways), or inverted (upside-down). If the face is upright or nearly upright, please code as '12' (which refers to 12 o'clock on the face of a clock) or, to be a little quicker, as '1'. In this case, the eyes are above the nose and the nose is above the mouth. If imagining the face being printed on the hour hand of a clock, this category would represent the hour hand being anywhere between 10: 30 and 1: 30. If the face is fully on the side or nearly on the side, please code as '3'. Here, the eyes, nose, and mouth are all at the same level, none is above the other. It does not matter if the face is on the right or left side, code both as '3'. Again with the clock analogy, this would mean that the hour hand is between 1: 30 and 4: 30 or between 7: 30 and 10: 30 on the clock. If the face is upside-down or nearly so, please code as '6'. Here, the mouth is above the nose and the nose is above the eyes. This would correspond to the clock hour hand falling between 4: 30 and 7: 30 on the clock. Smile: Both whether a smile is available to be coded for and if the face expressed a smile (which we are taking to be an indicator of happy`) is being coded here. Smiling is determined to occur when the corners of the lips are curled up and turned back. The forehead (if visible) should not be creased. (Taken from Hinsz & Tomhave, 1991.) The lips do not have to open and teeth do not have to be visible. Faces where only the lips are visible may be coded for smiling, if they fit the above criteria for smiling. If the face is clear enough on the video to allow for an accurate assessment of whether a face is smiling AND the face is actually smiling please indicate the time at which the smile started and ended. If the face is clear enough on the video to allow for an accurate assessment of whether a face is smiling AND the face is NOT smiling, please write 'no'. If the face is not clear enough to assess whether the face is smiling or the lips cannot be seen, please code as 'n/a'. Again, if the lips are not visible code the face as n/a` for smiling. If there is some combination of the above-three categories (smile time, 'no', and 'n/a'), please 173

Quantifying face exposure in infants and adults write down exactly what happened. Example: Face 2 is in the video between 6 and 18 seconds. Face 2 has their mouth visible, but they are not smiling from 6 to 10 seconds. Face 2 then smiles for three seconds. After their three-second smile, face 2 hides their mouth with a napkin until they disappear from the video. Face 2 Face Start Time 0 06 Face End Time 0 18 Smile Smile Start Time Smile End Time No / 11 ­14 / n/a

This does mean that the 'smile start time' and 'smile end time' boxes are simply being used as note-space for smiling. Fortunately, for the most part, a face is either smiling, not smiling, or doesn't have the lips visible, so this type of coding shouldn't happen too often. Since the data is being used to try and determine the type of exposure infants have to smiles and how this impacts infants' ability to discriminate between different facial expressions of emotion, it is important that faces that are not clear or that do not have the lower portion of the face available to the camera's field of view are not coded as smiling or not smiling. It is better to code 'n/a' than to over- or under-estimate smiling. Other Emotions: This will be coded in the same way in which smiling is coded. In this case, however, please note the emotion that was expressed by the face being coded. Inter-rater reliability is the primary method by which we are going to be assessing both the accuracy of face coding in addition to the accuracy of coding of emotion. To this end, please ensure that all videos are watched at least once at full speed to understand what will be viewed, once at reduced speed to code second-by-second for faces, and then once again at full speed to look for missed faces and verify the accuracy of coding for facial expressions of emotion. Coding at reduced speed can result in artifacts, whereby speaking and other facial movements that are not facial expressions of emotion appear to be facial expressions of emotion. Watching the video again at full-speed will help to ensure the accuracy of the coded video. Operational definitions of: Happy: See smiling (above description of smiling). 174

Quantifying face exposure in infants and adults

Surprise: Wide eyes, raised eyebrows, with an open mouth. Fear: Wide eyes with a closed mouth. Anger: Furrowed brow with lowered eyebrows and squinting eyes. Disgust: Upper lip curled up and furrows next to the nose. The sides of the mouth are moved in. Sad: Furrowed brow with downturned corners of the eyebrows and downturned corners of the mouth. Examples of relevant areas:

Taken from: Smith, Cottrell, Gosselin, & Schyns, 2005

Notes: Please use this section, on the right-hand-side of the sheet, to clarify anything that was weird, different, or could not be accurately coded for this face. (Use the left-hand margin of the sheet for your own notes to help you remember what you are coding.) Non-real faces: For any non-real faces, please be sure to note what exactly the face was on here. Ideally, the person who enters the coded data should be able to, from what was coded, understand what was being seen in the video. The notes should, in this case, answer the questions: a) What type of face is this exactly? (Real person, cartoon person, real animal, toy animal, abstract art?) b) Is the face meant to be a real face and if no, what is it instead? (For example, is it a 175

Quantifying face exposure in infants and adults photo of a real person?) c) How is the face viewed? (Is it a photograph, a wall decal, a cartoon cow on a milk carton?) d) If available, what is this face? (Is it Donald Duck? Is it Donald Trump? Is it Ronald McDonald?) Saying poster` in the notes section does provide information on how the face is viewed, but it does not provide enough information to answer questions A`, B`, or D`. A more appropriate note would be poster of cartoon kangaroo` or wall decal of sketch of Christopher Robin from Winnie the Pooh`. Emotions: For any emotions other than smiling, please note the emotion. Coding issues: If the information available in the video was in some way deficient, for example the faces were moving too quickly, the lighting was very poor, or there were many occlusions which resulted in it being impossible to accurately describe the properties of the face being viewed, please note these issues in the notes section. Reflections: If the face in the video is a reflection, please note, in the notes section, the face number that it is reflecting and that it is a reflection, as described below in the Quick Tips` section.

Coding Issues: Ruined Video: When participants first put on the video camera, the video does not represent what they see. In these cases, please make a note of when the video recording actually began and adjust the 'Vid. Length' (at the top of the first coding sheet) to reflect this by subtracting the 'ruined' time from the total video length. Additionally, it sometimes happens that video is impossible to watch because of a change of lighting (it take some time for the camera to adjust from dark to light or vice versa), high speed (the video skips, in this case), the participant moving way too much (everything is blurred), or an obstruction in front of the camera lens. In this case, please note the problem on the coding sheet (below the 'faces' previously coded' and before any faces to be coded) and adjust the 'video 176

Quantifying face exposure in infants and adults length' on the first sheet to reflect this new time. If the camera is removed and placed on a surface somewhere. In this case the scene viewed by the camera would be completely still and unmoving for a long period of time. Occasionally, the participant will be seen walking away from the camera. Please note this as 'ruined' video on the coding sheet and adjust the video length on the first coding sheet to reflect the shortened total video length. Inappropriate Video: Please stop coding and let Nicole know! Videos Without Faces: Some videos don't have faces. Please note, in big letters, on the coding sheet 'no faces'. Other Coding- or Video-Related Issues: Please ask Nicole!

Quick Tips: When the same face reappears: Some qualities of a face will not change. A first interaction requires all fields of the row for the face being coded to be completed. If, however, the face is seen again later, sex, age, race, type, and medium do not need to be coded again. Example: Face 1 appears, goes away, and then reappears. It would be coded:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

1 1

4 14

10 22

M

2

3

R

R

F P

Y N

2 4

0 0

12 12

No No

No No

When the same object reappears: Static objects will not change their view, interaction (n/a), proximity, upright/inverted status, smile, or other emotion if the participant does not move. This means that these three categories 177

Quantifying face exposure in infants and adults do not need to be completed over and over again for the object. Instead, draw an arrow down to indicate that the object continues at the same view, interaction, and proximity in which it was originally coded. CAUTION: if the participant moves, the proximity will change!!!! Example: A photo of a dog is visible, temporarily obscured by flying (faceless) monkeys, and then reappears. This would be coded as:
Face # Face start & Sex end time M/F Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end Other emotion Notes

4 4 4

216 218 220 216 220 225

\

\

\

N

S

F

\

2

0 0 0

1

N/a

Photo of dog

How to code reflections: Reflections should be coded as if they were the real thing with a note added to indicate that this was viewed in reflection`. Reflections are given their own individual face number. Reflections do not share the same number as the real non-reflected face. Instead, note in the margin that they are a reflection of face #(?). For example, A reflection of real alive face #2 is coded: type: R, medium: R, notes: Reflection of face #2. Coding FAQ: How long should coding take? It depends on the video. Some videos can be coded quickly (2x the video length, since the video is being watched at 0.5 speed) because there are no faces and the participant is doing something repetitive or not moving. Other videos take longer because there are faces. As a guideline, make sure that you have at least as much time to code as 4x the length of the video you plan to code. (To put this another way, if you want to code a video that is an hour long, ensure you have at least 4 hours to spend coding it!) What if I can't tell a person's age/gender/race/emotion/&c.? The purpose of not providing an option which is 'unsure' is to try and force the coders to make an educated guess about what type of face they're seeing. Since at least 20% of the videos will be coded by at least two coders, a high inter-rater reliability (having two different coders agree 178

Quantifying face exposure in infants and adults about the type of faces they're seeing) will allow us to be confident that our results are accurate. It does, however, happen that sometimes it is in fact impossible to tell at what type of face the participant is looking. This is especially difficult for far-away faces. In cases where it is ABSOLUTELY impossible to even guess at what type of face it is, place a slash ( \ ) through the box or put not available (n/a) in the box and write a note in the notes section which explains (in three words or less) why the face was not available or impossible to code. Examples of notes would be: far face, fast face, p moving, &c. When should I leave a box blank? Never. All boxes should have something in them, even if it's just a quick line through the box to indicate that the value being coded doesn't apply to the face being coded (see age or sex, for examples). Leaving a box blank leaves no record of whether what was left blank was actually coded for (and if so, what the box should say) or if somehow the value of the box was missed during coding. This means that the blank boxes will have to be filled in by someone else later. It's much harder (especially in videos with many faces) to go back and decide what face corresponds to any particular number and then, from there, fill in the missing information. Please do not leave any boxes blank! Exception: when faces reappear. See above. How clear should my coding sheet be? Clear as an unmuddied lake, as clear as an azure sky of deepest summer. While it is possible that you may be entering the data from your own coding sheet, it is also possible that someone else may be entering your data. Always code as if someone else will be entering your data; this way, if someone else does enter your data they'll be able to enter it easily and this will make them happy. If the person entering the coding sheet can't understand it, they will be very unhappy and the video will have to be re-coded to be able to ensure the accuracy of the face data. What if I need more than one coding sheet per video? Please use as many as you need. Ensure that the first coding sheet's noted video length is accurate. Place series numbers at the top of each coding sheet when you're done coding. (If you have coded 10 sheets, sheet 1 would be 1 of 10, sheet 2 would be 2 of 10, &c.) 179

Quantifying face exposure in infants and adults How will you know I have coded the video correctly? All coders have been trained up to 85% inter-rater reliability on the three training videos. This helped to ensure that everyone was on approximately the same page when they began. Unfortunately, sometimes people need little reminders from time to time. To this end, all video coding sheets will be randomly spot-checked for coding accuracy. If your video is found not to have accuracy issues, you will be asked to re-code the whole video to address these issues. This process will repeat itself until all issues are resolved. Additionally, since poor data entry can make a well coded video look like a poorly coded video, all entered data will also be spot-checked for accuracy. As with video coding, you will be asked to revise the spreadsheet until all issues are resolved. It is quicker and better to ensure accurate and high quality coding during the first coding attempt. It is much more difficult to remediate a video that was not well coded initially. To this end, try to do the best possible coding job initially! What if I have questions? PLEASE ask! If you have a question about coding, other people probably have or have had the same question. If you ask about it, Nicole will make sure that everyone gets the same information so we're all coding the same way. Additionally, no one will ever know who asked the question, but everyone will benefit from your asking by getting the answer! The old adage 'there are no dumb questions' holds here. Please, even if you think you understand something but aren't 100% sure, please email and ask. If you have a question please email Nicole at nsugden@ryerson.ca . You'll get an answer in 24 hours (or 48 on the weekend if she's not at school for the weekend).

Thank you!!
Environment, Houses, Cars, and Birds: In addition to faces, we are also coding for houses, cars, and birds. Use the appropriate coding sheet to document the environment, houses, cars, and birds in the video. As with face coding, this must be coded at .5 speed, at minimum. Do NOT code for environment, houses, cars, or birds while coding for faces. Watching for this many different things during a single viewing with inevitably result in a poor-quality coding job. 180

Quantifying face exposure in infants and adults

Environment: Here we are coding to describe the area in which the participant was recording the video. Area #: Use the environment` portion of the coding sheet to code the type of environment in which the video was shot. As with faces, each area into which the participant travels will be coded by a number. Different area numbers may refer to the same type of area. For example, area #1 may be the kitchen while area #2 may be the living room., despite the fact that the type of area for #1 and #2 are both area type 1 (inside a house or home). Area Type: 1 = inside a house or a home. This may be a participant`s home or another person`s home. Please not where in the home you believe the participant to be. 2 = inside a public area (not a house or home). This includes areas like malls, transit, or mommy-and-me classes. Again, please note where you believe the participant to be. 3 = outdoors. This includes all outdoor areas such as the park, the sidewalk, and a forest. Please note the type of outdoor area in which the video was shot. 4 = other. Please note what this is in the notes section. This can include things such as a car. Entry Time: Code the time at which the participant enters the area. This is the time at which the area encompasses the whole of the camera`s field of view. Do not code for areas at which the participant looks but does not enter. Houses: We are only coding for standard houses. This means fully detached houses not condominiums, semi-detached houses, row houses, or apartments.

House # / # of houses: 181

Quantifying face exposure in infants and adults

Houses, like cars, can be coded in batches. When there are a lot of houses to be coded (for example, when a participant is cycling through a residential neighborhood), then code the houses in batches. If there are only a few houses, code them individually. Indicate on the sheet whether the houses were coded in batch by writing batch` in the notes section. If coding by house #, code as per faces. Code this way if there are few houses. If coding by number of houses, count the number of houses within each view and interaction type that is visible in a ~2 minute interval. Code this way if there are many houses. View: 1 = If the full front of the house is visible and in-frame 2 = if any other view of the house 3 = Participant interacts with the house (Note the interaction type in the notes section.) Notes: Note for interactions. Also note for any atypical houses, for example cartoon houses. Cars: Code only for the external view of cars. We are only coding for cars, trucks, SUV`s, caminos, or vans. We are not coding for buses, motorbikes, scooters, or other motorized transport. Car # / # of cars: Cars, like houses, can be batch-coded. Again, as with houses, batch-coding is to be used only when a lot of cars are present (for example, when driving in traffic). If there are only a few cars, code them individually. Indicate on the sheet whether the cars were coded in batch by writing Batch` in the notes section. If coding by car #, code as per faces. Code this way if there are few cars. If coding by number of cars, count the number of cars within each type that is visible in a ~2 minute interval. Code this way if there are many houses. Car Type: 1 = Stationary car. The car is not moving throughout the time during which it is in frame. 2 = Moving car. The car is moving throughout the time during which it is in frame. 182

Quantifying face exposure in infants and adults 3 = Interaction. The participant interacts with the car in some way. Notes: Note for interaction or any atypical types of cars (example, cartoon cars or toy cars). Birds: With birds, we are coding for anything that has wings, feathers, and a beak (even if it`s just a cartoon representation of wings, feathers, and beaks). Bird # / # of birds Birds, like cars and houses, can be batch-coded. Batch-coding is to be used when there are a lot of birds present (for example, if attacked by a flock of birds). If there are only a few birds, code them individually. Indicate on the sheet whether the birds were coded in batch by writing batch` in the notes section. Bird Type: 1 = The bird is stationary (not moving around) AND within 10 feet of the participant. The bird should be clearly visible in the video. 2 = Not stationary or 10 + feet away. The bird is moving AND / OR the bird is more than 10 feet away from the participant. 3 = Interaction. Participant interacts with the bird in some way. (Note the interaction type in the notes section. Notes: Note if the participant interacts with a bird in any way. Also, as per all other coding, note when the bird is not real or otherwise atypical.

Finishing a Video: Re-View the Video: Double-check the video to ensure that no faces were missed. (Remember the invisible gorilla!) When re-viewing the video, do not watch the faces you had initially coded, but instead watch for any faces or other things that you may have missed while you were coding for faces. Each video must be viewed at least 3x by the coder to be considered finished` for coding. (This means watching it 2x for face coding and 1x for Environment, house, car, and bird coding.)

183

Quantifying face exposure in infants and adults Adjusted Run-Time: Videos often have segments that are ruined (cannot be coded) or do not represent the participant`s perspective. The reasons for this are often: - the camera is not on the participant`s head - something is occluding the camera lens - the lighting is poor and the camera cannot see anything - the video itself will not play - the participant is moving around very quickly and the film is a big unclear blur We do not wish to include these portions of ruined data in what we list as the total run-time of the video. Instead, we subtract the seconds of ruined` video from the total run time of the video to give the adjusted video run-time. For example: A 14 minute video begins with 1.5 minutes of putting the camera on, has a hand over the camera lens from 10 ­ 11 minutes (one minute total), and is so dark that nothing is visible from 12 ­ 12.5 minutes (half of a minute total). This means that we must subtract all of these ruined` portions from the total run-time of the video to give the adjusted video run-time. Here, this would be 14 ­ 1.5 ­ 1 - .5 = 12 minutes Email Nicole: When you have finished coding a video, email Nicole to let her know. In your email please include: The name of the video coded The adjusted run-time of the video coded Any issues with the video (large ruined sections, anything inappropriate) A brief (1 ­ 2 line) synopsis of what the video was about Data Entry: Data Entry Template: The template should be available on the desktop of the PC you are using. 184

Quantifying face exposure in infants and adults The templates for each coding sheet are as follows: Faces Houses Cars Birds Environment Data Entry RAW Data.sav Houses Coding Sheet RAW Data.sav Cars Coding Sheet RAW Data.sav Birds Coding Sheet RAW Data.sav Environment Coding Sheet RAW Data.sav

If this file is not on the desktop, it can be found in the SPSS Templates folder located at: BEELab/Studies/Study 03 Spy Goggles/Data Entry/SPSS Templates. WARNING: If you retrieve the file from the SPSS Templates folder and plan to use it, move the file to the desktop and save it there before entering data. If data is being entered while the file is still on the server, the server may drop the connection and all data will be lost. Before inputting data into the SPSS file, rename the file according to the naming convention discussed below under saving SPSS data` (filename adjustedrun time initials.sav). While entering data, save often to prevent major data loss! Data Entry Alpha-to-Numeric Conversion: SPSS works better with numbers, so we use numbers to represent values. For example, instead of using the letter M` to represent male, we use the number 1`. The conversions can be found by clicking the Variable View` tab at the bottom of the spreadsheet and clicking on the blue button within the column Values` and row corresponding to the variable of interest (for example, the sex` row). The conversions are as follows: Variable Sex Hand-coded value Male Female n/a n/a Asian Black Latin American South & West Asian Indiginous White Real alive person in-person 185 SPSS value 1 2 0 9 1 2 3 4 5 6 1

Age* Race

Type

Quantifying face exposure in infants and adults Not real alive person in-person Static Real, alive, and in-person On TV or moving media Front Profile Between Moving Unknown Yes No Upright (12) Sideways (3) Inverted (6) Happy Surprised Angry Fear Disgust Sad 0 0 1 2 1 2 3 4 0 1 2 1 3 6 1 2 3 4 5 6

Medium

View

Interaction

Inverted

Emotion Actual

The following variables` values are not changed: Value Face Number Start Minute Start Second End Minute End Second Age Proximity Surround Coding in SPSS Use the coded face numbers Use the coded face start minute Use the coded face start second Use the coded face end minute Use the coded face end second Use the coded age numbers If something does not have an age, code as 9` Use the coded values Use the coded values

LipsTTLSMin LipsTTLSSec, LipsTTLEMin, & LipsTTLESec are Lip Time: The LipsTTL columns represent the minute and seconds during which lips are visible on a face. If, when coding for smile, this value was n/a, please enter 0` in all of the LipsTTL fields. If there was a smile present and coded as smile` or no smile present coded as no smile` (which 186

Quantifying face exposure in infants and adults means that the lips were visible), please enter the time during which the lips were visible (regardless of whether or not the lips were smiling) into the LipsTTL column. If the LipsTTL columns are all 0`, the Smile and Emotn columns are necessarily all 0` as well. SmileSMin, SmileSSec, SmileEMin, & SmileESec are Smile Time: Enter only the time during which the lips were visible and smiling in this column. If there was no smile visible or present or lips were not visible and no smile could be seen, enter 0` in all of the cells. EmotnSMin, EmotionSSec, EmotnEMin, & EmotnESec are Emotion time: Enter the time during which other emotions (not happy/smiling or neutral) were visible. As with smiling, if there were no other emotions visible, enter 0` in all of the cells.

SPSS Data Quality Check Step 1: Make Friends: Visually inspect your data Scroll across and down the data sheet looking for anything that is blank, incomplete, or impossible. If something seems amiss, cross-reference it with your hand-coded paper sheet. Un-Blank the Blank Cells: Sort to check for missing cases Right-click on the Face` label at the top of the Face Number column Choose Sort Ascending` o This will re-organize the dataset by face number If there are any blank cases (rows with no data in them) at the top of the spreadsheet DELETE them. o Delete them by clicking on the corresponding number at the far left of the spreadsheet (in the blue column) and hitting the delete` button on the keyboard. Multiple cases can be deleted at once, but please ensure that no data-filled rows are being deleted. Move over to the Notes` column and inspect it for missing data. o Ensure that all of the faces that should have a note DO have a note. o Example: All Face 4`s have the note Dog` in notes because Face 4 is a dog`s face. 187

Step 2: -

-

Quantifying face exposure in infants and adults

Step 3: -

SPSS Searches Cells: Have SPSS check for missing data Go to Analyze  Descriptive Statistics  Frequencies o Drag into the Variable(s): box the following variables:  Sex, Age, Race, Type, Medium, View, Interaction, Proximity, Surround, Inverted o Ensure that the Display frequency tables` check-box at the bottom left-hand corner of Frequencies` pop-up window is checked o Click on the Okay` Button SPSS will open the output viewer window where there will be frequency tables. Look for the word Missing` in each of the frequency tables. EXAMPLE for Missing Values in the variable Age: Age

-

Frequency Percent Valid 3 606 85.7 Missing System 94 14.3 Total 700 100.0 -

Valid Cumulative Percent Percent 100.0 100.0

If you find the word Missing (as above) check the next column (Frequency). Frequency` column tells you how many cells are empty (have missing data) for this variable. (In this example: 94!) - Missing values are bad. If there are missing values, find the empty cells in the spreadsheet and fill the empty cells with the real values listed on the paper coding sheet. - Repeat Step 3 until no variables report missing values. (Missing` will be missing, as below.) Age Cumulative Frequency Percent Valid Percent Percent Valid 2 1 16.7 16.7 16.7 4 1 16.7 16.7 33.3 17 3 50.0 50.0 83.3 91 1 16.7 16.7 100.0 Total 6 100.0 100.0 Step 4: SPSS Finds Unreal Values: Have SPSS check for impossible data 188

Quantifying face exposure in infants and adults From the Frequencies output generated in Step 3, check the first row of each Value`s table to ensure that none of the values listed as Valid (high-lighted in the above example) are impossible. Example: o The above-table (yellow high-lighted) is possible because 2, and 4 are possible values that can be used to code for a participant`s Age` o The above-table (green high-lighted) is NOT possible because 17, and 92 are NOT values that can be used to code for a participant`s Age` If any impossible values are found, the second column (Frequency`) will tell you how many impossible values there are for each of the impossible values. Find all of the impossible values in the spreadsheet and insert the real (possible!) values from the paper coding sheet. Repeat Step Four until all of the listed values are possible values. SPSS Makes Sense: Run a script to ensure accuracy of time values

-

-

Step 5: A: B: C: D: E: -

-

-

Run a Script: Go to Transform  Compute Variable In the Target Variable` box print the name of the script: `CheckFace' In the Numeric Expression` box cut and paste the following: EndMin ­ StartMin Click OK` Repeat A-E, using the name `CheckLips' & the formula LipsTTLEMin ­ LipsTTLSMin Repeat A-E, using the name `CheckSmile' & the formula SmileEMin ­ SmileSMin o CheckFace, CheckLips, and Check Smile check to ensure that minute at which a face, lip, or smile starts is EARLIER than the minute at which it ends. Go to Analyze  Descriptive Statistics  Descriptives Go to Analyze  Descriptive Statistics  Frequencies o Drag CheckFace, CheckLips, and CheckSmile into the Variable(s) box (as with missing data and impossible data checks) Check the frequency table to ensure that that there are no NEGATIVE numbers (as below in green) or impossibly high numbers (as below in green). Negative numbers tell you that one of the start times is LATER than the end time. CheckLips 189

-

Quantifying face exposure in infants and adults Cumulative Percent 16.7 66.7 100.0

Frequency Percent Valid Percent Valid -2 1 16.7 16.7 1 3 50.0 50.0 40000 2 33.3 33.3 Total 6 100.0 100.0 -

If there are negative numbers, scroll through the variable that the frequency table describes (in this case, CheckLips) and find the negative value. In the same row, find the Start minute that is later than the End minute for that checked variable. (In this case, Lip start and end time.) Find the correct value on the paper coding sheet and enter it into SPSS to replace the incorrect value. Repeat until none of the frequency tables list any negative or impossibly high numbers. Saving SPSS Data:

File name: The file name for a spreadsheet is the name of the video (participant number, day number, video number) followed by the total adjusted run-time for that video and the coder`s initials. For example, if the 14 minute video #2 of day two for participant eight was coded by Nicole Sugden it would be saved as: p08d02v02 1400 NS.sav If the total running time of the video was 14 minutes, but 2 minutes were uncodeable or otherwise ruined, use the adjusted run time of the video (14 ­ 2 = 12 minutes) for the file name when you save it. This would mean that the file name would be: P08d02v02 1200 NS.sav Saving the file: Save the file to the desktop. Once the file is safe on the desktop, copy and paste it to the folder on the server: BEELab/Studies/Study 03 Spy Goggles/Data Entry 190

Quantifying face exposure in infants and adults

Once the file is safe on the server in the Data Entry folder, delete the file copy from the desktop.

Happy Coding!!
Proximity Exemplars: Proximity 0:

Proximity 1:

191

Quantifying face exposure in infants and adults Proximity 2:

Proximity 3:

192

Quantifying face exposure in infants and adults Proximity 4:

193

Quantifying face exposure in infants and adults Proximity 5:

194

Quantifying face exposure in infants and adults

Proximity 6:

195

Quantifying face exposure in infants and adults Appendix P. Coding Key
Subject#: Coding sheet updated:
Face # Face start & Sex end time M/F

Video #: Coder name: Viewer number: 1 2 3 4 (no more than 4 ppl may view)
Age Race range Type Mediu View Intera Proxi Surro Inve Smile m ction mity und rt? start&end

Date: Vid Length:
Other emotion Notes

(SPSS VALUES ARE LISTED IN BRACKETS)
Face #: Sex Age range (SPSS values ­ as listed) Give an individual a #. If the individual repeats, they keep their #. M (1) = Male 0 = 0-9 years 1 = 10-19 years 2 = 20-29 years 3 = 30-39 years F (2) = Female n/a(0) = not applicable/available 4 = 40-49 years 5 = 50-59 years 6 = 60-79 years 7 = 80+ years 9= n/a

Race (taken from statcan.gc.ca/censusrecensement/2006 population groups)

W (6) = Caucasian A (1) = Asian (Korean, Chinese, Japanese, Vietnamese, Cambodian, etc.) B (2) = Black L (3) = Latin American S (4) = South&West Asian (East Indian, Pakistani, Sri Lankan, Iranian, etc ) I (5) = Indigenous Peoples / Aboriginals n/a(0) = none, not applicable, or unclear R (1) = real person N (0) = not a real live person * NOTE

Type Medium View

R (1) = viewed moving in-person S (0) = viewed static** T (2) = viewed moving on television/pc ** NOTE medium (paper, doll, &c.) F (1) = front (both eyes & ears visible) P (2) = profile (one ear & one eye visible) B (3) = between (2 eyes& one ear visible) M (4) = moving (no dominant view) Y (1) = Yes N (2) = No Code the view in which the face spent the most time. It is expected that all faces will move, but if face spends most time in one view code as that view. U (0)= unknown /unsure 4 = face is 6 to 10 feet away 5 = face is 10 to 20 feet away 6 = face is more than 20 feet away ** AVERAGE number of faces in view of camera during the time that the face is in camera`s view. 6 = face is upside down

Interaction Proximity (SPSS values ­ as listed)

0 = face fills 100-80% of camera view 1 = face is less than 2 feet away 2 = face is 2 ­ 3 feet away 3 = face is 4 ­ 5 feet away

Surround (SPSS values ­ as listed)

0 = no other faces in view 4 = 6-10 other faces 1 = 1 other face in view 5 = 11-20 other faces 2 = 2 other faces 6 = 20+ other faces 3 = 3-5 other faces 1 = 12 o`clock = normal 3 = face is sideways

Invert (SPSS values ­ as listed)

196

Quantifying face exposure in infants and adults
Smile Other Emotions Time smile started & ended. **If multiple, place in lines below start & end time * NOTE EMOTION - sad, angry, surprise, disappointed, &c. SPSS VALUES 0 = n/a 1 = happy 2 = surprise 3 = angry 4 = fear 5 = disgust

Notes Environment: Area #:

Place notes here

Area type:

Area type notes:

Entry & Exit time:

Area # Area type: Entry & Exit time: Houses: House # *MAY BATCH CODE. SEE CODING GUIDE! House # / # of houses View:

Code each area with sequential numbers. 1 = house/home *note where 2 = indoor public area *note where 3 = outdoor public area * note where 4 = other

Time at which the area encompasses the whole view of the camera, indicating the subject has ENTERED the area. Do not code if area is observed but not entered. Start time End time View Notes

To be coded as per area # and face # coding schemes (may batch-code) 1 = full front view of whole house 2 = not full front view 3 = Participant interacts with home (Note the interaction type)

Cars: Car type Start time End time Car #/# of cars *MAY BATCH CODE. SEE CODING GUIDE! Notes

Car type

1 = Stationary (Car is stopped) 2 = Moving (Car is moving)

3 = Participant interacts with car (Note the interaction type)

Start/End time # of cars Notes Birds: Bird # /# Birds

For each car type, count the cars visible in 2 minute intervals Number of cars counted within the start/end time-frame Note type of interaction the participant has with the car ­ if P interacts w/car

Start time

End time Bird type Notes

197

Quantifying face exposure in infants and adults
*MAY BATCH CODE. SEE CODING GUIDE. Bird # Bird type Notes To be coded as per car and house coding schemes 1 = Stationary & within 10 feet 2 = Not stationary or 10+ feet away 3 = Participant interacts with bird (Note the interaction type)

Please note if subject interacts with the birds in any way (feeding, kicking, &c.)

198

Quantifying face exposure in infants and adults Appendix Q. Coder Orientation Agenda Welcome to the Brain and Early Experiences Lab! BEE Lab R/A Orientation Who we are Dr. Moulson, Kristina (K) , & Nicole (N)

What we do Overview & Current Projects

Grand tour of SBB Priorities Roles Helping with Participants o Second testing Coding videos Data Entry Literature review Babies!

Rules/Expectations Clean lab o Don`t give babies the plague! On time o Running late? Call N & K! o Lab 416 979 5000 ext 2189 o Nicole 647 238 5945 o Kristina 647 802 2696 199

Quantifying face exposure in infants and adults Shift coverage o Something critical came up? Sick? Call N & K as soon as you know! Babies always come first Answering the phone o Hello, BEE Lab, _____ speaking.` o Take a message (name, phone number, who they`re calling for) o Email N & K immediately to let them know who called and why Locked door policy Locked cabinet policy Computers off when you`re done Classwork in lab? No. Confidentiality Lab guests

-

Coffee, tea, &c. Time Sheets (hours & duties)

Thank you!

200

Quantifying face exposure in infants and adults Appendix R. Coder Confidentiality Agreement

CODING AGREEMENT

I understand that what I am about to view is confidential. I will not discuss the contents of this recording with anyone outside of the BEE Lab. I will not permit anyone else to view this recording. If I see anyone I recognize, I understand that I cannot discuss it with them, mention it to them, or otherwise indicate to them that they have been captured in a video recording. If I know or am acquainted with the participant who has recorded the footage or the persons who have been recorded, I will notify Nicole Sugden, the principal investigator, or Dr. Moulson, who is supervising the project. I will not view or code any footage in which I know or am acquainted with the participant or the people being recorded.

Video #: _____________________

___________________________ Name of coder

__________________________ Signature of coder

____________ Date

___________________________ Name of witness

__________________________ Signature of witness

____________ Date

201

Quantifying face exposure in infants and adults Appendix S. Coder Coding History Sheet Coding History Sheet Subject #: Video #: Video viewing #1 Coder Name: Start time: Start time: Start time: Start time: Start time: Start time: Coding Date: End time: End time: End time: End time: End time: End time: *** while coding coders must take at least 2 5-min breaks/hour Video viewing #2 Coder Name: Start time: Start time: Start time: Start time: Start time: Start time: Coding Date: End time: End time: End time: End time: End time: End time: *** while coding coders must take at least 2 5-min breaks/hour Video viewing #3 Coder Name: Start time: Start time: Start time: 202 Coding Date: End time: End time: End time: Video length: min.

Quantifying face exposure in infants and adults Start time: Start time: Start time: End time: End time: End time: *** while coding coders must take at least 2 5-min breaks/hour Video viewing #4 Coder Name: Start time: Start time: Start time: Start time: Start time: Start time: Coding Date: End time: End time: End time: End time: End time: End time: *** while coding coders must take at least 2 5-min breaks/hour

VIDEO TO BE ARCHIVED. NOTIFY NICOLE OF FINAL VIEWING. ARCHIVE DATE: DISC#:

203

