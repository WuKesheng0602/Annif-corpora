Semi-automated Extraction of Urban Road Networks by Geometric Analysis of IKONOS Imagery

A Thesis submitted to the School of Graduate Studies of Ryerson University in partial fulfillment of the requirements for the degree of Master of Applied Science in the Program of Civil Engineering

By

HAIBIN DONG, B.Eng. East China University of Science & Technology, China, 1994

Toronto, Ontario, Canada © 2003 Haibin Dong

R yER SO N U K iV u-w H i-L.^

UMI Number: EC53444

INFORMATION TO USERS

The quality of this reproduction is dependent upon the quality of the copy submitted. Broken or indistinct print, colored or poor quality illustrations and photographs, print bleed-through, substandard margins, and improper alignment can adversely affect reproduction. In the unlikely event that the author did not send a complete manuscript and there are missing pages, th ese will be noted. Also, if unauthorized copyright material had to be removed, a note will indicate the deletion.

UMI
UMI Microform EC53444 Copyright2009by ProQ uest LLC All rights reserved. This microform edition is protected against unauthorized copying under Title 17, United S tates Code.

ProQuest LLC 789 East Eisenhower Parkway P.O. Box 1346 Ann Arbor, Ml 48106-1346

Declaration

I hereby declare that I am the sole author o f this thesis.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

Haibin Dong Department of Civil Engineering Ryerson University

i

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

Haibin Dong Department of Civil Engineering Ryerson University

1 1

Borrower's page
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign helow, and give address and date.

Name of Borrowers

Date

Address

Signature

Ill

Abstract

This thesis addresses the topic of semi-automated extraction of urban road networks from high-resolution satellite imagery. Research on this topic is mainly motivated by the use of geographic information systems in transportation (GIS-T), and the need for reliable data acquisition methods and to update GIS-T databases. To this end, 1-m spatial resolution IKONOS imagery provides a new data source to collect the spatial models of citywide road networks.

In this thesis, a novel methodology of a semi-automated road extraction using highresolution satellite imagery over urban areas is developed. The main objective of this research is to extract urban road networks from a single IKONOS image. To detect the road features from a highly complex scene, a multiscale analysis of the optimal image was performed. To extract roads and their networks, the knowledge o f road geometry is exploited in an interactive environment. The key advantage of the developed method is the full employment of a human and a computer's abilities for fast and precise road extraction from high-resolution satellite imagery. The results show that the presented method enables reliable road extraction over urban areas. The potential applications exemplified in case studies indicate that the high-resolution satellite imagery offers an efficient and precise source for geographic and transportation databases. Based on this research, the limitations and future work for the prototype system are discussed.

IV

Acknowledgements

First of all, I would like to thank my supervisor Dr. Jonathan Li for his kind supervision and many good ideas. Special thanks for all fiuitful discussions, invaluable suggestions and critical remarks. I would also like to thank him for bringing me to the active research field of remote sensing for transportation. Many thanks go to Dr. Said M. Easa, my co supervisor, for his critical guidance and patience. His serious and significant research had a great influence on my work. I appreciate that he gave me initial research topic, ideas regarding extraction of various types of horizontal curves, transportation knowledge, and times o f discussion. Their efforts to ensure my financial support during my study are also appreciated.

I also attribute my accomplishments to Dr. Michael Chapman, Dr. Ahmed El-Rabbany, Dr. Songnian Li, and other faculty and staff members in the Department of Civil Engineering, for their encouragements, in particular, Desmond Rogan for kindly helping me many times to solve computer and network-related problems. Many thanks are also due to the department secretaries, especially Kim Kritzer and Dianne Mendonca, for their kindness and assistance.

I would like to acknowledge all my fellow graduate student at Ryerson University, who have helped me in countless ways and made the period of study an enjoyable time, in particular, Artur Fidera, Hongmei Zhao, Jun Nie, Mohamed Abdalla, Mohammed ElDiasty, Wenglong He, Xiangqian Gao, Yinfeng Li, and Yu Li.

The financial support partially provided by the School of Graduate Studies is gratefully acknowledged. Thanks also go to Anthony Sani of Spatial Geo-Link, Inc. in Toronto for his support with the latest version of ERDAS Imagine software and the Greater Toronto Airports Authority (GTAA) for providing the IKONOS satellite imagery used in my research.

Last, but not least, I wish to express my unfathomable gratitude to my parents, for their understanding and their enduring patience during my studies. I could have never completed this thesis without their greatest support.

VI

Table of Contents
Declaration.............................................................................................................................. ü Borrower's page.....................................................................................................................in Abstract...................................................................................................................................iv Acknowledgements................................................................................................................. v Table of Contents..................................................................................................................vii List of Figures......................................................................................................................... x List of Tables......................................................................................................................... xi List of Abbreviations............................................................................................................xii 1 1.1 1.2 1.3 1.4 2 2.1 2.2 2.3 INTRODUCTION......................................................................................................... 1 Motivation.....................................................................................................................1 Problem Statement....................................................................................................... 3 Research Objectives..................... 4

Thesis Organization..................................................................................................... 5 LITERATURE REVIEW............................................................................................6 Multiscale Edge Detection.......................................................................................... 7 Parametric Feature Detection.....................................................................................10 Automatic Methods.................................................................................................... 13 Use of Single Image........................................................................................... 13 Use of Multi source Data....................................................................................14 Use of Multiscale Images...................................................................................15 Use of Combination of Multisource Datasets and Multiscale Images 16

2.3.1 2.3.2 2.3.3 2.3.4 2.4

Semi-automatic Methods......................................................................................... 16 Active Tracing....................................................................................................17 Snakes................................................................................................................17 Template Matching............................................................................................ 18 Classification.......................................................................................................18

2.4.1 2.4.2 2.4.3 2.4.4 2.5

Summary of Existing Methods................................................................................ 19

vn

3 3.1 3.2 3.3

METHODOLOGY...................................................................................................... 21 Input Data Description............................................................................................... 21 General Strategy for Semi-automated Road Extraction........................................... 23 Image Preprocessing...................................................................................................25 Interpretation of Image Data............................................................................. 25 Standard Deviation Stretch................................................................................30 Decorrelation Stretch.........................................................................................34

3.3.1 3.3.2 3.3.3 3.4

Wavelet Edge Detection............................................................................................ 35 Frequency Analysis............................................................................................ 35 Time-Scale Analysis.......................................................................................... 35 Dyadic Wavelet Transform................................................................................38 Regularity Analysis............................................................................................ 38 Multiscale Edge Detection.................................................................................38

3.4.1 3.4.2 3.4.3 3.4.4 3.4.5 3.5

Geometric Feature Detection..................................................................................... 47 Extraction of Simple Horizontal Circular Curves............................................ 49 Extraction of Reverse and Compound Curves................................................. 55 Extraction of Spiral Curves................................................................................58 Extracting Second Roadside..............................................................................62

3.5.1 3.5.2 3.5.3 3.5.4 3.6 4 4.1 4.2

Connection to Desktop GISEnvironment..................................................................64 CASE STUDIES............................................................................................................67 Study Areas................................................................................................................. 67 Image Preprocessing...................................................................................................70 Standard Deviation Stretch................................................................................70 Decorrelation Stretch.........................................................................................73 Principal Components Analysis........................................................................ 73 Results and Discussion......................................................................................75

4.2.1 4.2.2 4.2.3 4.2.4 4.3 4.4

Wavelet Edge Detection............................................................................................ 75 Extraction of Road Curves......................................................................................... 80 Extraction of Simple CircularCurves................................................................ 81 Extraction of Reverse and Compound Curves................................................. 83

4.4.1 4.4.2

Vlll

4.4.3 4.4.4 4.5 4.6 5 5.1 5.2 5.3 5.4

Extraction of Spiral Curves..............................................................................84 Results and Discussion....................................................................................85 86

Extraction of Road Networks.......................................................................

Performance Evaluation............................................................................................ 88 CONCLUSIONS AND RECOMMENDATIONS.................................................. 97 Summary.................................................................................................................... 97 Limitations................................................................................................................. 99 Conclusions.............................................................................................................. 100 Recommendations for Further Research............................................................... 102

BIBLIOGRAPHY................................................................................................................103

IX

List of Figures
Figure 2.1 Overlooks and profiles of (a) step edge, (b) line edge, and (c) comer edge 8 Figure 3.1 Scheme for the proposed approach of extracting road networks...................... 24 Figure 3.2 Histograms of stretch methods............................................................................32 Figure 3.3 IKONOS Images of Kampsax, Denmark resampled at scale (a) 1:25,000, (b) 1:10,000, and (c) 1:2,500...............................................................................................37 Figure 3.4 Modulus maxima of continuous WT of ID signal,........................................... 39 Figure 3.5 Four test directions for the Canny algorithm......................................................41 Figure 3.7 Classical image Circle for the wavelet edge detection...................................... 47 Figure 3.9 Geometric properties of a circle.................................................................. 52 Figure 3.10 Schematic representation for establishing a simple horizontal curve.............53 Figure 3.11 Schematic representation for establishing a reverse horizontal curve............56 Figure 3.12 Schematic representation for establishing a compound horizontal curve 56 Figure 3.13 Flow diagram for establishing reverse and compound horizontal curves 59 Figure 3.16 Detection of double roadsides........................................................................... 63 Figure 4.1 SDS(a = 2) enhanced image of study area 1...................................................... 68 Figure 4.2 SDS(a = 2) enhanced image of study area 2 ......................................................69 Figure 4.3 Original image of study area 1 without any enhancement.................................71 Figure 4.4 Histogram of original image................................................................................72 Figure 4.5 Histogram of the SDS-enhanced image.............................................................. 72 Figure 4.6 SDS-DS-enhanced image of study area 1 depicted in Figure 4.3..................... 74 Figure 4.7 Histogram after DS-enhanced.............................................................................74 Figure 4.8 SDS-PCA enhanced image of study area 1 depicted in Figure 4.3...................76 Figure 4.9 DS-PCA-enhanced image depicted in Figure 4.3...............................................77 Figure 4.10 The difference image o f the PCA image and DS-PCA im age...................... 78 Figure 4.11 Edge image of the image of study area 1(Figure 4.9) at wavelet scale 1.......79 Figure 4.12 Edge image of the image of study area 1(Figure 4.9) at wavelet scale 2.......80 Figure 4.13 Edge image of the image of study area 1(Figure 4.9) at wavelet scale 3.......81 Figure 4.14 Results of establishing horizontal curves at complex freeway interchange.. 82 Figure 4.15 Results of establishing reverse horizontal curves in urban residential area.. 83 Figure 4.16 Results of establishing compound horizontal curves in urban highway area.84 Figure 4.17 Results of establishing spiral horizontal curves in urban highway area 85 Figure 4.18 Segmented freeway interchange in the image of study area 1........................ 87 Figure 4.19 Segmented road network in the image of study area 2.................................... 88 Figure 4.20 Vectorized freeway interchange in the image of study area 1.........................89 Figure 4.21 Vectorized road network in the image of study area 2.................................... 90 Figure 4.22 Extracted road centerlines using the method based on FMM (Li et al., 2003). ......................................................................................................................................... 92 Figure 4.23 Overlay of the extracted highways on the input image of study area..1........ 95 Figure 4.24 Overlay o f the extracted road networks on the input image of studyarea 2. 96

List of Tables
Table 3.1 Specifications of IKONOS imagery.................................................................... 22 Table 3.2 Weights of three conversion methods from RGB to gray-scale.........................27 Table 4.1 Sample image information................................................................................... 70

XI

List of Abbreviations

ID ..........................................................One-Dimensional 2D..........................................................T wo-Dimensional 3D..........................................................Three-Dimensional 4D..........................................................Four-Dimensional ANN......................................................Artificial Neural Network DEM..................................................... Digital Elevation Model DN........................................................ Digital Number DS......................................................... Decorrelation Stretch DSM..................................................... Digital Surface Model DWT......................................................Dyadic Wavelet Transform FMM..................................................... Fuzzy Mathematical Morphology GIS........................................................ Geographic Information Systems GIS-T.................................................... Geographic Information Systems in Transportation HT......................................................... Hough Transform INSAR.................................................. Interferometric SAR PCA......................................................... Principal Component Analysis SAR.......................................................Synthetic Aperture Radar SDS....................................................... Standard Deviation Stretch WT........................................................ Wavelet Transform

xn

1 INTRODUCTION

1.1 Motivation

From a practical point of view, research on automatic road extraction in urban areas is mainly motivated by the use of geographic information systems in transportation (GIS-T) and the need for data acquisition and update for GIS-T databases. Applications of road data of urban areas include analyses and simulations of traffic flow, estimation of air and noise pollution, street maintenance, and so on. From a scientific perspective, the extraction of roads in complex urban environments is one of the challenging issues in remote sensing and photogrammetric computer vision, since many tasks related to automatic scene interpretation are involved. Factors greatly influencing the scene complexity are, for instance, the number of different objects, the amount of their interrelations, and the variability of both. Moreover, each factor - and thus the scene complexity - is related to a particular scale.

Although traditional aerial photographs can provide maximum detail and precision, satellite imagery has already greatly benefited areas, such as functional planning of highway and railway networks. Since 2000, high-resolution satellite imagery has been used in various mapping and engineering applications. Moreover, satellite imagery over one area can be recaptured continuously over days or weeks. Satellite remote sensing is a fast and cost-effective way to collect digital images of road networks over a considerably large urban area. The new generation of high-resolution imaging satellites (e.g., IKONOS,

QuickBird) have presented more details and precision on urban man-made features (e.g., roads, buildings). For example, roads appear to be elongated regions in Im resolution IKONOS imagery rather than linear features in 30m resolution Landsat TM imagery. Nevertheless, extract useful spatial object information (e.g., buildings, roads, and vegetation) is a difficult task. Although human beings are good at abstracting useful information they need, the accuracy is lost during the vectorization due to mistakes in human interaction (e.g., misshaping and misplacement).

In general, man-made objects have regularities in size, shape, and surface. These regularities facilitate the extraction of man-made objects from remote sensing imagery. A good survey of existing approaches can be found in Zhang (2003). The geometry of a road is a good example of this regularity. Thus far, many approaches have been developed to extract roads from aerial and satellite imagery. These approaches are based on either spatial, spectral, or both characteristics of the road. In low-resolution satellite imagery (e.g., Landsat TM, SPOT HRV), roads appear as linear or curvilinear features, to which some contour finding methods can be applied. In medium-resolution satellite imagery (e.g., 1RS-1C/ID and MOMS-2), these roads appear as nearly homogenous elongated regions. In high-resolution satellite imagery (e.g., IKONOS and QuickBird), the roads appear as elongated regions with more details (e.g., traffic markings, manholes, curbs, cars, and shadows). The selection of extraction approaches should correspond with the level of image resolution. So far, many existing approaches, working on highresolution satellite imagery, are actually based on the algorithms developed for lower resolution satellite imagery following a downgrading preprocessing to reduce the image spatial resolution. This compromises the accuracy of the results and the full exploitation

of high-resolution data. Extracting roads and their networks from high-resolution satellite imagery and taking advantage of most data spectra should be a new research topic in remote sensing.

1.2 Problem Statement

In most cases, users prefer to work with a single image to extract all desired information. The new generation of high-resolution satellites can provide stable and economical highresolution image source. However, in high-resolution satellite imagery, detailed urban features (e.g., traffic markings, manholes, curbs, cars, and shadows) make urban road extraction more difficult. Fully automated methods have proven to be more sensitive to the details than semi-automated methods considering the reliability and accuracy of the results. As such, semi-automated methods may be more operational.

Most urban highways are designed and constructed using relevant policies of highway geometric design. With high-resolution satellite imagery, reestablishing geometric design parameters and reconstructing road networks from imagery are possible. One of the major responsibilities of highway survey for existing highways is to reestablish the centerlines of highways, of which curve segments are much more complex than line segments.

The curved highway segments can be either horizontal or vertical. However, most remote sensing images are overhead, or nearly overhead, snapshots of views parallel to the plane of local Earth's surface. The vertical alignment of the road is unclear without auxiliary

information, such as topographie data. However, compared to horizontal alignment, the scale of the vertical alignment eould be ignored especially in most urban areas. To maximize the retrieval of useful information, and suppress the unwanted or redundant data, three major image-processing techniques will be studied and applied. They are radiometric, spectral, and spatial enhancement.

1.3 Research Objectives

In this study, the road and its network extraction from high-resolution satellite imagery is the focus. The applications of remotely sensed data and analysis in geomatics and transportation areas are also illustrated. By fully exploiting high-resolution satellite image data, the ability of abstraction of human, and the high-accuracy and high-performance of digital processing technology, the objective of this study is to develop a semi-automatic road extraction method that can generate high accuracy data source for GIS-T databases. Specifically, the following tasks will be accomplished in this research: (1) To create a single-band image from a single true-colour IKONOS image by image preprocesing. (2) To generate an edge image appropriate for desired feature extraction from the single-band image using multiscale image analysis. (3) To extract the road networks by geometric analysis of linear and curve road edges presented in the edge image. (4) To approximate the road networks for the applications in such areas as remote sensing and GIS using the extracted road geometric parameters.

1.4 Thesis Organization

This thesis consists of five chapters. After this introduction, Chapter 2 introduces the basic concepts and describes previous related work, including semi-automatic and automatic road extraction methods, and the key techniques of image processing and analysis in remote sensing. Chapter 3 presents a detailed description of the methodologies developed and used in this thesis. In general, these methodologies are grouped into data collection, image pre-processing, wavelet multiscale analysis, feature extraction, and data integration, respectively. Chapter 4 includes case studies of the methodologies on IKONOS satellite imagery. The experimental results and system performance evaluation are presented. In Chapter 5, the summary and conclusions are presented based on the results of this research work followed by some recommendations for further research.

2 LITERATURE REVIEW

The extraction of urban road networks from remotely sensed images has drawn considerable attention lately. The existing approaches use a wide variety of strategies using different resolution aerial or satellite images. Semi-automated schemes require human interaction to provide interactively some information to control the extraction. Roads are then extracted by automatic algorithms. Automatic methods usually extract reliable hypotheses for road segments through edge and line detection and then establish connections between road segments to form road networks. This chapter tries to review several existing techniques.

As a complete road extraction methodology, low-level to high-level procedures are to be followed. These procedures are to find road pixels, road segments (road pixel group), road (road segment group), and road networks (road group), consecutively. Section 2.1 reviews the multi scale edge detection techniques that are useful for finding road pixels in imagery. Section 2.2 reviews the parametric feature detection techniques that are useful for finding of road segments. The automated and semi-automated methods dedicated to perform partial or complete road extraction procedures are reviewed and summarized in Sections 2.3,2.4 and 2.5, respectively.

2.1 Multiscale Edge Detection

An edge could be defined as points where the image intensity has sharp transitions (Mallat, 1998). Edges are the most important elements for identifying the feature by the human vision system. This can be explained by that when drawing a picture, the first thing to draw is the profile of targeted object, then, on which, colours and/or textures are added to further describe more properties. In most cases, the edges already tell what an object is or what an object looks like. For a computer vision system, many analytical methods are performed on the edge image generated rather than directly on the raw image. The edge image can depict the structural and morphological properties of important features abstracted from raw imagery.

The edge detection operation is important because it is used to locate where the roads might be. A survey on edge detection techniques can be found in Ziou and Tabbone (1997). According to them, the most common types of image intensity variations are steps, lines and comers (see Figure 2.1); and the majority of existing edge detection algorithms are applied to step edges which are the most common edges in images.

In low-resolution satellite images, a road detection algorithm is used to find the line edge, while in high-resolution satellite images where a road segment is depicted as elongated homogeneous area, it is used to find the two parallel step edges.

/

/ I

#: sr. .% < > '

i
%
(b)

#

(a)

(c)

Figure 2.1 Overlooks and profiles of (a) step edge, (b) line edge, and (c) comer edge.

It is a fact that one edge detector with one scale cannot identify all edges in an image (Ziou and Koukam, 1995). The multi-scale edge detection offers a solution for using only one detector with multiple scales (Ziou and Tabbone, 1997). A step towards multiscale image analysis techniques was motivated by the need for a preprocessing operation to regularize the differentiation operators (Torre and Poggio, 1980). Canny (1986) proposed a method that determines an "optimal smoothing filter" for multiscale detection of step edges. He pointed out that the smoothing filter could be approximated by the first-order derivative of a Gaussian kernel. He also introduced the concept of non-maxima suppression and hysteresis threshold.

Much of the research for the development of wavelets was carried out in the thirties of 20**' century, it was only in recent years that wavelet applications have been widely found.

The two-dimensional (2D) multiscale discrete wavelet transform (WT) analysis and associated fast filter bank algorithm were first founded in Mallat (1989). Mallat (1992a) argued that the fundamental weakness of the classical edge detectors is that they create binary edge images and lose most image information and create instabilities in further processing. Although the wavelet approach is equivalent to the Canny edge detector that is based on the gradient analysis on imagery, it manipulates the edges at multiple scales, and integrates the information at these scales to locate edges precisely, and to reduce noise simultaneously.

Most edge detectors perform poor at comers, where two edges intersect. Chen et al. (1995) proposed a WT-based comer indicator that locates the comer points based on the orientation variance. Multiscale image analysis is based on either intensity or edge images. According to the summary in Hay et al. (2003), multiscale image analysis is composed of two steps: (1) the multiscale representations of imageiy and (2) information extraction.

Mayer (1996a) created multiscale images with different smoothness kemel fi"om the source image, such that abstraction of desired features is to be found on appropriately scaled image. Mayer and Steger (1996b) introduced a concept of multi-abstraction that is another representation space. An abstraction is defined as the increase of the level of simplification and emphasis. Substmcture (minor stmctures) at each level should be neglected. Mayer and Steger (1998c) used their method to detect curvilinear stmctures in image. The idea of 2D spatial pattem is considered that the signal in an image is the composite of pattems at different scale superimposed on each other. The large-scale

pattems, such as land and sea, can be regard as background, on which small-scale pattems, such as buildings and roads, are added. Hoffinann (2001) used multi-scale IKONOS images to establish a hierarchical network of urban features based on the classification.

Although multiscale edge detection is an ideal way to achieve desired edges, the selection of the appropriate scale is still dependent on human interpretation, which is one of the main manual operations. However, several efforts have been done to do it automatically. Lindeberg (1998) introduced the concept of seal e-space edge, in which an automatic mechanism for selection of scale levels is applied in detecting one-dimensional (ID) image features, such as edges and ridges. The strength of edge response was the measure derived from third-order derivative in the gradient direction. Zhang and Bao (2002) reported a better resulting edge map when using a multiplication of adjacent scale edge images, such that the noise is further suppressed and the dislocation is improved. Jung and Scharcanski (2003) separated noise and edges with adaptive criteria in scale-space using the WT. Their results show that WT is capable of suppressing noise without the priori knowledge of noise level while still keeping sharp edges.

2.2 Parametric Feature Detection

The edges detected by edge detectors are simply composed o f the pixels considered as belonging to an edge based upon same definition. There is no intemal spatial relationship

10

among these edge pixels in an edge image. Finding and describing the relationship of these pixels with parameters are the tasks of parametric feature detection.

The pixels representing for edges of features can be linked using a simple contour-tracing algorithm (Gonzalez and Woods, 1993). They are encoded with the Freeman chain model (Freeman^ 1975) and saved in a Region Search Map with which structural and morphological information about the regions could be retrieved for further applications.

In this study, roads are of particular features of interest to be detected. In low-resolution satellite imagery, roads are at most only a few pixels wide and appear as light or dark lines. In high-resolution satellite imagery, roads are modeled as bright homogeneous regions bordered by parallel edges (Baumgartner et al., 1996), in which roads can be approximately treated as polygons.

Steger (1996) extracted the curved lines in aerial images by computing the Taylor polynomial approximation, and then determined the width of them. His solution still cannot give the parameters of the curves although the line can be given to subpixel accuracy. Dong et al. (1996) did some similar work in edge detection using WT, and edge orientation recognition using a statistical method, but on Landsat TM and SPOT HRV images. Ji (1996) applied dyadic WT to delineate the agricultural field boundaries from Landsat TM imagery. As the author inferred, his method was area-dependent and did not work well over urban areas.

11

Rosin and West (1989) presented a method to segment edges into lines and arcs. Their method requires two initial points at the ends of a chain of points to detect the arcs on this chain. Keller et al. (1995) introdueed a multiscale method for the detection of curvilinear structures in 2D image data, which is more sensitive to linear edges, while suppressed in curve seen from their sample results. Dori and Liu (1998) developed a vector-based arc segmentation method that computes the center of a potential arc. They categorized the arc detection methods into two main families. The methods in the first family are based on the Hough transform (HT) and work directly on the original pixels of the images. This family of methods proves to be quite robust in the presence of noise, but requires quite intensive computation.

The second family works on the chains of points or the polygonal approximation of such chains. The curvature of these chains can be estimated. Dosch et al. (2000) surveyed the two above-mentioned methods for arc and circle detection, and presented an improved method inspired by surveyed methods. However, these three methods were designed to work well under ideal condition, such as in a graphics document. They are insufficient to deal with complex context of features and noise in remotely sensed imagery. Mayer (1998b) described a way of detecting curvilinear structures in image which convolves image with second partial derivatives and finds the maximum direction as the normal directions of a curve.

Baker (1998) explored the approach to detecting the features through multi-cues, including steps, lines and comers. Carreira et al. (2002) used WT edge detector and four

12

dimensional (4D) HT to detect and classify perceptual primitives on close-range photographs.

2.3 Automatic Methods

Automated methods are not autonomous methods. There can be human interactions before and after computer-based phases. Many of them have been developed. All of them try to utilize as much information as possible from available data to accomplish the goal automatically. Thus, the methodologies are categorized by the strategy of how they utilize the dataset accordingly. They work with either (1) single image, or (2) multisource data, or (3) multiscale images, or (4) a combination of (2) and (3).

2.3.1 Use of Single Image

To reduce system errors and cost, many existing methods tried to extract the road from a single image. A road extraction system RoadF, developed and introduced by Zlotnick and Gamine (1993), was based on geometric constraints (parallel edge pairs of road) for automatic road finding, tracking, and linking from aerial images. Trinder and Wang (1998) presented a method, based on Marr's theory of vision (Marr 1982) and human knowledge, of automatic road extraction from aerial images. Three processing levels were involved, including parallel edge pair detection, linking and formation of road stmcture with knowledge of geometric and radiometric properties express as mles in Prolog, and recognition of roads. Xiong (2001) introduced an optimization-based method for extracting road networks. It is a method involved dynamic programming and

13

supervised classification. Doucette et al. (2001) used a neural network clustering method to extract the centerlines and to construct self-organized road networks on high-resolution classified aerial image. Li et al. (2003) presented an automated approach to urban road network extraction based on fuzzy mathematical morphology (FMM), the performance of which was easily affected by the complexity of context. The dislocations of road centerlines were obvious near the shadows or road intersections.

2.3.2 Use of Multisource Data

If a single data source is insufficient to retrieve the desired information or to achieve required accuracy, use of multisource data is one solution. For the purpose of road extraction, most methods use more than a single image, such as multiple images or another form of ancillary data.

Barzohar and Cooper (1996) presented an approach built on geometric- probabilistic models to find main roads in aerial images. A map was needed for their road estimation method. Steger et al. (1997) presented an approach of completion of road networks from aerial images, using a graph representation of the road network and Digital Surface Model (DSM) data. Ruskoné and Airault (1997) designed an approach, based on its automatic seeding, of detection of road networks from aerial images. It can, reportedly, extract 40% of the road networks. Klang (1998) used a knowledge source from road databases to discriminate roads from rivers, railways or other lines in the image, and the roads in the database were employed to initialize snake seeds. Fiset et al. (1998) developed a map-image matching method that uses artificial neural network (ANN) on

14

SPOT imagery and rasterised old maps to find the updated segments of the road. Zhang et al. (2001) presented a knowledge-based system for automatic extraction of 3D roads from stereo aerial images. In contrast to other approaches, the developed system integrates processing of colour image data and information from spatial databases, extracts and fuses multi-cues, takes into account context information, employs existing knowledge, rules, and models, and treats each road accordingly.

2.3.3 Use of Multiscale Images

Generally, a method used to extract roads is only appropriate for an image with a certain scale level. Different scale levels can be modeled and interpreted differently and accordingly. Multiscale images derived from a single image provide an ancillary means to analyze this image.

Heipke et al. (1995) used multiresolution analysis applied on aerial imagery to construct a hierarchical approach of detect roads in rural areas. Baumgartner et al. (1997) presented a multiresolution approach for automatic extraction of roads from aerial imagery. This approach is based on the extraction of edges in an aerial image and the extraction of lines in a resolution-reduced image. Baumgartner et al. (1999a) reported a three-module scheme for automatic road extraction in rural areas. The three modules are (a) multiscale detection of most part of a road network, (b) global grouping by the network characteristics o f roads, and (c) completion of the road network by analysis of path length. Baumgartner et al. (1999b) made use of versions of an aerial image with different resolutions to model and detect a network of intersections and links of the rural roads.

15

Amini et al. (2002) used a morphological algorithm to segment and convert an image into binary one, whose resolution was reduced by WT to extract the skeleton o f roads. The final roadsides are found by the searching roadside algorithm using the original image.

2.3.4 Use of Combination o f Multisource Datasets and Multiscale Images

Some newly developed methods exploit the advantages of use of both multisource datasets and multiscale images. Hinz et al. (1999) used a multiscale strategy to find initial hypotheses in rural area, and digital elevation model (DEM) data and road markings were used to help identify urban roads. Hellwich and Wiedemann (2000) used fusion technology on multisource data to extract the road network in rural areas. These data include the Im-resolution panchromatic aerial photographs, hyperspectral imagery, interferometric synthetic aperture radar (InSAR) data, and DEM. Continuing the work in (Hinz et al., 1999), Hinz and Baumgartner (2003) integrated high-resolution aerial imagery, DSM and context model to extract road networks over urban areas.

2.4 Semi-automatic Methods

Semi-automatic methods integrate manual operations with automatic modules in the workflow. These methods are categorized into four kinds: (1) active tracing, (2) active contour or snakes, (3) template matching, and (4) classification.

16

2.4.1 Active Tracing

This category of methods tries to trace the road extension by starting from a user defined point and/or road direction. McKeown and Denlinger (1988) developed a method that requires a start point and direction to trace a linked road in aerial imagery. Vosselman and Knecht (1995) also used tracing and a Kalman filter by the user-specified start point and direction. Given a starting point and direction, Geman and Jedynak (1996) traced the road network using "active testing" technique on a medium-resolution satellite imagery where road can be searched as a ID structure. Shukla et al. (2002) used a Canny edge detector to generate thin feature edges, with which the path-following technique is performed at the direction determined by a cost minimization technique.

2.4.2 Snakes

This category requires the seeds, set by a user, near the interested road to outline the road contour. Gruen and Li (1995a) applied WT in a SPOT image to sharpen the edges, where seed points were given by the user, then road tracking and linking are performed automatically and optimization is done by dynamic programming. Gruen and Li (1995b) designed a scheme based on either dynamic programming or least-squares B-spline snakes. In this semi-automatic technique, roads on aerial images, with many details and other objects distributed, cannot be processed appropriately. Gruen and Li (1997) used 3D least-squares B-spline snakes to detect boundaries of the roads in rural areas using aerial images. An approach based on multiscale detection, and geometry-constrained edge extraction using a snake algorithm was proposed and advanced by Mayer et al.

17

(1998) and Laptev et al. (2000), in which down-sampling to a coarse-scale image was performed in order to find edge points which are then used as snake seeds. Auclair et al.
(2001) worked with active contour, or "snakes" approach, but automates the seeding procedure by deriving existing topographic database.

2.4.3 Template Matching

Some methods regard a road as the concatenation of road segments with certain geometric properties. According to the geometric properties of a road segment, a template is designed and used to find the matched road segments in the image. Park and Kim (2001) presented a template-matching algorithm for road extraction fi' om 1-m IKONOS imagery. Given a road seed on the centerline, the algorithm used an adaptive leastsquares method to compare the template and window on image. The shortcoming of the algorithm is that it is sensitive to the position of the seed on the centerline, the presence of shadows, and the curvature of road segments. Dal Poz and Silva (2002) presented a semi-automated method for extracting road segments and centrelines from medium- and high-resolution images based on both active template testing and edge analysis.

2.4.4 Classification

Classification methods utilize the spectral characteristics o f roads in the image. The results are produced by a certain classification method, which divides the image into road areas and non-road areas. Chiesa (2001) developed a software package, called Veridian System that works with classification and extraction of transportation features in Landsat

18

TM imagery. However, this system does not offer additional benefit over manual extraction and vectorization as admitted by the author.

2.5 Summary of Existing Methods

Road data are important for many applications. However, manual extraction of road networks is time-consuming and sometimes inaccurate. That is why many automated and semi-automated extraction approaches have been developed. The road segment in highresolution satellite imagery of urban areas is susceptible to traffic markings, vehicles, sidewalks, curbs, shadows, etc. Methods based on tracing consider the parallel edges of road, and/or the profile of the road cross-section. Methods, like dynamic programming or snakes-based, were only designed for low-resolution imagery where roads appear to be linear features, and results are error-prone because the algorithms merely count on the local intensity of image if disturbances are present.

Multi-images or auxiliary data can assist in the extraction on the road features or even 3D information of the roads from 2D data. However, in flat urban areas, it is not preferable considering the availability, cost, and accuracy of the extra data, and aspects of efficiency.

Among the existing road extraction approaches, most of them work well on roads with relative simplicity in rural areas. Most of them use aerial imagery. Most of them assume that roads are linear or rectangle features on imagery, and regard implicitly the curve segment as the links of piecewise straight segments. Those studies on curve features

19

detection only work with ideal simple image (e.g., like graphic documents) or small-scale curve (e.g., the circle/arc whose diameter radius is less than the dimension of the image).

Many algorithms merely generate results as the group of pixels belonging to the road or its centerline, not the higher-level description for each road. Most of those algorithms, aiming at detection of high-level semantic objects, simply model road segments as lines or rectangular shapes, even along the curved segments. Those methods, considering a curve as higher order curvilinear feature rather than linked linear pieces, have to rely on the either active tracking or active contour (snakes) to approximate the curves. They are inaccurate and greatly sensitive to the disturbing objects and noise.

Many methods are designed to extract the roads with the characteristics of elongated linear or rectangle features. Nevertheless, some natural features (e.g., rivers) and manmade features (e.g., open ditches, running tracks) also satisfy this model. For practical applications, there should be involvement with human knowledge and interaction, more or less, integrated with automated steps.

From the summary of the literature review, this study focuses on the use of a single highresolution satellite imagery, employs a multiscale analysis technique, and is based on the geometric curvilinear feature detection for semi-automated road extraction. Chapter 3 and 4 will give the details on the new methodology and its implementation with two case studies.

20

3 METHODOLOGY

This chapter describes a semi-automated knowledge-based approach of road network extraction. Section 3.1 introduces some specifieations of high-resolution IKONOS imagery used in this study. Section 3.2 gives a brief deseription of the concept and procedures of the road extraction method. To assist further edge detection, some image preprocessing is used and discussed in Section 3.3. The multiscale edge detection based on wavelet transform is described in Section 3.4. The parametric feature detection methods for extracting the road network are presented in Section 3.5. Finally, Section 3.6 describes some methods that implement some useful applications for the proposed approach.

3.1 Input Data Description

The advent, over the last few years, of the third generation of high spatial resolution imaging satellites (e.g., 1-m IKONOS, 60-cm QuickBird) could stimulate the development of remote sensing of urban areas further. The data produced by these sensors facilitate superior discrimination of the urban features (Donnay et al., 2001). Many areas appear to be spectrally heterogeneous in images from the new, finer spatial resolution sensors. This implicates the more inherent spatial complexity of urban scenes, and the potential to extract urban features.

21

Space Imaging's IKONOS satellite is the world's first commercial satellite to collect panchromatic images with 1-m resolution and multispectral images with 4-m resolution. It orbits the Earth every 98 minutes at an altitude of approximate 680 km. IKONOS was launched into a sun-synchronous orbit, passing a given longitude at about the same local time (10:30 A.M.) daily. IKONOS can produce 1-m imagery of the same location on the Earth every 3 days. Table 3.1 lists the main spectral and spatial characteristics of the IKONOS sensor.

Using data fusion technology, these bands, with 1-m and 4-m spatial resolution listed in Table 3.1, can be transformed into 1-m resolution multispectral imagery, such as the true colour IKONOS image used in this study. Fundamentally, the proposed approach works with a single-band image, to which the IKONOS multispectral image should be converted before the application.

Road network extraction from IKONOS imagery has significant applicability in transportation. It is a means of creating and updating GIS-T databases, upon which abundant information could be utilized or analyzed for transportation purposes, such as traffic management, infrastructure pi arming, road safety analysis, and route guidance. The research work required the orthophotos not only for the integration with GIS databases, but also for precise geometric primitives to achieve good results. The linear and arc features are the most important parametric road segments in the image, in which each location of pixel should be linked to the real object coordinates.

22

Table 3.3 Specifications o f IKONOS imagery.

Band Blue Green Red Near-Infrared Panchromatic

Spectral Range (Mm) 0.45-0.52 0.51-0.60 0.63-0.70 0.76-0.85 0.45-0.90

Spatial Resolution (m)

Radiometric Resolution (bit)
1

Temporal Resolution (day)

3.2 General Strategy for Semi-automated Road Extraction

Using multispectral IKONOS imagery, the urban environment is one of the major problems preventing conventional spectral analysis. The high feature density of the urban scene causes problems, like shadows and mixed-pixel effects. Although conventional multispectral classification methods can be applied successfully to rural areas, these methods are error-prone for applications in urban areas.

In this section, a novel strategy for semi-automated road extraction is proposed. The strategy is illustrated in Figure 3.1. The main objective is to derive robust and efficient methods that process raw image data to extract road edge segments, find the edge correspondences across images, and transfer them to 2D object space that can be used in a desktop GIS environment. The scheme is designed as a bottom-up process, in which the available information and organizational process are introduced at several layers of image processing.

23

High-Resolution Satellite Image

Image Preprocessing (SDS, PCA and DS)

Grey Image

Edge Detection (Wavelet Transform Based)

Binary Edge Image

Human operator Intervention

Detecting Features (Line Segments by HT, Curve Segments by Developed Curve Extraction Methods)

Raster Image

V ector Image

F eature Parameters

Figure 3.1 Scheme for the proposed approach of extracting road networks.

The core of the system prototype consists of three main components: (1) edge extraction, (2) parametric road segment detection, and (3) road network reconstruction. There are two separate processes in the parametric segment detection component: detection of straight road segments and curve road segments. Each segment is important and possesses particular features. On the other hand, these two processes are related to each
24

other in terms of the computation of their attributes. Straight road segment detection is the premise of the curved road segment detection, whose results will be fed back to rectify straight road segments.

This study focuses not only on object detection, but also on object recognition and identification. At the detection level, the objective is to separate objects discretely. At the recognition level, the objective is to determine what the objects are. At the identification level, the objective is to identify the objects. In this study, the three levels refer, more specifically, to edge detection, road segment recognition, and road parameter identification.

3.3 Image Preprocessing

The image preprocessing techniques enhance the edge features in images, which facilitate the edge extraction process. Image enhancement aims to visually amplify these slight differences to make them readily observable (Lillesand and Kiefer, 2000).

3.3.1 Interpretation of Image Data

The images used in the case studies are subsets of an IKONOS image, which is original image without any enhancement. The subsets were cut with the original pixel value intact. To fully exploit the visibility for human vision and computer vision to perform image analysis, image enhancement is necessary. The visual spectrum for human eyes is the electromagnetic energy whose wavelength is approximately between 0.4-0.7 pirn . In

25

terms of colour perception of the human vision, the visual spectrum is from violet to red. Within the range of visual spectrum, human eyes are not uniformly sensitive to the intensity of the light. The peak sensitivity is located at about 0.55 //m , which is in green colour (Mather 1999).

Most remote sensing systems can acquire data concurrently from several channels (multi spectral) to hundreds of channels (hyperspectral) (Sonka et al., 1999). Most optical sensors and cameras are designed to separate the visual energy into three primary colours: red, green, and blue. The primary colours are also called additive colours (Coren and Ward, 1989), which means a colour can result from the weighted addition of three primary components. For example, the colours displayed on television or computer screen is the mixture of red, green, and blue. Image displayed with these three bands are called natural-colour images (ERDAS, 1999), or normal-colour images (Lillesand and Kiefer, 2000), which approximate the colour observation that appears to humans. Gray, or colourless, scene can be simply produced by the combination of three primary colours with the same weight.

Most airborne and spacebome sensors have the capability of detecting multiband data (e.g., the true-colour IKONOS images used in this study). Since WT or Canny edge detectors only inherently process single-band image, integrating as useful much information as possible from multiple bands into a single band (gray-level) image is the primary purpose of the image preprocessing stage in this study. There are many approaches to convert multiband imagery to single-band imagery. The most common approach is based on the theory and experiments on human vision. For human vision, the

26

pixel value in gray-level image represents the "brightness" of the energy projected on this position. Although it could be argued that the brightness is mostly related to the intensity, other dimensions, like wavelength and duration, affect the brightness of human perception as well (Coren and Ward, 1989).

Three common methods can be used to convert the true-colour images to gray-level images. All of them use linear combination of the three primary colours with different weights (Table 3.2). "Luma" is the classic method that complies with the industry video standards (Jack, 1996). "Luminance" is a new measure that mixes the RGB with new weights according to the new technology in the manufacturing of monitors (ITU, 1990). The "Average" method simply uses the arithmetical average of three primary colours, which makes sense when human perception will not be taken into account, and all the data from all bands have the same importance.

Digital images are typically stored in the format of array of primary colours, which provides the possibility to restore and display the original colour scene. Many theories use colour space to represent the colours. RGB cube is one of 3D representation of colour space. The size of the cube is the maximum value for red, green, or blue. These values in this space, called digital numbers (DN), correspond to the average radiance measured at each pixel. DNs are simply the positive integers that result from quantitizing the original electrical signal from sensor into positive integer values (Lillesand and Kiefer, 2000). For example, for data of 8-bit-per-pixel in radiometric resolution, the range of DN is from 0 to 255 (which equals to 2^-1). The number of colours that can be discreetly (i.e., digitally)

27

Table 3,2 Weights of three conversion methods from RGB to gray-scale. Gray-Scale Method Lum a Luminance Average Red 0.299 0.212671 1/3 Green 0.587 0.715160 1/3 Blue 0.114 0.072169 1/3

described is then equal to 2^'*=16,777,216. Gray "colour" is located on the diagonal line from the origin to the opposite comer o f this RGB cube. This means that identical values of red, green, and blue are assigned to a gray-level pixel.

There is no limitation for computers to recognize the binary "data spectrum" in full range mode. The range from energy-free to maximum radiometric value is entirely visible to the computer. However, the results are highly sensitive to the data distribution in the image band(s). For example, the above-mentioned colour-to-gray methods, generally speaking, use weighted averages, which lead to a counteractive effect when there is little or negative correlation between two bands. Thus, conversion from multi-band to single band inevitably loses information, which lies in different bands of the original image.

Fischer (1969) pointed out that colour photography offers a great potential for use in many fields in Earth sciences. It is more satisfactory and promising for recognizing significant features than the panchromatic photography. The preprocessing stage focuses on finding as much information as possible from multi-band images; eliminating as much redundancy and false signal as possible; and integrating the information into a single band image for further edge and feature analysis and extraction.

28

It is possible to reduce the original data dimensions into fewer dimensions without losing too much information, or retaining as much information as possible. For example, in extracting features from the natural-colour image, redundant work will be done if all RGB bands are processed individually, because high correlation in visual bands exists in the normal image. The resulting features will overlap, which introduces difficulty in unifying or separating them. The difficulty is avoidable if a subset of the data could be used in place of the full dataset. The colour-to-gray methods mentioned above are not ideal, at least in the remote sensing area.

Principal components analysis (PCA) has been used to enhance the visibility by the transformation from the original axis of observed variables to the space of principal axis (Mather, 1976).

All of conversion methods have weakness. "Luma" and "Luminance" methods (shown in Table 3.2) could only be applied on RGB bands, while many data source are available with up to more than three visible bands, or even hyperbands. They only focus on human perception, which may not be optimal for digital image processing. Although the "Average" method has no limit on the number of bands, it works well only on highly correlated bands. If little or negative correlation is shown in multiband, its side effect will show that the useful information or contrast is eliminated in the consequential gray-level image.

29

To transform an «-band image to primary component space, the first principal component (PCI) is the axe on which observed variables project with largest variance. The second principal component (PC2) is uncorrelated (orthogonal) to the first one and has the second largest amount of variance. The rest components are thus selected iteratively with descending order in terms of variance, until « mutually uncorrelated primary components have been chosen.

Data volume compression is one of common applications of PCA. As a compression method, PCA is a "lossy" method due to those information transformed in high-order primary components are to be discarded with respect to the low percentages in the total information. When one principal componet out of three bands is used, two thirds of original data space has been eliminated.

3.3.2 Standard Deviation Stretch

The digital number (DN) is the value associated with a pixel in a digital image, corresponding to the value of some physical quantity such as the radiance in a particular band, measured at the detector (Rees, 1999). The range of possible DN values is usually from zero to 2" -1 , where « is the number of binary bits available, in terms of radiometric resolution (Richards and Jia, 1999).

The Standard Deviation Stretch (SDS) is a radiometric processing method, which is widely used to enhance the radiometric characteristics of the original image. Its main

30

effect on the image is the increased intensity contrast compared to the original image that does not use the available full DN range. There are several reasons that the SDS is preferred for the enhancement of image intensity.

As previously mentioned, for the 8-bit radiometric resolution imagery, the possible DN values range from 0 to 255. In this research work, all of the sample and experimental data are in 8-bit radiometric resolution, which means that the possible DNs are always between the ranges. The data in each band are not distributed in the full range. In other words, the minimum value of data is larger than zero, and/or the maximum value of data is less than the possible maximum value. The Min/Max Stretch simply expands the data to the full range of possible values by the linear transformation:

Where, DNstretched = the new DN after stretching, DNoriginai = thc DN of thc original data, DN mox = the maximum DN of the original data, and DN mw = the minimum DN of the original data

The normal distribution is the most encountered data probability model in many natural phenomena. The mean value of normally distributed data is at the peak of the frequency curve, as shown in Figure 3.2. The amounts of data below and above the mean value are balanced. The distribution curve could be represented in the function below (ERDAS, 1999):

31

>20

moan

+2o

256

Stored data file values

Original Histogram
most of the data

^

most of the data ^

2o

moan

values stretched over 255 are not displayed
255

I
-2o

/n
m##n *2o 2S6

D

Stretched data file values

stretched data me values

standard Deviadon Stretch

Mln/Max Stretch

Figure 3.2 Histograms of stretch methods (ERDAS, 1999).

TTC Where, x = the quantity's distribution that is being approximated, n and e = mathematical constants, and

(3-2)

H and a = parameters controlling the location and shape of the probability.

The SDS uses the DNs at which the number of standard deviations stands above and below the mean DN value of original data, rather than the maximum and minimum DN values. Equation 3-2 is modified as:

DN Stretched

2 S S (D N q ,,^ -D N .,, ) D N ,., - D N .,,

(3-3)

32

Where:

cr = standard deviation, n = number of standard deviation, ^^+ncT ~ ^he DN value n a above the mean DN value, and = the DN value no" below the mean DN value.

For example, if the data are normally distributed, the data within two standard deviations ( ± 2 c r ) around the mean includes about 95% of all data (ERDAS, 1999).From the histogram of the normal distribution (see Figure 3.2), the percentage of theseextreme data is small, less than 5%. After using Min/Max stretch, where the data range expand from 0 to 255, these 5% data cover the radiometric space of more than 1/3 of the range. The majority of data are squeezed into the radiometric space of less than 2/3 of 255. Obviously, most of the data are not fully stretched to exploit the ability of human/computer vision.

The standard deviation ( s ^ of ^ sample values (Q) is calculated by (ERDAS, 1999):

^(Qi -M qY
Sq -

'·= '

.

(3-4)

in which, jU q is the mean of the k sample values, which is given by:

33

3.3.3 Decorrelation Stretch

Decorrelation stretch (DS), also called saturation stretch, is a spectral image enhancement technique. However, it works on the principal component space, not on the original spectral space. It exaggerates the least correlated portion of spectral data, improves the intensity and saturation without changing the distribution of hues (Gillespie et al., 1987). Three steps are involved in DS: (1) Principal components analysis (PCA). (2) Gaussian stretch is applied as contrast equalization on the principal components, whose histograms are, then, Gaussian distributed. (3) Inverse PCA transforms the Gaussian stretched PCs into the original spectral spaces.

The DS is the most commonly used image enhancement technique that makes visual interpretation easier. O f course, this method will benefit the machine vision as well. The proposed multilayer-to-gray conversion involves two general steps: (1)The source multilayer image is taken as the input of DS, which will generate a multilayer image. (2)The multilayer is taken as the input of PCA, which will generate the final output single-layer image.

34

3.4 Wavelet Edge Detection

3.4.1 Frequency Analysis

Fourier transform is the most commonly used frequency analysis of a signal. Its transformation operation on a signal/in L^(R) is:

=

(3-6)

where, co = the frequency, and t = time.

The signal/can be represented by inverse Fourier transforms:

f{ t) = ^ r F { o ) ) e '` ^d(o ZTt

(3-7)

However, the Fourier transform cannot analyze the local frequency of a signal, which makes it impossible to measure the local variation.

3.4.2 Time-Scale Analysis

An important property of the wavelet transform is that the window of analysis is adapted locally to the phenomena under investigation, such that it is able to provide information on local signals (Ranchin et al., 2001). In this context, the WT methods provide a
35

promising avenue of research and applications. They not only allow efficient data compression while preserving the original spectral values, but also can be used to fuse images at different resolutions (Donnay et ah, 2001).

The WT replaces Fourier transforms sinusoidal infinite waves by wavelets, a family of waves generated by translations and dilations. Two arguments (time and scale) are considered; while Fourier transform only takes one argument (frequency) Wavelet analysis is the time-scale view of a signal. In general, the scale parameter for timeffequency/time-scale analysis has the relationship with the frequency parameter in that: low scale means high frequency, and high scale means low frequency.

Time-scale is a more natural way for people to observe and analyze the signal obtained. The scale used in maps is one example. In mapping industry, small-scale represents a global view, and large-scale represents a detailed view. The scale domain also applies to remote sensing and image analysis. In large-scale (high-resolution) satellite imagery, the cars on highway are discernable, while in small-scale (low-resolution) satellite imagery, these ears may be regarded as noise or too small to detect. Hence, the scale magnitude affects the performance of feature recognition. On the other hand, when elassifying a satellite imagery, low resolution often simplifies the elassification since the area, with low-resolution both in spatial and spectral, could appear homogenous and is within the same class. Even in a single image, one kind of features can be separated from others by its distinct scale size. Such features, in remotely sensed imagery, may represent highways, buildings, cars, vegetation textures, and even noise, which are exemplified in descending order of their scales. Figure 3.3, showing the images with scales of 1:25,000,1:1,000,

36

Figure 3.3 IKONOS Images of Kampsax, Denmark resampled at scale (a) 1:25,000, (b) 1:10,000, and (c) 1:2,500

1:2,500, respectively, illustrates how different scales can make different understanding of the imagery.

The wavelet transform is defined by:

Wf{u,s)

>=

M

(3-8)

where xj/ is the zero average function, u and s are the time and scale arguments respectively. The wavelet is derived by the translations and dilations by:

(3-9)

To accelerate the computations, the dyadic WT is often used.

37

3.4.3 Dyadic Wavelet Transform

Dyadic wavelets transform (DWT) involves sampling the scale s to be the dyadic number y J e Z . Time is not sampled. The DWT o f signal f i s defined by substituting s by 2^, y G Z in Equation 3-9:

wf(u,v) =

V2-'

2-'

(

3- 10)

with

3.4.4 Regularity Analysis

Unlike Fourier transform analysis, the WT can analyze the local regularity of a signal. WT modulus maxima are related to the singularities of the signal. An ID wavelet analysis illustrates the ideas behind the singularity detection in Figure 3.4.

3.4.5 Multiscale Edge Detection

The magnitude of first differencing or gradient can be computed by finding the partial derivatives and and then determining the composite gradient (Mather, 1999) by

38

2
1

0 60 100 160 200 250

Figure 3.4 Modulus maxima of continuous WT of ID signal, Modulus maxima are in light gray in grayscale printing. (http://cas.ensmp.ff/~chaplais/Wavetour_presentation/Regularite/Detection_of_singulariti es.html)

(3-12)

The direction of the composite gradient is represented by the angle Û, which is given by

0 = tan -1

(3-13)

Ap ,

J

In terms of multiscale edge detection, it is useful to introduce the Canny algorithm first, as a classical but dominant method. As Mallat (1998) mentioned, his wavelet version of

39

edge detection is equivalent to the Canny method. Besides, the preliminary work for this thesis was also based on the Canny edge detector.

The input format required by the Canny edge detector is a gray-scale image, and the binary image is the output format, in which the significantly detected edges are supposed to be in white, while non-edge areas are supposed to be in black. The Canny algorithm is a fast and convenient edge detector for multiscale edge detection.

The Canny edge detector uses two tunable thresholds to divide the edge and non-edge pixels. The pixels whose DN lie above high threshold are set to edge pixels (strong edge), while the pixels whose DN lies below a low threshold are set to non-edge pixels. The pixels between these two thresholds are weak edge pixels, which could be output as final edge only if they show strong connection with strong edge pixels. Any noises with little connection to the true edge are eliminated. By tuning the criterion of connectivity, the output edge image is adaptive in accordance with the preferred scale of edge.

The gradient vector is composed of partial derivatives of p(x, y)\
/ a_ \

Vp =

dx

(3-14)

In the Canny algorithm, a point (xo, yo) in image p(x, y) is defined as an edge point when the modulus of gradient vector is locally maximum, which means along the direction of Vj9. The modulus of gradient vector at (xo, yo) is larger than the modulus of its ID

40

neighbors. This step of non-maximum suppression attempts to thin the qualified edge to a single pixel width.

Here, the procedures applied for the Canny edge detection are summarized as follows: Step 1: Smoothing. The image is pre-processed by a Gaussian filter to eliminate the noise and smooth the coarse appearence. Step 2: Differentiation. A first derivative operator is applied in the x and y directions, respectively. Thus, the edges that mark areas of different brightness are strengthened. Non-edge pixels are dimmed because the gradient magnitudes with respect to their neighboring pixels are low. This step starts off by reducing the angle of gradient to one of the four sectors shown in Figure 3.5. The algorithm uses its eight neighboring pixels. At each pixel, the center element of the neighborhood is compared with its two neighbors along line of the gradient given by the sector value. If the pixel value is non-maximum, that is, not greater than the neighbors, it is suppressed.

112.5 157.5;

67.5' :2.5`

247.5'

292.5'

Figure 3.5 Four test directions for the Canny algorithm.

41

Step 3: Thresholding. Canny edge detector uses double thresholds to generate a binary image. That is, unlike the single threshold method, if the pixel value lies above the upper limit, it is accepted as an edge pixel. If the pixel value lies below the lower limit, it is rejected. A pixel with values between the upper and lower limits is considered an edge if it exhibits strong connection with other edge pixels.

The WT-based edge detector employs the criteria of the Canny algorithm in the steps including smoothing and connecting, but the wavelet version has its own characteristics in the calculations and its advantages and disadvantages. The main advantage is the multiscale nature of the wavelet analysis. The wavelet smoothing kernel 6 is dilated at different scales of the wavelet. Two wavelets are to be constructed because of two directions in image processing:

(3-15)
OX

dy

(3-16)

The scale used in dyadic wavelet transform is simplified to{2-' }^.^2 5 as with Fast Fourier Transforms does, to limit the levels of scale.

=

(3-17)

42

--* - ,k ¥i> (^, y) = ¥ 2j i - x - y )

(3-18)

where k = \ ,2 , indicating the x and y directions, respectively.

The DWT on image p(x, y) is denoted by

W'^piu, v,2^ ) =< p(x, y),

{ x - u ,y - v ) > = p*if/\, (u, v)

(3-19)

The scaled convolution kernels could be written as

^ 2J

^2/

(3-20)

The two wavelets in Equations 3-16 and 3-17 are transformed into a scaled format:

(3-21) dx
-2 _ ,· d02` _ (3.22)

¥ 2> --2"^

dy

Equation 3-20 can be transformed into:
43

-- { p * 02` )(M,v) = 2^
W ^p{u,v,V )
OU

d -- (j7*^2/)(w,v)
,0 V

= 2 ^ 'V (p * Û 2 0 (u ,v)

(3-23)

Then, the modulus of the wavelet components is proportional to the gradient vector of p smoothed by 62^ :

M p{u,v,V ) = ^ \ w ^ p ( u , v , r f + \W ^p{u,v,V )\

(3-24)

The angle, a , of the wavelet vector is calculated by:

a = tan

W ^p{u,v,T) W 'p(u,v, 2^)^

(3-25)

The range of the angle falls into 0 < Ap{u,v,2^) < 2n-, where:

(3-26)

44

Now that the wavelet equivalents of modulus Mp(u,v,2^) and angle Àp(u,v,2^) are obtained, the same procedure is followed as with a Canny algorithm to find the local modulus maxima of wavelet transform. That is, it finds the maximum modulus of the local ID neighborhood at (uo, vg) along the direction o f Ap(u,v,2 -'). The local maximum pixel is the edge pixel at the scale of 2^.

A similar chaining method as the Canny algorithm is applied to the local modulus maxima of WT. The two neighbouring maxima are linked by a vector, which should be perpendicular to the angle direction Ap(u,v,2-' ) at each point.

Due to the uncertainty on the scale at which the qualified edges could be identified, the criteria should be selected by human interpreter according to the presence of edges of desired features, such as roadsides. Generally, for a small scale, the result is quite noisesensitive, resulting in many fine structures, and short twisted lines. For large scales, coarse edges are obtained, but some of them have large delocalization errors (Ziou and Tabbone, 1997).

The Vision Laboratory at the University of Algarve provides an interesting synthetic image (see Figure 3.6a) for testing edge detectors. This test image contains a vertical squarewave grating, a ring, and two thin diagonal lines. Figures 3.6b and 3.6c are the resultant edge maps from Figure 3.6a produced by the Canny edge detector and WT edge detectors used in this research, respectively.

45

I

(a)

I

(b)

(c)

Figure 3.6 Edge detection results (a) test image, (b) Canny detected edges, and (c) WT detected edges. By comparing Figures 3.6b and 3.6c, the pros and cons of each method can be stated as follows: (1) The WT-based method is able to correctly detect the edges at the intersection of the two edges, where both edges are continuous and cross each other, while one of the two edges is broken by the Canny method.

(2) The WT-based method is able to detect the line edge (see the diagonal lines in Figure 3.6c), while in Figure 3.6b, produced by the Canny method, a single line edge becomes double lines.

Figure 3.7 demonstrates of Mallet's wavelet edge detector, which is applied to an image with a single circle.

46

The original image is on top. WT angle for a non Vertical WT zero WT modulus modulus

Horizontal WT

WT modulus maxima

m

Figure 3.7 Classical image Circle for the wavelet edge detection. (http://cas.ensmp.fr/~chaplaisAVavetour_presentation/ondelettes%20dyadiques/Circle.ht ml)

3.5 Geometric Feature Detection

The proposed algorithm for road extraction is based on the extraction of road's geometric parameters (Easa et al., 2003). In most cases, the intersection of two roads, or turn point on one road, should be an arc of a circle. The reason is that the turning the speed of

47

vehicle is to be kept the same and smoothly once on a curve track. In terms of dynamics, once the object is moving, and rotating around one center, the linear velocity and rotational velocity keep constant on rotation. An arc is an ideal curve for this purpose. It starts from (changing direction) an original road, ends in another road (other direction). Obviously, both the start and end point are not only part of the start and end road segments, but are also on the arc. In other words, the curve is a connector of two straight lines; the slope o f the start point on arc must be same as the start line (road), likewise with end point to end line (road). In terms of calculus, continuous first order derivative leads a smooth curve.

From road safety perspective, a horizontal curve must have a minimum radius that ensures vehicle stability. The minimum radius depends on the road design speed, the superelevation and maximum side friction factor. Based on the law of dynamics, the radius of a circular curve is related to other variables (Easa, 2002),

where, R = minimum radius (m), V= vehicle speed (km/h), e = curve superelevation (m/m), and / = side friction factor.

48

To determine the minimum radius of a horizontal curve, the variables used in Equation 328 would be the design speed, maximum superelevation, and maximum side friction factor for V, e, and f , respectively.

In IKONOS imagery, two types of road arcs could be found. They are called comer arc and turning arc. The comer arc is at a street comer (e.g., at a signalized intersection), which is only visible on high-resolution satellite images (e.g., IKONOS or QuickBird). In low-to-medium resolution satellite images (e.g., Landsat TM and SPOT), this type of arc may not be discernable since the comer is almost similar to a right angle. That is, the radius is too small, in pixel length, to be measured. The tuming arc, such as a highway horizontal curve, which would appear in images of all resolutions since road alignments is generally discemable. This study focuses on the second type of road curves.

In this study, horizontal tuming arcs are further categorized into four subtypes. Each subtype has a different strategy developed for its extraction. They are: (1) simple circular arcs, (2) reverse arcs, (3) compound arcs, (4) spiral arcs.

3.5.1 Extraction of Simple Horizontal Circular Curves

For simple horizontal circular curves, the proposed algorithm simply detects the lines that are tangent to the horizontal circular curve at any points selected, and then finds the arc

49

that connects these lines. The Hough transform, a well-adapted algorithm in image feature detection, was used. For man-made objects (e.g., roads) in IKONOS imagery, their shapes appear to be simple, regular, and primitive, which can be accurately described mathematically. The standard Hough transform (Trucco and Verri, 1998) was applied to detect straight lines, which can be represented by (Figure 3.8)

p = x cos 6 +y sin 9

(3-28)

where pF distance from the origin to the line to be detected, angel between the x -axis and a line passing the origin and perpendicular to the line to be detected.

In a binary image, every pixel, whose location is (x, y) and value is non-zero, may belong to many lines (with parameters p and 9) passing through this pixel. A counter for every line passing through this pixel is incremented by one. Thus, after scanning all image pixels, the accumulator contains the number of pixels that every line has. Any line having pixels greater than a given threshold is a candidate line in this image. Obviously, although a line in an image might not be a perfect straight line (somewhere broken, noisy, or distorted), the statistical result can filter out these imperfections. A line recognizable to human eyes should have a large quantity of associated pixel members. The accumulator for recording these counters is a 2D array A(p, 9) that is initialized to zeros.

In a binary image, every pixel, whose location is (x, y) and value is non-zero, may belong to many circles (with parameters Xo,yo, and i?) whose perimeters pass through it (Figure

50

Figure 3.8 Geometric properties of a straight line.

3.9). The equation of a circle is given by

(x - XoY+ (y - yoY =

(3-29)

where Xg, yo = coordinates of the center of the circle, R = radius of the circle.

Similar to line detection, the proposed method first constructs an accumulator initialized with zeros, and then scans all pixels to find the candidate circles. This time, there are three unknown parameters (xo, yo, R), and, therefore, a 3D array accumulator is established to record the counting. The arc is only part of a circle. In IKONOS imagery, no perfect circle exists and many separate arcs may belong to one circle. Therefore, arc detection and circle detection are similar.

51

Figure 3.9 Geometric properties of a circle.

A simple curve is a circular curve connecting two tangents that intersect at the point of intersection (PI) (Figure 3.10). The beginning of the curve is the point o f curvature (PC) and the end of the curve is the point of tangency (PT).

In practice, finding specific tangents (lines) and the curve (arc) connecting them is more localized. That is, it does not need to find all lines and arcs in an image. There are many of them, and the difficulty is how to determine the threshold criteria for an image. Even if a road is short and its length is below the threshold, it still could be a candidate for investigation. An arc, whose center is located out of the image, cannot be detected. Therefore, automatic line and arc detection in the whole image is not feasible for the puiposes of this study. Instead, the searching area for lines is limited. The user is allowed to select the sides of a road, so that only two mouse clicks are required for detecting an arc (Figure 3.10). As noted before, the accumulator array is 3D, which means that arc

52

PC Line A PT

Road Segment 1

max

Line B'

^V-Road Segment 2

Figure 3.10 Schematic representation for establishing a simple horizontal curve,

detection requires greater memory and time than line detection.

To make the search results more accurate and to satisfy computation and computer storage limitations, a self-adaptive threshold is introduced to find a candidate line. Two filters are applied to the search: (1) the line must pass through the selected point and (2) the direction of the line must be the same as (or nearest to) the direction of the line in the small point window. Thus, a line is found finally on which the small point window (a or b in Figure 3.10) resides.

Once two intersecting roads have been found, the arc connecting them can be easily found. Its centre must reside on the bisector line (Line B in Figure 3.10) of their

53

intersection angle /, and its radius R must be the distance from the curve centre to either of the two lines. Now only the centre point of this arc is an independent unknown parameter, and C lies on the Line B. The problem is reduced to a ID analysis. The amount of computation and memory also could be greatly reduced. The centre of the searched circle must lie on Line B. It is assumed that the user would click the initial points on the straight part of the road, not on the arc. Then, the user picks the initial point (point a in Figure 3.10) which is less distant to the intersection point 7, and the algorithm will automatically makes an assistant line (Line A) perpendicular to the road line on which this initial point lies. The new intersection point (Cmax) generated by the assistant line and Line B is the farthest possible centre for the arc being searched.

To find the center of the searched arc, a ID accumulator is allocated to record the rank of each possible arc. Each possible arc is the one whose centre is between P I and Cmax, and whose radius is the distance between its centre and either of the two tangent lines. Only one independent unknown is involved because the centre lies on Line A. A statistical method, like Hough transform line detection, can tolerate imperfection of the image and determine the most likely 'actual' arc. After scanning all pixels which each arc passes, if not zero, the counter for this arc is incremented by integer one. The larger the radius, the more pixels on the chord of the arc would be scanned. To make each arc have an equal chance, after scanning, the counter number is divided by the arc length o f each arc. Thus, the arc that has the maximum relative hit count is selected. This results in the only one arc which is the best arc connecting the tangent lines. Once the best arc is determined, all corresponding parameters are saved, including its radius, beginning point, and end point.

54

3.5.2 Extraction of Reverse and Compound Curves

A reverse horizontal curve consists of two consecutive circular arcs in opposite directions. The radii of the two arcs can be same or different. A compound horizontal curve consists of two circular arcs in the same direction. The radii of the two arcs cannot be the same, otherwise they are portions of a simple horizontal circular curve. The sketches of reverse curve and compound curve are drawn in Figures 3.11 and 3.12, respectively.

These subtypes of horizontal curves cannot be established using the algorithm developed for simple curves because this algorithm requires two straight lines to extract the simple curve. The two arcs of the reverse or compound curves cannot be separately identified as two simple circular curves because their common part is a tangent point, not a straight line. If the reverse or compound curves are separated by a short tangent, the algorithm for simple curves can be applied to establish the two arcs separately. However, the common part of the reverse or compound curve is normally a common tangent point (point f in Figures 3.11 and 3.12). To establish these types of curves, other algorithms were developed to recognize these two subtypes. The algorithm for reverse curves is described below, but the same principles can be applied to compound curves.

The procedure for establishing reverse horizontal curves is illustrated in Figure 3.11. If the road is wide enough, two reverse horizontal curves can be shown in the image, each one represents each side of the road. This is the case in high-resolution satellite imagery where a road is shown as a band rather than a line. The reverse curve has two arcs (with same radii or not) with one common tangent point. The objective here is to find the

55

Line B Road Segment 1 C2 Line D R2. -Line C

/R2

Line A '?

Road Segment 2

Figure 3.11 Schematic representation for establishing a reverse horizontal curve.

Line B Line A R1 Lirie C

Road Segment 1

Road Segment 2 "

Figure 3.12 Schematic representation for establishing a compound horizontal curve.

56

starting tangent point e, ending tangent point d, and common tangent point ^ along one reverse curve of one road side as well as the radii and centers of the two arcs.

The algorithm involves the following steps to automatically establish the reverse curve illustrated in Figure 3.11. These steps are also applicable for compound curve illustrated in Figure 3.12:

(a) Find two straight lines representing the start and end tangents of the reverse curve (b) Select the first initial point a. To reduce the volume of computations, it is recommended that the initial point be selected on the side with the arc that has smaller radius (first arc). Then, select the second point b. As shown in Figures 3.11 and 3.12, two initial points a and b are marked on the two tangents of the reverse curve. The following steps are completed by the computer automatically. (c) Select every point on the first straight line (from a toward the first arc) to be the candidate of the starting tangent point. Make a line perpendicular to the starting line and through the candidate tangent point, such as Line A, on which the center of the candidate first arc must be located. (d) Try all possible radii and all possible common tangent points on the circumference of the candidate first arc. Using every possible common tangent point (such as/), make a common tangent line shared by both arcs, such as Line B, which will intersect with the end tangent at c. The distance c f must equal the distance cd. Thus, the position of the candidate end tangent point d can be located on the end tangent.

57

(e) Draw a line perpendicular to the end tangent line at d, such as Line C. The center of the second arc must be on Line C, and on the line (Line D) perpendicular to the common tangent Line B. These two lines (Line C and Line D) generate an intersection point, which is the centre of the second arc. (f) Calculate the percentage of matching pixels of the arc under consideration in the image.

There are many possibilities of such combinations for a reverse or compound arc. By trying every candidate, and comparing their percentage of match in the image, the combination with the maximum possibility can be selected as our final reverse or compound curve. The logical flow of the above procedure, which involves a three dimensional loop (distance over tangent, radius of first arc, and common tangent angle), is shown in Figure 3.13, coupled with Figures 3.11 and 3.12 to illustrate the procedures.

3.5.3 Extraction of Spiral Curves

A spiral is a curve with a uniformly changing radius. It is used in highway to overcome the abrupt change in direction that occurs where the alignment changes from a tangent to a circular curve. The spiral curve either connects one circular curve and one tangent, or connects two circular curves of different radii. A sketch of a spiral curve, which connects a tangent and a circular curve, is drawn in Figure 3.14.

The cubic spiral forms the first order approximation of the spiral whose curvature (reciprocal of the radius) is linearly related to its arc length. The circular curve, spiral

58

(cubic) curve, and straight line are represented in (% ,

space by Equations 3-31, 3-32,

and 3-33, respectively. Their relationships are illustrated in Figure 3.15.
(x -x o Y + (y -y o y --

(3-30)

Select a point on the first tangent with distance 2}-i=0

Select a point (centre o f circle) on Line A with radius

Select initial angle

Calculate the percentage o f matching Pij^

If P i j i > P m a x , then P m a x = P i j k . Store P ,, , a x and corresponding parameters, Rj, Rj^Cj and Cj.

Final angle? ,Yes Maximum
radiu.«s?

No

No

Yes

Last point on first tangent? Yes

No

The curve corresponding to the final P^ax is selected along with its parameters.

Figure 3.13 Flow diagram for establishing reverse and compound horizontal curves.
59

Tangent to Spiral

Spiral Curve Circular Curve

Figure 3.14 Spiral curve.

y = ax^ y =0 where Ji = unknown radius of the circular curve, yo = unknown center of the circular curve, a = unknown constant of the cubic spiral.

(3-31) (3-32)

The spiral curve is approximated by a polynomial curve as indicated by Equation 3-31. It is possible to detect the spiral curve in an image and its parameter by modifying a Hough transform. The basic idea is also based on the finding the parameter of the spiral statistically in an image, like 2D ( p , Û) line searching or 3D (xo,yo,.R) circle searching using a Hough transform. Thus, a Hough spiral curve detector can be designed to work in 4-dimensional
(x q ,

yo, R, Ô) searching space, which is almost impossible with the

computation power of the hardware (recall the discussion for HT-based circle detection). By extending the algorithm of detecting simple arc, it is possible to reduce the searching space to 3D searching as follows;

60

Road Segment 2

Line A (x-xoY+{y-yo) Road Segment 1 Jl y=ox^ X

Figure 3.15 Symmetrical spiral curves approximated by cubic spiral.

(1) Let x-axis be on the one of the straight road segment (tangent to spiral); (2) Let the tangent to spiral be the origin of coordinate system; (3) The coordinates of the intersecting point A of circular curve and spiral (cubic) curve are given by (% , ax^). At Point A, the first order derivatives of both curves must be the same for smooth transition. (4) The first order derivatives of the cubic curve (y=ca^) and road segment 1 at origin O must equal to 0. (5) Center C must locate on the bisector line (Line A) of the angle intersected by road segment 1 and 2.

Thus, the constant a in Equation 3-31 of spiral (cubic) curve, center C of the circular curve, and coordinates of A and B can be obtained by satisfying the above conditions. Further details on the extraction of spiraled horizontal curves are presented in Dong et al. (2003).
61

3.5.4 Extracting Second Roadside

Once the edge of one side of a road arc has been found, in terms of the parameters of radius and centre position, the next step is to find the other side of that road arc. The same way used for the first side can be applied again to extract the second arc on the same road, and, subsequently, the centerline can be determined. In this way, each arc on the same road is treated as an individual one, not related. Hence, the error which occurred when extracting the first arc will not affect the precision of the second arc. O f course, there is no guarantee that second arc is error-free without previous error for first arc. To extract both roadsides separately, four points should be clicked on the image. However, this process is inefficient and fault-prone because much human interference is involved.

From the road design perspective, the width of a road is normally constant, especially over the circular arc. The sight distance is much shorter on the curve than it is on the straight part of a road, because the view angle does not allow the driver to perceive the change of road width, not to mention that obstacles, such as buildings or trees, located at the comer may block the view sight.

In Figure 3.16, the inner arc is detected with radius R and centre C. The road width is set to W (distance between the two roadsides) is constant along the road arc. It is obvious that the outer curve is an arc with the centre C and radius R+W. If the case that the first arc detected is outer one, the inner curve is to be an arc with the centre C and radius R-W.

62

In both cases, the positions of both sides of arc road are located at C, which has been known from detecting the first arc. What is unknown is only the road width W. Once one side of a road is determined, the computer can find the other side of the same road, either inward or outward. To reduce the search space and the chance of errant detection, a user-defined parameter is needed: which roadside is selected, inner or outer. If it is the inner side, the direction of search is outward along the radial direction, and vice versa. The search space is also limited because of the actual road width in the real world. It is assumed that the minimum width of the road is one lane (approximately 4 m wide), and maximum width is 8 lanes (approximately 32-m wide). On IKONOS imagery, the search space is converted to pixel units. The conversion is straightforward:

Pixel _Width(pixel) =

Road _ Width{meter) Re solution _ o f _ \m age{meter i pixel)

(3-33)

Figure 3.16 Detection of double roadsides.

63

For example, the corresponding road width in IKONOS imagery varies from 4 to 32 pixels.

3.6 Connection to Desktop GIS Environment

Spatial data acquisition and interpretation are bottlenecks to GIS-T databases. Remote sensing has been one of the most effective means of spatial data collection. According to Wilkinson (1996), the interface between GIS and remote sensing can be envisaged in one of three different ways: (1) Remote sensing can be used as a tool to gather data sets for the use in GIS; (2) GIS data sets can be used as ancillary information with which to improve the products derived from remote sensing, and (3) Remote sensing data and GIS data can be used together for modeling and analysis.

Using vector data format, the feature boundaries are converted to straight-sided polylines that approximate the original curves. These polylines are encoded by determining the coordinates of their vertices, which can be connected later to form the curves (Sonka et al., 1999).

The automated creation and update of urban road networks, with semi-automated methods, can be faster, less error-prone and less tedious than using traditional manual vectorization from imagery. Here, the road network extracted in this research is in 2D. In

64

most urban areas, the overlook view approximates the urban scene closely, because the roads are flat and continuous with respect to their change of height.

Since the parameters of each detected road segments are precisely known using the proposed approach, these parameters can be used to generate the data compatible with the existing GIS-T databases. For example, a shape file is a widely used vector data format. It can store the vectors with the types of points, polylines, polygons in 2D or 3D domain. In the case studies, the parameters of both line and curve road segments are used to generate the shape files which can be read by most popular GIS software.

Figure 3.17 shows how the vector model constructs an arc connecting two straight lines, that simulates the turning part of a road. The left side is the extracted edge or centerline of a road segment. This is saved in raster format, pixel by pixel. The right side is the illustrated vector format of the segment. Only vertices (black dots) are saved (encoded) in persistent media, the other part (dashed line) can be inteipolated linearly when reconstructing the road (decoding). If the vertices are sampled within appropriate distances, the reconstructed shape could represent the original curve without noticeable coarse steps. The sampling procedure can be completed by the computer. The distance of the neighboring vertices can be determined by the curvature of the segment between the two vertices. Generally, the larger the curvature, the smaller the distance to be adopted. For example, in Figure 3.17, the straight segment (with curvature 0) only needs two vertices at the start and end points to be represented, while the simple circular curve (with the finite radius) needs 8 vertices for its representation.

65

Figure 3.17 Vectorized polyline approximation of linear and curve segments.

66

4 CASE STUDIES

4.1 Study Areas

To test the proposed algorithms, an experiment was designed and conducted to extract two types of horizontal curves from IKONOS imagery. One standard frame IKONOS imagery, acquired in August 2001, was provided by the Greater Toronto Airports Authority (GTAA). The IKONOS imagery was geometrically corrected in two dimensions (X and Y) in the Universal Transverse Mercator (UTM) projection coordinate system, zone 17° in the Geodetic Reference System of 1980 (GRS80) and North American Horizontal Datum of 1983 (NAD83). The imagery used in this study is a pan sharpened true-colour IKONOS image, which has three colours and 1-m spatial resolution.

Two areas were selected in this study. Both images are the subsets of the IKONOS imagery covering west Toronto, Canada. Figures 4.1 and 4.2 show these two images, enhanced by standard deviation stretch. Figure 4.1 covers a typical highway network at the intersection area of Highway 401 and Highway 427. The major disturbances are the vehicles, shadows of highways, and marking lines. Figure 4.2 covers a typical residential area. To comply with the requirement of wavelet dyadic transform, each image size is cut into a window consisting of 1024x1024 (2'°x2'°) pixels. Although processing arbitrary size is preferred and can be implemented by overlaying multiple intermediate square (2"-

67

g

Figure 4.1 SDS(a = 2) enhanced image of study area 1.

sized) images, the procedure is not discussed in the research session. Table 4.1 lists the brief information of each image.

The approach previously described in Section 3.5 was implemented in a PC environment on a Visual C++ platform and OpenCV code framework. The user interface was designed

68

to facilitate the initialization of seed points and selection of curve type for the user. The complete flow of processes on the image data has been illustrated briefly in Figure 3.1. Prior to the road extraction, image preprocessing (Section 4.2), and wavelet edge detection (Section 4.3), are performed. Since the two steps are not image-specific, the intermediate results produced are shown only on the sample highway image.

%»

m

Figure 4.2 SDS(a = 2) enhanced image of study area 2

69

Table 4.1 Sample image information.

Highway Area (Figure 4.1) Image Information Layers Image Size (pixel) Data Type Upper Left Coordinates (X,Y) Pixel Size (m) Datum 3(R, G,B) 1024x1024 Unsigned 8-bit (614293.013, 4836858.060)

Residential Area (Figure 4.2) 3(R, G, B) 512x512 Unsigned 8-bit (611074.01,4842065.06)

Map Information

1.0
NAD27 (Canada)

1.0
NAD27 (Canada)

Projection Information

4.2 Image Preprocessing 4.2.1 Standard Deviation Stretch

The original image (Figure 4.3) o f the study area 1 is the raw image that does not give appropriate brightness and contrast for both human operator and computer to see the features. The histogram (Figure 4.4) of the raw image shows that band data (green band) are mostly distributed at the lower DN range (the mean is 71.0), although the pixel values range from 0 to 255 (from the smallest to largest possible DN). Roughly speaking, seen from the shape of histogram its data is normally distributed. The standard deviation ( a ) of the normal distribution is 31.4, which means most of data are within the range approximately from 10 (mean- 2cr ) to 130 (mean+2cr). Let the mean value be the approximate measure of brightness, and the standard deviation be the approximate

70

Figure 4.3 Original image of study area 1 without any enhancement.

measure of contrast, neither of the brightness and contrast of the raw image are not suitable for human or computer vision analysis.

Applying SDS on the raw normally distributed data with 2, the SD-enhanced image is displayed in Figure 4.1, which gives a much clearer scene with highways, buildings, vegetation, vehicles, and other features, than the original image (Figure 4.3). The

71

improvement o f visibility can be inteipreted by histogram of the SDS-enhanced image as shown in Figure 4.5. Using green band as an example, the min/max values are still the same as the original image, but the mean value has moved from 71 to 127.2, which is around the middle value o f the range. The new standard deviation cr o f the SDS enhanced image is 58.3, which means the most data are distributed roughly from 10 to 245. These statistical values also proved that SDS can significantly enhance the brightness and contrast of the original image.

'  0 62025 * " 1

47.5004

255 ^

0

7019964

2 5 5 ''\': T 0 " : - ^

66.8443

255

15415

(a) Red

(b) Green Figure 4.4 Histogram of original image

(c) Blue

(Min = all zero; max = all 255; mean = 48, 71, 67; a = 30,31,33).

12B.4B9 21271

127217

127.171

7789

(a) Red

(b) Green Figure 4.5 Histogram of the SDS-enhanced image. (median = 125, 132, 136; a = 59, 58, 61)

(c) Blue

72

4.2.2 Decorrelation Stretch

It is noticed in Figure 4.5 that the mean value of each RGB band has been moved to middle of the radiometric range (around 127-128) after the SDS. This means that all RGB bands are SDS-enhanced individually and equally, and only the contrast of intensity of the RGB image has been enhanced by the SDS. Applying decorrelation stretch (DS) on SDS enhanced image (Figure 4.1) is the next step to further increase the contrast between colours. Figure 4.6 shows the image processed by the DS. Its contrast of colours has been visually enhanced. By comparison of the histograms of the DS-enhanced image to the histograms of the SDS-enhanced image, it can be found that the median values of red and blue bands have moved significantly towards lower DN and higher DN, while the mean values of red and blue bands do not change much. This phenomenon shows the visual contrast of different colours can be increased without changing the hue by the DS.

4.2.3 Principal Components Analysis

The final image needed for edge detection should be a gray-scale image. Both the SDS enhanced image (see Figure 4.1) and the SDS-DS-enhanced image (see Figure 4.6) include three bands. PCA can be applied to either of them at this stage to generate a single-band (gray-scale) image. In this study, both of the single-band images were generated and compared in order to find which one is optimal with respect to contrast. It could be found, according to the results of ERDAS Imagine, that 93.6% (SDS-enhanced) or 87.8% (SDS-DS-enhanced) of the information has been transformed into the first principal component for image of study area 1, and likewise for image of study area 2.

73

I

Figure 4.6 SDS-DS-enhanced image of study area 1 depicted in Figure 4.3.
127339 32518»! 255 0 30282^

128.403

255

;0 41759»"

120.385

255

72B2

9907

(a) Red

(b) Green Figure 4.7 Histogram after DS-enhanced (median = 119, 134,140; o= 62, 59, 62)

(c) Blue

74

4.2.4 Results and Discussion

The two gray-scale images generated by PCA and DS-PCA are shown in Figures 4.8 and 4.9, respectively. By employing change detection technique provided by ERDAS Imagine 8.5, the difference between the PCA image and DS-PCA image can be visually examined. Figure 4.10 shows such a difference image displaying the change of the two images. The green (light gray in gray image) areas are where the DN (brightness) in DSPCA image is larger (brighter) than the DN (brightness) in PCA image; the red (dark gray in gray image) areas are where the DN (brightness) in DS-PCA image is smaller (darker) than the DN (brightness) in PCA image; black areas are of no change. It can be seen that, in DS-PCA image, most of the highway areas are highlighted, and its background areas are dimmed, in comparison with the PCA image. When viewing the PCA image (Figure 4.8), the highways are generally brighter than their background areas. By DS-PCA processing, bright becomes brighter, dark becomes darker, and the contrast of the whole gray-scale image is enhanced by DS-PCA processing compared to PCA processing. Thus, the optimal gray-scale image for edge detection is to be the DS-PCA image (Figure 4.9).

4.3 Wavelet Edge Detection
The wavelet edge detection used in this study was implemented by LastWave, a signal processing (wavelet oriented) software developed by Emmanuel Bacry, CNRS (http://www.cmap.polvtechnique.ff/~bacrv/LastWave/).

75

I

Figure 4.8 SDS-PCA enhanced image of study area 1 depicted in Figure 4.3.

The gray-scale image (Figure 4.9) is used as the input image o f wavelet edge detector. The wavelet edge detector performs dyadic wavelet decomposition up to 3 levels (/ = 1, 2,3) or more. At each wavelet transform scale, extrema (local modulus maxima along the gradient direction) are computed. A threshold value is given to eliminate those extrema whose modulus is smaller than the threshold. Figures 4.11, 4.12 and 4.13 are the binary edge images at three scales (/ = 1,2,3), respectively.

76

compared to the edge image at scale 2 (Figure 4.12). Further checking the overlay of the gray-scale image (Figure 4.9) and the edge image at scale 3 (Figure 4.13) tells that there are dislocations of some edges to the true feature boundaries. The dislocations are due to the smoothing effect used at each wavelet decomposition scale. The edge image at scale 2 (Figure 4.12) keeps the most edges of desired features (roads). The dislocations of edge

Figure 4.10 The difference image of the PCA image and DS-PCA image (Green areas: DS-PCA>PCA; Red areas: DS-PCA<PCA; Black areas: DS-PCA=PCA).

78

%

M

Figure 4.9 DS-PCA-enhanced image depicted in Figure 4.3.

The edge image at scale 1 presents almost all intensity variations (whose moduli are above the specified threshold) of Figure 4.9. The edges of almost all features make it difficult for both human and computer to discriminate the desired features. The edge image at scale 3 looks like the most elegant one of the three edge images. However, some important boundaries of desired features (e.g., roads) disappear or become broken

77

Figure 4.11 Edge image of the image of study area 1 (Figure 4.9) at wavelet scale 1.

are unnoticeable by checking the overlay image. By observing and analyzing the edge images at all scales, the decision can be made that the edge image at scale 2 will be the best representation o f the feature boundaries.

79

Figure 4.12 Edge image of the image o f study area 1 (Figure 4.9) at wavelet scale 2.

4.4 Extraction of Road Curves

Although the background computation works on the edge image, the user input and results are displayed on the SD-enhanced colour image (e.g., Figure 4.1), which gives the most natural and comfortable view to facilitate the human operation.

80

Figure 4.13 Edge image of the image of study area 1 (Figure 4.9) at wavelet scale 3.

4.4.1 Extraction of Simple Circular Curves

The image for the simple horizontal curve is a freeway interchange that has many simple curves (Figure 4.14). As noted, all interchange curves were accurately identified using the proposed methodology. The identification was done sequentially (one curve at a time). The parameters identified for each curve included the centre, radius, start angel, and end

81

angel. Extracting simple circular curves is fast. It spent about 3 seconds to get the largestscale curve (in radius) in Figure 4.14. Thus, most of the time consumption for the road network extraction in the overall region is in the session of user interaction, such as clicking the seed points.

I

m

m

i

^0
Figure 4.14 Results of establishing horizontal curves at complex freeway interchange.
82

4.4.2 Extraction of Reverse and Compound Curves

The image for the reverse curve is a subset of the IKONOS imagery. As noted, the algorithm correctly identified the two arcs of the reverse curve (arc A and B in Figure 4.15), and two arcs of compound curves (arc A and B in Figure 4.16). Similar to simple curves, the algorithm can extract the parameters of the curve from the image, including the coordinates of the centers, radii, start point, end point, and common point. Computation on the reverse or compound curve is time-consuming. For example, it requires about 3 minutes to achieve the reverse curve in Figure 4.15.

:

m .

Figure 4.15 Results of establishing reverse horizontal curves in urban residential area.

83

msm

itM tS S .

'M mU

fMi

Figure 4.16 Results o f establishing compound horizontal curves in urban highway area.

4.4 J Extraction of Spiral Curves

The image for the spiral curve is a subset of the IKONOS imagery. As noted, the algorithm correctly identified the simple circular curve (arc A) and its two wing spiral curves (curve B and Q (see Figure 4.17). Here, the spiral curve is approximated by a cubic polynomial.

84

Figure 4.17 Results of establishing spiral horizontal curves in urban highway area.

4.4.4 Results and Discussion

As shown in Figure 4.14, almost all of the arcs can be extracted. The developed method can accurately establish simple, reverse, compound, and siralled curves, even for a complex freeway interchange. Some curves could not be extracted using the proposed methodology. An example is the transition curves (seen in the middle of Figure 4.1), which might be combination of spiral curve and circular curve(s).

85

The time consumed on computation of simple and complex arcs varies dramatically. The extraction o f a simple circular curve is almost instant, while the extraction of a reverse or compound curve is much slower. It is mainly due to the difference between using ID and 3D searching spaces. However, the time spent on reverse and compound arc is still tolerable, and the number of reverse and compound arcs is much less than the number of simple circular curves in a road network.

4.5 Extraction of Road Networks

The individual arc, simple or complex, with its centerline and/or two sides can be extracted from the image one by one. A road, visible in an image, is composed of straight segments and curved segments, or only a straight segment transiting the image. In the former case, the human operator instructs to close a road after extracting the last curve on it, and then starts with another road until all the roads of interest have been extracted. All the roads extracted together represents the road network. Note that the road-like feature in the upper-right part of study area 1 (Figure 4.1) is actually an open ditch, which should not be extracted as part of the road network although its alignments (arc F and G in Figure 4.14) can also be measured by the proposed method. Human knowledge is always needed to exclude those non-road but road-like features, which is difficult for automated methods. It is also noteworthy that the storage of all geometric parameters for each road network is less than 10KB. Figures 4.18 and 4.19 are examples of all extracted freeway interchange and road network in the image, respectively. The uncompressed sizes o f the files for the two images are 3MB and 768KB.

86

Figure 4.18 Segmented freeway interchange in the image of study area 1.

The retrieved geometric parameters of all line and curve segments were used to create the vector data files. Each road is represented as three polylines, which are two roadsides and one centerline. Figure 4.20 and 4.21 show the vector data displayed by ERDAS Imagine. The sizes of the files for the two vector files are 431KB and 54KB.

87

Figure 4.19 Segmented road network in the image of study area 2.

4.6 Performance Evaluation

This section discusses the performance evaluation of the developed method of road network extraction . Internal self-diagnosis and external evaluation of the obtained results are of major importance for the relevance of automatic methods for practical applications. However, only relatively little work has been carried out in this area. The measures for self-diagnosis should take into account the reliability of the generated road primitive as

88

well as the consistency between them. External evaluation is conducted by comparing the extracted roads with manually measured reference data.

The method of road extraction from high-resolution satellite imagery could be used in various applications. The extracted highway strictly complies with the highway design, which gives the chance that the orientation of the road at any point is geometrically

Figure 4.20 Vectorized freeway interchange in the image of study area 1.
89

Figure 4.21 Vectorized road network in the image of study area 2.

known. The orientation is strictly parallel to the centerline, the width of the road at any point is also known. If the centerline is represented as I (x, y), the road width at any point on the centerline is W (I). A unique 2D road model could be reconstructed. It is assumed that the width of the arc part of a road is constant. Two linked neighboring arcs could have different widths. The width along the straight segment, connecting these two arcs, changes linearly in order to smoothly change the width from one arc to another. The two ends of a road are exceptions, because the arcs connecting them are outside of the image

90

and, therefore, not visible. In such cases, the width is assumed to be the same as the width of the adjacent arc.

In transportation applications, roads are the area of interest. Only the objects on the road are to be analyzed. Unfortunately, road segments projected on the satellite image are, most likely, irregularly shaped, and not in the shape of simple rectangles. The contour of the road of interest is the most desirable in such cases. The method presented here is a fast and precise way to trace the outline of a road in a satellite image. Some highways in Figure 4.18 are samples of interest areas. Other highways of non-interest and non highway areas are blacked out. Now, in such a selective image, it is much easier for automatic algorithms to perform some tasks, such as detection of vehicles, marking lines or manholes, analysis of traffic flow, and etc. The results could be more convincing because the focus is simply on the roads of interest, not on the entire image.

Another advantage is the abundant auxiliary information, such as geometric parameters, central line and width of the road, are provided natively when the results are extracted. The information can be used accordingly as the criterion in various analyses. For example, to extract the vehicles on the highway, even if the area of the interested highway of interest is the only object displayed in the image (see Figure 4.18), it is still difficult to achieve the goal. The raster data in digital format are insufficient to provide accuracy with such a small scale, with only several pixels per vehicle. The detection algorithm would be sensitive to the extraneous object seen at this scale, such as the noise or non vehicle objects. The knowledge of the direction of the vehicle is the most important cue for ease of detection. The major axis of the rectangle of the moving vehicle body is

91

parallel to the local direction of the road. Since the direction of any position on a given road is known already. The searching will become a 2D (x, y) loop reduced from a 3D (x, y , 0 ) loop. This will greatly increase both the speed and accuracy of the detection of algorithm.

Given the same IKONOS images over the same residential area (see Figure 4.2), the resultant images (see Figures 4.21 and 4.22) are generated by the semi-automated method developed in this study and an automated method, based on Fuzzy Mathematical Morphology (FMM). This permits the analysis of the geometric and radiometric properties of roads and other non-road features in the imagery (Li et al, 2003). The

Figure 4.22 Extracted road centerlines using the method based on FMM (Li et al., 2003).

92

morphological structure element, an elongated rectangle window, was used to detect the straight road segments automatically.

From the result image (Figure 4.22) of this automated method, some disadvantages of this kind o f method are listed below: (1) The rectangle structure element is too simple to be used to detect all geometries. Some of the curve comers in Figure 4.2 will nearly become right angles in the detected centerline image (Figure 4.22) because of lack of curve structure elements, which cannot be designed as easily as the rectangle element with respect to the variation in curvature. (2) The centerline and roadside extracted are not as smooth as the real world. It is mainly due to the imperfections (e.g., trees, cars and shadows) on the road. (3) The resultant image (Figure 4.22) is actually a raster edge image, in which individual road has not been identified. (4) The time spent on FMM computation is increased by the order O (n^), where n is the image size in one dimension. For example, with double the dimension o f an image, the time would be 8 times longer. This is also a general time scale for such methods, which automatically scan all pixels and local directions in the entire image.

The method developed in this study has none of the above-mentioned problems. Its advantages over the automated method are: (1) Both straight and curved elements can be identified accurately.

93

(2) The method is not easily affected by the disturbances on the road. (3) The results can be the individual roads, and their geometric parameters. (4) The time increase in terms of size depends on how many new curve elements can be seen on the enlarged area. It is in the order of 0 ( n \ where n is the image size in one dimension.

If one is familiar with the manual vectorizing on an image, the steps in this method are similar, but much easier. First, when vectorizing the straight road segments, the human operator does not need to pinpoint the correct pixel on the side of road, since the system will identify the appropriate point to click around the edge of road. Second, there is no need to vectorize the curved road segments, which is the most difficult in manual vectorizing, since it is done automatically by the method presented in this study, based on the type of curve. Third, the human operator only needs to vectorize one side of a road, because the other side can be extracted automatically by this system.

An external evaluation is essential for the results from automatic road network extraction. The manually plotted or extracted data can be the reference data for evaluating the automated method (Heipke et al., 1997; Wiedemann and Hinz, 1999). Since the method introduced in this study can achieve a high accuracy for urban road maps, its results are a candidate for reference data for the evaluation of other automated extraction, or even manually plotted or extracted methods.

It is appropriate to check the validity and accuracy of the results of the proposed road extraction method by an internal evaluation. That is, the resultant vector data is

94

overlapped on the original image (enhanced if necessary) in order to check the performance visually by the user. Figures 4.23 and 4.24 are such overlay images

Figure 4.23 Overlay of the extracted highways on the input image of study area 1,

95

s

ü

m

Figure 4.24 Overlay of the extracted road networks on the input image of study area 2.

96

5 CONCLUSIONS AND RECOMMENDATIONS

In this thesis, a semi-automated method of urban road network extraction based on geometric analysis of IKONOS imagery has been presented. In this chapter, the major achievements of the developed approach are summarized in Section 5.1. Some limitations are discussed in Section 5.2. Based on the previous discussions, conclusions are drawn in Section 5.3. Finally, recommendations for future research are given in Section 5.4.

5.1 Summary

In this research work, a semi-automated extraction method of urban road networks from high-resolution satellite imageiy has been developed and implemented. This novel approach fully exploits the high-accuracy image information, the knowledge of road geometry, and the abstraction ability of humans to achieve more reliable and accurate results. The developed methodology differentiates itself from the traditional semi- or fully-automated approaches in two aspects: (1) the feature detection is based on the geometric characteristics of roads, in particular, the curve road segments; and (2) the feature parameters of lines and various types of horizontal road alignment are extracted precisely, and the 2D vector or symbolized model of road network can be reestablished. With this generic methodology, both urban and rural highways, even road networks in urban residential areas can be extracted from a single IKONOS image.

97

Most of the algorithms for detecting the linear and curve features are implemented to test and demonstrate the practicality of the new proposed approach. This potential technique can be used in mapping highways using available satellite images, extracting and exporting features into GIS databases. This can be done with either vectorized data in widely recognizable format, or the geometric parameters in order to save the storage space.

For the road network located in the urban and suburban areas (in this case, the Greater Toronto Area), the primitive structure o f highway geometry is relatively simple because of the limited space. Normally, simple horizontal curves are dominant in number in such areas due to the simplicity of design and construction, and limitation o f the available space for the designed highway. Some spiral curves can be found around the suburban areas which are far away from downtown and the mobility is the first concern in design. In residential areas, reverse curves are often seen, because accessibility is important factor to be concerned in urban areas.

The extracted arcs are regarded as the joints of the straight road segments. Once all the parameters of the joint arcs have been achieved, a complete 2D horizontal road can be reconstructed by the parameters o f its joints. Extracting a road without curvature segments in the image view field is achieved simply by detecting one linear segment.

Extracting residential roads are more difficult than extracting highways. There are three main factors influencing the results: (1) the straight segments of a road are not strictly connected by ideal curve(s) somewhere; (2) the detection o f straight road segments is

98

disturbed by the trees along streets or their shadow; and (3) many residential roads show a white border with one or two pixels width on one or both sides, which makes the detection of road width difficult. A visible street edge may appear to be irregularly dashed line. However, in most cases of the case studies, they can be detected Hough transform and the statistical method for curve detection. This is also one of the advantages of semi-automated methods over fully- automated ones, which are highly sensitive to these urban disturbances on high-resolution imagery.

5.2 Limitations

Although the objective of this research was to develop a generic methodology of road network extraction, only a prototype was studied or implemented for the time being. There are some limitations listed as follows: (1) Although the spiral curve is considered as a basic type, its detection is not implemented for all types of spirals because it involves various combinations with circular curves. (2) Only those basic types of road curves were considered. Other complex curves are most likely the combination of the basic curves (circular, reverse, compound, and spiral curves). The proposed methodology is based on the premise of successful detection of tangent lines, which does not exist within the combination of curves. (3) The connection of curves (grouping of road segments) is only implemented with simple circular curves. Other curve types are only tested individually.

99

(4) If one arc passes the boundary of an image, it is impossible to be detected using the proposed methodology, although some strategies can achieve acceptable results. (5) It is assumed that the intersection angle of the two tangents are subtended to the curve. Actually, two tangents can be parallel, and reverse subtended. The methodology should be modified to allow such special cases,

5.3 Conclusions

This thesis has presented a new semi-automated method for the extraction of urban road networks from a single IKONOS image. The method is based on multiscale analysis and knowledge of road geometry. Its applications to real case studies show the benefits provided by the method. Several findings and conclusions can be made as follows:

(1) The image pre-processing is a general and necessary step to employ the power of both human and computer vision. Here, the enhancement of the contrast is the first priority in image preprocessing, since enhancement will assist the next step of feature edge detection. The standard deviation stretch is used to linearly enhance the intensity contrast. The DS-PCA is used to enhance the spectral contrast if necessary. The DS-PCA method is not always better than the PGA method to obtain a single-band image. The contrast enhancement is expected to increase the global contrast. (2) As a method of spatial enhancement, edge detection is used to extract the primitive features in this research. Only sharp variations that outline important

100

features in the image remained. Since the features of interest (roads) in the study are large-scale, the small-scale features should be eliminated. The most common multiscale edge detectors, Canny and WT-based methods, are considered and compared. Canny method is impressive in its fast speed, and the fact it is not limited in image size. However, wavelet transform generates more satisfactory edges than the Canny method. (3) Hough transform is the basis of the proposed feature detection methodology. HT automatic line detection is used directly in this work to find the straight segments of roads. The HT-based automatic circle detection is not suitable for the largescale arc detection in this study. Several approaches were developed to extract the basic types of highway curves according to the highway geometry. (4) The basic idea of extracting road network is to find each road's curves, then extract those which are connected by straight lines. All the roads in the region of the image can be extracted likewise. The proposed method works best with highresolution imagery. (5) This proposed methodology was designed to work with high-resolution or median-resolution image, on which the road width is at least three pixels wide for IKONOS Im-resolution imagery, every single lane road is about 3~4m wide; for medium-resolution image, roads with width of 5m or above can be detected. Otherwise, the road can still be extracted if it is straight or with visible curved segments. From a practical point of view, the developed approach can be used as an operational and reliable road extraction method, whose output provides useful highway data.

101

5.4 Recommendations for Further Research

As discussed above, some limitations exist with the developed method. Future work may include: · To establish a whole road network within a certain region, a complete extraction system should consider the road's 2D spatial relationship. · Consider the use of auxiliary information (e.g., shadow of the road, or DSM data) to retrieve the relative or absolute elevation of each road, thus a 3D road model can be established. · Once the 2D road has been extracted and its heights along the road are known, it is possible to detect the parameters o f vertical alignments of the road using the same principle as with the detection of horizontal alignments. O f course, algorithms for extracting various vertical curves need to be developed.

102

BIBLIOGRAPHY

Amini, J., M.R. Saradjian, J.A.R. Blais, C. Lucas and A. Azizi, 2002. Automatic road side extraction from large scale imagemaps, International Journal o f Applied Earth Observation and Geoinformation, 4(2):95-107. Aronoff, S., 1989. Geographic Information Systems: A Management Perspective. WDL Publications, Ottawa, Canada. Auclair, F., D. Ziou, C. Armenakis and S. Wang, 2001. Automated correction and updating of road databases from high-resolution imagery. Canadian Journal o f Remote Sensing, 27(l):76-89. Bâhr, H.B., 2001. Image segmentation for change detection in urban environments. In: Donnay, J.P., M.J. Barnsley, and P.A. Longley (eds.): Remote Sensing and Urban Analysis, Taylor & Francis, London. Baker, S., 1998. Design and Evaluation o f Feature Detectors, PhD Dissertation, Graduate School of Arts and Sciences, Columbia University, New York. Barnsley, M.J., L. M(j)ller-Jensen and S.L. Barr, 2001. Inferring urban land use by spatial and structural pattern recognition. In: Donnay, J.P., M.J. Barnsley, and P.A. Longley, (eds.) Remote Sensing and Urban Analysis, Taylor & Francis, London. Barzohar, M. and D.B. Cooper, 1996. Automatic finding of main roads in aerial images by using geometric-stochastic models and estimation, IEEE Transactions on Pattern Analysis and Machine Intelligence, 18(7):707-721. Baumgartner, A., C. Steger, C. Wiedemann, H. Mayer, W. Eckstein and H. Ebner, 1996. Update of roads in GIS from aerial imagery: verification and multi-resolution QXivdiCiion, International Archives o f Photogrammetry and Remote Sensing, 31 (B3):53-58. Baumgartner, A., C. Steger, H. Mayer and W. Eckstein, 1997. Multi-resolution, semantic objects, and context for road extraction. Semantic Modeling fo r the Acquisition o f Topographic Information from Images and Maps, Birkhauser Verlag, Basel, Switzerland, pp. 140-156. Baumgartner, A., W. Eckstein, C. Heipke, S. Hinz, H. Mayer, B. Radig, C. Steger and C. Wiedemann, 1999a. T-REX: TUM Research on Road Extraction, In: Festschrift fur Prof. Dr.-Ing. Heinrich Ebner zum 60. Geburtstag, Hsg.: C. Heipke und H. Mayer, Technische Universitat München, Lehrstuhl fu r Photogrammetrie und Fernerkundung, pp. 43-64.

103

Baumgartner, A., C. Steger, H. Mayer, W. Eckstein and H. Ebner, 1999b. Automatic road extraction in rural areas. In: International Archives o f Photogrammetry and Remote Sensing, 32 (3-2W5): 107-112 Canny, J., 1986. A computational approach to edge detection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 8(6):679-698. Carreira, M.J., M. Mirmehdi, B.T. Thomas and Marta Penas, 2002. Perceptual primitives from an extended 4D Hough transform. Image and Vision Computing, 20(13-14):969980. Chen, C.H., J.S, Lee and Y.N. Sun, 1995. Wavelet transformation for gray-level comer detection. Pattern Recognition, 28(6);853-861. Chiesa, C., 2001. Multispectral Feature-space approaches to change detection and road extraction. In: Proceedings in Road Centerline Extraction & Maintenance Specialist Meeting, CLEM2001, August 6-7, Santa Barbara, CA. (http://www.ncgia.ucsb.edu/ncrst/meetings/clem2001/proceedings.html) Chui, C.K., 1997. Wavelets: A Mathematical Tool for Signal Analysis, SIAM Monographs on Mathematical Modeling and Computation, Society for Industrial & Applied Mathematics, Philadelphia, PA. Colwell, R.N., 1961. Some practical applications of multiband spectral reconnaissance, American Scientist, 49:9-36. Coren, S. and L.M. Ward, 1989. Sensation & Perception, 3 "^^ Edition, Harcourt Brace Jovanovich. Couloigner, 1. and T. Ranchin, 1998. Extraction of urban network from high-spatialresolution imagery using multiresolution analysis and wavelet transform. Wavelet Applications in Signal and Imaging Processing VI, SPIE Proceedings, 3458:103-112. Dal Poz A. P. and M. A. O. Silva, 2002. Active testing and edge analysis for road centreline extraction. International Archives o f Photogrammetiy and Remote Sensing, 34 (3B): B-44 ff. Dekker, A.G., V.E. Brando and J.M. Anstee, 2001. Imaging spectrometry of water. In: Van der Meer, F.D., and S.M. de Jong (Eds.), Imaging Spectrometty: Basic Principles and Prospective Applications. Bookseries Remote Sensing and Digital Image Processing. 4:307 - 359. Dong, H., S.M. Easa, and J. Li. 2003. Approximate extraction of spiraled horizontal cur\'cs from satellite imagery, ASCE., Journal o f Surveying Engineer, (under review). Dong, Y., B. Forster and C. Ticehurst, 1996, Street orientation detection and recognition in Landsat TM and SPOT HRY imagery. Pattern Recognition Letters, 18(8):759-769.

104

Donnay, J.P., M.J. Barnsley and P.A. Longley, (eds.) 2001. Remote Sensing and Urban Analysis, Taylor & Francis, London. Dori, D. and W. Liu, 1998. Stepwise recovery of arc segmentation in complex line environments. International Journal on Document Analysis and Recognition, 1(1):62-71. Dosch, Ph., G. Masini and K. Tombre, 2000. Improving arc detection in graphics recognition. In: Proceedings o f 15th International Conference on Pattern Recognition (ICPR'2000), Barcelona, Spain, pp. 243-246 Doucette, P., P. Agouris, A. Stefanidis, and M. Musavi, 2001. Self-organised clustering for road extraction in classified imagery, ISPRS Journal o f Photogrammetiy and Remote Sensing, 55(5-6):347-358. Easa, S., 2002. Geometric Design. Civil Engineering Handbook, W.F. Chen and J.Y. Liew eds., CRC Press, Boca Raton, FL, Chapter 63. Easa, S., H. Dong and J. Li, 2003. Use of satellite imagery to establish simple and reverse highway horizontal curves, ASCE Journal o f Surveying Engineering (accepted). ERDAS, 1999. ERDAS Field Guide. ERDAS, Inc., Atlanta, USA. Fischer, W.A., 1969. Examples of remote sensing applications to engineering. In: Special Report 102, Remote Sensing and Its Application to Highway Engineering, Highway Research Board. Fiset, R., F. Cavayas, M.C. Mouchot, B. Solaiman, and R. Desjardins, 1998. Map-image matching using a multi-layer perception: the case of the road network, ISPRS Journal o f Photogrammetry and Remote Sensing, 53(2):76-84. Freeman, J., 1975. The modeling of spatial relations, Computer Graphics and Image Processing, 4:156-171. Geman, D. and B. Jedynak, 1996. An active testing model for tracking roads in satellite images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 18( 1): 1-14. Gillespie, A.R., A.B. Kahle and R.E. Walker, 1987. Color enhancement of highly correlated images. 1. Decorrelation and HSI Contrast Stretches. Remote Sensing o f Environment, 20:209-235. Gonzales, R.C. and R.E. Woods, 1992. Digital Image Processing, Addison-Wesley, Reading, Massachusetts. Gonzalez, R.C. and R.E. Woods, 1993. Digital Image Processing, Addison-Wesley, New York.

105

Gruen, A. and H. Li, 1995a. Road extraction from aerial and satellite images by dynamic programming, JSPRS Journal o f Photogrammetry and Remote Sensing, 50(4): 11 -20. Gruen, A. and H. Li, 1995b. Automation of road extraction from space and aerial images, In Proceeding o f the 16'^ Asian Conference on Remote Sensing, November 20-24, Thailand, pp. E-3-1 to E-3-7. Gruen, A. and H. Li, 1997. Linear feature extraction with 3-D LSB-Snakes, In Automatic Extraction o f Man-Made Objects from Aerial and Space Images (II), Basel, Switzerland, Birkhauser Verlag, pp 287-298. Hay, G.J., T. Blaschke, D.J. Marceau and A. Bouchard, 2003, A comparison o f three image-object methods for the multiscale analysis of landscape structure, ISPRS Journal o f Photogrammetry and Remote Sensing, 57:327-345. Heipke, C., C., Steger and R. Multhammer, 1996. A hierarchical approach to automatic road extraction from aerial imagery. In McKeown, D. M. Jr., I. J. Dowman (Eds). Integrating Photogrammetrie Techniques with Scene Analysis and Machine Vision II, Proceedings of SPIE 2486:222-231. Heipke, C., H. Mayer, C. Wiedemann and O. Jamet, 1997. Evaluation of automatie road extraction. In: International Archives o f Photogrammetry and Remote Sensing, 32( 32W3):47-56. Hellwich, O., and C. Wiedemann, 2000. Object extraction from high-resolution multisensor image data. In Proceedings o f the 5'^^ International Conference Fusion oj Earth Data, Sophia Antipolis, January 26-28, pp. 105-115. Hinz, S., A. Baumgartner, C. Steger, H. Mayer, W. Eekstein, H. Ebner and B. Radig, 1999. Road extraction in rural and urban areas. In: Forstner, W., C.E. Liedtke, and J. Büekner (eds.). Semantic Modeling fo r the Acquisition o f Topographic Information from Images and Maps, SMATI '99, München, pp. 133-153. Hinz, S. and A. Baumgartner, 2003. Automatic extraction of urban road networks from multi-view aerial imagery, ISPRS Journal o f Photogrammetry and Remote Sensing, 58(l-2):83-98. Hofmann, P., 2001. Detecting urban features from IKONOS data using an object-oriented approach. In Proceedings o f P ` Annual Conference o f the Remote Sensing & Photogrammetry Society, 12-14 September, pp. 28-33. Hyvarinen, A., J. Karhunen and E. Oja, 2001, Independent Component Analysis, John Wiley & Sons, Toronto. ITU-R Recommendation BT.709, 1990. Basic Parameter Values fo r the HDTV Standard fo r the Studio and fo r International Programme Exchange, ITU, 1211 Geneva 20, Switzerland.

106

Jack, K., 1996. Video Demystified. Hightext Publications, Solano Beach, CA 92075. Ji, C.Y., 1996. Delineating agricultural field boundaries from TM imagery using dyadic wavelet transforms, ISPRS Journal o f Photogrammetiy and Remote Sensing, 51(6):268-283. Jung, C.R. and J. Scharcanski, 2003. Adaptive image denoising and edge enhancement in scale-space using the wavelet transform. Pattern Recognition Letters, 24(7):965-971. Kauth, R.J. and G. Thomas, 1976. The Tasselled Cap - a graphic description o f the spectral-temporal development of agricultural crops as seen by Landsat In Proceedings o f the Symposium on Machine Processing o f Remotely-Sensed Data 1976, Purdue University, West Lafayette, 46:41-51. Klang, D., 1998. Automatic detection of changes in road databases using satellite imagery. International Archives o f Photogrammetry & Remote Sensing, 32:293-298. Roller, T., G.Grieg, G. Szekely and D. Dettwiler, 1995. Multiscale detection of curvilinear structures in 2D and 3D image data. In Proceedings o f the 5'* International Conference on Computer Vision, pp 864-- 869. Rurhar, L., R. Schmidt, S. Dury and A. Skidmore, 2001. Imaging spectrometry and vegetation science. In: Van der Meer F.D., and S.M. de Jong (Eds.), Imaging Spectrometry: Basic Principles and Prospective Applications, 4:111-155. Laptev, I., H. Mayer, T. Lindeberg, W. Eckstein, C. Steger and A. Baumgartner, 2000. Automatic extraction of roads from aerial images based on scale space and snakes. Machine Vision and Applications, 12(1):23-31. Li, J., Y. Li., H. Dong and S. Easa, 2003. Automated extraction of urban road centerlines from IRONOS imagery based on fuzzy mathematical moiphology, Photogrammetrie Engineering and Remote Sensing (under review). Lillesand, T. and R. Riefer, 2000. Remote Sensing and Image Interpretation, 4*'' Edition, John Wiley & Sons, New York. Lindeberg, T., 1998. Edge detection and ridge detection with automatic scale selection, IJCV 30:117-154. Liu, J.G. and J.M. McMoore, 1996, Direct decorrelation stretch technique for RGB colour composition. International Journal o f Remote Sensing, 17:1005-1018. Mallat, S, 1989. A theoiy for multiresolution signal decomposition: The wavelet representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, ll(7):674-693. Mallat, S. and W.L. Hwang, 1992a. Singularity detection and processing with wavelets, IEEE Transaction Information Theory, 38(2):617-643.
107

Mallat, S., 1992b. Characterization o f signals from multiscale edges, IEEE Transactions on Pattern Analysis and Machine Intelligence, 14(7):710-732. Mallat, S., 1996. Wavelets for a vision, In Proceedings o f the IEEE, 84(4):604-614. Mallat, S., 1998, A Wavelet Tour o f Signal Processing, Academic Press, San Diego Toronto. Marr, D., 1982. Vision, Freeman, San Francisco, CA. Mather, P.M., 1976. Computational Methods o f Multivariate Analysis in Physical Geography, Wiley, New York. Mather, P.M., 1999. Computer Processing o f Remotely-Sensed Images: An Introduction, John Wiley & Sons, New York. Mayer, H., 1996a, Abstraction and scale-space events in image understanding, International Archives o f Photogrammetry and Remote Sensing, 31 (B3/III):523-528. Mayer, H. and Steger, C., 1996b. A New Approach for Line Extraction and its Integration in a Multi-Scale, MultiAbstraction -Level Road Extraction System. In: lAPR TC-7 Workshop: Mapping Buildings, Roads and other Man-Made Structures from Images, Oldenbourg Verlag, Vienna, Austria, pp. 331-- 348. Mayer, H., A. Baumgartner and C. Steger, 1998a. Tutorial on road extraction from aerial imagery. In: CVonline: The Evolving, Distributed, Non-Proprietary, On-Line Compendium o f Computer Vision. Mayer, H., I. Laptev and A. Baumgartner, 1998b. Multiscale and snakes for automatic road extraction. In: Proceedings o f the 5''' European Conference on Computer Vision, pp. 720-733. Mayer, H., C. Steger, 1998c. Scale-Space Events and Their Link to Abstraction for Road Extraction, ISPRS Journal o f Photogrammetry and Remote Sensing, 53(2):62-75 Mayer, H., 1999. Automatic object extraction from aerial imagery - a survey focusing on buildings. Computer Vision and Image Understanding, 74(2):138-149. McKeown, D.M., and J.L. Denlinger, 1988. Cooperative methods for road tracking in aerial imagery. Computer Vision and Pattern Recognition, pp. 662-672. Park, S.R. and T. Kim, 2001. Semi-automatic road extraction algorithm from IKONOS images using template matching. In Proceedings o f the 22"^ Asian Conference on Remote Sensing, 5-9 November, Singapore. Phasomkusolsil, S., N. Hinsamooth, F. Cheevasuvit, K. Dejhan, S. Mittatha, S. Chitwong and A. Somboonkaew, 1998, Principal component analysis for multi-resolution
108

images, In Proceedings o f Asian Conference on Remote (http://www.gisdevelopment.com/aars/acrs/1998/ps3/ps3018pf.htm).

Sensing.

Price, K., 1999. Road grid extraction and verification. International Archives o f Photogrammetry and Remote Sensing, 32(3-2W5):I01-106. Quegan, S. and 1. Rhodes, 1994. Relating plarimetric SAR data to surface properties --the MAC-Europe experiment. In: Mather, P.M. (ed.), 159-174. Ranchi, T., L. Wald and M, Mangolini, 2001. Improving the spatial resolution of remotely-sensed images by means of sensor fusion: a general solution using the ARSIS method. In: Donnay, J.P., M.J. Barnsley, and P.A. Longley, 2001. Remote Sensing and Urban Analysis, Taylor & Francis, London. Rees, W.G., 1999. The Remote Sensing Data Book, Cambridge University Press, Cambridge, England. Richards, J.A. and X. Jia, 1999. Remote Sensing Digital Image Analysis, 3"* edition. Springer-Verlag, Berlin. Roger, R.E., 1996. Principal components transform with simple, automatic noise adjustment, InternationalJournal o f Remote Sensing, 17:2719-2727. Rosin, P. L. and G.A.West, 1989. Segmentation of edges into lines and arcs. Image and Vision Computing, 7(2): 109-114. Ruskoné, R. and S. Airault, 1997. Toward an automatic extraction of the road network by local interpretation of the scene. Photogrammetrie Week, Wichmann Verlag, Heidelberg, Germany, pp. 147-157. Sânchez-Âvila, C., 2003, Wavelet domain signal deconvolution with singularitypreserving regularization. Mathematics and Computers in Simulation, 61(3-6): 165176. Shukla, V., R. Chandrakanth and R. Ramachandran, 2002. Semi-automatic road extraction algorithm for high resolution images using path following approach. In Proceedings o f the 3'''^ Indian Conference on Computer Vision, Graphics and Image Processing, Ahmedabad, India. Sonka, M., V. Hlavac and R. Boyle, 1999. Image Processing, Analysis, and Machine Vision, 2"** edition, Brooks-Cole, Pacific Grove, CA. Steger, C., 1996. Extraction of curved lines from images. In Proceedings o f the 13"' International Conference on Pattern Recognition, pp. 251-255. Steger, C., H. Mayer and B. Radig, 1997. The role of grouping for road extraction. In: A. Gmen, E. Baltsavias and O. Henricsson (eds). Automatic Extraction o f Man-Made

109

Objects from Aerial and Space Images (II), Birkhauser Verlag, Basel, Switzerland, pp. 245-256. Torre, V. and T.A. Poggio, 1980, On edge detection, IEEE Transaction on Pattern Analysis and Machine Intelligence, 8(2):147-163. Trinder, J.C. and Y. Wang, 1998. Automatic road extraction from aerial images. Digital Signal Processing, 8(4):215-224. Vosselman, G. and J. de Knecht, 1995. Road tracing by profile matching and Kalman filtering. In Proceedings Workshop on Automatic Extraction o f Man-Made Objects from Aerial and Space Images, Birkhauser Verlag, Basel, Switzerland, pp. 265-274. Wang, Y. and Q. Zheng, 1998, Recognition of roads and bridges in SAR images. Pattern Recognition, 31(7):953-962. Wiedemann, C. and H. Mayer, Automatic verification of roads in digital images using profiles, Mustererkennung 1996, Springer-Verlag, Berlin, Germany, pp. 609-618. Wiedemann, C., C. Heipke, H. Mayer and O. Jamet, 1998. Empirical evaluation of automatically extracted road axes. In: K. J. Bowyer and P. J. Phillips (eds). Empirical Evaluation Methods in Computer Vision, IEEE Computer Society Press, Los Alamitos, California, pp. 172-187. Wiedemann, C. and S. Hinz, 1999. Automatic extraction and evaluation of road networks from satellite imagery. International Archives o f Photogrammetry and Remote Sensing, 32(3-2W5):95-100. Wiedemann, C. and H. Ebner, 2000, Automatic completion and evaluation o f road networks. International Archives o f Photogrammetry and Remote Sensing, 33(Part B):979-986. Wiemker, R., A. Speck, D. Kulbach, H. Spitzer and J. Beinlein, 1997. Unsupervised robust change detection on multispectral imagery using spectral and spatial features. In Proceedings o f the 3'^ International Airborne Remote Sensing Conference and Exhibition, Copenhagen, Denmark, 1:640-647. Wilkinson, G.G., 1996. A review of current issues in the integration of GIS and remote sensing data. International Journal o f Geographical Information Systems, 10(I):85101. Xiong, D., 2001. Optimization-based method for road network extraction, In Proceedings o f Road Centerline Extraction & Maintenance Specialist Meeting {CLEM200I), August 6-7, Santa Barbara, CA. (http://www.ncgia.ucsb.edu/ncrst/meetings/clem2001/proceedings.html) Zhang, C:, E. Baltsavias and A. Gruen, 2001. Knowledge-based image analysis for 3D road reconstruction, Asian Journal o f Geoinfomatics, 1(4):3-14.

110

Zhang, L. and P. Bao, 2002. Edge detection by scale multiplication in wavelet domain, Pattern Recognition Letters, 23(14): 1771-1784. Zhang, C., 2003. Updating of cartographic road databases by images analysis, PhD Thesis, November, ETH Zurich. Ziou, D. and A. Koukam, 1995. The selection of edge detectors using local image structure. In Proceedings o f the 7''' IEEE International Conference on Tools with Artificial Intelligence, Virginia, pp. 366-370. Ziou, D. and S. Tabbone, 1997. Edge Detection Techniques - An Overview, Technical Report, No. 195, Department of Mathematics & Informatics, University of Sherbrooke, Quebec. Zlotnick, A. and P.D. Gamine, 1993. Finding road seeds in aerial images. Computer Vision and Image Understanding, 57(2):243-260.

I ll

