«X o

Y

STATISTICAL MODEL BASED DIGITAL IMAGE RETRIEVAL A N D FRAGILE W ATERM ARKING
HU A YUAN B.Sc Shanghai, P.R.China, 1997

A thesis
Subm itted in partial fulfillment of the requirements for the degree of M aster of Applied Science in the program of Electrical and Computer Engineering

Departm ent of Electrical and Com puter Engineering Ryerson University Toronto, Ontario, Canada © H U A YUAN 2004

PROPERTY OF RYERSON UNiVLfiSlTY UBRARY

UMI Number: EC52989

All rig h ts re s e rv e d INFORMATION TO USERS

T he quality of this reproduction is dep en d en t upon the quality of the copy subm itted. Broken or indistinct print, colored or poor quality illustrations and photographs, print bleed-through, substandard m argins, and improper alignm ent can adversely affect reproduction. In the unlikely event that the author did not send a com plete m anuscript and there a re missing p ag es, th e se will be noted. Also, if unauthorized copyright material had to be rem oved, a note will indicate the deletion.

UMI

___

®

UMI Microform EC52989 Copyright 2008 by P roQ uest LLC All rights reserved. This microform edition is protected against unauthorized copying under Title 17, United S ta te s Code.

P roQ uest LLC 789 E ast E isenhow er Parkw ay P.O. Box 1346 Ann Arbor, Ml 48106-1346

B O R R O W E R 'S P A G E
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

N am e

S ignature

A d d ress

D a te

Ill

S ta tis tic a l M o d e l B a s e d D ig ita l Im a g e R e tr ie v a l A n d F ragile W a term a rk in g
Master of Applied Science 2004 HUA YUAN Electrical and Computer Engineering Ryerson University

A b str a c t
The objective of this thesis is to acquire abstract image features through statistical mod elling in the wavelet domain and then based on the extracted image features, develop an effective content-based image retrieval (CBIR) system and a fragile watermarking scheme. In this thesis, we first present a statistical modelling of images in the wavelet domain through a Gaussian mixture model (GMM) and a generalized Gaussian mixture model (GGMM). An Expectation Maximization (EM) algorithm is developed to help estimate the model parameters. A novel similarity measure based on the Kullback-Leibler divergence is also developed to calculate the distance of two distinct model distributions. We then apply the statistical modelling to two application areas: image retrieval and fragile watermarking. In image retrieval, the model parameters are employed as image features to compose the in dexing feature space, while the feature distance of two compared images is computed using th e novel similarity measure. The new image retrieval method has a better retrieval perfor mance than most conventional methods. In fragile watermarking, the model parameters are utilized for the watermark embedding. The new watermarking scheme achieves a virtually imperceptible embedding of watermarks because it modifies only a few image data and em beds watermarks at image texture edges. A multiscale embedding of fragile watermarks is given to enhance the embeddability rate and on the other hand, to constitute a semi-fragile approach.
iv

A c k n o w le d g m e n t
I would like to acknowledge the support of everyone in the CASPAL Lab who have made m y two years of graduate study at Ryerson University more pleasant and easier. The great sup p o rt and the invaluable intellectual inspiration provided by Prof. Xiao-Ping Zhang, my supervisor, has helped in every aspect of my graduate studies and I have no doubt th a t the knowledge and the research skills th a t he shared with me will benefit my future studies or work. I would like to thank Prof. Ling Guan, Songnian Li and Xavier Fernando for being the mem ber of my thesis defense committee. I appreciate very much their time on reviewing my thesis draft and the valuable comments and suggestions th a t they provided on the thesis draft. I would like to take this opportunity to thank Prof. Ling G uan for his interesting course tau g h t in my first year of study. Discussions with him broadened my understanding in

content-based image retrieval and stim ulated my research in this area, which has become an im portant p a rt in this thesis. I am very grateful to the departm ent of Electrical and C om puter Engineering for the funding in my graduate studies. I am also grateful to the Ryerson University for providing me a small, b u t very pleasant and cozy cam pus environment. I express th e warmest appreciation to my parents and my wife for their caring and support all th e tim e. They are and will always be the driving force th a t helps me accomplish th e g raduate study and all future objectives.

Contents
1 Introd u ction 1.1 Motivation and O b je c tiv e s .............................................................. 1.2 B a c k g ro u n d ................................................................................................................... 1.2.1 1.2.2 Image R e trie v a l............................................................................................... Image W aterm ark in g ..................................................................................... 1 1 2 3 6 9 11 12 12 12 13 15 19 21 21 21 22 24

1.3 C ontribution .................................................................................................................. 1.4 Structure of T h e s i s ........................................................... 2 Prelim inaries 2.1 The EM Algorithm for Mixture M o d e ls................................................................. 2.1.1 2.1.2 2.1.3 2.2 3 Maximum L ikelihood..................................................................................... The General EM A lg o r ith m ........................................................................ The Estim ation of Gaussian Mixture Density Parameters Using EM . ...........................................................................

The Kullback-Leibler Divergence

S ta tistica l M od ellin g in th e W avelet D om ain 3.1 New Statistical Models and Related EM A lgorithm s............................................ 3.1.1 3.1.2 3.1.3 A Gaussian Mixture Model in the Wavelet D o m a in .............................. An EM Algorithm for the Gaussian Mixture M o d e l .............................. A Generalized Gaussian Mixture M odel.....................................................

3.2 A Kullback-LeiblerDivergence Based Similarity Measure for the Statistical M o d e ls............................................................................................................................ 27

VI

3.2.1

General Minkowski D i s t a n c e s ........................................................................ . . . .

27 28 29 33 33 34 35 36 46 47 47 52 54 60 61 65 T'l

3.2.2 Sim ilarity Measure Based on the Kullback-Leibler Divergence

3.2.3 Analysis of the New Similarity M easu re....................................................... 4 S ta tis tic a l M o d e l B a se d Im age R etriev a l 4.1 4.2 4.3 4.4 4.5 5 Overview of th e Proposed CBIR S y s t e m ................................................................ The Indexing Feature Space for Image R e tr ie v a l................................................... Kullback Divergence Based Similarity M easu re...................................................... Sim ulation R e s u l t s ........................................................................................................ Sum m ary .........................................................................................................................

S ta tis tic a l M o d e l B a sed Fragile W aterm ark in g 5.1 Em bedding Inform ation into the Statistical M o d e l................................................ 5.2 M ultiscale Embedding of A uthentication M essages................................................ 5.3 Sim ulation R e s u l t s ........................................................................................................ 5.4 Sum m ary ........................................................................................................

6

C o n clu sio n s an d F uture W ork

A T h e N e w to n -R a p h so n M e th o d V it a

vu

List of Figures
1.1 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 General Architecture of A Fragile Watermarking System.................................... The Proposed CBIR System...................................................................................... Initial Retrieval of A Query from Class D87.......................................................... Second Round Retrieval of the Same Query from Class D87.............................. Initial Retrieval of A Query from Class D98.......................................................... Second Round Retrieval of the Same Query from Class D98.............................. Initial Retrieval of A Query from Class D i l l ........................................................ Second Round Retrieval of the Same Query from Class D i l l ............................ Initial Retrieval of A Query from Class D114........................................................ Second Round Retrieval of the Same Query from Class D114............................ 8 34 41 41 42 42 43 43 44 44 45 45 51 52 55

4.10 Initial Retrieval of A Query Image Using Euclidean Distance............................ 4.11 Initial Retrieval of Same Query Image Using Separate Kullback Distance. . . 5.1 5.2 5.3 5.4 An Iterative Approach for Coefficient Modification.............................................. Multiscale Embedding of Authentication Messages.............................................. The Original Lena Image (a) and the Watermarked Lena Image (b)................ The HL Wavelet Subspace of Original Lena Image (a) and the HL Wavelet Subspace of Watermarked Lena Image (b).............................................................. 5.5 5.6 Message Bits Embedded into the Wavelet Blocks................................................. The Original Peppers Image (a) and the Watermarked Peppers Image (b) with Lab Logo "CASPAL" Embedded..............................................................................

55 56

57

vni

5.7

T he D W T of Original Peppers Image (a) and the DW T of W aterm arked Peppers Image (b) with Lab Logo "CASPAL" Em bedded.................................... 58

IX

List of Tables
4.1 4.2 4.3 4.4 4.5 4.6 5.1 5.2 5.3 5.4 5.5 Initial Retrieval Rate Based on D bl And Db2 Filters.......................................... Comparison of Different Decomposition Scales...................................................... Retrieval Results of 4 Different Queries.................................................................. Initial Retrieval Rate Based on Similarity Measures............................................ GMM Compared with GGMM.................................................................................. GMM & Kullback Compared with Other Traditional Methods......................... Code Map for Message Bits Embedding.................................................................. Average Param eter Difference Caused by Single Pixel Modification................. Param eter Difference Caused by Noise.................................................................... Param eter Difference Caused by Compression....................................................... Param eter Difference Caused by Some Malicious Attacks ................... 37 37 38 38 39 40 53 58 59 59 60

Chapter 1 Introduction
1.1 M o tiv a tio n an d O b je c tiv e s

M any image applications require an accurate modelling of images to have a better under standing and utilization of image contents. Image modelling is aimed at the exploitation of statistical characteristics of the images. The success of some traditional approaches th a t use mean and variance to interpret image d a ta implies a more complicated Gaussian statistical model, which also has a mean and a variance param eter, would be more effective and natural for image modelling. The primary objective of the thesis is to interpret an image through a G aussian statistical modelling in the wavelet domain, realizing the fact th a t the wavelet transform has a multiscale image decomposition and the statistical approach provides an accurate yet concise interpretation of the decomposed image data. T he image features ob tained from th e statistical modelling are applied in two application areas: image retrieval and fragile waterm arking. T he statistical model based image retrieval has many attractive features and advantages. The image retrieval is based on the comparison of image features, which represent image sta  tistical characteristics and can therefore be b etter obtained through the statistical modelling. Moreover, a statistical model based feature extraction is efficient in feature representation and com putation because it results in a relatively compact indexing feature space. Thus, our interest lies in th e derivation of some new feature extraction m ethods based on the developed statistical modelling to have a compact indexing feature space. It is also desired th a t the
1

2 extracted image features can reflect some characteristics of human perception and have a sound image retrieval performance. We are also interested in utilizing the statistical modelling to develop some new fragile watermarking methods. Most traditional fragile watermarking methods inevitably need to modify a large amount of image data for watermark embedding in order to protect the whole image area. They are not efficient and in conflict with the watermarking principle th at requires an imperceptible embedding of watermarks. Using the statistical approach, we aim at developing a new fragile watermarking method th at modifies a few image data for watermark embedding, while keeping sensitive to any image tampering. Besides, the increasing interest nowadays for a semi-fragile watermark is what we wish to address in our new method.

1.2

B ack grou n d

W ith the development of the Internet and digital storage techniques, digital image libraries have been widely used for commercial and research purposes. People want to have an efficient way to browse the library. At the same time, they may require that the information they acquire are secure and authorized to use, in other words, they are authenticated. Im a g e re trie v a l provides an effective way to search and browse the image libraries based on their indexing features. Depending on the characteristics of queries, the image retrieval progressed from original text based retrieval to current more effective content based retrieval. The content based image retrieval (CBIR) usually uses color, texture, and shape in the work toward identifying suitable image features. The performance of a CBIR system is directly related to the effectiveness and compactness of the indexing feature space, which is studied under a statistical approach in this thesis. Im a g e w a te rm a rk in g , on the other hand, provides a solid solution for data hiding and image authentication. The digitized images distributed on the Internet are easy to

be manipulated and tampered. In applications people want to make sure their retrieved images are true copy of the author's and can be legally used, the authentication techniques

3 are required. Some watermarks, after being embedded into a host image, can detect any unauthorized modifications on th at image. Therefore they can be used for authentication purposes. These waterm arks, commonly known as fragile watermarks, is one focus of the research in this thesis. Traditional methods usually modify a lot of image d ata and seldom consider hum an perception characteristics while embedding watermarks. Therefore there is a need for an efficient fragile watermarking scheme using a statistical approach.

1 .2 .1

Im a g e R e tr ie v a l

As more and more images are being captured and digitally stored into a database, an effective image retrieval system is required to make use of the information stored in images. In

traditional databases, the approach to indexing and retrieval of images is based on simple attrib u tes such as image number and text description. T he performance of this text-based indexing and retrieval technique is quite low because the simple text attributes are not able to describe the features of the images completely and accurately. Besides, text-based retrieval system s also cannot accept content-based queries. To overcome these lim itations of textbased indexing and retrieval techniques, content-based indexing and retrieval techniques are pursued. The earliest use of the term CBIR in literature was by K ato [1992], to describe his exper im ents into an autom atic retrieval of images from a database depending on colour and shape features. T he term has since been widely used to describe the process of retrieving desired images from a large collection on the basis of features (such as colour, texture and shape) th a t can be autom atically extracted from the images themselves. CBIR differs from classical inform ation retrieval in th a t image databases are essentially unstructured, since digitized images consist of arrays of pixel intensities th a t have no inherent meaning. Therefore One im p o rtan t task is to extract useful information from the image raw d ata for indexing before any kind of retrieval operation on the image library is possible. The indexing and retrieval in CB IR are defined as follows:  Indexing - th e computer-assisted d ata reduction of images into m athem atical features;

Indexing may be subdivided into the steps of:

0 Segmentation - the determination of the boundaries of the objects of interest; 0 Feature extraction - the obtaining of the colour, shape and texture properties of
the objects of interest;

0 Feature vector organization - the organization of the feature vectors in the database
for the purpose of searching efficiently;

0 Classification - the labelling of segmented objects into categories of interest.
 Retrieval - the user interaction to retrieve desired images from the database; this may includes:

0 Query formulation - the method used to specify the query; Most common methods
are queries by image examples or queries by sketches; 0 Query feature extraction - the reduction of the query image (or sketch) into a feature vector compatible with those stored in the database; 0 Similarity measure - the method used to compare the query with each stored image and to measure the similarity between them. W ith the development of Internet and mass media storage techniques, CBIR has been very active in assisting people to browse online digital libraries since 1990s. Some wellknown CBIR systems include IBM 's QBIC [1], Virage [2], VisualSEEk [3] and Photobook [4]. Being compliant with the above mentioned indexing and retrieval characteristics, the core of a typical CBIR system is mainly composed of feature extraction techniques, similarity measure approaches, and relevance feedback mechanisms. One of our research objectives focuses on image texture features. They, along with

color features and shape features, are part of image low level features that are always the focus of research in image feature extraction. A lot of texture feature extraction tools and methods have been developed. Some researchers used the codebook concept to compose

5 th e indexing feature space, in which the images are divided into blocks and each block is coded through feature extraction and be p art of the codebook. O ther researchers noticed the m ultiresolution benefits of image transform s in the compressed domain and developed feature extraction m ethods employing Gabor filters [5], the pyram id-structured wavelet transform (PW T ) and th e tree-structured wavelet transform (TW T) [6], In the T W T based method, a wavelet filter and a scaling filter are used to decompose an image into four sub bands and these subbands can be further decomposed to form a tree structure. Energy values of the subbands are calculated and used to extract the texture features. In the P W T based method, only the scaling subband is decomposed by the filters at each scale. In the Gabor filter based m ethod, an image is decomposed by the Gabor transform and the mean and the variance of th e coefficients are used to represent image texture features. Based on th e extracted image features, similarity measure computes the distance between th e query image and each image in the database so th a t the top m atched images to the query can be retrieved. The similarity measure used to rank the images has direct im pact on the retrieval performance. One commonly used approach for similarity measure in many retrieval system s is the norm-based distance between two feature vectors, such as the Cityblock distance and the Euclidean distance. However, it is far from optim al since the extracted image features are different from each other in global variances. Therefore they are not to be com pared on a same scale if the simple Euclidean distance is adopted for sim ilarity measure. In [7], a Kullback divergence similarity measure is proposed to com pute the distance of features extracted by a generalized Gaussian density (GGD) model in the wavelet domain. T he Kullback divergence approach addresses the above problem by com paring all different features w ithin a same framework of the probability density function (PD F). While the Kullback divergence is more accurate and effective than norm-based distances w ith regard to th e statistical model, the GGD is not optim al for the marginal distribution of wavelet coefficients. W ith more sophisticated and accurate models applied to the wavelet coefficients, their Kullback divergence forms may become very complicated and their com putational complexity may arise.

6 The features we extract from images such as colors, textures or shapes are often low-level features because most of them are extracted directly from digital representations of images in the database and have little or nothing to do with the human perception. On the other hand, the similarity between two images can be very high-level, or semantic. This requires the system to measure the similarity in a way human being would perceive or recognize. Thus, the gap between low-level features and high-level semantic meanings of the images has been the major obstacle to a better retrieval performance. Various approaches have been proposed to improve the accuracy of CBIR systems. Essentially, these approaches

fall into two main categories: to improve the features and to improve the learning of CBIR systems, so th at more high level semantics of human perception can be reflected. Researchers have tried many features th at are believed to be related with human perception, and they are still working on finding more. On the other hand, when the feature set is fixed, many algorithms have been proposed to measure the similarity in a way human beings might take. Besides, some interactive mechanisms [8] [9] [10] th at involve human as part of the retrieval process, which are called relevance feedback, are introduced into CBIR systems.

1 .2 .2

Im a g e W a term a rk in g

Usage of digital images has experienced a tremendous growth during the last decade because it has some notable benefits in efficient storage, ease of manipulation and transmission. While they are getting into people's life more and more nowadays, digital images are im portant commercial assets th at need to be efficiently managed, transferred and protected. Unfortunately, the nature of the digital images makes the work of pirates and tampering easier, since the digital contents are very easy to be reproduced or modified. It has become an especially severe issue with the rapid development of the Internet in recent years. Every year there is a huge loss for those intelligent companies who are owners of issued products. Even worse, the fear of piracy has made digital content creators and distributors hesitant in releasing their assets in the public. For example, it is known that sometimes the new movies can be downloaded from the internet even before they are projected in the cinemas.

7 Therefore it is generally difficult for product owners or rights holders to control and manage th e usage of their works and at the same time, keep them from being improperly used by others. One of th e solutions th a t addresses the annoying problem is the watermarking process, where inform ation can be hidden into the ''essence" of the m ultim edia object for protection, w ith condition to be either robust or fragile depending on real applications. T he embed ded w aterm arks can be either visible or invisible. However, under most circumstances, the invisible w aterm arks are preferred because they don't change the visual appearance of an image and they are unseen to prevent potential attacks. The existence of such an invisible w aterm ark can be determ ined only through a waterm ark extraction or detection algorithm. Different applications of invisible watermarks divide them into two categories: Fragile Wa term ark and R obust W atermark, with each term defined as follows:  F ra g ile W a te r m a rk : A watermark, which is destroyed when the image is manipulated digitally. Such a watermark is useful in proving authenticity of an image or verifying integrity of image content, just as related to the prior example of retrieved images. If th e w aterm ark is still intact, then the image has not been modified and can be regarded as an authenticated one. If the w aterm ark has been destroyed, then the

image has been tam pered with certain image operations such as compression, noising or malicious attacks.  R o b u s t W a te r m a rk : A watermark, which is very resistant to destruction under any image m anipulation. This is useful in verifying ownership of an image th a t is suspected of m isappropriation. Digital detection of the waterm ark would indicate the source of th e image. O ur interest of w aterm ark is on the fragile aspect, with an intention to prevent copyright violation and content tam pering by designing some authentication techniques. The robust w aterm ark, which features the ability to survive substantial image operations for d ata hiding or ownership detection purposes, is out of the scope of this thesis and will not be discussed.

8 H o stlm a^j

Key Channel Watermark Decoding

Watermark Embedding

Watermarks Ætered linage Authentic [ Identical?

Extracted Watermarks

F ig u r e 1.1: G eneral A rchitecture of A Fragile W atermarking System .

Figure 1.1 displays the general architecture of a fragile watermarking system. There are two major parts in the system: watermark embedding and watermark decoding. In the em bedding process, the watermarks are hidden into the host image on a public or private key basis through some watermarking techniques. The embedded watermark can be a number, a text, or even an image and is usually represented by a binary data sequence. Then the water marked image is transm itted trough certain channels to the reception end and experiencing all kinds of distortions or attacks during this phase. At the reception end, the estimation of original watermarks is extracted from the watermarked image and compared with the orig inal ones. If there are any subtle changes induced by compression, noise or attacks during the transmission phase, the extracted watermarks will not be identical with original ones and as a consequence of that, the image obtained will be claimed as not authentic. There has been a lot of dedications in the search of an efficient fragile watermarking method. The fragile watermarks can be embedded in either the space domain or the com pressed domain of an image. W ith the focus in the space domain, several fragile watermark ing methods th at utilize the least significant bit (LSB) of the image data were developed. For examples, a technique th a t inserts a checksum determined by the 7 most significant bits into the LSBs of selected pixels was proposed in [11]. A technique which embeds a digital

9 signature of the m ost significant bits of a block of an image into the least significant bits

of th e same block on a secret user key basis was developed by Wong in [12]. And later he extended his research on a public key scheme [13]. W ith the focus in the compressed domain, a wavelet-based fragile w aterm arking m ethod th at allows spatial and frequency localization of image tam pering is proposed in [14]. Some other researchers noted the constraints of a single fragile w aterm ark and developed a hybrid authentication waterm ark consisting of a fragile w aterm ark and a robust waterm ark [15]. The above stated m ethods are all successful in an im perceptible embedding of watermarks and the detection of potential image content tam pering. However, they need to change a large amount of image d ata to embed water marks, which is not quite efficient and may reduce the quality of the waterm arked image. Their approaches also don't facilitate the work toward a semi-fragile waterm ark, which is highly favorable in recent applications of fragile watermarks.

1.3

C o n tr ib u tio n

In this thesis, we obtain abstract image features by developing a statistical modelling in the wavelet domain. Based on the extracted image features, an image retrieval system and a fragile w aterm arking m ethod are presented.

T he statistical modelling uses mixed Gaussian or generalized Gaussian components to de scribe th e distribution of wavelet coefficients. The modelling has three m ajor contributions as follows: 1. A Gaussian m ixture model (GMM) and a generalized Gaussian m ixture model (GGMM) are developed for image modelling in the wavelet domain; 2. Two expectation maximization (EM) algorithms are developed to help estim ate the model param eters of GMM and GGMM, respectively; 3. A novel sim ilarity measure based on the Kullback-Leibler divergence for GMM and GGMM is developed.

10

Based on the statistical modelling, a new image retrieval system is presented. It has following characteristics and contributions: 1. GMM or GGMM param eters are used as image feature descriptors and are compliant with certain characteristics of human vision; 2. The indexing feature space is compact and has a miltiresolution representation of image texture contents; 3. The novel similarity measure based on the Kullback-Leibler divergence is applied in the distance com putation of two feature vectors and proved to be effective in image retrieval.

Based on the statistical modelling, a novel fragile watermarking method th at embeds wa term arks at multiple wavelet scales is developed. The presented method has four attractive features and contributions: 1. The watermark embedding process modifies only a few image data and conforms to human vision characteristics; 2. The new method constitutes a semi-fragile watermark approach, in which unautho rized changes made by some normal image operations such as compression can be distinguished from those caused by malicious attacks; 3. The new method can embed personal authentication information such as signatures or logos into the host image; 4. The new method is able to not only detect but also localize any slight image tampering.

,

1

1 .4

S tr u c tu r e o f T h e sis

In C hapter 2, we introduce some background knowledge th a t we will employ in later chapters. T he EM algorithm is used to estim ate statistical model param eters depending on the training d a ta provided. The Kullback divergence is used to measure the sim ilarity of two distribution functions. In C hapter 3, we develop a statistical modelling of images in the wavelet domain through GMM and GGMM. Some EM algorithms are developed to help estim ate the statistical model param eters. A novel similarity measure based on the Kullback divergence for the statistical models is presented. In C hapter 4, we present a CBIR system th at incorporates GMM based image feature extraction and Kullback divergence based similarity measure. GMM param eters from all decomposed wavelet subspaces are employed to compose the indexing feature space. The sim ilarity m easure of two indexing feature vectors is based on the novel Kullback divergence approach. In C hapter 5, we present a new fragile waterm arking method. A uthentication information is em bedded into th e statistical model through m anipulations of GMM param eters. Later on, a multiscale embedding of fragile watermarks is presented. In C hapter 6, we conclude the thesis and give some prospects of the future work.

Chapter 2 Preliminaries
In this chapter, we introduce some background knowledge th at will be employed later in this thesis. The EM algorithm for mixture models and the Kullback-Leibler divergence are briefly summarized here.

2.1

T h e E M A lg o r ith m for M ix tu r e M o d els

We describe the maximum-likelihood param eter estimation problem and how the expectationmaximization (EM) algorithm can be used for its solution [16]. We first present an abstract form of the EM algorithm as it is often given in the literature. We then develop an EM param eter estimation procedure to find the parameters of a mixture of Gaussian densities.

2 .1 .1

M clxim um L ik e lih o o d

Recall the definition of the maximum-likelihood estimation problem. We have a density function p(x\Q) th at is governed by the set of parameters © (e.g., p might be a set of Gaussians and © could be the means and covariances). We also have a data set of size N , supposedly drawn from this distribution, i.e., X = {zi, - - - , x n }- We assume th at these data vectors are independent and identically distributed with distribution p. Therefore, the resulting density for the samples is:
N

p(x|6) = Hpfeie) = 'L(eix).
i= l

(2.1)

12

13 This function L (0 |X ) is called the likelihood of the param eters given the data, or ju st the likelihood function. The likelihood is thought of as a function of the param eters 0 where th e d ata X is fixed. In the maximum likelihood problem, our goal is to find the 0 th a t maximizes L. T h a t is, we wish to hnd 0* where

0* = argm ax L (0 |X ). 0 Often we maximize lo g (L (0 |X )) instead because it is analytically easier.

(2.2)

Depending on the form of p (x |0 ) this problem can be easy or hard. For example, if p(a;|0) is simply a single Gaussian distribution where © = (/x, cr^), then we can set the derivative of lo g (L (0 |X )) to zero, and solve directly for fi and (this, in fact, results in the

stan d ard formulas for the mean and variance of a data set). For many problems, however, it is not possible to hnd such analytical expressions, and we m ust resort to more elaborate techniques.

2 .1 .2

T h e G e n e r a l E M A lg o r ith m

The EM algorithm is one such elaborate technique. The EM algorithm [17] [18] [19] is a gen eral m ethod of hnding the maximum likelihood estim ate of the param eters of an underlying distribution from a given data set when the data is incomplete or has missing values. The EM algorithm is applied in applications where optimizing the likelihood function is analyti cally intractable b u t the likelihood function can be simplihed by assuming the existence of (and hence values for) some additional missing (or hidden) parameters. As before, we assume th a t d ata X is observed and is generated by some distribution. We call X the incomplete data. We assume th a t a complete d ata set exists Z = (X, Y ) and specify a joint density function:

p(z\Q) ^ p{x, y\Q) = p(y\x, 0 )p (x |0 ).

(2.3)

W here does this joint density come from? Often it "arises" from the m arginal density function p(a;j0) and the assum ption of hidden variables and param eter value guesses (just

14 like in the case of Gaussian mixture). In other cases (e.g., missing data values in samples of a distribution), we also must assume a joint relationship between the missing and observed values. W ith this new density function, we can define a new likelihood function, L (0|Z ) = L (0 |X ,Y ) = p (X ,Y |0 ), called the complete-data likelihood. Note that this function is in fact a random variable since the missing information Y is unknown, random, and presumably governed by an underlying distribution. That is, we can think of L (0 |X ,Y ) = hx,e(Y ) for some function /ix,e(-); where X and 0 are constant and Y is a random variable. The original likelihood L (0 |X ) is referred to as the incomplete-data likelihood function. The EM algorithm first finds the expected value of the complete-data log-likelihood lo g p (X ,Y |0 ) with respect to the unknown data Y given the observed data X and the current param eter estimates. That is, we define:

Q (0, e('-')) = E [logp(X,Y|0)|X, 0('-^)] ,

(2.4)

where 0^"^) are the current parameter estimates that we use to evaluate the expectation and 0 are the new parameters that we need to optimize to increase the value of Q. The key thing to understand (2.4) is th at X and 0^'"^) are constants, while 0 is a normal variable we wish to adjust and Y is a random variable governed by the distribution / (y|X, Therefore, the right side of (2.4) can be rewritten as:

E [logp(X ,Y |0)|X ,0('-')] = / logp(X ,i/|0)y (i/|X,0('-^)) % Jyer

(2.5)

Note th a t / (^|X, 0 ^ " ^^) is the marginal distribution of the unobserved data and is depen dent on both the observed data X and on the current parameters 0^'"^), and T is the space y belongs to. In the best of cases, this marginal distribution is a simple analytical expression of the assumed parameters might be very hard to obtain. The evaluation of this expectation is called the E-step of the EM algorithm. Notice the meaning of the two arguments in the function Q ( 0 , 0 ). The first argument 0 corresponds and perhaps the data. In the worst of cases, this density

15 to th e param eters th a t ultim ately will be optimized in an attem pt to maximize the likelihood. T he second argum ent © corresponds to the param eters th a t we currently use to evaluate th e expectation. T he second step (the M-step) of the EM algorithm is to maximize the expectation we com puted in th e first step. T h a t is, we find:

©W -- argm ax Q (©, ©('
0

.

(2.6)

These two steps are repeated as necessary.

Each iteration is guaranteed to increase

th e log-likelihood and the algorithm is guaranteed to converge to a local maximum of the likelihood function. As presented above, there is not a fixed form to code the algorithm. This is the way, however, th a t the algorithm is presented in its most general form. The details of the steps required to com pute the given quantities are very dependent on the particular application, so th ey are not discussed here when the algorithm is presented in this general form.

2 .1 .3

T h e E s tim a t io n o f G a u ssia n M ix tu r e D e n s it y P a r a m e te r s U s in g E M

T he m ixture density param eter estim ation problem is probably one of the m ost widely used applications of the EM algorithm in the com putational p attern recognition community. In th is case, we assume the following probabilistic model:
M

p{x\G) = ' ^ a i p i { x \ 6 i ) ,
i-- l

(2.7) ûj = 1 and each pi

where th e param eters are © = (ai, · · , cum,

- ,& m ) such th a t

is a density function param eterized by 6i- In other words, we assume we have M component densities mixed together with M mixing coefficients a^. T he incom plete-data log-likelihood expression for this density from d a ta X is given by:

16
N N / M \

log(L(0|X )) = log JJp (2 ;j|0 ) = ^ l o g ( '^oiiPj{xi\9j) ], (2.8) i=l i=l \j= l / which is difficult to optimize because it contains the log of the sum. However, if we consider X as incomplete and assume the existence of unobserved data items Y = whose values

inform us which component density "generated" each data item, the likelihood expression can be significantly simplified. T hat is, we assume that yi £ I, -  , M for each if the sample was generated by the mixture component. i, and yi = k

If we know the values ofY,

the likelihood becomes;
N N

lo g (L (e|X ,Y )) = log(p(X, Y |e ) ) = J2^og(p(x,\m)P(yi)) = ^log(Q ,,p,.(xi|«»< )),
1=1 1=1

(2.9)

which, given a particular form of the component densities, can be optimized using a variety of techniques. The problem, of course, is th at we do not know the values of Y. If we assume Y is a random vector, however, we can proceed. We must first derive an expression for the distribution of the unobserved data. Let's first guess at parameters for the mixture density, i.e., we guess th at = (af, · · · , Of , - " , ^m)

are the appropriate parameters for the likelihood L(0® |X,Y). Given 0^, we can easily compute pj{Xi\$j) for each i and j. In addition, the mixing parameters aj can be thought of as prior probabilities of each mixture component. Therefore, using Bayess rule, we can compute:

and
N

p(y|X , 03) = \ \ p { y i \ x i , ©3), (2.11) i=l where y = (yi, - - - , 2 /at) is an instance of the unobserved data independently drawn. When we now look at (2.5), we see th at in this case we have obtained the desired marginal density by

17 assum ing the existence of the hidden variables and making a guess at the initial param eters
of their distribution. In this case, (2.4) takes the form:

Q(©,©^)

=

Y ^ lo g (b (© |X ,y ))X y |X ,© ^ ) yeT
N N

yeT 1 = 1 M N M

j=i M M N

=

E E
1=1

^og{aipi{xi\9i))
y i= ly 2=l
Vn = 1

Hp(yj\^j^
j= l

(2.12)

i= l

A fter some m anipulations, (2.12) can be evolved into:

M

N

Q(©,©») 1=1

\og{aipi{xi\ei))p{l\xu ©^)
M N M N

=
1=1 i= l

log(ai)p(Zki, 0 ® ) + X ] X ] ^og{pi{xi\ei))p{l\xi, ©»).
1=1 i = l

(2 .13)

To maximize this expression, we can maximize the term containing ai and th e term contain ing Q i independently since they are not related. To find th e expression for a/, we introduce the Lagrange multiplier A w ith the constraint th a t -- 1, a,nd solve the following equation: d dai As a result, we obtain:
M N

= 0.
1=1 i = l

(2.14)

^ ,- 1 To find an analytical expression for 6i, we m ust first assume a distribution function for th e com ponent density. For example, if we assume a Gaussian distribution w ith m ean /// and variance af for each component I:

18 (X ^

pi{x\m,af) = --= ^ e V27T(7(

,

(2.16)

then the distribution parameters [fii, af] can be derived through following procedures. Taking the log of (2.16), ignoring any constant terms (since they disappear after taking derivatives), and substituting into the right part of (3.8), we get:

M

N

M

N

/

/

\2 \

5 ^ J]log(P/(^ih.crD )P(^ki>© ® ) = m m 1= 1 i=l 1= 1 i=l ^

------------------------------------- (2 17) I /

Taking the derivative of (3.12) with respect to fii and setting it to zero, we get:
N

m i=l with which we can easily solve for p;:

- m)p(^ki, Ô®) = 0,

(2.18)

fii =

E i l l Xip{l\Xi,Q3)

y

(2.19)

To find af, we take the derivative of (3.12) with respect to ai and setting it to zero:

m

(-^ +

P(^kû G") - 0,

(2.20)

with which we can solve for af:

Summarizing, the estimates of the new parameters © in terms of the old parameters ©» are as follows:

19

^2 _ E t= i ' E f= .P (/|x < ,e» )



2 .2

T h e K u llb a ck -L eib le r D iv e r g e n c e
Assuming we having a

F irst, let us have a definition of the entropy of a distribution.

distribution p = {p(x) : x G X}, the entropy of p, say H(p), is defined as:

H{p) = - ^ p { x ) logp(æ) = E p [- logp(X )]. (2.25) xex T he entropy represents the am ount of energy in a system th a t is described by the distribution function p. Based on the concept of entropy, Kullback and Leibler (1951) introduced a measure of inform ation associated with two probability distributions of a discrete random variable [20]. Assum ing th e two probability distributions are represented by p and q respectively, the m easure (or the discrim ination function) of the two distributions is defined as:

D{p, q) = J 2

^

= E,

9(X )J-

(2.26)

This m easure is called the Kullback-Leibler Divergence, also called relative information, di rected divergence, cross entropy by different authors. It is effective in evaluating the distance of two discrete distributions from a statistical point of view. Following two properties make the Kullback-Leibler divergence an appropriate choice for distance evaluation: P r o p e r t y 1 (Nonnegativity). D{p,q) > 0, with equality i f p = qP r o p e r t y 2 (A dditivity). where p i,q i G A ,,,P 2,92 G AmA lthough very effective in distance evaluation, (2.26) is not symm etric sym m etric version, which is known as J-divergence, is given by: in p and q. Its D{pi * ps, qi * %) = D{pi,qi) 4- D{p 2 , 92),

PROPERTY OF RYERSOfi UBHA ny

20

J{p,q) = D{p,q) + D(q,p) = ^
xX

(p{x) - q { x ) ) l o g ^ j ^ . ^

(2.27)

If X is a continuous random variable instead, assuming there are two probability density functions p{x) and q{x) with respect to x, then the Kullback-Leibler divergence between them [21] is defined as;

D(jp,q)=

JR

f p { x ) l o gQK^) ^^dx.

(2.28)

Chapter 3 Statistical M odelling in the Wavelet Domain
In this chapter, we present a statistical model containing multiple Gaussian components to describe the wavelet coefficients. An EM algorithm is developed to help estim ate the statistical model param eters. Based on the statistical modelling, a novel sim ilarity measure of two distinct model distributions is developed using the Kullback-Leibler divergence.

3 .1
3 .1 .1

N e w S ta tis tic a l M o d e ls an d R e la te d E M A lg o r ith m s
A G a u s s ia n M ix tu r e M o d e l in t h e W a v e le t D o m a in

T he 2-D wavelet transform is known to decompose an image into many wavelet subspaces at different scales. In each decomposed wavelet subspace, the image information is carried in th e wavelet coefficients. Therefore an appropriate description of these coefficients can help us w ith a b etter understanding of the image and a better utilization of the coefficients in some applications. T he Gaussian m ixture model has an accurate description of the wavelet coefficients. Since th e wavelet coefficients have a peaky, heavy-tailed marginal distribution [22] and a near zero m ean, their probability density function (PDF) can be well expressed through a m ulti-state G aussian m ixture:

21

22

(3.1)

. E m =l -P m --1 )

where the states of coefficients are represented by subscript "m" and the a priori probabilities of the M states are represented by P^. The zero mean Gaussian component 0,

corresponding to the state m has the variance am^. Note Wi,i = 1, , K, represent the wavelet coefficients in a single wavelet subspace. It is also observed th at in this peaky, heavy-tailed marginal distribution, only a few coefficients have large values at the positions where image edges occur, while most others have very small values. Therefore it is reasonable to simplify the GMM into a two-state representation as shown in (3.2). One state is used to describe large coefficient distribution and the other state is used to describe small coefficient distribution. ' p{wi) = Ps g{wi, 0, cr/) -h Pi · g{wi, 0, ai^), (3.2) P, + P = 1. The state of small coefficients is represented by subscript "s" and the state of large coeffi cients by subscript "f" . The a priori probabilities of the two states are represented by Pg and Pi, respectively. The zero mean Gaussian component g{wi, 0, cTs^) corresponding to the small state has a relatively small variance capturing the peakiness around zero (small coef

ficients), while the component g{wi,0, ai"^) corresponding to the large state has a relatively large variance capturing the heavy tails (large coefficients).

3 .1 .2

A n E M A lg o r ith m for th e G a u ssia n M ix tu r e M o d e l
cr/^] must first be obtained before they can be used for any

The GMM parameters [Pg, Pi,

purpose. Taking the coefficients of each image as the training data, its GMM parameters

23 can be obtained through the EM algorithm introduced in C hapter 2. In each iteration of the
EM algorithm , there are two steps. The E step calculates the individual state probabilities for each wavelet coefficient Ps,t,P/,j and the M step involves simple closed-form updates for th e variances ai^] and the overall state probabilities [Pg, P;]. The two steps interact with

each other in an iterative process to help obtain a set of final converged GMM param eters;

E M A lg o r ith m fo r G M M Step 1) I n itiliz a tio n : Select an initial model estimate: 6 (0 ) = [Pg(0),P,(0),(Tg"(0),(T,:^(0)], where 0 represents the GMM param eter set [Pg, Pi,(7s^,cri^]. Set iteratio n counter n = 0. Step 2) E s te p ; Calculate the state probabilities for each wavelet coefficient W i'. Pg{n) -g (w i,0 ,cr/(n )) Ps{n) g(wi, 0, ag2(n)) + P;(n) · g{wi, 0, cr;2(n)) Pii = Pi{n) g{wi,0,ai'^{n)) Pg{n) g{wi,Q, (Jg2(n)) + P ( n ) · g{wi,0, (Ji^{n)) (3.4) (3.5) (3.3)

where K represents the total number of coefficients in the wavelet subspace. Step 3) M s te p : U pdate the model param eters to maximize the overall probabilities: 0 (n ) -- » 0 ( n + 1) Pg(n + 1) = Pl{n + 1) = ;^ CTg2(n + l) = , S i= l P^.i) (3.6)

^

Step 4) Set n = n + 1. If convergence condition is satisfied, then stop; Otherwise, return to E s te p .

24

3 .1 .3

A G e n e ra lized G a u ssia n M ix tu r e M o d el

The GMM is a specific case of a generalized Gaussian mixture model (GGMM). A two-state representation of GGMM is given as follows: ' p{Wi) = Ps · hs{'Wi,Ois,P) + Pi  h{wi, a , p ) =
. P s + P i = I-

,

(3.7)

The state of small coefficients is represented by subscript "s" and the state of large coefficients by subscript "I". The generalized Gaussian component hs{wi,as,/3) corresponding to the small state has a relatively small variance represented by ctg, while the component hi{wi,oii, /3) corresponding to the large state has a relatively large variance represented by ai. Here T{t) = u*~^e~'^du is the Gamma function and /3 can be any fixed exponent value. When

/? = 1, the GGMM becomes a Laplacian mixture model (LMM) and when (3 = 2, the GGMM is exactly the GMM.It is possible th at some GGMM cases, with their exponentvalues other than 2, may have a better description of wavelet coefficients than the GMM. Therefore, we need to compare their performance with th a t of GMM in certain applications. For this purpose, we specifically develop an EM algorithm to help estimate the GGMM parameters [Psi Pi) ^s) O ^i]' As known from Chapter 2, the EM algorithm employs an iterative approach to estimate model parameters. In each iteration (say g), the objective of the EM algorithm is to obtain an updated parameter set 0 from the current parameter set 0^ by maximizing the following log-likelihood function Q:

K

Q (0,0® )

=

y^,'^Og{Pmhm{Wi\oirri))p{m\Wi,Q^)
m = s ,l i = l

K

K

=

1 ] J^ lo g (P ,,, )p (m |ia i,0 S )+
m = 3 ,l i=l

^
m=s,J i=l

log(/irn(w(|am))p(m|w{, 0^),(3.8)

where 0» represents the current model param eters [P f, P f , a f , af] and K represents the total

25 num ber of coefficients in the wavelet subspace. T he two state probabilities for each wavelet
coefficient Wi are represented by p{m \wi,0^ ), which can be easily calculated using Bayes's rule:

To m aximize the log-likelihood expression in (3.8), we can maximize the term containing Pm and th e term containing a^. independently since they are not related. To find th e expression for Pm, we introduce the Lagrange multiplier A with the constraint th a t = 1, and solve the following equation: d As a result, we obtain:
K K

^

^

\og{Pm)p{m\wi, 03) + A ^

- 1

=

0.

(3.10)

Pm =
i= l

(3.11)

To find an analytical expression for am, we input the generalized Gaussian function h{wi, a,j3) as given in (3.7) into the right p art of (3.8) and obtain:
K

\O g { h m { W i\O im )) p { m \'W i, 0^) m = s,l i=l
K 1 y ] y ] I log/) - io g 2 o ^ - l o g r ( - )

=

Wi

p (m |w i,0 3 ).

(3.12)

m = s,l i= l

%

Taking th e derivative of (3.12) w ith respect to

and setting it to zero, we get:

y^

( -- -- + (3 \w ifa m

p {m \W i,

0®) = 0,

(3.13)

w ith which we can solve am?

(3.14)

26 To be concluded, the update of model parameters in the EM algorithm is an iterative

procedure until a final converged set of parameters are found. In each iteration, the EM algorithm has two steps: the E-step and the M-step. The E- step calculates the individual state probabilities for each wavelet coefficient p{m\wi,Q^) and the M-step involves the up dates for the model parameters [Ps-, Pi,as,oti\. The complete EM algorithm for GGMM is given as follows:

E M A lg o rith m for G G M M Step 1) In itiliz a tio n : Select an initial model estimate: (3.15) where 0 represents the GGMM param eter set [Ps,Pi,as,Oii]. Set iteration counter n = 0. Step 2) E ste p : Calculate the state probabilities for each wavelet coefficient p{m\wi, ©(n)): p{s\wi,Q{n)) =
P s { n ) h s { w i y a s { n ) , 0 )

Ps{n) · hs{wi,a^{n),j3) + Pi{n) hi{wi,ai{n),

,

i = I, -  , K ,

(3.16) p(l\wi,G(n)) = ___________ Pijn) · hi{wi,ai{n),f3) ___________ Psin) hs{wi,as{n),f3) + P/(n) · hi{wi,ai{n), f3)'
i -- I,-- - , K ,

(3.17) where K represents the total number of coefficients in the wavelet subspace. Step 3) M ste p : Update the model parameters to maximize the overall probabilities: Q{n) Q{n + 1)

' Ps{n + 1) = ;^ E £ i p(g|wi, 0 (n )),
--

1

(3.18)

27 Step 4) Set n = n + 1. If convergence condition is satisfied, then stop; Otherwise, return to
E s te p .

3 .2
3 .2 .1

A K u llb a ck -L eib le r D iv e r g e n c e B a s e d S im ila r ity M e a  su r e for th e S ta tis tic a l M o d e ls
G e n e r a l M in k o w sk i D is ta n c e s

In m any applications based on the statistical modelling, there is a necessity to measure the sim ilarity of two distributions th a t are determined by their model param eters. The most com m on way to compare two param eter sets is done by the Minkowski distance. Given two N dim ensional param eter set X and T , the general Minkowski distance between X and Y is:
/N -l \ r

d ,(x ,y )=

.

(3.19)

If r = 1, the distance is known as the City-block or M anhattan distance. If r = 2, the distance is called the Euclidean distance. It can be observed th a t the general Minkowski distance is not effective because it fails to treat each param eter equally during comparison. Some large value param eters will dominate the distance function d r ( X , Y ) regardless of th e fact th a t some small value param eters may have the same im portance. For example, th e two probability param eters [Ps,Pi] in GMM should be treated equally with the two variance param eters [ag^, ai^] in distance calculation, however their values are too small and alm ost neglectable in the Minkowski distance. The normalized Euclidean distance we used in [23] [24] is one way to alleviate the problem such th a t all param eters have approximately th e sam e influence on the overall distance. However, it is still not optim al because the

param eters represent measurements of different image characteristics. It is unlikely to have an objective distance calculation by simply including all param eters with different natures into th e Mikowski formula and calculating their overall distance.

28

3 .2 .2

S im ila r ity M e a su re B a se d o n th e K u llb a ck -L eib ler D iv e r  gence

The Kullback-Leibler divergence (or Kullback divergence) provides an effective approach for similarity measure of two distributions. Suppose we have two probability density functions (PDFs) p\{x) and P2 {x) th at are for wavelet coefficients in a wavelet subspace. As known from Chapter 2, their Kullback divergence is calculated as follows: diPi{x),P2(x)) J P t{x )ln ^^d x. (3.20)

In case we use the GGMM to model the coefficients, the two distributions pi(x) and P2 (x) take the forms as:
Pi{x) = Ps,h^i(x,as,,P) + Pi^hi^{x,ai,,P),

(3.21)
P2{x) = P, ^hs^{x, as^, P) + Pi^hi^{x,ai2, (3).

By substituting (3.21) into (3.20), we obtain the complete Kullback divergence form:

= y

/)) -k ^

«,,,/))) In
(3.22)

It can be seen th a t all GGMM parameters [Pg, Pi, a ,, a;] are involved in the Kullback diver gence computation as given in (3.22) to measure the similarity of two distributions pi{x) and P2 {x), no m atter how different are these parameters in their values and in their meanings of image characteristics. However, there is no simple closed form for the complete Kullback divergence given in (3.22) so it can only be numerically calculated. The computational complexity is so high th a t the complete Kullback approach is not practical for a CBIR system. It is observed th at by dividing the Gaussian mixture distribution into two separate Gaussian distributions, the simple closed form of the Kullback divergence for each separate Gaussian distribution can be easily computed [25]. The complete Kullback divergence can be approximated by the sum of two separate Kullback divergences. Therefore, we present a new Kullback divergence based similarity measure for GGMM as follows: dk{Pi{x),P2 {x)) =
Fs{x)

4- F i { x ) ,

(3.23)

J P / W = l p., h,, (x, a , , , 0) In

Ps^hs^{x,as^,fi) ^ dx.

29 (3.24) (3.25)

T he two separate Kullback divergences Fs{x) and Fi{x) have simple closed forms after inte gral calculation, as given by (3.26) and (3.27): P .(x) = P ,, l n '

+ Ps-^CXsJ ' (3
2 \ ^ Ph \Ph<^kJ /?

Si

O :® !
-

a .32

1

(3.26)

Fi{x) = Pi, In

^ 1 - 1

(3.27)

As for th e GMM, the new Kullback divergence based similarity measure take the following form: dk{Pi{x),P 2 {x)) = Fs{x) + Fi{x), P ,(x ) = P ,.ln V 52^51 (3.28) - 1 (3.29) (3.30)

+ +

Si
Ph

C T : Si '32
( o-(i

T he sim ilarity measure based on the proposed separate Kullback divergence approach can be calculated very efficiently using GMM or GGMM parameters. In fact, its com putational com plexity is retained at the same level as other conventional similarity measures using Minkowski distances. On the other hand, this separate Kullback divergence approach (3.23)(3.25) has nearly the same efficiency as the complete Kullback com putation (3.22), which will be shown later in the simulation results of image retrieval. Both Kullback approaches outperform traditional similarity measures by having a more accurate distance com putation and a higher image retrieval rate.

3 .2 .3

A n a ly s is o f th e N e w S im ila r ity M e a su r e

Now it is proposed th a t the separate Kullback divergence can approxim ate the complete Kullback divergence in distance com putation. The closeness of the two divergences can be justified through a m athem atical analysis.

30
Assume we have two Gaussian mixture distributions: Pi{x) = Pa,9si{x) + Pi^gi^ix) = A + B,

(3.31)
P2{x) = Ps^gsiix:) + Phghi^) = C + D. For simplicity, we use A, B, C, D to denote their four Gaussian components. Their complete Kullback divergence (3.22) can be rewritten as: d{pi{x),pi{x)) =

j

{A ^ B ) \ ï i ^ ^ ^ d x =

j

A \n -^ ^ ^ d x

+ J Bln ^ ^ ^ d x ,

(3.32)

while their separate Kullback divergence becomes: dk{pi{x),P2 {x)) =

J A l n ^ d x + J B l n -- dx.

(3.33)

If we suppose the two Gaussian mixture distributions are similar to each other, which means:

#we can further derive: A +B A
--

(3-34)

c +n C
A+ g B C+D-D-

(3.35)

If we substitute (3.35),(3.36) into (3.32) and then compare it with (3.33), we will get the conclusion: dk{Pi{x),p2{x)) ^ d{pi{x),p2{x)). (3.37)

T hat means the separate Kullback divergence is able to approximate the complete Kullback divergence when the two Gaussian mixture distributions are similar to each other. As far as the application of image retrieval is concerned, since any two images from the same class will have relatively similar Gaussian mixture distributions, their distance can be computed accurately using the separate Kullback divergence in stead of the complete Kullback diver gence. It is also known th at an accurate similarity measure of images within the same class plays a key factor in overall image ranking. From this point of view, the separate Kullback divergence is successful in substituting the complete Kullback divergence for image retrieval.

31 In case th e two Gaussian m ixture distributions are different from each other, it is worth
of stu d y th a t how th e separate Kullback divergence and the complete Kullback divergence will respond to this difference respectively. To simplify the problem, we assume th a t they have same G aussian components b u t slightly different state probabilities:
P i { x ) = Ps Çs i x) + Pi gi ( x) ,

(3.38)
P 2 { x) = {Ps + 5 ) g s { x ) + {Pi - S ) gi { x ) ,

where J is a very small quantum compared with Pg and Pi. T he difference between their com plete Kullback divergence and separate Kullback divergence is given by: T = d{pi{x),p2{x)) - dk{pi{x),p2{x)) In
P , g , { x ) + Pi gi { x) {Ps + 6 ) g s { x ) + {Pi - S) gi { x) Psgs{x) + P m { x ) {Ps + 5 ) g s { x ) + {Pi - S) gi { x)

-- J Psgs{x)
+ j Pi g i ( x )

In

Paga{x) {Ps + 5)gs{x)
Pi g i { x ) {Pi - 6 ) g i { x )

dx dx. (3.39)

In

In

A pplying Taylor's series, since In =
P s p s i x ) + Pi gi { x) {Ps + 5 ) g s { x ) + {Pi - S) gi { x) S \ , . 5 { gs { x)

In 9i(x))

PsPsix)
{Ps + 6)ps{x)

In I 1 +

In

1+

PsP s{x) + PiPi{x)

S{ps{x) - g i { x ) ) P sP s{x) + PiPi{x) S { P s + Pi ) g i { x ) P s {P sP ,{^ ) + PlPl{x))

+ o(<^) (3.40)

and In = In
5
P sG aix) + PiPl{x)

: -- 7 --In ·

{P s + S ) p s { x ) + {Pi - S ) p i { x )

Pi9i{x) { P i - S)gi{x)

1

- l - . n

1+

K 9 s{x) - gi{x))

Ps9s{x) + Pi9i{x)
,

6 { ps { x) - p i { x ) )

~P,~

+

^ '
(3.41)

--6{Ps + P i)9s{x)

32
we substitute (3.40),(3.41) into (3.39) and obtain:

^

f 5{Ps + P[)gi{x)gs{x)

_

f SjP ^ + Pi)gs{x)gi{x)

J = 0.

Psgs{x) + Pigi{x)

^

J

Psgs{x) + Pigi{x) (3.42)

The result reveals th a t the separate Kullback divergence is exactly the same as the complete Kullback divergence if the two Gaussian mixture distributions under comparison are slightly different in parameters. Therefore, the separate Kullback divergence can be regarded as a very good approximation to its complete counterpart.

Chapter 4 Statistical Model Based Image Retrieval
T he statistical modelling of GMM and GGMM provides a new way to interpret image tex tu re contents through the model param eters, which can be applied very naturally in the application of image retrieval. In this chapter, we present a new CBIR system th a t incor porates statistical model based image features and a Kullback divergence based similarity measure. T he images are modelled by GMM or GGMM in the wavelet domain and the statistical model param eters are employed to construct the indexing feature space for the C B IR system . T he similarity measure of two indexing feature vectors is performed based on th e novel Kullback divergence approach presented in the previous chapter. Simulations are conducted to dem onstrate the effectiveness of the new CBIR system.

4 .1

O v e r v ie w o f th e P r o p o s e d C B IR S y s te m

Figure 4.1 shows the architecture of the proposed CBIR system. For each image in the image database, its low-level features (textures, shapes and colors) will be extracted by the GMM and other feature processing techniques and the obtained indexing feature vector will be stored in th e feature database. W hen a query image comes in, its feature vector will be com pared with those in the feature database one by one based on the kullback divergence sim ilarity measure. T he top M images in the database with smallest feature distances to the query will be retrieved. 33

34
Feature Extraction
Storing of feature vectors Feature Database (N) Im a^ Database (N)

Query image Similarity Measurement

M retrieved images User Interaction

Final retrieved images

Updated query & weight parameters Relevance Feedback

Image Retrieval

F ig u r e 4 .1 : T he Proposed CBIR System.

Since there is always a gap between low-level image features and high-level semantics of human perception, the M retrieved images may not be the optimal results. Therefore the relevance feedback mechanism, which gets human involved in the retrieval process, is introduced in the CBIR system. The user will compare the M retrieved Images with the query and determine which one is relevant and which one is irrelevant based on his visual discrimination. Based on the discrimination results, the query and the feature weight pa rameters will be updated and applied in the next round of similarity measure. Through this iterative process, the gap between low-level image features and human perception can be compensated and accordingly the retrieval performance will be improved. The iterative process will stop if there is no further improvement compared with the previous round of retrieval or the optimal retrieval result is achieved.

4.2

T h e In d ex in g F eature Space for Im age R etriev a l
cr/^]

While constructing the indexing feature space, we consider the GMM parameters [P^, Pi,

as legitimate image texture features. From a human perception point of view, since large coefficients indicate singularity such as image edges or visible texture patterns, the two a priori probabilities Pg and Pi are able to represent the denseness of such singularity within an image while the two Gaussian variances (jg^ and are able to represent the depth

of such singularity. Therefore, they all have significant meaning in image texture content

interp retatio n and are very good candidates of image texture features.

35

T he indexing feature space consists of GMM param eters obtained from all decomposed wavelet subspaces. As known, the 2-D wavelet transform decomposes an image into three wavelet subspaces (horizontal, vertical and diagonal) at each scale. T he decomposed wavelet subspaces contain different image texture information, therefore their respective GMM pa ram eters should be all incorporated into the indexing feature space, which has a following form of representation: F = [WiH,Wiv, · · · , W r h , W r v , W rd ], (4.1)

where W represents the GMM param eter set [F*, P;, cTg^, ct/^] of a single wavelet subspace. Subscripts H , V , and D represent the three different directions (Horizontal, Vertical and Diagonal) of the wavelet transform at each scale and subscript R represents the number of scales the image is decomposed. As for the GGMM, its indexing feature space has a same form of representation given by (4.1), with W representing the GGMM param eter set [Ps, Pi,as,ai] instead.

4 .3

K u llb a c k D iv e r g e n c e B a sed S im ila r ity M e a su r e

In order to m easure the similarity of an image and the query, we need to com pute their overall feature distance. Using the separate Kullback divergence approach given in Chapter 3, we com pute th e distance of the pair of Gaussian m ixture distributions in each decomposed wavelet subspace and then sum them up to get an overall distance, which can be shown as follows:
D (U , V ) = ^

^
^ d k { Ui j { x ) , Vi j { x ) ) , (4.2)
i= l j= H ,V ,D

where U and V represent the feature vectors of the image and the query, respectively. Their gaussian m ixture distributions in each decomposed wavelet subspace are represented by Uij{x) and Vij{x). T he separate Kullback divergence dk{Uij{x),Vij{x)) can be calculated using (3.23)-(3.30).

36

4 .4

S im u lation R esu lts

The Brodatz image database is used to demonstrate the effectiveness of the proposed feature extraction method. The database consists of 1,856 images in 116 different classes, with each class containing 16 similar images. Given a query from any class, the ideal condition is th a t all 16 images in the same class as the query are retrieved. The retrieval performance of the presented new method is evaluated by the overall retrieval rate which is defined as the average percentage of images belonging to the same class as the query in the top 16 matched [5]. Besides, since the first round of retrieval (or initial retrieval) reflects objectively the effectiveness of the applied feature extraction technique and similarity measure, we use the initial retrieval rate to benchmark the retrieval performance. We consider the following two factors will affect the retrieval performance: 1) How many wavelet scales each image is decomposed, 2) which wavelet and scaling filters are used in the wavelet decomposition. W ith more levels of wavelet decomposition, the retrieval performance will get better because more image texture information will be represented by the indexing feature space. However at the same time, the feature number will increase accordingly, which will lower the efficiency of the whole feature space. Besides the decomposition levels, different wavelet and scaling filters have different characteristics in decomposition and will also affect the retrieval performance. In order to test the filters' impact on the retrieval performance, the dbl (Haar) filters and the db2 (Daubechies 2) filters are used in the wavelet decomposition, respectively. Images are decomposed into two wavelet scales in this test. A comparison of their retrieval performance is given in TABLE 4.1. We can see that db2 filters slightly outperform the d b l filters in our experiment. Although the db2 filters are more complex and ought to have a better decomposition of image texture contents, its retrieval performance is not significantly better than th at of the dbl filters. We further compare the retrieval performance of our method by decomposing the images into two wavelet scales and three wavelet scales, respectively. In the two-scale decomposition, we get a total of 6 wavelet subspaces and 1 scaling subspace. Since each wavelet subspace

Initial Retrieval Rate Wavelet Scales

D bl Filters 68.96% 2

37
Db2 Filters 69.12% 2

T able 4.1: Initial Retrieval Rate Based on Dbl And Db2 Filters.

has 4 features, the to tal number of features in the indexing feature space is 6 x 4 = 24. It is also obvious th a t the feature number in the three-scale decomposition is 9 x 4 = 36 . TA BLE 4.2 lists the comparison result. We can see th at -with three scales of decomposition, th e retrieval rate is enhanced by 3 percent. B ut at the same time, the number of features also increases by nearly 50%. Scales of Decomposition 2 3 Initial Retrieval Rate 69.12% 73.72% Number of Features 24 36

T a b le 4 .2 : C om parison o f Different D eco m p o sitio n Scales.

To illustrate th e performance of the new method, we select four different query images from th e B rodatz database and perform the retrieval. Figure 4.2 - 4.9 display the retrieval results. All th e four query images are full of edge and texture information therefore are ideal to evaluate th e retrieval performance. TABLE 4.3 lists the retrieval results of the four queries. As can be seen, the initial retrieval result is very satisfactory and the performance is further improved in the second round of retrieval by involving hum an interaction. This result indicates th a t the features we extracted are appropriate and effective. Besides, the image retrieval rate can be significantly enhanced if we introduce the relevance feedback m echanism and perform more iterations of retrieval. We continue the experiment to compare the Kullback divergence based similarity mesr sure w ith other sim ilarity measure schemes. In this experiment, two levels and three levels of wavelet decomposition are performed respectively. According to (4.1), the two-level decom-

38
Query Class 87 98 111 114 Correctly Retrieved Images Among Top 16 Matched Second Round Retrieval Initial Retrieval 16 14 15 14 15 13 16 12

T a b le 4 .3 : R etrieval R esults of 4 Different Queries.

position generates six wavelet subspaces and has twenty-four features (four features for each subspace) in the feature vector, while the three-level decomposition generates nine wavelet subspaces and has thirty-six features in the feature vector. Then three different kinds of similarity measures (normalized Euclidean distance, complete Kullback divergence and sep arate Kullback divergence) are applied on the texture features to compare their retrieval performances, as shown in TABLE 4.4. Scales of Type of Similarity Measure Decomposition Normalized Euclidean Complete Kullback Separate Kullback 2 scales 69.12% 71.87% 71.63% 3 scales 73.72% 75.68% 75.50%

T a b le 4 .4 : Initial Retrieval R ate Based on Sim ilarity Measures.

When calculating the complete Kullback divergence, we use a discrete integral approach with integral range [-1500,1500] and integral step 1 to obtain the result. As can be seen from TABLE 4.4, the similarity measure based on the Kullback divergence achieves a bet ter retrieval rate than the normalized Euclidean distance approach, because the GMM is a statistical model that uses PD F to describe image texture features. The closeness of two images, represented by the similarity of their PDFs, can be more accurately measured using Kullback divergence than other approaches. Figure 4.10 - 4.11 show the top 16 matched images of the query "dl2 _ l" based on the Euclidean distance and the Kullback divergence.

39 respectively. T he correctly retrieved images are marked w ith check boxes. It can be seen
in this example th a t the similarity measure based on Kullback divergence has a better per formance th a n th a t based on Euclidean distance. It can also be seen from TABLE 4.4 th a t the presented new sim ilarity measure based on separate Kullback calculation has the same effectiveness as th a t based on the complete Kullback com putation. Meanwhile, it has much lower com putational complexity and is practical in a CBIR system. In order to observe the impact of different exponent values in GGMM on the retrieval perform ance, we com pare different GGMM cases with the exponent value (3 ranging from 1.0 to 3.5. T he model becomes LMM if = 1 and GMM if /3 = 2. Some researchers stud

ied wavelet coefficients using a uni component GGD model and suggested the appropriate exponent is around 0.5 for low or middle frequency subspaces [26]. In fact, the appropriate exponent value selected for retrieval is dependent on the model applied, the subspaces de composed and the image database th a t is tested. In our case, as far as GGMM is adopted and some high frequency subspaces are used for feature extraction, the appropriate exponent value for retrieval is around 2.0. In our experiment, image features from three wavelet scales are extracted and the similarity measure is based on the separate kullback divergence. It can be concluded from Table 4.5 th a t the retrieval rate achieves the highest when (3 takes a value between 2.0 and 2.5, which means, the GMM is appropriate and near optim al among all GGMM cases when the experiment is conducted on the brodatz image database. GMM /? = 2.0 75.50% (3= 1.0 69.15% (3 = 1.5 73.75% GGMM (3 = 2.5 75.80% 13 = 3.0 73.63% (3 = 3.5 68.44%

Retrieval R ate

T a b le 4 .5 : G M M C om pared w ith G G M M .

We then compare the GMM and separate Kullback based approach with other traditional m ethods, such as th e P W T (Pyramid Wavelet Transform) based and the G abor filter based m ethods. Like GMM, these m ethods also extract image texture features from the compressed domain. We also compare our method with the GGD model based Kullback divergence

40 approach presented in [7]. The GGD is another statistical model in the wavelet domain, but
it's a uni model th at contains only one generalized Gaussian component. In our experiment, we apply the whole Brodatz image database (1,856 images in 116 classes) instead of using the portion of it (640 images in 40 classes) as done in [7]. TABLE 4.6 lists the comparison result. The new method achieves a higher retrieval rate than the PW T and Gabor methods, with equal or fewer features in the feature vector. When compared with the GGD model based Kullback approach, the new method has more features but also a much higher retrieval rate. It proves th at GMM is more accurate for the marginal distribution of wavelet coefficients than GGD. GMM & Kullback 2 scales 3 scales 71.87% 75.50% 24 36 GGD & Kullback 2 scales 3 scales 49.82% 56.26% 12 18 PW T 68.70% 24 Gabor 74.37% 48

Retrieval Rate Feature Number

Table 4.6: GMM & Kullback Compared with Other Traditional Methods.

41

i

D

0

n

D

F i g u r e 4 .2 : Initial R etrieval o f A Q uery from C lass D 87.

E

E

E

E

E

E

E

E

E

E

E

E

E

E

E

G

D

D

D

F i g u r e 4 .3 : Second R ound R etrieval o f th e Sam e Q uery from C lass D 87.

42

E

E

E

E

D

E

E

E

E

E

0
F igure

D

C

D

D

4 .4 : Initial Retrieval of A Query from Class

D98.

Q u"r^ liiRK E E E E E

d981

E

E

E

E

E

E

B

E

E

i

D

D

D

C

D

Figure 4.5: Second Round Retrieval of the Same Query from Class D98.

43

B

E

E

B

E

E

E

E

r

P

F ig u re 4.6: Initial R etrieval of A Query from C lass D ill.

Q u e E E E E E

d11

B

E

E

E

E

E

E

E

E

E

0

D

D

n

E

F igure 4.7: Second Round Retrieval of the Same Query from Class D i l l .

44

I"":"!'

E

c

n

n

r,

E

D

C

C

D

F ig u r e 4 .8 : Initial Retrieval of A Query from Class D114.

Juery Imaje:;
Idi,41 ffii

E

E

E

E

E

E

E

E

E

E

E

D

C

D

D

Figure 4.9: Second Round Retrieval of the Same Query from Class D114.

45

i

E

E

E

E

E

E

E

E

n

r

r

D

D

G

E

E

F i g u r e 4 .1 0 : In itial R etrieval o f A Q uery Im age U sin g E uclid ean D istan ce.

u e i E E E E E
d12

E

E

E

E

E

E

B

C

E

E

D

D

E

E

E

F i g u r e 4 .1 1 : In itial R etrieval o f Sam e Q uery Im age U sin g S eparate K ullback D istan ce.

4.5

Sum m ary

46

In this chapter, a new CBIR system is presented for image retrieval based on GMM or GGMM extracted image features and a Kullback divergence similarity measure. The obtained image features are effective in capturing image characteristics. Besides, the Kullback divergence is an appropriate and efficient way to measure the similarity of features extracted by statis tical models such as the GMM and GGMM. Simulation results indicate that the Kullback divergence based similarity measure achieves a higher image retrieval rate, while keeping the same level of computational complexity as those Minkowski distance based similarity measures. It is shown th at the new CBIR system with the combination of GMM or GGMM extracted image features and the Kullback divergence similarity measure outperforms many other image retrieval methods.

Chapter 5 Statistical Model Based Fragile Watermarking
The statistical modelling of GMM and GGMM describes image statistical characteristics through the model param eters, which can be utilized for image watermarking purposes. In this chapter, a novel fragile watermarking method based on the statistical modelling is developed. First, a prelim inary watermarking scheme is presented to embed authentication inform ation into th e statistical model. The embedding is analyzed to achieve the least

distortion on the host image. Then a multiscale fragile watermarking scheme is presented to embed authentication messages such as personal signatures or logos into the host image. Sim ulation results are given to dem onstrate the effectiveness and advantages of the new m ethod.

5.1

E m b e d d in g In fo rm a tio n in to th e S ta tis tic a l M o d e l

As known, the 2-D wavelet transform decomposes an image into three wavelet subspaces (horizontal, vertical and diagonal) at each scale. If the Gaussian m ixture model and the EM algorithm are applied to these three subspaces, three different sets of model param eters will be obtained. We can modify the large coefficients of a single wavelet subspace so th a t its large variance param eter will have the same value as th a t of another wavelet subspace

[27]. This specially formed relationship serves as the basis of the proposed fragile w aterm ark ing m ethod. Any image operations or malicious attacks will inevitably change the wavelet
47

48 coefficients, therefore they wUl break this relationship and be detected. The modification of
only large coefficients brings two ad\'antages. First, The large coefficients usually represent image edges in the space domain whidi, wffien modified, are generally difficult to be detected by human vision. Second, large coefficients are not so many in a wavelet subspace therefore the changes made on them will not introduce much image distortion. To make the large \w iance parameter a f the same value as O; , each large coefficient Wi will be modified by a certain amount Am, . The modification is guided by the following principle:

+ A'lCj)^ --w"^] = K (^aI -- , (5.1) Î=1 where P is the number of modified coefficients and K is the total number of coefficients in the wavelet subspace. Theory behind the principle is th at the variance difference contributed by the coefficients modification should be equal to the overall parameter difference. Since the modification of large coefficients are independent from one another, there seems to be numerous solutions satisfying (5.1). Therefore, it is worth of analysis th at among all possible solutions, which one can lead to a minimum image distortion, which is a basic requirement of all watermarking systems. We are able to analyze this problem and get an optimal solution by Theorem 1. T h e o re m 1 ; Assume af and a f are the large variance parameters of two wavelet subspaces; Assume Wi,i = 1,  , P represent the P coefficients with the largest absolute values in the wavelet subspace of af, and the total number of coefficients in that wavelet subspace is K ; I f each large coefficient Wi is to be modified by a respective amount Aw i in order to make a f and equal, i.e., (5.1) is satisfied, then the optimal way of modification with least

image distortion is to minimize the following mean square error (MSE):
p
J ( A w i \ i = 1, · · · , P ) =
1=1

Awj^,

(5.2)

which leads to the conclusion that each coefficient W{ must be modified with a constant pro

portional rate a , that is:

49

Awi - awi.
P r o o f : Let the image distortion defined as the MSE after modification: (Awi|z = 1, · · · , P ) =
i=l

( 5 .3 )

J

A w j^\

(5.4)

Let th e m odification principle (5.1) be a constraint condition:
p = 1, . . . , P) = ^ [(u»i +
t= i

D

{A w i\i

A w i f

-

w /] -

K

-

a f \

=

0,

(5.5)

under which we seek a way to minimize the image distortion. Using the Lagrangian approach, we construct a Lagrangian relaxation function as follows: /
= {A w i\i = ! ,  , P ) ) + X D

J {A w i\i

= 1, · - · , P
+

(Awj|i = 1, · · ·
-- \ K

,P )

p
=

^
i-\

[(1 + A) A w i ^

2 \W iA w i\

.

(5.6)

A m inim ization of the Lagrangian relaxation: argm in | / {A w i\i = 1, · · · , P ) jd J ' {A w i\i

= 1, ·  , F) d (Awi)

=

0

=> Aw i = ---- ^ = aWi

(5.7)

tells us: when all large coefficients wi are modified with a constant proportional rate a, it achieves th e least image distortion in terms of MSE. S u b stituting the conclusion of (5.7) into (5.1), we obtain an updated modification prin ciple: { [wi(1 + a )Y -- W i} = K (ai -- af ^ ,
i=l

(5.8)

50 which can be further evolved into a quadratic equation regarding the proportional rate a:

+ Therefore, a value can be easily calculated.

a + K ( y f - a f j = 0.

(5.9)

It is noticed th at the two large variance parameters a f and a f are obtained through the EM algorithm, while in the modification principle, the gap between them are compensated using a simple statistical approach other than the EM algorithm. In fact, after the modifi cation guided by (5.8), there is still a small discrepancy between the updated param eter of a f and the target parameter a f . Therefore an iterative approach involving the modification and the EM algorithm in each single step is required to finally adjust the large variance parameter a f to the target value a f , as demonstrated in Figure 5.1.

51
Start

Obtain the large variance p aram eters a f , e rf of wavelet su bspace 1 and 2, respectively.

Calculate CC according to the modification principle in (12).

Update the large coefficients in wavelet su bspace 1 by :
w ,.

-Wi(l+a)

r Recalculât e the large variance par am eter erf of wavelet subs pace 1 using EM ale orithm

F igu re 5.1: An Iterative Approach for Coe&cient Modification.

52

5.2

M u ltisca le E m b ed d in g o f A u th e n tic a tio n M essa g es

We consider the following three aspects very attractive for a fragile watermarking system: 1) Can embed some anthentication messages into the host image. 2) Can localize the image tampering if there is any. 3) Can distinguish some normal image operations from malicious attacks. Integrated with some coding techniques and implemented at multiple wavelet scales, our proposed method is able to achieve the above objectives. Figure 5.2 has an overview of the watermark embedding process. Authentication message are initially translated into some binary bit streams. Then the wavelet subspaces at multiple scales are divided into a number of wavelet blocks depending on how many message bits being embedded and how many wavelet scales these bits will spread into. The binary bit streams are finally embedded into the wavelet blocks on a private key basis by forming some special relationships specified by the code map. Authentication Messages

Code Map

Key Embedded Watermarks

Message Coding

Binary Bit Streams

Multiscale Embedding

Wavelet Block Division

Wavelet Blocks

F ig u r e 5 .2 : M ultiscale Em bedding o f A uthentication M essages.

To embed a binary bit stream into the wavelet subspace instead of a single bit, we must not use the entire wavelet subspace but divide it into many wavelet blocks [28]. Every three wavelet blocks obtained at the same position from the wavelet subspaces (Horizontal, Vertical, Diagonal) can form a special relationship to encode two message bits. An example is shown in TABLE 5.1. The parameters represent the variances of the large coefficients of the three

Formed Relationship n-2 _ ^i.v = crf.D = (^l,D ^LV -- -- ^LD

53
Coded Bits 00 01 10 11

T a b le 5 .1 : C ode M ap for M essage B its E m bedding.

wavelet blocks obtained from horizontal subspace, vertical subspace and diagonal subspace respectively. Various param eter equity relationships among affj, a f y and a f ^ can be formed in th e way shown in TABLE 5.1 to encode different two bits into these three wavelet blocks. Since there are groups of such wavelet blocks, at most 27V^ bits at a single wavelet scale

can be embedded. Any unauthorized changes made in a specific area of the watermarked image will destroy th e corresponding relationship and message bits, therefore the tam pering can be detected and localized. T he new m ethod can be used to embed message bits into multiple wavelet scales so th a t th e w aterm ark embeddability can be further enhanced. Furthermore, it can help us to distinguish some normal image operations such as image compression from malicious attacks. Therefore we may determine the source of tam pering. As will be shown in the sim ulation results, the compression has a gradually decreased im pact on wavelet coefficients and fragile w aterm arks as the wavelet scale increases. O ther malicious attacks do not have th is characteristic. Using the proposed method, the introduced image distortion is imperceptible because of th e statistical approach to embed watermarks. Only a few image d a ta in the wavelet domain is modified, no m atter the watermarks are embedded a t high frequency or low frequency scales.

54

5.3

S im u lation R e su lts
X

Two 512

512 images are used to demonstrate the effectiveness of the presented fragile

watermarking method. One is the Lena image and the other is the peppers image. The Lena image is used to present a preliminary scheme of the fragile watermarking method, while the peppers image is applied in a more complicated scheme to embed watermarks into multiple wavelet scales. In the experiment of the Lena image, we select the vertical wavelet subspace (or the HL wavelet subspace) at the first scale to embed the authentication information. The wavelet subspace is divided into 4 x 4 equal-size blocks. We name the first block at the left upper corner as the watermark block where authentication information is embedded and the part consisting of the remaining fifteen blocks as the reference block . According to (5.1), we modify the large coefficients in the watermark block so th at its large variance parameter has the same value as th at of the reference block after modification. This specially formed relationship is used by us to authenticate an image or to detect image tampering. Figure 5.3 shows the original Lena image and the watermarked image for quality com parison in the spatial domain. The left upper corner enclosed by two marking lines is where the authentication information is embedded. As can be seen, the modifications are hardly detected by human vision. The watermarked image looks just like a perfect copy of the original image. Figure 5.4 displays the HL wavelet subspace before and after watermarking. Before

watermarking, the large variance param eter is 41.32 for the watermark block and 246.70 for the reference block. After watermarking, the parameter of the watermark block is adjusted to 246.70, the same value as th a t of the reference block. It can be observed from Figure 5.4 th at only a few coefficients in the watermark block are modified. Actually, the total number of modified coefficients is 44, which ensures an imperceptible alteration of original image contents after watermarking. In the experiment of the peppers image, our lab logo "GASPAL" is embedded as the fragile watermark. The logo is first translated into a binary bit stream. Since at least five

F i g u r e 5 .3 : T h e O riginal Lena Im age (a) and th e W aterm arked Lena Im age (b).

Figure 5.4: T h e HL W avelet Subspace o f O riginal L en a Im age (a) and th e HL W avelet Sub sp ace
o f W aterm arked L en a Im age (b ).

56 bits are required to encode the alphabet (00001 for A, 00010 for B, so on · · ·), the total

number of bits required to represent the logo is 5 x 6 = 30. According to TABLE 5.1, at least 15 blocks are needed at each wavelet subspace. To facilitate the operation, each wavelet subspace is divided into 16 blocks so that 32 message bits representing the logo are embedded. Figure 5.5 shows the wavelet subspaces with 32 message bits embedded into 16 divided wavelet blocks. Every three wavelet blocks obtained at the same position from the wavelet subspaces are used to embed two message bits. For example, the three shaded wavelet blocks embed message bits "00", which are the initial bits of the letter "C", using the relationship shown in TABLE 5.1.
Vertical Subspace 00 01 00 10 01 01 00 10 10 00 11 10 01 00 00 00 11 00 00 01 10 00 11 10 01 00 00 10 01 00 00 00 11 00 00 00 11 00 00

.00 ! 01

01 00 10

10 00 11

Horizontal Subspace

Diagonal Subspace

F ig u r e 5.5: Message Bits Embedded into the Wavelet Blocks.

Figure 5.6 displays the original peppers image and the watermarked peppers image. As can be seen, the embedding of the lab logo "CASPAL" doesn't cause any perceptible distortion in the watermarked image. The main advantage of the proposed fragile watermarking method is th a t it doesn't need to modify much image data and doesn't have much image distortion. Figure 5.7 plots

57

F ig u r e 5 .6 : T h e O riginal Peppers Im age (a) and the W aterm arked Peppers Im age (b) w ith Lab L ogo "C A S P A L " E m b ed ded.

the wavelet coefficients of the original peppers image and the watermarked peppers image, respectively. T he changes made on the wavelet coefficients can be observed by comparing the two plots. It is calculated th a t the total number of modified coefficients in the watermarked image is 680 (out of 512 x 512 image data). Compared with some conventional fragile

w aterm arking m ethods [11] [13] [14] th a t modify nearly half of the image pixels, the statistical model based approach modifies much fewer image data. Besides, the changes are only made on large coefficients th a t represent image edges in the space domain. W hen watermarks are em bedded a t image edges, they are generally more imperceptible by hum an vision, as shown in Figure 5.6. If we think of waterm arks as a kind of noise introduced in the host image, the PSN R (peak-signal-to-noise-ratio) is an appropriate indicator of how much image distortion is involved in th e waterm arking process. In our experiment, the PSNR is 52.12 db, which indicates very few image distortion involved. To test th e sensitivity of the waterm ark detection, first we perform a single pixel tam  pering experim ent by 20 times, in each of which a randomly selected pixel is modified by

58

F ig u r e 5 .7 : T he D W T of Original Peppers Im age (a) and the D W T o f Watermarked Peppers Im age (b) w ith Lab Logo "CASPAL" Em bedded.

a small amount and its impact to the embedded watermark is recorded. TABLE 5.2 shows the mean value of relative parameter differences deviated from the constructed parameter equity relationship as in TABLE 5.1, which can represent the sensitivity of the watermark detection. Number of Trials Average Parameter Difference Off Balance Corresponding Message Bits Destroyed 20 0.11% Yes

Table 5 .2 : Average Param eter Difference Caused by Single P ixel M odification.

As can be seen, no m atter how slight the tampering is, it will be detected because it destroys the formed parameter equity relationship by a noticeable amount. The location of the tampering can be determined since it only destroys the message bits at positions of the tampering.

59 TA BLE 5.3 lists th e relative param eter differences caused by the additive noise with

different variances using the new waterm ark embedding method at two scales. As can be seen, no m a tte r how slight th e tam pering is, the previously formed param eter equity relationship will be broken and the tam pering will be detected. Moreover, the param eter differences tend to become larger w ith the increase of the extent of tampering. Noise Variance 0.0002 0.0005 2.37% 6.06% 8.59% 10.27%

Scale Level

0.0001 1 1.25% 2 4.65%

0.0010 19.42% 17.49%

Table 5 .3 : P aram eter D ifference C aused by N oise.

By em bedding the fragile watermarks at multiple wavelet scales, we can distinguish some norm al image operations such as image compression from malicious attacks. TABLE 5.4 shows the im pact of the JPE G compression on the watermarked image th a t has watermarks em bedded at scales 1 to 4. The numbers in Table 5.4 represent relative param eter differences. It can be seen th a t a t the same compression level, the relative param eter difference decreases as th e wavelet scale increases. On the other hand, some malicious attacks, including additive G aussian w hite noise and deliberate slight change of image contents, are simulated. The sim ulation results are shown in TABLE 5.5. The param eter changes due to these malicious attack s do not have the same characteristic as the image compression. Therefore we may use this feature to distinguish image compression from these malicious attacks. Compression Ratio 25% 38% 60% 1.47% 2.36% 2.86% 0.84% 1.27% 1.76% 0.21% 0.31% 1.18% 0.09%" 0.23% 0.54% 15% 4.63% 2.75% 1.99% 0.81%

Scale Level

1 2 3 4

T a b le 5 . 4 : Param eter Différence Caused by Compression,

60

Scale Level

1 2 3 4

Malicious Attacks Gaussian White Noise Content Change 1.65% 3.06% 0.34% 7.27% 0.93% 6.13% 1.13% 14.75%

T a b le 5 .5 : Param eter Difference Caused by Som e M alicious A ttacks.

5.4

S u m m ary

In this chapter, a new fragile watermarking method is developed. The new method uti lizes statistical model parameters to embed watermarks for image authentication. The new method modifies only a very small amount of image data and has a virtually imperceptible alteration of the original image. Integrated with some coding techniques, the new method can easily embed authentication messages such as personal signatures or logos into the host image. Any unauthorized changes th at remove the embedded watermarks will be detected and localized. Embedding of watermarks at multiple wavelet scales is able to enhance the robustness of tampering detection. On the other hand, it can help distinguish some normal image operations, such as compression, from those deliberate or malicious attacks.

Chapter 6 Conclusions and Future Work
M any image applications are based on the image characteristics obtained from image mod elling. Since th e wavelet transform has a mulresolution image decomposition th a t is quite com pliant w ith hum an vision characteristics, an efficient image interpretation through image modelling in th e wavelet domain is preferred and sought in our research. In this thesis, we notice th e wavelet coefficients have a peaky, heavy tailed marginal distribution and hence de velop a statistical modelling m ethod based on GMM and GGMM. The statistical modelling is able to depict wavelet coefficients flexibly and accurately through a variety of Gaussian com ponents being employed. As for statistical model parameters, they are usually estim ated by using an EM algorithm approach. In this thesis, we specifically develop some new EM algorithm s for GMM and GGMM to help estim ate their model param eters. Based on th e statistical modelling and the obtained model param eters, a new image retrieval system and a novel fragile watermarking method are developed. T he image retrieval system employs a new feature extraction m ethod based on the s ta  tistical modelling and a new similarity measure based on the Kullback divergence. It is observed th a t th e extracted image features are able to represent image texture contents ef fectively and th e new similarity measure outperforms traditional measures using Mikowski distances. We notice th a t the traditional Minkowski distances are not very effective for the com parison of features extracted from statistical modelling. Therefore we transform the problem of m easuring the similarity of two feature vectors to the problem of m easuring the

61

62 similarity of two distinct model distributions, where the Kullback divergence can be applied.

Simulation results indicate th at the Kullback divergence based similarity measure achieves a higher image retrieval rate than the Minkowski distance based similarity measures. Besides, since we develop a separate Kullback approach for distance computation, the computational complexity is retained at the same level as that of the Minkowski distances. The new image retrieval system is also compared with some other traditional methods and it can be observed from the experiments th at the new system achieves a better retrieval performance. In the fragile watermarking, the major concern in our research is how to have an effi cient embedding of watermarks to authenticate an image. Most conventional methods are able to satisfy the basic authentication requirement of detecting and localizing unauthorized image tampering. However, they seldom address the `efficient' embedding problem. The efficient embedding can be interpreted as modifying as fewer image data as possible to em bed the watermarks imperceptibly into the host image. In our research, we develop a novel fragile watermarking method by utilizing the statistical model parameters. We manage to set up some special relationships among the model parameters to authenticate an image. One attractive advantage of the novel method is th at it can embed practical authentication messages such as personal signatures or logos into the host image. At the same time, the embedded messages are able to detect and localize any image tampering. The new method has an efficient embedding of watermarks. Since the watermarking process uses a statisti cal approach and modifies only large coefficients, the image data modified for watermark embedding is far less than most traditional methods. Besides, the modification made on large coefficients are virtually imperceptible because large coefficients usually represent im age texture edges th at when modified, are generally unnoticed by human vision. In our research, we also successfully develop a semi-fragile watermarking approach by embedding the watermarks at multiple wavelet scales. The interest for a semi-fragile watermark lies in the application where people wish the watermarks are not so `fragile' to certain image operations such as compression, while keeping fragile to malicious attacks. The semi-fragile application is quite practical nowadays, considering people frequently wish to distribute and

transmit the watermarked images over the Internet where the images are often stored in an com pressed format.

In th e future, we are interested in furthering our studies in the following areas: 1. In th e statistical modelling of wavelet coefficients using GGMM, the exponent /? has a pre-determ ined or fixed value for all mixed Gaussian components. On the other hand, if we take /? as another unknown variable for each Gaussian component, th a t will lead to a fully flexible GGMM. Therefore, in the two state representation of GGMM, the G aussian com ponent with a small variance will have a relatively large (3 value, while th e G aussian component with a large variance will have a relatively small /? value. The problem now is how to develop an EM algorithm to obtain the model param eters. The EM algorithm involving the estimation of j3 is extremely complicated, which remains to be studied in our future research. We hope th at the new GGMM with flexible

G aussian exponents has a more accurate description of wavelet coefficients. W hen applied to image retrieval, it can further improve the retrieval performance. 2. T he robust w aterm arks can survive any malicious attacks but have no way to tell where and how th e image is attacked. On the contrary, the fragile watermarks are not resistant to image tam pering but can detect and localize it if there's any. There is some applications where the two types of watermarks can be integrated together as a hybrid w aterm ark into a host image. The attacking information provided by

th e fragile w aterm arks can help the robust watermarks have a better encoding and decoding strategy. Besides, the two watermarks can share some im portant information such as a secret key with each other so th a t the whole waterm arking scheme is more secure and reliable; 3. T h e JP E G 2000 compression standard may become a m ajor image compression tool, especially for those images distributed on the Internet. Prom an application point of view, there is a need to further develop our fragile waterm arking scheme to make it

64 compliant with JPE G 2000 compression, which means, the embedded watermarks are

able to resist the JPE G 2000 compression but keep fragile to other image operations and tampering at the same time. The fact th at the JPEG 2000 compression standard and our fragile watermarking scheme both work in the wavelet domain will facihtate our work to achieve this objective based on the same statistical modelling.

A ppendix A The Newton-Raphson M ethod
T he N ew ton-Raphson m ethod is a widely used root-finding algorithm which uses the first few term s of the Taylor series of a function to numerically search for its solutions. The Taylor series of f { x ) about th e point a; = Æ q + e is given by:

f{xQ + e) = f{xo) -I- / (xo)e -f - / (xo)e^ + - - - Keeping term s only to first order,

(A .l)

f{xo + e) % f{xo) 4- f'(xo)e. This expression can be used to estim ate the amount of offset e needed root startin g from an initial guess gives:
xq.

(A.2) to land closer to the

Setting / { xq -I- e) -- 0 and

solving (A.2) for e = eo

which is th e first-order adjustm ent to the root's position. By letting Xi = xo + co, calculating a new ci, and so on, th e process can be repeated until it converges to a root using:

65

66 Unfortunately, this procedure can be unstable near a horizontal asymptote or a local ex

tremum. However, with a good initial choice of the root's position, the algorithm can by applied iteratively to obtain:

%n+]

=

X n --

(A.5)

for n = 1,2,3,

. An initial point

xq

that provides safe convergence of Newton's method is

called an approximate zero.

B ibliogr aphy
[1] M. Flickner, H. Sawhney, W. Niblack, and et al, "Query by image and video content: th e QBIC system ," IEE E Computer, vol. 3, no. 9, pp. 23-32, 1995. [2] J. Bach, C. Puller, A. G upta, and at al., "The virage image search engine: An open fram ework for image m anagement," Proc. SP IE Storage and Retrieval fo r Image and Video Databases, vol. 2670, pp. 76-87, 1996. [3] J. R. Sm ith and S. Chang, "Visualseek: a fully autom ated content-based image query system ," A C M Multimedia, pp. 87-98, 1996. [4] A. Pentland, R. W. Picard, and S. Sclaroff, "Photobook; content-based m anipulation of image databases," International Journal of Computer Vision, vol. 18, no. 3, pp. 233-254, June 1996. [5] B. S. M anjunath and W. Y. Ma, "Texture features for browsing and retrieval of image d a ta ," IE E E Trans, on PAML, vol. 18, no. 8, pp. 837-842, Aug. 1996. [6] T. Chang and C.-C. J. Kuo, "Texture analysis and classification with tree-structured wavelet transform ," IEE E Trans, on Image Processing, vol. 2, pp. 429-441, Oct. 1993. [7] M. N. Do and M. Vetterli, "Wavelet-based texture retrieval using generalized Gaussian density and Kullback-Leibler distance," IE E E Trans, on Image Processing, vol. 11, no. 2, pp. 146-158, Feb. 2002. [8] Y. Rui, T. S. Huang, and S. F. Chang, "Image retrieval: past, present, and future," Journal o f Visual Communication and Image Representation, vol. 10, pp. 1-- 23, 1999.
67

68 [9] R. Picard and T. P. Minka, "Vision texture for annotation," Journal o f Multimedia

Systems, vol. 3, no. 1, pp. 3-14, 1995. [10] S. Sclaroff, L. Taycher, and M. L. Cascia, "Imagerover: A content-based image browser for the world wide web," IEEE Workshop on Content-based Access o f Image and Video Libraries, pp. 2-9, June 1997. [11] S. Walton, "Information authentication for a slippery new age," Dr. Dobbs Journal, vol. 20, no. 4, pp. 18-26, Apr. 1995. [12] P. W. Wong, "A watermark for image integrity and ownership verification," Proc. IS& T PIC Conf, pp. 374-379, May 1998. [13] P. W. Wong, "A public key watermark for image verification and authentication," Proc. IEEE Int. Conf. on Image Processing, vol. 1, pp. 445-449, Oct. 1998. [14] A. Paquet and R. Ward, "Wavelet-based digital watermarking for image authentica tion," Proc. IEE E Canadian Conf. on Electrical and Computer Engineering, vol. 2, pp. 879-884, May 2002. [15] J. Fridrich, "A hybrid watermark for tamper detection in digital images," Proc. Int. Symposium on Signal Processing and its Applications, pp. 301-304, Aug. 1999. [16] J. Bilmes, "A gentle tutorial on the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models," 1997. [17] A. P. Dempster, N. M. Laird, and D. B. Rubin, "Maximum likelihood from incomplete data via the EM algorithm," Journal of the Royal Statistical Society Series B, vol. 39, no. 1, pp. 1-38, Nov. 1977. [18] R. A. Rednet and H. F. Walker, "Mixture densities, maximum likelihood and the EM algorithm," SIAM Review, vol. 26, no. 2, pp. 195-239, Apr. 1984.

69 [19] M. Jo rd an and R. Jacobs, "Hierarchical mixtures of experts and the EM algorithm ,"

Neural Computation, vol. 6, no. 2, pp. 181-214, Mar. 1994. [20] S. Kullback and R. A. Leibler, "On information and suciency," Annals o f Math. Statis tics, vol. 22, pp. 79-86, 1951. [21] T . Cover and J. Thom as, Elements o f Information Theory, Wiley Series in Telecom m unications. John Wiley & Sons, 1991. [22] J. Romberg, H. Choi, and R. Baraniuk, "Bayesian tree-structured image modeling using wavelet-domain hidden Markov models," IEE E Trans, on Image Processing, vol. 10, no. 7, pp. 1056-1068, July 2001. [23] H. Yuan, X.-P. Zhang, and L. G nan, "A statistical approach for image feature extrac tion in the wavelet domain," Proc. IE E E Canadian Conf. on Electrical and Computer Engineering, vol. 2, pp. 1159-1162, May 2003. [24] H. Yuan, X.-P. Zhang, and L. Guan, "Content-based image retrieval using a Gaussian m ixture model in the wavelet domain," Proc. SP IE Visual Communications and Image Processing, vol. 5150, pp. 422-429, June 2003. [25] H. Yuan and X. P. Zhang, "Texture image retrieval based on a Gaussian m ixture

model and sim ilarity measure using a Kullback divergence," Proc. IE E E Int. Conf. on M ultimedia & Expo, June 2004. [26] Q. Cheng and T. S. Huang, "Robust optimum detection of transform dom ain m ulti plicative w aterm arks," IE E E Trans, on Signal Processing, vol. 51, no. 4, pp. 906-- 924, Apr. 2003. [27] H. Yuan and X. P. Zhang, "Fragile waterm ark based on the Gaussian m ixture model in th e wavelet dom ain for image authentication," Processing, vol. 1, pp. 505-508, Sept. 2003. Proc. IE E E Int. Conf. on Image

[28] H. Yuan and X. P. Zhang,

70 "A multiscale fragile watermark based on the Gaussian

mixture model in the wavelet domain," Proc. IEEE Int. Conf. on Acoustics, Speech,
and Signal Processing, May 2004.

V IT A

NAME: PLA C E O F BIRTH: Y E A R O F BIRTH: PO ST-SECO N D A RY EDUCATION AND DEG REES:

Hua Yuan Shanghai, China 1974 Fudan University Shanghai, China 1992-1997, B.Sc The People's Scholarships 1994-1996 Software Engineer Alcatel Shanghai Bell Corporation 1997-2001

HONORS AND AWARDS:

RELATED W O R K EXPERIEN CE:

PUBLICA TIO N S 1. H. Yuan, X.-P. Zhang and L. Guan, "A statistical approach for image feature extraction in th e wavelet dom ain," Proc. IE E E Canadian Conf. on Electrical and Computer Engineering (CCECE), vol. 2, pp. 1159-1162, May 2003. 2. H. Yuan, X.-P. Zhang and L. Guan, "Content-based image retrieval using a Gaussian m ixture model in the wavelet domain," Proc. SP IE Visual Communications and Image Processing (V C IP ), vol. 5150, pp. 422-429, June 2003. 3. H. Y uan and X.-P. Zhang, "Fragile watermark based on the Gaussian mixture model in th e wavelet dom ain for image authentication," Proc. IE E E Int. Conf. on Image Processing (IC IP), vol. 1, pp. 505-508, Sep. 2003. 4. H. Y uan and X.-P. Zhang, "A multiscale fragile waterm ark based on the Gaussian m ixture model in the wavelet domain," Proc. IE E E Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), Montreal, Canada, May 17-21, 2004, 5. H. Y uan and X.-P. Zhang, "Texture image retrieval based on a Gaussian m ixture m odel and sim ilarity measure using a Kullback divergence," Proc. IE E E Int. Conf. on M ultimedia & Expo (ICME), Taipei, Taiwan, June 27-30, 2004.

71

