Indices of force
by Michael Lantôt Bachelor of Architectural Studies (Honours), University of Waterloo, 2005

A design thesis project presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Architecture in the Program of Architecture

Toronto, Canada, 2011 © Michael Lanctôt 2011

Author's Declaration

I hereby declare that I am the sole author of this work. I authorize Ryerson University to lend this thesis project to other individuals or institutions for the puprpose of scholarly research.

__________________________________ Michael Lanctôt I further authorize Ryerson University to reproduce this thesis project by photocopying or by other means, in total or in part, at the request of other individuals or institutions for the purpose of scholarly research.

__________________________________ Michael Lanctôt

Indices of force
Master of Architecture Degree, 2011 Michael Lantôt Master of Architecture Ryerson University, Toronto

Abstract
This thesis investigates the morphogenetic capacities of material systems far from equilibrium and attempts to draw from them a set of architectural principles. The approach taken toward materiality here is not based on structural performance or sensual quality; rather, it looks to processes by which systems of matter and energy spontaneously develop local order, persisting by continuously adapting their configurations in response to shifting forces. From an introductory discussion of the formation of a familiar but surprisingly complex architectural material, granite, a number of simpler systems will be described in order to elucidate individual mechanisms. A design project integrating several aspects of material systems thinking is then developed, in this case, a proposal for a dairy farm as an element within an extended infrastructural/agricultural framework. The project develops form and program synergistically, creating a system of linked material and energy flows coupling the production of food and fuel.

v

vi

Table of contents
Author's Declaration Table of contents List of figures Motivation: Campo de Dalías Introduction: Material systems Granite: Material signifiers and material signs Reaction-diffusion systems and emergent differentiation Slime Molds: Encapsulation of dynamic systems Path optimization with self-organizing thread networks iii vii ix xv 1 7 15 19 27

Abstractv

Ferrofluid31 Form-Finding37 Fabric simulation Magnetic lattices The dairy farm: an intermediate-scale morpho-ecological module  Cellular subdivision using force-directed graphs Appendix 1: Anaerobic digestion and distributed generation Appendix 2: Algaculture List of figures 45 55 61 71 75 81 90 Morpho-ecologies51

References88

vii

viii

List of figures
Figure Group 0.1: Satellite images of the Campo de Dalias in 1974, 1987, and 2000 Figure 0.2: A Typical street in the Campo Figure 1.1: The peridoic table, representing electrochemical properties Figure 1.2: The nuclide chart, representing nuclear stability Figure group 1.3: Lotka-Volterra model of a simple predator-prey relationship Figure 2.1: Johnson-Burgee's AT&T building Figure 2.2: Granite ascent mechanisms Figure Group 2.3: Granite specimens Figure 2.4: Remarkable Rocks, Kangaroo Island, Australia Figure Group 3.1: Simulated reaction-diffusion patterns Figure 3.2: The Belousov-Zhabotinsky reaction pathway Figure 3.3: An active BZ reaction Figure 3.4: Andrew Witkin's instrumentalization of RD systems Figure 4.1: Discoideum dictyostelium Figure Group 4.2: Physarum polycephalum Figure Group 4.3: Physarum locomotion speed relative to periodic environmetal stimulus Figure 4.4: A large wild physarum plasmodium Figure Group 5.1: String binding simulation study Figure Group 5.2: Wet thread physicals models Figure Group 5.3: String binding with extrinsic repulsion Figure Group 5.4: Appearance of emergent nodes Figure 6.1: Ferrofluid in a simple magnetic field Figure Group 6.2: Ferrofluid in complex fields Figure Group 6.3: Complex geometry and simple control points Figure 6.4: Detail Figure 6.5 Detail Figure 7.1: Form-finding model for Munich Olympic Stadium Figure Group 7.2: Mannheim Multihalle Figure Group 7.3: Catenary models Figure Group 7.4: Formation of the Downland Gridshell Figure 8.1: Shell studies using fabric simulation Figure 8.2: Complex manifold modelled with simulated fabric Figure Group 8.3: Gridshell design tool study Figure Group 9.1: Responsive surface structures: pinecones and veneer component Figure 9.2: Veneer components assembled into a self-supporting shell Figure Group 10.1: A modular formal system using spherical magnets Figure Group 10.2: Magnetic lattice study 1 Figure Group 10.3: Magnetic lattice study 2 Figure Group 10.4: Magnetic lattice study 3 Figure 11.1: Crozier Dairies, Namao Alberta, satellite photo Figure 11.2: Schematic analysis of bioenergy productive capacities of a 500 cow dairy. xii xiv 2 2 4 6 8 10 10 14 16 17 17 18 20 22 24 26 27 28 29 30 32 33 34 35 36 38 40 42 44 46 48 51 52 54 56 57 58 60 62

ix

Figure Group 11.3: Generative adjacency schemes using spring-particle networks Figure 11.4 Schematic dairy farm plan derived from generated adjacency scheme Figure 11.5 Schematic dairy farm 3D view Figure 11.6 Schematic dairy farm 3D view

64 66 67 68

Figure Group 12.1: Cellular spatial subdivsion using force-directed graphing and the Voronoi 70diagram Figure Group 12.2: Cellular spatial subdivsion using force-directed graphing and the Voronoi 72diagram

x

xi

xii

xiii

Figure group 0.1: Satellite images of the Campo de Dalia in 1974, 1987, and 2000

In the horticultural nursery cum stock market, the actual growth of a tomato signals growth in profits. Trade bargains, the differentials of labor costs, and the lust for enhanced and stylized vegetables can transform this fruit into a semi-precious nugget and an object of international piracy... A comedy of intense control and endless research accompanies the quest for the perfect tomato. Multinational seed companies are headquartered in the El EjidoAlmeria area, on the highway with the plastics factories and other essential ingredients of a greenhouse agripole. These companies continually merge and change names, only occasionally revealing their affiliation with larger biotech or drug companies. They act as private versions of a state or university extension agency, often developing laboratories in areas of greenhouse concentration around the world. In their installations one can see, in miniature, the factors of global competition. Keller Easterling, Enduring Innocence: Global Architecture and its Political Masquerades, p. 43

xiv

Motivation: Campo de Dalías
In southern Spain, an extraordinarily intense agglomeration of greenhouses has sprung up over the past thirty years. While satellite photographs of the Campo de Dalias in 1974 show an unremarkable agricultural landscape, more recent images reveal an almost continuous mat of polyethylenesheet greenhouses extending from the edge of the sea to the Sierra de Gador mountains, up to fifteen kilometers away, enclosing an estimated twenty-six thousand hectares (260 km2). Produce grown here is transported across Europe year round, accounting for roughly two billion euros in annual economic activity. Within these greenhouses, vegetables are grown in soilless hydroponic media with optimized nutrient solutions, virtually eliminating the vicissitudes of traditional farming; such a method of production is an evolved form of intensive agriculture, building on a long tradition of technological landscape alterations including terracing, irrigation, and fertilization, and more recently, mechanical cultivation, high-density feedlots, chemical pest control, and genetic modification. The pattern of development in the region superficially resembles that of many low-density urban areas, with construction initially concentrated along existing infrastructural corridors, gradually radiating outward along paths of greatest convenience. However, the simplicity of the high-tunnel greenhouses favoured in the region has permitted an extremely rapid deployment, one which has proceeded largely through the agency of the farming families who own the land rather than a central planning commission. Satellite photographs document this process over its entire brief history, providing a rough time-lapse view of a process which, in an earlier era, might have taken centuries to unfold, presenting novel insights into the mechanisms by which human settlements structure themselves. The motivation behind this development has been predominantly entrepreneurial, with the result that the Campo has, like most large modern agricultural operations, been dominated by monocultural approaches seeking to maximize short-term profitability. Despite the limited focus of the region's producers, the sheer scale of activity has prompted the growth of a number of subsidiary industries including plastics production and recycling, desalination, construction, and waste disposal, all operating alongside the resorts, beaches, and golf courses of a Mediterranean tourist destination. In this thesis project, it is presumed that the development of such extensive/intensive landscapes is likely to become more widespread, emerging as a means of amplifying the various relative advantages of diverse locales. A critical issue in this case becomes the architectural structuring of such intensive ecosystems. From a performative standpoint, the longer-term vulnerability of monocultures is well known, as is the synergistic effect of diversity in ecosystems; a flexible high-level systems architecture is indicated as a means not only of avoiding what ecologist Garrett Hardin has termed the tragedy of the commons (a social mechanism whereby narrow self-interest among competitors sharing a common resource leads to overexploitation, to the detriment of all), but of increasing overall productivity. More

xv

Figure 0.2: A typical street in the Campo

xvi

significantly, by negotiating the coexistence of variegated practices and usages through infrastructure, it would be possible to prevent landscapes from becoming, like the Campo, mere food factories operating according to a single bottom line, but thriving hybrid ecologies. However, the planned integration of complex systems of inputs, outputs, and flows at such a grand scale poses significant design challenges, especially given the timeframes. The massively parallel computational capacity of material systems, their ability of "resolving through feedback multidimensional forces acting on the linked field" (Reiser + Umemoto) offers an attractive alternative to the traditional approach of imposing order through reductive diagrams; using one material system to model another more complex one, "[t]he critical issue then becomes how to set up those conditions in the architecture that will be minimal enough to index force yet maximal enough to enable emergent organizations to arise." (Reiser + Umemoto). The ensuing design experiments were undertaken with this in mind, focussing on the bottom-up development of simple systems directing, but not overdetermining the organization of material components, exploring ways of working loosely with complexity, with the goal of developing a set of high-level form-finding strategies for the subdivision of space, the establishment of connective networks, and the design of lightweight enclosure systems.

xvii

What kind of philosophical concepts are needed to apprehend material variability?...The typical questions that philosophers in the past have used and the linguistics of the twentieth century rejected is that a cloud, a mountain, a plant, an animal, all have an identity that is independent of our minds because they have an essence...The opposite paradigm would be to endow matter with morphogenetic capacities of its own and say there are forms because there are processes. Manuel DeLanda, Material Evolvability and Variability, in The Architecture of Variation, p. 10

Introduction: Material systems
This thesis investigates the morphogenetic capacities of material systems and begins to develop methods of encapsulating their behaviour within a system of representation amenable to architectural manipulation. The approach taken toward materiality here looks to processes by which systems of matter and energy spontaneously develop local order, persisting by continuously adapting their configurations in response to shifting forces. From an introductory discussion of the formation of a familiar but highly complex material, granite, a number of simpler systems will be described in order to elucidate individual mechanisms. A design project integrating several aspects of material systems thinking is then developed, in this case, a proposal for a dairy farm as an element within an extended infrastructural/agricultural framework. The project develops form and program synergistically, creating a system of linked material and energy flows coupling the production of food and fuel. Since modernity, a deterministic, machinic conceptualization of the real has been yielding to a probabilistic, fluid one. Manuel De Landa traces the origin of this development to the mid-nineteenth century, with a problem arising from "deep dissimilarities between causality in the fields of physics and chemistry". The appearance of novel material properties as the result of a chemical reaction cannot be compellingly explained solely as the result of collisions between molecules. After a collision, the positions and velocities of particles are different, but the entire system remains basically the same. However, when two gases, hydrogen and oxygen react, the product, water, has properties possessed by neither reagent. The emergence of novel properties and capacities as the result of a causal interaction posed a significant philosophical challenge: if material systems operate like linear clockwork systems (as in classical mechanics), how is novelty possible in the absence of a transcendent agency? The behaviour of nonlinear systems has prompted a revaluation of the term `mechanism'. The sense of mechanism as a logical series of purposive operations has been challenged by what De Landa calls mechanisms of emergence, processes that are rationally describable, but which capture the appearance of qualitative novelty. Understanding these kinds of mechanisms is essential to the understanding of process rather than state. The concept of emergence deals with the coming into being of irreducible wholes as a function of large numbers of coordinated interactions, objects defined by their properties, capacities, and tendencies. A knife, for example, is different from a blunt piece of steel because its geometry establishes the property of sharpness. This property gives it the capacity to cut objects that have the capacity to be cut. Properties are always actual and intrinsic; they represent a state of being of an individual. They can be extensive (a pattern of spatial or temporal intervals) or intensive (having a value on a continuous scale). In the example of the knife, sharpness is an extensive property, deriving from a specifically dimensioned sectional profile, while the relative hardness of the steel can be considered intensive. Each of these properties influences the knife's capacity to cut.

1

2

Capacities, by contrast, remain potential until they are realized, and they are always relational. The actualization of a capacity produces an event- if a cuttable object and a sharp object interact, a cut is performed. Tendencies are similar in that they remain latent until actualized, and manifest as events. However, they describe modes of response to extrinsic conditions rather than abilities. The knife has the property of solidity, but only within a limited range of conditions. At high temperatures, the steel melts and the knife ceases to exist; it has been forced to manifest the tendency to liquify. An object's range of tendencies covers a limited set of states that the object will tend to be in, for example, solid, liquid or gaseous. In the case of the melted knife, the phase change irreversibly destroys its pattern; once it cools, the steel will be solid again, but not in the same form. To become a knife again, the amorphous metal will need to undergo a particular sequence of events.
Two approaches to a combination-space representation of the elements. In both, the number of protons in the atomic nucleus (atomic number) is the key organizational factor. Figure 1.1, Top: The periodic table organizes elements so that those with similar chemical properties share columns. The table's periodicity is due to the structuring of electron shells. Since isotopes (elements of the same atomic number, but differing quantities of neutrons) are chemically identical, they are not accounted for. Figure 1.2, Bottom: In the table of nuclides, each cell represents a unique combination of protons and neutrons. The color-coding indicates its rate of radioactive decay. The simplest nuclide, the free neutron, (half-life, fifteen minutes) is at bottom left. Each subsequent row represents a different element.

Processes of this type, that produce emergent concrete wholes, are what mechanisms of emergence attempt to describe. Unlike the knife, however, the wholes produced by material systems are not derived from templates; their identities are historically contingent, the products of structured process and stochasticity interacting over time. The structuring of material systems typically results as a condition of being far from stabilty. In this state, the amount of energy coursing through a system exceeds the system's ability to dissipate it. In response, material either reorganizes itself to permit a higher rate of dissipation, or disintegrates. This way of thinking about material systems has a bearing on architecture insofar as it is a material practice. In this connection, Stan Allen observes: Two claims can be made: first, that architecture's instrumentality can be be reconceived, not as a mark of modernity's demand for efficient implementation, but as the site of architecture's contact with the real. By immersing architecture in the world of things, it becomes possible to produce what Robin Evans, paraphrasing Lyotard, has referred to as "volatile, unordered, unpoliceable

3

4

communication that will always outwit the judicial dominion of language". The second claim is for a practice engaged in time and process- a practice not devoted to the production of autonomous objects, but rather to the production of directed fields in which program, event, and activity can play themselves out. Stan Allen, Infrastructural Urbanism, p. 52 The matter of these claims is investigated in this thesis, which begins with an examination of the morphogenetic capacities of self-organizing material systems in nature, discusses the instrumentalization of material processes in design and construction, and proceeds to a set of experiments using physical models and simulation. The goal of these experiments is to develop a sensibility and
State space representation of a Lotka-Volterra model depicting predator-prey relationships over time Figure 1.4, Top: This graph charts a single oscillation of population values as a function of predation. Time is represented along the x-axis, with the population of each species on the y-axis. Figure 1.5, Bottom: A phaseplane representation of the same phenomenon, but with a number of starting conditions (the upper graph is represented by the black line). The central tendency of the system (its attractor) becomes evident with the addition of more layers of data. Here, time is not explicitly represented, only the relationships between population parameters. Thus, given an initial population of 10 baboons (blue line), one could expect to see a population of either 9 or 36 cheetahs when the number of baboons is 80, depending on whether the population has been growing or shrinking.

a set of techniques facilitating the architectural schematization of spatial and structural systems which negotiate the competing demands of complex sets of forces to effect high levels of performance. An attempt is made to utilize material self-organization to arrive at formal arrangements structured according to the flows moving through them, indexing the forces they channel.

5

Figure 2.1: The AT&T building, Johnson/Burgee

AT&T insisted they wanted something other than just another glass box. We were looking for something that projected the company's image of nobility and strength. No material does that better than granite. Philip Johnson, quoted in Harvey, p 114

6

Granite: Material signifiers and material signs
The architectural use of materials as signifiers has been well developed since antiquity and remains familiar as a legacy of postmodernism. In this approach, materials historically invested with symbolic properties act, along with other formal elements, as morphemes within an architectectonic linguistic system, itself the raw material of architectural authorship. The performance of a material derives from its capacity to express an abstract attribute. In the case of the AT&T building, the `nobility and strength' conventionally associated with granite is ostensibly conferred on the corporation. The design team went to great lengths in order to establish this effect; the mass of the granite required a correspondingly massive and complicated structural system. Engineer Les Robertson reported that "No steel-frame building in the history of construction had ever supported so much granite. That much weight could cause enormous deformations in the steel structure. And if the granite were mounted in a conventional manner, the failure of just one stone could result in the progressive failure of other stones in the building." (Unger, 1982). Ethical concerns relating to resource consumption (whether genuine or affected) have prompted a widespread reevaluation of the use of materials in architecture. The performance of a building, its material economy, energy efficiency, healthfulness, comfort, utility- what it can do- is a factor beginning to weigh heavily on theoretical approaches driven by aesthetics. This is not to say that, paraphrasing Loos, architectural expressiveness and variation are inherently irresponsible, but that they may better derive from the structuring and integration of diverse performances relative to a site's unique conditions than from a desire to make architecture communicate an abstract idea, represent its historical situation, or simply be spectacular. Natural building materials such as granite are exemplary of the phenomenon of aesthetic value emerging coextensively with performative capacity. Their patterned internal structures are the result of sequences of processes unfolding indeterminately over large possibility spaces, producing a wide variety of similar-but-different instances from which the architect may select, based on criteria of both utility and beauty. An attempt to instrumentalize this method of morphogenesis is at the core of contemporary generative design, which permits the rapid visualization of different states of a system of parametric relationships between different intensive (e.g. degree of insolation) and extensive (e.g. size of an aperture) properties. Rather than first developing a formal concept and working backward from it to determine the structure it requires, this process involves a structuring of the relationships guiding a procedural development and an exploration of the ensuing implications by tuning parameters and seeing what happens. A challenge with this approach is of course the incorporation of a sensitivity to real phenomena at the scale of architecture. If the goal is to seriously engage the issue of performance, the behaviours of material and energy over time cannot be guessed at; rather, generative techniques should operate isomorphically with the material systems they seek to emulate, which organize themselves by the reactions of large numbers of agents to continuous extrinsic force-fields and to each

7

Figure 2.2. Types of magma ascent

8

other, rather than a numeric control scheme; they should attempt to encapsulate the mechanisms of emergence operant within complex systems, rather than aping their products. In this connection, the formation of granite makes an interesting case study. As an igneous rock, it is the direct product of the large-scale geotectonic forces structuring the planet, which establish a differentiated, fluctuating strain field in the crust and mantle, mobilizing and directing the ascent of large volumes of fluid magma. The eventual evolution of a magma body into granite is contingent on many events. Given a direct path to the surface, it cools quickly, forming materials such as obsidian, a hard, brittle, noncrystalline volcanic glass of such internal homogeneity that knapped flakes may develop smooth, sharp edges only a few molecules thick. Granite results when magma is trapped and cools slowly below the surface. In deep magma chambers, the intensity of chemical, thermal, and mechanical interactions keep the system far from equilibrium, slowly effecting a transformation of the raw material, which becomes more, rather than less, organized over time. The development of granite's characteristic crystalline structure is responsible not only for the figure of its grain when cooled, but for the strength and toughness which make it so well-suited for monumental architecture. Ascent mechanisms Low-inertia flow is the classic explanation for the ascent of magma (Pitcher). Because of its low density relative to even the ductile lower crust, the magma begins to rise, displacing the surrounding matrix along its path in a phenomenon known as diapirism. In the simplest model, the magma is imagined as forming a spheroid body, rising like a bubble in a lava lamp. More sophisticated low-inertia approaches consider the effects of turbulence and convection on flow, drawing from models such as Rayleigh-Taylor convection, which describes the spontaneous formation of convection cells in fluid media, and the Rayleigh-Bénard instability, which describes the complex interface formed between fluid bodies as they flow past one another. It has been estimated, though, that diapirism alone would not be able to drive magma past the ductile-brittle boundary, the depth at which the plastic, viscous lower crust transitions into the hard upper crust. Although it cannot fully explain the emplacement of all granitic intrusions, buoyancy due to density contrast is nonetheless a contributing factor, especially in the early stages of ascent. Fracture propagation describes a mechanism akin to the spreading of cracks in glass. Because of density and viscosity contrasts with wall rocks, magma flows upwards into existing cracks or weak zones; the induced strain causes them to spread, forming a self-focusing fracture network and drawing magma up further. The thermal and pressure gradients between the bottom and top of these channels establishes a stack effect, instensifying the process. Magma delivery is pulsed, producing solitary waves (magmons), which have the capacity to propagate unattenuated along the conduits and to pass through one another without interacting. Whereas with the low-inertia models, the process is driven by a contrast between the properties of the magma and the wall rocks, fracture propagation attrib-

9

Figure group 2.3. Granite specimens: speckled, graphic, and orbicular patterns frozen in place, revealing the final organization of slow-cooling magma.

Figure 2.4. Remarkable Rocks, Kangaroo Island, Australia. A large piece of caprock from the complex boundary between the granitic pluton (base) and its surrounding rock (now eroded away) remains, preserving the form of a large-scale dynamic process.

10

utes the capacity of magma to ascend solely to its own intrinsic properties. More recently, a third ascent mechanism has been proposed: deformation-induced ascent. The crust constantly experiences tremendous strain due both to self-weight and tectonic activity. The distribution of this stress is uneven, constantly shifting with the occurence of seismic events, as material redistributes itself in an attempt to equalize local differentials in the stress field. In deformationinduced ascent, active tectonic forces effectively cause the crust to pump the magma upwards through a process called strain partitioning. During deformation, the crust moves laterally with respect to a deep body of magma. Strain concentrates in the magma due to its low relative viscosity, and vorticity is induced, resulting in a forceful expulsion of material perpendicular to the path of crustal travel, along a path connecting zones of relatively high local strain. While ascent still occurs along fracture networks, the propelling impetus is markedly different; whereas in the first models magma itself is the lone agent, with deformation-induced ascent the matrix itself plays an active part. An ascending body of magma is not yet granite, nor is it even destined to become granite; depending on the conditions the plume encounters, a large number of outcomes are possible. For instance, as early crystallization occurs in the hot, young mass, materials with a high solidus (the temperature below which a material becomes fully solid) precipitate from the fluid and are left behind. This process, called igneous differentiation, transforms the composition of the magma over its course, significantly altering its properties; thus the overall melting point of magma at the top of the plume may be several hundred degrees lower than that at the base. In order to become granitic, a liquidus (the temperature above which a material becomes fully melted) of roughly 700°C is required. The question of what eventually halts the the plume's progress is essential to explaining the formation of the enormous magma chambers which eventually become granite batholiths. If buoyancy due to density and viscosity contrast is the prime mechanism driving magma through the fracture networks, this halt could be explained by the existence of a neutral density level, at which the contrast between magma and wall rock is zero. No such level has been observed to exist, however; hot magma is less dense than almost any solid rock. The likelier explanation is that the plume encounters an area of relative weakness in the crust, so that its momentum is diverted laterally and it becomes easier for it to spread out than to continue rising. When emplacement begins, the igneous material is substantially different from the primitive magma it began as. However, this transformation is mostly due to a process akin to distillation, in which an initially complex material is simplified through fractional separation. Because of the relative rapidity of pulsed magma delivery, little interaction occurs with wall rock. Once trapped in a magma chamber, though, vigourous interaction occurs. As the surrounding rock is heated by the magma, a complex boundary develops. The inner layer of this boundary slowly disintegrates due to melting and convection-driven mechanical scouring, adding new compounds to the mix and stirring them in thour-

11

oughly. Further out, the wall rock, softened but not melted, slumps and stretches, seeking equilibrium against fluid pressure and gravity. In this condition, the magma chamber is capable of retaining its energies for great lengths of time. Moreover, while it was once believed that large plutons are the product of a single continuous emplacement event, it now appears that even the largest magma chambers would not be able to remain molten nearly long enough to acheive the levels of mixing seen in nature. It seems that magmatic pulses, occuring at long intervals, can keep chambers active for extended periods. For example, the Half Dome Granodiorite in Yosemite National Park shows indications of a four-million year span between the emplacement of its western and eastern extremities, suggesting numerous influxes. Sharp contacts between such theoretical deposits had never been observed at Half Dome. However, close examination has shown evidence of cryptic contacts, subtle transitional zones created by the limited diffusion of two fluid boundaries into one another. Because of its long history, granite undergoes a complex process of formal individuation. While sources of obsidian can vary in their degree of purity, such a metric does not apply to granite, since, as an aggregate material, it is inherently inhomogeneous. Individual granitic bodies can, however, vary in the degree to which they are interesting, especially when they capture moments of high disequilibrium. These specimens are not only aesthetically interesting, they are like fossilized soft tissue, permitting a rare reading of a dynamism that is seldom preserved. Developing a fluency reading, understanding, and working with such processes is one of the principal objectives of the experiments conducted over this thesis project. Sanford Kwinter expresses the value of this approach: To follow the grain of the world and to see in this infinite twisting dance the expression of multiple, converging, formal and diagrammatic logics, are both the a priori and the mandate of design research. As materialists, we do not approach linguistics or economics to extract from them a method or to pillage their banks of metaphors; we see them as themselves material expressions of exogenous (external) and endogenous (internal) shaping forces. (Kwinter, Into the void: a new organon? in Far From Equilibrium, p. 49)

12

13

Figure group 3.1. Simulated reaction-diffusion patterns

14

Reaction-diffusion systems and emergent differentiation
In his 1951 paper, `The Chemical Basis of Morphogenesis', Alan Turing proposed a mechanism for the spontaneous formation of structure in an initially homogeneous chemical system. Specifically, it attempted to schematically formulate, in mathematical terms, the material processes by which a developing embryo becomes anatomically differentiated as it grows. Although Turing's exercise was purely theoretical, it provided a rigourous foundation for the understanding and explanation of a number of actual processes discovered later, both in inorganic chemistry and biology. In a reaction-diffusion system, chemical substances, called morphogens by Turing, diffuse through a tissue, moving from areas of high concentration to low, reacting with one another. From a stable, homeogeneous composition, oscillatory instability develops around small random irregularities, producing dynamic behaviour in which the concentrations of the morphogens become spatially inhomogeneous, producing macroscopic ordered patterns. Superficially, this type of process may seem to be at odds with a principle of thermodynamics, in which diffusion typically drives a system directly towards equilibrium, as with a melting ice cube. Reaction diffusion systems do not avoid this tendency toward sameness; eventually, the sources of morphogen production will be consumed and the depleted system will lapse irreversibly into equilibrium. The remarkable quality of these systems is that, given a sufficient supply of energy, they will maintain themselves far from equilibrium, spontaneously establishing and maintaining a surprising degree of orderliness. In its simplest form, a reaction-diffusion system comprises an actuator and a suppressor that modulate the behaviour of a third substance such as a pigment. Both compounds diffuse spatially through the medium (each at its own variable rate) from areas of higher to lower concentration. As they diffuse, they react, causing the concentration of each to vary with respect to that of the other, recalling the unstable oscillations of the predator-prey relationship. In Turing's model, the result is a stable pattern, such as dappling or whorling. Since Turing proposed his mathematical mechanism, real chemical systems exhibiting the described behaviour have been discovered, most notably the Belousov-Zhabotinsky (BZ) reaction. In a homogeneous aqueous suspension, the solution periodically changes colour as the reaction sequence proceeds and the concentrations of reagents fluctuate. In a thin film on a flat surface, the system develops large-scale geometric patterns from an initially near-homogeneous state, beginning as concentric bulls-eye or spiral waves which grow and interfere with one another. The complete pathway for this system was mapped out by Fields, Koros, and Noyes in 1972, consisting of eleven different chemical reactions coordinated by their mutual interdependencies. Not only is the physical system extraordinarily difficult to model accurately, but the invariant properties of its material components make it difficult to extend; while it is capable of producing a

15

Figure 3.2. The Belousov-Zhabotinsky reaction pathway. A complex system of reactions, some reversible, others not, capable of producing emergent spatio-temporal patternings as a function of its dynamics. This process has become an important device for studying the mechanics of far-from equilibrium systems.

16

wide variety of patterns, they tend to be of a limited type. By concentrating on the essential mechanisms operating within the system rather than its particulars, more general simulative models have been developed which are amenable to a much higher degree of experimental control. Andrew Witkin, a computer scientist whose work with Pixar Studios has led to the development of an important body of work connecting physical simulation with creative modelling, developed a method for instrumentalizing these mechanisms to produce naturalistic generative textures over complex geometries. ..by identifying processes that are widespread in nature, we can develop models that are broadly useful for texture synthesis. Already, RD models significantly extend the range of textures that can be synthesized. Their characteristic organic appearance lends an interesting new element to synthetic imagery. In addition, RD textures have the potential to extend the range of surfaces to which textures can be applied because they can be grown to compensate for parametric distortion and joined smoothly patch to patch. Witkin and Kass, Reaction-diffusion textures, p. 8

Figure 3.3. An active BelousovZhabotinsky reaction

Figure 3.4. Space Cookies (1992). Produced by Witkin, demonstrating textures synthesized using RD reaction modelling

17

j

i

h g

f e c b a

d

Figure 4.1. Discoideum at various stages of development. a) loose aggregate b) tight aggregate c) finger d) slug e-j) fruiting body Throughout this process, formerly indiscernible amoebae consolidate into a pseudoplasmodium capable of slug-like motility, eventually developing into a fruiting body. Across the developing body, the various capacities of the general amoeboid component are deployed differentially in space and time, generating a sequence of adaptive forms and behaviours without central control.

18

Slime Molds: Encapsulation of dynamic systems
In slime molds, dynamic chemical systems are implicated in the establishment of a rudimentary collective intelligence. Because of their differentiated macroscopic anatomies, slime molds were once considered to be fungi, however it is now understood that they are not true multicellular organisms, but highly developed amoebae capable of forming coordinated assemblies. Two principal types have been observed: the cellular and the acellular. Cellular slime molds spend most of their lives as free-roaming individuals, agglomerating into composite bodies in response to specific environmental triggers. An acellular slime mold is essentially a giant cell with many nuclei contained within a single membrane, the product of the fusion of many amoebae. These assemblies are not simply amorphous, haphazard blobs, but spatially differentiated structures integral to each species' survival. The crucial element to their distributed coordination is timing; complex systems of chemical oscillators, with rates and phases modulated by environmental factors such as temperature, enable the organism to execute patterned movements, develop anatomical structures, and even to anticipate periodic events. One of the most basic adaptive functions in colonial single-celled organisms of any type is the ability to sense and respond to the local population density. For example, bacteria will alter their behaviour in unison when their numbers reach a critical level, taking advantage of a new capacity afforded by the different condition. This does not occur passively in response to changes in the ambient background, but rather tends to be the result of an active emission of dedicated signaling substances into extracellular space. This decoupling of the signal medium from the environmental background affords a level of agency to the colony that it would otherwise not have, even though it lacks any kind of central nervous system. In this way, it gains the ability to alter its behaviour only at the point when it becomes effective to do so. The mechanism by which this occurs is known as quorum sensing. Slime mold cells constantly emit a number of chemical signals while sampling their local concentrations. At low ambient levels, very little of a given signal will be produced, reducing the likelihood of a cell misinterpreting its own presence as that of another. As the concentration increases, so does production, establishing a positive feedback relationship (autocatalysis) that accelerates the process of recognition. When an established threshold value is reached, the expression of a set of genes occurs, prompting new behaviour in the entire local population simultaneously. This simple mechanism underlies the emergence of more complex integrative behaviours. Chemotaxis describes the tendency of an organism to move bodily along the gradient of a specific substance toward an area of higher concentraton. In the cellular slime mold Dictyostelium discoideum, this process directs the aggregation of individual cells into a spore-producing fruiting body. At the beginning of their life cycle, individual amoebae feed on bacteria, growing and dividing. As the bacterial food source becomes depleted, starvation induces the secretion of a quorum-sensing molecule, glycoprotein conditioned medium factor (CMF). When CMF concentration reaches the threshold

19

Figure group 4.2. Physarum plasmodia showing spatial organization. Left: Connection of population centers surrounding Tokyo. At t=0, a plasmodium begins to radiate from a large central supply of oat flakes, representing Tokyo. Subsequently, an efficient protoplasmic transport network emerges as the plasmodium connects newly discovered sources. Top: A wild plasmodium showing various stages of development. At its expanding front, its morphological strategy is oriented toward maximum coverage as food sources are sought. The kinetic energy is devloped by diffusion and peristalsis; the conduits perform work as well as transporting material. Bottom: A small mature plasmodium in the early stages of sporulation.

20

level (indicating a sizable starving population), production of a second messenger substance, cyclic adenosine monophosphate (cAMP) begins, initiating the aggregation phase. While it was once believed that at this point, `shepherd' cells developed to guide the process, it has been discovered to be completely decentralized. CAMP is not simply emitted into the extracellular medium and allowed to diffuse, but follows the periodic dispersal pattern characteristic of reaction-diffusion systems. This pattern of concentration waves is much richer in information than a simple gradient, enabling the amoebae to orient themselves much more effectively. Once a sufficiently dense aggregate has formed, a new set of processes begins, in which cellular differentiation occurs. From a tight blob, the aggregate metamorphoses into an axial structure called a slug, which, like its namesake, is capable of directed locomotion along a trail of slime. The slug, about 3 millimeters long, is able to move due to the phased synchronization of oscillating chemical clocks, which direct a concerted pumping of protoplasm. It migrates toward warmth and humidity. Finding a suitable location, it begins its final transformation into a fruiting body: a vertical stalk made of dead cells tipped with a spore-filled nodule. The acellular slime mold Physarum polycephalum employs a similar set of techniques at a grander scale. While D. discoideum spends most of its life in a unicellular vegetative stage, reaching macroscopic size only to disperse its spores, P. polycephalum develops as a plasmodium, a large sac of protoplasm containing many amoebal nuclei within a single membrane. In this species, the plasmodium can grow to be well over a foot across in the presence of a rich nutrient source. In its early development, it expands from a point source by producing slow pressure waves in the protoplasm. As obstacles and differences in nutrient levels are encountered, the contour of the expanding front becomes complex, with individual streams budding and branching out in all directions. At a certain point, areal expansion slows and the plasmodium adjusts its morphology, withdrawing from poorer areas in favour of richer, connecting sites with a cross-linked network of tubular conduits. This network is both a production and distribution system; there is no anatomical differentiation within the plasmodium, only spatial patterning. Polycephalum's ability to solve complex spatial flow problems has been dramatically demonstrated in recent experiments. A research team at the University of Hokkaido created a model of the greater Tokyo area using piles of oat flakes to represent population centers (Nakagaki et al). The plasmodium initially spread out in tightly spaced streams as it explored the territory, densifying around the food sources as it discovered them. Over time, the generic system of branches was adaptively refined as high-performing conduits became dominant and migrated into new positions. Eventually a small number of routes stabilized, with local optimization (directness of routes between nodes) often sacrificed for superior system-wide gain. The intent of this experiment was to compare the network formed by the plasmodium to that of the regional rail system. While no two runs produced exactly the same pattern, definite isomorphisms between the engineered system and the slime mold network

21

PRL 100, 018101 (2008)
a
(%) (°C) 100 26 80 60 24 22 0.4 0.2 0 0.4 0

PHYSICAL REVIEW LETTE
C1 C2 C3 C4 C5 S4 C6 C7

TM HU

S1

S2

S3

a
Speed (mm/10min)

0.4

S

0.2

Speed (mm/10min)

b

0 60 40 20 0 0

b
Occurrence of slowdown (%)

9

Speed (mm/10min)

c

60T120 180 S I C A L R E V I E W L0E T ER S

-0.4

week 240 300 360 420 480 540 600 660 ending 720
Time (min)

11 JANUARY 2008

60 12

a 1. rigger stimula- FIG. 1.00 SPS and SPSD responses. Typical time course of loco480 min), 40% motion for an organism (wet weight  15 mg) before and 1.0 after FIG. 2. Statistica in). At all time three periodic applications (S1, S2, and S3) and single applicaterms of mean s 4) of dry stimulation. (a) Temperature is denoted by the occurrence of spo that the time tion (S0.99 calculated from 43 ase of the pre- upper line (TM) and humidity by the lower line (HU). (b) Locoand from 39 samp as observed at motion speed calculated over successive 10 min intervals. ( speed) defined as the difference in speed periodic stimulatio The SPSD re- (c) Acceleration 0.98 between successive intervals in (b). S1, S2, S3, and S4 indicate times of the real . the time points of the real stimulations, whereas C1, C2, . . ., C7 the times of the m model that indicate the time points of the virtual stimulations. The 0 SPS induced at C1 by ure 4 shows a response was induced at time point C1, C2, and C3 by periodic C6 by trigger stim 0.97 n of the behav- stimulation (closed arrows), andTime at time point C6 and C7 by arrow). The organ servations. We trigger stimulation at S4, after disappearing once (open arrows). of a series of examined throu b1 b3 b2 ocomotion, as Figure 2 shows the results of statistical analyses of the speed [Fig. 2( activities in a SPS, indicating the average speed [Fig. 2(a)] and statistical [Fig. 2(b)]. The  ll movements occurrence of slowdowns [open arrow in F [Fig. 2(b)], calculated over 43 reower spectrum peats. The locomotion speed dropped significantly at the varied from 420 24 hours. This first instance of virtual dry stimulation. SPS was evident at of oscillation. this point in the averaged time course, and the analysis the frequency revealed the SPS at C1 more clearly [closed arrow in Figure group 4.3. Plasmodial locomotion speed relative to periodic environmental stimuli. Changes in temperature and 30* FIG. 4. oscillator dynamics and simulation of SPS and bed by simple humidity cause chemical to phase-synchronize (bottom), generating response pulses Fig. 2(a)]. Simple The systems initial wet model weights of the organisms inat the same 40* SPSD responses. (a) Simulation of the variation locomotion rate as the stimuli. These responses continue for a short while, even after stimulationof ceases. j (0   < 1), Fig. 2 were 10 ­19 mg. The smaller plasmodia, in the range 50 S with time (black line), and the function form of Ht frequency !j . of speed 5­10 mg wet weight, were more sensitive to the dry 60 (dashed line). (b) Schematic illustration of the model behaviors. 22 portion of the stimulation, and those below 5frequencies mg wet weight could be 70 Many oscillators with different (the same symbols scillators with seriously damaged by it. The SPScounterclockwise response was thus de80 denote the same frequencies) rotate on the ring
Function form of H(t) Locomotion speed

 (min)

emerged, with near-identical fragments occasionally being produced. The systems of chemical oscillators responsible for coordinating P. polycephalum's spatial behaviour also permit a simple form of temporal pattern sensing. In another experiment (Saigusa et al), researchers applied periodic changes to the ambient conditions of a cultured plasmodium and observed its behavioural response. Yoshiki Kuramoto describes a procedure in which temperature and humidity, normally held at 26°C and 90%, were dropped to 23°C/60% for short periods at regular intervals while the plasmodium's locomotion speed was measured. During periods of `dry stimulation', this speed dropped noticeably in response. However, after three periods of dry stimulation, conditions were held constant for a while. Rather than returning immediately to a consistent rate of locomotion, the plasmodium continued to display dips in speed at the same periodicity of the previously applied disturbances, only returning to normal after three more intervals. When a single stimulus was applied a short time later, this behaviour reapppeared. The mechanism underlying this seeming ability to predict simple events involves the oscillators' passive response to changes in ambient conditions. Locomotion is governed by multirythmic timing sequences. The state space of an oscillator can be visualized as a circle, which represents a single oscillation. Each oscillator can be represented as a symbol on this circle, with identical symbols depicting oscillators of the same frequency. The angular position of a symbol along the circle represents that oscillator's phase, its current position along its cycle. In a simple simulation, Kuramoto was able to numerically duplicate the slime mold's behaviour. It was seen that the periodic application of changes to environmental parameters caused certain oscillation frequencies to synchronize in phase, that is, to cluster together in time. Say there are six of oscillator A running simultaneously at one cycle per second. If they are maximally out of phase, there will be a consistent one-sixth second interval between the completion of an A cycle; if they are all in phase, beginning and ending at the same moments, there will be one second between timing events. This phase synchronization mechanism can greatly amplify the difference caused by passive slowing of chemical processes, permitting a small rate change to effect control over a surprisingly long time span. In the simulation, several oscillators were seen to exhibit this effect. Dry stimulation caused temporal clustering followed by a slow redispersion as the oscillators drifted back out of phase. This recovery period is the key to the plasmodium's ability to anticipate. The alignment of oscillators in response to environmental conditions acts as a representational scheme; intensive parameters imprint themselves in the sytem's activity. These are not represented spatially, but as continuously modulated polyrythms. The tendency of phase patterns to persist in time rather than changing abruptly can be simply illustrated by the example of slightly out-of-sych windshield wipers. They drift in and out of unison slowly, with a fuzzy zone between synchrony and opposition in which they are loosely, if not perfectly, coaligned. The time it takes the pattern to drift

23

Figure 4.4. A large wild Physarum plasmodium

24

apart can be considered the duration of a memory of their alignment. This capacity of dynamical systems to economically encode and store information is essential to the plasmodium's seeming awareness; it grants it the ability to not only image the current state of its surroundings, but to compare that image to previous ones. Physarum's ability to solve topological problems through the parallel actions of many agents is significant because many complex problems can be generalized topologically. Like the reaction-diffusion systems that it encapsulates, the plasmodium itself can theoretically be used as a computational device (Adamatzky). Replicating this capacity of the biological system interestingly then becomes a criterion of effectiveness for physarum simulation algorithms performed on digital computers. The crux of many simulation problems is in how to make one material system (silicon microprocessor) model the behaviour of another, more complex one (the weather). Because each interaction in a complex system has a one-to-many relationship with all other interactions at a given point in time, modelling timesteps becomes exponentially more intensive as the number of interactions increases. Even with significantly faster serial processors, the serialization of massively parallel real processes complicates an already difficult endeavour. Material computers would seem to be well suited to this type of application. The problem becomes how to program them and interpret their response.

25

Figure 5.1. Spontaneous organization of a point-to-point network as a function of simple force interactions modelled with a two-dimensional physics engine. Images: author

26

Path optimization with self-organizing thread networks
In Finding Form, Frei Otto describes an experiment investigating the capacity of a network of threads thoroughly connecting a set of points to reorganize itself when loosened and dipped in water. The water's surface tension causes the threads to bundle together, establishing a branched routing system in which the directness of connectivity between pairs of points is reduced, but the areal footprint and number of individual pathways is reduced in compensation, recalling the minimal detour configuration of Physarum plasmodia. The intent of this experiment is to simulate this behaviour computationally using techniques drawn from the basic force-directed graph experiment.

Figure group 5.2. Physical thread models constructed by Marek Kolodziejczyk at the Institute for Lightweight Structures.

This model utilizes a set of datatypes representing particles, strings, and attractors whose interactions are coordinated by a two-dimensional physics engine. First, a set of points is defined, then these points are interconnected with `threads', here rendered as linear strings of particles and springs interpolated between point pairs. Finally, two attractors are assigned to each particle of every thread, one positive, causing particles to move toward one another, and one negative, preventing them from occupying the same space at the same time. These attractors mimic the coherence effected by hydraulic surface tension. By adjusting the properties of the simulated objects, a range of fiber types can be produced, from supple, elastic strands to stiff splines. In addition to the attractors linked to the thread particles, freestanding attractors can be placed in the space, establishing an ability to adjust the overall tendency of the network to favour or avoid different sites. Extending this technique, it is possible to quickly schematize highly effective connective systems negotiating a complex set of influences.

27

Figure 5.3. Introduction of external influence. The magenta circle indicates a negative attractor which repels thread particles.

28

Figure 5.4. Emergent nodes. If conditions are set up such that the springs comprising the threads are in a particular strength range relative to the forces acting upon them, an autocatalytic chain reaction can occur, in which thread particles form a mass dense enough to act as a superattractor, dominating other influences as it draws material into itself.

29

Figure group 6.1. Ferrofluid in a simple magnetic field

30

Ferrofluid
Ferrofluid is a suspension of iron nanoparticles in mineral oil. In the presence of a magnetic field, the iron particles align themselves along the field's lines of force, drawing the volume of oil with them. If the field is held constant, a metastable fluid body quickly forms. In response to a single magnetic pole, as with one side of a disc magnet, this form consists of a spiky dome rising from a meniscus, an equilibrium between gravity, surface tension, and ferromagnetism. In this simple configuration, altering relationships such as the volume of fluid against magnetic intensity produces a range of typical variants. When the fluid is first introduced to the magnet in a small quantity, it forms a tightly curved ball covered with numerous sharp spikes. As the fluid volume is increased, the ball begins to slump outwards and the spikes become larger and fewer. At a certain point the spikes disappear altogether, leaving a smooth black lump with an indistinct edge. At all times, the fluid is capable of flowing within its form without distorting it. Surface tension in the oil will cause a spike to stick to a sharp-tipped probe, allowing it to be dragged around the surface of the dome. In response to this disturbance, adjacent spike cells will redistribute themselves in such a manner as to minimize the effect on cells further away. When the probe is removed, the surface quickly restabilizes. If multiple magnets are used, their relative strengths and their polarity relationships come into play. If two magnets of opposite polarity are placed next to one another, the fluid will form a continuous body stetched between the poles; if they are of the same polarity, the fluid will split, forming separate beads with a sharp demarcation along the line of equidistance. Magnets of different sizes and strengths vary in their attractive and repulsive powers. Here, we are describing the distibution of disc magnets on a flat surface. In this situation, numerous magnetic elements placed in proximity to one another will tend to self-organize, with opposite polarities aggregating wherever possible. As a cluster forms, it essentially comprises an asymmetric composite magnet, with its polarity a net result of the contributions of its components. The formation of mutually repellent clusters usually reaches a point of détente before total consolidation, however. Rather than resolving into a supercluster, boundaries develop where the attraction between like clusters is counterbalanced by repulsion to unlike. The networks of force formed by North and South polarities stabilize each other at an intermediate scale between disarray and sameness. Ferrofluid maps this field of intensities.

31

Figure group 6.2. Ferrofluid in composite fields

32

Figure group 6.3. Complex geometry resulting from the simple placement of control points.

33

Figure 6.4. Ferrofluid detail.

34

Figure 6.5. Ferrofluid detail.

35

Figure7.1. Form-finding model for the Munich Olympic Stadium

The "reverse path" method makes it possible to recognize formation processes in animate and inanimate nature to the extent that such processes are set in motion artificially. This is done by experiment and the technical development of constructions. Technical developments driven forward at a high level of qualification permit better knowledge of nature's non-technical constructions. This is known as the reverse path. Nature is not copied, but made comprehensible through technical developments. Frei Otto, Finding Form, 45

36

Form-Finding
The research program initiated by Frei Otto has produced an important body of work relating to the analysis and classification of self-organizing material systems, especially at the architectural scale. Otto's methodical exploration of naturally-occuring processes of formation has enabled an approach to the design of architectural form inclusive of the agency of physical force and material tendency. The role of the physical model in this scheme is central; soap films, suspended nets, stretched manifolds and inflated membranes are all soft material systems exhibiting a common tendency toward minimal configurations, producing efficient complex geometries in their equilibrium states. The morphogenetic capacity of a given system ideally becomes architectonically instrumentalized through a process of translation Otto terms the `reverse path'. The self-organization of territorial occupation and traffic flow, as, for example, at a crowded beach, were an early research subject of Otto's. The thread experiment previously mentioned reveals the remarkable capacity of ordinary materials to calculate effective morphologies. If a set of points is connected each with all others by a taut thread, the path between any two points is always minimal, consisting of a straight line. While such an arrangement is optimal in terms of travel time, it results in a very high overall path length and a tight network with numerous, small interstitial spaces. If the threads are proportionally elongated by a small amount and dipped in water, the slackened strings will bind together under the influence of surface tension and gravity, producing a branched `mininmal detour' network with localized variations in throughput capacity. In this configuration, the consolidation of routes results in a lesser total path length and a more compact areal footprint leaving larger insterstitial spaces. An eight percent increase to the length of individual routes can reduce the overall path length by thirty to fifty percent. Using soap films, it is possible to determine the absolute shortest path network connecting an arbitrary set of points, an arrangement minimizing the use of material, but resulting in extremely long path distances between certain point pairs. In a related experiment, Otto used floating magnets to initiate the subdivision of an arbitrary space into cellular territories, prioritizing the configuration of space over path (Otto, Finding Form, p. 71). If a number of bar magnets are oriented vertically with their poles pointing in the same direction, they will repel one another. If they are attached to ballasted floats and placed in a container of water, the units will disperse, filling the basin in an arrangement with each magnet at the center of its own space. The boundaries of these territories will be identical to a Voronoi diagram, and the lines of magnetic interaction equal to the DeLaunay triangulation. Stronger magnets will occupy larger spaces than weaker ones, producing irregular geometries. This arrangement is metastable. Small fluctuations, such as wavelets on the water's surface, will distort the pattern slightly, but its organization will not degrade. If one of the magnets is moved around by an external force, other units in its vicinity wil adaptively respond, always tending toward positions in which the repulsive force is equalized in all directions.

37

Figure group 7.2 Mannheim Multihalle, Frei Otto, 1975

38

The self-organizing tendency of soft structural systems makes them ideal for the development of high-performance design strategies minimizing embodied resources. The form-finding model allows schematic parameters set out by the designer to be integrated at a high level of resolution by interacting physical processes; the specific characterteristics of the system and the inherent variability of material can have unforeseeable consequences, often producing the kinds of lucky accidents that catalyze qualitative breakthroughs. With the form-finding process, the issue becomes how to frame a problem in terms of appropriate phenomena, requiring an extensive vocabulary of possible approaches. One of the signal accomplishments of Otto's research has been the development and documentation of diverse techniques for instrumentalizing the physical model, making it work not only as a representation, but a performative analog. While Otto's early work focussed explicitly on self-organization in simple material systems, his best-known work was with large-scale lightweight enclosure systems. Tensile structures such as those of the German Pavilion at the Montréal Expo and the Munich Olympic Stadium were developed using sophisticated form-finding models and measuring systems. These were used not only to determine geometric properties like the positions of nodes and the outlines of skin panels, but to measure the strain field in the stretched cable net and observe deformational tendencies under different loading conditions. Computer simulations were also used, but the physical model played an important role in corroborating its outputs and dealing with exceptional circumstances. The architectural use of tents is of course an ancient practice, but limited by scale to small applications; Otto's work permitted a finely calibrated rendering at the large scale, using high-performance materials like polycarbonate and steel cable. Of special interest to this thesis is a lesser-known project, the Mannheim Multihalle, completed in 1975. Whereas the earlier tent structures segregated forces into specialized material assemblies (tension in the cable net and compression in the masts), the Multihalle developed a hybrid shell/membrane system acting in both compression and bending: the timber gridshell. Like the tents, the gridshell develops a high strength-to-weight ratio through its large number of interconnections, providing numerous pathways of force distribution. Its geometry is determined with a form-finding approach similar to that used by Gaudí in the church at Colònia Güell and the Sagrada Família: a suspended network of chains that asumes a minimal equilibrium form under self-weight. The curve assumed by a hanging chain with its ends at the same level is called a catenary; its geometry is partially the result of the fact that each link must carry the weight of all those below it, resulting in a continuously varied load distribution. If conditions are modified, for instance if one point of fixation is elevated or a weight is attached at some point, the curve will deflect into a new equilibrium position. The true catenary can be modelled by a single straighforward equation, however generalized catenary behaviour is much more complex, especially in a network of linked strands. The

39

Figure group 7.3: Catenary models. Form results from the response of tensile elements to gravity under self-weight (top) and a volume of plaster (bottom).

40

process used to develop the form of the Multihalle began with a plan outline used to constrain the edges of a fine chain mesh. This mesh was progressively relaxed until the lateral force at its edge and the curvature of the shell were within acceptable ranges. Because this form is developed purely in tension (chains have no compressive strength), its inversion is theoretically a purely compressive minimal structure under self-weight. In order to construct this form, a suitable structural system was needed, one that was flexible enough to adapt to the shell's double curvature but also capable of acting in compression. A multilayered grid of timber laths was used; the long, slender pieces of wood are flexible enough that they are able to approximate the behaviour of a hanging chain, yet able to direct compressive force while bent. An extensive perpendicular grid of laths was laid out flat on the ground and joined at its intersections with loose pins. This lattice mat, essentially a large-scale piece of fabric, was then drawn into shape by cranes and a system of cinching straps. The loose pin connections permit a scissoring action, enabling the fabric's weave to distort while the laths are flexed. When the final form was reached, the connections were tightened and the edges secured, fixing it; the frame was then clad in a lightweight membrane. Originally intended as a temporary festival structure, the Multihalle has been in operation for over thirty-five years. For much of that time, no new timber gridshells were produced. Time-consuming to engineer and not without construction difficulties (thousands of breakages occured during and after formation), the method drew little interest until recently, with the emergence of a new generation of simulation techniques. Several projects built in England over the last several years have advanced Otto's approach from materials, construction, and design standpoints. The Downland gridshell, completed in 2002, developed several innovations improving on Mannheim. Of primary concern was the breakage problem, making timber selection especially important. A decision was made to use locally sourced oak with an elevated moisture content, the green wood being much less brittle than conventionally dried timber. Selected lengths were finger jointed together, producing continuous laths of up to fifty metres. An improved node clamp was developed which permitted a sliding as well as a scissoring action, enabling a greater range of deformation. The formation method was also significantly different; whereas Mannheim's lath mat was laid out on the ground and hoisted into place, the Downland's was built atop a densely spaced array of jacks and pulled downward into shape, granting much more precise control over the formation process. The reason these practical advances could be made was that a much more complete simulation was possible. While both physical and digital models were critical to the development of the design, the accuracy of the physical model's performance is limited by scale. In his discussion on proportion in anatomy, On Being the Right Size, biologist J.B.S. Haldane highlights the effect of a geometrical relationship, the square-cube law, that imposes constraints on the scaling-up of a given material system.

41

Figure group 7.4. Formation of the Downland gridshell. Edward Cullinan Architects, 2002

42

Essentially, he argues that it would be impossible for a mouse to be enlarged to the size of an elephant while preserving its proportionality and materiality since its mass is proportional to its volume, while the structural performance of its limbs is proportional to their cross-sectional area. This means that the limb's strength decreases with increasing scale. The elephant's thick legs are so because of the limited strength of bone. A scaled-up mouse would need to be of elephantine proportions unless the strength of its bones were exponentially increased. This general property makes scale a difficult issue with form-finding models, especially regarding elastic properties. The bending properties of the laths were disregarded in Otto's chain model; presumably, it was believed that this property would play a negligible role due to the slenderness of the members. The Downland design, however, was primarily driven by stiffness requirements (Kelly et al., 5), and modelling the effects of this property could only be accomplished through simulation. This is an instance where the catenary model's weaknesses become apparent. Furthermore, minimal form alone is insufficient for the provision of structural robustness, as a building experiences not only constant selfweight but a variety of probabilistic loads. Excess structural capacity is always required, suggesting a degree of latitude with respect to the structural optimization of form. Finally, in optimizing toward lightness, a number of performative potentials ensuing from form are disregarded. Factors like solar geometry or design for passive ventilation, if appropriately developed, can generate benefits outweighing the sacrifice of a certain degree of structural performance. The basic premise of driving a morphogenetic process in a material system continues to evolve, with an emerging focus on the integration of multiple influences. Physical models continue to play an active role, but simulation and numerical analysis have become indispensible tools in performance-oriented architectural design.

43

Figure group 8.1. Shell studies using fabric simulation

44

Fabric simulation
The prevalence of efficient fabric simulation algorithms is largely due to the work of Andrew Witkin, previously mentioned in association with the use of reaction-diffusion systems as texture generators. A computer graphics pioneer, much of his later professional work was developed in close collaboration with Pixar. Pixar was making a name for itself as an innovative animation house, unprecedentedly working exclusively in the medium of computer animation. The technical foundations required for such an enterprise are substantial, creating a demand for a specially-tailored approach to simulation. Whereas academic computing and scientific simulation require rigour and exactitude, theatrical animation relies on the creation of convincing illusions. Witkin's innovations centered around a rigourous yet anexact implementation of physical process in an artistic domain. The most straightforward application of this approach is in the replication of complex flowing effects, ubiquitous in reality but intensely difficult to draw convincingly, especially when in continuous movement. Materials like hair, water, fabric, and skin are present in almost any scene; the ability to render their appearance compellingly within the limits of a pure CGI workflow necessitates a generalized framework. Balancing performance against appearance requires an abstraction capturing the essence of a complex behaviour with a manageable set of mechanisms. The technique developed by Witkin to represent cloth has its roots in a programming paradigm called object-oriented design. This approach to computing has been around since the early 1980s, emerging in response to the limitations of an earlier paradigm, procedural programming. Rather than conceiving a computer program as a simple list of instructions, an object-oriented approach involves the definition of abstract virtual entities implementing properties and methods. The object is like an ideal Platonic form, not an actual presence but an idealized template for any number of variant instances. The methods associated with an object can be invoked to generate changes in the object's state. A simple example would be a door object. We can define any parameters we like: properties like location, width, height, thickness and opening angle can be used in the creation of a geometric representation. Methods describe actions the object is capable of performing: in the instance of the door, we would at least want an `open' and `close' method, preferably with the ability to control its angle. If we define the `open' method to accept a time and an angle parameter, and the `close' method to accept only a time parameter, the lines blueDoor.open(3, 15) blueDoor.close(.5) would cause the door instance called `blueDoor' to open fifteen degrees over three seconds, then close in half a second. The low-level operations contained within a method can be hidden from the user, who, like the driver of a car, only needs to know how to use it, not how it works.

45

Figure 8.2. Complex manifold modelled with simulated fabric

46

The creation of an abstract type involves an understanding of real process and intended use. If the goal is to produce an opening door for a scene, it is probably not necessary to consider the internal structure of wood; if the goal is to show it bursting into splinters, it is. Actual textiles are hierarchically nested networks of fibers, threads and yarns, held together by twisting, braiding, weaving, tangling, and knotting. The properties of each subsystem influence the macroscopic behaviour of the cloth, producing a range of qualities from diaphanous to rugged. The simulation strategy advanced by Witkin ignores the deeper performance of strands and weaves, focussing on the top level. By representing fabric as an array of nodes and springs, convincingly fabric-like behaviour can be replicated with a set of simple units. The simplicity of this model is important not only for its computability, but its usability. Simulation proceeds, like a film, by a series of discrete steps that approximate the flow of time. At each step, the forces acting on each node and spring in the system are calculated and their respective properties updated. Each spring has parameters determining its strength, damping, and equilibrium length, while nodes have properties of mass and angular stiffness (the degree to which they resist being bent out of plane). In response to an extrinsic force such as gravity, the nodes are drawn `downward' along the gravity vector. If a node is held in place (as by a pin), the cloth will begin to deflect as it falls. The springs closest to the points of fixation will begin to elongate first, pulling on those next to it, propagating strain waves through the system. Eventually, the springs' resistance limit is reached and they reverse the process, causing the system to bounce back, then fall again, until equilibrium is reached. Turbulent forces like simulated wind can reproduce the aperiodic fluttering of a flag. In the simulated environment, one force is no different from another; if the goal is to produce a form that is adaptive to multiple environmental factors, these factors can be rendered as forces in the simulation. While it is simple to make a chain mesh deflect under the influence of gravity, having it morphologically self-adapt to solar geometry is not. The degree of control over force in approximative simulation frameworks opens up a set of architectural modelling possibilities at least as rich as that of more conventional generative geometric techniques.

47

Figure group 8.3. Gridshell design tool: Working from the observation that, in the design of the Downland Gridshell it became necessary to reinforce the structure's valleys in response to concentrated loading, a process was devised to continuously modulate the spacing of laths in the initial mat rather than doubling it. For the purpose of this experiment, the modulation was generated by a simple polynomial function, however the technique is extendable to more sophisticated layout processes, such as the use of gradients or a string/attractor system.

48

When subjected to simulated gravity, the simple planar geometry begins to distort, eventually coming to rest in a configuration determined by the elastic properties of the fabric components. As with the string/attractor experiment, the members in this system are modelled with vertices and edges having particle- and spring-like properties in a programmable force environment.

49

Architecture as a material practice operates through the articulation of spatial, material and energetic interventions within a specific context. Enhanced context-sensitivity of an integral design approach lies at the base of the approach introduced here, entitled `Morpho-Ecologies' This approach commences from the unfolding of performative capacities inherent in material systems in relation to the specific environment they are embedded within, as well as an intensively empirical mode based on physical and computational form-generation and analysis methods. Hensel, M. and Menges, A., Inclusive Performance: Efficiency Versus Effectiveness, in Versatility and Vicissitude, p. 55

50

Morpho-ecologies
In the morpho-ecological design approach, the specificity of a context plays a generative role in design development. Like vernacular architectures calibrated to regional idiosyncracies of weather, topography, and materiality, this approach works from a perspective in which human settlement is not seen as constituting an autonomous self-contained reality, but as being coextensive with the ecological systems in which it is embedded. Accomplishing the most with the least is a key principle in this aim. However, this does not imply a conventional optimization process of paring down, but of multiplying. Rather than conceiving of a building as a collection of segregated subsystems, each the province of a specialized consultant, it is approached as an integral whole which stands to benefit from the spinoffs of greater complexity and connectedness. Likewise, environmental conditions are not seen as forces to be overpowered with mechanical brute force, but as morphogenetic agents in their own right. This approach is in marked contrast to the normative tendencies of modernist rationalism, which looked to universal, rather than particular strategies in its pursuit of performance. The phenomenon of biological adaptiveness supplies an unmatched range of case studies, as the means by which organisms maintain themselves in a fluctuating, competitive environment are necessarily high-performance and low-cost. In his project Responsive Surface Structures: Instrumentalising Moisture Content Activated Dimensional Changes of Timber Components, Steffan Reichert examined the ability of pine cones to open and close passively due to the effects of the absorption of atmospheric moisture and derived a component-based skin system utilizing this effect. The mechanism by which the pine cone releases its seeds accomplishes two feats simultaneously; it limits the release of seeds to periods of when conditions are conducive to germination, and it effects a coordinated kinetic process without consuming any of the pine tree's energy reserves. Reichert's skin system uses pieces of wood veneer in the same capacity; being only partially held down, they respond directly to humidity, curling up to increase the skin's porosity when increased ventilation is needed, adding a layer of functionality to what would otherwise be a simple barrier.

Figure group 9.1. Responsive surface structures: pinecones and veneer component (Steffan Reichert)

51

Figure 9.2. The components assembled into a self-supporting shell. Slight dimensional variations between units allow the system to conform to a wide range of implicit surfaces.

52

Having established the basic performative element, Reichert then integrated a structural armature with the skin panel allowing the components to be joined together with tabs to form a rigid shell requiring no additional framing. While this case study focusses closely on a single phenomenon, this kind of integration of capacities is the crux of the morpho-ecological approach; beginning at a low level of resolution, well-defined patterns are selected, combined, and built up into succesively more complex, higher performing organizations at increasing scalar magnitudes in the manner of natural systems. In such systems of systems, the addition of new elements involves a rapid increase of possible connections, multiplying potentials but also increasing the complications attendant to design. Material systems, being structured flows of energy, negotiate this complexity effortlessly and indifferently across scales, their observable configurations indexing the forces acting within and upon them. Effecting a smoother integration of human-produced and natural ecosystems requires a resonance with this condition; the traditional top-down approach to the architectural determination of form is at odds with this aim. A brief consideration of language is instructive in this connection. Languages can be considered as natural systems; they have emerged gradually from rudimentary forms, they involve complex, multilevel assemblies of objects (morphemes, syllables, words, sentences, etc) in continuous evolution, and they embody a set of criteria governing the fitness of linguistic constructs, criteria which, while operating at a low level, enable and circumscribe enormous expressive potential. However, a language is relatively autonomous, needing only be to consistent with itself. Ultimately, the structuring of a language is arbitrary, but in the institutionalization of its conventions, it becomes useful. There is no objective reason for `A' to precede `B' in an alphabet, but the fact that it does so consistently allows for alphabetic sorting, a highly useful procedure. Beyond the scope of a particular language, though, this scheme becomes meaningless. The concept of an autonomous language of architecture suffers from this inward focus. The pursuit of an architecture of emergence can be considered as an attempt to allow architectural systems to enter into an intimate communication with the environments in which they dwell.

53

Figure group 10.1. When short strings are folded into loops, they form regular polygons. When expanding these polygons with successive loops, their relative orientations affect the geometry and stability of the composite component.

Colinear orientation of fields

Square packing of opposite-oriented chains

Hexagonal packing of like-oriented chains

54

Magnetic lattices
This experiment explores a simple formal system consisting of arrangements of identical spherical magnets. As with the ferrofluid experiment, the attraction and repulsion between magnetic dipoles is used to construct coherent, differentiated assemblies that actively contribute to their own structuring. Here, the focus is on the modular development of stable units across scalar domains, from atom to molecule to composite. The use of identical units is meant to highlight the generative capacity of the combinatorial approach, to achieve a kind of symmetry-breaking, creating difference from initial homogeneity. The nature of the components makes it impossible to directly approach the construction of large-scale assemblies. A serial construction technique, such as the way bricks are laid out one at a time in rows, one row atop another, quickly leads to instability. As more units are added, the net force of magnetic attraction increases, and the growing assembly, if it can, will collapse in on itself, forming a rough lump. In order to produce a large assembly, care must be taken to develop a system of wellproportioned nested modules, each level of which is a stable pattern. The condition of stability is mediated by two factors: magnetic interaction and spherical packing geometry. If a number of marbles are placed in a container and shaken up, gravity will cause them to arrange themselves as densely as possible, and they will stochastically organize into clusters of different packing arrangements. Unlike marbles, magnetic spheres have a specific axial orientation along which they exert a constant force. Two spheres will spontaneously orient themselves such that the nearest opposite poles come together in direct contact; in this way, short chains can be made along which the composite magnetic field extends. When two chains are placed next to one another, the relationship between the orientations of their respective magnetic fields will drive the packing geometry in one of two directions: opposing orientations result in a square pattern, while like orientations produce the more stable hexagonal pattern. This principle applies when strings are folded into loops. When composed of few elements, loops will form regular polygons, stable forms which contain empty space. When additional layers are added, the result may be a flat tile, as in the case of the hexagon, or a conoid shell, resulting from the pentagon. These shells then take on another orientation deriving from the relationship between the directions of curvature and field. From this point, enough formal diversity has been established that a third level of assembly can produce a broad range of composites.

55

Figure group 10.2. Shell studies using fabric simulation

56

Figure group 10.3. Modular lattice study2

57

Figure group 10.3. Modular lattice study 3

58

59

Figure 11.1. Crozier Dairies, Namao, Alberta

60

The dairy farm: an intermediate-scale morpho-ecological module
Viewing the problem of the Campo de Dalias from a morpho-ecological standpoint, the issue becomes how to address the structuring of multiple performances to produce a high-functioning managed ecosystem. This applies at every scale from the building component to the distribution of land usages. Currently, operations in the Campo are highly optimized toward the singular goal of growing vegetables as efficiently as possible, to the sole benefit of the farmer/landowner; other opportunities not directly related to this industry are ignored. This experiment develops an approach toward the spatialization of process blocks using a weighted force-directed graphing technique, creating lists of objects with unique sets of inputs and outputs, scanning the lists for compatible pairs, and connecting them with springs so that connected receptors strongly attract one another while weakly repelling everything else. The connectivity of inputs and outputs in the system establishes an abstract network topology that then resolves itself spatially as the physical system tends toward equilibrium. Instead of a hydroponic vegetable farm, the practice modeled in this experiment is a dairy farm. Because of the perishability of their product, dairy farms are constrained by distance to regional markets to a greater extent than other forms of agricultural practice. While grain or livestock are commonly shipped long distances to processing facilities and are situated according to specific landscape capacities, milk production is spatially linked to human population. As with other forms of industry, there are simultaneous forces of attraction and repulsion between dairy farms and expanding urban areas. Unlike most industrial practices, however, dairies often exist directly within a larger extensive cropping operation that provides feed and bedding for the animals, utilizing hundreds of hectares of land. As cities sprawl into this territory, this type of agriculture is being challenged by the competing demands of suburban and logistics landscapes. The practice of spreading manure on fields, for example, becomes both a nuisance and a public health concern when carried out in proximity to residential areas, yet helps to maintain soil nutrient levels and biomass without chemical fertilization. The diversity of mechanical and biological processes involved in the production of milk are also typically implemented with the straightforward goal of minimizing the farmer's expenses; it costs less to grow, process, and store a cow's feed onsite than to purchase it from the open market, where transportation and brokerage incur cost for the buyer. The intermingling of biological and mechanical systems on the farm requires carefully integrated infrastructures for the storage and transportation of forage, silage, water, fuel, pesticides, fertilizers, manure, and milk. This project proposes an extension of these infrastructures, utilizing untapped capacities to increase performance. The emphasis here is not on how to design a more profitable dairy farm, but to retool an existing material practice with the aim of developing an integrated approach to the production of fuel, energy, and food. As a departure point, a schematic analysis was conducted of the inputs and outputs of a 500head dairy operation, focussing on the effects of integrating biogas production from the anaerobic

61

Figure group 11.2. Schematic analysis of bioenergy productive capacities of a 500-cow dairy farm

62

digestion of dairy manure and other organic wastes, electricity generation from biogas combustion, algaculture from liquid digestate, flue gas, and sunlight, and biodiesel production from algal biomass and canola crushing. The purpose here was not to produce an exhaustively detailed list of production capacities, but to determine what the rough spatial requirements of the various operations were, and whether their productivity would be sufficient to justify their inclusion. With this schematic data and a set of process blocks (for example, the digester system contains blocks for manure input, organic waste input, mixing, digestion, biogas storage, and digestate storage), a set of datatypes was created to represent each block at a particular scale, to match its inputs and outputs to compatible points in other blocks and make them attractive to one another, to assign a system of weights permitting less important blocks to move more freely than more important ones, and to label the content and direction of flow. The magnitude of flow between points was not considered. In addition to setting up the conditions of the physical simulation, a degree of user-interactivity was established, allowing process blocks to be dragged with a mouse. The reason for this is that the system is capable of reaching multiple relatively stable configurations; typically, there isn't a single overwhelmingly superior arrangement, but a small set of relatively equivalent solutions. Interactivity permits the system to be shaken up after it comes to rest, allowing the topology of the network to be transformed without rearranging the logical relationships between nodes. The diagrams thus produced establish a means of gauging the effectiveness of different nodal configurations at the schematic level, quickly working through complex sets of conflicting priorities by the simple manipulation of a small set of control points. This approach is intended to be scalable. As each process node in the local network of the farm has a unique set of receptors through which it communicates with other nodes, the farm itself acts as a node at the larger scale, with its own set of connective potentials; conversely, each node within the farm can be broken down still further. Integrating the kinds of experimental systems explored in this project into a framework in which they can work together coordinatedly across scales is the next step toward the devlopment of a high-level toolkit for morpho-ecological design.

63

system at t = 0

Figure group 11.3. Generative adjacency schemes using spring-particle networks

64

Force-directed adjacencies for the linked subsystems

65

Schematic layout

Figure group 11.4. Schematic dairy farm plan derived from generated adjacency scheme

66

Figure group 11.5. Schematic dairy farm 3D view

67

Figure group 11.5. Schematic dairy farm 3D view.

68

69

Figure group 12.1. Cellular spatial division using force-directed graphing to control a Voronoi diagram

70

Cellular subdivision using force-directed graphs
A force-directed graph is an application of the spring-node abstraction for spatializing large quantities of data. When attempting to create a map of relationships between numerous elements, the problem of where to place them when working with a serial process such as hand drawing can be significant; the right amount of space for the remaining elements must be conserved with each placement. A top-down organizational approach to such a problem might be the establishment of a regular spatial system such as a grid, a set of static positions into which elements are either placed or not. This approach has the drawback that the grid must be scaled to accomodate the densest region of the graph, leaving relatively sparse regions where data is thin. With a basic force-directed graph, an iterative approach is used, in which elements are placed simultaneously and allowed to spatially selforganize over a number of time steps. When the system reaches mechanical equilibrium, the process is stopped, producing a graph in which the data points are evenly distributed. This can be achieved with a straightforward physical simulation. Nodes are treated as mutually repellent charged particles, with each node representing an element of data. Springs denote logical connections between nodes, and act to constrain their dispersal pattern. At t=0, the set of interconnected nodes is placed, usually dispersed at random within a small area, and with each timestep, the simulation calculates the effects of all of the forces within the system, updating position and velocity or length values for every element. This spatialization process tends toward a minimal-energy configuration. As such, it becomes a useful tool for a variety of generative design applications; a simple case is the development of architectural adjacency diagrams when routing efficiency between zones is desirable. In this exercise, a two-tier compositional strategy is developed, in which clusters of nodes sharing a specific level of repulsion are created, each member of which interacts with the nodes in other clusters with a second force value. By itself, a single cluster with few nodes will expand uniformly, producing a regular polygon. If the number of nodes in a cluster surpasses a threshold relative to the cluster's spring strength, nodes may become trapped in the center. When clusters begin to interact, they move and distort according to the relationship between the intensities of local and global forces. If the local force dominates, there is little distortion of the cluster, however many nodes can become trapped in its center; this will produce a realtively even node spacing. At high enough force levels, this can result in a constant circulation of nodes throughout the cluster; while its centroid does not migrate and the overall distribution of clusters remains invariant, the system is unable to settle down, despite the fact that no stimulus is applied. Conversely, if the local force is weak relative to the global force, the system will tend towards a heterogeneous distribution. Finally, a cluster with a large number of nodes is significantly more plastic than one with a low node count, and has a wider range of deformation.

71

Figure group 12.2. Cellular spatial division using force-directed graphing to control a Voronoi diagram

72

In the visualization, each node acts as a site in a Voronoi diagram, with its cell coloured to indicate cluster membership; this permits a representation of the area `controlled' by the node, since any point drawn within a Voronoi cell will be closer to this node than to any other. At t=0, a single cluster is created near the center of the viewing area and allowed to expand for a short period of time. Subsequently, the centroid of the largest Voronoi cell is chosen as the site for the instantiation of a new cluster. This process of subdivision is repeated an arbitrary number of times. A limited degree of randomness is applied to the size of each newly generated cluster, adding an amount of stochasticity to the process. When the size range is sufficiently large, one cluster may engulf one or more others, resulting in interlocking patterns whereby two or more clusters stabilize each other, producing a composite body of a higher total energy level than that of each alone. By varying the force and size parameters, a range of pattern types can be generated, with similar instances sharing morphological characterists without being identical.

73

74

Appendix 1: Anaerobic digestion and distributed generation
Overview
Anaerobic digestion is a process in which organic waste material is broken down by bacteria, producing biogas (mostly methane, with an elevated carbon dioxide content) and a nutrient-rich liquid effluent. Digestion occurs in a sealed bioreactor; temperature control, oxygen exclusion and gas containment are important factors in digester design. In the context of the dairy farm, the digester is simply the last step in an extended process of cellulose breakdown, beginning in the silo and continuing in the cow. Dairy cattle produce, on average, 51 litres (13.5 gallons) of `as excreted' manure daily (Burke). Herd sizes can exceed a thousand, necessitating a significant manure-handling infrastructure. Typical practice has been to collect manure in a storage pit, spreading it on the fields in the spring. While this process retains biomass within the local ecosystem, significant quantities of methane and carbon dioxide (both greenhouse gases) are released into the atmosphere, odour can be a problem with nearby residents, pathogenic bacteria can contaminate water or food sources, and flies are produced in vast numbers. Digestion can mitigate these problems while producing a carbon-neutral fuel source.

Inputs
On its own, dairy manure has low biogas production potential. The productivity of digesters can be greatly enhanced with the provision of higher-energy feedstocks. For example, on-farm digesters typically accept industrial food waste as a means of both boosting methane production and generating income from tipping fees (Burke, Pronto & Gooch). A large heat source is required, as the bacterial culture requires a consistent temperature around 37°C.

Outputs
As digestion proceeds, much of the remaining organic material in the manure is decomposed into biogas (roughly 60% methane, 30% carbon dioxide, and 9% nitrogen, with traces of hydrogen and hydrogen sulphide), and a nutrient-rich, low-odour fluid effluent, while particulate matter accumulated over the collection process is separated and discarded. The biogas is typically used to power a generator, often providing more than enough electricity to run the farm and enough heat to warm the digester. The liquid effluent is collected in a long-term storage pond and spread in the spring in place of raw manure.

Technologies
While several reactor types are suitable for implementation on a dairy farm, the focus here will be on two types of biological process: the mesophilic, which performs optimally around 37°C, and the thermophilic, which prefers a temperature around 60°C. In the thermophilic process, waste is broken down quickly and pathogens are destroyed, however the effluent produced tends to remain rather malodorous. The slower mesophilic process does not destroy pathogens, but produces an odour-free

75

76

effluent with a higher methane yield. The combination of these two processes is called temperaturephased digestion. Although more heat and additional reactor volume is required by this approach, the higher-rate thermophilic phase vessel can be significantly smaller than than that for the mesophilic phase due to its higher throughput. Operation A contact digester accepting food waste would involve the following stages: -Food waste pit: High-energy substrates need to be fed slowly into the digester to avoid shocking the bacterial culture, requiring a dedicated short-term storage area. -Manure/blending pit: Food waste and manure are mechanically chopped and mixed together before being pumped into the digester pit. -Digester pit(s): Depending on reactor design, the mixed digestate will pass through one or more chambers containing a specialized bacterial consortium, a diverse culture of micro-organisms, in which each type performs a unique biochemical task. Some bacteria release enzymes which break down and dissolve organic solids, while others process the (sometimes toxic) resultant coproducts like hydrogen and acetic acid. This process takes roughly twenty days (Pronto & Gooch). -Solid/liquid separation. The liquid component is typically diverted to a large long-term storage pond to await spring spreading. With the contact process, solids are returned to the digester; this practice replenishes the bacterial consortia, greatly improving the process rate compared to reactor types requiring bacterial growth in parallel with digestion. Refractory solids (sand, etc.) do build up in such a system, requiring mechanical separation devices. -Gas reception pit: In the sealed environment of the anaerobic digester, biogas is being produced at a more or less constant rate. The simplest way of storing this gas is with a flexible membrane enclosure, which can passively expand or contract to maintain an operating pressure range. If gas is produced more quickly than it can be consumed or stored, it must be flared.

Yields
In one case study, the biogas produced by an on-farm digester was sufficient to supply 225 kW of electrical generation capacity. Over the ten month study period, a 130 kW genset operated at an average capacity factor of 0.881, producing 92 738 kWH per month, almost twice what the dairy consumed. Heat from the gas engine was reclaimed to warm the digester. In total, this operation is estimated to have reduced operating costs by $41 000 annually (Pronto & Gooch). The dairy investigated was near the lower threshold of digester viability, at 525 cattle, and incorporated a significant amount of food waste as influent. The liquid effluent produced was spread over 728 hectares of land.

77

78

Design considerations
Siting is an important factor in digester design; the barn should be at a higher level than the digester to permit gravity to draw manure into the influent pit. The duration of the digestion process determines the size of the digester vessel; a twenty-day hydraulic retention time means that the reactor must have enough capacity to hold twenty days worth of influent. In the case study mentioned above, the loading rate was 25 000 gallons per day, with a treatment volume of 634 836 gallons; the digester dimensions were 68' x 78' x 16', covering roughly 5000 square feet. A gas-handling building housing the generator was also required, as well as a 4.2 million gallon long-term storage pond.

Integration By input
Digesters fare better with a mixed diet. While they solve several health and nuisance concerns relating to manure handling quite well, if biogas production is to be emphasized, substrates need to be combined with the manure. Depending on the marketability of biodiesel coproducts such as canola meal or algae biomass, their addition to the digester could be an option. The disposal of food and cellulosic wastes is already well established, as is the use of reclaimed heat from biogas combustion (cogeneration).

By output
The introduction of high-nutrient substrates results in rich effluent that may exceed the fertilizer requirements of the local land-base. A high-intensity cultivation system such as a greenhouse or photobioreactor could readily employ such a liquid fertilizer.

79

80

Appendix 2: Algaculture
Overview
Algaculture is one of the most promising new biodiesel production technologies. Microalgae, (as opposed to macroalgae, or seaweed) are unicellular phytoplankton that grow in water. While these simple organisms are evolutionarily distinct from plants, they have photosynthetic metabolisms, processing sunlight and carbon dioxide into organic compounds. Unlike plants, they reproduce entirely by cellular division, which greatly shortens their development time. Having no cellulosic structure, they are able to devote a high proportion of energy and material to lipid production. Since they grow in aqueous suspension, relatively simple pumping and filtering techniques can be employed in cultivation. These factors permit theoretical per-acre biodiesel yields one or two orders of magnitude greater than conventional feedstocks such as soybeans or canola.

Inputs
The requirements for microalgae growth are relatively simple: sunlight, carbon dioxide, water, and nutrients (mainly nitrogen, phosphorus, and potassium). In practice, the principal limiting factor constraining growth is the availability of light. While artificial lighting can be used to grow algae, it is counterproductive from an energy standpoint.

Outputs
After dewatering, the biomass lipid content can exceed seventy percent by weight. In addition to its utility as a biodiesel source, the algae itself (depending on the species) has value as a base for nutritional supplements, cosmetics, and animal feed.

Technologies
There are two basic technologies for growing microalgae: the pond and the photobioreactor (PBR). The chief advantage of the pond is its simplicity; requiring no enclosure and a minimum of handling equipment, it is relatively inexpensive to cover a large area with open algae ponds. The downsides are that evaporation becomes a significant factor, requiring a large water input: contamination by detritus and invasive species can occur relatively easily: and the horizontal orientation reduces the efficiency of sparging (bubbling gas through the growth suspension). Photobioreactors are closed systems consisting of horizontal tubes, columns, or flat plates in which the environmental conditions affecting growth can be precisely controlled. While significantly more complex and capital-intensive than ponds, they are also much more productive. Because they are closed, evaporation is not a problem, and being free from the ground, their areas of application are potentially much more diverse.

Parameters
1- Lighting. Sunlight is the primary limiting factor in algal growth, and good reactor design is crucial to maximizing its effectiveness. However, at high levels of intensity, algae experience light satu-

81

82

ration. To mitigate this effect, light must be spatially diluted. Current research indicates that a surfaceto-volume ratio of 400 square meters of insolation per cubic meter of reactor volume is optimal for this purpose. Photosynthesis can utilize less than 50% of the spectrum of visible light, suggesting the inclusion of a companion technology to capture the remaining energy. 2- Mixing. Agitation of the algal suspension is essential to promoting growth. Mobilizing the cells within the growth medium exposes them to varying regions of brightness, and enhances nutrient uptake. Typically, mixing is accomplished by sparging, in which gas, typically with an enhanced CO2 content, is bubbled up through the medium. The size of the bubbles, the rate of flow, and the concentration of CO2 will all affect the performance of the culture. Best results have been achieved using a dual sparging approach, in which large bubbles of plain air are used to promote turbulent mixing while the high-CO2 gas is introduced at a finer scale through a perforated membrane. 3- Water consumption. Algae can grow with a broader range of water types than land-based crops, including seawater and brackish water, fresh water, and waste water. Indeed, one of the most promising applications of algaculture is as a complement to waste treatment processes, which can be designed to produce effluents high in nitrogen and phosphorus, essentially providing a cost-free growth medium while solving a disposal problem. 4- CO2 consumption. A significant benefit of PBR operation is the ability to scrub carbon dioxide from such sources as flue gases, which can consist of as much as 13% CO2 (atmospheric levels are currently 0.0387%). Because of the need for a steady, clean supply of carbon dioxide, the coupling of PBRs with processes involving combustion is recommended. 5- O2 removal. As photosynthesis occurs, oxygen is released into the growth medium. Excessive oxygen adversely affects algae growth, requiring a venting strategy. While this is a straightforward procedure with flat-plate and column type reactors, the horizontal tubular reactor is significantly constrained by oxygen buildup in its long runs. Because of this factor, the tubular reactor style has fallen out of favour for high-yield applications. 6- Nutrient Supply. Nitrogen, phosphorus, and small amounts of other nutrients are required for algal growth, and the relative proportions of these nutrients can significantly affect the process. For example, when deprived of nitrogen or phosphorus, the stressed algae will adaptively increase their lipid production, increasing the percentage of oil as a component of biomass. The rate of growth in this case suffers, however. A potential strategy is to modulate the nutrient supply, promoting quick growth up the point of optimum cell density, then cutting nutrient levels to promote lipid storage. 7- Temperature. Being essentially fluid-filled greenhouses, heat buildup in PBRs can be significant, up to 30 degrees celsius above ambient. Because each strain of algae grows optimally within a

83

84

fairly narrow temperature band, thermal control is essential to performance. 8- pH. As with temperature, algae strains have narrow optimal pH ranges, requiring monitoring and adjustment. While the control systems required for optimization can become complex, the basic principle of the photobioreactor is quite simple. Growth medium with a low biomass density (number of algae cells per unit of volume) is introduced to the reactor vessel and exposed to light. The algae cells ingest carbon dioxide and nutrients from the medium, growing and dividing, and releasing oxygen back into the medium. At a certain point, the biomass density reaches a peak value, past which the growth rate begins to decrease; this is the time to harvest. Processing involves separating the algal suspension into three components: solid biomass, depleted nutrient solution, and lipids. Currently, PBR biodiesel yields are in the range of 50 000 to 150 000 L/ha·yr, or about 5 to 15 litres per square meter per year, depending on geography, algae species, and reactor design (Bayless, Mulumba and Farag). While there is significant room for improvement, ultimately biodiesel production is constrained by the availability of sunlight; a figure for the theoretical upper limit of areal productivity in North America is 43 L/m2·yr (Bayless). The growth of algae in a volumetric fluid medium involves several nonlinear processes. At the moment fresh medium is introduced to the reactor, the cell density is fairly low, and the suspension is relatively transparent. As density increases due to cell growth and division, the suspension becomes more opaque, affecting the optical path within the reactor vessel, possibly decreasing the growth rate. Thus, a `young' suspension can be optimally sustained with less light than a mature suspension. Similarly, as the culture becomes more dense, the requirements for agitation, oxygen removal, and carbon dioxide supply change. As mentioned above, algae under nutrient stress will show increased lipid production. If the nutrient content of the suspension can be controlled to allow fast growth early on and a stress period before harvesting, yields should increase. In order to maintain optimal environmental conditions, inputs into the system must be modulated against the growth rate and the form of the reactor over the time-space of the growth sequence must be carefully designed.

85

86

87

References
Allen, S. (1999). Points + Lines: Diagrams and Projects for the City. New York: Princeton Architectural Press Adamatzky, A. (2010) Physarum machines: computers from slime mold. Hackensack: World Scientific Press Andersen, P. (2010). The architecture of patterns. New York: W.W. Norton & Co. Bonner, J. (2009). The social amoebae : the biology of cellular slime molds. Princeton: Princeton University Press. DeLanda, M. (2009). Material variability and evolvability. In Spuybroek, L. Editor, Research & design: the architecture of variation (pp. 10-17). Thames & Hudson DeLanda, M. (2011). Philosophy and simulation : the emergence of synthetic reason. New York, NY: Continuum. Easterling, K. (2005). Enduring innocence: global architecture and its political masquerades. Cambridge, Mass: MIT Press. Epstein, I. (1998). An introduction to nonlinear chemical dynamics : oscillations, waves, patterns, and chaos. New York, NY: Oxford University Press. Harvey, D. (1990). The condition of postmodernity. Blackwell Hensel, M., Menges, A., (2008) Inclusive performance: Efficiency versus effectiveness towards a morpho-ecological approach for Design. In Hensel, M. Editor, Versatility and Vicissitude: Performance in morpho-ecological design. London: Wiley. Hensel, M., Menges, A., Sunguroglu, D. (2008). Material Performance. In Hensel, M. Editor, Versatility and Vicissitude: Performance in morpho-ecological design. London: Wiley. Hensel, M., Menges, A., Weinstock, M. (2006) Techniques and technologies in morphogenetic design. London: Wiley Hensel, M., Menges, A., Weinstock, M. (2010) Emergent technologies and design. New York, NY: Routledge. Kwinter, S. (2002). Architectures of time : toward a theory of the event in modernist culture. Cambridge, Mass: MIT Press. Kwinter, S. (2007). Far from equilibrium : essays on technology and design culture. New York: Actar-D. Nakagaki, T., Yamada, H., Tóth, Á. (2000). Intelligence: maze-solving by an amoeboid organism. Nature 407 (6803): 470. Otto, F. (2009). Occupying and connecting: thoughts on territories and spheres of influence with particular reference to human settlement. Stuttgart: Axel Menges.

88

Otto, F., Rasch, B. (1995). Finding form : towards an architecture of the minimal. Stuttgart: Axel Menges. Pitcher, W. (1997). The nature and origin of granite. London: Chapmman & Hall. Reiser, J., Umemoto, N. (2006) Atlas of novel tectonics. New York, NY : Princeton Architectural Press. Saigusa, T., Tero, A., Nakagaki, T., Kuramoto, Y., (2008) Amoebae anticipate periodic events. Hokkaido: Hokkaido University Collection of Scholarly and Academic Papers Turing, A. (1952) Chemical basis of morphogenesis. Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences, Vol. 237, No. 641. (Aug. 14, 1952), pp. 37-72. Weinstock, M. (2010) The architecture of emergence: the evolution of form in nature and civilisation. London: Wiley

89

List of figures
Figure Group 0.1: Satellite images of the Campo de Dalias in 1974, 1987, and 2000. Images from United Nations Environment Programme, retrieved from ftp://edclxs25.cr.usgs.gov/ UNEP/atlas_image_directory/site_172/HighResolution/24jan1974.tif, http://na.unep. net/atlas/webatlas.php?id=172 Figure 0.2: A Typical street in the Campo. From Google Street View Figure 1.1: The peridoic table, representing electrochemical properties. Image from http://upload.wikimedia.org/wikipedia/commons/e/e5/Periodic_table_of_elements_showing_electron_shells.png Figure 1.2: The nuclide chart, representing nuclear stability. Images from International Atomic Energy Agency, found at http://www-nds.iaea.org/relnsd/vcharthtml/ncc.png Figure group 1.3: Lotka-Volterra model of a simple predator-prey relationship. Images from Wikimedia Commons, retrieved from http://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_ equation Figure 2.1: Johnson-Burgee's AT&T building. img190/7685/01postmgrooeditt4iy.jpg retrieved from http://img190.exs.cx/

Figure 2.2: Granite ascent mechanisms. tent/304/1/1/F1.large.jpg

Image from http://sp.lyellcollection.org/con-

Figure Group 2.3: Granite specimens. Images, L-R: 1. from http://upload.wikimedia.org/wikipedia/en/3/34/Various_granites.jpg 2. from http://libraryphoto.cr.usgs.gov/htmlorg/lpb352/land/bes00193.jpg 3. from http://www.geologyrocks.co.uk/system/files/images/DSCN2937.jpg Figure 2.4: Remarkable Rocks, Kangaroo Island, Australia. From http://geo-sites.zoomshare.com/ files/remarkable-rocks-sa3.jpg Figure 3.2: The Belousov-Zhabotinsky reaction pathway. From http://upload.wikimedia.org/wikipedia/commons/d/de/BZGraphScheme.png Figure 3.4: Andrew Witkin's instrumentalization of RD systems. From http://img.artknowledgenews.com/files2009a/Witkin_Reaction_Diffusion_Textures.jpg Figure 4.1: Discoideum dictyostelium. From http://genomics.nimr.mrc.ac.uk/online/resources/ dicty-development.jpg Figure Group 4.2: Physarum polycephalum. 1. From http://3.bp.blogspot.com/_6dWrARvFLx4/TR_n2aQ0iJI/AAAAAAAACGU/Sl3riMf1pzg/ s1600/PICT0065.JPG 2, 3. From http://www.designundersky.com/storage/blog-images/2010/january-2010/slimein-transit/slime_mold3.jpg?__SQUARESPACE_CACHEVERSION=1264133539464 Figure Group 4.3: Physarum locomotion speed relative to periodic environmetal stimulus From Saigusa et al (2008). Amoebae anticipate periodic events. Hokkaido: Hokkaido University Collection of Scholarly and Academic Papers

90

Figure 4.4: A large wild physarum plasmodium. From http://174.132.159.253/~jfrazer/wp-content/uploads/2010/03/flickr_plasmodium1.jpg Figure Group 5.1: String binding simulation study. Author Figure Group 5.2: Wet thread physicals models. From Otto, Finding Form, p69 Figure Group 5.3: String binding with extrinsic repulsion. Author Figure Group 5.4: Appearance of emergent nodes. Author Figure 6.1: Ferrofluid in a simple magnetic field. Author Figure Group 6.2: Ferrofluid in complex fields. Author Figure Group 6.3: Complex geometry and simple control points. Author. Figure 6.4: Detail. Author. Figure 6.5 Detail.. Author. Figure 7.1: Form-finding model for Munich Olympic Stadium. From Otto, Finding Form, p107 Figure Group 7.2: Mannheim Multihalle. From From Otto, Finding Form, pp. 138-142 Figure Group 7.3: Catenary models. From From Otto, Finding Form, pp. 61, 136, 137 Figure Group 7.4: Formation of the Downland Gridshell. From Dickson, M., Harris, R., Kelly, O. Construction of the Downland Gridshell. From http://www.istructe.org/branch/southern/ pictures/diary/Weald_and_downland_structures_paper_with_pics.pdf Figure 8.1: Shell studies using fabric simulation. Author Figure 8.2: Complex manifold modelled with simulated fabric. Author Figure Group 8.3: Gridshell design tool study. Author Figure Group 9.1: Responsive surface structures: pinecones and veneer component. From Versatility and Vicissitude, p. 39 Figure 9.2: Veneer components assembled into a self-supporting shell. From Versatility and Vicissitude, p. 41 Figure Group 10.1: A modular formal system using spherical magnets. Author. Figure Group 10.2: Magnetic lattice study 1. Author. Figure Group 10.3: Magnetic lattice study 2. Author. Figure Group 10.4: Magnetic lattice study 3. Author. Figure 11.1: Crozier Dairies, Namao Alberta, satellite photo. From Google Maps. Figure 11.2: Schematic analysis of bioenergy productive capacities of a 500 cow dairy. Author. Figure Group 11.3: Generative adjacency schemes using spring-particle networks. Author. Figure 11.4 Schematic dairy farm plan derived from generated adjacency scheme. Author. Figure 11.5 Schematic dairy farm 3D view. Author Figure 11.6 Schematic dairy farm 3D view. Author Figure Group 12.1: Cellular spatial subdivsion using force-directed graphing and the Voronoi diagram. Author. Figure Group 12.2: Cellular spatial subdivsion using force-directed graphing and the Voronoi diagram. Author

91


