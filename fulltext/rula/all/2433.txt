Magnetic Resonance Image Segmentation and its VHDL Implementation
by

Zheng Wei LI

A project presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Engineering In the Department of Electrical and Computer Engineering

Toronto, Ontario, Canada, 2005 © Zheng Wei LI 2005
PROPEFTY0F RYER90N d W V m iT Y U8RAHY

UMI Number: EC53043

All rights reserved INFORMATION TO USERS

The quality of this reproduction is dependent upon the quality of the copy submitted. Broken or indistinct print, colored or poor quality illustrations and photographs, print bleed-through, substandard margins, and improper alignment can adversely affect reproduction. In the unlikely event that the author did not send a complete manuscript and there are missing pages, these will be noted. Also, if unauthorized copyright material had to be removed, a note will indicate the deletion.

UMI
UMI Microform EC53043 Copyright 2008 by ProQuest LLC All rights reserved. This microform edition is protected against unauthorized copying under Title 17, United States Code.

ProQuest LLC 789 East Eisenhower Parkway P.O. Box 1346 Ann Arbor, Ml 48106-1346

Borrow List
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

Name

Address

Signature

Date

Ill

Magnetic Resonance Image Segmentation and its VHDL Implementation
Zheng Wei LI Master of Engineering Electrical and Computer Engineering Department Ryerson University 2005 Abstract
From experiments, it is shown that the Co-occunence matrix for one still MR] brain image does not provide enough information for segmentation. The 6D Co-occurrence image segmentation idea for 3D MRI image is modified and implemented in 2D MR] image segmentation. That idea is to take two or three images as input at the same time and then process them with 3D Co-occurrence matrix. With this kind o f processing a lot of information was brought into the Co-occurrence matrix, which is enough to segment the images. To compare the result, some other segmentation ideas were tested in this project. From the results, it can be seen that the MRI image segmentation based on the Co occurrence texture analysis with two images or three images sampling is practical and the result is satisfying. The segmentation is simulated in MATLAB. After the simulation, the segmentation is implemented in FPGA using VHDL. MODELSIM is used for FPGA functionality simulation. The result is close to the MATLAB simulation. This makes it possible to implement the system with FPGA hardware.

K eyw ord s: MRI, image segmentation, Co-occurrence, texture analysis, FPGA, VHDL.

IV

ACKNOWLEDGMENTS
I would like to bring my sincere thanks to my supervisor Prof. Lev Kirischian for helping me accomplish my studies in RYERSON. His broad knowledge and rich engineering experience gave me great help during my studies. I will memorize his kindness and professional engineering ethics forever. I need thank all the faculty and staff o f the Electrical and Computer Engineering Department. It is their hardworking attitude and innovative intelligence that lead this department to a better and better tomorrow. The special thanks also need give to my wife and my lovely daughter for their complete support for my work and study.

TABLE OF CONTENTS
Page

LIST OF FIGURES LIST OF TABLES LIST OF ACRONYM S Chapter 1 1.1 1.2 1.3 1.4 2 2.1 2.2 2.3 2.4 3 P R O JE C T IN T R O D U C T IO N M otivation O bjective o f The Project and A pproach Original Contribution Thesis Organization

ix xii xiv

1 1 2 3 4

T H E O R Y O V E R V IE W AND R E L A T E D W O R K S 5 Im age Segmentation and its Applications 5 Texture Analysis and Co-occurrence M atrix Based Texture Analysis 7 General Image Processing System 9 10 Related Works D E V E L O P M E N T O F T H E C O -O C C U R R E N C E M A T R IX BASED IM A G E S E G M E N T A T IO N 13 SY STEM 13 Algorithm Six-Dimensional Co-occurrence Matrix 13 Three-Dimensional Co-occurrence Matrix 15 The City Block Distance Histogram o f Samples And 16 Controls o f Image 21 City Block Distance M apped Image 23 Applications on Different M aterials The Application on M aterial w ith Strong Texture 23 Pattern
VI

3.1 3.1.1 3.1.2 3.1.3 3.1.4 3.2 3.2.1

3.2.2 3.3 3.3.1 3.3.2 3.3.3

The Application on M aterial without Strong Texture Pattern The Specific Approach for MRI Brain Image The Result Based On Two Input Images The Feature Vector Analysis The Result Based on Three Input Images

24 25 26 30 33

4

IMPLEMENTATION OF THE MRI IMAGE SEGMENTATION WITH HARDWARE DESCRIPTION LANGUAGE
Block Diagram o f Algorithm Implementation In FPGA Using VHDL The Implementation o f Co-occurrence M atrix Calculation The Feature Vector and LI Distance Calculation Implem ented W ith VHDL The SRAM Module for Data Input and Output The Register M odule for D ata Delay and Address Delay Test Bench Design for Simulation Input Data Preparation and Organization Output Data Organization Timing Analysis of Control Signals

36
37 39 47 52 55 56 55 58 59

4.1 4.2 4.3 4.4 4.5 4.6 4.6.1 4.6.2 4.6.3

5

RESULT COMPARISION, ANALYSIS AND CONCLUSION

64 68
I I I II II

References
APPENDICES APPENDIX APPENDIX APPENDIX APPENDIX A1 ; DEVICE UTILIZATION SUMMARY FOR XC2V2000 A2: TIMING REPORT FOR DEVICE XC2V2000 A3 : DEVICE UTILIZATION SUMMARY OF XC2 V4000 A4; TIMING REPORT OF DEVICE XC2V2000

Vll

APPENDIX APPENDIX APPENDIX APPENDIX APPENDIX APPENDIX APPENDIX APPENDIX

B : MATLAB PROGRAMS B1 : MAIN PROCESSING PROGRAM B2: PROGRAM FOR CO-OCCURRENCE CALCUALTION B3 : PROGRAM FOR IMAGE REDUCTION B4: PROGRAM FOR ENTROPY CALCULATION B5: PROGRAM FOR ENERGY CALCULATION B6: PROGRAM FOR CONTRAST CALCULATION B7: PROGRAM FOR INVERSE DIFFERENCE MOM ENT CALCULATION APPENDIX B8: PROGRAM FOR MAXIMUM PROBABILITY CALCULATION APPENDIX B9: PROGRAM FOR CORRELATION CALCULATION APPENDIX BIO: PROGRAM FOR CONTRAST CALCULATION APPEND IX C: PROGRAM TO TRANSFORM IMAGE DATA INTO DATA FILE FOR VHDL TESTBENCH APPENDIX D: PROGRAM TO DISPLAY VHDL TESTBENCH RESULT APPEND IX E: VHDL TESTBENCH PROGRAM

III III XVI XVIII XVIII XIX XIX XX XX XXI XXII

XXII

XXIII XXV

Vlll

LIST OF FIGURES
Figure 2-1 Sample of Image Segmentation Figure 2-2 Images with Strong Texture Pattern Figure 2-3 Images with Less Texture Pattern Figure 2-4 General Pattern Recognition System Figure 3-1 MRI Images Figure 3-2 Samples of Material a Figure 3-3 Samples o f Material b Figure 3-4 Samples o f Material c Figure 3-5 The LI histogram of samples and controls for image Figure 3-6 LI distance mapped image o f 3-1 (a) Figure 3-7 RAW Image Figure 3-8 LI Distance Mapped Image o f Figure 3-7 Figure 3-9 Application on Image with Strong Texture Figure 3-10 Segmented Result Based on One Input Image Figure 3-11 Samples Taken From Two Input Images Figure 3-12 (a) The Segmented Image With Different Gray Levels Figure 3-12 (b) The Segmented Image With Different Colors Figure 3-13 The Result Based On Two Input Images Figure 3-14 The Third Original Image Figure 3-15 Sample of Material a From 3 Images Figure 3-16 Sample of Material b From 3 Images Figure 3-17 Sample of Material c From 3 Images 6 7 7 9 16 17 17 17 21 22 22 22 23 24 26 28 29 29 30 31 31 31

ix

Figure 3-18-A The Feature Vectors of Three M aterials Figure 3-18-B Three Images Based Feature Vector Histogram Figure 3-19 the segmented image with 3 samples from 3 original images Figure 3-20 Segmented Brain Image Figure 4-1 Block Diagram of Algorithm Implementation in Hardware Platform Using VHDL Figure 4-3 Diagram o f Data Concatenation Figure 4-4 Simulation Result o f Data Concatenation Figure 4-5 Addresses Accumulation Figure 4-6 Co-occurrence Calculation Figure 4-7 Co-occurrence Simulation Result Figure 4-8 One Dimension Data Array Figure 4-9 M atrix Version o f Figure 4-3 F igure 4-10 Tum ing Points Figure 4-11 The Final Result o f Co-occurrence M atrix Figure 4-12 The Co-occurrence Matrix o f 5x15 Image Input Block Figure 4-13 Feature Calculation

33 33 34 34

38 41 41 42 43 44 44 44 46 47 48 50 51 52 53 54 54 55 55

Figure 4-14 LI Distance Calculation Figure 4-15 W rite Operation o f Input Block RAM Figure 4-16 The Read Operation o f Input Block RAM Figure 4-17 Co-occurrence Matrix Ram Write Operation Figure 4-18 Read Operation o f Co-occurrence M atrix Figure 4-19 Input Data Delay Figure 4-20 Address Delay

Figure 4-21 The Control Signals o f Co-occurrence Matrix Calculation Figure 4-22 Feature Vector and LI Distance Calculation Control Signals Figure 4-23 The Overview o f All The Simulation Waveforms Figure 5-1 FPGA Based Segmentation Simulation Result

60 61 62 65

XI

LIST OF TABLES
Table 2-1 (a) 4x4 Image M atrix Table 2-1 (b) Sample O f Co-occurrence M atrix Table 3-1 4x4 Sample Block Table 3-2 Uniformed Image Block Table 3-3 The Co-occurrence Matrix o f table 3-2 Table 3-4 Average Co-occurrence Matrix o f Sample a Table 3-5 Average Co-occurrence Matrix o f Sample b Table 3-6 Average Co-occurrence Matrix o f Sample c Table 3-7 Feature Vector o f Material a Table 3-8 Feature Vector of Material b Table 3-9 Feature Vector o f Material c Table 3-10 Average Co-occurrence Matrix o f Sample a (Figure 3-11) Table 3-11 Average Co-occurrence Matrix o f Sample b (Figure 3-11) Table 3-12 Average Co-occurrence Matrix o f Sample c (Figure 3-11) Table 3-13 Feature Vector o f Material a Table 3-14 Feature Vector o f Material b Table 3-15 Feature Vector o f Material c (Figure 3-11) (Figure 3-11) (Figure 3-11) 8

8
17 18 18 19 19 19 20 20 20 26 27 27 27 28 28 31 31 32 32 32

Table 3-16 Average Co-occurrence Matrix o f Material a (Figure 3-15) Table 3-17 Average Co-occurrence Matrix o f Material b (Figure 3-16) Table 3-18 Average Co-occurrence Matrix o f Material a (Figure 3-17) Table 3-19 Feature Vector o f Material a Table 3-20 Feature Vector o f Material b (Figure 3-15) (Figure 3-16)

XU

Table 3-21 Feature Vector o f Material c (Figure 3-17) Table 4-1 Addresses Accumulation Table 4-2 Co-occurrence Matrix Result Table 4-3 The Right Co-occurrence Matrix Table 4-4 The Co-occurrence Matrix o f 5x15 Image Input Block Table 5-1 Comparison between PC based System and Hardware Based System

32 42 43 46 48 66

xui

LIST OF ACRON Y M S
FPG A ----- Field Programmable Gate Array M RI 2D M agnetic Resonance Image ------ 2 Dimension

3D ------- 3 Dimension RA M ------Random Access Memory SRAM -- Static Random Access Memory PC............ Personal Computer DSP------- Digital Signal Processing IIG GA D-- Intensity(i), Intensity(k), Gradient magnitude(i). Gradient magnitude(k), Angle and Distance HD--------- Intensity(i), Intensity(k), and Distance L I D istance-- City Block Distance IDM ------- Inverse Difference M oment M P---------M aximum Probability

XIV

CHAPTER I PROJECT INTRODUCTION
1.1 Motivation
In recent years, the achievements in semiconductor have made it possible to implem ent some very complex algorithms into hardware. One o f the greatest achievements is the Field Programmable Gate Array (FPGA) technology. Nowadays, there are more and m ore logic resources in FPGA, its lower price and higher capacity and especially its unique architecture has encompassed a lot of aspects of digital image and video processing. Its high speed has made it possible to do real-time image and video processing. The rapid prototyping character o f FPGA also gives the engineers great help in changing the design flexibly. Its platform character also brings the flexibility to test multiple algorithms without wasting time on multiple hardware platforms. For more than one century, scientists and engineers have been and continue trying to create the "intelligent machine". The computer is one o f such machines. Digital Image Processing, Digital Audio Processing and Digital Video Processing are all the research subjects. At the same time the computer system engineers are trying to implement the newest algorithm with the most advanced technology. Among the targets the scientists and engineers are searching for, the visibility is one of the most important one. With visibility, the machine can recognize the object. The development o f this kind o f technology has been widely used everywhere, such as the vehicle plate recognition system, finger print recognition system.

In such systems, partial "machine vision" functions are implemented. In these systems, image segmentation is one o f the very important steps for a machine to recognize the target. So it has always been an interesting and important subject for engineers to implement the new segmentation methods with the cutting edge technology. Driven by the same purpose, in this project, the Co-occurrence matrix based image segmentation is simulated in MATLAB and implemented in FPGA.

1.2

Objective of The Project and Approach
Image segmentation is an important and perhaps the most difficult low-level task

[I]. Its application is widely spread into almost everywhere o f image processing. The target of this project is: 1. To create a new segmentation algorithm with the texture analysis technique and implement it on hardware platform (FPGA card) using VHDL Language. The application is on the Magnetic Resonance Image (MRI). The 2 Dimensions (2D) Co occurrence matrix based image segmentation algorithm will be altered to fit the MRI image. 2. The algorithm will be verified by simulation in MATLAB. The result from MATLAB will be compared with some traditional ways of image segmentation. 3. The VHDL implementation and simulation for FPGA based platform. Because o f the natural difference between computer based MATALB simulation and hardware based ModelSim simulation, the results were compared. The speed, cost is different between the computer based system and FPGA based system. VHDL is hardware description language, so it is hardware oriented, so a lot o f functions such as division and logarithm in MATLAB need a lot o f logic resources in FPGA. So the implementation in

FPG A is quite different with its counter part in MATLAB. Some im plem entation techniques will be emphasized in this project.

1.3

Original Contributions
Texture feature analysis has been extensively used in image analysis. The 2D

texture analysis has been studied pretty well. 1. There are a lot o f discussions about 3 Dimensions (3D) texture analysis also [8]. The 2D Co-occurrence matrix is useful to do texture analysis. The Co-occurrence m atrix based image segmentation is quite effective. As it can be seen, the MRI image does not have too m uch texture information inside. But is it possible to do the segmentation with the texture analysis based Co-occurrence matrix? In this project, such a segmentation idea is presented and verified. 2. As it is recognized in the engineering field, there is always a distance between the theoretical result and practical performance. It means it is not always possible to implem ent the theoretical simulation with real hardware. So in this project, the C o occurrence matrix based image segmentation is implemented in FPGA with VHDL and its result is compared with the MATLAB simulation result. Some ideas o f implementation such as Co-occurrence matrix calculation, logarithm calculation are implemented, tested and presented. 3. In this project, MATLAB and M ODELSIM FPGA simulation are connected by the design o f test bench. This is useful for further studies and research.

1.4

Thesis Organization
This thesis has six chapters and two appendices. A brief introduction is held

in the first chapter. The motivation, objective and approach will be presented in this chapter. The second chapter is theory overview and related works. Image segmentation theory and texture analysis and Co-occurrence matrix is discussed here. The general image processing system is introduced in this chapter also. The related works and some precedent studies and applications are in this chapter. Chapter three is "Development of the Co-occurrence M atrix Based MRI Image Segmentation System" . In this chapter, the whole process of the IID Co occurrence Matrix based segmentation method is described. The simulation result from MATLAB is provided and analyzed. Chapter four provides the FPGA implementation process of the

segmentation method discussed in previous chapter. The comparison between FPGA and MATLAB based simulation is presented. Different hardware modules described by VHDL is also discussed in this chapter. Chapter five is result comparison and analysis. The conclusion and future work will be addressed in this chapter also. The MATLAB simulation program will be provided appendix A and VHDL simulation program will be provided in appendix B, C, D. Appendix E will provide the LUT for calculations.

CHAPTER II THEORY OVERVIEW AND RELATED WORKS
2.1 Image Segmentation and its Applications
As mentioned in the introduction part, image segmentation is a very difficult low level task. Image segmentation has been extensively used everywhere o f image processing, such as image compression, image retrieval, object recognition. Basically the image segm entation process is defined as one that partitions a digital image into disjoint (non overlapping) regions [2]. It refers to the grouping o f image elements that exhibit "sim ilar" characteristics [1], Since seventies scientists have researched on the 2D image

segmentation. Till now some mature and practical ideas have been developed and proved like the image segmentation by thresh-holding (global thresh-holding, adaptive threshholding, optimal threshold selection), gradient-based segmentation methods, detection and linking. All these ideas are belong to edge region

approach, boundary approach and edge approach respectively.

The region approach

attempts to assign all the pixels to different particular object or region, like the histogram techniques. If the algorithm tries to locate the boundaries that exist between the different regions, it is called boundary approach, like the gradient image THRESHOLDING and LAPLACIAN Edge Detection. The edge approach is between the region approach and

boundary approach. It tries to identify the pixels on the edge, it means the pixels between the different regions. After the pixels are identified, it will be linked to form the boundary. Recent years, a lot o f new algorithms have been created, like the 3D Co-occurrence matrix based image segmentation relies on the texture pattern o f the object, the segmentation using

genetic and hybrid search method [3] and the brain tissue segmentation based on Gegenbauer reconstruction pre-processing [4], Figure 2-1 is one sample of image segmentation. 2-1(a) is the original image and 2-1 (b) is the segmented image. This sample is segmented by the region approach.

(a) Original Image (14)

(b) (Segmented Image (15)

Figure 2-1 Sample of Image Segmentation Because image segmentation is a low-level task, so its applications have been widely spread everywhere of image and video processing such as image coding and content-based retrieval [20], feature extraction, recognition and extraction. In the real world, with the fast development o f the micro-electronics technology, the application o f the segmentation based image processing system is becoming deeper and wider. The vehicle plate recognition system can be seen on the high way and the apartment building. The high end industrial inspection system can be found in all kinds o f industries.

2.2

Texture Analysis and Co-occurrence Matrix Based Texture Analysis
Texture analysis has drawn a lot of attention in the passing decades. With

the different texture type and the specific image analysis problems, texture analysis can be found in a lot o f applications. Figure 2-2 is some pictures with strong texture pattern in them. The picture on the left side is some kind o f fabric and the picture on

â

«

Fabric [16] Pebble Wall [17] Figure 2-2 Images with Strong Texture Pattern the right side is an image o f a pebble wall. Figure 2-3 is some pictures with less texture pattern in them. The picture on the left side is the research subject o f this

Figure 2-3 Images with Less Texture Pattern [18] project, the M RI brain image. The picture on the right side is the picture of the Mars taken by the Mars Pathfinder. The tissue characteristic on the above four images are all different. So the ways to segment these images are different. For images with

strong texture information, the texture analysis is needed for segmentation. Among the different texture analysis techniques, Co-occurrence matrix is a special one. Haralick et al. [5] and Gallow ay [6] suggested the gray level Co-occurrence m atrix and run length matrix and they have been extensively used in texture classification and segmentation. The successful synthesis of textures motivates the use of Co-occurrence as features for texture classification [9]. Table 2-1 is one sample of the Co-occurrence Matrix. Table 2 - 1(a) is a 4x4 image matrix, the gray level is from 0 to 3. Table 2 -1(b) is the Co-occurrence Matrix of 2-1 (a) with distance 1 and direction 0 degree. Each element in Table 2-1 (b) shows the occurrence rate of the gray-level at distance 1 and direction 0. For example, the "2" (shaded) means that it happens twice from gray-level " 1" to gray-level "2", which is exactly what happened in Table 2-1 (a).

Table 2-1 (a) 4x4 Image Matrix 1 3 1 2 1 3 2 1 3 3 0 2 0 3 1

Table 2-1 (b) Sample of Co-occurrence Matrix 0 1 . 0 1 1 1 1 0 0 2 1 0 0 1 1 3

A s it can be seen from Table 2-1, the Co-occurrence M atrix is to identify the occurrence rate o f each gray level at certain distance and direction. Obviously it is a very good tool for texture analysis.

2.3

General Image Processing System
M ost o f the image processing system has some common parts like image capture,

image segmentation and feature extraction, classification and recognition.

Input

Image Segmentation

Segmented Image

Feature Vector
[xl, x2, x3...Xn]

Recognition

Classification

Figure 2- 4 General Pattern Recognition System A general image processing system, or more specifically the pattern recognition system was presented in Figure 2-4. As we can see from the above model, image segm entation process plays a fundamental role in all the subsequent interpretation process, like image retrieval, pattern recognition, and feature analysis. The image processing system can be divided into two categories. The first category is the PC based image processing system, which will process the image with software. The second category is the hardware based system. Normally the hardware based

system is better in cost, processing speed and size. In this project, the MATLAB simulation can be considered as the PC based image processing system and the VHDL implementation is developed towards the direction o f hardware based system.

2.4 Related Works
As it is mentioned in previous chapters, image segmentation is very important. So this subject has been extensively studied. A lot o f traditional ways o f image segmentation are based on gray-level thresh-holding, image gradient or edge detection and linking. A lot o f new algorithms are appearing and seem to be effective, like the "Adaptive Image Segmentation Based on Color and Texture" [11] proposed by Jinqing Chen from ECE department of Northwestern University and Aleksandra Mojsilovic from IBM research centre. The adaptive algorithms are gradually taking more places nowadays. Bir Bhanu from University o f California presented the adaptive genetic way of segmentation in

"Adaptive Image Segmentation Using Genetic and Hybrid Search Methods" [3]. Haralick et al. [5] and Galloway [6] suggested the gray level Co-oceurrenee matrix and run length matrix and they have been extensively used in texture elassification and segmentation. Gabriele Lohmann used the Co-occurrence matrix as the tool o f texture analysis and synthesis in "Analysis and synthesis of Textures: A Co-oceurrenee-Based Approach". Vassili etc presenting a new method o f MRI texture analysis using Cooccurrenee matrix. That method is based on extended, multi-sort Co-occurrence matrices that combine intensity, gradient and anisotropy image features in a systematie and consistent way. This method has pushed the application o f Co-occurrence matrix to a new

10

high point. That also means the hardware realization o f the algorithm will be too expensive, that makes it impossible to do it with current technology. There are different ways to implement the segmentation algorithms. Since the com puter was invented, people have been using it as the implementation tools, especially now days when computers are becoming more and more powerful. The algorithm can be program m ed by different languages such as C++, Basic, Java or M ATLAB. But no m atter which program to use, there is always a computer, which is too big in size and too expensive in cost and also comparably slow in speed. Because this type of implementation always needs to be programmed, so it is called software based. So when real-time processing is in need, the hardware based implementation is always the first choice. The hardware based systems are also different by the hardware it uses. For some small system, the micro-processor based embedded system is normally used. Before the Field Programmable Gate Array (FPGA) technology became powerful enough, the Digital Signal Processing (DSP) based system was very popular. One sample o f this system is developed by V.Gemignani etc. in "Real-Time Implementation o f A new Contour Tracking Procedure in a M ulti-Processor System" [12]. With the development o f the FPGA technology towards the direction of larger capacity, faster speed, much more flexible configuration, the FPGA based system is becoming more and more popular. Some system is based on DSP+FPGA combination. A lot o f systems are based on FPGA only. Mr. Steffen Klupsch presented a typical system in [13]. A very important feature o f FPGA is so called "rapid prototyping". The engineers can have the hardware prototype in hand at the beginning stage o f the project, but there still leaves a lot more space for them to change the

11

design or even the methodology without changing the hardware, because that type o f job can be done in VHDL.

S u n i i n a . r y ! B rief description o f image processing and segmentation theory. The general image processing system is discussed. The implementation with PC and hardware were compared in this chapter. The related works and precedent studies were presented in this chapter.

12

CHAPTER III DEVELOPMENT OF THE CO-OCCURRENCE MATRIX BASED IMAGE SEGMENTATION SYSTEM Introduction:
This project is trying to find a way to segment the 2D MRI image with CoOccurrence matrix. As it is known the Co-occurrence matrix has been widely used in image texture analysis, but the application in image segmentation be can rarely seen. One simple reason is that there is no obvious texture structure in MRI brain image (this is proved through experiment in this project). From the paper o f Vassili A. Lovalev al. [8], some innovative ideas for the Co-occurrence m atrix's application in the 3D M RI image is brought up. Could the same idea be used on the 2D image? How and what to modify and then improve it to fit the 2D MRI brain image segmentation? Is the result acceptable? In this project all these questions were answered.

3.1

Algorithm
As discussed in previous chapter, the six dimensional Co-occurrence matrix

Segm entation has to be modified to fit the 2D image. This section will focus on this.

3.11

Six-D im ensional Co-occurrence M atrix
I f given a direction and a distance (one pixel, two pixels, etc) in an image. Then

the elem ent

o f the Co-occurrence matrix P for an object is the num ber o f times, divided

13

by M, that gray levels i and J occur in two pixels separated by that distance and direction in the object, where M is the number o f pixel pairs contributing to P. The matrix P is (NxN), where the gray scale has N shades of gray. Once there is the Co-occurrence matrix, texture features can be computed from it. The author of [8] proposed a new 3D texture analysis of magnetic resonance imaging brain datasets. It is based on extended, multi-sort Co-occurrence matrices that employ intensity, gradient and anisotropy image features in a uniform way [8].This idea does not change the basic ideao f Co-occurrence, but increase the sensitivity and specificity of Co occurrence descriptors. And the new extended 3D Co-occurrence idea has the rotation and reflection invariance, which is very important to the texture analysis of the MRI image. According to this article, if we have an arbitrary voxel (voxel is the element of the 3D image) pair (/, k) defined on discrete voxel lattice by voxel indexes i = ( x - , y . , Z j ) ,
k =

and with the Euclidean distance d { i , k ) . The intensities o f these voxels are

/(i)a n d I { k ) , local gradient magnitudes by G{i ), G( k) , and the angle between their 3-D gradient vectors by a{i,k). Then the general, six-dimensional (6D) Co-occurrence matrix is defined as [8]
W =\ \ w{I{i ), I{k), G{i), Gi k), ai i, k), d{i , k)\ \

(1)

G(i) = ^G^Ai) + G l i i ) + G^[i)
a{i,k) = cos ~' { g{ i ) »g{ k) )

(2) (3)

Equation (1) is consisted o f "Intensity (1), Intensity (k), Gradient (I), Gradient (K), Angle (1,K) and Distance (I, K). So this kind o f Co-occurrence matrix like (1) is called IlGGAD

Matrix [8], it is a 6D matrix.

14

3.1.2 Three D im ensional Co-occurrence M atrix
From IIGGAD, some reduced versions o f the above IIGGAD matrix, such as intensity (IID), gradient magnitude (GGD) and gradient angle (GAD) matrices can be derived [8], As the author mentioned, the IID version o f the IIGGAD matrix is the simple 3-D version o f the traditional Co-occurrence matrix. And in this project, this version will be used to segment the 2-D MRI image. There are several mature texture features based on this IID Co -- Occurrence [8]. (P is the Co-occurrence m atrix element) ENTROPY:

=
i=l y=l

(4)

INERTIA:

^=

(5)

ENERGY:

^ =
i=l /=l

(6)

CONTRAST:

C=

/=: y=| '

I z -jlR . ^ I J

C)

INVERSE DIFFERENCE M OM ENT (IDM):
V N

/=i y=i M AX IM U M PROBABILITY

MP = MAX{P.^)
CORRELATION:

(9)

( 10)

where x and y are elements o f the Co-occurrence matrix.

15

According to [8], LI distance (City Block Distance) is needed to classify RO l (region o f interest) or AOI (area o f interest) and the background, "sample" is for ROI and "control" is for background in this project. LI distance is defined as follow:

----------i= l (=1

( 11 )

FTM, F "are vectors of Co-occurrence feature descriptor for samples and controls, they are made up by the features like ENTROPY, ENERGY, CONTRAST, INVERSE

DIFFERENCE MOMENT (IDM) and MAXIMUM PROBABILITY (MP).

3.1.3 The City Block Distance Histogram of Samples and Controls of Image
The target for this project is to segment the different tissues in the MRI images based on their different texture character. In order to have a more straightforward idea about this project, here is the brief introduction of the original image used in the test. Figure 3-l(a)

Figure 3-1 MRI Images (Courtesy o f the Biomedical Engineering Research Group of Ryerson University)

(a )

0)

16

and Figure 3-1 (b) are both 256x256 MRI image. Both images have 256 gray levels. Figure 3-7 is another image with 256 gray levels. The purpose of getting different sizes and

different types o f images is to check if there is any difference in the segmentation results. A t the beginning o f this project, one o f the tissues in the image was used as sample and the other as controls (background). Nine samples were taken from the ROI and

Figure 3-2 Samples of M aterial a

Figure 3-3 Samples of M aterial b

Figure 3-4 Samples of M aterial c also from backgrounds. Figure 3-2, 3-3 and 3-4 are the samples o f materials a, b and c respectively. The samples are taken by 4x4 block, so there are 16 pixels in one sample. The images shown in Figure 3-2, 3-3 and 3-4 are enlarged 7.5 times to be visible. All the sample images have to be uniformed before the calculation o f Co-occurrence matrix. As it is m entioned before, the raw image has 256 gray-levels. If the image is not uniformed, there w on't be any useful information in the Co-occurrence Matrix. Table 3-1 shows a 4x4 Table 3-1 4x4 Sample B ock 180 27 94 67 197 250 29 78 90 125 34 56 27 94 32 67

17

image block. The Co-occurrence matrix of this block will be a 256x256 matrix, most o f its elements will be "0" except at location (180, 197), (197, 90), (90, 27), (250, 125), (125, 94), (94, 29), (29, 34), (34, 32), (67, 78), (78, 56), (56, 67), there is a " 1" at these locations. But even these " l "s are so sparse, there w on't be enough information for processing. If the 4x4 block is uniformed by reducing the gray-level to 4: 0-- 63->0, 64-- 127->1, 128-- 191-^2, 192-- 2 5 5 ^ 3 the uniformed image shows in Table 3-2. Table 3-2 UnilTtrmed Image Block 3 0 1 0 3 3 0 0 1
1 0 0

0 2 0 0

]o-occurrence Matrix of Table 3-2 at distaiice " 1" and dii Table 3-3 The Co-occurrence Matrix o f ' fable 3-2 5 2 0 0 0 0 0 2 0 1 0 0 1 0 0 1

The Co-occurrence matrix o f the reduced image has more useful information. From the samples shown above in Figure 3-2, 3-3 and 3-4, the Co-occurrence matrix o f each sample block can be calculated after reducing them into 4 gray-levels. Then the values of the corresponding elements of the 9 Co-occurrence matrixes are added together, then

18

divided by 9, the average Co-occurrence matrix for all sample ROI can be calculated as shown in Table 3-4, 3-5, 3-6, for m aterial a, b and c respectively. Table 3-4 Average Co-occurrence M atrix o f Sample a 3.0000 1.2222 1.1111 0.5556 0.6667 0.7778 0.7778 0.5556 0.7778 0.2222 O. l l l I 1.1111 0.2222 0.2222 0.3333 0.3333

Table 3-5 Average Co-occurrence M atrix o f Sample b 1.7778 0.5556 0.6667 0.1111 0.7778 1.0000 0.5556 0.4444 0 J3 3 3 0.7778 1.2222 0.5556 0.5556 0.4444 0.8889 1.3333

Table 3-6 Average Co-occurrence M atrix o f Sample c 2.2222 1.1111 0 0.2222 0.7778 0.6667 1.0000 0.4444 0.3333 1.0000 1.1111 0.7778 0 0.2222 0.8889 1.2222

Table 3-4 is the average Co-occurrence matrix o f material a. Table 3-5 is the average Co-occurrence matrix o f material b and Table 3-6 is the average Co-occurrence m atrbr o f m aterial c. Each R O I's feature vector can be calculated from the average C o occurrence matrix. Each feature vector consists o f "Entropy", "Energy", etc, defined by equation (4) to (10) respectively. Table 3-7, 3-8, 3-9 is the feature vector list o f m aterial a, b and c.

19

Table 3-7 Feature Vector o f Material a Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability Table 3-8 Feature Vector of Material b Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability Table 3-9 Feature Vector o f Material c Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability

9 0.4129 16.2222 22 5.0864 3

9 -2.5270 11.6296 17.6667 4.6574 1.7778

9 0.1339 13.7531 11.5556 5.8302 2.2222

So LI distance can be calculated from the ROI feature vectors verses the ROI samples' average feature vectors. For the samples of the background, the same thing can be done: get each background sample's feature vector and calculate the LI distance with these feature vectors verses the background samples' average feature vector. To test the effectiveness o f LI distance, 18 LI distances were calculated. The histogram o f the LI distance can be drawn. Figure 3-5 is the LI histogram o f Figure 3-1 (b) The Y axis is the LI distance value. On the X axis, 1 to 9 is the LI distance o f the background samples versus the ROI samples' average feature vectors, 10 to 18 is the LI distance o f the background samples versus background samples' average feature vectors. From this histogram, it can be seen there is very strong difference between the LI distance

20

o f the ROI and background. That means the segmentation can be done based on the Co occurrence matrix.

10

12

14

16

18

20

Figure 3-5-- the LI histogram o f samples and controls for image

3.1.4

L 1 Distance M apped Image
From previous section, it has approved that LI distance is effective to do the

segmentation. Based on that, a 5x5 window is running through the image. Each w indow 's LI distance is calculated (each window's feature vector verses the average ROI feature vector). Different gray levels were assigned to the different LI distance in the new image. The gray level based LI probability map image is shown as below. Figure 3-6 is the LI distance m apped image o f Figure 3-l(a). Figure 3-8 is the LI mapped image o f Figure 3-7. Com paring with the original images, these images show not only the LI distance, but also the segm entation information. The segmentation seems to be well done, but obviously this can not be used as the final segmentation resu lt..

21

Figure 3-6 LI distance mapped image o f 3-1(a) In Figure 3-6 and Figure 3-7, the LI distance mapped image of image 3-6 and 3-8 shows clearly the edges o f the different tissues. But this is not the aim o f segmentation. For

tv

Figure 3-7 RAW Image

Figure 3-8 LI Distance Mapped Image o f Figure 3-7

segmentation, different materials need to be separated clearly with different colors or different gray scales to identify different parts in the image. But for the LI distance, it is

22

very hard to set the different threshold. LI distance mapped image might be used for edge detecting, but it needs more research and studies. So far, it proves LI distance is a very good feature for segmentation, but how to use it becomes a new problem.

3.2

Applications on Different Materials
It seems if the threshold o f the LI distance can be found, the segmentation problem

can be easily solved.

3.2.1

The Application on M aterial w ith Strong Texture Pattern

Co-occurrence matrix well describes the occurrence frequency o f the different graylevels at certain distance and direction, so it should have good segmentation result on images with strong texture. To prove this, one example is given here. As shown in Figure 3-9(a), it is an image with very strong texture infonnation inside. Two types o f samples are

"1

(b) (a) Figure 3-9 Application on Image with Strong Texture

23

taken from the original image, from these samples, the feature vectors are calculated. Then a 4x4 window is running through the image, the feature vector of each block will be used to calculate the LI distance against the two different textures. The smaller LI distance means the current block belongs to that texture with which it is calculating the LI distance. Figure 3-9(b) is the segmented image, the result is satisfactory. So the next step is to apply this technique on the images without strong texture information.

3,2.2

The Application on Material without Strong Texture Pattern
Section 3.2.1 proves that the algorithm to be effective on the segmentation for

images with strong texture. But as it is so obvious for us, the MRI brain image datasets do not have very strong texture information inside. What is the result will be if same idea is applied to such images? So for images in Figure 3-1, instead o f taking only two kinds o f samples, three kinds of samples are taken from the original image.

i S

- '

Figure 3-10 Segmented Result Based on One Input Image

24

Three average feature vectors for these three kinds o f samples need to be calculated. And then the running window will go through the image. For each window, first to calculate the LI distance verses all three samples to get three L I distance for each window (or the small image block). Second to look for the least LI for this window, the least LI means this window is very close to that kind o f sample. Then assign different colors or gray levels to this kind o f tissues. After finishing running the whole image, a new segmented image is stocked in a matrix. This image will only have three different colors or three different gray levels. So the purpose o f segmentation is achieved. According to above ideas, segmentation is done in the new programs. The segmentation result is shown in Figure 3-10. Unfortunately, the result is not acceptable. If take a look back at the sampling on the original image, it can be found out that when the samples are taken from one kind o f m aterial, there are almost no useful information in the Co-occurrence matrix o f the samples. The histogram o f theses samples LI distance verses the average feature vectors proves this. From the original concept o f Co-occurrence, it is known that it is obvious that the Co occurrence for this kind o f material is so random and sparse that can rarely provide any useful information. The different tissues taken from the MRI brain image are almost uniform , that means there is not much texture information in it. It will be discussed it in the next section.

3.3

The Specific A pproach for M RI Brain Image
Som ething has to be changed in order to segment the M RI images successfully

with the IID Co-occurrence matrix. After some trial and tests were done, the solution is found.

25

3.3.1

The Result Based On Two Input Images

From the medical knowledge of the MRI brain images, it is known that Figure 3 -l(a) and Figure 3-1(b) are the same images but with different features shown up. With the different feature shown up, these two images have different gray-level at the same spot. That is what the Co-occurrence matrix needs to do the segmentation. This gives a chance to use the Co-occurrence matrix. So this time three kinds of samples will still be taken. A 4x4 sample block is taken from image a, and another 4x4 sample from image b, these two 4x4 block form a 4x8 sample block. Nine such samples for each kind o f materials will be taken in total. Figure 3-10 is the samples taken from two images. The average Co-occurrence matrix can be calculated. From the average Co-occurrence matrix, the average

III
Sample a

Sample b Sample c Figure 3-11 Samples Taken From Two Input Images

feature vector of the three materials will be calculated. The average Co-occurrence matrix is shown in Table 3-10, 3-11, 3-12. able 3-10 Average Co-occurrence Matrix o f Sample a (Figure 3-11-a) 19.8889 0.1111 0 0 0.5556 0.5556 0.3333 0 0.8889 0.5556 1.4444 1.1111 3.6667 0.2222 1.3333 14.3333

26

Table 3-11 Average Co-occurrence M atrix o f Sample b (Figure 3-11-b) 20.0000 0 0 0 0.5556 1.1111 0.4444 0 2.0000 0.5556 5.7778 1.6667 2.4444 0 1.4444 9.0000

able 3-12 Average Co-occurrence M atrix o f Sample c ('Figure 3 -1 1-c) 5.3333 1.8000 0.7333 0.4000 2.2000 5.9333 3.2667 1.0667 0.7333 2.8667 7.9333 2.2667 0.1333 0.6667 2.4667 7.2000

A fter all the feature vectors were got, a 4x8 running window will be used to sample the original images. The LI distance will be calculated verses the three average feature vectors. Once the least L I is found, the current sample block belongs to that kind o f material that calculated the LI distance with. The current block is labeled with different colors or different gray-level into a new image matrix. The segmentation would be done once finish running through the whole image. The average feature vector is shown in Table 3-13, 3-14 and 3-15.

Sample Quantity Entropy Energy Contrast Inverse Difference Moment M ax Probability

9 146.2917 621.4444 41.4444 4.6852 19.8889

27

Table 3-14 Feature Vector of Material b (Figure 3-11-b) Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability Table 3-15 Feature Vector of Material c (Figure 3-11-c) Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability

9 135.4420 531.2716 34.6667 5.4383 20

9 90.3208 219.4533 32.4667 15.7259 7.9333

Figure 3-12 and Figure 3-13 are the segmented images o f Figure 3 -la (or 3-lb). Figure 3-12 is shown with different gray scales and Figure 3-13 is shown as different colors. It can be seen that the image is very well segmented according to their texture structure. Because only 3 samples are taken from the original image and no sample were taken from the black background, so it seems a messy in the area around the brain MRI. But that does not affect our aim o f segmentation the MRI brain image.

Figure 3-12 (a) The Segmented Image With Different Gray Levels

28

Figure 3-12 (b) The Segmented Image With Different Colors The above results are based on the original image from 3 -1(a) and 3 - 1(b). If the two input images are exchanged. The segmentation result is like Figure 3-13. Please notice that the edge o f the image is processed, so it looks better.

1

Figure 3-13 The Result Based On Two Input Images

29

3.3.2

The Feature Vector Analysis

As shown in Figure 3-11. 3-12 and 3-13, the segmented results are acceptable but there is still space for improvements. It seems that the sampling idea used to construct some texture is working well. So if continue to do this with more images, the result should be much better. Another original image is added in the sampling. This time, a 5x5 sampling block is used instead o f 4x4 block. By doing this, only the center point o f each block was set to the level it belongs to. So the final segmented image will be much smoother. The third image is shown in Figure 3-14.

Figure 3-14 The Third Original Image (Courtesy o f the Biomedical Engineering Research Group of Ryerson University) Same as the two input images, for each kind o f material, nine samples are taken firom 3 original images at the same location. Because it is time consuming to take all the samples manually, so the sample capture program is useful here. The 3 samples are shown as Figure 3-15, 3-16 and 3-17

30

Figure 3-15 Sample of M aterial a From 3 Images

Figure 3-16 Sample o f M aterial b From 3 Images

Figure 3-17 Sample o f M aterial c From 3 Images From this three samples, the average Co-occurrence matrix are shown in tables below. Table 3-16 Average Co-occurrence M atrix o f M aterial a (Figure 3-15) 19.8889 0.1111 0 0 0.5556 1.6667 1.8889 0 0.8889 1.6667 18.0000 52222 3.6667 0.4444 1.6667 14.3333

Table 3-17 Average Co-occurrence M atrix of M aterial b (Figure 3-16) 20.3333 0 0 0 2.0000 4.2222 1.1111 0 3.0000 1.5556 11.6667 0.4444 0 1.5556 3.6667 20.4444

31

Table 3-18 Average Co-occurrence Matrix o f Material c (Figure 3-17) 34.3333 3.0000 0 0 3.0000 4.6667 0 0 0 0 0 0.1111 4.2222 0.7778 0.1111 19.7778

Using the above average Co-occurrence matrix, the feature vectors are in Table 3-19,

Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability Table 3-20 Feature Vector of Material b (Figure 3-16) Sample Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability Table 3-21 Feature Vector of Material c (Figure 3-17) Saniple Quantity Entropy Energy Contrast Inverse Difference Moment Max Probability

9 239.1657 978.9383 49.4444 11.8519 1&8889

9 242.7560 1.0181e+003 27 9.9167 20.4444

9 287.9804 1.6282e+003 47.3333 6.8858 34.3333

3-20 and 3-21. Figure 3-18-A is the feature vectors of three different materials. Figure 318-B is the plotting of 5 features of the 3 different samples. On the X axis, 1-9 is sample 1, 9 to 18 is sample 2, 19 to 28 is sample 3. It is obvious that the 3 images based feature vectors are very effective The LI distance is the combination of all the features. The image is segmented based on LI distance.

32

::
1400 § -lO O C I -

M aterial M aterial 5 M aterial C

J

«0

-

600 jlOD 200

°C 2 E n tro p y

JU

16

18

IDM

M a x R /ob

b jlity

Figure 3-18-A The Feature Vectors o f Three M aterials
3 0 0
2000 I 1500

I 8 250, I ·s > .2 0 0

I
1 5 0 .
25

I  a3 0

"140;

Figure 3-18-B Three Images Based Feature Vector Histogram

3.3.3

The R esult B ased on Three Input Images
For each kind o f material, nine samples are taken from 3 original images at the

same location. The sample capture program is used here. This time a threshold was held to filter out the background (pure black), so the final result looks much nicer. A ll the

33

procedures are the same as the previous one. The final segmented image is shown in Figure 3-19. In Figure 3-19 it is clear to be seen that around the brain there are skin and some other stuff. That kind of stuff is not needed in the brain segmentation. If taken out that stuff in this project, the result is shown like Figure 3-20. In order to compare, the gray level is assigned differently.

»

Figure 3-19 the segmented image with 3 samples from 3 original images

Figure 3-20 Segmented Brain Image

34

From Figure 3-19 and Figure 3-20, a conclusion can be drawn. The result with sam pling from 3 images is much better than the one with sampling from two images. The m aterials are almost clearly segmented. That proves the idea o f constructing the texture and then using Co-occurrence to analyze the brain image is a practical way.

S u n i n i a , r y ; The whole process o f the development o f the IID based M RI image segm entation system is presented in this chapter. Algorithm m odification was discussed in details. The trial and test approach for the approval o f the algorithm is included in this chapter. The effectiveness o f L I distance and feature vectors is approved. The final result is presented and approved to be effective.

35

CHAPTER IV IMPLEMENTATION OF MRI IMAGE SEGMENTATION WITH HARDWARE DESCRIPTION LANGUAGE Introduction;
One important part of this project is to implement the segmentation algorithm in FPGA using VHDL language. All the simulations in MATLAB in section III of this project can be considered the PC based implementation. In MATLAB, the images are considered as matrixes and MATLAB is pretty good at processing matrixes. The PC based implementation also provides the engineers and researchers very good debugging environment. So at the algorithm development stage, the PC based implementation is necessary and useful. In most of the cases, the implementation has to be on a hardware device. DSP (Digital Signal Processing) device provides a very good solution because some of the DSPs provide floating point calculations, high speed real time processing, etc. With the development of FPGA technology, it's becoming more and more popular in digital signal processing. Its reconfiguring and parallel processing capability is very useful for image and video processing. The FPGA implementation with VHDL is hardware based, so some operations like matrix processing in MATLAB needs a lot of logic resources. A lot of such processing as division, multiplication and logarithm or floating point calculation become quite different in VHDL comparing with their counterparts in MATLAB. In MATLAB, all these

36

calculations can be done in floating point. But in FPGA, these operations are done in fixed point calculations. For sure this will bring some differences to the final result. At the end o f this section, the results are compared with each other.

4.1

Block Diagram o f The Algorithm Implementation in FPGA Using VHDL
Chapter two and three already described the outline o f the theoretical

approach o f the IID based MRI image segmentation. From there, a b rief diagram can be draw n as Figure 4-1. The input data is a 4x4 or 5x5 image block. The average Co-occurrence m atrix o f the input data is calculated. From the Co-occurrence matrix, the feature vectors are calculated. These feature vectors are used to calculate the LI distance with the three different m aterial samples. The feature vectors o f the three different m aterials are predefined. The m inimum LI distance is found that means the current block belongs to this type o f material. Certain gray-level is assigned and the result is stored and output for display.

In this project. Block Random Access Memory (BRAM) module and Shift R egister module are used for implementation. The input data is loaded from the harddrive from the PC by test bench and stored in a BRAM module named "RAM 144x2". "RA M 16x8" is the BRAM module defined to store the Co-occurrence Matrix. "IIR A M -Syn" is the BRAM module defined to store the final output data for display.

37

"REGISTER 1" is the Shift Register module defined for data delay and "REGISTER2' is the Shift Register module defined for address delay.
Im age In put block
WRl c l k lld m a l BRAM RAM144x2

dma2

R egisterl (Delay)
WR2 elk

Data Concatenation D atl& dat2

Addresses Accumulation Co-occurrence Matrix
L U T Log Square F eature Vector A

BRAM R A M I6x8

FEATURE VECTOR
y:?, y s , y ; , y c ;/

F eature Vector B
finDUtl

F eature Vector C
tlnDutt

tinDutl

L I D ISTA N C E L IA

L I DISTANCE L ie

L I D ISTAN CE L IB

L1=LIA I f L1A<=L1B andL1A<=L1C L l = L l B I f L l B < = L l A a n d L lB < = L lC L l= L l C I fL l C < = L l A and L I C<=L1B Ready
W E elk

SZ.
A ssign Gray L evel to L I

O UTPU T

K

BRAM R esult

Figure 4-1 Block Diagram o f Algorithm Implementation in Hardware Platform Using VHDL

38

4.2

The Implementation o f Co-occurrence Matrix Calculation
The Co-occurrence matrix calculation in MATLAB has been introduced in

previous section. MATLAB can handle matrix flexibly and images are considered as matrices. VHDL is hardware description language, and it describes has to be practically em bedded into hardware. So it can not transform matrix directly. Com paring with M ATLAB, another big difference is the input data. In MATLAB, the input data is the 256x256 raw image matrix. With the matrix index, the program can take any block o f the image and process it. In VHDL or actual hardware, the data is stored in memory. Normally, it is serially read into the next processing word by word. For example, the data in M A TLA B is in the following version;
"0 0 "," 0 1 "," 10 "," 11 ",

"10","01","00","01",
"10","H ","10","01",
" 10 "," 0 1 "," 10 "," 11 ",

The above m atrix format needs 2-dimensional index to address each element. In this particularly implementation with VHDL, the above matrix is input like this:

["00","01","10","H ","I0","01","00","01","10","H ",'T0","01",'T0","01","10","H "], which only needs one dimension index, (Please be noted that there are ways to index two or three dim ensional m atrix in VHDL). Because o f the matrix processing, the Co-occurrence

m atrix calculation is just a few lines o f program in MATLAB:
i f (a l = = 1)

39

fo r row

=

l . rows

f o r col = L c o ls- d i J
=

image(row, col); imagefrow, col+d);

=

CM(iJ) = CM(iJ) + 1; i f (a2
= =

1)

CMO,i) = CMO.i) + 1; end end end end

the above program is to find the Co-occurrence matrix with distance 1 and direction o f 0 and 180 degree. The idea is to start from the top left point, moving to the direction o f east and west, each two adjacent pixels, say (rl, c l) and (rl, c2) with gray level 3 and 6 respectively, causes the value o f element (3, 6) in the Co-occurrence matrix increment 1. Thus a certain texture pattern o f the regarding image could be presented in its corresponding Co-occurrence matrix. Obviously, circuitry described in VHDL can not calculate the Co-occurrence matrix like this. In this project, the calculation o f Co occurrence Matrix is done as following: First, the input data is loaded into "RAM144x2". The output o f "RAM 144x2" is named "dat2" . (See Figure 5-3); Second, "dat2" is loaded into "REGISTER 1". The output o f "REGISTER 1" is called "d a tl". Comparing with "dat2", "d a tl" is one clock cycle delayed.

40

Third, "d a tl" is logically concatenated with "dat2" to get an output. The block diagram o f these steps is shown in Figure 4-3. 00..01..10..N d atl RAM 144x2 K REGISTER 1

V

datl

dat2 OUTPUT

I Z
datl& dat2

Data3 Figure 4-3 Diagram o f Data Concatenation

0

The sim ulation result o f the data concatenation process Figure 4-4. "d a ta i" presents "d a tl' in Figure 4-3, "data2" presents "dat2" in Figure 4-3. "Data3" is the output.
=4f TPave F ile E d it

d e fa u lt
View In se rt Form at T o o ls Window

"k

i

i S f i rm im #

m

i >

m
0110
..powori

m
91011

in 110

noGi

loioo

ooooi

Figure 4-4 Simulation Result o f Data Concatenation As it is shown in Figure 4-4, "00" & "01 "="0001", "01" & " 10"= "0110" . the concatenation function in VHDL. If the input image is a 4x4 block, there will be 16 output results. These results are used as the address o f "RAM 16x8" , this RAM is used to store the value o f the Co-occurrence matrix. That means when the input is the 1x16 one is

41

dimension array such as; ["00","01","10","11","10","01","00","01","10","11","10","01","10","01","10","11"], there will be 15 addressees ["0001", "0110", " 1011", " 1110", " 1001", "0100", "0001", "0110", " 1011", " 1110", " 1001", "0110", " 1001", "0110", " 1011"]. The fourth step of Co-occurrence matrix calculation is "Addresses

Accumulation". "RAM16x8" 's contents are all "0"s when reset. Whenever there is an address from the address concatenation process, the content of the address pointing to will increase 1. For example, when there is the first " 1011", the content of address " 1011" pointing to will become 1, if there is another one before all the address ends, the content will become 2. This is shown as Figure 4-5.
= * ? wave - d e f a u l t
F ile View Insert, Fo rm a t Toels Window

WBBBÊBÊ
...djb/powon ,

Figure 4-5 Addresses Accumulation To show clearly the idea, the one dimension address array is transformed into Table 4-1. The elements which do not have any address will be filled with 0. 'able 4-1 Addresses Accumulation

00 00 01 10 11 0 1 0 0

01 1+1 0 1+1+1 0

10 0 l+ l+ l+ l 0 1+1

11 0 0 1+1+1 0

Address "00 01" shows up twice so the content of "0001" becomes 2, "01 10" shows

42

up three times, so the content o f "01 10" becomes 3, the same thing with the rest of the addresses. The simulation result is shown in Figure 4-6.
tf w ave - d e f a u l t
F ile : E dit View Insert Formal Tools Window

tb/data1

stmmm
H m niM B IinM

LT U 11 no m
10 Ï01 00

r U Li U loo Ml (1 0

U 1 1 1 11 1 0 IBT
3

101 110 111 110 1 0 1 1 110 0000 1001 011011011 101111110
0000 10111111011001

..vh d jb /resel ..dJb/(WA'oni ..dJW wrlîim . J iL/wi2iim

.·i1 ib/dmaZ
iJ. 'b-'crpâl
..VI

id Ib/mcril

Figure 4-6 Co-occurrence Calculation As shown in Figure 4-6, the operation starts from "0001" (the line points to). "Data out" changes to 2 when the second "0001" shows up. After all the addresses have been eheeking through, the results o f the Co-occurrence matrix is in Table 4-2. able 4-2 Co-occurrence Matrix Result

00 00 01 10 11 0 1 0 0

01 2 0 3 0

10 0 4 0 2

11 0 0 3 0

The simulation result is in Figure 4-7.

43

" =w ave - d e f a u l t
F ile E d it View Insert Format Tools Window

% m

±T i \ K ^ \ ^

^

0

!2

Ï01

Figure 4-7 Co-occurrence Simulation Result As shown in Figure 4-7. "Address3sim" is the address for "RAM16x8" . The result of Co-occurrence Matrix is stored in this Block RAM. The results match Table 4-2. But neither Figure 4-7 nor Table 4-2 gives the right result. If checking carefully of this data array again: f"00","01","I0","U" ,"10","01","GO","01" "I0","H","10","01" "io","oi","io","H'T Figure 4-8 One Dimension Data Array If this array is put back into a matrix: 0Q","01","10'y'U

Figure 4-9 Matrix Version of Figure 4-3 As predefined in the former section of this project, the distance o f the Co-occurrence is " 1" and the direction is 0 degree. But when the data is collected as an array, there will be some problems at the gray area shown in Figure 4-8. The gray area in Figure 4-8 is the same gray area in Figure 4-9. In Figure 4-8, from " 11" to " 10" in the gray

44

area, the distance is " 1" and the direction is "0" degree, but in Figure 4-9, the distance is still 1 but the direction is not "0" degree, it is kind o f 180 degree( in fact, there is no such definition here). So as shown in Figure 4-9, from " 11" to " 10", "01" to " 10", "01" to " 10", where the arrows are pointing, the three addresses have to be removed from the addresses list. To simplify the logic, in this project, all these addresses at the comers are set to "0000" by the following VHDL process:

outaddress.-process (maincount) begin I f (mamcount="OOOOOOOOOOOIOIII ") or (maincount="OOOOOOOOOOOI 1011") or (maincount= "000000000001I I I I " ) then ou taddri <="0000"; else ou taddri < = d a tl & d a tl; en d if; en d process;

In this process, M AINCOUNT is the counter, when it reaches the turning point at "0000000000010111", "0000000000011011" and "0000000000011111", it will changes these addresses to "0000". The simulation is shown is Figure 4-10.

45

i

«ave E d il

d e fa u lt
View In se rt F o rm a t T o o ls Window

2 .il«

# I
25~

i j'__ 1 il-- I
Ï2T1

i ji-- r
Ï24 ! J ï æ

i iiJ S î i t g I >

Eh

...b/datar» J l i

î Figure 4-10 Turning Points

I

In Figure 4-10, the arrows are pointing to the addresses which have been changed to "0000". After these addresses have been changed to "0000", the contents of these addresses will be right, but the content o f address "0000" is pointing to will have 3 extra " l "s added to it. So to get the right value, the content of address "0000" has to subtract 3. This is done by the following process:
i f (addr="0000") then ram (0) := conv_std_logic_vector((unsigned(ram(0)) - 3),8); dataout < = ram (address); else dataout < = ram (address); end if;

In the end, the right Co-occurrence matrix is in Table 4-3

00 01 10 11

00 0 1 0 0

01 2 0 3 0

10 0
2

J

0
I

11 0 0 3 0

46

Comparing with Table 4-2, the underlined number is different. The simulation is in Figure 4-11.

a ny # i^ % « IQ H  a lii I

F ile

E d it

View

Insert

Format

Tools

Window

« y % I t ±T i

I@ 1 et

BX I a urn 0 0
48 43 5

Figure 4-11 The Final Result o f Co-occurrence Matrix As shown in Table 4-3 and Figure 4-11. The result of the Co-occurrence matrix is right. If the input image block is changed from 4x4 to 5x5, there will be 4 addresses changed to "0000", so the content of "0000" has to subtract "4" to get the right value. W hen the Co-occurrence matrix is ready, it is time to calculate the feature vectors and the LI distance. This will be discussed in the next section.

4.3

The Feature Vector and LI Distance Calculation Implemented with VHDL
As described in section 4, when the Co-occurrence matrix is ready, it is time to

calculate the feature vectors. Equations (4) to (10) present the mathematical formation o f all the feature vectors. In VHDL, it is a little bit harder to do the mathematical operations. This section will describe the details one by one. Before starting the calculations, here is the brief introduction o f the Co-occurrence matrix used here. The

47

Co-occurrence matrix result is from three input images. The input data is a 5x15 image block which is from three different images. It is shown in Figure 4-12.
=4=f w a v e F ile E d it

d e fa u lt
View Insert Form at T o o ls Window

i ^ % ...fa^arraF
...b /d atain ...d j b / c i k

reî'îSsirn
7
...tb/m cnt tb /ie s e t

sam
9 III 10 II

Figure 4-12 The Co-occurrence Waveform of 5x15 Image Input Block The Co-occurrence matrix is shown in Table 4-4. "able 4-4 The Co-occurrence Matrix of 5x15 Image Input Block

00 01 10 11
yj. E N TRO PY

00 38 7 1 0

_

01 6 9 3 0

^

10 0 1 3 1

11 0 0 0 1

As equation (3) shows, function LOGARITHM needed to calculate the entropy. There is not such function in VHDL standard library, unless the third-party core is purchased. In this project, the maximum value for F is 70, the minimum value is 0. So the LUT table will be very useful here. All 70 values of PlogP were pre calculated and stored in the LUT. So when there is any input P, there is a corresponding PlogP. The ENTROPY will be all the PlogP added together. All

48

the calculations in the LUT is round up with integer, because the fraction calculations are very resources consuming in VHDL.
B. E N E R G Y

As indicated in equation (6), ENERGY is the square sum o f all Co-occurrence matrix elements. So the function o f square is very important here. In VHDL there is not square function available in standard library. To simplify the logic, in this project, LUT is still the best solution. When the Co-occurrence value is input one by one, the corresponding square will be summed up and the result is the ENERGY. C. IN TE R IA In equation (5), there is the definition o f INTERIA. Three steps to calculate INTERIA. 1. The absolute value o f the difference between the row index and column index of the Co-occurrence Matrix, called |i-yj2. The square o f |/-y|, this is done using the same idea as LUT. 3. Multiply the result o f step 2 with the corresponding Pij. (Pij is the Co-occurrence matrix element).
D. C O N T R A ST

As described in equation (7), contrast is the sum of product o f (i-j) and the square o f Pij. The square can be found in the LUT, (i-J) is simple to approach.
E. IN V E R S E D IF F E R E N C E M O M E N T

Equation (8) describes the Inverse Difference Moment. It is very similar with contrast. Instead o f multiplication, the square divided by the absolute difference o f
(i-j), then sum up, the result is the IDM.

49

F.

M A XIM U M PROBABILITY

Just to compare and always keep the larger value, when finish checking all the elements of the Co-oeeurrence matrix, there is the maximum probability. The simulation result of all the feature ealculations is in Figure 4-13

View Insert Formal Tools W indow

Iiess3sim

1631

i1E3

far

I PHHiiMll

Figure 4-13 Feature Caleulation One input image block's feature vectors calculation is shown Figure 4-13. "Address3Sim" is the address of the block memory (RAM 16x8) which stores the C o
occurrence matrix information. There are 16 values, so the addresses are from 0 to 15.

The addresses and eorresponding Co-oceurrenee matrix value are;0^38, l->6, 2->0, 3->0,4->7, 5->9, 6-> l, 7->0, 8-> l, 9 ^ 3 , 10->3, ll-> 0 , 1 2 ^ 0 , 13->0, 1 4 ^ 1 , 1 5 ^ 1 . Taking ENERGY as one example: ENERGY=38x38+6x6+0x0+0x0+7x7+9x9+... =1444+6x6+0x0+0x0+7x7+9x9+.. .=1480+0x0+0x0+7x7+9x9+...=1529+9x9+.. .=16 10+....This is same as shown in Figure 4-13. When all the ealculations are done, the results are shown in the last cloek eycle of Figure 4-13. Putting the results in a veetor, it is [22, 22, 38, 274, 1632, 96]. The

50

elements are corresponding to INTERIA, Contrast, M aximum Probability, Entropy, Energy and Inverse Difference M oment respectively.
G. L I D istance Calculation

W hen the feature vectors are ready, it is time to calculate the LI distance. As shown in equation (11), the LI distance calculation involves the division. As known, it is straight forward for FPGA to do the divisions o f any number which is the power of 2. But in this case, the division has a lot of numbers which are not the power of 2. To simplify the calculation, the division part is removed here. So the LI distance will be the sum o f the difference o f the feature vectors. This for sure will introduce some deviations to the results. The simulation result is shown in Figure 4-14.
» a v e -- d e fa u lt
F ile E d it View Insert Format T o ols Window

u ...u m i

H H
0000000000000001

g ly H
 M 269 27W Ill 11  

Figure 4-14 LI Distance Calculation

51

In Figure 4-14, "Lldistssim l" and "Lldistssim2" and "LldistssimS" are the three LI distance simulation results, they are 1246, 1195 and 814 respectively. The minimum value will be chosen from the three values. In this case, "LldistssimS" is the one. So the first block is judged to belong to the third type of materials (which the LI distance is calculating against with). "01" will be assigned to this block. When the write enable signal "WESIM" is ready, "01" is written to address "0000000000000001" o f "addriisim". "Addriisim" is the address output Block RAM ("IIRAM-SYN"). After the whole image is finished, there should be 65536 values in this memory.

4.4 The Block RAM Module for Data Input and Output
Most o f the XILINX devices provide embedded dual-port RAM modules. Virtex-11 devices feature a large number of 18 Kb block SelectRAM memories. [10] The block SelectRAM memory is a True Dual-Port RAM, offering fast, discrete, and large blocks of memory in the device. The memory is organized in columns, and the total amount of block SelectRAM memory depends on the size of the Virtex-11 device. The 18 Kb blocks are cascadable to enable a deeper and wider memory implementation, with a minimal timing penalty incurred through specialized routing resources. [19] The Block RAM is used a few times in this project. There are three Block RAM Modules used in this project. The first one is for the image block input. The second one is for Co-occurrence matrix. The third one is for the final result output. All these three Block RAMs are used as single ported only. The image input Block RAM is for 256 pixels, there are 8 bit per pixel, so this RAM is 256x8. In this project, maximum there are 75 input values, so it is more than enough. The

52

control signals are address (addresslSim ) and Read and Write Enable (W rlSim ). Figure 415 is write operation of this Block RAM. When "w rlsim " is set to " 1" , the Block RAM is in "W rite" mode, the data ("datain") is written into this Block RAM, one data per clock cycle, "addressIsim " is the writing address.
ave F ile E d it

d e fa u lt
View Insert Format Tools Window

(  im m B

Figure 4-15 Write Operation o f Input Block RAM Figure 4-16 is the read operation o f input RAM. When "w rlsim " is set to "0", the Block RAM is in "Read" mode, the data ("data2") is read out from this Block RAM, one data per clock cycle, "addressIsim " is the reading address.
»ave F ile E d it

d e fa u lt
View Insert Format Tools Window

W

#

i ^

%

@

1

kM1^

:^

I [V

^

I

^

I 0

I im

l:K 1 # ^ 1 ^

I >

Figure 4-16 The Read Operation o f Input Block RAM. For the Co-occurrence matrix Block RAM (RAM 16x8), as discussed in previous section, if the write enable signal is ready, "wr2"='T ", when the address o f this Block RAM appears, the corresponding content o f that address pointing to will increase " 1" . This is done as shown in Figure 4-17. This RAM is defined as 16x8, because there are only 16 values in this Block RAM.

53

«ave File E d it

d e fa u lt
View Insert Format Tools Window

c ^ H S i

t ï T
0 00 I Ï01 _ _

4

B: i

0

BaB i i
tb/wr2sim ...d_tb/data1 ,..d jb /d 3 ta 2 d Jb/dataS ,..ddtess3sim .. b/data_out

01!

110 101 0101 0110 1001 0100

oral 010110110

Figure 4-17 Co-occurrence Matrix Block Ram Write Operation It can be seen from Figure 4-17, the content of address "0000" has been increasing from 0 to 8, and " 1001" from 0 to 2. "Address3Sim" is the address for Co-occurrence matrix Block RAM. The read operation is in Figure 4-18.
=4t w ave -- d e f a u l t
F ile E dit View Insert Format Tools Window

...vhd tb/clk d jb /d a ta l ...d_lb/dala2 ...dJb/dataS ...ddtesî3sirn ...b/data out

0101 ïoifloïoniïlooo

TôTïïld ü iilii oïïli 101 il 11 o>TnT)5üDô

Figure 4-18 Read Operation o f Co-occurrence Matrix When "wr2sim" =0, the read signal is effective. At this time, the content is sending out to "data-out" as shown in Figure 4-18. For the above Block RAM, only the read and write control signals are not enough. There are some other signals to control the read and write signals, they will be discussed in the later section. The final result output Block RAM is already discussed in previous section, so it won't be repeated here.

54

4.5

The Register Module for Data Delay and Address Delay
In this project, register modules are used to delay the signals. The first register

module is used to delay the input data. The purpose o f this delay is to produce the addresses o f the Co-occurrence matrix. As shown in Figure 4-19, "d a ta i" is one clock cycle after "dataZ". The second register module is used to delay the address. As seen in Figure 4-20, "address]" is one clock cycle after "addressZ" .
==ft » a v e F ile E d it

d e fa u lt
View Insert Format T oo ls Window

Or

Figure 4-19 Input Data Delay
w ave F ile E d it

d e fa u lt
View In sert Fo.rmat Tools Window

. . . . . . . . . . . . . . . . . . . . . . . . . . . .^ . . . . . .% . . . . . .# ............ i .. ^
...vhdjb.'dâta_array ..._n ew th /hd_th/clt. ,..d jb /ôd d (ess2sim ,..d tb/'sddreîîSsirn

t

:tr i ï ï f

Figure 4-20 Address Delay

55

4.6

Test Bench Design for simulation
"With gate counts and system complexity growing exponentially, engineers

confront the most perplexing challenge in product design: functional verification". [7] So functional verification is a very important step to the design. In this project, the software used for functional verification is MODELSIM from Model Technology. The version used is ModelSim XE II 5.7 C, which is the custom version with XILINX ISE 6. So it is very convenient to use with XILINX design environment.

4.6.1

Input Data Preparation and Organization

In this project, the input image size is 256x256, so there are total 65536 pixels in the original image. As discussed in section IV, if three images were taken as input, and each block took 25 (5x5) pixels. These three "5x5" blocks are put together from left to right, so each image block is 5x15=75 pixels. In order to improve the segmentation quality, when the window is scanning through the image, each time the window only move one pixel. So only the pixel at the centre point is replaced with the new gray level. In this case, there are 63504 image blocks (because of the edge). In total there are 4762800 pixels as input. As mentioned in previous section, the input data is in a one dimensional array: 1x75. In this project, MATLAB is used to pre-organize the input data. MATLAB puts all the 5x15 image blocks into a data array, and then put all these data into a binary file sequentially from the first image block to the last one. Test Bench will read this file from the hard-drive of the PC. Test Bench handles the binary file as the following process:

56

R ead_From _Fite: process(clkl) Variable indataJin e: line; Variable indata: integer ; variable h .'integer :=0; file inpu t_dataJile:text open r e a d jn o d e is "C:/PROJECT/matlab/data/orig2.bin"; begin i f risin g_edge(clkl) and (h < = 1024145) then -1 0 2 4 1 4 5 -4 7 6 2 8 0 0 readline(input_data J ile , indata J in e ); read(in datajin e, indata); 1D< =conv_stdJogic_vector(indata,2); data_array(h) <= ID ; h := h + I; i f endfile(input_data J ile ) then report "end o f file file_close(inpiit_data J l e ) ; file_open(in pu t_dataJile, "C:/PROJECT/matlab/data/orig2.bin"); en d if; en d if; en d process;

Orig2.bin is the binary file o f the input data which is saved in the hard-drive under the directory o f "C:/PROJECT/matlab/data". In this process, "C L K I" is used. It is a different clock. It is only for reading the data from the binary file. This clock is independent with the processing clock "CLK". The function o f this process is to open the binary file and write the data into "data_array", one data per clock cycle. The reading process is ahead of time o f the processing. So when the main process reads data from "data_array", the data is always ready there, "h" is to setup to stop reading at certain time. For example, in the program shown above, the reading process will stop at the 1024145* data. This is good for debugging the program. Test bench needs read each image block for processing. The reading operation is done by the following process
f o r j in 0 to 65535 loop k ;= j* 7 5 + l;

57

fo r i in 0 to 14 loop ad d rl < = conv_std_logic_vector(i,8); DA TAIN< =Data_array(i+k) ; end loop;

There are total 65535 image blocks, each time 75 data is read into the program for processing. The reading of these 75 data is done by the internal loop. "A d d rl" is the address for input Block RAM "RAM 144x2". K controls which image block to read. For some reason the first data of "Data_array" is not an effective one, so the first data is skipped by adding one to K {k:=j*75+I instead oïk:=j*75).

4.6.2

Output Data Organization

The output is the reversed operation of the input. When all the output data is ready in the RAM, it will be sent out. The following process is for data output;
w r ite jo J ile : PROCESS (clkl) variable ou tdatajine: line; variable outdata:integer: =0; variable holdon:std_logic; file outputjdata J ile : text open w rite jn o d e is "C:/PROJECT/matlab/vhdl_output521_2. bin "; begin if (W E sim ='l) then if rising_edge(clkl) then outdata: =abs(CO N VJnteger(LlD ist)); write(outdata_line, outdata); writeline(output_dataJile, ou tdatajin e); end if; end if; en d process;

In this process, when "WEsim" is effective, the data in this Block RAM will be written in the file named "vhdl_output521_2.bin". This file is saved on the hard-drive

58

under the directory o f "C:/PROJECT/matlab". In both input and output processes, "std.textio.all" needs to be included in the library. This file will be loaded by MATLAB. MATLAB takes the data and reform into an image, the image is the segmented image. The idea used to communicate between MATLAB and ModelSim in this project make it possible to test and verify the algorithm and simulations result. This is good because the final result can be verified and viewed before the design approach to the hardware stage.

4.6.3

Tim ing Analysis o f Control Signals
In previous section, all the components have been introduced. The timing o f

these components has to be controlled to get the right result. In logic design, timing is very important. In this project, the control signals are introduced by two parts. The first part is the Co-occurrence. The simulation waveform is in Figure 4-21. As shown in Figure 4-21, "C lk l" is an independent clock, it is only for reading all the data from PC to test-bench. "data array" is the array where test-bench storages all the data. Because this "data array" needs to load 4762800 bytes into the memory of the PC, so the simulation process is very slow and resource consuming, the PC was frozen many times during the simulations. "CLK" is the clock signal which drives the rest o f the logics. "POWERON" signal is the initial reset signal, so when this signal is " 1", the whole system will reset. That means "reset" signal is effective. The reason to have "POWERON" is that the "reset" signal is effective for every image

59

:=?: wave - d e f a u lt
F ile E d it View Insert Format Tools Window

ÛÏ e

#

I j{, % m *

I

j

It ^

..v h d jb /d k l

,./data_air'â^)
.,vhd_tb/clK<-

djb/ck*@ in"
..hd (ri/'m cnf
..djb/coui-it ..tbj-'cnt.lxim .Jb /w rlsîm ...d_iu'ôddtl .addtesslsim ,,.d_tb/mlsiiri ...d_t.b/dma2 ..._tbA-vt2sim ...addtesrs2sim ...addfessSsim ,..d_WdMa1 ...d jb /d ata2 ...d jb /d ata3

tD M D Jm JW D ID

uumw rnmrnmi
010011C

0
0100101 0100101 01001011 (00000000

'ÿ jg g g g g illjÿ lljlg .

0 0

uuuu '
UULIU

01
01 0101

...dJbAsddrS
. ,b/addt2sim ...djb.'status ...dJb/stateS ...hd tb/reset

uuuu uuuu
1
1

0

Figure 4-21 The Control Signals of Co-occurrence Matrix Calculation

block. When "reset" is effective "dma2" is set to " 1", "count" is set to "75", which is the total quantity of each image block. When "dm al" is " 1", "W R l" is set to " 1" immediately. So the data is read into the program, "cntlsim " is the counter for reading the data, when it reaches "75", that means the data reading process finish for the current image block. Then "W R l" is set to "0". When "dma2" and "wr2" are both effective " 1", the input RAM is in read mode, so the data is read out from the RAM and the calculations of Co-occurrence matrix starts. "WR2" is effective means

60

"R A M I6x8" for Co-occurrence matrix is in "write" mode. After the Co-occurrence matrix is calculated, the values are saved in this RAM. When "WR2" is set to "0", "R A M I6x8" is at "read" mode, the Co-occurrence matrix value is read out for feature vector calculation. The feature vector and LI distance calculation control signals are shown in Figure 4-22.

w ave F ile E d it

d e fa u lt
View Insert Format Tools Window

't i
.vhd_tb/clk . ...hdjb/rftcfft-. ...addresi35jtn' ..,b/data_out';
.

^I

t

i

^

BX

! 0

! 0

0

#

m

I

9122012211 2 2 2 l:2 2 3 l:2 2 4 p 2 5 i2 E Ï 2 M 2 m 12 113 3 Ï0

12301(231 ):232)533l234I235)536)3^

fu u a to

st-ateadiisim
0

u
0 0 0 O' 0 0 0 0
--

. dldistssinrt

...yi1dbt£..îim2 . 0 ....·''IldistssimS ...d_tb/'ititeria ..tb /con b ait ...vhdj.b/tnb ..._tb2entropi) ..._tb.<'energj> ...vhd_tb/idm d jb .'`finiîh

. .dJLATOiinn 0
...tb/addriiiim ...d jb /lld i& t ...ageirida-'ouf ...hd tbA eset 0

H

OOOOOOOOOOII.

Figure 4-22 Feature Vector and LI Distance Calculation Control Signals The Co-occurrence matrix data are loaded out to calculate the feature vectors. When the feature vectors are ready, "datareadysim" is set to be effective for three clock cycles. In this three clock cycles, the LI distance is calculated. When LI distance

61

PROPERTY 0F RYERSON U tiim SlTY U8RARY

w ave - d e f a u l t
F ile E d it Viev; Insert Format Tools Window

y

â

I

^%

#

010010*01001011

010010 1

ma

#* ! ! »# ## ## ## mm m w m ## m m i

#

#

#

#

»

#

_ _ T L JÏ_
1
010010 10

0
000010

I B

i

m

Ï
--
000000
001010

I
II
M M M II

001101

odoioi
,vhd_tb/idm . 000001
·d jb /lld ist .ageindexcMjt . vhd lb/id i ...d tb/finish 00 00 10 0

M 'n --

i

Figure 4-23 The Overview of All The Simulation Waveforms

62

calculation is done, "finish" signal is set to be effective, "finish" makes "WE" ("wesim" in Figure 4-22) effective. "WE" is the "write-enable" signal for the output Block RAM, when this signal is ready, the gray-level for the current image block is written into this Block RAM. Figure 4-23 is the overview o f all the simulation waveforms o f this project. In Figure 4-23, there are around 16 image block processing. For the whole image there are around 65535 such processing.

Summary:
The IID based MRI image segmentation was implemented in FPGA using VHDL. The implementation scheme is presented and the specific approaches for Co occurrence matrix calculation implementation, logarithm calculation implementation and square calculation implementation are discussed. The logic hardware modules like Block RAM, Register are presented. The timing controls and data input and output were discussed in details. The simulation waveforms are presented.

63

CHAPTER V RESULT COMPARISION, ANALYSIS AND CONCLUSION
For the above simulations, the FPGA chip used is XILINX "XC2V2000-6bf957". This device has 24, 192 logic cells and 1008 K bits BRAM and 624 user 10. [10] APPENDIX A1 is the device utilization summary. As shown in APPENDIX A l, the slices are not enough to accomplish the project. There are two ways to solve this problem. One way is to change the device which has more resources. This for sure will increase the cost. Another way is to optimize the design to reduce the unnecessary logic resources. The timing report of this project utilizing this device is shown in APPENDIX A2. The timing report in APPENDIX A2 does not have practical value because the device does not have enough resources. For comparison, device XC2V4000 was selected. XC2V4000 has 51,400 logic cells, which doubled the logic cells of XC2V2000 [10]. The rest o f the resources like BRAM, Multipliers and user 1/Os also doubled the ones in XC2V2000. APPENDIX A3 is the device utilization summary of XC2V4000. As shown in APPENDIX A3, XC2V4000 has enough slices to accomplish this project. Its timing report is in APPENDIX A4. From APPENDIX A2 and A4, it can be seen that there is almost no difference between these two timing reports. The maximum required output time is a little bit delayed in APPENDIX A4. Same as MATLAB based simulation, in this project FPGA based simulation has three different results classified by one, two or three input images. One input image based

64

segmentation result is very close to Figure 3-10. Two input images based segmentation is very close to Figure 3-12. Both of these results are not very satisfying results, so there is no need to discuss any more here. Figure 5-1 is the three input image based segmentation result. Comparing with Figure 3-12, it is very close. The result is satisfying. But because of the calculation errors between FPGA based and MATLAB based simulations, there are some differences between these two results. With more detailed guidance o f pathological knowledge, these differences can be defined as good or bad, so the segmentation result can be improved easily. If considering the result in Figure 5-1 as a good segmentation result, a FPGA based segmentation system can be implemented with hardware system. This system for sure will include FPGA, SRAM. Such system has its own advantage and disadvantage against the PC based system.

0!

Figure 5-1 FPGA Based Segmentation Simulation Result

65

Matlab (PC) Based System SPEED COST SIZE 180 Second -1000$ 0.032M3

Hardware (FPGA) Based System 0.7S -100$ 0.0015M3

ADVANTAGE

257 times faster real-time processing -10 times cheaper 20 times smaller

From Table 5-1, it can be seen the hardware based system has a lot of advantages. Real time processing is one o f the most important characters of the FPGA based system. And the processing speed won't change too much when the size of input Images are increasing. That is because o f the parallel processing ability of the system. The input images can always be divided into several images and be processed at the same time. But for the PC based system the increasing size of input images means to dramatically increase the processing time.

SUM M ARY
This project went through the whole process of algorithm modification, theoretical verification and simulation by MATLAB and most importantly the implementation with FPGA using VHDL. The simulation with MATLAB approves the IID based segmentation to be an effective way for MRI image segmentation. Because of its special characteristics, the gradient or edge detection based segmentation idea can not segment the exact border o f the different materials inside the MRI image. The IID based segmentation is based on the Co-

66

occurrence o f the different materials, so it has brought some effective elements into the segmentation. The implementation with FPGA in VHDL is an important part of this project. VHDL is hardware description language, so for MATLAB and C++, it is software programming, but for VHDL, it is hardware designing. So at the beginning o f this project, a lot o f troubles showed up like changing the method from "programming" to "designing". The MATLAB programming is more like a sequential thing, but the VHDL design is a parallel thing, so the "timing" becomes extremely important. After the baiTiers were conquered one by one, the implementation with FPGA using VHDL was successfully accomplished. The result is very close to the MATLAB based simulation result. The result is satisfying. That approves the IID based MRI segmentation can be practically implemented with FPGA hardware. And the FPGA hardware based system is faster and more economical. There are still a lot of things can be done regarding the extension o f this project. To physically implement the system will top everything else. It will take a lot of guts and time to do it. On the algorithm side, the different directions and different distances based Co occurrence matrix can be tried for segmentation. And a lot o f new algorithms can be adapted to this system also, such as the self-organized segmentation system [21]. And with more pathological research on the subject can help the system with more practical value.

67

References
1. R. M. Haralick and L.G. Shapiro, "Survey: image Segmentation," Computer
Vision, Graphics, Image Proc., vol.29. pp.100-132, 1985.

2. R.M.Haralick and L.S. Shapiro, Computer vision (Vol.l). Addision Wesley Reading, MA pp.46-50 (1992).
3. BIR BHANU, SUNGKEE LEE and SUBHODEV DAS. "Adaptive Image

Segmentation Using Genetic and Hybrid Search Methods" . IEEE Transactions on
Aerpspace and Electronic Systems VOL.31, N 0.4 pp. 1268-1291, OCTOBER

1995. 4. Archibald R; Chen KW; Gelb A; Renaut R. "Improving tissue segmentation o f human brain MRI through preprocessing by the Gegenbauer reconstruction method". NEUROIMAGE 20(1): pp 489-502. 2003 5. R,M. Haralick, K. Shanmugan, and I. Dinstein, "Textural features for image Classification," /EEE Trans. Syst. Man. Cybern., vol. SMC-3, pp.610-621, June 1973.
6.

M. M. Galloway, "Texture analysis using gray level run length," Comput. Graph.
Image Processing, vol.

172-179, 1975.

7. Janick Bergeron "Writing TestBenches-- Functional Verification of HDL Models". Qualis Design Corporation, Kluwer Academic Publishers, 2000.pp 1-3 8. Vassili A. Kovalev, et. "Three-Dimensional Texture Analysis o f MRI Brain Datasets", IEEE Trans on Medical Image Processing, vol.20, N 0.5, pp424-433. May 2001

68

9. Gabriele Lohmann, "Analysis and synthesis o f Textures: A Co-occurrence-based Approach". Comput. & Graphics, Vol. 19, N o .l, pp. 29-36, 1995 10. XILINX.Virtex II Platform FPGA User Guide. Page 112. UG002 (v2.0) 23 M arch 2005. XILINX 11. Unqing Chen, Aleksandra Mojsilovic. "Adaptive Image Segmentation Based on Color and Texture". Proceedings o f IEEE International Conference on Im age
P rocessing (ICIP'02), Rochester, New York, Sept. 2002 pp 777-780.

12. V. Gemignani, M. Demi, M. Patemi, and A. Benassi, "Real-time implementation o f a new contour tracking procedure in a multi-processor dsp system," Circ. Sys. Commun. Comp., pp.3521-3526, 2000. 13. Steffem Klupsch, etc. "Real Time Image Processing Based on Reconfigurable Hardware Acceleration" . Proceedings o f IEEE Workshop Heterogeneous
Reconfigurahle Systems On Chip (SoC), (no pp). April 2002.

14. http://people.cs.uchicago.edu/~pff/segment/beach.gif 15. http://people.cs.uchicago.edu/~pfl7segment/beach-seg.gif 16. http ://q3 .bevondirc .net/texture s/fabric .zip 17. http://www.theswancoip.com/.../ images/pebble.jpg 18. http://robotics.stanford.edu/~ruzon/NASA/MPF sol3 lander.jpg 19. Virtex-II Platform FPGAs: Complete Data Sheet. Page 3. D S031 (V3.4) March. 1, 2005. XILINX 20. G.Qiu, "Constraint Adaptive Segmentation For Color Image Coding and Content-Based Retrieval". IEEE Workshop on Multimedia Signal Processing, October, Cannes, France, pp.269-274 IEEE 2001.

69

21. Axel Wismuller, Frank Vietze, Johannes Behrends, Anke Meyer-Baese, Maximilian Reiser, Helge Ritter "Fully automated biomedical image segmentation by self-organized model adaptation" //ewra/ Networks 17 pp. 1327-1344. 2004

70

APPENDIX A l Device Utilization Summary for XC2V2000
Device utilization summary: Selected Device : 2v2000bf957-6 Number o f Slices: Number o f Slice Flip Flops: Number of 4 input LUTs: Number of bonded lOBs: Number of MULTI 8X18s: Number of GCLKs: 16916 out o f 10752 1221 out o f 21504 15934 out o f 21504 220 out o f 624 2 out o f 14 1 out o f 16 157% (*) 5% 74% 35% 14% 6%

WARNING: Xst:1336 - (*) More than 100% o f Device resources are used

APPENDIX A2 Timing Report for Device XC2V2000
TIMING REPORT Clock Information:
------- ---- ------------------ + +------ --+

Clock Signal elk

\ Clock buffer (FF name) \BUFGP

| Load \
\3269 |
+

----------------- ------ -------------- -- --+---------------------------------------- 4--------- - + + --------------------------------------- +

Timing Summary: Speed Grade: -6 Minimum period: 22.062ns (Maximum Frequency: 45.327MHz) Minimum input arrival time before clock: 7.879ns Maximum output required time after clock: 11.056ns Maximum combinational path delay: 4.915ns

APPENDIX A3 Device Utilization Summary of XC2V4000
D evice utilization summary: Selected Device : 2v4000bf957-6 N um ber o f Slices: Num ber o f Slice Flip Flops: N um ber o f 4 input LUTs: Num ber o f bonded lO B s: Num ber o f M ULT18XI8s: Num ber o f GCLKs:_ _ _ _ _ _ _ _ 16916 out o f 23040 73% 1221 out o f 46080 2%, 15934 out o f 46080 34% 220 out o f 684 32% 2 out o f 20 10% 1 out o f 16 6%

APPENDIX A4 Timing Report of Device XC2V4000
TIMING R E P O R T Clock Information:
..+ -----------------------------

Clock Signal elk

+ --+ I Clock buffer (FF name) | L o a d |
\3 2 6 9 |

\B U F G P

+--------------------------------- +
Timing Summary: Speed Grade: -6

+

M inim um period: 22.062ns (Maximum Frequency: 45.327M H z) M inimum input arrival time before clock: 7.879ns M aximum output required tim e after clock: 11.056ns M aximum com binational path delay: 4.9I5ns

U

APPENDIX B : MATLAB PROGRAMS
APPENDIX B l: MAIN PROCESSING PROGRAM
% LlA _STD .m - Zhengwei LI %fmd the threshholds o f distance in feature space (LI distance) %by applying samples and controls to the experiment function [] = Ll_STD(image_src, im age_srcl, image_src2)

%size o f ROI R01 = 5; %number of gray levels the image ROI reduced to g ra y b in s = 4; %descriptor: distance distance = 1;

%read samples inx 1=imread('ca 1.jpg'); al=im read('al.jpg'); al=rgb2gray(al); a2=imread('a2 .jpg') ; a2=rgb2gray(a2); a3=imread('a3 .jpg'); a3=rgb2gray(a3); a4=imread('a4.jpg') ; a4=rgb2gray(a4); a5=imread('a5 .jpg'); a5=rgb2gray(a5); a6=imread('a6.jpg'); a6=rgb2gray(a6); a7=imread('a7.jpg'); a7=rgb2gray(a7); a8=imread('a8.jpg'); a8=rgb2gray(a8); a9=imread('a9.jpg'); a9=rgb2gray(a9); al_ l= im read('al_l.jpg'); a l_ l= rg b 2 g ra y (a l_ l); a2_l=im read('a2_l .jpg'); a2_l=rgb2gray(a2_l ); a3_l=lm read('a3_l .jpg'); a3_l=rgb2gray(a3_l );

III

a4_l=imread('a4_l jp g '); a4_ 1=rgb2gray (a4_ 1); a5_l =imread('a5_l jp g '); a5_ 1=rgb2gray(a5_l ); a6_l=imread('a6_l jpg'); a6_l =rgb2gray(a6_l ); a7_l=imread('a7_l jpg'); a7_ 1=rgb2gray (a7_ 1); a8_l =imread('a8_l jpg'); a8_ 1=rgb2gray (aS_ 1) ; a9_l=imread('a9_l jpg'); a9_l =rgb2gray(a9_l ); a 1_2=imread('a 1_2 jpg') ; al_2=rgb2gray(al_2); a2_2=imread('a2_2 jpg') ; a2_2=rgb2gray(a2_2); a3_2=imread('a3_2jpg'); a3_2=rgb2gray(a3_2); a4_2=imread('a4_2jpg'); a4_2=rgb2gray(a4_2); a5_2=imread('a5_2jpg'); a5_2=rgb2gray(a5_2); a6_2=imread('a6_2jpg'); a6_2=rgb2gray(a6_2); a7_2=imread(' a7_2 jpg') ; a7_2=rgb2gray(a7_2); a8_2=imread('a8_2jpg'); a8_2=rgb2gray(a8_2); a9_2=imread('a9_2jpg'); a9_2=rgb2gray(a9_2); S=[al, al l, al_2, a2, a2_l, a2_2, a3, a3_l, a3 2; a4, a4 1, a4 2, a5, a5_l, a5_2, a6, a6_l, a6_2; al, a l j , a l 1, aS, a8_l, aS_2, a9, a9_l, a9_2]; %S = imread(sam_srcl); imshow(S,[]); SAM_big = S; [maxrow, maxcol] = size(SAM big); sample_num = 0; for i = 1 ; ROI : maxrow - ROI +1 for j = 1 : ROI + ROI + ROI ; maxcol - ROI - ROI - ROI + 1 sample_num = sample_num + 1; SAM(:, sample_num) = SAM_big(i;i+ROI-l, j j+ROI+ROI+ROI-1); SAMa(;, sample_num) = SAM_big(i:i+ROI-l, j j+ROI-1); SAMb(:, sample_num) = SAM_big(i:i+ROI-l, j+ROIj+ROI+ROI-1); SAMc(:, sample_num) = SAM_big(i;i+ROI-l,j+ROI+ROIj+ROI+ROI+ROI-1);

IV

end end %reduced sample ROIs SAM RE = zeros(R01, ROI+ROI+ROI, sample num); %cooccurrence matrices computed from sample ROIs SAM CO M = zeros(gray_bins, gray bins, sample num); %average cooccurrence matrix for samples REP_M = zeros(gray_bins, gray bins); %computation o f each sample's cooccurrence matrix T_CORRELATION = 0; for i = l:sample_num %A_Correlation(i) = Correlation_I(SAM(:, i)); %T_CORRELATION = T_CORRELATION + A_Correlation(i); T_R1 = Correlation_I([CooccurrenceM(Reducelmage4(SAMa(:, i)), gray bins, distance), CooccurrenceM(Reducelmage4(SAMb(:, :, i)),gray_bins, distance)]); T_R2 = Correlation_I([CooccurrenceM(ReduceImage4(SAMa(;, :, i)), gray bins, distance), CooccurrenceM(Reducelmage4(SAMc(;, i)),gray_bins, distance)]); T_R(i) = (T_R1 + T_R2)/2; T_C0RRELAT10N = T_C0RRELAT10N + T_R(i); SAM_RE(:, :, i) = ReduceImage4(SAM(:, :, i)); SAM_CO_M(;, ;, i) = CooccurrenceM(SAM_RE(;, :, i), gray bins, distance); end % computation o f average cooccurrence matrix for Class A (ca) samples for i = 1;gray_bins for] = l:gray_bins for k = lisa m p le n u m REP_M(i, j) = REP_M(i, j) + SAM_CO_M(i, j, k); end REP_M(i, j) = REP_M(i, j)/sample_num; end end display (REP_M); % computation o f the typical feature vector from %the average cooccurrence matrix T_ENTROPY = Entropy(REP_M); waterfall(Entropy(REP_M)); T_ENERGY = Energy(REP_M); T_CONTRAST = Contrast(REP_M); T_I_D_M = I_D_M(REP_M); T_CORRELATION = T_C0RRELAT10N/sample_num; T_M AX_P = Max_P(REP_M);

bl=imread('bl.jpg'); bl=rgb2gray(bl); b2=imread('b2.jpg'); b2=rgb2gray(b2); b3=imread('b3.jpg'); b3=rgb2gray(b3); b4=imread('b4.jpg'); b4=rgb2gray(b4); b5=imread('b5.jpg'); b5=rgb2gray(b5); b6=imread('b6.jpg'); b6=rgb2gray(b6); b7=imread('b7.jpg'); b7=rgb2gray(b7); b8=imread('b8.jpg'); b8=rgb2gray(b8); b9=imread('b9.jpg'); b9=rgb2gray(b9); bl_l=im read('bl_l.jpg'); b 1_ 1=rgb2gray (b 1 1 ); b2_l=imread('b2_l .jpg'); b2_l =rgb2gray(b2_l ); b3_l=imread('b3_l .jpg'); b3_l=rgb2gray(b3_l); b4_l=imread('b4_l .jpg'); b4_l =rgb2gray(b4_l); b5_l=imread('b5_l jpg'); b5_l=rgb2gray(b5_l); b6_I=imread('b6_l .jpg'); b6_ I =rgb2gray(b6_ 1) ; b7_I=imread('b7_l jpg'); b7_ I =rgb2 gray (b7_ 1) ; b8_l=imread('b8_l jpg'); b8_l=rgb2gray(b8_l); b9_l=imread('b9_l jpg'); b9_ 1=rgb2gray (b9_ 1); b 1_2=imread( 'b 1_2 jpg') ; b 1_2=rgb2gray(b 1 2 ); b2_2=i mread('b2_2 jpg') ; b2_2=rgb2gray(b2_2); b3_2=imread('b3_2 jpg'); b3_2=rgb2gray(b3_2); b4_2=imread('b4_2.jpg'); b4_2=rgb2gray(b4_2); b5_2=iinread('b5_2.jpg');

VI

b5_2=rgb2gray(b5_2); b6_2=imread(T36_2 .jpg') ; b6_2=rgb2gray(b6_2); b7_2=imread('b7_2.jpg'); b7_2=rgb2gray(b7_2); b8_2=imread('b8_2.jpg') ; b8_2=Tgb2gray(b8_2); b9_2=imread('b9_2 .jpg') ; b9_2=rgb2gray(b9_2); cb= [bl, b l _ l, b l_ 2 , b2, b2_l, b2_2, b3, b 3 _ l, b3_2; b4, b 4 _ l, b4_2, b5, b 5 _ l, b5_2, b6, b 6 _ l, b6_2; b7, b7_l, b7_2, b8, b8_l, b8_2, b9, b9_l, b9_2j;
figure;

imshow(cb,[]);

%read controls in %C = imread(sam_src2); %CON_big = rgb2gray(C); CON_big = cb; [maxrow, maxcol] = size(CON_big); control_num = 0; for i = l:ROI;maxrow - ROI+1 for j = l;R01+ROI+ROI;maxcol - ROI - ROI - ROI + 1 c o n tro ln u m = co n tro ln u m + 1; CON(:, control num) = CON_big(i:i+ROI-l, j:j+ROI+ROI+ROI-l); CONa(:, control num) = CON_big(i:i+ROI-l, j:j+R O I-l); CONb(:, control num) = CON_big(i;i+ROI-l, j+ROI;j+ROI+ROI-l); CONb(:, control_num) = CON_big(i:H-ROI-l, j+ROI+ROIij+ROI+ROI+ROI-l); end end %reduced control ROIs CON RE = zeros(ROI, ROI+ROI+ROI, control num); %cooccurrence matrices computed from control ROIs CON GO M = zeros(gray_bins, gray_bins, control_num); CON_M = zeros(gray_bins, gray bins); % computation of each sample's cooccurrence matrix CON_CORRELATION = 0; for i = 1;control_num %B_Correlation(i) = Correlation_I(CON(:, i)); %CON_CORRELATION = CON_CORRELATION + B_Correlation(i); C0N_R1 = Correlation_I([CooccurrenceM(ReduceImage4(CONa(:, i)), gray_bins, distance), CooccurrenceM(ReduceImage4(CONb(:, :, i)),gray_bins, distance)]);

VII

C0N_R2 = Correlation_I([CooccurrenceM(ReduceImage4(CONa(:, i)), gray bins, distance), CooccurrenceM(Reducelmage4(CONb(;, i)),gray_bins, distance)]); CON_R(i) - (C0N_R1 + CON_R2)/2; CON_CORRELATION = CONCORRELATION + CON_R(i); CON_RE(;, i) = Reducelmage4(C0N(:, i)); CON_CO_M(;, i) - CooccurrenceM(CON_RE(:, i), gray bins, distance); end " /ocomputation of average cooccurrence matrix for Class B (cb) samples for i = 1:gray_bins for] = l:gray_bins for k = 1;control_num CON_M(i, j) = CON_M(i, j) + CON_CO_M(i, j, k); end CON_M(i, j) = CON_M(i, j)/controI_num; end end display (CON M); %computation of the typical feature vector of cb from %the average cooccurrence matrix CON_ENTROPY = Entropy(CON_M); C O N EN ER G Y = Energy(CON_M); CON_CONTRAST = Contrast(CON_M); C0N_1_D_M = 1_D_M(C0N_M); CONCORRELATION = CON_CORRELAT10N/control_num; CON_MAX_P = Max_P(CON_M); cl=imread('cl.jpg'); cl=rgb2gray(cl); c2=imread('c2.jpg'); c2=rgb2gray(c2); c3=imread('c3 .jpg'); c3=rgb2gray(c3); c4=imread('c4 jp g j; c4=rgb2gray(c4); c5=imread('c5.jpg'); c5=rgb2gray(c5); c6=imread('c6jpg'); c6=rgb2gray(c6); c7=imread('c7 jpg') ; c7=rgb2gray(c7); c8=imread('c8jpg'); c8=rgb2gray(c8); c9=imread('c9jpg'); c9=rgb2gray(c9); cl_l=im read('c l_l.jpg'); cl_l= rgb2gray(cl_l);

-

v m

'S
es. m o
IT ï

O

es.

^

. ^ 'W )

d,

. ^ "O Û

C l#^

. ^ 'ô û

. ^ "0 0

.

1.
,

I ·

I

o# ^

.

"ô û

I

Dh^

. .V

/-- N Q. /'-- V CL
fN

0 0 . ^

0 0 . ^

(N '-7> C N

\ Q. /'-- V rv /'-- V Q.

ôû..>

bD . .

bX).^

C N ·'-fi C N ·'-ri <N *-7»C N --t j C N

\ Cl,

bO . .

b û . ^

On

iT )

| e < D (N
5b (N

Z199 os r i 9î M Dl'ë r^i^T;, 00 | e ï e | ô | e ï
/

^

 m
u

>,0

> ^_ o

m

^

.

vo u

^

o

. 00

.

o\

e Ea

^

x> hx> y ^

cd 5 b c d 5bcd 5bcd 5b 4 ) ( N <U(N D ( N <U(N

w ) E t j ) y ùo y cj) c ù û S

yx> h - û y - o

cQ ô û 0>(N

cd b X ) < U (N

tN

Ëb¥

X > ÜÆ Ü

<UtN

( Ut N

(N (N t N| t N| t N| t N| ( N| ( N | < N| t N| t N | ( N| t N| ( N| ( N| ( N^ ( N^ ( N |

Il îr T îr T iT T îr T îr T îr T îr T ir
Ü Ü Ü O Ü Ü Ü Ü O O O Ü O O O

t ï ûE b o S b o E

hÆ y

( Ut N

<UtN

bûË bûE

fe ) ^ Ëb's Ëb (U (N (UCN U f N HÆ h J 3 Ü
boS bûE

tJû

rN(NmmTfTfmir)\ci\or~r~'OOooa\o\
Ü Ü Ü O Ü Ü O Ü O O O O O O O O O

u o

CC_big = cc; [maxrow, maxcol] = size(CC_big); cc_num = 0; for i = l;R01:maxrow - ROI+1 for j = 1.·ROI+ROI+ROI :maxcol - ROI - ROI - ROI+I cc_num = cc_num + 1; CC(:, cc num) = CC_big(i:i+ROI-l, j:j+ROI+ROI+ROI-I); CCa(;, cc num) = CC_big(i:i+ROI-l, j;j+ROI-I); CCb(:, cc num) = CC_big(i:i+ROI-l, j+ROI:j+ROI+ROI-I); CCc(:, cc num) = CC_big(i:i+ROM, j+ROI+ROI:j+ROI+ROI+ROI-I); end end %reduced cc ROIs CO RE = zeros(ROI, ROI+ROI+ROI, cc_num); %cooccurrence matrices computed from control ROIs CC_CO_M = zeros(gray_bins, gray bins, cc num); CC_M = zeros(gray_bins, gray bins); %computation of each sample's cooccurrence matrix CC_CORRELATION = 0; for i = 1 .cc num %C_Correlation(i) = Corrclation_I(CC(:, :, i)); %CC_CORRELATION = CC_CORRELATION + C_Corrclation(i); CC_R1 = Corrclation_I([CooccurrcnccM(ReduceImage4(CCa(:, i)), gray bins, distance), CooccurrenceM(ReduccImagc4(CCb(;, :, i)),gray_bins, distance)]); CC_R2 = Correlation_I([CooccurrcnccM(RcduceImagc4(CCa(:, ;, i)), gray bins, distance), CooccurrcnceM(RcduccImagc4(CCc(:, i)),gray_bins, distance)]); CC_R(i) = (CC_R1 + CC_R2)/2; CC_CORRELATION = CC_CORRELATION + CC_R(i); CC_RE(:, i) = ReduceImage4(CC(;, :, i)); CC_CO_M(:, ;, i) = CooccurrcnceM(CC_RE(;, :, i), gray bins, distance); end %computation of average cooccurrence matrix for Class C (cc) samples for i = 1.'gray bins for] = I;gray_bins f o rk = l;ce_num CC_M(i, j) = CC_M(i, j) + CC_CO_M(i, j, k); end CC_M(i, j) = CC_M(i, j)/cc_num; end end display (CC_M); " /ocomputation o f the typical feature vector from %the average cooccurrence matrix

CC_ENTROPY = Entropy(CC_M); CC_ENERGY = Energy(CC_M); C C C O N T R A ST = Contrast(CC_M); CC_1_D_M = I_D_M(CC_M); CC C O R R E LA TIO N = CC_CORRELATION/cc_num; CC_MAX_P = Max P(CC_M); " /ooutput the typical feature vector CA REP = {'sample number', sample num; 'ENTROPY = ', T ENTROPY; 'ENERGY = ', T ENERGY; 'CONTRAST = ', T_CONTRAST; 'IDM = ', T_1_D_M; 'CORRELATION = ', T_CORRELATION; 'MAX PROBABILITY = ', T_MAX_P
}

dispIay(CA_REP); CB REP = {'CB sample number', control num; 'ENTROPY = ', C O N EN TR O PY ; 'ENERGY = ', CON ENERGY; 'CONTRAST-: CON CONTRAST; 'IDM = ', CON I D M; 'CORRELATION=', CO N C O RR ELA TIO N ; 'MAX PROBABILITY= ', CON MAX P
}

display(CB_REP); CC REP = {'CC sample number', cc num; 'ENTROPY = ', CC ENTROPY; 'ENERGY = ', CC_ENERGY; 'CONTRAST = ', CC_CONTRAST; 'IDM = ', CC_I_D_M; 'CORRELATION = ', CC CORRELATION; 'MAX PROBABILITY = ', CC_MAX_P
}

display(CC_REP); %SEG %read in the original image IMAGE = im read(im agesrc); IMAGE 1 = imread(image_srcl); IMAGE2 = imread(image_src2); IMAGE = rgb2gray(IMAGE); IM AGEI =rgb2gray(IM A G El); IMAGE2 = rgb2gray(IMAGE2); [maxrow, maxcol] = size(IMAGE);

XI

SEGEDIMAGE=zeros(maxrow, maxcol); %probabillty map PM = zeros(maxrow, maxcol); PM_all = zeros(maxrow, maxcol); %maximum LI and minimum LI maxLl = 0; m inLl = 0 ; c=R01/2;

%calculate the probability map based on LI distance %the original image is scanned by size of ROI fo ri = 1 : l:maxrow-ROI+l for j = 1 : 1: maxcol - ROl+1 %calculate ROI's cooccurrence matrix lMAGE_R01a = lMAGE(i:i + R O M , j:j + RO M ); IMAGE ROlb = IM AGE I (i:i + R O M , j :j + RO M ); IMAGE_ROIc = lMAGE2(i;i + R O M , j;j + R O M ); 1MAGE_R01 = [lMAGE_R01a, IMAGE_R01b, IMAGE_ROIc]; 1MAGE_R01_AVERAGE_GRAYLEVEL=AVERAGE_GRAYLEVEL(IMAGE_R0I); IMAGE_ROI_AVERAGE_GRAYLEVEL 1=AVERAGE_GRAYLEVEL(lMAGE_R01b); if(lMAGE_ROI_A VERAGE_GRA YLE VEL< 15) SEGEDIMAGE(i;i+ROI-1, j :j+ROI-1)=1 ; elseif(lMAGE_ROI_A VERAGE_GRA YLEVEL 1<61) SEGEDIM AGE(i :i+R O M , j :j+ROM )=1 ; else Ma = CooccurrenceM(ReduceImage4(lMAGE_ROIa), gray bins, distance); Mb = CooccuirenceM(ReduceImage4(lMAGE_R01b), gray bins, distance); Me = CooccuirenceM(ReduceImage4(IMAGE_R01c), gray bins, distance); Mab =[Ma, Mb]; Mac =[Ma, Me]; IMAGE_R01_C0RRELAT10N1 = CorrelationJ(M ab); IMAGE_R01_C0RRELAT10N2 = CorrelationJ(M ac); IM A G ER O IC O R R ELA TIO N = (1MAGE_R01_C0RRELAT10N1 + IMAGE_R01_C0RRELATI0N2)/2; IM A G E R O IR E = ReduceImage4(lMAGE_R01); IMAGE_ROI_CO_M = CooccurrenceM(lMAGE_R01_RE, gray bins, distance);

XII

%calculate ROI's feature vector IMAGE_ROI_ENTROPY = Entropy(IMAGE_ROI_CO_M); IMAGE_ROI_ENERGY = Energy(IMAGE_ROI_CO_M); IMAGE_ROI_CONTRAST = Contrast(IMAGE_ROI_CO_M); IMAGE_ROI J D M = I_D_M(IMAGE_ROI_CO_M); IMAGE_ROI_MAX_P = MAX_P(IMAGE_ROI_CO_M); %calculate ROI's LI distance I_tA = abs(IMAGE_ROI_ENTROPY-T_ENTROPY) + abs(IMAGE_ROI_ENERGY-T_ENERGY) + abs(IMAGE_ROI_CONTRASTT_CONTRAST) + abs(IM AGE_ROI_I_D_M -TJ_D_M ) + abs(IMAGE_ROI_MAX_PT_MAX_P) + abs(IMAGE_ROI_CORRELATION-T_CORRELATION); lA = IMAGE_ROI_ENTROPY + IMAGE_ROI_ENERGY + IMAGE_ROI_CONTRAST + IM A G E_RO IJ_D _M + IMAGE_ROI_MAX_P + IMAGE ROI CORRELATION ; tA = T E N T R O P Y + T E N E R G Y + T C O N T R A S T + T_I_D_M + T_MAX_P + T_CORRELATION; IM A G E R O IL IA = I_tA7(IA + tA); I J B = abs(IMAGE_ROI_ENTROPY-CON_ENTROPY) + abs(IMAGE_ROI_ENERGY-CON_ENERGY) + abs(IMAGE_ROI_CONTRASTCON_CONTRAST) + abs(IMAGE_ROI_I_D_M-CON_I_D_M) + abs(IMAGE_ROI_MAX_P-CON_MAX_P) + abs(IMAGE_ROI_CORRELATIONCON_CORRELATION); IB = IMAGE_ROI_ENTROPY + IMAGE_ROI_ENERGY + IMAGE_ROI_CONTRAST + IMAGE_ROI_I_D_M + IMAGE_ROI_MAX_P + IMAGE R O IC O R RELA TIO N ; tB = CON_ENTROPY + CON ENERGY + CON CONTRAST + CON_I_D_M + C O N M A X P + CO NCORRELA TIO N; IMAGE RO I_LlB = I_tB/(IB + tB);

I j C = abs(IMAGE_ROI_ENTROPY-CC_ENTROPY) + abs(IMAGE_ROI_ENERGY-CC_ENERGY) + abs(IMAGE_ROI_CONTRASTC C C O N T R A ST ) + abs(IMAGE_ROI_I_D_M-CC_I_D_M) + abs(IMAGE_ROI_MAX_P-CC_MAX_P) + abs(IMAGE_ROI_CORRELATIONCC_CORRELATION); IC = IMAGE_ROI_ENTROPY + IM A G E R O IE N E R G Y + IM A G E R O IC O N T R A S T + I M A G E R O I J D M + I M A G E R O I M A X P + IMAGE_ROI_CORRELATION ; tC = CC_ENTROPY + C C E N E R G Y + C C C O N T R A ST + CC_I_D_M + CC_M AX_P + CC_CORRELATION; IM AGE_R0I_L1C = IjC /(IC + tC); IMAGE ROI L1=IMAGE R0I_L1A;

XIII

if IMAGE_ROI_L 1>1MAGE_ROI_L 1B IM AGE_ROI_L 1=IM AGE_ROI_L 1B ; end if IM AGE_ROI_L 1>IM AGE_ROI_L 1C IM AGE_ROI_L I =IMAGE_ROI_L 1C; end if IM AGE_ROI_L 1=1M A G E_R 0I_L 1A SEGEDIM AGE(i ;i+ROI-1, j ;j+ROI-1)=4; end if IMAGE ROI L I ==IMAGE_ROI_L IB SEG EDIM AG E(i:i+R0I-l,j;j+R0I-I)=2; end if IMAGE_ROI_L 1==IMAGE_ROI_L 1C SEG ED IM A G E(i;i+R0I-l,j:j+R0I-l)=3; end end %mark probability label in full range, not regarding threshhold %PM_all(i+c, j+c) = 1MAGE_R0I_L1 ; % if IMAGE_ROI_LI > maxLl % m axLl = IMAGE ROI LI ; %end % if m inLl > IMAGE_R0I_L1 % minL 1 = IMAGE ROI L 1; %end

%mark probability label to the center of the ROI according to threshhold % i f L l j o w >= IMAGE_ROI_LI % PM(i + c, j + c) = L M ow ; % elseif LI high > IMAGE ROI LI > LI low % PM(i + c, j + c) = IMAGE_ROI_L 1; % else % PM(i + c, j + c) = LI high; % end

end end error_size = 4; for i = 1 : 1-.maxrow for j = error_size+I : I: maxcol-error_size if(((SEGEDIMAGE(i, j)^l)& SE G E D IM A G E (i, jerror_size)=I)&(SEGEDIM AGE(i, j+error_size)==I))

XIV

SEG EDIM AG E(i,j)=l; end end end figure; imshow(SEGEDIMAGE, []); %display(SEGEDIMAGE); %convert the probability map to 256 level gray image %M = fmd(PM == 0); %PM(M) = LI high; %display(PM); %IM AGE_PM = mat2gray(PM, [LI high, Ll_low]); %imshow(IMAGE_PM, []);

%M = find(PM_all -- 0); %PM_all(M) = m axLl ; %display(PM_all); %IMAGE_PM_all = mat2gray(PM_all, [m axLl, m inLl]); %imshow(IMAGE_PM_all, []);

XV

APPENDIX B2: PROGRAM FOR CO-OCCURRENCE CALCUALTION
% CooccurrenceM.m - Zhengwei LI % calculates the cooccurence matrix, CM, of an image, i % d is the distance of the i pixel from the j pixel, and should be a two element vector, such as [1,1] function [CM] = CooccurrenceM(image, gray bins, d) image = double(image); [rows, cols] = size(image); %choose which type(s) to proceed al = 1 % - 0 a2 = 0 % -1 8 0 a3 = 0 % -4 5 a4 = 0 % -2 2 5 a5 = 0 % - 9 0 a6 = 0 % -2 7 0 a7 = 0 % -1 3 5 a8 = 0 % -3 1 5

% Initialize P to be all zeros CM = zeros(gray_bins, graybins);

%Oand 180 if (al == 1) for row = 1:rows - d for col = 1:cols - d i = image(row, col); j = image(row + d, col + d); C M (ij) = C M (ij) + l; if (a2 == 1)
C M (j,i) = C M (j,i) + l;

end end end end

%45 and 225 if(a3 == 1)

XVI

for row = (1 + d):rows for col = 1;(cols - d) i = image(row, col); j = image(row - d, col + d); C M (ij) = CM (iJ) + 1; if (a4 = = 1 ) CM(j,i) = CMO.i) + 1; end end end end %90 and 270 if (a5 == 1) for row = (1 + d);rows for col = 1:cols i = image(row, col); j = image(row - d, col); C M (iJ) = C M (i,j)+ l; if (a6 == 1) CMC,i) = CM G,i)+ 1; end end end end % 135and315 if (a7 -- 1) for row = (1 + d):rows for col = (1 + d);cols i = image(row, col); j = image(row - d, col - d); CM (iJ) = C M (ij) + l; if(a8 = 1) CMO',i) = CMOM)+ 1; end end end end

xvn

APPENDIX B3: PROGRAM FOR IMAGE REDUCTION
%ReduceImage4.m - Zhengwei LI %convert the input image to 4 gray level grayscale image %and shift all of the levels up by one to enable the gray %level to represent an index into the co-occurrence matrix %(index o f a matrix can't be 0). function y = Reducelmage(x)
X = double(x); X = mat2gray(x); X = grayslice(x,4);

% scale % reduce the number of gray levels to eight

a = find(x==0)
b - find(x==l)

% find the levels

c = fin d (x = 2 ) d = find(x==3) x(a) = 1 x(b) = 2 x(c) = 3 x(d) = 4 % shift them by one

y =(x);
APPENDIX B4: PROGRAM FOR ENTROPY CALCULATION
% Entropy .m - Zhengwei LI % calculates the entropy given a co-occurrence matrix, m function [Entropy] = Entropy(M) [rows,cols] = size(M); Entropy = 0; for i = 1;rows for] = Lcols if M ( ij) ~ = 0 Entropy = Entropy + M (iJ) * log2(M(iJ));

XVIII

end end end

APPENDIX B5: PROGRAM FOR ENERGY CALCULATION
% Energy.m - Zhengwei LI % calculates the energy given a co-occurrence matrix, M function [Energy] = Energy(M) [rows,cols] = size(M); Energy = 0; for i = 1 .TOW S for j = Lcols Energy = Energy + M(i,j) end end

2;

APPENDIX B6: PROGRAM FOR CONTRAST CALCULATION
% Contrast.m - Zhengwei LI % calculates the contrast given a co-occurrence matrix, P function [Contrast] = Contrast(M) [rows,cols] = size(M); Contrast = 0; for i = 1TOWS for j = Lcols i f M ( ij ) ~ = 0 Contrast = Contrast + (abs(i - j))'^2 * M (iJ); end end end

XIX

APPENDIX B7; PROGRAM FOR INVERSE DIFFERENCE MOMENT CALCULATION
% I_D_M.m - Zhengwei LI % calculates the inverse difference moment given a co-occurrence matrix, M function [1_D_M] = I_D_M(M) [rows, cols] = size(M); I_D_M = 0; for i = 1;rows for j = Lcols if i~ = j if M(i,j) ~= 0 I_D_M = I_D_M + (M(i j)) / ((abs(i - j)) ^ 2); end end end end

APPENDIX B8: SUBPROGRAM FOR MAXIMUM PROBABILITY CALCULATION
% Max P.m - Zhengwei LI

% calculates the maximum probability given a co-occurrence matrix, M function [Max_P] = Max P(M) [rows,cols] = size(M); Max_P = 0; for i = 1;rows for] = Lcols Max_P = max(M(i, j), Max_P); end end

XX

APPENDIX B9: PROGRAM FOR CORRELATION CALCULATION
% % % % Correlation ! .m - Zhengwei LI calculates the correlation of pixels in two images. This feature vector can be calculated from the image itself, no need for cooccurrence matrix here, illustrated as follow;

function [R] = Correlation_I(I) I = double(I); I = mat2gray(I); % scale [rows,cols] = size(l); %initilize variables in the correlation function R = 0;
X = 0;

y = 0; Sxy = 0; Sx = 0; Sy = 0; 8x2 = 0; Sy2 = 0; N = rows * (cols/2); " /ocalculate the correlation for i = 1irows for] = 1: (cols/2) x = I(i,j); y = I(i,j + (cols/2)); Sxy = Sxy + x * y; Sx = Sx + x; Sy = Sy + y; Sx2 = Sx2 + X * x; Sy2 = Sy2 + y * y; end end R = (N * Sxy - Sx * Sy)/sqrt((N * Sx2 - Sx * Sx) * (N * Sy2 - Sy * Sy));

XXI

APPENDIX BIO: PROGRAM FOR CONTRAST CALCULATION
% Contrast.m - Zhengwei LI % calculates the contrast given a co-occurrence matrix, P function [Contrast] = Contrast(M) [rows,cols] = size(M); Contrast = 0; for i = 1:rows for j = Lcols ifM ( ij)~ = 0 Contrast = Contrast + (abs(i - j))^2 * M(i,j); end end end

APPENDIX C: PROGRAM TO TRANSFORM IMAGE DATA INTO DATA FILE FOR VHDL TESTBENCH
function [] = getorigout(image_src, image_srcl, image_src2)

%size of ROI ROI = 5; %number of gray levels the image ROI reduced to g ray b in s = 4; %descriptor: distance distance = 1; %read in the original image IMAGE = imread(image_src); IMAGE 1 = imread(image_srcl); IMAGE2 = imread(image_src2); IMAGE = rgb2gray(IMAGE); IMAGE I =rgb2gray(IM AGEl); IMAGE2 = rgb2gray(IMAGE2); [maxrow, maxcol] = size(IMAGE); %probability map PM = zeros(maxrow, maxcol);

xxn

PM_all = zeros(maxrow, maxcol); %maximum LI and minimum LI maxLI = 0; m inLl = 0; c=R0I/2;

fid = fopen('d;\mri\mri-three-imagebased\samplel\orig5x5.binVw'); %calculate the probability map based on LI distance %the original image is scanned by size o f ROI for i = 1 : l;m axrow-ROI+l for j = 1 : 1: maxcol - ROl+1 %calculate ROl's cooccurrence matrix IM A G E R O la = lMAGE(i;i + ROl-1, j:j + ROl-1); lMAGE_R01b = IMAGE l(i:i + R O M , j:j + R O M ); IMAGE_R01c = lMAGE2(i:i + R O M , j:j + R O M ); IMAGE ROl = [IMAGE ROla, IMAGE_ROIb, IMAGE__ROIc]; tempBlock = reshape(double(IMAGE_R01'), 75, 1); fprintf(fid,'%d\n', tempBlock);

end end fclose(fid);

APPENDIX D: PROGRAM TO DISPLAY VHDL TESTBENCH RESULT
fid=fopen('d:\MRI\Mri-Three-imageBased\samplel\vhdl_output521_2.bin', 'r'); InputLabel = fscanf(fid, '%4d'); InputLabel fclose(fid); L = size(InputLabel); L (l) Templmg = zeros(63504, 1); Templmg = Templmg + 4; count = 1 ; %for i = 1 : 1 : 65536 for i = 1 : 2 : L (l)

XXIU

TempImg(count, l) = InputLabel(i); count = count + 1; end %fid = fopen('d:\mri\mri-three-imagebased\samplel\vhdl5x5.binVw'); %fprintf(fid,'%d\n',TempImg(l ;L(1), 1)); %fclose(fid);

L = size(TempImg); L (l) Outlmg = reshape(TempImg, 252,252); Outlmg = Outlmg'; figure; imshow(OutImg, []);

XXIV

A PPENDIX E; VHDL TESTBENCH PROGRAM
-- VHDL Test Bench Created from source file featurevector.vhd -- 10:29:53 04/10/2005 -- Notes: --This testbench has been automatically generated using types std logic and -- std_logic_vector for the ports o f the unit under test. Xilinx recommends --that these types always be used for the top-level I/O of a design in order --to guarantee that the testbench will bind correctly to the post-implementation -- simulation model. LIBRARY ieee; USE ieee.std logic l 164.ALL; USE ieee.numeric_std.ALL; use IEEE.std_logic_arith.all; use IEEE.std_logic_signed.all; use std.textio.all; ENTITY featurevector newTB vhd tb IS END featurevector newTB vhd tb; ARCHITECTURE behavior OF featurevector newTB vhd tb IS COMPONENT featurevector PORT( DATAIN : IN std_logic_vector(0 to 1); elk : IN std_logic; clkl : IN std logic; count : IN std_logic_vector(0 to 7); addrl : IN std_logic_vector(0 to 7); addr2 : IN std_logic_vector(0 to 3); dm al : IN std logic; dma2 : IN std logic; reset : IN std_logic; POWON : IN std logic; data out : INOUT std_logic_vector(0 to 7); ENTROPY : INOUT std_logic_vector(0 to 9); INTERIA : INOUT std_logic_vector(0 to 7); ENERGY : INOUT std_logic_vector(0 to 12); CONTRAST : INOUT std_logic_vector(0 to 7); IDM : INOUT std_logic_vector(0 to 12); MB : INOUT std_logic_vector(0 to 7); L ID ist : INOUT std_logic_vector(0 to 1); Finish : INOUT std logic;

XXV

MCNT ; OUT std_logic_vector(0 to 15); cntlsim : OUT std_logic_vector(0 to 7); address Isim : OUT std_logic_vector(0 to 7); intsim : OUT std_logic_vector(0 to 7); address2sim ; OUT std_logic_vector(0 to 3); addressSsim : OUT std_logic_vector(0 to 3); addr2sim ; OUT std_logic_vector(0 to 3); status ; OUT std logic; WEsim : OUT std logic; addriisim ; OUT std_logic_vector(0 to 15); state3 : OUT std logic; w rlsim : OUT std logic; wr2sim : OUT std logic; DataReadySim : OUT std_logic; LlD istsSim l : OUT std_logic_vector(0 to 12); LlDistsSim2 : OUT std_logic_vector(0 to 12); LlDistsSim3 ; OUT std_logic_vector(0 to 12); datai ; OUT std_logic_vector(0 to 1); data2 ; OUT std_logic_vector(0 to 1); data3 ; OUT std_logic_vector(0 to 3); IminusJ2sim ; OUT std_logic_vector(0 to 7); Imagelndexout ; OUT std_logic_vector(0 to 1)
):

END COMPONENT; type testdata_array is array ( 0 to 5160 ) o f std_logic_vector (0 to 1); --1024145 signal data_array : testdata_array;

type testdata_array 1 is array ( natural range <> ) o f std_logic_vector (0 to 1); constant all_test_datal ; testdata_arrayl ;=
( "0 1 " ," 10"," 11","0 0 ",

"11","10","01",'T0", "11","00",'T1","10",
" 1 1 " ," 1 0 " ," 1 1 "," 0 0 "

);

SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL SIGNAL

DATAIN ; std_logic_vector(0 to 1); elk ; std logic; MCNT ; std logic_vector(0 to 15); count : std_logic_vector(0 to 7); addrl : std_logic_vector(0 to 7); cntlsim : std_logic_vector(0 to 7); address Isim : std_logic_vector(0 to 7); intsim : std_logic_vector(0 to 7); address2sim : std_logic_vector(0 to 3); address3sim : std_logic_vector(0 to 3);

XXVI

SIGNAL addrl SIGNAL addrlsim SIGNAL dm al SIGNAL dm al SIGNAL status SIGNAL state3 SIGNAL w rlsim SIGNAL w rlsim SIGNAL clkl Signal WEsim Signal addriisim

: std_logic_vector(0 to 3); ; std_logic_vector(0 to 3); : std logic; ; std logic; : std logic; : std logic; : std_logic; : std logic; : std jo g ic; std lo g ic; std_logic_vector (15 downto 0);

SIGNAL DataReadySim : std logic; SIGNAL L lD istsSim l : std_logic_vector (0 to 11) SIGNAL L lD istsS im l : std_logic_vector (0 to 11) SIGNAL LlDistsSim3 : std_logic_vector (0 to 11) SIGNAL datai ; std_logic_vector(0 to I ); SIGNAL datai ; std_logic_vector(0 to I); SIGNAL data3 : std_logic_vector(0 to 3); SIGNAL data out : std_logic_vector(0 to 7); SIGNAL reset ; std logic; SIGNAL POWON : std jo g ic; SIGNAL INTERIA,CONTRAST,MB ; std logic_vector(0 to 7); SIGNAL ENTROPY : std_logic_vector(0 to 9); SIGNAL ENERGY, IDM : stdjogic_vector(0 to II); SIGNAL IminusJlsim : std_logic_vector(0 to 7); Signal LlD ist stdjogic_vector(0 to 1); Signal Imagelndexout; stdjogic_vector(0 to 1); SIGNAL ID : stdjogic_vector(0 to I); Signal Finish : std_logic; Signal holdon :std logic; BEGIN uut: featurevector PORT MAP( DATAIN => DATAIN, clk => clk, MCNT => MCNT, count => count, addrl => addrl, cntlsim => cntlsim , address I sim => address I sim, intsim => intsim, addresslsim => addresslsim, address3sim => address3sim.

xxvn

addr2 => addrl, addrlsim => addrlsim, dm al => dm al, dma2 => dm al, status => status.
States
= > States,

w rlsim => wrlsim , w rlsim => wrlsim , clkl - > clkl, WEsim => Wesim, addriisim => addriisim, DataReadySim => DataReadysim, LlD istsSim l => L 1DistsSim 1, L lD istsSim l => LlD istsSim l, LlDistsSimS => LlDistsSimS, datai - > datai, datai => datai, dataS => dataS, d a ta o u t => d a ta o u t, reset => reset, POWON => POWON, ENTROPY => ENTROPY, INTERIA => INTERIA, ENERGY => ENERGY, CONTRAST => CONTRAST, IDM => IDM, IminusJlsim => IminusJlsim, MB => MB, LIDist => LIDist, ImageIndexout=> Imagelndexout, Finish => Finish
);

- *** Test Bench - User Defined Section *** tb ; PROCESS variable k;integer; BEGIN POWON < = T '; for j in 0 to 68 loop

XXVllI

reset < = '!'; clk<='l'; wait for 10 ns; clk <= not cUc; wait for 10 ns; POWON <= 'O'; reset <= 'O'; dma2 <= '1 '; count<="01001011 "; dm al <= '1'; k:=j*75+l; clk<='l'; wait for 10 ns; clk <= not clk; wait for 10 ns;

-- write ram by means o f dma;

for i in 0 to 74 loop addrl <= conv_std_logic_vector(i,8); clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; DAT AIN <=Data_array (i+k) ; end loop; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; dm al <= 'O'; for i in 0 to 75 loop clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; end loop; dma2 <= 'O'; for i in 0 to 60 loop clk <= not clk; wait for 10 ns; clk <= not clk; --15

-w rite ram by means of dma;

XXIX

wait for 10 ns; end loop; for i in 0 to 16 loop addr2 <= conv_std_logic_vector(i,4); clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; end loop;

clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns;

clk <= not clk; wait for 10 ns; clk <= not clk; wait for 10 ns; end loop; END PROCESS; --*** End Test Bench - User Defined Section *** Read_From_File; process(clkl) Variable indata_line:line; Variable indata:integer; variable b :integer :=0; file input_data_file;text open read mode is "C:/PROJECT/matlab/data/orig2.bin";

XXX

begin if rising_edge(clkl) and (h<=1024145) then -1024145-4762800 readline(input_data_file,indata_line); read(indata_line, indata); lD<=conv_std_logic_vector(indata,2); data_array(h) <=1D; h:=h+l; if endfile(input_data_file) then report "end of file"; file_close(input_data_fiIe); file_open(input_data_file, "C:/PROJECT/matIab/data/orig2.bin"); end if; end if; end process;

clock_gen:process begin C lk l< = 'l'; wait for 10 ns; clkl<='0'; wait for 10 ns; end process;

write_to_fiIe: PROCESS (clkl) variable outdata line: line; variable outdata:integer:=0; variable holdon:std_logie; file ontpnt data file: text open write mode is "C:/PROJECT/matlab/vhdl_output521_2.bin"; begin if (W E sim -1') then if rising_edge(clkl) then outdata:=abs(CONV_integer(LlDist)); write(outdata_line, outdata); writeline(output_data_file, outdata_line); end if; end if; end process; END;

XXXI

