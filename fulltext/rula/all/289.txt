Expressing Tonal Closure in Music Performance: Auditory and Visual Cues

Donovon Keith Ceaser
Macquarie University

William Forde Thompson
Macquarie University

Frank Russo

Ryerson University

digital.library.ryerson.ca/object/289

Please Cite: Ceaser, D. K., Thompson, W. F., & Russo, F. (2009). Expressing tonal closure in music performance: Auditory and visual cues. Canadian Acoustics, 37(1), 29-34.

library.ryerson.ca

Journal of the Canadian Acoustical Association - Journal de l'Association Canadienne d'Acoustique

MARCH 2009 Volume 37 -- Number 1
GUEST EDITORIAL / ÉDITORIAL INVITÉ TECHNICAL ARTICLES AND NOTES / ARTICLES ET NOTES TECHNIQUES
Clarifying Spectral And Temporal Dimensions Of Musical Instrument Timbre
Michael D. Hall, and James W. Beauchamp

MARS 2009 Volume 37 -- Numéro 1
1

3 23 29

Deconstructing a musical illusion: Point-light representations capture salient properties of impact motions
Michael Schutz and Michael Kubovy

Expressing tonal closure in music performance: Auditory and visual cues
Donovon Keith Ceaser, William Forde Thompson and Frank A. Russo

Perception of Synthetic Vowels by Monolingual Canadian-English, Mexican-Spanish, and Peninsular-Spanish Listeners - Errata 34 Cross-modal melodic contour similarity
Jon B. Prince, Mark A. Schmuckler and William F. Thompson 35

Other Features / Autres Rubriques
Book Reviews / Revue des publications Canadian News - Retirement of David Quirt What is New in Acoustics in Canada? CAA Prizes Announcement / Annonce de Prix Canadian News - Acoustics Week in Canada 2009 / Semaine Canadienne d'acoustique 2009
50 52 54 60 62

THE CANADIAN ACOUSTICAL ASSOCIATION P.O. BOX 1351, STATION "F" TORONTO, ONTARIO M4Y 2V9
CANADIAN ACOUSTICS publishes refereed articles and news items on all aspects of acoustics and vibration. Articles reporting new research or applications, as well as review or tutorial papers and shorter technical notes are welcomed, in English or in French. Submissions should be sent directly to the Editor-in-Chief. Complete instructions to authors concerning the required camera-ready copy are presented at the end of this issue.
CANADIAN ACOUSTICS is published four times a year - in March, June, September and December. The deadline for submission of material is the first day of the month preceeding the issue month. Copyright on articles is held by the author(s), who should be contacted regarding reproduction. Annual subscription: $30 (student); $70 (individual, institution); $300 (sustaining - see back cover). Back issues (when available) may be obtained from the CAA Secretary - price $10 including postage. Advertisement prices: $600 (centre spread); $300 (full page); $175 (half page); $125 (quarter page). Contact the Associate Editor (advertising) to place advertisements. Canadian Publication Mail Product Sales Agreement No. 0557188.

L'ASSOCIATION CANADIENNE C.P. 1351, SUCCURSALE "F" TORONTO, ONTARIO M4Y 2V9

D'ACOUSTIQUE

ACOUSTIQUE CANADIENNE publie des articles arbitrés et des informations sur tous les domaines de l'acoustique et des vibrations. On invite les auteurs à soumettre des manuscrits, rédigés en français ou en anglais, concernant des travaux inédits, des états de question ou des notes techniques. Les soumissions doivent être envoyées au rédacteur en chef. Les instructions pour la présentation des textes sont exposées à la fin de cette publication.
ACOUSTIQUE CANADIENNE est publiée quatre fois par année en mars, juin, septembre et décembre. La date de tombée pour la soumission de matériel est fixée au premier jour du mois précédant la publication d'un numéro donné. Les droits d'auteur d'un article appartiennent à (aux) auteur(s). Toute demande de reproduction doit leur être acheminée. Abonnement annuel: $30 (étudiant); $70 (individuel, société); $300 (soutien - voir la couverture arrière). D'anciens numéros (non-épuisés) peuvent être obtenus du Secrétaire de l'ACA - prix: $10 (affranchissement inclus). Prix d'annonces publicitaires: $600 (page double); $300 (page pleine); $175 (demi page); $125 (quart de page). Contacter le rédacteur associé (publicité) afin de placer des annonces. Société canadienne des postes - Envois de publications canadiennes - Numéro de convention 0557188.

EDITOR-IN-CHIEF / RÉDACTEUR EN CHEF
Ramani Ramakrishnan Department of Architectural Science Ryerson University 350 Victoria Street Toronto, Ontario M5B 2K3 Tel: (416) 979-5000; Ext: 6508 Fax: (416) 979-5353 E-mail: rramakri@ryerson.ca

EDITOR / RÉDACTEUR
Chantal Laroche Programme d'audiologie et d'orthophonie École des sciences de la réadaptation Université d'Ottawa 451, chemin Smyth, pièce 3062 Ottawa, Ontario K1H 8M5 Tél: (613) 562-5800 # 3066; Fax: (613) 562-5428 E-mail: claroche@uottawa.ca

ASSOCIATE EDITORS / REDACTEURS ASSOCIES
Advertising / Publicité
Jason Tsang 7 Parkwood Crescent Ottawa, ONTARIO K1B3J5 E-mail:jtsangeng@yahoo.ca

Canadian News / Informations
Jérémie Voix Sonomax Hearing Healthcare Inc 8375 Mayrand Street Montréal, QC, H4P 2E2, Canada Tel: (514) 932-2674 Fax: (514) 932-4994 E-mail: jvoix@sonomax.com

Research article / Article de recherche

EXPRESSING TONAL CLOSURE IN MUSIC PERFORMANCE: AUDITORY AND VISUAL CUES
Donovon Keith Ceaser, William Forde Thompson1, and Frank Russo2 1 - Department of Psychology, Macquarie University, Sydney, Australia 2 - Department of Psychology, Ryerson University, Toronto, Canada

ABSTRACT
We examined whether musical performers communicate tonal closure through expressive manipulation of facial expressions and non-pitch features of the acoustic output. Two musicians hummed two versions of Silent Night: one ended on the tonic of the scale and exhibited tonal closure; the other ended on the dominant and was therefore tonally unclosed. In Experiment 1, video-only recordings of the hummed sequences were presented to 15 participants, who judged whether the (imagined) melody was closed or unclosed. Accuracy was reliably above chance, indicating that the musicians expressed tonal closure in facial expressions and listeners decoded these cues. Experiment 2 was conducted to determine whether musicians also communicate tonal closure in acoustic attributes other than pitch. All tones in the hummed melodies were pitched-shifted to a constant mean value, but performances still differed in loudness, microtonal pitch variation, timing, and timbre. Participants judged whether audio-only recordings were closed or unclosed. Accuracy was not above chance overall, but was marginally above chance for judgement of one of the two singers. Results suggest that tonal closure can be mapped onto non-pitch aspects of performance expression, but is primarily restricted to the use of facial expressions.

RESUME
Nous avons examiné la communication de conclusion tonale chez les performeurs musicaux, et spécifiquement si elle se fait à travers les manipulations d'expressions faciales et de caractéristiques d'information acoustique autres que la hauteur du son. Deux musiciens ont fredonné une différente version de la mélodie de Sainte Nuit : l'une d'elle terminant sur la tonique de la gamme et donc ayant une conclusion tonale; et l'autre terminant sur la dominante et donc n'ayant pas de conclusion tonale. Lors de l'expérience 1, des extraits d'enregistrements vidéo sans sons des mélodies fredonnées ont été présentés à 15 participants, qui ont ensuite effectué un jugement selon la présence ou l'absence de conclusion tonale dans la mélodie (imaginée). Le niveau d'exactitude des participants excédait le niveau du hasard, indiquant que les musiciens exprimaient la conclusion tonale à travers de leurs expressions faciales et que ces indicateurs furent décodés par leurs auditeurs. L'expérience 2 a été effectuée afin de déterminer si les musiciens communiquaient aussi la conclusion tonale à travers les caractéristiques acoustiques autres que la hauteur du son. La hauteur de tous les sons musicaux dans les mélodies fredonnées a été changée à une hauteur moyenne constante, mais les performances étaient toutefois différentes en tant que force sonore, variations de hauteur microtonale, synchronisation, et timbre. Les participants ont effectué un jugement selon la présence ou l'absence de conclusion tonale dans des extraits d'enregistrement audio des mélodies. Dans l'ensemble, le niveau d'exactitude des participants n'excédait pas le niveau du hasard, mais l'exactitude des jugements envers l'un des deux musiciens excédait à peine le niveau du hasard. Ces résultats suggèrent qu'une conclusion tonale peut être établie à l'aide d'attributs d'expressions de performance autres que la hauteur des sons, mais qu'elle est généralement établie à l'aide d'expressions faciales.

1.0 Introduction
The performer is the middle link in a system of communication that extends from the composer who notates musical ideas onto a score to the listener who perceives, interprets, and experiences an acoustic realization of these ideas. The performer not only converts notated symbols (musical notes) into sound; they interpret the musical structure and convey this interpretation expressively (Palmer, 1997). That is, a critical goal of music performance is to communicate the struc29 - Vol. 37 No. 1 (2009)

ture of the music clearly to listeners (Gabrielsson, 1999). A number of researchers have investigated how musicians manipulate acoustic attributes in order to elucidate musical structure. For example, musicians often manipulate timing, dynamics (changes in sound intensity) and tempo (musical speed) in order to communicate or emphasize the temporal structure of music (Clarke, 1982; 1985; 1988; Povel, 1977; Repp 1992; Sloboda, 1983, 1985; Todd, 1985). Some expressive actions, such as a crescendo (getting louder), are easier to detect than others, such as a diminuendo (getting softer)
Canadian Acoustics / Acoustique canadienne

(Nakamura, 1987; Senju & Ohgushi, 1987). More generally, listeners may not decode all aspects of musical structure, so the communicative intentions of performers may be only partially realized. Recently, researchers have examined how expressive information from auditory and visual modalities is combined to communicate musical structure (for a review, see Schutz, 2008). In experiments that involve auditory-only, visual-only, and audio-visual conditions, participants show increased sensitivity to musical structure in audio-visual conditions (Krumhansl & Schenck, 1997; Vines et al., 2006). Indeed, visual information is often surprisingly informative. When participants are asked to make judgements about expressive intentions, participants may perform better in a visual-only condition than in an audio-only condition (Davidson, 1993). Thompson, Graham, and Russo (2005) reported that facial expression influence perceptions of interval size, dissonance, and emotional connotations. Thompson, Russo and Quinto (2008) confirmed that listeners unconsciously and automatically consider cues arising from the facial expressions of performers when forming an emotional interpretation of music. Schutz & Lipscomb (2007) reported that the judged duration of a marimba note was longer if accompanied by a video recording of a performer making a "long gesture" when striking the note than if accompanied by a video recording of a "short gesture." Finally, Thompson & Russo (2007) found that observers were able to differentiate the size of sung intervals on the basis of visual information alone. Judgements of size were well correlated with veridical interval size and appeared to be based on a combination of head movement, eyebrow raising and mouth opening. The findings underscore the importance of the visual modality for the perception of music. In the current investigation, we examined the manner in which musicians modify their use of performance expression in order to communicate tonal closure, both in their facial expressions and the expressive manipulation of sound attributes other than pitch. Musical closure is a general term that refers to the perception that a musical phrase or section has come to a permanent or temporary end. Tonal closure refers to the contributions of tonality to this effect, and occurs when a musical phrase ends on a tonally stable pitch, such as the tonic note or chord (e.g., as in a perfect cadence). Although tonal closure is an aspect of pitch structure, performers may introduce non-pitch cues to reinforce or clarify the perception of tonal closure, including temporal cues (ritards, duration lengthening), cues related to sound intensity (diminuendos), and even visual cues associated with facial expressions and gestures. Two experiments were conducted to determine whether tonal closure is mapped onto such non-pitch aspects of performance expression. Experiment 1 considered expressive uses of facial expression; Experiment 2 considered the expressive manipulation of acoustic cues.

communication of tonal closure. If listeners can perceive the difference between the tonally closed and unclosed clips by viewing the faces of singers alone (i.e. with no acoustic signal), then such a finding would corroborate and extend previous reports that facial expressions of performers reflect and communicate pitch structure.

2.1 Method
Participants. Fifteen undergraduate students (7 males and 8 females) were recruited from the University of Toronto community, ranging in age from 18 to 27 years (mean = 22.36), and possessing between zero and 14 years of musical training (mean = 7.53 years). All participants reported normal hearing. Stimuli. The stimuli consisted of sung recordings of the melody of Silent Night. This melody was selected because it is popular and highly recognizable. The final phrase of the song ("Sle-ep in hea-ven-ly peace") follows the diatonic scale pattern of 8-5-3-5-4-2-1 and implies a tonic-dominant-tonic (IV-I) harmonic accompaniment. Three experienced singers (one male and two females) were recruited to hum two versions of the final phrase of the melody. One version (original) ended on the tonic of the scale (as in the original melody) and was tonally closed; the other version ended on the dominant of the scale and was therefore tonally unclosed. More specifically, in the unclosed version, the last four notes of the original melody were reversed (1, 2, 4, 5), such that the final note of the melody (5) is the dominant. Note that the size of the final melodic interval (major second) was the same in both versions. Singers were instructed to stare directly into the camera as they hummed the tunes. Each singer hummed six examples of the closed and unclosed versions each. From the audiovisual recordings of these performances, 3 examples were selected for each singer and each condition of closure, yielding 18 recordings (3 examples X 2 conditions of closure X 3 singers). The video recordings (no sound) were extracted for use in Experiment 1; audio recordings (no video) were used in Experiment 2. Each clip was edited so that it began with the singer's inhaling breath, and ended after the first beat of the final bar. Procedure. Edited video clips were loaded into the Experiment Creator program. Each of the 18 clips was presented three times, yielding 54 trials presented in random order. Participants were tested in a sound-attenuated booth. They were told that they would be viewing video-only recordings of Silent Night, and that there would be two versions: a conventional version and a nonconventional version with an alternate ending. For each presentation, the task was to judge whether the imagined melody was closed or unclosed (forced choice). The experiment took between 20 and 30 minutes to complete. Following the experimental trials, participants were administered a questionnaire related to the cues that they used to make their judgements.

2.0 EXPERIMENT 1
Experiment 1 examined the role of facial expressions in the
Canadian Acoustics / Acoustique canadienne

Vol. 37 No. 1 (2009) - 30

2.2 Results
The proportion of closed responses for closed and open clips was 0.61 and 0.37 respectively. ANOVA was conducted with repeated measures on two factors: Singer (3 levels) and Closure (2 levels). There was a significant effect of Closure, F (1, 14) = 21.69, p < 0.001, confirming that performers expressed musical closure in their facial expressions and participants successfully decoded these cues. To further explore the role of facial expressions in the communication of musical closure, we examined the closed and unclosed clips with the highest decoding accuracy, focusing on three features: width of eye opening (squint), eyebrow height, and head height. These features were informally scrutinized because a post-experiment interview revealed that participants identified them as relevant to their judgements of closure. Measurements were taken from two video stills for each singer's clip, one at the onset of the first note (after the initial breath), and again at the end of the last note. Eye opening was measured from the top of the lower lid to the bottom of upper lid. Eyebrow position was measured from the top of the eyebrow to the bottom of upper lid. Head movement was measured by comparing the position of the chin at the beginning and end of the video clip. By subtracting the value obtained in the second still from the first, we obtained a measurement of the difference in facial position. Table 1 displays the change in measurements for each feature from the beginning to the end of each clip. The amount of change is shown in centimeters. Positive values for eye opening indicate that the eyes were wider at the end of the clip than at the beginning of the clip; positive values for eyebrow height indicate that the eyebrows were raised to a greater degree at the end of the clip than at the beginning of the clip; positive values for head height indicate that the chin was at a higher position at the end of the clip than at the beginning of the clip. Note that the values in the Table indicate measurements from the computer monitor and understate actual movements. A comparison of values for closed and unclosed clips suggests that, in comparison with closed clips, unclosed melodic endings were associated with reduced widening of the eyes, raised eyebrows, and raised chin. The greatest movements were observed for eyebrow height, consistent with findings on the use of facial expressions during music performance (Thompson & Russo, 2007). Specifically, for closed clips the eyebrows were raised more at the beginning of the clip than at the end of the clip, reflecting movement from instability to stability and closure; for unclosed clips the eyebrows were raised more at the end of the clip than at the beginning of the clip, reflecting the lack of

closure at the end of the clip.

2.3 Discussion
Participants reliably differentiated between tonally closed and unclosed clips based on visual cues alone. This finding confirms that musicians can express musical closure in the use of facial expressions and viewers are able to decode these expressive actions. A comparison of movement analyses for closed and unclosed clips suggests that eyebrow and head movement may be especially relevant to this effect. In comparison with facial movements associated with closure, facial expressions associated with non-closure involved raised eyebrows and chin relative to initial positions. These differences in the relative height of facial features may reflect the degree to which each ending violated or confirmed expectancies. When expectancies were fulfilled with a closed ending, the chin and eyebrows were not raised, or were lowered. When expectancies were violated with an unclosed ending, the chin and eyebrows were raised.

3.0 EXPERIMENT 2
We next assessed whether listeners can decode tonal closure on the basis of the acoustic aspects of performance expression other than pitch. Stimuli consisted of the audio-only recordings of "Silent Night" taken from the recordings described in Experiment 1. Because tonal closure is determined by pitch structure, it was necessary to disentangle the direct cues provided by pitch structure from the indirect cues provided by performance expression. To this end, Protools software was used to shift all tones in each performance to a constant mean pitch level. This procedure retaining expressive variations in intensity, timbre, and timing.

3.1 Method
Participants. 25 undergraduate students (12 males and 13 females) ranging in age from 18 to 28 (mean = 19.44) years were recruited from the University of Toronto community. Participants had between zero and 18 years of musical training (mean = 3.66 years). All participants reported normal hearing. Stimuli. Stimuli were a subset of the recordings described in Experiment 1. We selected three exemplars of closed and unclosed clips performed by a female singer (M) and two exemplars of closed and unclosed performed by a male singer (T), yielding 10 clips for use in the experimental trials. Each clip was presented 5 times, yielding 50 trials. Using Protools,

Table 1. Change in the position of facial features from initial to final notes of closed and unclosed clips (in cm).

Facial feature Eye width Eyebrow height Head height
31 - Vol. 37 No. 1 (2009)

Closed +0.64 -2.29 -0.64

Unclosed +0.38 +0.38 +0.51

Difference in change -0.26 +2.67 +1.15
Canadian Acoustics / Acoustique canadienne

each audio file was altered such that all tones were set to the same pitch. This procedure yielded a set of monotonic phrases that differed in performance expression. That is, they differed in terms of expressive variation in intensity, timing, and vocal timbre throughout the phrase. All pitches were adjusted to the mediant (third scale degree) of the key of the melody. This pitch was chosen so that the degree of pitch shifting required was approximately equal for the closed and unclosed conditions. Procedure. Experiment Creator was used to control presentation of the 50 trials and collection of responses. Participants were seated in front of a Macintosh computer in a sound-attenuated booth. They were first introduced to one example of an original and altered (pitch shifted) version of a closed and unclosed exemplar from each singer (i.e., four familiarisation trials). These trials were used to familiarise participants with the nature of the pitch-shifted stimuli and were excluded from the experimental trials. They were then given 10 practice trials: 5 unclosed and 5 closed trials. After each presentation, they indicated whether the clip was derived from a musically closed or unclosed melody (forced choice). No feedback was provided. The 50 experimental trials were then presented in random order and took about 30 minutes to complete. Following the experimental trials, participants were administered a questionnaire related to the cues that they used to make their judgements.

3.3. Discussion
Across the two singers, participants were unable to differentiate closed and unclosed audio clips when pitch cues were absent. However, closure was communicated with marginal significance by one of the two singers. Because closed and unclosed versions were equivalent in nominal pitch, judgements of closure for this singer must have been based on expressive cues related to intensity, microtonal pitch variation, timing, and vocal timbre. Thus, even though tonal closure is defined and communicated by pitch stability, other expressive cues may have also been introduced by the performer to convey closure. It is unclear how well these cues were perceived by viewers. The data do not allow us to determine which, if any, of these cues were used to decode tonal closure. However, the post-experiment questionnaire suggested that the unclosed ending seemed "faster" than the closed ending (expressive timing); closed endings had more "flow" than unclosed endings (expressive phrasing); and the tonal quality (vocal timbre) differed between closed and unclosed endings.

4.0 GENERAL DISCUSSION
The results of this investigation indicate that performers effectively communicate tonal closure through the use of nonpitch cues. These expressive cues are reliably communicated in the facial expressions of performers, and may be conveyed by certain performers in the expressive manipulation of nonpitch acoustic features. The findings corroborate and extend the growing evidence that performers make use of both auditory and visual aspects of music, and that "listeners" attend not only to musical sounds; they are also "viewers" that integrate visual information with the acoustic signal. Surprisingly, the expressive use of facial expressions was more reliably effective at communicating tonal closure than the acoustic cues introduced by the performer. In particular, the performer's capacity to communicate tonal closure through acoustic aspects of performance expression was surprisingly limited. Quite possibly, tonal closure may be most effectively communicated through musical structure and facial expressions, but to a limited extent through acoustic cues introduced by the performer. It is important to acknowledge that closed and unclosed melodies differed in a number of features, including the tonal stability of the final tone (tonal closure), the overall pitch height of the final tone, and the contour of the final four tones. Any of all of these differences may have influenced the facial expressions adopted by performers, as well as expressive variation in singing. For example, melodic contour varied with our manipulation of closure (closed melodies had a downward contour, unclosed melodies had an upward contour). Along with differences in the tonal stability of the final note of the melody, such contour differences likely contributed to the facial expressions adopted by performers, as well as the expressive variation in their singing. Quite possibly, production constraints associated with differences between
Vol. 37 No. 1 (2009) - 32

3.2 Results
The proportion of closed responses for closed and open clips was 0.58 and 0.53 respectively. ANOVA was conducted with repeated measures on two factors: Closure (closed or unclosed) and Example (1-5). There was no significant main effect for Closure, F (1, 24) < 1.0, nor for Example, F (1, 24) < 1.0. The interaction between Closure and Example was significant, F (1, 24) = 7.00, p < 0.05. The interaction was explored by running separate analyses of variance for each of the two singers. These analyses revealed that there was a marginally significant effect of Closure for the female singer, F (1, 24) = 4.16, p < 0.055. For this singer, the proportion of closure responses was higher for trials derived from tonally closed sequences (M = 0.64, SE = 0.059) than for trials derived from tonally unclosed sequences (M = 0.43, SE = 0.051). There was no significant effect of Closure for the male singer, F (1, 24) = 3.21, n.s. This pattern of results implies that some singers are more capable than others at using non-pitch expressive cues to communicate tonal closure. Follow-up acoustic analyses revealed that for the female singer, final tones of tonally open productions were more variable in pitch and amplitude that final tones of tonally closed productions (i.e., perturbations within tones were more frequent and extreme). For both singers, the final tones of tonally open productions were marginally longer (~ 125 msec) and possessed higher harmonicity (~ 1 to 2 dB; i.e., were less hoarse) than their closed counterparts.
Canadian Acoustics / Acoustique canadienne

closed and unclosed melodies contributed to the mapping of closure onto facial expressions and expressive variation on singing (difficulty in singing upward versus downward melodies, certain scale notes being more stable in memory and easier to produce than others). Nonetheless, the aim of this investigation was to document the ability of viewers to detect closure from facial expressions and other expressive actions, and they were indeed successful with this task. As many cues contribute to tonal closure in the acoustic realization of music, it is reasonable to assume that multiple cues also contributed to the perception of tonal closure in our investigation. More generally, it should be emphasized that musical closure invariably arises from a collection of convergent cues and it is not possible to manipulate one aspect of musical structure (e.g., tonal stability) without affecting other potential features (e.g., pitch height, pitch interval). As such, the relative contribution of potential cues to melodic closure cannot be determined from the current results. Nonetheless, because our participants explicitly judged closure, only those expressive actions that were relevant to closure should have influenced judgements, and therefore cannot be construed as an experimental confound. That is, the presence of multiple differences between conditions is compatible with the conclusion that melodic closure is mapped onto facial expressions and other expressive actions and communicated to perceivers. Participants were still able to distinguish between closed and unclosed melodies when provided with visual information alone. The finding extends previous evidence that facial features reflect music structure, including melodic, rhythmic, and tonal structure (Thompson et al., 2005; Thompson & Russo, 2007). Self-reports by participants, corroborated by an informal analysis of two videos, suggested that eyebrow and head movements were associated with expressions of closure and non-closure. In particular, relative to closed endings, raised eyebrows and a higher head position signaled an unclosed ending. As argued, facial expressions reflected multiple ways in which closed and unclosed versions differed, but only relevant aspects of facial expressions should have influenced direct judgements of closure. Although not the focus of the current investigation, future research may include a more standardized set of facial measurements. More generally, research is needed to determine whether facial expressions reflect tonal closure in a way that is distinct from the manner in which they reflect other aspects of musical closure. The cues used in expressing musical closure may reflect a general system of symbolic communication whereby facial and acoustic features express internal states. Across several cultures, lowered eyebrows signal increased dominance whereas raised eyebrows signal appeasement (Keating et al., 1981). Such cues are analogous to findings for musical and spoken stimuli. In music, melodies played at a higher pitch height are judged to be less aggressive and more submissive than melodies played at a lower pitch height (Huron, Kinney and Precoda, 2006). In speech, high or rising vocal pitch is associated with a lack of confidence, whereas low or falling vocal pitch is associated with confidence (Bolinger, 1964).
33 - Vol. 37 No. 1 (2009)

Familiarity with the music, along with sensitivity to closure, may have played a role in determining the current results. All participants were aware that the performer was singing Silent Night. This familiarity may have led participants to form a stable mental representation of the melody along with the facial expressions associated with sung versions of the phrase. Future research should be conducted to confirm that sensitivity to facial expressions of tonal closure is reliable for unfamiliar melodies. The current results may be interpreted within a multimodal framework, whereby one of two strategies for introducing facial expressions may be invoked: reinforcement or compensation. Using a reinforcement strategy, performers may form a mental representation of musical structure and emphasize that structure through their use of facial expressions. In the current investigation, performers appeared to underscore tonal closure through movements of the eyebrows and head, complementing their expressive manipulations of intensity, timing, and vocal timbre. Using the categories of facial expression outlined by Kurosawa and Davidson (2005), such expressions may be characterized as illustrators because they function to reinforce or illustrate a structural feature of the music. In this case, raising the eyebrows and head at the end of the melody acted to reinforce the lack of tonal closure that was conveyed by the pitch structure. Alternatively, performers may adopt a compensatory strategy. In this case, performers might evaluate the degree of tonal information available in pitch and rhythmic structure, compare this information to their expressive intentions, and evaluate the discrepancy between the two. Expressive actions are then introduced only to the extent that available cues become sufficiently clear to allow a typical listener to extract the structural information that the performer wishes to convey. For example, performers in this investigation appeared to compensate for a lack of tonal closure in open sequences through final tone lengthening. Again, this process of communicating musical structure may involve the expressive manipulation of acoustic cues but may also include facial expressions, gestures, and other body movements.

REFERENCES
Bolinger, D.L. (1964). Intonation across languages. In: J.H. Greenberg, C.A. Ferguson & E.A. Moravcsik (Eds.), Universals of Human Language, Vol. 2: Phonology. Stanford, CA: Stanford University Press, pp. 471-524. Clarke, E. F. (1982). Timing in the performance of Erik Satie's `Vexations'. Acta Psychologica, 50, 1-19. Clarke, E. F. (1985). Structure and expression in rhythmic performance. In P. Howell, I. Cross, & R. West (Eds.), Action and perception in rhythm and music (pp. 19-33). Stockholm: Publication issued by the Royal Swedish Academy of Music, No. 55. Clarke, E. F. (1988). Generative principles in music performance. In J. A. Sloboda (Ed.), Generative processes in music: The psychology of performance, improvisation. and composition (pp. 1-26). Oxford: Clarendon Press.
Canadian Acoustics / Acoustique canadienne

Davidson, J. W. (1993). Visual perception of performance manner in the movements of solo musicians. Psychology of Music, 21, 103-113. Gabrielsson, A. (1999). The performance of music. In D. Deutsch (Ed.), The Psychology of Music (Vol. xvi, pp. 807). San Diego, CA US: Academic Press, Inc. Huron, D., Kinney, D., & Precoda, K. (2006). Influence of pitch height on the perception of submissiveness and threat in musical passages. Empirical Musicology Review, 1, 170-177. Krumhansl, C. L., & Schenck, D. L. (1997). Can dance reflect the structural and expressive qualities of music? A perceptual experiment on Balanchine's choreography of Mozart's Divertimento no. 15. Musicae Scientiae, 1, 6385. Kurosawa, K., & Davidson, J. W. (2005). Nonverbal behavior in popular music performance: A case study of The Corrs. Musicae Scientiae, 9, 111-133. Nakamura, T. (1987). The communication of dynamics between musicians and listeners through musical performance. Perception & Psychophysics, 41, 525-533. Palmer, C. (1997). Music Performance. Annual review of Psychology, 48, 115-158. Povel, D. J. (1977). Temporal structure of performed music. Some preliminary observations. Acta Psychologica, 41, 309-320. Repp, B. H. (1992). Diversity and commonality in music performance: An analysis of timing microstructure in Schumann's "Traeumerei." Journal of the Acoustical Society of America, 92, 2546-2568.

Senju, M., & Ohgushi, K. (1987). How are the player's ideas conveyed to the audience? Music Perception, 4, 311324. Schutz, M. (2008). Seeing music? What musicians need to know about vision. Empirical Musicology Review, 3, 83 ­108. Schutz. M., & Lipscomb, S. (2007). Hearing gestures, seeing music: Vision influences perceived tone duration. Perception, 36, 888-897. Sloboda, J. A. (1983). The communication of musical metre in piano perfomance. Quarterly Journal of Experimental Psychology, 39, 273-293. Sloboda, J. A. (1985). Expressive skill in two pianists: Metrical communication in real and stimulated performances. Canadian Journal of Psychology, 39, 273-293. Thompson, W. F., & Russo, F.A. (2007). Facing the music. Psychological Science, 18, 756-757. Thompson, W. F., Graham, P., & Russo, F. A. (2005). Seeing music performance: Visual influences on perception and influence. Semiotica, 1(4), 177-202. Thompson, W. F., Russo, F. A. & Quinto, L. (2008). Audiovisual integration of emotional cues in song. Cognition & Emotion, 22, 1457-1470. Vines, B. W., Krumhansl, C. L., Wanderley, M. M., & Levitin, D. J. (2006). Cross-modal interactions in the perception of musical performance. Cognition, 101, 80-113.

PERCEPTION OF SYNTHETIC VOWELS BY MONOLINGUAL CANADIAN-ENGLISH, MEXICAN-SPANISH, AND PENINSULAR-SPANISH LISTENERS
Geoffrey Stewart Morrison School of Language Studies, Australian National University, Canberra, ACT 0200, Australia e-mail: geoff.morrison@anu.edu.au

ERRATA
The article published in Volume 34, Number 4 (December 2008), pp. 17­23 contained a number of typesetting errors. In the English abstract, delete "4105" Throughout the article, except in the figures and in the first paragraph of page 21, the phonetic symbols were incorrect. for // read K for /I/ read + for // read G for /E/ read ' for // read GK for // read C for // read R for // read RC for /V|/ read DVR^ for //, //, and // read DKRC, DGKRC, and DGRC for /Û/, /IÛ/, /Û/, and /EÛ/ read DKR, D+R, DGR, and D'R

Canadian Acoustics / Acoustique canadienne

Vol. 37 No. 1 (2009) - 34


