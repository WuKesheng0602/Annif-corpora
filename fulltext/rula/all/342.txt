Ryerson University

Digital Commons @ Ryerson
Computer Science Technical Reports Computer Science

4-16-2013

SQLite Page Caching Algorithm
Jason V. Ma
Ryerson University, jason.ma@ryerson.ca

Follow this and additional works at: http://digitalcommons.ryerson.ca/compsci_techrpts Part of the Databases and Information Systems Commons Recommended Citation
Ma, Jason V., "SQLite Page Caching Algorithm" (2013). Computer Science Technical Reports. Paper 3. http://digitalcommons.ryerson.ca/compsci_techrpts/3

This Technical Report is brought to you for free and open access by the Computer Science at Digital Commons @ Ryerson. It has been accepted for inclusion in Computer Science Technical Reports by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

SQLite Page Caching algorithm Modification

Jason Ma jason.ma@ryerson.ca April 16, 2013.

1

Contents
Introduction Project Objective SQLite Page Cache Overview SQLite Page Cache Modifications Performance Benchmarks Conclusion Appendix Reference 3 3 4 5 7 15 16 18

2

Introduction
SQLite is a database which can be easily embedded inside an application written in the C programming language. One common use is inside the Mozilla Firefox web browser. It supports a subset of the SQL language but was not intended to be a replacement for a multi-user database such as MySQL, Oracle or Microsoft SQL Server. The entire database is integrated into one *.c file and the command shell for the command line interface is inside another file. Thus to embed the database a developer just has to copy and paste the source code into their database. It also comes in another format with separate files for each component but is not recommended for use due to slower performance. SQLite's developers indicate there is a 5-10% performance improvement when using the amalgamation due to compiler optimizations for a single file [3]. SQLite supports connections via multiple threads, but it does not support intra-query parallelism. For example commercial databases can divide a large query so that it is run concurrently across separate CPUs. SQLite has a very coarse locking level. Since the database is located inside one file, the entire file is locked for writing. Concurrent reads can still occur on the file. It does not support finer levels of locking such as table or row locks.

Project Objective
Modify SQLite's page caching algorithm so that it will be able to determine which page cache to evict based on the number of historical memory references to a page.

3

SQLite Page Cache Overview
Illustration 1 displays the overall page cache architecture for SQLite. It implements two linked lists. The first is the dirty page list which is a linked list of pointers pointing to the actual data in the LRU list. The dirty page list keeps track of transient pages which have been marked as dirty. Once the number of memory references reaches zero, the page is moved from the dirty list to the LRU list. The source code (pcache.h, struct PGroup) documents this list as Least Recently Used (LRU) list, however from studying the source code it operates in a simple (First In First Out) FIFO mode. There is no indication in the data structures (struct PGroup, PgHdr1, PgHdr, PCache and struct PCache1) that it keeps track of how often a page was used in the past, nor is there any sort of order. When a page needs to be evicted the first item pointed to by the LRU list is removed. In our case this would be the page pointed to by the head pointer. The cache can operate in two modes: · · Shared: There is a global Page Group which can contain multiple caches. Each cache belongs to only one Page Group. Separate: Each Page Group has only one cache. Each cache belongs to only one Page Group.

SQLite also permits a third party to implement their own page caching algorithm for the LRU list via the function pointers seen below. A developer can write their own implementation and point the function pointers below to their own implementation. SQLite does not provide an interface for developers to modify the Dirty Page list.
typedef struct sqlite3_pcache_methods2 sqlite3_pcache_methods2; struct sqlite3_pcache_methods2 { int iVersion; void *pArg; int (*xInit)(void*); void (*xShutdown)(void*); sqlite3_pcache *(*xCreate)(int szPage, int szExtra, int bPurgeable); void (*xCachesize)(sqlite3_pcache*, int nCachesize); int (*xPagecount)(sqlite3_pcache*); /* Truncated list of functions */ }

SQLite's documentation also explicitly states that "The cache must not perform any reference counting. A single call to xUnpin() unpins the page regardless of the number of prior calls to xFetch()" [1]

4

Illustration 1: SQLite Page Cache Overview. Note each page in the LRU list can belong to different caches.

SQLite Page Cache Modifications
Two changes were made to the LRU a algorithm in two stages: 1. Sort the LRU list so that the head contains the least frequently referenced memory page and the tail contains the most frequently used page. 2. The array histLookup was added to improve insertion speed into the LRU list. The first change is self explanatory. To keep track of the historical references to the page, the function sqlite3PCacheSynchHist() was added to synchronize the historical reference (histRef member) between the structures PgHdr (dirty list structure) and PgHdr1 (LRU structure). Additional changes were made to the function pcache1Unpin. Change #2 was made to try and improve on the slow performance after making modification #1 above. The goal was to improve insertion performance to reduce the length taken to insert a new item into the LRU list. The idea is to add an index to the linked list so that an insert goes quickly without having to traverse the entire linked list to perform an inserted sorted by histRef value.

5

This was implemented by adding an array with a size the same as the largest number of histRef counts. For example if histRef wraps around when it reaches 30, the histLookup[] array is the same size. Illustration 2 displays the change. A detailed list of changes such as functions change is in the Appendix section.

Illustration 2: Modifications made to LRU algorithm. A reference count was added (e.g. Ref:0) and the index histLookup to permit quick inserts. histLookup always points to the last element with the same histRef so that an insert will be made immediately after the node it points to. After the insert histLookup is updated to point to the new node.

6

Performance Benchmarks
SQLite includes its own set of benchmarks under the test directory which is called from a Tcl script. The test run was speed1.test which contains many other sub tests. The tests require that development tcl libraries and headers be installed. 1. Add -g (symbols) to TCC and BCC makefile variables 2. Add -ltcl8.5 to LIBTCL makefile variable 3. make test 4. ./testfixture test/speed1.test Illustration 3 displays the output. Orig is the unmodified SQLite, Mod. LRU is the first modification in which the LRU list is sorted. Opt. LRU is when the histLookup index was added to try and improve insert performance into the list. The number behind it is the maximum histRef count before it wraps around. The histLookup array for each test was set to the same size as the maximum histRef. The initial modifications have disappointingly slowed the performance of the database down by 3 to 5 times compared to the unmodified SQLite.

Speed1.test
14000000
Execution time (micro seconds)

12000000 10000000 8000000 6000000 4000000 2000000 0 select1 select4 update1 delete1 drop1 random-del2 insert1 createidx select6 update3 delete2 random1
Subtest from Speed1.test

Orig Mod. LRU (15) Mod. LRU (30) Opt. LRU (15) Opt. LRU (30) Opt. LRU (60)

Illustration 3: Mod. is the first modification where the LRU list is sorted. Opt. is when the histLookup index was added to try and improve insert performance. Illustration 4 is a closeup of some copy/update/drop/delete operations. We can see that after adding

7

the histLookup array index it improves performance over the original modification of just sorting the LRU list. However it is still much slower than the unmodified SQLite. Illustration 4: Closeup of update/copy/delete operations since these ran faster then the histLookup index was added.

Speed1.test (close up of update/copy/delete)
5000000 4500000 4000000 3500000 3000000 2500000 2000000 1500000 1000000 500000 0 update4 copy1 copy2 copy3 random-del1 update3 delete1 delete2 drop1 random1 random-del2
Subtest from Speed1.test

Execution Time (micro seconds)

Orig Mod. LRU (15) Mod. LRU (30) Opt. LRU (15) Opt. LRU (30) Opt. LRU (60)

The Valgrind tool [2] was used to determine where most of the slow down was occurring. valgrind ­tool=callgrind ­trace-children=yes ./testfixture ../test/speed1.test After making change #1 we see that pcache1Unpin is consuming a lot of time (6.56 CPU execution time). The window on the right shows the source code where the slowdown is occurring. It is the code to traverse the linked list. Illustration 5 shows this output. If Valgrind is run on the unmodified SQLite, pcache1Unpin's CPU usage is only a small fraction and thus very far down the list. After implementing change #2 by adding the histLookup array index for quick inserts performance improves slightly and we see the overall CPU execution for this time go down from 8 th place down to 23rd place in Illustration 6. Valgrind shows the same parts of the source code which is slow. This is a decent improvement but is still slower than the unmodified SQLite. Illustration 6 shows this output.

8

The algorithm for pcache1Unpin works by: 1. Check if histRef is smaller or equal to the value in the head node of the linked list. If so we can quickly insert it to before the head node. 2. Check if histRef is larger or equal to the value in the tail node of the linked list. If so we can quickly append the new page to the end of the list. 3. Check histLookup index to see if we can quickly insert the value into the list. 4. Traverse list if #3 fails. Most of the cases should fall into step #1 to step #3, except when the histLookup array is being populated the first time. Additional coding improvements were made by adding the newly inserted page into the histLookup index in step #1 and step #2. After making these changes performance has significantly improved and is close to the original performance of SQLite as seen in Illustration 7 As the maximum number of historical references (histRef) for each page is increased from 15 to 30 there is a slight performance decrease as well. This value does not have any effect on the length of the LRU list. In Illustration 7 there will still be some overhead during the initial insert into the LRU linked list before the histLookup index array is populated. SQLite has a hash table for quick lookup of a memory page (**apHash in struct PCache1) when specifying a key (iKey) associated with the page. This is not useful for sorting of the LRU list since it is sorted on histRef instead of iKey.

9

Illustration 5: Valgrind output after making change #1 (sorting LRU list). pcache1Unpin is consuming 6.56 CPU units during execution. Code on right side shows 2.39 CPU units consumed just to traverse the linked list. Note: I'm unable to find how what units are used by Valgrind to measure CPU execution time.

10

Illustration 6: Valgrind output after adding the histLookup index for quick inserts. Performance is improved but still much slower than the unmodified SQLite.

11

Speed1.test after further optimization
14000000 12000000
Execution Time (micro seconds)

10000000 8000000 6000000 4000000 2000000 0 select1 select4 update1 delete1 drop1 random-del2 insert1 createidx select6 update3 delete2 random1
Subtest from Speed1.test

Orig Mod. LRU (15) Opt2 LRU (15) Opt2 LRU (30)

Illustration 7: Significant performance increase after adding original optimizations, performance almost the same as the default SQLite. Opt2 is the new optimization by ensuring histLookup is populated for all cases (see p.9). Opt2 is almost as fast as the unmodified database. From Illustration 7 and the associated data performance is close a few percentage points within original SQLite for most benchmarks. Illustration 8 shows the numbers used to generate the graph in Illustration 7. Random deletes (random-del1, random-del2) are still significantly worse by approximately 2 to 8.5x worse than default SQLite. SELECT benchmarks select4 and select5 are 25% and 27% slower compared to Opt2 LRU (15). update1 and delete1 are about 18% and 11% slower than default SQLite respectively.

12

insert1 insert2 select1 select2 createidx select3 select4 select5 select6 vacuum update1 update2 update3 update4 delete1 copy1 delete2 copy2 drop1 copy3 random1 random-del1 random-del2

Orig 465582 773463 635233 1838341 396145 287580 1318412 1683413 859303 665195 180882 1155061 499155 1498018 9973 558177 441137 569343 11848 43747 145629 233280 168091

Mod. LRU (15) 1594615 2799851 2832418 11893310 1551221 1434262 4925507 6467880 2719964 1910530 658463 4207034 1640951 4506684 701283 1704603 1793114 1971115 592399 129779 574572 1334421 3225259

Opt2 LRU (15) 457555 766634 568456 1815030 382539 287498 1650302 2139556 849291 658362 213863 1420840 506391 1507706 11159 543964 438189 549928 12612 41917 141679 582503 1477310

Opt2 LRU (30) 464109 770597 563469 1858608 377332 285867 1683368 2171434 863764 658689 216163 1443180 499641 1511417 10984 540905 433722 544757 12603 42014 140712 573923 1433234

Illustration 8: Numbers which generated the graph for Illustration 7

13

insert1 insert2 select1 select2 createidx select3 select4 select5 select6 vacuum update1 update2 update3 update4 delete1 copy1 delete2 copy2 drop1 copy3 random1 random-del1 random-del2

Orig 465582 773463 635233 1838341 396145 287580 1318412 1683413 859303 665195 180882 1155061 499155 1498018 9973 558177 441137 569343 11848 43747 145629 233280 168091

Mod. LRU (15) 1594615 2799851 2832418 11893310 1551221 1434262 4925507 6467880 2719964 1910530 658463 4207034 1640951 4506684 701283 1704603 1793114 1971115 592399 129779 574572 1334421 3225259

Opt2 LRU (15) 457555 766634 568456 1815030 382539 287498 1650302 2139556 849291 658362 213863 1420840 506391 1507706 11159 543964 438189 549928 12612 41917 141679 582503 1477310

Opt2 LRU (30) 464109 770597 563469 1858608 377332 285867 1683368 2171434 863764 658689 216163 1443180 499641 1511417 10984 540905 433722 544757 12603 42014 140712 573923 1433234

Illustration 10: Numbers for Illustration #7

Illustration 9: Valgrind output for unmodified SQLite. Illustration 9 shows the Valgrind output for unmodified SQLite and Illustration 9 shows the Valgrind output after the final optimization.

14

Illustration 10: Valgrind output for all modifications made so that the speed1.test is approximately the same as unmodified SQLite. These correspond to Illustration 7's Opt2 runs.

Conclusion
SQLite's page caching algorithm was modified so the LRU list is sorted by the number of past historical references so that the most frequently used page is kept in memory, but the least recently used is evicted. SQLite's unmodified LRU algorithm is just a FIFO and exhibits no signs that it keeps track of past references. An index was also added so that items added to the LRU list do not have to traverse the linked list to to perform a sorted insert. After two stages of optimizations, the final performance is very close to the unmodified SQLite database except for a few benchmarks which are still slow than the unmodified SQLite database.

15

Appendix
List of functions modified. Each modification has a comment beside it called "Jason" so it can easily be found by using the UNIX/Linux grep function. pcache.h
Function/Structure struct PgHdr Purpose Structure used to keep meta data for dirty list page. Structure used to keep meta data for LRU list page. Change(s) Made Added histRef member to keep track of how many times the page was referenced in the past. Added histRef member to keep track of how many times the page was referenced in the past. Moved some function declarations from pcache.c to pcache.h so some functions can be called from both pcache*.c files.

struct PgHdr1

struct pcache.h

pcache.c
Function/Structure sqlite3PCacheFetch sqlite3PcacheRelease sqlite3PcacheRef Purpose Obtain page from cache. Decrement reference count on page. This is different than histRef count. Increase reference count on page. This is different than histRef count. Remove page from dirty list. Mark page as clean Synchronize histRef counts between the dirty list and LRU list. · · · · Change(s) Made Initialization of histRef=0 Call pcache1HistRefInc Call sqlite3PcacheSyncHist Increment PgHdr->histRef and wrap around when it reaches the max e.g. 15 Call sqlite3PcacheSyncHist Call sqlite3PcacheSyncHist

sqlite3PcacheDrop sqlite3PcacheMakeClean sqlite3PCacheSyncHist

· ·

·

New function.

pcache1.c
Function/Structure pcache1HistRefInc pcache1Fetch Purpose Increment histRef count for LRU page. Fetch page by key value. Also Changes Made

· ·

New function Initialize histRef=0

16

allocates new pages as well. pcache1Unpin Mark page as unpinned (eligible for recycling) · · Inserted page based on histRef order Created quick look up table for inserts into list based on histRef New function

pcache1PrintList

Used for debug purposes to print out LRU linked list.

·

Debug information was added during testing to ensure the linked list contained histRef values in order. Sample of debug fprintf() messages below.
====== pcache1Unpin - Enter =====

pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin

pCache->nRecyclable: 6 pPage->iKey: 15 pPage->histRef: 0 pGroup->pLruHead.iKey: 13 pGroup->pLruHead.histRef: 0 pGroup->pLruTail.iKey: 14 pGroup->pLruTail.histRef: 2

pcache1Unpin - Adding page to front of list pPage->iKey: 15 pPage->histRef: 0 ============ Printing Linked list after adding to tail ============== PgHdr1->iKey 15 PgHdr1->histRef 0 PgHdr1->iKey 13 PgHdr1->histRef 0 PgHdr1->iKey 10 PgHdr1->histRef 0 PgHdr1->iKey 9 PgHdr1->histRef 0 PgHdr1->iKey 11 PgHdr1->histRef 0 PgHdr1->iKey 12 PgHdr1->histRef 1 PgHdr1->iKey 14 PgHdr1->histRef 2 ============ Linked list end ============== inc pCache->nRecyclable 7 ====== pcache1Unpin - Exit ===== pcache1PinPage - Dec. to pPage->pCache->nRecyclable: 6 pcache1PinPage -exit pcache1PinPage - Dec. to pPage->pCache->nRecyclable: 5 pcache1PinPage -exit ====== pcache1Unpin - Enter ===== pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pcache1Unpin pCache->nRecyclable: 5 pPage->iKey: 15 pPage->histRef: 0 pGroup->pLruHead.iKey: 13 pGroup->pLruHead.histRef: 0 pGroup->pLruTail.iKey: 12 pGroup->pLruTail.histRef: 1

17

pcache1Unpin - Adding page to front of list pPage->iKey: 15 pPage->histRef: 0 ============ Printing Linked list after adding to tail ============== PgHdr1->iKey 15 PgHdr1->histRef 0 PgHdr1->iKey 13 PgHdr1->histRef 0 PgHdr1->iKey 10 PgHdr1->histRef 0 PgHdr1->iKey 9 PgHdr1->histRef 0 PgHdr1->iKey 11 PgHdr1->histRef 0 PgHdr1->iKey 12 PgHdr1->histRef 1 ============ Linked list end ============== inc pCache->nRecyclable 6 ====== pcache1Unpin - Exit =====

References
[1] SQLite ­ Application Defined Page Cache http://www.sqlite.org/c3ref/pcache_methods2.html [2] Valgrind http://valgrind.org/ [3] SQLite Amalgamation http://sqlite.org/amalgamation.html

18

