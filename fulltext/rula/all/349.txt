Ryerson University

Digital Commons @ Ryerson
Librarian and Staff Publications Library

10-30-2012

"Feels like you've hit the lottery": Assessing the implementation of a discovery layer tool at Ryerson University
Courtney Lundrigan
York University, clund@yorku.ca

Kevin Manuel
Ryerson University, kevin.manuel@ryerson.ca

May Yan
Ryerson University, may.yan@ryerson.ca

Follow this and additional works at: http://digitalcommons.ryerson.ca/library_pubs Part of the Information and Library Science Commons Recommended Citation
Lundrigan, Courtney; Manuel, Kevin; and Yan, May, ""Feels like you've hit the lottery": Assessing the implementation of a discovery layer tool at Ryerson University" (2012). Librarian and Staff Publications. Paper 19. http://digitalcommons.ryerson.ca/library_pubs/19

This Conference Presentation is brought to you for free and open access by the Library at Digital Commons @ Ryerson. It has been accepted for inclusion in Librarian and Staff Publications by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

"Feels  like  you've  hit  the  lottery":  Assessing  the  implementation  of  a  discovery   layer  tool  at  Ryerson  University     
Courtney  Lundrigan,  Kevin  Manuel,  and  May  Yan  

  

   The  research  study  was  initiated  to  evaluate  and  assess  the  web-scale  discovery  (WSD)  service  Summon   to  coincide  with  its  launch  at  Ryerson  University  Library  in  September  2011.  The  project  utilized  a  mixed   methods  sequential  explanatory  strategy  and  applied  an  inductive  analysis.  Quantitative  data  was   gathered  with  two  online  questionnaires,  followed  by  a  series  of  focus  groups  with  students  for  the   qualitative  phase.  The  quantitative  phase  of  the  study  collected  over  6,200  survey  responses  (21%  of  the   university  population),  with  over  420  students  indicating  interest  in  participating  in  a  qualitative  follow- up  (6.7%  of  the  respondents).  The  survey  data  showed  that  most  undergraduate  students  rated   Summon  highly  in  ease  of  use;  however,  there  was  a  lower  satisfaction  with  the  large  quantity  of,  and   relevance  of  search  results.  Additionally,  participants  indicated  that  they  used  Summon  in  conjunction   with  other  research  tools,  such  as  Google  Scholar.  In  the  qualitative  phase,  small  focus  groups,  consisted   of  a  total  of  13  participants,  allowed  the  students  to  express  their  experiences  with  Summon  in  depth.   The  study  has  given  insight  into  the  role  of  Summon  in  terms  of  undergraduate  information-seeking   behaviour.  Participant  feedback  revealed  potential  improvements  for  Summon  at  Ryerson  and  will  be   useful  to  other  institutions  either  using  or  considering  the  use  of  similar  products.  Overall,  the  results   from  the  study  will  help  to  inform  Ryerson  Library  practice  surrounding  future  directions  in  reference,   instruction,  and  service  promotion.     

Abstract    

Introduction
   With  the  recent  explosion  of  web-scale  discovery  (WSD)  services  in  libraries,  both  users  and  library  staff   alike  are  adjusting  their  information  seeking  behaviors  in  response  to  these  new  tools.  The  evaluation   and  assessment  of  WSD  services  will  increasingly  become  a  priority  to  determine  user  satisfaction  and   value  of  investment.  Assessing  this  return  on  investment  of  a  WSD  service  in  any  library  is  a  challenging   task  and  would  require  the  use  of  multiple  avenues  of  study  to  evaluate  its  impact  comprehensively.   Upon  implementing  Summon1  in  September  2011,  a  team  of  three  librarians  at  Ryerson  University   Library  and  Archives  began  an  assessment  project.  Recognizing  the  various  potential  study  foci  -  such  as   usage  statistics,  information  literacy,  usability,  etc.  -  the  investigators  chose  to  evaluate  user  satisfaction   to  meet  a  gap  in  research  literature.        To  contextualize  this  study,  Ryerson  University's  library  serves  a  population  of  over  28,000  students,   including  about  2,300  graduate  students,  as  well  as  780  tenured  and  tenure  track  faculty  and   approximately  1,700  administrative  and  support  staff.  In  addition,  Ryerson  boasts  a  growing  distance   and  continuing  education  enrolment.  Situated  in  the  heart  of  downtown  Toronto,  the  library  is  the  only   one  serving  the  campus.        Given  that  the  use  of  questionnaires  is  one  of  the  preferred  methods  of  gathering  user  feedback  about   electronic  resources  in  libraries,2  the  investigators  chose  to  conduct  online  surveys  to  gather   quantitative  data  about  user  experience  with  Summon.  Seeking  feedback  from  the  entire  Ryerson  

community,  they  designed  an  online  questionnaire  to  be  completed  voluntarily.  After  receiving  approval   from  the  university's  Research  and  Ethics  Board,  the  team  promoted  and  launched  the  surveys  in   October  2011.       

Literature Review
   WSD  services  are  still  new  to  many  libraries,  so  researchers  are  only  starting  to  publish  library  literature   on  tools  such  as  Summon,  EDS,  primo  etc.  It  was  not  surprising  the  research  team  found  very  little   material  in  the  initial  literature  review  at  the  time  of  study  planning.  Using  federated  searching   technology  as  a  proxy  for  WSD  services,  researchers  anticipated  that  the  publication  of  library  literature   to  follow  in  a  similar  fashion.          Using  the  five  categories  of  federated  searching  literature  from  Way  and  Belliston,  Howland  &  Roberts3,   the  research  team  placed  the  current  state  of  Web  Scale  Discovery  library  literature  into  the  following   analogous  categories4:  (1)  Comparisons  of  WSD  products  currently  on  the  market  to  each  other  and/or   to  Google  Scholar,  (2)  reports  of  specific  WSD  product  implementations,  (3)  evaluation  of  the  technical   functionalities  of  products  and  how  well  WSD  worked  with  and/or  impacted  other  library  systems  or   resources,  (4)  Usability  and  design  of  WSD  and  (5)  articles  examining  librarians'  and  students'   perceptions  of  and  satisfaction  with  WSD  products.      At  the  time  of  the  study  planning,  published  articles  about  web  scale  delivery  focused  on  providing   information  to  librarians  who  were  in  the  decision  making  phase  of  discovery  service  acquisition.  As   such,  most  articles  were  about  WSD  product  announcements,  feature  comparisons5,  and   implementations  of  various  WSD  products.6  These  category  1  and  2  articles  are  regularly  published  as   WSD  products  evolve,  different  institutions  are  implementing  their  WSD  services,  and  they  continue  to   be  of  general  interest.      Early  adopters  of  discovery  layers  shared  their  evaluation  of  the  technical  functions  of  Summon  and  how   well  it  worked  with,  or  impacted  other  library  systems  and  resources.  In  "The  Impact  of  Web  Scale   Discovery,"  Way  reviewed  Summon's  impact  on  usage  statistics,  while  Silton  checked  the  linking  to  full   text  articles7,  and  Asher  et  al.  compared  searching  between  EDS  and  Summon.8  Many  more  researchers   studied  the  usability  of  various  WSD  products,  such  as  VueFind9,  Ebsco  EDS10,  Summon11,  and   WorldCat.12  Buck  &  Nichols,13  and  Breeding  explored  furthering  the  design  of  future  WSD  products.14      The  investigators  found  only  a  small  amount  of  library  literature  evaluating  user  satisfaction  with  using   WSD  in  the  context  of  their  research.  At  that  time,  only  three  articles  were  noteworthy.  In  their   discussion  of  their  Summon  implementation,  Slaven  et  al.  shared  qualitative  feedback  from  their  users   related  to  decisions.  Dartmouth  University  Library  summarized  their  user  assessment  results  in  an   internal  report15  at  a  high  level  by  user  groups.  Finally,  Howard  &  Wiebrands  shared  their  survey  of   librarians  and  staff  about  their  perceptions  of  Summon.16  Interestingly,  Way  had  already  identified  that   "studies  are  needed  to  examine  why  and  how  patrons  are  using  these  resources  and  how  easily  they  are   meeting  their  information  needs."17  The  research  team  designed  this  study  to  contribute  to  the  latter   category  of  literature,  with  the  aim  to  discover  user  satisfaction  in  the  context  of  their  search.            Nearly  a  year  after  the  initial  literature  review,  other  researchers  have  since  contributed  to  this  last   category  of  research.  Articles  surveyed  librarians  using  Summon  and  document  the  librarians'   perceptions  and  their  experiences  with  Summon  concentrated  on  the  impact  of  WSD  to  information  

literacy  instruction,  or  reference  service  delivery18  furthering  the  work  of  Howland  &  Wiebrands.  In   some  of  these  papers,  librarians  shared  feedback  from  and  about  their  patrons  and  their  satisfaction   with  using  Summon.  Cardwell  et  al.,  reported  feedback  from  lower  level,  upper  level  and  graduate   students  groups  based  on  their  instruction  and  reference  sessions.  Buck  &  Mellinger  in  their  survey   instrument,  asked  librarians  to  indicate  the  level  of  satisfaction  of  their  patrons  with  using  Summon.        Outside  of  librarians'  observations  or  perceptions  of  user  satisfaction,  only  a  few  publications  have   actually  examined  students'  satisfaction  with  Summon  using  direct  student  feedback.19  Mussel  &  Croft   presented  the  results  of  their  satisfaction  survey  of  distance  education  students.20  Varnum  only   summarized  a  survey  of  library  users  of  their  Summon  implementation,  but  did  not  elaborate  on  the   composition  of  respondents.  Outside  of  Summon  no  other  WSD  platform  users  have  yet  reported  user   satisfaction  evaluation  results  of  those  systems.  Ryerson's  study  is  differentiated  from  some  of  the   above  studies  in  terms  of  scale  and/or  survey  methodology  as  a  both  a  qualitative  and  quantitative   study  and  aims  to  fill  this  gap  in  the  existing  research  on  WSD.  

Methodology
   In  this  study,  the  central  research  questions  gauged  the  user's  ease  of  use  and  the  level  of  satisfaction   with  Summon.  The  investigators  implemented  a  multi-phased  project  that  utilized  a  mixed  methods   sequential  explanatory  strategy.  They  then  applied  an  inductive  analysis  that  would  reveal  insight  into   the  information  seeking  behaviour  of  the  respondents.        The  initial  research  design  included  two  online  questionnaires  to  be  followed  by  a  series  of  focus  groups   with  students,  thereby  collecting  both  quantitative  and  qualitative  data.  Questionnaire  participants   would  be  self-selected  from  the  Ryerson  community  and  were  not  required  to  have  previous  experience   with  Summon  or  to  be  active  library  users.  Participants  would  also  had  the  option  to  volunteer  for  post- survey  qualitative  interviews  when  completing  the  questionnaire.        Survey  Monkey  Gold  level  was  selected  as  the  questionnaire  tool  as  it  provided  the  required  online   accessibility  and  analysis  tools.  The  surveys  drew  from  a  participant  pool  that  would  consist  of  all   Ryerson  Library  users,  faculty,  staff,  students  and  other  community  members.  Overall  the  goal  of  the   surveys  was  to  produce  a  representative  sample21  of  the  Ryerson  community  and  their  user  experience   with  Summon.      Phase  one  of  the  project  was  conducted  in  September  and  October  2011.  A  questionnaire  with  10  open-   and  closed-ended  questions  was  created  with  the  first  five  questions  collecting  demographic   information  such  as  enrollment  and  degree  status,  faculty,  program  and  gender.    The  final  five  questions   asked  the  respondent  about  their  information  search  behaviour  and  awareness  of  Summon.        Posters  promoting  the  questionnaire  were  placed  around  the  campus  and  the  team  utilized  the  library's   various  social  media  outlets  to  solicit  survey  response.  Using  the  library's  news  blog,  a  post  linking  to  the   questionnaire  was  published  at  the  time  of  its  launch  and  in  the  days  leading  up  to  the  deadline  for   participation.  The  team  also  reached  out  to  users  via  the  Ryerson  Library's  Facebook  page,  which  has   1,022  `likes,'22  and  the  library's  Twitter  feed,  which  has  1,197  followers.23       

Despite  having  offered  an  incentive  of  $50  gift  certificates  from  the  Ryerson  University  Bookstore,  the   questionnaire  drew  only  191  responses,  below  the  desired  400  participants  to  provide  a  more   representative  number  of  responses  from  the  campus  population.24  Questionnaire  participants  were   eligible  for  the  draw  for  the  incentives  by  voluntarily  supplying  their  institutional  email  address.  The   survey  was  available  from  September  28,  2011  until  the  end  of  October  2011.      Overall,  the  main  goal  of  the  first  survey  was  to  create  an  awareness  of  Summon  and  to  explore  some  of   the  initial  feedback  to  inform  the  development  of  questions  for  the  second  survey.  The  results  the  first   survey  will  be  briefly  noted  here.  56%  of  respondents  had  used  Summon  while  74.7%  indicated  they   planned  to  use  it  for  their  next  search,  whereas  10.6%  would  not  use  it  again,  and  14.7%  were   undecided.        For  the  second  phase  of  the  study,  another  questionnaire  was  developed  in  November  2011.  Again,  it   was  a  combination  of  open-  and  closed-ended  questions,  but  with  10  ­  15  questions  that  were  funneled   based  on  the  respondent's  status  and  experience  using  Summon  in  their  last  academic  research  activity   (see  Appendix25).  Similar  to  the  first  questionnaire,  the  beginning  of  this  survey  collected  demographic   information  such  as  gender,  faculty,  program,  and  enrollment  and  degree  status.  For  the  remainder  of   the  survey,  the  questions  asked  respondents  about  their  information  search  behavior  in  their  last   academic  search  assignment.  More  specifically,  the  investigators  wanted  to  know  if  they  used  Summon,   its  ease  of  use,  their  satisfaction  with  the  tool,  and  what  other  resources  they  use  to  search  for   academic  information.        In  an  effort  to  draw  a  higher  response  rate  in  the  second,  more  detailed  questionnaire,  the  investigators   offered  a  more  substantial  incentive  of  three  iPads.  As  with  the  first  questionnaire,  respondents   provided  their  institutional  email  address  voluntarily  in  order  to  be  eligible  for  the  prize  draw  and  only   included  students.        In  addition  to  the  social  media  outlets  and  poster  distribution,  the  team  used  a  campus-wide  emailing   system  to  reach  potential  respondents.  The  second  questionnaire  was  available  from  November  4  ­   December  9,  2011.  With  the  campus-wide  email,  distributed  just  days  before  the  questionnaire's   closure,  the  number  of  respondents  viewing  the  survey  jumped  from  a  few  hundred  to  6,344!        Such  a  large  number  of  responses  to  the  second  questionnaire  may  indicate  that  library  users  were   more  inclined  to  participate  because  of  the  more  substantial  prizes  offered,  in  comparison  with  the  first   questionnaire.  It  should  be  noted  though  that  141  of  191  respondents  (74%)  provided  their  contact   information  for  the  first  questionnaire,  whereas  3,930  of  6,344  respondents  (61%)  provided  their   contact  details  for  the  second  questionnaire.  These  numbers  demonstrate  that  many  survey  participants   were  not  solely  motivated  by  the  prize  draws.      The  second  questionnaire  provided  the  option  for  respondents  to  volunteer  to  participate  in  follow-up       focus  groups  or  interviews,  and  participants  were  selected  from  this  pool  of  community  members.  In  the   second  survey,  424  students  indicated  an  interest  to  participate  in  focus  groups  which  were  conducted   in  February  2012  with  9  undergraduate  and  4  graduate  students.  The  turnout  to  the  focus  groups  was   much  lower  than  expected  but  the  timing  of  the  scheduled  sessions  unknowingly  coincided  with  some   midterm  exams.        In  future  evaluation  and  assessment  projects,  research  teams  should  consider  the  use  of  campus-wide   email  systems  to  reach  as  many  potential  project  participants  as  possible.  While  both  questionnaires  

yielded  valuable  information  about  user  satisfaction  with  the  WSD  service  at  Ryerson,  a  higher  volume   of  feedback  was  gathered  from  the  second  questionnaire  and  has  been  invaluable  in  moving  the  project   forward.     

Results and Discussion
   The  second  survey  collected  6344  responses  with  6280  (99%)  consenting  and  64  (1%)  declining  to   participate.  5363  (84.5%)  respondents  finished  the  survey.  In  terms  of  gender,  the  respondents  were   59.2%  (3238)  female  and  40.4%  (2210)  male,  and  the  status  distribution  was  4861  (88.9%)   undergraduates,  452  (8.3%)  Masters  students,  80  (1.5%)  PhD  students,  12  (0.2%)  faculty,  53  (1%)  staff   and  10  (0.2%)  research  assistants.  The  percentage  of  student  status  responses  was  fairly  reflective  of  the   actual  student  status  distribution  at  Ryerson.  For  enrollment,  4347  (81.8%)  were  full-time  students,  858   (16.1%)  were  part-time  students,  and  111  (2.1%)  were  not  students.  The  top  three  faculties  that  replied   to  the  survey  were  the  Ted  Rogers  School  of  Management  (business)  -  1517  (27.7%),  Engineering,   Architecture  and  Science  -  991  (18.1%),  and  Community  Services  (health/medical)  -  937  (17.1%).      The  questionnaire  asked  the  respondent  to  identify  a  recent  assignment  where  they  had  to  search  for   academic  information  and  to  use  that  scenario  to  answer  the  rest  of  the  questionnaire.  As  for  the   breakdown  of  the  assignments,  3776  (71%)  of  respondents  were  writing  an  essay,  while  493  (9.3%)  were   writing  an  article/thesis,  373  (7%)  were  preparing  for  a  presentation,  315  (5.9%)  were  preparing  for  a   lab.  359  (6.8%)  were  working  on  other  academic  research  (case  studies,  preparing  for  exams,  etc.).      When  assignment  type  was  cross-tabulated  by  subject  of  search26  (see  Table  1),  essay  was  predominant   in  nearly  all  subjects  of  search  -  Art  and  Design  (75.9%),  Business  (71.6%),  Communication  (52.8%),   Education  (95.7%),  Engineering  (31.3%),  Health/Medicine  (82.5%),  Humanities  (92.6%),  and  Social   Science  (88.9%).  Engineering's  lower  response  were  offset  by  the  increase  in  research  at  25%  of   responses27,  and  working  on  a  Lab  (24.4%).  Science  respondents  were  the  only  respondent  with  another   assignment  type,  working  on  a  Lab  (35.9%),  ahead  of  essay  (32%).       
Health/Medicine   Communication   Assignment   type/Subject  of   Search   Social  Science   88.9%   3.0%   6.7%   1.0%  

Art  &  Design  

Engineering  

Humanities  

Education  

Business  

General  

Essay   Presentation   Research   Lab  Related  

75.9%   9.7%   11.2%   1.1%  

71.6 %   9.9 %   14.0 %   2.0 %  

52.8%   15.3%   15.3%   15.3%  

95.7%   1.7%   1.7%   .0%  

31.3%   14.8%   25.0%   24.4%  

53.3%   13.3%   26.7%   .0%  

82.5%   5.8%   9.1%   1.2%  

92.6%   3.1%   3.3%   .9%  

32.0%   6.4%   25.1%   35.9%  

Science  

Exam  Prep   Project  

.7%   .7%  

.7%   1.1 %  

.0%   .4%  

.0%   .0%  

1.5%   1.1%  

6.7%   .0%  

.0%   .5%  

.0%   .0%  

.0%   .3%  

.0%   .1%  

Table  1  Assignment  type  by  subject  of  search  

Overall,  the  majority  of  undergraduate  students  were  writing  essays  (74.4%),  followed  by  research   (8.8%),  working  on  a  lab  (6.7%),  preparing  a  presentation  (6.6%).  Project  and  exam  preparation  were   less  than  1%  each.      When  asked  if  they  had  used  Summon  to  locate  academic  information,  3235  (60.9%)  of  respondents  had   used  it  while  2081  (39.1%)  had  not  used  it.  1028  participants  skipped  the  question.    

  

   Respondents  were  asked  how  easy  Summon  was  to  use  and  655  (20.5%)  participants  found  it  extremely   easy,  1423  (44.6%)  very  easy,  946  (29.6%)  moderately  easy,  134  (4.2%)  slightly  easy,  and  33  (1%)  not  at   all  easy.  When  filtered  for  just  undergraduate  students,  the  results  were  very  similar  with  19.89%   finding  it  extremely  easy,  44.66%  very  easy,  30.25%  moderately  easy,  4.36%  slightly  easy,  and  0.84%  not   at  all  easy.  Accordingly,  these  results  produced  a  positively  skewed  curve.      In  the  next  question,  respondents  were  asked  how  easy  it  was  to  find  resources  when  using  Summon.   394  (12.4%)  indicated  it  was  extremely  easy,  1119  (35.1%)  very  easy,  1290  (40.4%)  moderately  easy,  298   (9.3%)  slightly  easy,  and  90  (2.8%)  not  at  all  easy.  Cross-tabulating  the  variable  ease  of  finding  resources   with  student  status  revealed  that  within  the  undergraduate  sample,  12.07%  found  it  extremely  easy,   35%  very  easy,  40.86%  moderately  easy,  9.46%  slightly  easy,  and  2.62%  not  at  all  easy.  Again,  the   responses  produced  a  positively  skewed  curve  of  results.      Responses  to  the  open-ended  question28  helped  clarify  some  of  the  reasons  for  ease  of  finding   resources'  lower  ratings.  There  were  1678  comments  from  users  that  rated  ease  of  finding  resources   from  moderately  easy  to  not  at  all  easy.  260  respondents  left  a  negative29  comment,  22  were  directly   related  to  a  technical  problem  with  document  retrieval  with  the  OpenURL  resolver30  or  issues  with  full   text  access.        Some  usability  issues  in  the  comments  echoed  the  finding  of  Gross  and  Sheridan.31  For  example,  book   reviews  were  confused  with  records  of  a  book:     "about  50%  of  the  search  results  were  1-page  book  reviews,  not  very  helpful"   "Advanced  Search  to  find  what  I  need,  since,  if  I  don't,  I  end  up  with  tons  of  reviews  about  the   book/article  I'm  trying  to  find  rather  than  the  thing  itself"   "[...]Dammit,  I  want  books".          Students  demonstrated  difficulty  understanding  the  differences  between  various  formats  of  the   information  in  the  result  set  which  was  then  exacerbated  by  some  users'  preference  for  one  format  over   another  either  due  to  research  style  or  habit:   "I  found  that  it  was  a  little  difficult  differentiating  the  types  of  sources  these  search  results   provided."   "When  I  want  resources,  I  usually  look  for  a  specific  type"   "I  usually  know  what  I'm  looking  for,  that  is,  I  know  if  it's  a  book  or  a  journal".  

Summon  Users  

     Predominately,  the  negative  comments  were  about  the  size  of  the  result  set  for  respondents'  queries.   Without  knowing  the  actual  keywords  used,  the  investigators  are  unable  to  further  determine  if  the   volume  of  the  information  is  from  the  nature  of  WSD  searches  or  the  use  of  vague  keywords32  or  other   flawed  search  strategies.      In  terms  of  satisfaction  with  Summon,  415  (13%)  respondents  were  extremely  satisfied,  1279  (40.1%)   were  very  satisfied,  1147  (35.9%)  were  moderately  satisfied,  272  (8.5%)  were  slightly  satisfied,  and  78   (2.4%)  were  not  at  all  satisfied,  producing  another  results  curve  that  was  positively  skewed.     

Figure  1  Satisfaction  ratings  by  undergraduate  Summon  users  

  

When  just  examining  the  undergraduate  responses  and  satisfaction,  12.98%  were  extremely  satisfied,   39.81%  were  very  satisfied,  36.32  were  moderately  satisfied,  8.69%  were  slightly  satisfied,  and  2.2%   were  not  at  all  satisfied  (see  Figure  1).      Compared  with  graduate  responses,  there  was  a  very  similar  positively  skewed  curve,  demonstrating  a   consistency  in  the  satisfaction  with  Summon  with  the  student  respondents  in  general.        In  Buck  and  Mellinger's  survey  of  perceived  satisfaction  by  librarians  of  undergraduates  using  Summon,   the  result  was  that  49%  were  satisfied.33  In  the  Ryerson  study,  the  undergraduates  that  were  very   satisfied  and  extremely  satisfied  made  up  of  over  52%  of  the  respondents.  If  including  respondents  that   rated  that  they  were  even  moderately  satisfied,  the  numbers  goes  up  significantly  to  89%  in  both  the   undergraduate  and  the  overall  survey  population.       

While  many  users  found  the  product  very  or  extremely  easy  to  use,  their  overall  satisfaction  level  was   less  positively  skewed.  Such  data  indicates  that  participants  did  not  confuse  ease  of  use  with   satisfaction.  For  example,  some  indicated  that  Summon  was  extremely  easy  to  use,  but  were  only   moderately  satisfied  with  it.  This  may  have  been  because  it  did  not  fully  meet  their  research  needs  or   they  were  more  satisfied  with  another  product.  This  may  be  one  of  the  reasons  the  satisfaction  ratings   were  lower  than  ease  of  use  ratings  as  demonstrated  in  Figure  1.      As  with  many  evaluation  and  assessment  projects,  the  study  conducted  reflects  a  snapshot  in  time.      While  all  of  the  feedback  is  valuable,  the  data  collected  is  representative  of  user  satisfaction  with  the   product  at  a  time  when  the  service  was  relatively  new  at  Ryerson  and  before  Summon  implemented   Index-Enhanced  Direct  Linking.  Serial  Solution  had  indicated  initially  an  average  of  20%  improvement  to   resources  over  link  resolvers,34  this  number  is  to  increase  over  time  as  the  vendor  further  enhances  this   feature.  The  resolution  of  technical  problems  may  result  in  an  increase  in  the  ease  of  finding  resources   ratings.                                                                                                                                                                                                                                                                                                                                                                                                                            

Figure  2  Resources  consulted  by  undergraduate  Summon  users=  

  

In  a  cross-tabulation  of  the  type  of  resources  that  undergraduate  students  consulted  in  a  search  for   academic  information  (see  Figure  2),  the  results  illustrated  that  1822  used  the  Ryerson  University   Library,  985  searched  Google  or  other  search  engines,  973  asked  a  professor  or  instructor,  599  used   other  libraries  (public,  other  universities),  559  asked  friends  (including  social  media),  and  534  used   websites  (not  search  engines).  The  respondent  could  select  one  or  more  of  these  options.      The  Library  was  the  predominant  resource  in  the  results  for  undergraduate  students.  Whether  or  not   this  high  level  of  response  was  skewed  because  the  respondents  were  influenced  by  answering  a  

Library-sourced  survey  is  unknown.  The  value  of  an  instructor's  opinion  was  also  of  importance  to   students.  Not  surprisingly  the  use  of  Google  and  other  search  engines  scored  quite  high  as  well.  As   Ryerson  is  located  in  the  centre  of  large  metropolitan  area  with  two  other  universities,  it  is  also  not   unexpected  that  a  number  or  responses  for  the  use  of  another  library,  either  public  or  academic,  is   present.  The  use  of  friends  as  a  resource  to  find  academic  information  was  evident,  as  well  as  the  use  of   non-search  engine  websites.      The  value  of  the  instructor's  endorsement  was  further  highlighted  by  comments  to  open  ended  survey   questionnaires  and  the  focus  group  where  both  undergraduate  and  graduate  students  expressed  the   best  way  to  increase  use  of  Summon  is  by  direct  instruction  in  class.  Students  often  will  follow  the   direction  of  their  instructor:     "If  the  professor  tells  me  what  to  do,  I  just  do  it  that  way"   "The  way  I  learned  was  through  my  professors  "     

Figure  3  Undergraduate  student  satisfaction  ratings  by  subject  of  search  

  

When  analysing  the  level  of  satisfaction  amongst  undergraduate  students  that  has  been  cross-tabulated   with  the  subject  of  the  search,  it  revealed  that  most  of  the  topics  of  research  were  very  satisfied  -  at   around  40%  -  with  the  Summon.  The  one  exception  was  in  the  subject  of  education  which  had  a  lower   very  satisfied  result  at  25%  and  may  be  the  result  of  a  preference  of  using  a  particular  database  such  as   ERIC  for  their  research  (see  Figure  5).  Accordingly,  there  were  a  higher  number  of  moderately  satisfied   with  education  as  a  subject  search  at  55.36%  compared  to  the  other  subjects  typically  around  35%.   Humanities  as  a  subject  search  had  the  highest  combined  slightly  satisfied  and  not  at  all  satisfied  at   nearly  15%  compared  to  10%  for  most  of  the  other  subjects.       

Figure  4  Satisfaction  Rating  of  Summon  of  all  users  by  database  types  used  

  

In  another  cross-tabulation,  a  comparison  was  conducted  using  the  satisfaction  with  Summon  with   other  types  of  resources  to  find  academic  information  (see  Figure  4).  When  looking  just  at  respondents   who  only  used  Summon,  13.31%  were  extremely  satisfied,  40.47%  were  very  satisfied,  35.64%  were   moderately  satisfied,  8.29%  were  slightly  satisfied,  and  2.3%  were  not  at  all  satisfied.        When  thinking  about  the  implementation  of  Summon,  it  was  necessary  to  consider  how  other  resources   would  compare  such  as  databases  or  Google.  The  results  from  the  survey  illustrated  that  those   respondents  who  had  only  used  Summon  had  a  very  similar  satisfaction  rating  to  those  who  had  also   used  Google  or  another  multi-disciplinary  databases.  Accordingly,  these  results  supported  other   evidence  collected  from  the  focus  groups  that  Summon  provided  the  `Google-like'  search  experience   and  was  responding  to  the  research  needs  of  the  Library's  users.          One  anomaly  that  did  come  out  of  the  results  of  satisfaction  with  Summon  when  compared  to  other   resources  was  that  those  respondents  who  had  also  used  subject  specific  databases  gave  a  lower   satisfaction  rating  than  those  who  had  used  Google  or  other  multi-disciplinary  databases.  Their   responses  did  not  present  the  same  positive  distribution.  When  conducting  the  focus  groups,  it  was   revealed  in  the  session  with  graduate  students  that  they  had  preferred  using  specific  subject  databases   for  their  research  rather  than  broader  searching  resources.  It  is  therefore  not  surprising  that  these   graduate  students  commented  that  the  results  from  Summon  were  too  general  and  broad  for  the   purposes  of  their  research  needs.  But  they  did  recognize  that  it  was  a  useful  starting  point  for  most   undergraduate  students.  This  type  of  a  preference  for  subject  specific  databases  may  be  the  reason  why   users  who  also  used  subject  specific  databases  rated  Summon  lower  in  satisfaction.       

Figure  5  Satisfaction  rating  of  summon  by  patrons  also  using  named  resources  

  

Some  interesting  results  came  from  the  levels  of  satisfaction  from  users  of  resources  other  than   Summon  (see  Figure  5).  In  particular,  users  of  subject  specific  databases  such  as  JSTOR,  CINAHL  and   Medical  (ProQuest  Nursing,  PubMed  etc.)  ranked  Summon  quite  high,  with  well  over  30%  of   respondents  selecting  very  satisfied  and  higher.    On  the  other  hand,  ERIC  and  art  databases  (Avery,   ArtStor,  etc.)  had  significantly  lower  satisfaction  results  in  comparison,  where  most  were  only   moderately  satisfied  at  66%  and  71%  respectively.  These  results  reflect  focus  group  findings  that  within   certain  fields  of  research  there  is  a  preference  for  select  database  resources.  Given  the  low  numbers  of   responses  that  mentioned  specific  databases,  this  information  -  while  of  interest  -  should  not  be   considered  to  be  statistically  significant  or  representative.     

Figure  6  Usefulness  of  help  formats  by  status  

  

In  addition  to  data  collected  about  satisfaction  and  ease  of  use,  the  investigators  asked  for  feedback   about  the  respondents  preferred  method  of  getting  help  with  the  product  (see  Figure  6).  Contrary  to   conclusions  that  users  prefer  self-serve  help  tools  and  digital  interactions,  the  most  popular  amongst  all   user  groups  surveyed  was  to  receive  in-person  help  at  the  reference  desk.  Other  preferred  methods   include  librarian  demonstrations  in  a  classroom  setting  or  a  workshop,  followed  by  FAQs  and  online  chat   services.     

Non-Summon  Users  
   Another  question  that  produced  some  intriguing  results  when  analyzed  was  comparing  the  types  of   resources  by  undergraduate  respondents  who  had  not  used  Summon  (see  Figure  7).  

Figure  7  Resources  consulted  by  undergraduate  students  that  did  not  use  summon  

  

The  majority,  1357,  had  used  the  Ryerson  University  Library,  compared  to  1082  that  had  used  Google.   590  respondents  had  consulted  their  professors  whereas  393  had  asked  friends  about  resources  for   academic  information.  As  for  the  use  of  websites,  there  were  450  responses  and  335  had  used  libraries,   such  as  other  universities  or  public.  Table  2  presents  the  other  named  databases  used  by  non-Summon   Users  in  descending  order.     
Database  Used   Google  and  Other  Search  Engines   ProQuest   JStor   Ebscohost   Other  Medical  (ProQuest  Nursing,  PubMed  etc.)   Academic  Search  Premier   CINAHL   Other  Business  (GMID,  PMB,  DataStream  etc.)   ERIC   Number  of  Responses   1082   49   26   23   21   16   13   12   8  

Scopus   Other  Engineering(Knovel,  IEEE,  etc.)   Other  Art  (Avery,  ArtStor,  etc.)   Web  of  Science  
Table  2  Named  Academic  databases  used  by  undergraduate  non-Summon  users  

5   3   3   1  

Conclusion  
   The  current  results  indicate  that  many  users  were  at  least  moderately  satisfied  with  Summon.  While  this   consistency  demonstrates  that  the  service  is  likely  meeting  the  needs  of  the  targeted  undergraduate   population,  more  research  is  required  to  draw  a  more  comprehensive  conclusion.  Opportunities  for   further  research  are  plentiful.  They  may  include,  but  are  not  limited  to,  comparisons  between  users  who   used  Summon  versus  those  who  used  other  academic  searches,  such  as  Google  Scholar  or  particular   databases.  It  may  also  be  of  interest  to  determine  differences,  if  any,  in  satisfaction  levels  of  various   user  groups.  For  example,  were  undergraduate  students  more  satisfied  with  the  service  than  graduate   students  or  faculty  members?  Furthermore,  there  may  be  differences  in  satisfaction  levels  across   academic  disciplines  worth  exploring.      It  would  have  been  useful  to  have  gathered  data  on  how  far  participants  were  in  their  respective   programs.  While  the  undergraduate  population  was  the  targeted  demographic  for  this  study,  having   students  self-identify  if  they  were  new  students,  at  a  midpoint  in  their  programs,  or  even  at  an  upper   undergraduate  level  could  have  provided  some  perspective  on  the  data  collected.  For  example,  students   at  a  third-  or  fourth-year  level  had  likely  already  become  accustomed  to  consistently  searching  for   academic  research  using  specialized  tools  and  therefore  would  not  have  found  Summon  to  be   satisfactory.  This  is  especially  true  in  cases  of  highly  specialized  databases,  such  as  those  relying  on   controlled  vocabulary  searches,  as  many  WSD  services  are  unable  to  search  these  tools  in  the  prescribed   manners.      The  data  collected  from  the  second  survey  points  to  consistency  in  satisfaction  for  Ryerson  Library's   users  and  provides  a  springboard  for  further  research.  Although  the  results  presented  focus  on  the   undergraduate  experience,  data  was  also  collected  from  graduate  students  and  will  be  presented  in   forthcoming  publications.  In  addition,  having  survey  respondents  self-identify  which  area  of  study  they   are  in  provides  another  avenue  for  analysis  and  publication  of  results.  Overall,  the  cross-tabulation  of   the  data  revealed  only  a  few  anomalies,  but  it  painted  a  picture  of  consistency.  Most  respondents  found   the  product  easy  to  use  and  were  moderately  satisfied  with  the  results  returned  in  searching.        Looking  ahead,  the  data  collected  can  also  be  used  to  inform  Ryerson  library  practices  surrounding   reference,  instruction,  the  creation  of  online  tutorials  and  instructional  resources,  as  well  as  the   placement  and  customization  of  resources  on  the  library's  website.  Although  the  project's  value  is   primarily  as  an  assessment  of  WSD  services  provided  by  academic  libraries,  the  benefits  of  gathering  the   data  will  be  far-reaching  in  aspects  of  public  service  in  the  library.                  

   Appendix   Search  Everything  Questionnaire     Introduction      You  are  being  asked  to  voluntarily  participate  in  a  research  study.  This  survey  is  designed  to  learn   about  your  use  of  the  Search  Everything  feature  of  the  Ryerson  University  Library  website.  You   should  expect  to  be  able  to  complete  this  questionnaire  in  5 -10  minutes.   Before  you  give  your  consent,  please  read  the  following  information  about  your  involvement.   *Questions  with  an  asterisk  means  you  must  answer  the  question  in  order  to  proceed.   This  survey  is  designed  to  identify  your  use  and  satisfaction  of  the  Search  Everything  feature   of  the  Ryerson  University  Library.  All  members  of  the  Ryerson  University  community  are   eligible  to  participate  in  this  questionnaire.  Your  choice  of  whether  or  not  to  participate  will   not  influence  your  future  relations  with  Ryerson  University.   The  questionnaire  used  in  this  study  is  not  experimental  in  nature.  The  only  experimental   aspect  of  this  study  is  the  gathering  of  information  for  the  purpose  of  analysis.  All  individual   responses  will  remain  confidential  and  only  available  to  the  investigators.  Aggregated   responses  will  be  released  through  presentations  and  publications  that  are  produced  by   investigators.  Your  responses  are  made  anonymous  from  the  collection  of  identifying  data   used  in  participating  in  the  incentive  (draw).  We  will  not  link  your  email  or  IP  address  to  the   survey  responses  unless  you  express  interest  in  participating  in  future  focus  groups  or   interviews.   Should  you  feel  uncomfortable  answering  any  of  the  questions  presented  in  this  survey,  you   may  stop  your  participation  at  any  time  by  using  the  option  to  "Exit  the  Survey",  effectively   withdrawing  your  consent  to  participate.  (You  can  also  close  this  web  browser  to  exit  the   survey.)   Ryerson  library  will  benefit  from  the  results  of  this  study  in  the  evaluation  of  the  use  of  the   Search  Everything  tool.  You,  as  a  participant  will  have  no  direct  benefit  from  your   participation  outside  of  an  increase  in  awareness  of  available  resources.   Study  investigators  are  Ryerson  University  librarians,  Kevin  Manuel  (x2868),  Graham   McCarthy  (x2119),  Courtney  Lundrigan  (x4093)  and  May  Yan  (x5146).  If  you  have  any   questions  about  your  participation  in  this  study,  please  contact  Kevin  Manuel.   To  thank  you  for  your  participation,  at  the  end  of  the  survey,  you  may  enter  your  Ryerson  email   address  to  be  eligible  for  a  draw.  We  will  issue  three  (3)  prizes  of  an  Apple  iPad  2  (16GB  Wi-Fi   model  in  your  choice  of  Black  or  White,  with  any  colour  polyurethane  cover).  While  we  welcome   all  to  answer  this  survey,  only  eligible  participants  with  valid  Ryerson  email  addresses  will  be   eligible  to  enter  the  incentive  draw.  RFA  and  Library  staff  are  not  eligible  to  enter.   Answering  yes  to  the  question  below  indicates  that  you  have  read  the  information  in  this   agreement  and  agree  with  the  above  terms.     

*Do  you  consent  to  participate  in  the  study?        Yes   No  

Search  Everything  
   Search  Everything  is  a  new  search  tool  that  will  let  you  access  the  majority  of  the  Library's  resources   (online  and  print)  with  a  single  search  right  from  the  library  homepage.   With  an  easy  to  use  single  search  box,  Search  Everything  helps  you  locate  relevant  information  in   much  less  time  by  searching  across  the  library's  resources  in  one  place.  Use  Search  Everything  to  look   for  books,  journal  articles,  databases,  newspaper  articles,  e-books,  dissertations,  institutional   repositories,  conference  proceedings,  cited  references,  reports,  digital  library,  and  more.      The  following  is  a  screenshot  of  the  Ryerson  University  Library  Website  highlighting  the  Search   Everything  tool  in  red.

            *1a.  The  library  has  a  number  of  resources  to  help  you  get  familiar  with  using  Search  Everything ,   please  indicate  if  you  used  any  of  the  following  to  learn  about  Search  Everything:    Research  Skills  Workshops    FAQ    Reference  Desk    Ask  Us  online  chat  

 

Librarian  Demonstrated  Search  Everything  in  class   N/A;  Did  not  use  

   *1b.  Please  rate  the  resources  in  helping  you  understand  how  to  use  Search  Everything.   1  -  Not  at  all   2  -  Somewhat   3  -  Very  useful         Research  Skills  Workshops               FAQ               Reference  Desk               Ask  Us  online  chat               Librarian  Demonstrated  Search               Everything  in  class  

N/A       

              

Who  you  are
   *2a.  What  is  your  gender?    Male    Female    Other      *2b.  What  faculty  are  you  in?    Faculty  of  Arts    Ted  Rogers  School  of  Management    Faculty  of  Communication  &  Design    Faculty  of  Community  Services    Faculty  of  Engineering,  Architecture  and  Science    Yeates  School  Graduate  Studies    Continuing  Education    Not  Applicable      *2c.  Which  program  are  you  in?   [Text  box]      *2d.  Which  of  the  following  best  describe  your  current  status  with  Ryerson  University?    Undergraduate  Student    Masters  Student    PhD  Student    Faculty    Staff    Research  Assistant  

Students  -  CE,  Undergraduate  &  Graduate  

   *3a.  If  you  are  a  student,  what  is  your  enrollment  status?    Full  Time  Program    Part  Time  Program    Not  Applicable      Please  think  of  a  recent  time  when  you  had  to  search  for  academic  information  as  an  example.  Use  this   example  in  answering  the  following  questions.      *3b.  What  type  of  assignment  were  you  completing  when  you  were  searching  for  academic   information?    Writing  essay    Writing  Article/thesis    Preparing  for  Lab    Preparing  for  Presentation    Other  (please  describe)      *3c.  Please  indicate  the  subject  of  this  search?  Choose  from  the  drop  down  list,  and  if  not  found,  enter   the  other  subject  in  the  textbox  below.   Accounting   Aerospace  Engineering   Architecture   Arts  and  Contemporary  Studies   Biology   Biomedical  Engineering   Biomedical  Physics   Business  Management   Business,  Administrative  and  Labour  Law   Gerontology   Canadian  Law   Caribbean  Studies   Chemical  Engineering   Chemistry  &  Chemical  Engineering   Child  &  Youth  Care   Civil  Engineering   Communication  and  Culture   Community  Development   Computer  Science   Criminal  Justice   Dance   Disability  Studies   Early  Childhood  Education   Economics   Electrical  Engineering   English   Environmental  Studies  

Fashion   Finance  and  Investment   French        Nutrition  and  Food   Geography   Graphic  Communications  Management   Health  Services  Management   History   Hospitality  and  Tourism   Human  Resources  Management   Image  Arts   Immigration  and  Settlement   Industrial  Engineering   Information  Technology  Management   Interior  Design   International  Business  and  Economics   Journalism   Law,  Canadian   Market  Research   Mathematics   Mechanical  Engineering   Midwifery  &  Childbirth   Molecular  Science   Music   Nursing   Occupational  Health  and  Safety   Philosophy   Physics   Physiotherapy   Politics   Professional  Communication   Psychology   Public  Health   Public  Policy  and  Administration   Public  Relations   Radio  &  Television  Arts   Retail  Management   Social  Work   Sociology   Spanish   Spatial  Analysis   Theatre   Urban  &  Regional  Planning   Women's  Studies   Other  (please  specify  in  space  below)   [text  box]      *3d.  Did  you  use  Search  Everything  in  searching  for  academic  information?  

 

Yes   No  

Students  -  Used  Search  Everything  
*4a.  How  easy  is  Search  Everything  to  use?    Extremely  easy    Very  easy   

Moderately  easy  



Slightly  easy  



Not  at  all  easy  

   *4b.  How  easy  is  it  to  find  resources  you  need  using  Search  Everything?    Extremely  easy    Very  easy    Moderately  easy    Slightly  easy      *4c.  How  satisfied  are  you  with  using  Search  Everything?  
 Extremely   satisfied    Very   satisfied    Moderately   satisfied    Slightly   satisfied  



Not  at  all  easy  



Not  at  all   satisfied  

   4d.  Is  there  anything  you'd  like  to  share  about  your  experience  with  Search  Everything?   [text  box]      4e.  Did  you  use  any  other  resources  in  your  academic  search?  [Click  on  as  many  as  applicable.]    Friends  (including  social  media)    Web  Search  Engine  (Google,  Bing,  etc.)    Professor/Instructor    Ryerson  University  Library    Other  Library  (Toronto  Public,  U  of  T,  York  U,  etc.)    Websites  (not  search  engines)    Other  Academic  Databases  (please  specify)      *4f.  As  a  follow  up  to  this  questionnaire,  we  are  looking  for  volunteers  who  are  interested  in  being  a   part  of  focus  groups  to  talk  about  your  experiences  with  Search  Everything.  Please  answer  if  you   would  be  interested  in  being  a  part  of  this  focus  group?  [Note  that  only  if  you  choose  to  participate   will  your  answers  be  associated  with  your  email  address.  Separately  at  the  end  of  this  survey  is  the   opportunity  to  enter  for  the  prize  draw.  Answering  No  to  this  question  will  not  affect  your  chances  at   the  prize  draw.]    Yes    No  

Students  -  Did  not  use  Search  Everything  
*4b.  Which  resources  did  you  use  in  your  academic  search?  [Click  on  as  many  as  applicable.]    Friends  (including  social  media)    Web  Search  Engine  (Google,  Bing,  etc.)    Professor/Instructor    Ryerson  University  Library  

  

Other  Library  (Toronto  Public,  U  of  T,  York  U,  etc.)   Websites  (not  search  engines)   Other  Academic  Databases  (please  specify)  

   4c.  The  library  has  a  number  of  resources  to  help  you  get  familiar  with  using  Search  Everything,  please   indicate  if  any  of  the  following  might  increase  your  interest  in  using  Search  Everything  [Click  on  as   many  as  applicable.]    Research  Skills  Workshops    FAQ    Reference  Desk    Ask  Us  online  chat    Librarian  Demonstrated  Search  Everything  in  class      4d.  Is  there  anything  you'd  like  to  share  about  your  experience  with  Search  Everything?   [text  box]      *4e.  As  a  follow  up  to  this  questionnaire,  we  are  looking  for  volunteers  who  are  interested  in  being  a   part  of  focus  groups  to  talk  about  your  experiences  with  Search  Everything.  Please  answer  if  you   would  be  interested  in  being  a  part  of  this  focus  group?  [Note  that  only  if  you  choose  to  participate   will  your  answers  be  associated  with  your  email  address.  Separately  at  the  end  of  this  survey  is  the   opportunity  to  enter  for  the  prize  draw.  Answering  No  to  this  question  will  not  affect  your  chances  at   the  prize  draw.]    Yes    No                                                                 

                                                                                                                                   Notes      1   Ryerson  University  Library  re-branded  Summon  as  `Search  Everything'  on  its  Library  homepage.   2   Marie  Kennedy,  "What  are  we  really  doing  to  market  electronic  resources?"  Library  Management,  32,   3  (2011),  144.   3   Doug  Way.  "The  Impact  of  Web-Scale  Discovery  on  the  use  of  a  Library  Collection,"  Serials  Review  36,   no.  4  (2010),  215.   4   Ibid.,  215.  Way  uses  the  following  five  categories  to  discuss  the  literature  of  federated  searching:  "(1)   Discussions  of  the  desirability  and/or  difficulty  of  creating  a  robust  federated  search  tool,  (2)  reports  on   one  or  more  specific  federated  search  implementations,  (3)  comparisons  of  federated  search  products   currently  on  the  market  to  each  other  and/or  to  Google  Scholar,  [and]  (4)  views  on  how  to  implement  a   subject-specific  federated  searching  tool."  Way  cites  Belliston,  Howland,  and  Roberts'  four  categories  of   federated  searching  literature  as  the  underpinning  of  his  categorization,  along  with  "a  fifth  category  of   articles  examines  librarians  and  end-users'  perceptions  of  and  satisfaction  with  federated  searching."   Ibid.,  215.  See  also  C.  Jeffrey  Belliston,  Jared  L.  Howland,  and  Brian  C.  Roberts,  "Undergraduate  Use  of   Federated  Searching:  A  Survey  of  Preferences  and  Perceptions  of  Value-added  Functionality,"  College   and  Research  Libraries  68,  no.  6  (November  2007),  474.   5   Jason  Vaughan,  "Serials  Solutions  Summon,"  Library  Technology  Reports  47,  no.  1  (2011),  22-29,2;   Jason  Vaughan,  "Web  Scale  Discovery:  What  and  Why?"  Library  Technology  Reports  47,  no.  1  (2011),  5;   Ronda  Rowe,  "Web-Scale  Discovery:  A  Review  of  Summon,  EBSCO  Discovery  Service,  and  WorldCat   Local,"  The  Charleston  Advisor  12,  no.  1  (2010),  5-10;  Athena  Hoeppner,  "The  Ins  and  Outs  of  Evaluating   Web-Scale  Discovery  Services,"  Computers  in  Libraries  32,  no.  3  (04,  2012),  6-40;  Chris  Keene,  "Discovery   Services:  Next  Generation  of  Searching  Scholarly  Information,"  Serials  24,  no.  2  (2011),  193;  Helen   Timpson  and  Gemma  Sansom,  "A  Student  Perspective  on  E-Resource  Discovery:  Has  the  Google  Factor   Changed  Publisher  Platform  Searching  Forever?"  Serials  Librarian  61,  no.  2  (Aug,  2011),  253-266.   6   Alison  Sharman  and  Eileen  Hiller,  "Implementation  of  SUMMON  at  the  University  of  Huddersfield,"   SCONUL  Focus,  no.  51  (Spring  2011),  50-52;  Michael  Klein,  "Hacking  Summon,"  Code4Lib  Journal,  no.  11   (2010);  Jason  Vaughan,  "Investigations  into  Library  Web-Scale  Discovery  Services,"  Information   Technology  &  Libraries  31,  no.  1  (2012),  32-82;  Cathy  Slaven  et  al.,  "From  "I  Hate  it"  to  "it's  My  New  Best   Friend!":  Making  Heads  Or  Tails  of  Client  Feedback  to  Improve  our  New  Quick  Find  Discovery  Service"   (ALIA  Information  Online  Conference,  Australian  Library  and  Information  Association,  Sydney,  New   South  Wales,  Australia,  2011);  Nara  L.  Newcomer,  "The  Detail  Behind  Web-Scale:  Selecting  and   Configuring  Web-Scale  Discovery  Tools  to  Meet  Music  Information  Retrieval  Needs,"  Music  Reference   Services  Quarterly  14,  no.  3  (2011),  131-145;  Valeri  Craigle,  "Discovery  Layers  in  Law  Libraries  A  Progress   Report  on  how  our  Institutions  are  Implementing  this  New  Technology,"  AALL  Spectrum  16,  no.  3  (12,   2011),  7-9;  Tonia  Graves  and  Angela  Dresselhaus,  "One  Academic  Library--One  Year  of  Web-Scale   Discovery,"  Serials  Librarian  62,  no.  1-4  (Jan,  2012),  169-175;  David  Rapp,  "Discovery  at  Dartmouth,"   http://www.thedigitalshift.com/2012/02/digital-libraries/discovery-at-dartmouth/  (accessed  June  29,   2012).   7   May  Yan  and  Kate  Silton,  "If  you  Build  it,  Will  They  Come?"  (Presentation,  Electronic  Resources  &   Libraries,  Austin,  TX,  April  4,  2012).   8   Asher,  Andrew  D.,  Lynda  M.  Duke,  and  Suzanne  Wilson.  "Paths  of  Discovery:  Comparing  the  Search   Effectiveness  of  EBSCO  Discovery  Service,  Summon,  Google  Scholar,  and  Conventional  Library  

                                                                                                                                                                                                                                                                                                                                                                                                   Resources."  College  &  Research  Libraries  (forthcoming).  Published  electronically  at   http://crl.acrl.org/content/early/2012/05/07/crl-374.full.pdf+html.     9   William  Denton  and  Sarah  J.  Coysh,  "Usability  Testing  of  VuFind  at  an  Academic  Library,"  Library  Hi   Tech  29,  no.  2  (2011),  301-319.   10   Sarah  C.  Williams  and  Anita  K.  Foster,  "Promise  Fulfilled?  An  EBSCO  Discovery  Service  Usability  Study,"   Journal  of  Web  Librarianship  5,  no.  3  (2011),  179-198.   11   Helena  Luca,  "KonSearch  Usability  Study  :  Evaluation  of  the  New  Literature  Search  Engine  of  the   University  of  Konstanz,"  (2011);  Julia  Gross  and  Lutie  Sheridan,  "Web  Scale  Discovery:  The  User   Experience,"  New  Library  World  112,  no.  5  (2011),  236-247.   12   Melissa  Becher  and  Kari  Schmidt,  "Taking  Discovery  Systems  for  a  Test  Drive,"  Journal  of  Web   Librarianship  5,  no.  3  (2011),  199-219.   13   Stefanie  Buck  and  Jane  Nichols,  "Beyond  the  Search  Box,"  Reference  &  User  Services  Quarterly  51,  no.   3  (Spring  2012),  235-245.   14   Marshall  Breeding,  "Looking  Forward  to  the  Next  Generation  of  Discovery  Services,"  Computers  in   Libraries  32,  no.  2  (2012),  28-31.   15   Dartmouth  College  Library,  An  Evaluation  of  Serials  Solutions  Summon,  2009.   16   Howard,  David  and  Constance  Wiebrands.  "Culture  Shock:  Librarians'  Response  to  Web  Scale  Search."   ALIA  Information  Online  Conference,  Australian  Library  and  Information  Association,  Sydney,  New  South   Wales,  Australia,  2011.   17   Way,  "The  Impact  of  Web-Scale  Discovery,"    219,   18   Catherine  Cardwell,  Vera  Lux,  and  Robert  J.  Snyder,  "Beyond  Simple,  Easy,  and  Fast,"  College  &   Research  Libraries  News  73,  no.  6  (June  2012),  344-347;  Stefanie  Buck  and  Margaret  Mellinger,  "The   Impact  of  Serial  Solutions'  SummonTM  on  Information  Literacy  Instruction:  Librarian  Perceptions,"   Internet  Reference  Services  Quarterly  16,  no.  4  (October  2011),  159-181.   19   Rosie  Croft  and  Jessica  Mussell,  "Discovery  Layers  and  the  Distance  Student:  The  Online  Search  Habits   of  Students,"  Journal  of  Library  and  Information  Services  in  Distance  Learning  (forthcoming),  published   electronically  at   http://dspace.royalroads.ca/docs/bitstream/handle/10170/471/Mussell_Croft_Discovery_Layers.pdf?se quence=3;  Slaven  et  al.,  "From  `I  Hate  it'  to  `It's  My  New  Best  Friend!':  Making  Heads  Or  Tails  of  Client   Feedback  to  Improve  our  New  Quick  Find  Discovery  Service";  Varnum,  "Serials  Solutions'  Summon:   Familiarity  Breeds  Success,"  18.   20   Ryerson  also  has  a  significant  distance  education  community  as  part  of  the  Change  School  of   Continuing  Education,  but  as  they  were  not  a  focus  of  this  study,  distance  education  users  were  not   asked  to  self-identify.   21   "representativeness"    A  Dictionary  of  Sociology.  John  Scott  and  Gordon  Marshall.  Oxford  University   Press  2009.  Oxford  Reference  Online.  Oxford  University  Press.   22   Current,  as  of  August  10,  2012.   23   Current,  as  of  August  10,  2012.   24   Statistics  Canada,  Introduction  to  Basic  Statistics  (Toronto:  Statistics  Canada  Advisory  Services,  2010).   25   A  shortened  survey  instrument  is  presented  in  the  appendix  showing  the  questions  that  students   answered.  Faculty/Staff/Researcher  Assistant  questionnaires  are  omitted  here  for  brevity.     26   Researchers  coded  the  various  subjects  presented  by  the  respondents  from  the  drop  down  selection   list  and  write  in  subjects  into  the  following  10  subject  categories  to  better  organize  the  responses  for   analysis.   27   Graduate  Students  made  up  of  27.29%  of  the  Engineering  subject  respondents.   28   Question  4d  (Is  there  anything  you'd  like  to  share  about  your  experience  with  Summon?)   29   Comments  were  coded  into  the  following  categories:  Positive,  Neutral  and  Negative.  

                                                                                                                                                                                                                                                                                                                                                                                                   30   Ryerson's  link  resolver  SFX  was  struggling  at  the  time  to  link  to  the  new  ProQuest  platform.  Comments   such  as  "Links  to  ProQuest  do  not  work"  is  an  example  from  one  "slightly  easy"  rating  for  ease  of  finding   resource  rating.   31   Julia  Gross  and  Lutie  Sheridan,  "Web  Scale  Discovery:  The  User  Experience,"  New  Library  World  112,   no.  5  (2011),  236-247.   32   Ibid.   33   Sum  of  Satisfied  and  Very  Satisfied  ratings  from  Table  5  in  Stefanie  Buck  and  Margaret  Mellinger,  "The   Impact  of  Serial  Solutions'  SummonTM  on  Information  Literacy  Instruction:  Librarian  Perceptions,"   Internet  Reference  Services  Quarterly  16,  no.  4  (2011),  159-181.   34   Andrew  Nagy  (Market  Manager,  Discovery  Services,  Serials  Solutions),  email  to  Summon  Clients,   November  11,  2011.  


