The Distributions of the J and Cox Non-Nested Tests in Regression Models with Weakly Correlated Regressors

Leo Michelis

Ryerson University

digital.library.ryerson.ca/object/360

Please Cite: Michelis, L. (1999). The distributions of the J and Cox non-nested tests in regression models with weakly correlated regressors. Journal of Econometrics, 93(2), 369­401. doi:10.1016/S0304-4076(99)00026-3

library.ryerson.ca

Journal of Econometrics 93 (1999) 369 } 401

The distributions of the J and Cox non-nested tests in regression models with weakly correlated regressors
Leo Michelis*
Department of Economics, Ryerson Polytechnic University, Toronto, Ont., Canada M5B 2K3 Received 1 March 1995; received in revised form 1 April 1999; accepted 19 April 1999

Abstract This paper examines the asymptotic null distributions of the J and Cox non-nested tests in the framework of two linear regression models with nearly orthogonal non-nested regressors. The analysis is based on the concept of near population orthogonality (NPO), according to which the non-nested regressors in the two models are nearly uncorrelated in the population distribution from which they are drawn. New distributional results emerge under NPO. The J and Cox tests tend to two di!erent random variables asymptotically, each of which is expressible as a function of a nuisance parameter, c, a N(0, 1) variate and a (q) variate, where q is the number of non-nested regressors in the alternative model. The Monte Carlo method is used to show the relevance of the new results in "nite samples and to compute alternative critical values for the two tests under NPO by plugging consistent estimates of c into the relevant asymptotic expressions. An empirical example illustrates the &plug in' procedure. 1999 Elsevier Science S.A. All rights reserved. JEL classixcation: C12; C15 Keywords: Non-nested tests; Null distribution; Near population orthogonality; Nuisance parameters; Monte Carlo simulations

* Tel.: #1-416-979-5092. E-mail address: michelis@acs.ryerson.ca (L. Michelis)

0304-4076/99/$ - see front matter 1999 Elsevier Science S.A. All rights reserved. PII: S 0 3 0 4 - 4 0 7 6 ( 9 9 ) 0 0 0 2 6 - 3

370

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

1. Introduction Most of the theoretical and empirical research on non-nested hypothesis testing in econometrics has been carried out in the context of two possibly nonlinear non-nested regression models and under the assumption of model non-orthogonality; that is when the sample or population covariance matrix among the non-nested regressors in the two models is a non-null matrix. This restriction of model non-orthogonality introduces two related considerations regarding non-nested tests. First, how valid are existing non-nested tests when the non-nested regressors are suspected of being nearly orthogonal or uncorrelated? At the theoretical level this is as legitimate a question as it would be when one suspects, for instance, heteroskedasticity or autocorrelation in the data. Second, in applied work cases may arise when model non-orthogonality is not a tenable assumption. For instance, in testing Keynsian versus New Classical theories of output or unemployment determination one has to use the OLS residuals from government policy equations as generated regressors in the New Classical empirical equations. Since Keynsian speci"cations have common regressors with the policy equations this procedure gives rise to rival empirical models with orthogonal regressors; see Pesaran (1982). Given these considerations, it is important to investigate the asymptotic distribution of non-nested tests under the assumption of model orthogonality. The purpose of this paper is to derive, under a speci"c condition of model orthogonality, the asymptotic null distributions of two well-known non-nested hypothesis tests in econometrics: the Cox test (henceforth the C test) of Cox (1961, 1962) and the J test of Davidson and MacKinnon (1981). The framework of analysis involves two linear regression models with nearly orthogonal nonoverlapping or non-nested regressors. More speci"cally, the analysis is based on the concept of near population orthogonality (NPO), according to which the non-nested regressors in the two models are nearly uncorrelated in the population distribution from which they are drawn. New results emerge under NPO. The J and C tests tend to two di!erent random variables asymptotically each of which is expressible as a function of a nuisance parameter, denoted c, a N(0, 1) variate and a (q) variate, where q is the number of non-nested regressors in the alternative model. Monte Carlo simulations indicate that the theoretical results under NPO predict better than standard results the "nite sample behavior of the J and C tests. Furthermore, a new procedure is proposed for testing nearly orthogonal regression models. This consists of plugging consistent estimates of c into the asymptotic expressions to compute critical values for the two tests under NPO. Here, the Monte Carlo evidence shows that the J test performs better than the C test. The new theoretical results are useful in providing a correct understanding of the behavior of non-nested tests under model orthogonality. First, reading the early literature on this issue, one is left with the impression that non-nested tests

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

371

are unde"ned when the non-nested models are orthogonal (e.g., see Pesaran, 1979; Klein, 1983). However, it should be clear from the results in this paper that this is a false impression in general. Second, the J and C tests are no longer asymptotically equivalent under NPO as they are in the standard case of nonorthogonal models. Third, the new results provide additional theoretical insights to the Monte Carlo evidence which shows that the J and C test tend to over-reject more severely when the correlation among the non-nested regressors is weakened (Godfrey and Pesaran, 1983). The rest of the paper is organized as follows. Section 2 sets out the underlying framework of analysis, which includes the models and the regularity conditions. Section 3 reviews brie#y the standard case of non-orthogonal models. Section 4 discusses the asymptotic null distributions of the J and C tests under NPO. Section 5 presents the results of a Monte Carlo experiment designed to investigate the relevance of the new theoretical results in "nite samples and to compute critical values for the two tests using the &plug in' procedure. Section 6 illustrates the plug in procedure with an empirical example and the last section concludes the paper. The appendix contains the proofs to the main results of the paper.

2. The framework of analysis Consider the following two non-nested linear regression models H : y"X #u, u&iid(0, I ), 0( (R,  L H : y"Z #v, v&iid(0, I ), 0( (R,  L (2.1) (2.2)

where y is an n;1 vector of observations on the dependent variable, X and Z are the n;p and n;q observation matrices of the explanatory variables of models H and H respectively, and are p;1 and q;1 vectors of unknown   regression coe$cients and u and v are n;1 vectors representing the random errors in the two models. We assume, for convenience, that the non-nested models intersect only at the origin. If this assumption is not true to begin with, then any common regressors can be removed in an obvious way, by projecting the dependent variable and the non-overlapping regressors in each model into the space orthogonal to the intersection subspace. Whatever the joint distribution of columns of X and Z may be, we shall assume that the following probability limits exist, are "nite and the matrices and are non-singular: VV XX (A1) plim (n\XX)" , L VV (A2) plim (n\ZZ)" . L XX

372

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

In addition to (A1) and (A2) the following assumption has been made in the literature for the standard case of non-orthogonal models. (A3) plim (n\XZ)" O0. L VX The condition O0 is to be understood as stating that not every element of VX the p;q matrix is zero. If that is not the case and the elements of are VX VX near but not necessarily equal to zero, then the distributional results that we obtain are quite di!erent from those in the existing literature. For the analysis of the non-nested tests under model orthogonality, we shall replace (A3) by the following formalization of the notion of NPO: (A4) plim (n\XZ)" , L where is a p;q matrix of constants. Notice that condition (A4) implies that plim (n\XZ), "0, (2.3) VX L where is the covariance matrix of the random variables in X and Z and 0 is VX a p;q matrix of zeros. It is obvious from (2.3) that the columns of X ad Z become asymptotically uncorrelated or orthogonal as the sample size, n, tends to in"nity. Since is O(1) by assumption, asymptotic orthogonality is attained at a rate proportional to n\. Alternatively, as the sample size becomes large, the sample matrices X and Z are drawn from a (p#q)-dimensional distribution of which the p components are nearly uncorrelated with or orthogonal to the remaining q components. For this reason, we call (A4) the near population orthogonality condition. It is illuminating to compare (A4) with the condition used by Staiger and Stock (1997) in their recent work on instrumental variables with weakly correlated instruments. For endogenous variables X and instruments Z, they let X"Z #w where w is a random error and " n\, so that the coe$cients on the instruments Z in the "rst stage regression tend to zero at a rate proportional to n\. With standard conditions on (X, Z, w), this implies the condition (A4) n\XZP # , XX where is multivariate normal with mean zero and covariance matrix  . U XX Under (A4), the key parameter c in the present paper can no longer be estimated consistently and the problem of constructing alternative critical values for the J and C tests will be magni"ed by the presence of additional nuisance

 In fact, this is not a su$cient condition for the validity of standard asymptotic results. What is required is O0 (see Godfrey and Pesaran, 1983, Appendix A). VX

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

373

parameters. On the other hand, (A4) allows consistent estimation of c and, as will be seen below, does a fairly good job in delivering reasonable critical values especially for the J test.

3. The standard case In this section we brie#y consider the J and C tests and comment on their asymptotic properties in the context of the two non-nested models in (2.1) and (2.2) above and under the assumptions (A1)}(A3). We call this the standard case in order to point out the fact that existing theory assumes that O0. VX The J tests is easily computed from an arti"cial regression as a t statistic for a nesting parameter. Given the two linear models in (2.1) and (2.2), the J test arti"cial regression may be written as H : y"X # P y# , (3.1) ( X where P "Z(ZZ)\Z and P y"Z ( is the orthogonal projection on the span X X of Z, representing the n;1 vector of "tted values from H . Let ( be the ordinary  least squares (OLS) estimate of the nesting parameter in (3.1). Then the J test is simply the t-statistic for the hypothesis "0, i.e. J" yP M y X V , ( (yP M P y) ( X V X (3.2)

where ( is the OLS estimate of the standard deviation of the error in the J test ( regression. Turning to the C test, we adopt a criterion based on Cox's simpli"ed test procedure discussed in Fisher (1983). As long as H and H have distributions   that belong to the Koopman}Darmois family this test is asymptotically equivalent to the conventional Cox test and can also be interpreted either as a test based on &parameters of interest' (Dastoor, 1983) or as a &variance encompassing test' (Mizon and Richard, 1986). For a test of H against H this statistic may be   written as n( ( ! (  ) H C" , (3.3) 2 ( (yP M M M P y) V X V X V where (  is a consistent estimate of the error variance in the alternative model, (  is a consistent estimate of  , the pseudo-true value of  under H , and ( is H H  a consistent estimate of the standard deviation of the error term in the null model. In this paper, ( , (  and ( will be taken to be the maximum likelihood H estimators of the corresponding population parameters. (e.g., see McAleer and Pesaran, 1986).

374

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

In the standard case, the asymptotic null distribution of each of the two tests is standard normal. Furthermore, the J and minus the C tests tend to the same random variable asymptotically and are thus asymptotically equivalent. Substi , tuting for y"X #u in (3.2) and (3.3) and using the fact that, under H , ( P  (  , it can be easily seen that this random variable is and ( P XP M u X V . ( XP M P X ) X V X 4. Near population orthogonality In this section we consider the asymptotic null distributions of the two tests under near population orthogonality in the sense of the condition (A4) discussed in Section 2. It should be clear from that discussion that NPO is much less restrictive than ESO (exact sample orthogonality) according to which X and Z are orthogonal in a given sample; i.e., XZ"0. Further, our de"nition of model orthogonality by the NPO condition (A4) is similar but not directly comparable to the notion of asymptotic (local) orthogonality of Szroeter (1992, p. 560); see also Kent, 1986. In fact, in the present context, it could be argued that Szroeter's notion of orthogonality corresponds to "0 as opposed to NPO VX which means "0 but O0 exists. VX 4.1. The J test Consider the J test for testing H against H given by (3.2). Under H we have    yP M y" XP M u#uP M u, (4.1) X V X V X V yP M P y" XP M P X #2 XP M P u#uP M P u (4.2) X V X X V X X V X X V X and  . ( P ( (4.3) (3.4)

Using the identity M "I !P to expand the right-hand side of each of (4.1) V L V and (4.2) and using (A1), (A2) and (A4) to determine the terms of leading order of magnitude, we obtain the asymptotic relations yP M y" XP u#uP u#O (n\) X V X X  and yP M P y" XP X #2 XP u#uP u#O (n\), X V X X X X  (4.5) (4.4)

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

375

where XP u, XP X , and uP u are all O (1). In view of (4.3), (4.4) and (4.5) X X X  it is clear that under H the J statistic (3.2) converges asymptotically to the  random variable XP u#uP u X X . (4.6) ( XP X #2 XP u#uP u) X X X In view of this result, we might expect the asymptotic null distribution of the J test to be di!erent from its own distribution in the standard case and under ESO. However, since it is possible that di!erent random variables may have the same asymptotic distribution, it is necessary to obtain the asymptotic distribution of (4.6) and hence that of the J test. The following theorem provides this and shows the exact form that this distribution takes. Theorem 4.1. Under NPO the asymptotic null distribution of the J statistic (3.2) is given by the random variable c< #<#<   O\ , J " (4.7) LNM ((< #c)#< )  O\ where c,D/ in which D"  \  , < is a N(0, 1) variate and < is XX  O\ a (q!1) variate which is independent of < .  Proof. See the Appendix. Theorem 4.1 makes it clear that the asymptotic null distribution of the J test is a complicated function of a N(0, 1) variate and a (q) variate. Nonetheless, the fact that these two variates appear in (4.7) is appealing because the former is relevant in the standard case whereas the latter results under ESO (Michelis, 1996). Furthermore, the asymptotic expression (4.7) includes ESO and standard results as special cases when c"0 and cPR respectively. Evidently, NPO irons out the discontinuity in the distribution of the J test which arises under ESO relative to the standard case. The di!erent results for ESO and NPO may seem counterintuitive since one might expect the same result under NPO as one gets under ESO. Nonetheless, this "nding is signi"cant because it highlights the importance of the conceptual distinction between ESO and NPO. In the context of this distinction the two di!erent outcomes make perfect sense. The ESO result (i.e., J& (q)) is obtained under the restriction of zero sample correlations among the non-nested regressors in H and H . On the other hand, NPO allows for non-zero sample  
 To see this explicitly, just substitute < for <#< in (4.7) after expanding the squared term O  O\ in the denominator.

376

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

correlations despite the fact that the columns of X and Z may arise from an underlying parent joint distribution in which the corresponding population correlations approach zero at a rate proportional to n\. Next, consider the special case when q"1. Evidently, in this case the J statistic has the same asymptotic distribution under ESO as it does in the standard case, namely N(0, 1). However, this is no longer true when q is greater than one. Intuitively, in some sense, the problem with the distribution of the J test is to determine its correct degrees of freedom (df ) when testing for the signi"cance of the "tted values from the model H . With standard asymptotics df"1 and with  ESO df"q. Clearly, the problem dissapears when q"1. 4.2. The C test Consider, "rst, the numerator of (3.3). Using the de"nitions of (  and (  , and H upon further manipulation the numerator can be written as n( ( ! (  )"yP P P y!yP y. (4.8) H V X V X Under H , the right-hand side of (4.8) reduces to  2 XP P u#uP P P u!(2 XP u#uP u). (4.9) X V V X V X X Therefore, using (A1), (A2) and (A4) to determine orders of magnitude and retaining only the O (1) terms, we have the following result asymptotically:  yP P P y!yP y" !(2 XP u#uP u)#O (n\). V X V X X X  (4.10)

Next consider the denominator of (3.3). Under H the bracketed expression  becomes yP M M M P y" XM M M X #2 XM M M P u V X V X V X V X X V X V #uP M M M P u. (4.11) V X V X V Simplifying each term on the right-hand side of (4.11) by using the facts that XM "0 and ZM "0, we can write V X yP M M M P y" XP X #O (n\) V X V X V X  (4.12)

in which XP X is O (1) as before. X   , it is Putting together (4.10) and (4.12) and using the fact that under H ( P  easily seen that minus the C statistic (3.3) converges to the following random variable asymptotically, 2 XP u#uP u X X . 2 ( XP X ) X (4.13)

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

377

Given (4.13) we state and prove the following theorem regarding the asymptotic null distribution of the C test. Theorem 4.2. Under NPO with non-null and  O0, the asymptotic null distribution of the C statistic (3.3) is given by the random variable 2c< #<  O, C ,!  2c (4.14)

where c, < and < are the same quantities as those dexned in Theorem 4.1.  O Proof. See the Appendix. In Theorem 4.2 the condition being non-null and  O0 is needed to rule out the possibility of dividing the numerator of C by zero. It is clear from  (4.14) that the complete (standardized) Cox test is well de"ned under our notion of model orthogonality in the sense of NPO. This result which is true under NPO cannot be obtained under the existing notions of model orthogonality (i.e., ESO or "0). VX Yet, another important result emerges from the present analysis. In the standard case the J and C tests are asymptotically equivalent not only in the sense of having the same null distribution, but also because they tend to the same random variable asymptotically. By contrast, under NPO this equivalence is no longer true. To see this, notice "rst that a comparison of (4.6) and (4.13) shows that the two tests are di!erent random variables asymptotically. Furthermore, Theorems 4.1 and 4.2 establish that the two tests have di!erent asymptotic null distributions as well. Consequently, studying these tests independently is a useful and informative exercise in its own right. Also, the results of the present paper may be viewed as providing theoretical explanation of Monte Carlo evidence that indicates that the J and C tests tend to over-reject the null more severely as the correlation among the non-nested regressors decreases. Theorems 4.1 and 4.2 show that the J and C tests involve not only a N(0, 1) variate but also a (q) variate. With c positive, the (q) variate will shift the distribution of the J test to the right of N(0, 1) on average, and the distribution the C test to the left of N(0, 1) because of the minus sign in (4.14); see Figs. 1 and 2 below. Since non-nested hypothesis testing entails two-sided tests and the simulation evidence is based on nominal values from N(0, 1), each test will tend to over-reject the null more often under NPO. The right shift of the J test will cause it to over-reject the null more often in the right tail, and the left shift of the C test will cause it to over-reject the null more often in the left tail.
 Note that the mean of C is !q/2c which is negative, and the mean of J is positive with the   mean of its numerator being equal to q.

378

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Fig. 1. Five edfs of the J test plotted against the cdf of N(0, 1) for q"2. The edfs are based on 20,000 replications with n"100.

Finally there is an useful interpretation of the parameter c in (4.7) and (4.14) which distinguishes ESO, NPO and standard asymptotics. In particular, under the null, c is the population analog of the chi-squared statistic for testing the signi"cance of Z in the &"rst stage' regression used to obtain the "tted values from H . It is worth noting that c is not the actual chi-squared statistic testing  the signi"cance of Z in the model H , but rather something which is equivalent  to it under the null hypothesis. Under NPO one should expect c to be small but non-zero. Thus, the sample version of this statistic, c ( "( K XP X K )/ ( , should X be quite useful in practice in detecting near orthogonality. In practice, of course, any common regressors in empirical non-nested models must be removed suitably before computing the c (  statistic. This can be accomplished by projecting the regressand and the non-nested regressors in each model o! the intersection subspace in the two models.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

379

Fig. 2. Five edfs of the C test plotted against the cdf of N(0, 1) for q"2. The edfs are based on 20,000 replications with n"100.

In Staiger and Stock (1997) the Wald statistic plays a similar role in detecting weak instruments. However, their speci"c asymptotics do not allow consistent estimation of the Wald statistic. Here, in contrast, c ( is a consistent estimator of c and, in addition, the values of c ( can be used in (4.7) and (4.14) to compute alternative critical values for testing non-nested models with weakly correlated non-nested regressors. We exploited this fact to obtain the Monte Carlo results reported in Section 5.2.3 below.

5. Monte Carlo simulations The purpose of the Monte Carlo simulations is to study the "nite sample behavior of the J and C tests primarily under NPO. Three related questions of

380

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

practical signi"cance are analyzed. First, how do the J and C tests perform in "nite samples and how important is NPO asymptotically? Second, do the asymptotic formulae (4.7) and (4.14) yield good approximations to the "nite sample distributions of the two tests when the non-nested regressors are weakly correlated? Third, what is the size of each test under NPO, if one computes critical values from (4.7) and (4.14) after substituting c ( for c in the asymptotic expressions? Three sets of Monte Carlo experiments were performed to investigate these questions. The simulation results will be analyzed following the description of the experimental design. 5.1. Design of the experiments The design of the experiments is similar to that given in Godfrey and Pesaran (1983). The &true' model that generated the n observations on the dependent variable y was given by N H : y" # x #u , t"1,2, n,  R  G RG R G (5.1)

where "( , ,2, ) is the vector of the true regression coe$cients. For   N each replication the values of the explanatory variables x were generated RG according to IIN(0, 1) using the pseudo-random number generating subroutine DRNNOF from the IMSL library. The covariance matrix of the explanatory variables was chosen to be the identity matrix, I , so that E(x xl ) is unity if t"l N RG H and i"j and zero otherwise. The values of the error term, u , were also generated by the DRNNOF R subroutine according to IIN(0, ) where  is the error variance in the model given in H . Furthermore, the values of u were chosen independently of the  R values of x so that E(x u )"0 for all t and i. RG RG R The alternative &false' model was also linear and given by O H : y" # z #w , t"1,2, n,  R  G RG R G (5.2)

where "( , ,2, ) is the vector of regression coe$cients and the error   N term w was generated, similarly to u , according to N(0, ) where  is the R R error variance in the alternative model. All the values of and  were "xed at unity for all the experiments that were carried out.

 DRNNOF is a double precision subroutine that generates pseudo-random numbers from N(0, 1) using the transformation method (e.g., see Davidson and MacKinnon (1993)).

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

381

The DGP for each explanatory variable in H was given by  z " x #v , i"1,2, min(p, q) RG G RG RG and, if q'p,

(5.3)

z "v , i"p#1,2, q, (5.4) RG RG with v &IIN(0, 1) for t"1,2, n. The values of the were set according to the RG G relation " /(1! ), i"1,2, min(p, q), (5.5) G G G where is the simple population correlation coe$cient between x and z . G RG RG We carried out several experiments to cover various possibilities of interest in the context of the issues raised earlier. The di!erent experiments that were carried out involved the parameters (p, q, , n, , , c) which were used to G generate the data. The parameters p and q represent the number of non-overlapping regressors in H and H , respectively. The theoretical results in Section 4 depend explicitly   on q through the < term in Theorems 4.1 and 4.2. Therefore, it was important O to consider di!erent values for q. Accordingly, we set p"2 and we investigated the cases: q"2, q"4 and q"6. As mentioned earlier, it is important to set q greater than one; otherwise the J statistic is numerically equal to the F(1, n!p!q) statistic of which the distribution is known exactly and is independent of the parameters . Also, the asymptotic null distributions of the G J and C tests depend explicitly on , the regression coe$cient vector in H ,  through the c,D/ term in the Theorems 4.1 and 4.2. Since what matters is the value of c, we set and equal to unity throughout all the experiments and changed the value of the key parameter c by changing the values of q and . G Of the remaining parameters, the sample size, n, was set at two values: some experiments were performed with n"50 and some other with n"100. The value n"50 is moderately small and is intended to capture the small sample behavior of the J and C statistics in the various cases we investigated. If asymptotic theory is ever going to be a poor guide in "nite samples it should be in this case rather than when n"100. Alternatively, when n"100 we should expect the experimental results to improve and be in closer agreement with those provided by asymptotic theory. The crucial parameters were set, via the in (5.5), at a range of high and G G low values. Assuming that " , typical values of were G "(0.70, 0.40, 0.20, 0.10, 0.01). We also carried out an extra set of experiments where we allowed for di!erent . As long as all the are high (i.e., 0.40 or above) G G or low (i.e., 0.30 or below), the experimental results were virtually the same as if " . For this reason we do not report the results in this case. G The computer programs used in the Monte Carlo experiments were written in Fortran 77 and were executed on an IBM R/S 6000 workstation. Each

382

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

experiment was started by calling the DRNNOF subroutine from the IMSL library and then replicating either 5000 times for the numerical results or 20,000 times for the graphical results (see below). 5.2. Simulation results The simulation results are displayed either in tabular form or in graphical form. The former includes numerical tables with rejection frequencies, means and variances of the two test statistics. The latter consists of plots of the empirical distribution functions (EDF's) of the J and C statistics against either the cumulative distribution function (CDF) of N(0, 1) or the EDFs of (4.7) and (4.14) once with c known and another time with c estimated. The plots were obtained as follows. To construct the EDFs we took the experimental data for the relevant test statistics and sorted them in increasing order of magnitude. From the sorted data we then computed cumulative relative frequencies by choosing certain points over the range of the data. A total of 400 points were chosen. To construct the CDF of the standard normal distribution, we generated 400 numbers from the interval !10.0 to #5.0 and then used the IMSL subroutine DNORDF to compute the CDF of N(0, 1). Once the 400 data points of sample cumulative relative frequencies and values of the standard normal CDF were available, the EDFs and the CDF were plotted using the motif graphing device of the software package S-PLUS (Statistical Sciences, S-PLUS, 1993). 5.2.1. Comparison to standard results The experiments in the "rst set were intended to assess the performance of the J and C tests and the NPO results in relation to standard asymptotics. The objectives in these comparisons were to examine how the J and C tests perform with near orthogonality and to see how important is near orthogonality asymptotically. To accomplish these objectives we computed, for each of the 5000 replications, the J, C, J and C statistics given by (3.2), (3.3), (4.7) and (4.14)   respectively, and then we obtained estimates of Type I error (i.e., estimated size) by calculating the proportion of times that each test rejected the null hypothesis at the 10%, 5% and 1% nominal levels of signi"cance (i.e., nominal sizes). This meant calculating the proportion of times that the test statistics were greater than 1.645, 1.96 and 2.576 in absolute value (i.e., the 10%, 5% and 1% critical values for the standard normal distribution). Besides calculating rejection frequencies we also computed the sample means and variances for each test statistic using the data from the total number of replications. The numerical results for the J and C tests are contained in Tables 1 and 2 respectively. Several features emerge from these experiments. Consider "rst the results in Table 1. It is clear that, in general, the estimated size and mean of the J test increase, and its variance decreases as and c take on smaller values.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401 Table 1 Size, mean and variance of the J test Estimated size Z-reg. in H  q c-par. c rho 10% 5% 1% Sample mean J M 0.102 0.301 0.550 0.680 0.748 0.495 0.618 0.916 1.054 1.111 0.890 0.942 1.250 1.371 1.432

383

Sample variance <(J) 1.020 1.001 0.980 0.904 0.875 1.106 1.008 0.960 0.951 0.902 1.080 1.069 1.021 0.978 0.933

2

7.06 4.16 2.41 1.99 1.50 8.21 5.66 3.70 2.97 2.66 8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01

0.1066 0.1151 0.1462 0.1536 0.1696 0.1570 0.1618 0.2282 0.2598 0.2774 0.2412 0.2442 0.3480 0.3838 0.4068

0.0550 0.0586 0.0800 0.0898 0.0996 0.0894 0.0934 0.1412 0.1738 0.1752 0.1548 0.1602 0.2380 0.2648 0.2828

0.0108 0.0168 0.0216 0.0260 0.0270 0.0270 0.0262 0.0444 0.0588 0.0606 0.0508 0.0556 0.0936 0.1096 0.1158

4

6

Note: Each experiment is based on 5000 replications and n"50.

The size distortions become excessively large as q increases successively from the value of 2 to 4 to 6. Turning to Table 2, it is seen that as and c become smaller the size, mean (in absolute value) and the variance of the C test all increase. When q"2, the increase in size is much greater than is the case for the J test, and this is especially true for values of at 0.20 or below. Notice also the large increase in the variance of the C test for low values of and c. This stands in contrast to the behavior of the J test, the variance of which falls under similar conditions. Moreover, as q increases the size of the C test increases uniformly. However, when q"4 and q"6 the size distortions are smaller for the C test than for the J test. It is instructive to compare the behavior of the two tests for high and low values of and c. Notice that when "0.70 and c"7.06, the two tests behave
 This result is not global and depends on the choice of the parameters in the experiments. For instance, when the c parameter is made smaller by setting "3, the size of the C test becomes substantially larger than the size of the J test at every value of q. These results are available form the author upon request.

384

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Table 2 Size, mean and variance of the C test Estimated size Z-reg. in H  q c-par. c rho 10% 5% 1% Sample mean C M !0.091 !0.281 !0.560 !0.780 !0.881 !0.340 !0.513 !0.745 !0.844 !0.920 !0.540 !0.722 !0.920 !1.031 !1.032 Sample variance <(C) 1.030 1.262 1.990 3.304 3.803 1.116 1.243 1.470 1.631 1.832 1.150 1.219 1.481 1.518 1.533

2

7.06 4.16 2.41 1.99 1.50 8.21 5.66 3.70 2.97 2.66 8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01

0.1084 0.1264 0.1668 0.1998 0.2108 0.1342 0.1632 0.1974 0.2226 0.2444 0.1738 0.1946 0.2534 0.2790 0.2788

0.0536 0.0770 0.1202 0.1558 0.1678 0.0780 0.1092 0.1460 0.1674 0.1830 0.1048 0.1304 0.1844 0.2062 0.2062

0.0124 0.0340 0.0652 0.0998 0.1074 0.0218 0.0446 0.0766 0.0928 0.1066 0.0342 0.0602 0.0964 0.1132 0.1050

4

6

Note: Each experiment is based on 5000 replications and n"50.

similarly and according to the standard theory. Both estimated sizes, mean and variances are close to the nominal levels of the N(0, 1) distribution. But notice that when and c fall to 0.20 and 2.41 respectively the size of both tests is excessively large. A related issue is whether or not the observed di!erences in the simulation results are due to experimental error. To investigate this, consider the case (c, )"(2.41, 0.20) where the estimated sizes of the J and C tests are 0.1462 and 0.1668 respectively. Let ( , and N denote estimated size, nominal size and number of replications respectively, and de"ne the z-score by z"( ( ! )/ ( (1! )/N). Then under the null hypothesis that "0.10, the z-scores are 10.89 and 15.74 respectively. Clearly, the null hypothesis is decisively rejected at practically all signi"cance levels. As another example, when (c, )"(7.06, 0.70) and the nominal size is 5% the estimated sizes of the J and C tests are 0.0550 and 0.0536 respectively. Under the null that the size of each test is 5% the two z-scores are 1.62 and 1.17 respectively. In this case the null hypothesis for either test cannot be rejected at the 5% level of signi"cance. In order to gain more insight on the dependence of the distributions of the J and C tests on (or equivalently c), we have plotted the CDF of N(0, 1) against

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

385

the EDFs of the two tests for di!erent values of . Figs. 1 and 2 contain the relevant results for the J and C tests respectively. In both "gures the results were obtained for the case with q"2 and n"100. Reading from the left (right), the "rst curve is the CDF of N(0, 1) followed by the EDFs of the J (C) test for set at values 0.70, 0.40, 0.20, 0.10 and 0.01 respectively. The corresponding values of the key parameter c are also reported on the graphs. It is clear from Fig. 1 that the J test is not invariant with respect to . As decreases gradually from 0.70 to 0.01 the EDFs of the J test drift further to the right from the CDF of the standard normal distribution. Notice in particular that even when drops from 0.70 to the relatively high value of 0.40 the distribution of the J test shifts; compare the two EDFs in Fig. 1 starting from the left. Moreover, the shift to the right is greater when drops from 0.40 to 0.10 than when it drops from 0.70 to 0.40. This "nding is explainable in terms of the theory of Section 4 since at low values of the J test does not follow the N(0, 1) distribution. A di!erent picture emerges from Fig. 2. As falls toward zero, the EDFs of the C test drift to the left rather than to the right as is the case for the J test under the same conditions. This is understandable, since the C test has a negative mean and the J test a positive mean. Notice also the shape di!erences in the distribtution functions of the J and C tests. The C test has a longer lower tail than the J test and the tail becomes thicker as decreases. Thus, given that rejection frequencies are based on two-sided nominal critical values from N(0, 1), the C test tends to over-reject more in the lower tail than in the upper tail compared to the J test. Tables 3 and 4 report the simulation results for the J and C statistics. In   what follows, when referring to nearly orthogonal samples it will be taken to be samples arising from values of "0.20 or less. Of course, in practice, near orthogonality can be detected by means of a  test using the observed value of c ( . Table 3 shows that the J statistic mimics closely the behavior of the J test  with nearly orthogonal samples. For every value of c, and nominal size, the size of J is less than the size of the J test in Table 1. This result is expected,  since the results in Table 1 measure the total size distortion of the J test whereas the results in Table 3 can be viewed as measuring the proportion of the test's size distortion accounted for by the near orthogonality. Viewed this way, it is evident from comparing the Tables 1 and 3 that, for nearly orthogonal samples, NPO explains over 95% of the actual size distortion of the J test. This is rather compelling evidence for the relevance of the NPO results in explaining the actual behavior of the J test in nearly orthogonal samples. Table 4 documents the simulation results for the C statistic. Unlike J of   which the size is uniformly lower than that of the J test, the size of the C statistic shows more variation in nearly orthogonal samples. For all values  of q, its size is uniformly above or below the size of the C test as the nominal size

386

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Table 3 Size, mean and variance of the J statistic  Estimated size Z-reg. in H  q c-par. c rho 10% 5% 1% Sample mean J M  0.162 0.301 0.530 0.670 0.728 0.355 0.568 0.851 1.034 1.091 0.620 0.812 1.140 1.301 1.352 Sample variance <(J )  0.970 0.951 0.920 0.844 0.825 0.950 0.888 0.890 0.832 0.831 0.930 0.879 0.861 0.868 0.803

2

7.06 4.16 2.41 1.99 1.50 8.21 5.66 3.70 2.97 2.66 8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01

0.0988 0.1058 0.1332 0.1484 0.1610 0.1104 0.1360 0.2052 0.2472 0.2798 0.1562 0.1874 0.2944 0.3476 0.3702

0.0520 0.0550 0.0750 0.0846 0.0874 0.0524 0.0714 0.1226 0.1448 0.1734 0.0854 0.1074 0.1898 0.2428 0.2470

0.0092 0.0098 0.0192 0.0192 0.0210 0.0110 0.0160 0.0348 0.0420 0.0522 0.0246 0.0292 0.0616 0.0886 0.0870

4

6

Note: Each experiment is based on 5000 replications and n"50.

is 10% or 1% respectively. At the intermediate 5% level, the size of C is either  above or below the size of the C test reported in Table 2. This type of behavior of the C statistic can be explained by its increasing variability, at every value of  q, as the samples become successively more orthogonal (see the last column of Table 4). Judging from the numerical and graphical results so far, it is clear that the asymptotic equivalence of the two tests breaks down for nearly orthogonal regression models. In this case, the distribution of the C test behaves di!erently, and is more volatile than that of the J test. Overall, it seems that the J test tends to behave better than the C test. 5.2.2. Comparison of EDF quantiles This section reports the simulation results of the second set of experiments designed to examine how well the asymptotic distributions under NPO approximate the "nite sample distributions. This was done by comparing selected quantile estimates from the EDFs of the J and J statistics and the EDFs of  the C and C statistics. Tables 5 and 6 report quantiles at the 50%, 75%, 90%,  95%, 97.5% and 99% levels for given values of q, c and . To give the asymptotic

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401 Table 4 Size, mean and variance of the C

387



statistic

Estimated size Z-reg. in H  q c-par. c rho 10% 5% 1% Sample mean C M  !0.131 !0.261 !0.550 !0.810 !0.901 !0.260 !0.493 !0.695 !0.834 !0.900 !0.410 !0.661 !0.850 !0.986 !1.022 Sample variance <(C )  0.990 1.112 1.910 3.694 5.243 1.056 1.163 1.460 1.651 1.842 1.060 1.193 1.361 1.498 1.503

2

7.06 4.16 2.41 1.99 1.50 8.21 5.66 3.70 2.97 2.66 8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01 0.70 0.40 0.20 0.10 0.01

0.1056 0.1238 0.1814 0.2290 0.2400 0.1182 0.1560 0.2116 0.2504 0.2562 0.1354 0.1978 0.2480 0.2802 0.2978

0.0510 0.0708 0.1164 0.1650 0.1724 0.0644 0.0984 0.1398 0.1724 0.1836 0.0728 0.1250 0.1706 0.2014 0.2088

0.0088 0.0212 0.0518 0.0878 0.1002 0.0146 0.0354 0.0596 0.0784 0.0896 0.0218 0.0412 0.0718 0.0892 0.0960

4

6

Note: Each experiment is based on 5000 replications and n"50.

theory a better chance of proving itself, we set n"100 and allowed for 20,000 replications in order to reduce the experimental error. Table 5 shows the estimated quantiles from the EDFs of the J and J statistics. As shown in the table, the J statistic delivers quantile estimates   which are near to those of the J test when the samples are nearly orthogonal. This is especially true when q"2, with the di!erence between corresponding quantiles becoming slightly greater as q increases. For instance, the 90% pairs of quantiles of the J and J statistics when "0.20 and q"[(2), (4), (6)] are  [(1.666, 1.652), (1.925, 1.881), (2.260, 2.181)] respectively. On the other hand, when the samples are not orthogonal the quantile di!erences are greater. Consider for example the 90% quantiles of J and J for the three values of  q when "0.70. They are [(1.368, 1.264), (1.642, 1.540), (1.923, 1.691)] respectively. Clearly the di!erences in the latter pairs of quantiles are greater than the di!erences in the former pairs. These results are as expected, since the NPO expression (4.7) should have more predictive power with nearly orthogonal samples. Table 6 gives the estimated quantiles for the C and C statistics. The results  here are, in some respects, di!erent from those in Table 5. For every value of q,

388

Table 5 Quantiles from the edfs of the J and J statistics 

Quantiles from the edf of J  95% 97.5% 99% 50% 75% 90% 95% 97.5% 99%

J

q

c

50%

75%

90%

2

7.06 4.16 2.41 1.99 1.50

0.70 0.40 0.20 0.10 0.01

0.178 0.178 0.408 0.607 0.710

0.752 0.833 1.063 1.238 1.327

1.368 1.429 1.666 1.826 1.900

1.757 1.790 2.028 2.169 2.244

2.062 2.088 2.346 2.482 2.535

2.443 2.459 2.713 2.856 2.859

0.103 0.190 0.405 0.608 0.709

0.655 0.944 1.059 1.230 1.323

1.264 1.406 1.652 1.794 1.876

1.715 1.792 2.011 2.131 2.221

2.032 2.077 2.319 2.435 2.502

2.302 2.462 2.662 2.797 2.822

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

4

8.21 5.66 3.70 2.97 2.66

0.70 0.40 0.20 0.10 0.01

0.351 0.433 0.679 0.940 1.069

1.030 1.090 1.341 1.580 1.689

1.642 1.695 1.925 2.161 2.268

2.005 2.055 2.275 2.513 2.628

2.330 2.361 2.575 2.845 2.913

2.707 2.737 2.997 3.195 3.323

0.252 0.390 0.673 0.934 1.078

0.924 1.054 1.305 1.550 1.689

1.540 1.663 1.881 1.121 2.240

1.925 2.022 2.237 2.483 2.608

2.199 2.289 2.488 2.727 2.859

2.593 2.606 2.861 3.051 3.189

6

8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01

0.650 0.716 1.015 1.279 1.380

1.315 1.390 1.678 1.910 2.001

1.923 1.998 2.260 2.492 2.593

2.309 2.361 2.610 2.853 2.948

2.629 2.667 2.908 3.145 3.243

3.045 3.023 3.287 3.474 3.625

0.425 0.638 0.987 1.224 1.351

1.900 1.281 1.613 1.862 1.961

1.691 1.863 2.181 2.427 2.519

2.052 2.227 2.526 2.771 2.856

2.341 2.533 2.815 3.032 3.151

2.707 2.885 3.141 3.388 3.511

Note: Each experiment is based on 20,000 replications with n"100.

Table 6 Quantiles from the edfs of the C and C statistics 

Quantiles from the edf of C  75% 90% 95% 97.5% 99% 95% 97.5% 99% 50%

C

q

c

50%

75%

90%

2

7.06 4.16 2.41 1.99 1.50

0.70 0.40 0.20 0.10 0.01

!0.035 !0.072 !0.207 !0.349 !0.443

0.635 0.578 0.419 0.265 0.191

1.210 1.090 0.865 0.681 0.588

1.543 1.830 1.099 0.905 0.805

1.821 1.330 1.294 1.072 0.969

2.141 1.583 1.516 1.263 1.171

!0.096 !0.178 !0.363 !0.525 !0.635

0.575 0.492 0.354 0.224 0.148

1.191 1.095 0.981 0.873 0.822

1.562 1.471 1.372 1.270 1.238

1.883 1.784 1.707 1.600 1.568

2.258 2.201 2.081 1.947 1.968

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

4

8.21 5.66 3.70 2.97 2.66

0.70 0.40 0.20 0.10 0.01

!0.177 !0.273 !0.481 !0.623 !0.682

0.520 0.401 0.202 0.059 0.040

1.090 0.940 0.704 0.556 0.520

1.423 1.221 0.977 0.814 0.772

1.706 1.462 1.184 1.023 0.974

2.044 1.738 1.425 1.244 1.206

!0.203 !0.329 !0.556 !0.717 !0.807

0.483 0.365 0.167 0.048 0.034

1.081 0.984 0.814 0.691 0.637

1.453 1.350 1.198 1.404 1.036

1.774 1.659 1.539 1.075 1.378

2.142 2.021 1.907 1.787 1.768

6

8.28 5.88 4.17 3.48 3.33

0.70 0.40 0.20 0.10 0.01

!0.331 !0.465 !0.653 !0.783 !0.852

0.341 0.231 0.043 0.082 0.135

0.934 0.785 0.583 0.465 0.406

1.266 1.105 0.873 0.761 0.702

1.525 1.351 1.105 0.982 0.923

1.866 1.599 1.377 1.210 1.147

!0.305 0.377 !0.494 0.218 !0.729 0.001 !0.871 !0.128 !0.948 !0.165

0.993 0.821 0.644 0.546 0.503

1.358 1.188 1.021 0.948 0.879

1.677 1.493 1.343 1.273 1.231

2.053 1.861 1.731 1.644 1.616

Note: Each experiment is based on 20,000 replications and n"100. 389

390

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

the 50% quantiles are now negative rather than positive. Also, with nearly orthogonal samples the C and C quantiles are smaller than those of the J and  J statistics. Again, this re#ects the leftward shift in the distribution of the  C test that was documented above in Table 2 and Fig. 2. More importantly, the predictive performance of C is not as good as that of the J statistic. With   nearly orthogonal samples the gap between the C and C quantiles is greater  that the gap between the J and J quantiles. For instance, with q"2 and  "0.01 the absolute di!erence of the 90% quantiles in Table 6 is 0.234, about ten times larger than the value of 0.024 observed under the same conditions in Table 5. At q"4 or q"6, the quantile di!erences are reduced at every nominal level but remain relatively larger compared to those in Table 5. To extract more information about the behavior of the EDFs with nearly orthogonal samples, we plotted them in Figs. 3}8. In some "gures, the

Fig. 3. The edfs of the J, J and J tests for "0.10, c"1.99 and q"2. The edfs are based on   20,000 replications with n"100.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

391

Fig. 4. The edfs of the J, J and J tests for "0.10, c"2.97 and q"4. The edfs are based on   20,000 replications with n"100.

horizontal axis was set at di!erent ranges in order to highlight the distinction among the tests. In the "gures, in addition to the EDFs of J, J , C and C , the   EDFs of J and C were also plotted. The latter two EDFs are useful in   practice and correspond to the asymptotic expressions (4.7) and (4.14) with c estimated by c ( from the simulated data rather than assumed known. Because of the consistency of c ( , the EDFs of J and C are almost exactly overlayed   onto the EDFs of J and C respectively, so that only two EDFs appear   visible in each graph. In all cases shown, the EDFs were constructed from 20,000 replications with n"100, "0.10 and q"2, 4, 6 along with corresponding values of c. As shown in the Figs. 3}5, the EDFs of J and J are much more  tied together than the EDFs of C and C in the Figs. 6}8. The EDFs of  J track very well the EDFs of the J statistic throughout the whole range of  their variation, but that is not the case with the EDFs of C and C which seem 

392

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Fig. 5. The edfs of the J, J and J tests for "0.10, c"3.48 and q"6. The edfs are based on   20,000 replications with n"100.

to deviate more from each other in the tails of their distributions. Further, the C and C statistics have a much longer left tail than do the J and J statistics.   Overall, it seems that J predicts better the behavior of the J test than does  C for the C test.  It is of considerable importance that the observable J and C statistics   track almost exactly the J and C statistics which are not observable in   practice. This means that the above arguments could be justi"ably re-casted in terms of the J and C statistics instead of the J and C statistics. Further,     as an anonymous referee suggested, one may use the observed quantiles of the J and C statistics, rather than those of N(0, 1), for the purpose of testing   nearly orthogonal regression models. We outline this testing procedure in the next section.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

393

Fig. 6. The edfs of the C, C and C tests for "0.10, c"1.99 and q"2. The edfs are based on   20,000 replications with n"100.

5.2.3. The plug in test In this section we exploit the fact that the c ( is a consistent estimator of c and use it to construct reasonably sized tests for testing nearly orthogonal nonnested regression models. To construct a test, realized values of c ( are plugged into either (4.7) or (4.14) instead of known values of c. For this reason, we call this the plug in test. Two issues should be clear in relation to this test. First, signi"cance is the key concern with the plug in test; that is, the question is whether the population value of c is small enough to invalidate using the standard J and C tests. Second, this is a somewhat ad hoc procedure since the

 The term plug in was suggested by an anonymous associate editor.

394

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Fig. 7. The edfs of the C, C and C tests for "0.10, c"2.97 and q"4. The edfs are based on   20,000 replications with n"100.

actual distribution of each test conditional on the outcome of the pre-test with respect to c is unknown. To carry out this test, the following steps are required: 1. Use the data to estimate c by c ( " K XP X K / ( where K and ( are the OLS or X maximum likelihood estimators of and respectively. If c (  is statistically signi"cant, relative to an appropriate  distribution, conclude that the models are not nearly orthogonal and use the conventional J or C test. Otherwise proceed as in (b) and (c). 2. Plug in c ( in (4.7) or (4.14) and compute the desired quantile of the J or  C statistic.  3. Compute the J or C test and compare its realized value to the critical value (quantile) obtained from (b). Reject the model under the null if the test statistic exceeds the critical value.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

395

Fig. 8. The edfs of the C, C and C tests for "0.10, c"3.48 and q"6. The edfs are based on   20,000 replications with n"100.

Is the plug in test properly sized? We investigated this question by the third set of the Monte Carlo experiments. The simulations were carried out for nearly orthogonal samples only and for n"100. Tables 7 and 8 contain the simulation results for the estimated size of the plug in tests, denoted J and C respectively. N N The critical values used for the two tests were obtained from the EDFs of the J and C statistics respectively based on 20,000 replications with n"100.   For the sake of comparison, the sizes of the conventional J and C tests are also given in the tables. Table 7 shows the estimated size of the J and J tests. It is clear from the table N that the size of J is remarkably near its nominal level at every value of q. It N over-rejects the null only slightly at the 10% nominal level when q"4 or q"6 and "0.01. On the other hand, under the same conditions the J test has very large size distortion which increases dramatically with q even when n"100.

396

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

Table 7 Estimated Size of the J and J tests N Estimated size of J N q c 2.41 1.99 1.50 3.70 2.97 2.66 4.17 2.48 3.33 0.20 0.10 0.01 0.20 0.10 0.01 0.20 0.10 0.01 10% 0.1018 0.1094 0.1050 0.1084 0.1098 0.1114 0.1058 0.1090 0.1108 5% 0.0495 0.0558 0.0578 0.0566 0.0572 0.0574 0.0518 0.0522 0.0516 1% 0.0140 0.0114 0.0136 0.0116 0.0146 0.0130 0.0138 0.0118 0.0148 J 10% 0.1189 0.1508 0.1658 0.1996 0.2678 0.2778 0.3052 0.3614 0.3936 5% 0.0650 0.0846 0.0944 0.1214 0.1674 0.1774 0.2012 0.2508 0.2684 1% 0.0186 0.0208 0.0224 0.0384 0.0512 0.0574 0.0682 0.0914 0.1038

2

4

6

Note: Each experiment is based on 20,000 replications and n"100.

Table 8 Estimated Size of the C and C tests N Estimated size of C N q c 2.41 1.99 1.50 3.70 2.97 2.66 4.17 3.48 3.33 0.20 0.10 0.01 0.20 0.10 0.01 0.20 0.10 0.01 10% 0.0950 0.0881 0.0881 0.0856 0.0877 0.0824 0.0788 0.0751 0.0669 5% 0.0480 0.0413 0.0398 0.0163 0.0430 0.0404 0.0385 0.0342 0.0288 1% 0.0094 0.0101 0.0081 0.0103 0.0100 0.0080 0.0080 0.0067 0.0053 C 10% 0.1412 0.1770 0.2080 0.1742 0.2000 0.2436 0.2146 0.2566 0.2854 5% 0.0952 0.1398 0.1652 0.1224 0.1474 0.1830 0.1532 0.1866 0.2078 1% 0.0458 0.0818 0.1034 0.0554 0.0858 0.1054 0.0714 0.0918 0.1044

2

4

6

Note: Each experiment is based on 20,000 replications and n"100.

Table 8 reports the results for the C and C tests. As the results indicate, the N C test tends to be undersized at every value of q. It seems that the underN rejection problem becomes more severe when q increases and when the samples

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

397

become more orthogonal. This under-rejection property of C can be attributed N to the fact that the quantiles of C are larger than the quantiles of C with nearly  orthogonal samples; see Table 6 and Figs. 6}8. Comparing the simulation results in Tables 7 and 8 it is plainly clear that the J test outperforms the C test in terms of size. The size of J is much closer to N N N the nominal level at every value of q and is more stable across nearly orthogonal samples. For those reasons, it may be preferable to use the J test in practical N applications. An empirical example is given in the next section.

6. Empirical example This section gives a brief empirical example to demonstrate the practical signi"cance of weakly correlated regressors and, at the same time, demonstrate the plug in testing procedure outlined in the previous section. Beyond these objectives, no serious attempt was made to evaluate the models with the battery of model speci"cation tests that exist in the literature. In this sense, the empirical results should be viewed as illustrative. In the example we consider two non-nested aggregate unemployment models: one justi"ed by standard Keynesian arguments (the K-model) and the other deriving from the Natural Rate/Rational Expectations hypothesis (the Rmodel); see for example Neftci and Sargent (1978) and Pesaran (1982). From a Keynesian perspective, the systematic components of "scal and monetary policies can in#uence the real side of an economy, so that including lagged values of such policy variables in an unemployment equation makes perfect sense. On the other hand, according to the Natural Rate/Rational Expectations hypothesis only the random components of government policies matter. The real e!ects of the systematic components of policies are nulli"ed by the o!setting behavior of rational and forward looking economic agents. The K and R models were speci"ed as follows: K: ; " # ; # t# M # G # , (6.1) R   R\   R\  R\ )R R: ; " # ; # RESG # RESM # . (6.2) R   R\  R  R 0R The variables are: ; "log[;R /(1!;R )], where ;R is the rate of unemployR R R R ment, M "log(M1 ), where M1 is the narrow de"nition of the money supply, R R R G "log(GE ) where GE is real government expenditures measured in 1990 R R R prices and RESG and RESM are proxies for the unobserved random compoR R nents of the "scal and monetary policies respectively. These proxies were obtained as the OLS residuals from regressing G and M on a constant, ; , R R R\ M and G respectively. As in Pesaran (1982), the Keynesian speci"cation R\ R\ includes a time trend variable, t, to capture trend changes in labour participation and other slowly changing variables.

398

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

The data used in the empirical example are annual time series US data for the period 1948}1996 and, except for the rate of unemployment, were obtained from the IFS data base of the IMF. The unemployment rate was not available in the IFS and was obtained from the Cansim tape of Statistics Canada. Given these data, the two models were estimated by the method of iterated maximum likelihood which adjusts for "rst-order serial correlation. The "tted versions of Eqs. (6.1) and (6.2) are K: ; K "!1.29 #0.225; #0.026t !0.003G !0.237M , R R\ R\ R\ (1.54) (0.151) (0.034) (0.001) (0.151) R: ; K "!2.22 #0.213; !0.002RESG #1.68RESM . R R\ R R (0.387) (0.0003) (0.133) (0.802) The numbers in the parentheses are standard errors of the estimated coe$cients. Also, we computed R"0.60, and D="1.86 for the K-model and R"0.66 and D="1.97 for the R-model. In testing K versus R, the c ( estimate turned out to be 1.989. The square of c ( is 3.956 which is less than 5.99, the 5% critical value of the  distribution with q"2 degrees of freedom. Consequently, we conclude that the two models are nearly orthogonal and proceed with steps (b) and (c) of the plug in test. The J test will be employed since it has better size properties than the C test. N N Suppose the non-nested test is carried out at the 5% level. Using the corresponding critical values from the N(0, 1) and (1) distributions along with c ( "1.989 in the expression (4.7) yields the critical value J "2.63. The realized  value of the J statistic was computed from the data to be 3.88. Since this exceeds the number 2.63, the K model is rejected by the evidence provided by the R model. Similarly, in testing the R-model against the K-model the value of c ( was 0.447. This together with the 5% critical values of the N(0, 1) and (2) yielded the value J "3.119. In this case the J statistic was computed to be 2.75. This falls  in the non-rejection region of the test. Therefore, the R-model can not be rejected by the evidence provided by the K-model. This turns out to be a rather appealing result since the R-model is more parsimonious than the K model (q"2 versus q"3). Also, notice that if the conventional procedure had been applied both models would have been rejected since in both cases the J test is greater than 1.96, the critical value of the N(0, 1).

7. Conclusion This paper investigated the asymptotic null distributions of the J and Cox non-nested tests under a speci"c assumption of model orthogonality. Having

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

399

introduced the NPO condition, new distributional results have been obtained. The two tests converge to two di!erent random variables asymptotically, each of which is expressible as a function of a nuisance parameter, c, a N(0, 1) variate and a  variate. As a result, they are no longer asymptotically equivalent as they are in the standard case of non-orthogonal models. The simulation results show that, with nearly orthogonal models, the J and C tests have excessive size distortion that increases with the number of nonnested regressors in the alternative model. The size distortion is accounted for, in large measure, by the simulated NPO expressions derived in the paper. Our formalization of NPO by the condition (A4) allows for consistent estimation of the nuisance parameter, c, from the data. Based on this insight, a new plug in testing procedure is proposed for testing nearly orthogonal non-nested regression models. The Monte Carlo evidence shows that the plug in test incorporating the J test has better size properties than the plug in test associated with the C test. An empirical example involving two aggregate non-nested unemployment models was used to demonstrate the practical usefulness of the plug in test. This paper has focused on the null distributions of the J and Cox non-nested tests under NPO. It would be informative to investigate and compare the size/power properties of the plug in test with other testing procedures that may have desirable properties under near orthogonality. One possibility is to consider J-type or C-type bootstrap tests. Another possibility is to consider nonnested pretest tests that combine the J or C test through pretesting for model orthogonality with other tests, such as the J test of Fisher and McAleer  (1981) or the encompassing F test. This is a topic under current research by the author.

Acknowledgements I am grateful to R. Davidson and J.G. MacKinnon for helpful suggestions and comments, an associate editor for constructive advice and an anonymous referee for very important suggestions including the plug in procedure. Also I thank T. Breusch, R. Carter, J. Knight, A. Mansoorian, A.L. Nagar and T. Stengos for helpful comments. All remaining errors are my own.

Appendix Proof of Theorem 4.1. Start from (4.6) and consider "rst the term XP u. It is X easily seen that < , XP u/ ( XP X ) is a N(0, 1) variate asymptotically.  X X  D,  \  . Therefore, we obtain Also, under (A1)}(A3) XP X P X XX

400

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

XP u" D< . Next, consider the term < ,uP u/ . Obviously this is X  O X distributed as (q) asymptotically. Further, notice that uP u can be written as X the sum of two independent components: < "<#< . In fact, O  O\ < "uP u"uP u#u(P !P )u, (A.1) O X  X  where P is the orthogonal projection matrix on to S[P X ]. The decomposi X tion in (A.1) can be understood by noting that P X is one vector in the X q-dimensional span of P , and so P can be split into the sum of two mutually X X orthogonal projections, one on to the direction of P X and one on to its X orthogonal complement. Dividing both sides of (A.1) by  we obtain < "uP u/ #u(P !P )u/ . (A.2) O  X  The "rst term in (A.2) is just < and the second term, denoted < , is  O\ independent of it and distributed as (q!1). To complete the proof, substitute D< for XP u and < for uP u in (4.6). Then using the decomposition  X O X < "<#< , letting c"D/ and manipulating the resulting expression O  O\ algebraically gives the desired result.  Proof of Theorem 4.2. It su$ces to consider the distribution of each term in (4.13). From the proof of Theorem 4.1) we know that XP u" D< where X  D.  < &N(0, 1), uP u" < where < & (q), and XP X P Conse X O O V quently, de"ning c"D/ as before and substituting each of these relations in (4.13) gives the desired result (4.14). 

References
Cox, D.R., 1961. Tests of separate families of hypotheses. Proceedings of the 4th Berkeley Symposium on Mathematical Statistics and Probability, vol. 1, pp. 105}123. Cox, D.R., 1962. Further results on tests of separate families of hypotheses. Journal of the Royal Statistical Society, Series B 24, 406}424. Dastoor, N.K., 1983. Some aspects of testing non-nested hypotheses. Journal of Econometrics 17, 213}228. Davidson, R., MacKinnon, J.G., 1981. Several tests for model speci"cation in the presence of alternative hypotheses. Econometrica 49, 781}793. Davidson, R., MacKinnon, J.G., 1993. Estimation and Inference in Econometrics. Oxford University Press, New York. Fisher, G.R., 1983. Tests for two separate regressions. Journal of Econometrics 21, 117}132. Fisher, G.R., McAleer, M., 1981. Alternative procedures and associated tests of signi"cance for non-nested hypotheses. Journal of Econometrics 16, 103}119. Godfrey, L.G., Pesaran, M.H., 1983. Tests of non-nested regression models: small sample adjustments and Monte Carlo evidence. Journal of Econometrics 21, 133}154. Kent, J., 1986. The underlying structure of nonnested hypothesis tests. Biometrica 73, 333}343. Klein, R.W., 1983. Model speci"cation tests against non-nested alternatives: comment. Econometric Reviews 2, 115}119.

L. Michelis / Journal of Econometrics 93 (1999) 369 } 401

401

Michelis, L., 1996. Orthogonal regression models and the distribution of non-nested tests. Journal of Quantitative Economics 12, 1}16. McAleer, M., Pesaran, M.H., 1986. Statistical inference in non-nested econometric models. Applied Mathematics and Computation 272}311. Mizon, G.E., Richard, J.-F., 1986. The encompassing principle and its application to testing non-nested hypotheses. Econometrica 54, 657}678. Neftci, S., Sargent, T.J., 1978. A litlle bit of evidence on the natural rate hypothesis from the U.S. Journal of Monetary Economics 4, 315}319. Pesaran, M.H., 1974. On the general problem of model selection. Review of Economic Studies 41, 153}171. Pesaran, M.H., 1982. A critique of the proposed tests of the natural rate-rational expectations hypothesis. Economic Journal 92, 529}554. Staiger, D., Stock, J.H., 1997. Instrumental variable regression with weak instruments. Econometrica 65, 557}586. Statistical Sciences, S-PLUS, 1993. User's Manual, Version 3.2, Seattle, MathSoft Inc. Szroeter, J., 1992. The asymptotic local structure of the cox modi"ed likelihood-ratio statistic for testing non-nested hypotheses. Econometric Theory 8, 553}569.

