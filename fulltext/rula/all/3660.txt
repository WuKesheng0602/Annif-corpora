SEQUENTIAL SUBSPACE ESTIMATOR FOR AN EFFICIENT MULTIBIOMETRICS AUTHENTICATION AND ENCRYPTION

By MD. OBAIDUL MALEK M.A.Sc, McMaster University 2009 B.Sc (Honors), University of Dhaka 1994

A Dissertation presented to Ryerson University in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the program of Electrical and Computer Engineering Toronto, Ontario, Canada

c (Md. Obaidul Malek) 2015

Author's Declaration

I hereby declare that I am the sole author of this dissertation. This is a true copy of the dissertation, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this dissertation to other institutions or individuals for the purpose of scholarly research I further authorize Ryerson University to reproduce this dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my dissertation may be made electronically available to the public.

ii

Abstract
SEQUENTIAL SUBSPACE ESTIMATOR FOR AN EFFICIENT MULTIBIOMETRICS AUTHENTICATION AND ENCRYPTION Doctor of Philosophy 2015 Md. Obaidul Malek Department of Electrical and Computer Engineering Ryerson University

The principal challenge in biometric authentication is to mitigate the effects of any noise while extracting biometric features for biometric template generation. Most biometric systems are developed under the assumption that the extracted biometrics and the nature of their associated interferences are linear, stationary, and homogeneous. When these assumptions are violated due to nonlinear, nonstationary, and heterogeneous noise, the authentication performance deteriorates. As well, demands for biometric templates are on the rise in the field of information technology, leading to an increase in the vulnerability of stored and dynamic information. Thus, the development of a sophisticated authentication and encryption method is necessary to address these challenges. This dissertation proposes a new Sequential Subspace Estimator (SSE) algorithm for biometric authentication. In the proposed method, a sequential estimator is being designed in the image subspace that addresses challenges arising from nonlinear,
iii

nonstationary, and heterogeneous noise. The proposed method includes a subspace technique that overcomes the computational complexity associated with the sequential estimator. In addition, it includes a novel MultiBiometrics encryption algorithm that protects the biometric templates against security, privacy, and unlinkability attacks. Unlike current biometric encryption, this method uses cryptographic keys in conjunction with extracted MultiBiometrics to create cryptographic bonds, called "BioCryptoBond". To further enhance system security and improve authentication accuracy, the development of a biometric database management system is also being considered. The proposed method is being tested on images from three public databases: the "Put Face Database", the "Indian Face Database", and the "CASIA Fingerprint Image Database Version 5.1". The performance of the proposed solution has been evaluated using the Equal Error Rate (EER) and Correct Recognition Rate (CRR). The experimental results demonstrate the superiority of the proposed method in comparison to its counterparts.

iv

Acknowledgements

First and foremost, my praise and gratitude goes to Almighty God, Allah, our Creator, the Most Merciful, the Most Compassionate. Without the help of Allah, none of the work in my life would have come to light. I am simply very thankful to Allah for allowing me to recognize these rewards. By the grace of Allah, I have had the opportunity to be blessed with several extraordinary people in my life whose presence, love, cooperation, and contributions have helped me to achieve my goals. I humbly acknowledge their undeniable contributions and dedication to my success. I would like to express my special thanks to my supervisors, Prof. Anastasios Venetsanopoulos and Prof. Dimitrios Androutsos. They have been instrumental in the development of my academic expertise, and in organizing me to establish myself as a graduate research fellow. I have benefited tremendously from their leadership, and interest in developing the intellectual and personal growth of their high profile team members. The results in this dissertation would not have been possible without their
v

engaging and insightful discussions. They have always been committed, supportive, and flexible, and have shown understanding during hard times. Certainly, they have left an indelible mark upon me, and there is still much I can learn from them. In fact, their leadership, support, expertise, and openness were vital to the successful completion of my PhD degree. I am honoured to have had Prof. Venetsanopoulos and Prof. Androutsos as my supervisors. In a nutshell, they are much more than supervisors to me; perhaps I have blessed by Allah to have had the opportunity to work with these two extraordinary supervisors. My deepest gratitude and appreciation goes to my Mother Sofia Malek and my Sister Dr. Laila Alamgir, MD. Their uninterrupted love and encouragement have been tremendous in inspiring me to pursue this higher study. They have taught me to make my own decision. Without their love, motivation, and support, I wouldn't be what I am today. From the bottom of my heart, I would like to thank my wife Salma, and my two daughters Sophia and Sadia. During my time of study, they have always shown patience, perseverance, and continuous understanding. No one has been impacted by my PhD degree more than them. I would also like to sincerely thank my father Prof. A. Malek, father-in-Law A. Hoque, brother A. Malek, and brother-in-law Attorney M. Alamgir for their continuous support, motivation, and cooperation. I have been surrounded by numerous great friends, group members, lab members, our program administrator, and our technical staff who are hard to forget; my sincere thanks for all of their support. Special thanks to all of the faculty members of Ryerson University; especially Prof. S. Krishnan, Prof. Anpalagan, Prof. Zhao, Prof. Guan, Prof. Alirezaie, Dr. M. Kyan, and Dr. J. Smith whose direct and indirect contributions helped me explore my research in this area. I would also like to extend my special thanks to Prof. E.
vi

Petriu and Prof. A. Sadeghian. Finally, I am grateful to all my school teachers, faculties of University of Dhaka, and to every individual who has taught me in some way.

vii

Dedications To My

Mother Sofia Malek Sister Dr. Laila Alamgir, MD and Wife Salma, and Two Daughters Sophia and Sadia

Contents
Abstract Acknowledgements List of Acronyms, Keys and Bonds List of Special Characters, Databases, and Notations 1 Introduction 1.1 Biometric Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.1.1 1.1.2 1.1.3 1.1.4 1.2 1.3 Encryption and Enrollment . . . . . . . . . . . . . . . . . Authentication . . . . . . . . . . . . . . . . . . . . . . . . . Biometric Modalities . . . . . . . . . . . . . . . . . . . . . Performance Analysis . . . . . . . . . . . . . . . . . . . . . iii v 1 3 5 6 11 12 13 15 17 20 20 21 22 23

Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Proposed Method . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3.1 1.3.2 1.3.3 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . Application Areas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
ix

1.4

Organization

2 Literature Review and Prerequisites 2.1 2.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.2.1 2.2.2 Authentication . . . . . . . . . . . . . . . . . . . . . . . . . Biometric Cryptography . . . . . . . . . . . . . . . . . . . 2.2.2.1 2.2.2.2 2.3 Biometric Encryption (BE) . . . . . . . . . . . . Features Transformation Based Approach . . .

25 25 26 26 29 30 30 39 39 40 44 46 46 47 48 50 52 52 53 53 54 55 56 57 59 59

Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.3.1 2.3.2 2.3.3 2.3.4 2.3.5 Resampling . . . . . . . . . . . . . . . . . . . . . . . . . . . Statistical Properties . . . . . . . . . . . . . . . . . . . . . ML and MAP . . . . . . . . . . . . . . . . . . . . . . . . . . Databases . . . . . . . . . . . . . . . . . . . . . . . . . . . . Nonlinear, Nonstationary, and Heterogeneous Noise . 2.3.5.1 2.3.5.2 2.3.5.3 2.3.6 2.3.7 Nonlinear . . . . . . . . . . . . . . . . . . . . . . . Nonstationary . . . . . . . . . . . . . . . . . . . . Heterogeneous . . . . . . . . . . . . . . . . . . . .

Noncooperative Target . . . . . . . . . . . . . . . . . . . . Privacy, Security, and Unlinkability . . . . . . . . . . . . 2.3.7.1 2.3.7.2 2.3.7.3 Privacy . . . . . . . . . . . . . . . . . . . . . . . . . Security . . . . . . . . . . . . . . . . . . . . . . . . Unlinkability . . . . . . . . . . . . . . . . . . . . .

2.3.8 2.3.9 2.4

Data Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . Tensor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Discussions and Conclusions . . . . . . . . . . . . . . . . . . . . .

3 Sequential Subspace Estimator 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
x

3.2

Problem Formulation and Filtering with Principal Component Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 3.2.2 3.2.3 3.2.4 3.2.5 Principal Component Analysis (PCA) . . . . . . . . . . PCA with Wiener Filter (PCA-Wiener) . . . . . . . . . 63 64 66

PCA with Maximum Likelihood Estimator (PCA-MLE) 68 PCA with Bayesian Estimator (PCA-BE) . . . . . . . . Extended Kalman Filter (EKF) . . . . . . . . . . . . . . 69 71 72 73 75 79 79 81 81 83 90 91 93 98 99

3.3

Model Formulation and Sequential Subspace Estimator . . . 3.3.1 3.3.2 3.3.3 Subspace . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Model Formulation . . . . . . . . . . . . . . . . . . . . . . Working Principle . . . . . . . . . . . . . . . . . . . . . . . 3.3.3.1 3.3.3.2 3.3.3.3 3.3.4 3.3.5 3.3.6 3.3.7 Extract Quality Facial Image . . . . . . . . . . . Detect and Create Biometric Template . . . .

Biometric Template Matching . . . . . . . . . .

Sequential Subspace Estimator . . . . . . . . . . . . . . . Selection of Parameters . . . . . . . . . . . . . . . . . . . . Training Using MLP-SSE . . . . . . . . . . . . . . . . . . Computational Complexity . . . . . . . . . . . . . . . . .

3.4

Experimental Results and Analysis . . . . . . . . . . . . . . . . 3.4.1 3.4.2 3.4.3 3.4.4 Identification . . . . . . . . . . . . . . . . . . . . . . . . . .

Verification . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . 103 Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

3.5

Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121 123

4 MultiBiometrics Encryption and its Management System 4.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
xi

4.2 4.3

Filter Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 MultiBiometrics Encryption and Enrollment . . . . . . . . . . 127 4.3.1 4.3.2 MultiBiometrics Template . . . . . . . . . . . . . . . . . . 128 BioCryptoBond . . . . . . . . . . . . . . . . . . . . . . . . . 128 4.3.2.1 4.3.2.2 4.3.2.3 4.3.2.4 4.3.3 BioCryptoBondu . . . . . . . . . . . . . . . . . . . . 131 BioCryptoBondF P . . . . . . . . . . . . . . . . . . . 131 BioCryptoBondF . . . . . . . . . . . . . . . . . . . . 132 BioCryptoBondF F . . . . . . . . . . . . . . . . . . . 135

Enrollment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 4.3.3.1 4.3.3.2 User . . . . . . . . . . . . . . . . . . . . . . . . . . 136 Subject or Target . . . . . . . . . . . . . . . . . . 136

4.3.4 4.4

Authentication . . . . . . . . . . . . . . . . . . . . . . . . . 139 . . . . . . . . . . . . . . 142

Biometrics Data Management System 4.4.1 4.4.2

Hot-Key Function . . . . . . . . . . . . . . . . . . . . . . . 142 Segmentation Process . . . . . . . . . . . . . . . . . . . . . 143

4.5 4.6

Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 Experimental Results and Analysis . . . . . . . . . . . . . . . . 147 4.6.1 4.6.2 User Authentication . . . . . . . . . . . . . . . . . . . . . . 147 Authentication and Retrieval of the Subject's Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 4.6.3 Analysis and Discussions . . . . . . . . . . . . . . . . . . . 156

4.7

Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158 161

5 Implementation and Execution 5.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 5.1.1 Lottery and Gaming Corporation (Self-Exclusion Program) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
xii

5.2

MultiBiometrics Authentication and Encryption ­Integrated System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 5.2.1 5.2.2 Operational Principle . . . . . . . . . . . . . . . . . . . . . 164 Enrollment Process . . . . . . . . . . . . . . . . . . . . . . 167 5.2.2.1 5.2.2.2 5.2.3 User Enrollment . . . . . . . . . . . . . . . . . . . 167 Subject or Member Enrollment . . . . . . . . . 169

Tracking Process . . . . . . . . . . . . . . . . . . . . . . . . 171 5.2.3.1 Verify if member is in T emp T racking Database or Not . . . . . . . . . . . . . . . . . . . . . . . . . 173 5.2.3.2 5.2.3.3 5.2.3.4 T emp T racking Database is NULL . . . . . . . . . 173 T emp T racking Database is Not NULL . . . . . . 174 Member Not in (or in) Local Database EncryptF 174

5.2.4 5.3

Tracking and Authentication Process . . . . . . . . . . . 175

Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . 178 5.3.1 5.3.2 5.3.3 5.3.4 Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179 Tests and Results . . . . . . . . . . . . . . . . . . . . . . . 179 Authentication . . . . . . . . . . . . . . . . . . . . . . . . . 180 Tests and Results . . . . . . . . . . . . . . . . . . . . . . . 183 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183

5.4 5.5

Discussions

Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188 191

6 Conclusions and Future Work 6.1 6.2 6.3

Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 System Vulnerability and Failure . . . . . . . . . . . . . . . . . . 196 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 203

A Possible Attacks

A.1 User Enrollment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
xiii

A.1.1 Attack on Sensor . . . . . . . . . . . . . . . . . . . . . . . . 205 A.1.2 Attack on Communication Channel . . . . . . . . . . . . 205 A.1.3 Attack on Feature Extraction Method . . . . . . . . . . 206 A.1.4 Attack on Encrypted Domain . . . . . . . . . . . . . . . . 206 A.1.5 Attack on Enrollment Status . . . . . . . . . . . . . . . . 207 A.1.6 Attack on Database . . . . . . . . . . . . . . . . . . . . . . 208 A.2 Subject Enrollment . . . . . . . . . . . . . . . . . . . . . . . . . . 208 A.3 Authentication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209 A.4 Tracking and Authentication . . . . . . . . . . . . . . . . . . . . 211 B Hash-Function and Foreign Key C Experimental Data 215 221

xiv

List of Figures
1.1 1.2 1.3 1.4 1.5 1.6 2.1 2.2 2.3 2.4 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 Fingerprint Biometric Patterns [7-11] . . . . . . . . . . . . . . . . . . Iris Biometric Patterns [12-15] . . . . . . . . . . . . . . . . . . . . . . Facial Biometric Patterns [16-20] . . . . . . . . . . . . . . . . . . . . Gait Biometric Patterns [21-26] . . . . . . . . . . . . . . . . . . . . . Biometric Verification, Enrollment, and Identification . . . . . . . . . Performance Evaluation [37] . . . . . . . . . . . . . . . . . . . . . . . Biometric Encryption -Key Binding and Retrieval Process . . . . . . Features Transformation -Transformation and Authentication Process Images in Time Variant Domain -Put Face Database . . . . . . . . . Heterogeneous Images -Multimodal and Milt-Background . . . . . . . Adaptive Wiener Filter . . . . . . . . . . . . . . . . . . . . . . . . . . SSE Subspace -Transformation Process . . . . . . . . . . . . . . . . . Sequential Subspace Estimator (SSE) . . . . . . . . . . . . . . . . . . Extract Quality Facial Image . . . . . . . . . . . . . . . . . . . . . . Create Biometric Template . . . . . . . . . . . . . . . . . . . . . . . . Template Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . SSE Algorithm - One Cycle of Operation . . . . . . . . . . . . . . . . A Sample from Test Data (Put Face Database) . . . . . . . . . . . . A Sample from Training (Put Face Database) . . . . . . . . . . . . . 9 10 11 12 14 18 31 33 49 51 66 76 78 80 82 84 89 94 95 96

3.10 A Sample from Test Data (Indian Face Database) . . . . . . . . . . .
xv

3.11 A Sample from Training Data (Indian Face Database) . . . . . . . . .

97

3.12 Identification - Performance Comparison . . . . . . . . . . . . . . . . 101 3.13 Verification - Performance Evaluation . . . . . . . . . . . . . . . . . . 104 3.14 Verification - Performance Evaluation . . . . . . . . . . . . . . . . . . 105 3.15 Verification - Performance Evaluation . . . . . . . . . . . . . . . . . . 106 3.16 Verification - Performance Evaluation (With Less Hetero-Nonlinear Dataset) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 3.17 Efficiency Evaluation -Execution Time . . . . . . . . . . . . . . . . . 112 3.18 Performance Evaluation -Verification . . . . . . . . . . . . . . . . . . 113 3.19 Performance Evaluation -Verification . . . . . . . . . . . . . . . . . . 114 3.20 Performance Evaluation -Verification . . . . . . . . . . . . . . . . . . 115 3.21 Efficiency Evaluation -Execution Time . . . . . . . . . . . . . . . . . 116 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 A Set of MultiBiometrics Template . . . . . . . . . . . . . . . . . . . 129 System Architecture -BioCryptoBond . . . . . . . . . . . . . . . . . . 130 Fingerprint Biometrics ­Features Extraction . . . . . . . . . . . . . . 133 Facial Biometrics -Feature Extractions . . . . . . . . . . . . . . . . . 134 User Enrollment Process . . . . . . . . . . . . . . . . . . . . . . . . . 137 Subject Enrollment Process . . . . . . . . . . . . . . . . . . . . . . . 138 User Authentication Process . . . . . . . . . . . . . . . . . . . . . . . 140 Key Generation Process . . . . . . . . . . . . . . . . . . . . . . . . . 144 Segmentation Process . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

4.10 User Fingerprint Biometrics -Verification Process . . . . . . . . . . . 149 4.11 MultiBiometrics Encryption ­Put Face Database(20 subjects) . . . . 151 4.12 MultiBiometrics Encryption ­Put Face Database(40 subjects) . . . . 152 4.13 MultiBiometrics Encryption ­Indian Face Database (10 subjects) . . 153 4.14 MultiBiometrics Encryption ­Indian Face Database (20 subjects) . . 154 4.15 MultiBiometrics Encryption -Identification Process . . . . . . . . . . 155
xvi

5.1 5.2 5.3 5.4

MultiBiometrics Authentication and Encryption -Integrated System . 165 MultiBiometrics Encryption and Authentication -Enrollment Process 168

MultiBiometrics Encryption and Authentication -Tracking Process . . 172 MultiBiometrics Encryption and Authentication -Tracking and Authentication Process . . . . . . . . . . . . . . . . . . . . . . . . . . . 176

5.5 5.6 5.7 5.8

Integrated System -Tracking (T emp T racking Database)

. . . . . . 181 . . . . 184 . . . . 185

Integrated System -Authentication (EncryptionF P Database) Integrated System -Authentication (EncryptionF F Database)

Integrated System -Authentication (Subject Database) . . . . . . . . 186

A.1 Attacks on User Enrollment Process . . . . . . . . . . . . . . . . . . . 204 A.2 Attacks on Subject Enrollment Process . . . . . . . . . . . . . . . . . 210 A.3 Attacks on User Authentication Process . . . . . . . . . . . . . . . . 212 A.4 Attacks on Tracking and Authentication Process . . . . . . . . . . . . 213 B.1 Hashing Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216 B.2 Relational Database -Reference Key . . . . . . . . . . . . . . . . . . . 218 B.3 Relational Database -Hot-Key . . . . . . . . . . . . . . . . . . . . . . 219 C.1 Experimental Data -Chapter-3 (Fig. 12) . . . . . . . . . . . . . . . . 222 C.2 Experimental Data -Chapter-3 (Fig. 13) . . . . . . . . . . . . . . . . 223 C.3 Experimental Data -Chapter-3 (Fig. 14) . . . . . . . . . . . . . . . . 224 C.4 Experimental Data -Chapter-3 (Fig. 15) . . . . . . . . . . . . . . . . 225 C.5 Experimental Data -Chapter-4 . . . . . . . . . . . . . . . . . . . . . . 226 C.6 Experimental Data -Chapter-5 . . . . . . . . . . . . . . . . . . . . . . 227 C.7 Sample of Extracted Data (Grayscale) -Chapter-3 (Section-3.3) . . . . 228

xvii

List of Acronyms, Keys and Bonds

BE BDMS CRR DOS EER FAR FBI FOB FOV FRR i.i.d MLE NGI PCA ROC

Biometric Encryption Biometrics Data Management System Correct Recognition Rate Department of State Equal Error Rate False Acceptance Rate Federal Bureau of Investigation Forward Operating Base Field of View False Rejection Rate Independent and Identically Distributed Maximum Likelihood Estimator Next Generation Identification Principal Component Analysis Receiver Operating Characteristics
1

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Digital Ks Ks


Random Keys Subject -Facial or Fingerprint Biometric Features Subject -MultiBiometrics (Facial and Fingerprint) User -Fingerprint Biometric Features Bonds Cryptographic Bond -User Cryptographic Bond -Facial Features MultiBiometrics Cryptographic Bond -Facial and Fingerprint Cryptographic Bond -Subject Fingerprint Features

Ku Cryptographic BioCryptoBondu BioCryptoBondF BioCryptoBondFF BioCryptoBondFP

2

List of Special Characters, Databases, and Notations
( ) (µ ) () () ( ) () () () ( ) ( ) Encryptionu EncryptionF EncryptionF F EncryptionF P Subject Database dBs Temp Tracking Database User Database dBu Noise due to Non-Cooperative Moving Target Expected Value or Mean Fourier Transformation Noise Vector Orientation Angle Orthogonal Matrix Output of Segmentation Operation Output of Tensor Operation User and Subject Interface Pointer Variance of Desired Signal Database -Encrypted User Fingerprint Features Database -Encrypted Subject Facial Features Database -Encrypted Subject MultiBiometrics Database -Encrypted Subject Fingerprint Subject Master Database Temporary Tracking Database User Master Database

3

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

List of j (· ) (· )T (· )H |·| ·    (· )-1

Notations the unit imaginary number j = the conjugate operator the transpose of a vector or a matrix the Hermitian transpose of a vector or a matrix the inversion of a matrix the determinant of a matrix the Euclidean norm of a vector the Kronecker matrix product the gradient operator the operating wavelength  -1

4

Chapter 1

Introduction
The rapid evolution of information technology has rendered the traditional tokenbased authentication and security management system no longer be sophisticated enough to handle the challenges of the 21st century. As a result, biometrics has emerged as the most reasonable, efficient, and ultimate solution to authenticate the legitimacy of an individual. The origin of the word  biometric comes from the two Greek words  bio and  metrics , which mean  life and  to measure . The main objective of biometrics is to uniquely authenticate a known or unknown individual by using their physiological characteristics. However, the concept of authentication using behavioral characteristics, such as gait and voice, has also become popular over the last several decades, since an individual uses these characteristics somewhat instinctively. Thus, the study of biometric systems became a science that statistically analyzes and measures both human physiological and behavioral characteristics [1],[2]. The physiological and appearance-based biometric traits including facial, fingerprint, and gait are the oldest, simplest, and most reliable sources of biometric characteristics. These traits have been used to authenticate known and unknown individuals since the beginning of civilization. The advent of computer technology along with the rise in security and privacy concerns led to the emergence of biometric systems in the
5

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

late 20th century. However, the growing demands of an ever-increasing population has caused the once simple task of authentication to become more challenging due to computational complexity, intra-class variations, and inter-class similarities. The potential of biometric technology is ever-increasing after the tragic 9/11 attacks on the United States [3],[4]. As a result, the Federal Bureau of Investigation (FBI) officially launched a state-of-the-art face recognition project at a cost of one billion US dollars, a milestone in the development of the Next Generation Identification (NGI) program. This program is a compilation of initiatives that serve to improve or expand the existence of biometric systems, and accelerate information processing and sharing demands in support of anti-terrorism. In November 2012, the FBI also revealed a new request to produce a mobile biometric hand-held software solution to become a part of their biometric identification. This mobile methodology would allow them to capture biometric and biographic information in real time, anywhere in the world [3]. This dissertation systematically investigates the challenges associated with the biometric systems and proposes a novel method to overcome them. This chapter is organized as follows: Section 1.1 presents an overview of biometric systems; Section 1.2 discusses the challenges associated with biometric systems; Section 1.3 examines the proposed method and its objectives, contributions, and application areas; and Section 1.4 includes the organization of the remaining chapters.

1.1

Biometric Systems

The fundamental architecture of the biometric system is based on the extraction of irrevocable physiological and behavioral features, their conversion into useful information, and the utilization of that information for its intended purpose, such as verifying the authenticity of an individual. Ideally, it is an automated method for identifying an individual using computer-aided algorithmic formulations. With the unprecedented
6

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

growth of biometric systems, concerns about security, privacy, and unlinkability attacks are the crucial issues for the 21st century. Not only does the biometric template (another term for biometric features) contain the unique and sensitive physiological and behavioural traits of an individual, it is also unary, and cannot be revoked or reissued if compromised. The most common biometric traits are fingerprint, face, iris, hand geometry, gait, voice, signature, and keystrokes. Each biometric trait has its own strengths and weaknesses [5],[6]. However, fingerprint, iris, face, and gait biometric traits are widely used in the field of biometrics and are discussed in the following subsections. Fingerprint As mentioned earlier, the fingerprint is the most reliable and secure biometric trait in the field of biometric systems. A fingerprint is made up of a series of ridges and furrows on the surface of the finger. Ridges are the segments in the upper skin layer of the finger, consisting of minutiae points, ridge endings, ridge bifurcations, and core points. These components determine the uniqueness of the fingerprint. This biometric is comparatively cost effective, non-intrusive, and easy to use. Application areas include: cell phones, access control, law enforcement, background checks, and notebook computers. The most common fingerprint biometric patterns are shown in Fig. 1.1 [7-11]. Iris The iris as a biometric identifier is a new, but efficient and robust biometric trait. It is the thin circular structure in the eye responsible for controlling the diameter and size of the pupil, and is the only visible internal human organ that uniquely identifies an individual. The iris is protected by the cornea and gives the eye its color. Glasses, contact lenses, and even eye surgery can t change the pattern of the
7

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

iris. Typically, camera technology with subtle infrared illumination can be used to scan and even analyze over 200 points of the iris (i.e. rings, furrows, and corona). The main advantages of iris technology are its processing speed and very low false matching rate; however, the user must hold still at the time of scanning. Typical application areas are in identification cards, passports, and security systems. The most common iris biometric patterns are shown in Fig. 1.2 [12-15]. Face Identification of an individual by facial geometrical physiology can be achieved by extracting facial biometric features, including size or shape of the eyes, nose, lips, cheekbone, and jaw, as well as their relative distance and orientation. Authentication typically uses an algorithm that compares input data with the biometrics stored in the database. The authentication process based on facial features is fast and accurate under favorable constraints, and as a result this technology is evolving rapidly. Biometric authentication using facial biometrics can also be accomplished easily in public or noncooperative environments; the subject's awareness is not required. Typical application areas for facial biometrics are in passports, voter ID cards, driver's licenses, access control, and surveillance zones. The most common facial biometric patterns are shown in Fig. 1.3 [16-20]. Gait The gait is a behavioral characteristic used to recognize an individual by the particular way they move on foot. Unlike other biometrics, it is based on the dynamic movement of the target. Gait biometric authentication can also be done easily in noncooperative environments. However, gait features are not robust enough. Studies show that the fusion of face and gait biometric features can improve the overall performance of a biometric system. Typical application areas of the fusion of these biometrics are in
8

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Fingerprint Ridges

(b) Orientation Angle, Core, and Delta Points

Figure 1.1: Fingerprint Biometric Patterns [7-11]

9

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 1.2: Iris Biometric Patterns [12-15]

access control and surveillance zones. The implementation method for the surveillance zone presented in Chapter 5 is based solely on facial biometrics, however. The most common gait biometric patterns are shown in Fig. 1.4 [21-26].

Soft Biometrics Soft biometric traits are physical and behavioral characteristics that provide information about a subject but lack distinctiveness and permanence. They are easily collected, but cannot uniquely and reliably authenticate an individual. The most common soft biometrics are age, height, gender, and ethnicity. These biometrics in conjunction with the primary traits including face, fingerprint, and iris can enhance authentication accuracy. Authentication performance can be further improved by tuning or narrowing the parameters. These biometrics are not vulnerable to the individual's personal security and privacy. More importantly, soft biometrics can be used as a filtering tool in order to segment the large scale database, as well as to enhance the performance of the searching and authentication process of the biometric systems
10

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 1.3: Facial Biometric Patterns [16-20]

[27]. The main operations performed on a biometric system can be categorized as encryption, enrollment, and authentication. These three operations are integral parts of each other and are briefly stated below.

1.1.1

Encryption and Enrollment

Encryption in a biometric system is essentially a mathematical or algorithmic formulation. It is used to cryptograph the plain biometric features in such a way that encoding or decoding should not require too much effort for the legitimate user but must be hard enough for the unintended user. The whole point of encryption is to keep biometric features out of the hands of unauthorized individuals. The strength of the encryption system is proportional to its ability to protect itself. An enrollment is a straightforward process where the system takes images or photographs of the user or subject. Afterwards, it detects and locates the area of interest to collect the necessary biometric information (features). The received information is then analyzed, and the useful biometric features are extracted and encoded based on certain algorithmic formulations. These encoded features or templates are then stored in the database
11

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 1.4: Gait Biometric Patterns [21-26]

system for future use.

1.1.2

Authentication

Biometric authentication (verification and identification) is an automated computeraided algorithm for authenticating an individual based on their physiological and behavioural characteristics. Depending on the application context, a biometric authentication system can operate in either verification mode or identification mode. In the verification mode, the system performs a 1:1 comparison between the captured live biometric template and a specific template previously stored in the database system during the enrollment process. First, the system captures live biometrics from the claimed individual and creates a biometric template with the same algorithm used during the enrollment process. This new biometric template is used as a key to retrieve a specific template from the storage system. Using the matching algorithm, the two templates are compared to verify that the individual is the person they claim to be. On the other hand, in identification mode, the system performs 1 : many
12

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

comparisons. In this process the system compares the captured live biometric template with all of the stored templates in the databases in an attempt to establish the identity of the unknown individual [28],[29]. A simplified block diagram of the biometric encryption, enrollment, and authentication processes is shown in Fig. 1.5.

1.1.3

Biometric Modalities

Biometric modality is a method that ensures the type and number of biometrics that are used to analyze and create biometric templates. The effectiveness of the biometric system depends on the appropriate selection of this modality. Modality can be classified as monomodal or multimodal [28-30]. Typically, monomodal or monomodality uses a single sample from a single biometric trait captured by a single device. The probability of having noise using the monomodal technique is very high due to its imperfect and limited data acquisition facilities. Furthermore, the physiological and behavioral characteristics of an individual are always influenced by anatomical, pathological, emotional, and environmental factors. As a consequence, a monomodal biometric system faces authenticity, privacy, and security challenges due to biometric spoofing attacks, intra-class variation, inter-class similarities, inaccuracy, non-universality, and unreliability. More importantly, studies found that no single modality can achieve the optimal performance level required for a biometric system [28],[31]. On the other hand, multimodalities (multimodal or MultiBiometrics) represent a biometric authentication system that uses more than one biometric trait and source. In MultiBiometrics, biometric information is extracted from the multiple traits and sources (sensors, samples, backgrounds, algorithms, or/and units), and this information is manipulated, combined (or fused) for the exploitation of biometric encryption, enrollment, and authentication processes. The biometric system usually processes the biometric traits sequentially until the system achieves an acceptable recognition
13

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 1.5: Biometric Verification, Enrollment, and Identification

14

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

score. MultiBiometrics in general and fusion in particular is a useful class of biometric recognition systems. It relies on the evidence presented by multiple sources and can overcome the challenges experienced by the monomodal biometric technique [28], [32-34]. 1.1.4 Performance Analysis

A biometric is a measurable quantity. In fact, any measurable physiological or behavioral characteristic is a potential candidate for a practical biometrics system as long as it satisfies the following requirements [35],[36]: · Universality: Every individual under consideration should possess the biometric characteristics. · Measurability: Ease of measurement; quantitative analysis can be performed on the biometric characteristics. · Distinctiveness: Two individuals should have sufficient distinguishable characteristics. · Permanence: The characteristics should be time invariant. · Performance: Achievable authentication accuracy, efficiency, and robustness of the biometric systems. · Acceptability: An individual's willingness to accept a particular biometric. · Circumvention: How easy it is to imitate a biometric. A comparison of several biometric traits based on these properties is illustrated in Table 1.1. More importantly, the performance of the biometric system depends on the percentages of the Correct Recognition Rate (CRR), False Acceptance Rate (F AR), and
15

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 1.1: A Comparison of Biometric Traits Traits Universality Performance Uniqueness Measurability Acceptance Circumvention F ingerprint Low High High Medium Medium Low F ace High Medium Low High High High Iris Low High High Medium Low Low Gait Medium Low Low Low High Medium V oice Low Low Low Medium High High

False Rejection Rate (F RR). The performance of a biometric identification system is evaluated based on CRR, which is the measure of the number of samples being correctly classified. CRR can be stated as: CRR = Number of samples being correctly classified Total number of test samples

whereas the performance of the verification algorithm can be evaluated by the F AR and F RR. In biometrics, the instance in which a biometric security system incorrectly authenticates an unauthorized person is known as a False Acceptance Rate (F AR), and can be stated as: F AR = Number of successful attempts by imposter . Total number of attempts by imposter

On the other hand, the failure to authenticate a legitimate user is known as a False Rejection Rate (F RR), and can be stated as: F RR = Number of failed attempts by legitimate user . Total number of attempts by legitimate user
16

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

These are the crucial measures to evaluate the performance of a biometric system. If the system does not require a very close match, fewer subjects will be rejected, meaning F RR will be low but FAR will be high. This type of setup is useful in surveillance applications. For the system requiring a close match it is the reverse, and is useful in top level security (i.e. forensic applications). However, at some point biometric security needs to compromise by making FAR and F RR equal. This is known as the Equal Error Rate (EER), which is the measurement of the performance of the biometric verification process. The performance evaluation graph is presented in Fig. 1.6 [37].

1.2

Challenges

With a few prominent successes and continuous challenges in mind, authenticity and the protection of confidential information are considered to be the vital issues for different government and law enforcement organizations­including military, civil aviation, Secret Service, border security, and financial institutions. The stakes are so much higher if classified information falls into the hands of unintended recipients. Current conventional authentication and data protection schemes are dependent on passwords or shared secret keys (something an individual knows) and identity cards (something an individual has), which can easily be forgotten or stolen. These algorithms can also be traced using guesswork, social engineering attacks, or a simple password cracking program. In addition, organizations such as law enforcement are often required to track or authenticate a noncooperative subject to verify that they are the same person who had entered a room or crowd. As a result, biometrics (something an individual is) is regarded as a conclusive solution in this area. Biometrics offers unique physiological and behavioral characteristics for authenticating an individual that are secure, efficient, and accurate. Importantly, these characteristics
17

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) FAR and FRR

(b) ROC Curve

Figure 1.6: Performance Evaluation [37]
18

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

cannot be forgotten, handed over, or lost. Most biometric systems are developed under the assumption that extracted biometrics and the nature of their associated noise is linear, stationary, and homogeneous. The performance of the biometric authentication deteriorates when the underlying assumptions are violated due to nonlinear, nonstationary, and heterogeneous noise. Secrets have always been hard to keep. Due to the proliferation of changing technologies, demands from public and private institutions to protect these secrets in digital form have risen higher than ever. A limited number of biometric traits also possess sensitive human information that is vulnerable to security, privacy, and unlinkability attacks. Furthermore, after biometric data acquisition, the method of biometric data manipulation and representation techniques is almost the same as any other traditional data management system. Therefore, concerns about the vulnerability of the extracted biometric template have become of paramount importance. Biometric systems are increasingly used to recognize individuals and regulate access to physical spaces, information, services, and other rights or benefits, including the ability to cross international borders. The motivations for using biometrics are diverse and often overlap. They include improving the convenience and efficiency of routine access transactions, reducing fraud, and enhancing public safety and national security. The efficacy and applicability of a biometric system can be affected by the cultural, social, and legal considerations that shape the way in which people engage and interact with these systems. One's deliberate choices how or whether to engage, as well as their unintended actions all affect system performance. For example, some people may choose not to place their fingers on a fingerprint scanner for fear of contracting a disease, or may be unable to do so. It is therefore incumbent upon those who conceive, design, and deploy biometric systems to consider the cultural, social, and legal contexts of these systems. Failure to attend to these considerations and social
19

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

impacts diminishes their efficacy and can bring forth serious unintended consequences. Ideally, authenticity and security of the templates are achieved based on mathematical algorithms that must be efficient, accurate, and acceptable, and difficult to decrypt by the unintended recipient. In addition, a template protection algorithm should be irreversible, robust, diverse, revokable, and secure. Therefore, a sophisticated biometric system needs to be developed to deal with these challenges.

1.3

Proposed Method

The proposed method addresses the predominant deficiency of the biometric system and systematically investigates a MultiBiometrics authentication and encryption system. In this method, a novel Sequential Subspace Estimator (SSE) for biometric authentication is presented in the image subspace that considers the effect of nonlinear, nonstationary, and heterogeneous noise on the extracted biometric features. As well, a new MultiBiometrics encryption algorithm is proposed that protects the biometric features against security, privacy, and unlinkability attacks. To further enhance the security protection and to improve authentication accuracy, a Biometric Data Management System (BDMS) is being developed, and the implementation of this method is also presented. In this case, biometric features from facial and fingerprint images found in the approved public databases have been used. Finally, the performance of the model is evaluated by the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Correct Recognition Rate (CRR); this is compared with the other state-of-the-art algorithms.

1.3.1

Objectives

The main objectives of this research are to:
20

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Propose a novel biometric authentication system that produces quality biometrics and reduces computational complexity, and execution time. · Mitigate the effects of noise from nonlinear, nonstationary, and heterogeneous noise while extracting biometric features for template generation using a novel SSE algorithm. In the experiment, the received image is first analyzed in the image subspace to reduce noise levels and overcome the associated computational complexity. Afterwards, the biometric features are extracted and templates are created and stored in the database. This template is then compared with other encoded biometric templates to authenticate the legitimacy of an individual. · Improve the current two-stage independent biometric encryption system, first to authenticate and then to release the secret key. This method includes a multilayered, MultiBiometrics secret key-bond algorithm for the cryptographic bond, so that the encryption system can protect the biometric features from security, privacy, and unlinkability attacks. A biometric data management system is also being developed using the cryptographic bond in conjunction with the hash function and the data segmentation technique. This system improves authentication accuracy and ensures better protection of the biometric features. · Design and implement an integrated system based on the proposed MultiBiometrics authentication and encryption method in order to track and authenticate the legitimacy of a single individual under surveillance.

1.3.2

Contributions

Over the last decade, the demand for biometric systems has grown steadily in the field of information technology, leading to increased template vulnerability. The production of quality biometric features and associated computational complexity are
21

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

vital challenges for the exploitation of biometric systems. In most cases, biometrics deals with large volumes of datasets. Noise associated with these datasets is very likely to be present due to misalignment, illumination, position orientation, and facial expression effects. This dissertation discusses two important aspects of a biometric system: MultiBiometrics encryption and authentication; these ensure the high quality of biometric features and reduce the computational complexity. The main contributions of this research are to: · Develop a novel Sequential Subspace Estimator (SSE) algorithm in the image subspace that overcomes the challenges associated with computational complexity, reduce execution time, and mitigates the noise of the extracted biometric features. · Develop a novel MultiBiometrics encryption algorithm to provide multilayered protection for biometric features against security, privacy, and unlinkability attacks. · Integrate the SSE and MultiBiometrics encryption methods and implement the integrated method as a single biometric system.

1.3.3

Application Areas

The potential application areas of this integrated method are in the Lottery and Gaming Corporation's (or Casino) self exclusion program, airport security, and financial institutions (i.e. Biometric Banking). Here, continuous authentication, access control, and surveillance are necessary to ensure the security and legitimacy of a single individual in real time domain. The SSE method can be used as an authentication system, whereas the encryption method can be implemented to protect the stored and dynamic biometric features against security, privacy, and unlinkability attacks.
22

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

1.4

Organization

The organization of this dissertation is as follows: Chapter-2: Chapter 2 includes prerequisites and a comprehensive literature review relating to the proposed authentication and MultiBiometrics encryption method. Chapter-3: Chapter 3 presents the proposed Sequential Subspace Estimator (SSE) algorithm based on the underlying authentication challenges. The computational complexity, experimental results, and analysis are also presented in this chapter. The method is made independent of biometric traits; however, it is tested on facial and fingerprint biometric features. Chapter-4: Chapter 4 introduces a MultiBiometrics encryption method that can protect biometric features against security, privacy, and unlinkability attacks. In this case, facial and fingerprint biometric features have again been used. The computational complexity, experimental results, and analysis are also presented in this chapter. Chapter-5: Chapter 5 presents the proposed SSE and MultiBiometrics encryption method as an integrated system. Afterwards, this integrated method is implemented as a single system. Chapter-6: Chapter 6 includes conclusions and the recommendation for this dissertation.

23

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

24

Chapter 2

Literature Review and Prerequisites
2.1 Introduction

The future of biometrics has continuously grown since the 9/11 attacks, as the world is facing more complex and diverse terrorist threats than ever before. As a consequence, in 2004, the Department of State (DOS ) started adding biometric facial recognition features from more than 90 million photographs into their database to identify individuals that were previously denied entry into the United States. It is of paramount importance for government and private organizations­including Secret Service, military, and civil aviation­to establish an accountable, robust, efficient, and secure surveillance zone for their field of view (FOV). As well, there are always concerns about acceptability and adaptability with new technologies, especially when the vulnerability of the useful and sensitive biometric features to security, privacy, and unlinkability attacks increases with demand in the field of information technology. In fact, the performance, robustness, and vulnerability of the biometric system depends on the quality of the extracted features, its encryption method, its intra-class
25

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

similarity, and its extra-class variations. Despite the underlying challenges arising from these demands, advancements in biometric systems have lead to significant accomplishments in a number of areas, including public safety, national security, and border patrolling over the past few decades [3],[4]. The proposed MultiBiometrics authentication and encryption system is a novel state-of-the-art method in this regard. The main focus of this chapter is to present a comprehensive literature review related to the method introduced in this dissertation and discuss prerequisites, before getting into the detailed analysis, formulation, implementation, and execution of this method. This chapter is organized as follows: Section 2.2 presents a detailed literature review; Section 2.3 presents the prerequisites of the proposed model; and discussions and conclusions are drawn in Section 2.4.

2.2

Literature Review

A comprehensive literature review is presented in this section for the two parts of the proposed method: authentication and encryption.

2.2.1

Authentication

Most authentication systems are based on linear, stationary, and homogeneous systems, though a few studies have addressed the challenges due to nonlinear, nonstationary, and heterogeneous noise. D. Zizhe et al. [35] developed a new algorithm in the nonlinear PCA domain termed the adaptive Strong Tracking Filter (STF). The authors showed that the model is a special case of Kalman Filter and Recursive Least Squared algorithms, and is immune to system model mismatch. The algorithm converges quickly and is robust at the cost of computational complexity. One study conducted by the National Science and Technology Council [36] proposed a Linear
26

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Discriminant Analysis (LDA) method for facial authentication. The author used LDA to maximize the inter-class and minimize the intra-class variations, since PCA performance deteriorates if a full frontal face can't be presented. However, this model was designed for linear and homogeneous systems and faces challenges if there are an inadequate number of data samples in the received dataset. L. Chan et al. [38] proposed a linear facial biometric authentication (identification and verification) system using PCA in conjunction with LDA. In that approach, the authors used PCA for dimension reduction, while LDA was used to improve the discriminant ability of the PCA system in order to overcome the challenges associated with illumination and facial expression effects. The main problem with this model is that it is inadequate to deal with noise under consideration. P. Selvi et al. [39] proposed an algorithm based on fingerprint and iris biometrics to overcome dictionary attacks, and used the image processing method to extract biometric characteristics. In this case, minutiae points and texture attributes are extracted from the fingerprint and iris biometric features, then are encrypted and stored in the server database. During the authentication process, a symmetric key is generated based on mutual authentication between the server side and the user; this key is used for further biometric transactions between them. In this model, the authors claimed that the system does not need any additional computational power if it is directly applied to the existing password and biometric-based system. This multimodal encryption system is simple, but the authors didn't mention the cryptographic process or the achievable F AR and F RR. G. Lakshmi [40] introduced another fingerprint identification and encryption system, and used a Wiener and a digital transformed filter to mitigate the noise. However, the authors addressed the issues based only on a linear and homogeneous system. C. Nandini et al. [41] proposed a biometric authentication based on vein patterns. The authors used the length of the vein and the angle of the bifurcation points as the key features. To enhance
27

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the quality of the vein pattern, the authors used different filtering techniques including the Wiener and the Median filter. The experimental results were very promising; however, the algorithm is based on linear and homogeneous systems. H. Lu et al. [42], presented a new PCA algorithm in an uncorrelated multilinear PCA domain using unsupervised subspace learning of tensorial data. This system offered a methodology for maximizing the extraction of uncorrelated multilinear biometric characteristics, but it is an iterative process and inadequate to deal with a nonstationary and heterogeneous system. M. Law et al. [43] presented a nonlinear dimensionality reduction algorithm under the assumption that high dimensionality data are available in the mainfold. Hence, dimensionality reduction can be achieved by mapping with respect to certain properties associated with the mainfold. The authors used the sequential processing method, which outperformed the computationally demanding approach, batch processing. Unfortunately, it is very likely to contain misleading information if the system is dependent only on the information contained in the mainfold. J. Suo et al. [44] developed a gender transformation algorithm based on hierarchy fusion strategy. In that approach, the authors used a stochastic graphical model to transform the attributes of a high-resolution facial image into a new image as the opposite gender with the same age and race. The main objective is to modify the gender attributes while retaining facial identity. This is an interesting model; however the authors didn't consider the associated heterogeneity due to the different race and age groups. In addition, E. Carlos et al. [45] developed a new algorithm for covariance estimation for the Bayesian classifier. This method successfully addressed the challenges associated with the Bayesian Estimator due to limited numbers of sample data. However, this model was developed under the assumption that variation in the data class is the same; hence similarities in the covariance shape are highly expected in all classes. As a result, this method is inadequate to deal with a nonlinear and heterogeneous operating environment. L. Lin et al. [46] proposed a hierarchical regenerative
28

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

model using an "And-Or Graph" stochastic graph grammar methodology. In that model, the probabilistic bottom-up formulation was used for object detection, and the recursive top-down algorithm was used for the verification and searching process. Here, objects with larger intra-variance were broken into their constituent parts, and linking between the parts was modeled by the stochastic graph grammar technique. The authors also addressed the localization challenges due to the background clutter effect. The proposed verification process was developed in a homogeneous and controlled environment. K. Nandakumar [47] introduced a Bayesian approach in his M.Sc thesis. In that study, the author considered that the authentication matching scores received from the different modalities were heterogeneous, but overcame this challenge by normalizing the outcome before the fusion process. Unfortunately, the author failed to consider the heterogeneous nature of the received observable data used for the authentication method. Another study concerning the Bayesian Estimator was conducted by M. Nounou et al. [48], addressing the problem associated with the MLE and PCA algorithms. Unfortunately, this method was also developed under the assumption that the system is stationary and homogeneous.

2.2.2

Biometric Cryptography

With the increase in number of constantly evolving electronic technologies, demands from public and private institutions for digital protection have risen higher than ever. Biometric technology is the viable solution for these demands. Typically, in biometric systems, a legitimate user needs to access the system to perform two modes of operations­identification and verification. In the identification process, the received biometrics need to be compared with all of the stored biometrics in the database. During the verification process, the received feature vectors (biometric template) only need to be compared with the biometric template of the claimed individual. Existing
29

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

studies on the biometric features protection algorithms can be categorized into: i) Biometric Encryption (BE ), and ii) Features transformation based approach; both of which are discussed in the following subsections.
2.2.2.1 Biometric Encryption (BE)

Cryptography uses encryption to send and receive secret messages that can only be decrypted by the intended recipient. It uses algorithmic formulations to protect security and privacy, including confidentiality, integrity, and authenticity of the information. Biometric Encryption is a process that generates a digital secret key that monotonically bonds with the extracted biometric template to create a secret compound cryptographic data block. The secret key can also be derived from the biometric features. In both cases, candidate biometric features are stored in a database known as a helper data, and this key is used as the secret key for the overall biometric transaction [29],[34]. Typically, this data block is stored in a remote location, and neither the biometric features nor the secret key can be retrieved from this data block without a successful biometric authentication. A typical block diagram of a key bond and the retrieval process is shown in Fig. 2.1.
2.2.2.2 Features Transformation Based Approach

In the Features transformation based approach, an algorithm is implemented to create a transformed function, which is then applied to the extracted biometric template. In this case, only the generated transformed template is stored in the database for the biometric transaction. The original template cannot be retrieved if it is compromised, since matching is performed directly in the transformed domain. Fundamentally, parameters of the transformed function (or transformed domain) are derived from the random key or a user-specific password. During the authentication process, the same transformation function is applied to the query and matched to the stored templates
30

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 2.1: Biometric Encryption -Key Binding and Retrieval Process

31

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

in the transformed domain. This template is cancelable and revocable. Two of the most widely used features transformation based approaches are cancelable biometrics and biohashing. A typical block diagram of this approach is illustrated in Fig. 2.2.

Biometric Encryption Vs Features Transformation The proposed study is based on the Biometric Encryption (BE) method. The primary reason this method was chosen was that it provides more privacy and security protection, since the original biometric features cannot be retrieved from the cryptographic bond. Even if the intruder is able to decode the secret key, the original biometric features cannot be retrieved. In contrast, the features transformation technique is based on the template transformation function; by decoding the transformation function, it is possible to decrypt the original biometric features. Since the proposed encryption method is based on Biometric Encryption, most of the discussions will be focused on this particular method. In the BE method, a system-generated cryptographic key or a generated key from biometrics is securely bound to the biometric features and is stored as an encrypted biometric template. Neither the secret key nor the biometrics can be retrieved from the stored encrypted template [28],[29]. Some of these methods involve a two-stage independent process: authentication, and the release of the secret key. However, biometric features can be retrieved if the cryptographic key, or its location, is obtained by the imposter. Other key binding methods involve using the secret key along with biometric features to secure the biometrics. In their self-exclusion model, A. Cavoukian et al. [28] proposed a biometric encryption algorithm based on facial biometrics. The system is composed of two distinct stages: i) creation of a watch list consisting of a maximum of five patrons (the top 5 matches), using the traditional 1:many biometric comparison technique based on facial biometric features; and ii) implementation of a biometric encryption module
32

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 2.2: Features Transformation -Transformation and Authentication Process

33

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

and released keys for each of the top match patrons, and the generation of a match alert by the system that is then reviewed by administrators. During the enrollment process, the subject's facial image is captured and a nonmeaningful unique enrollment ID (id) is created. A commercial recognition process is used to extract the facial features and generate a template t1, which is indexed by the enrollee ID and stored into the face recognition database. Another biometric template t2 is passed through the biometric encryption (BE ) key binding algorithm and helper data (or a private template) is created using a combination of biometric data and a random pointer key. The pointer key represents the location of the subject s facial image as well as other personal information of the self-excluded individual within the database. Finally, the BE helper data is sorted by the same enrollee ID and stored in another location. For OLG's security reasons, t1 and t2 use different facial algorithms to extract features, which are not interoperable. The major shortfall of this method is that it is a combination of manual and automated processes, and the authors do not consider the challenges that could occur during the extraction of facial features from the moving subject due to illumination, position orientation, and other environmental interferences. During the authentication process, a traditional 1 : many facial algorithm is used to create a watch list with the top five matching patrons, and the BE algorithm is used to retrieve enrolled ID s of the top match patrons. The final stage of verification is initiated if a key can be retrieved from the BE helper data associated with one of the potential matches. Here, the pointer that stored personal information associated with the potential match is regenerated, and recorded. An administrative operator then manually verifies the retrieved facial images with the live image of the Casino patron in question. The proposed BE method can achieve an optimal F AR with minimal increase in F RR. In their self-exclusion model, K. Martin et al. [48] proposed a biometric encryption algorithm based on a small subset of the subject's
34

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

facial biometrics database. The authors here used feature vectors in their key binding process to secure the cryptographic key. This is a novel model, and they achieved low FAR at the cost of FRR. W. Zhang et al. [50] proposed a robust facial recognition method by synthesizing a facial sketch from a face photo under different pose and lighting conditions. Generally, synthesized approaches have been surpassed in performance by discriminative feature-based approaches. A key advantage of synthesis methods is that once a sketch has been converted to a photograph, matching can be performed using existing face recognition algorithms. The proposed method improved the performance of the authentication process; however, the authors here proposed to further investigate their method with expression variations. K. Nandakumar et al. [51] proposed a fuzzy vault scheme where the authors derived a multibiometrics template from multiple templates of a single user. They used fingerprint minutiae points and iriscodes templates and transformed them into a multibiometrics vault. Both the biometrics and the secret key were secured using the multibiometrics vault as a single entity. The overall security achieved using their proposed method was around 49 bits, as compared to 41 bits for a stored individual template using separate vaults. A. Jain et al. [52] presented a biometric data hiding approach to secure the transmitted as well as stored biometric data. A. Ross et al. [53] proposed a visual cryptography method to protect the privacy of the biometric templates. In their method, an image is decomposed into two host images and stored in the two central databases. The original image can only be revealed when two images are available simultaneously. B. Klare et al. [54] proposed a heterogeneous facial recognition algorithm based on discriminative features. The author presented a framework termed Local Featurebased Discriminant Analysis (LFDA) in order to identify forensic sketches. This method provides substantial improvements in matching forensic sketches to the corresponding facial images. X. Wang et al. [55] proposed a random sampling method
35

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

using the multiple classifiers. The authors here developed an ensemble framework based on random sampling of feature space, training samples, and subspace parameters, and demonstrated the effectiveness of random sampling LDA for facial recognition. This subspace facial authentication method addressed the associated challenges of the small dimensional subspace dataset in comparison to the high dimensional features. In this case, multiple stabilized Fisherface and Null Space LDA (N-LDA) classifiers are constructed and then integrated using fusion, which preserves the discriminative information. Random sampling is also applied to the parameter selection in order to optimize the selection process. Afterwards, the random sampling framework is used for the integration of multiple features. This is a simple and straight forward approach. However, the authors suggested that more complex fusion (Kittler and Roli) algorithms can be used in order to enhance the authentication accuracy. S. Bucak et al. [56] reviewed the Multiple Kernel Learning (MKL) method for solving optimization problems for object recognition. In their studies, the authors resolved the conflict associated with the MKL method regarding its efficiency and effectiveness in object recognition. The authors argued that the seemingly contradictory conclusions offered by the previous studied were due to different experimental setups. The author here showed that the MKL is an extremely useful tool for visual object recognition, since it provides a methodology for combining the strengths of different object representations. However, the classification accuracy of MKL is more critical to improve without sacrificing the computational efficiency. U. Park et al. [57] proposed a facial tracking and recognition system using static and Pan-TillZoom (PTZ) cameras to acquire high resolution images up to a distance of 12 meters. The authors here used a linear prediction model and a pan-tilt motion velocity control method for robust tracking. The outcome of their method showed that the proposed automated facial authentication system could track and authenticate a subject at a distance of up to 12 meters. However, the main limitation of this method is that the
36

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

camera needs to be adjusted manually and the system can recognize a face only when it is close to the frontal view. N. Srinivas et al. [58] proposed a method to differentiate between identical twins based on facial marks. In this case, the authors used high resolution images. This multiscale automated face detection method to distinguish identical twins is solely based on the geometrical distribution of facial marks. The authors detected bright and dark regions with high radian symmetry at different scales, and used this to determine the prominence of facial marks. Facial marks are defined as visible changes in the skin, which differ in texture, shape, and color from the surrounding skin area. The authors suggested that these facial marks could be enhanced to make them more distinguishable, using texture, shape, and color. A. Paulino et al. [59] proposed a new robust fingerprint matching algorithm especially designed for matching latent fingerprints. The authors used a descriptor-based Hough transformation algorithm for aligning fingerprints and measured similarities between them by considering both minutiae and orientation field. Their method is useful for law enforcement and commercial applications, since the orientation field is constructed from minutiae points, which in their method are dependent on the manually marked algorithm. B. Klare et al [60] proposed Heterogeneous Face Recognition (HFR) in random subspaces. In this study, the authors considered heterogeneity that involved matching two facial images from alternate imaging modalities, such as an infrared image to a photograph or a sketch to a photograph. In this method, both test and training images were represented in terms of nonlinear similarities to a collection of prototype face images. The nonlinear kernel similarity between an image and the prototypes is measured in the corresponding modality. To further enhance recognition accuracy, the random subspace framework is employed in conjunction with LDA subspace analysis. The author tested the method in different heterogeneous environments, however more tests need to be performed to further enhance the recognition accuracy. F. Hao et
37

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

al. [61] proposed a handwriting signature-based system where velocity, pressure, altitude, and azimuth are extracted and converted into binary bits. This system has achieved a 1.2% FAR and 28% F RR. A. Teoh et al. [62] proposed a multispace random projection method. The distance-preserving property of multispace random projection is analyzed based on a normalized inner product, and an approximately zero equal error rate (EER) is achieved; however privacy and changeability are the main concerns in this paper. C. Lee et al. [63], introduced a two factor method for generating cancelable fingerprint templates using local minutia information. The transformation function is associated with the randomly generated P IN number, which is used to change the biometric template. The major drawback to this method is that there is a tradeoff between performance and changeability. O. Song et al. [64] tested the Reed-Solomon method on the three different fingerprint databases and found that on average an F RR of below 1% is achievable. Y. Wang [65] introduced a random projection algorithm for the template transformation method based on facial biometric features. The author implemented a vector translation technique to achieve a strong changeability. To enhance security and privacy as well as to improve recognition accuracy, only the index numbers of the sorted biometric template are stored as vectors. The index framework is then evaluated to produce a reissuable and secure biometric template. This method provides better protection of user privacy, and template revocability if it is compromised, at the cost of EER. The author also mentions that this methodology should be integrated with the biometric encryption system in future work in order to achieve the optimal level for biometric template protection. M. Savvides et al. [66] proposed a template transformation algorithm in the encryption domain. During the authentication phase, a query facial feature is convolved with a random kernel. This same kernel is used during the enrollment process to convolve with the training images, and is then correlated with the stored template in order to check the similarity. The stored template
38

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

is revocable and a new random kernel may be applied if it is compromised. However, the author doesn't clearly mention how the system would protect its privacy if the random kernel is compromised, since the original biometric may be retrievable if this occurs. D. Maio et al. [67], implemented a multihashing algorithm, where scores of selected fingerprint matchers and those obtained by a face authenticator are combined. Score level fusion is performed for each new biometric feature and a linear support vector machine is used for the final classification. Furthermore, to enhance the performance of this system, a random subspace based method is further combined with the similarity matching scores. A. Goh et al. [68], proposed a biohashing technique where the eigenprojection method is implemented to extract facial features. Each feature is hashed with a pseudorandom number in order to extract a single bit. A bit string is created and is further reduced to a single cryptographic key using Shamir  s secret sharing. The achievable entropy using this method is 80-bit with 0.93% F RR.

2.3

Prerequisites

The method introduced in this dissertation is developed under the assumption that the noise environment is nonlinear, nonstationary, and heterogeneous. As well, the extracted biometrics features (stored and dynamic) are vulnerable to security, privacy, and unlinkability attacks. This section introduces some fundamental concepts as prerequisites before getting into a detailed analysis of the proposed method.

2.3.1

Resampling

A digital image is a collection of evenly spaced pixels on a rectangular grid in the image space. Different mathematical operations can be performed on these images. One of the most important operations is resampling of the image, which is a mathematical
39

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

formulation used to create a new version of the image [69]. The two most commonly used methods in this regard are up-sampling and down-sampling. Increasing the size of an image by a factor of an integer or a rational fraction greater than unity is called up-sampling. In the case of up-sampling, the number of pixels increases with the size of the image. An up-sampled image usually contains all of the original information, but the image is smoother. On the other hand, reducing the size of an image by a factor of an integer or a rational fraction greater than unity is called down-sampling. In the case of down-sampling, the number of pixels decreases with the size of the image. A down-sampled image usually contains less information than the original image, however the image becomes sharper [69].

2.3.2

Statistical Properties

Statistical properties of the information processing system deal with the mean, covariance, probability, probability density function, autocorrelation, and cross correlation functions. These properties are the backbone of information technology. Parameter estimation, biometrics, and filtering hypothesis are performed based on these properties. But the fundamental limit on performance, based on this hypothesis, deviates from the optimal level due to the insufficient independent and identically distributed (i.i.d) sample data set, errors in receiver elements, and the diverse nature of the noise [70-72]. As a result, adaptive signal processing is now the subject of extensive research due to its capability of reducing the effects from the diversification of the underlining assumptions, in order to work and adapt with the more real world environment. Therefore, it is very important to have a core concept of the information technology from a statistical perspective. The following subsections state some fundamental statistical properties based on previous work in biometric and estimation theory.
40

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Mean

Now, assume that µX is the mean (also known as expected value) of a random process X. If x is a vector that contains L samples of the random process X, then it can be written that: x = [x1 and the expected value or the mean: µx = E[x] = [E [x1 ] E [x2 ] . . . E [xL ]]T . (2.2) x2 . . . xL ]T (2.1)

Now consider another random process Y , where y is vector of length L of that process with mean µy ; then the mean of the two random variables is the sum of their means and can be stated as: µx+y = µx + µy . (2.3)

Covariance

The covariance can be stated as a measure of how two non-identical variables change together. If the two variables are identical, then this property is called the variance. The covariance matrix can be defined as: Qxy = E[(x - µx )(y - µy )H ] = E[xyH - µx yH - xµy + µx µH y ]. In the case of a zero mean, covariance can be stated as: Qxy = Rxy .
41

(2.4)

(2.5)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Using these relationships, variance: Qxx = Rxx where (.)H , Rxx , (2.6)

and Rxy are the Hermitian transpose, autocorrelation, and

cross-correlation respectively, and have been defined in the next section. The standard deviation can be stated as a measure of the variability or dispersion of a data set. It is represented as the square root of the variance (or covariance). Therefore the standard deviation is: x = Qxx . (2.7)

Cross Correlation

Let us consider two stochastic processes X and Y . The correlation between two stochastic processes is called the cross correlation, and can be stated as: Rxy = E[xyH ]. (2.8)

The autocorrelation of a stochastic process describes the correlation between the process at different points in time. Thus it can be stated as: Rxx = E[xxH ]. (2.9)

Therefore, according to equations [2.5 - 2.9], it can be concluded that at a mean of zero, the variance and covariance are equal to autocorrelation and cross correlation respectively.
42

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Posterior Probability Density Function

Probability theory is concerned with analysis of random phenomena. It is a measure of how likely it is that some event will occur. Typically, probability can be denoted by P [.]. Conditional probability on the other hand is defined as the knowledge of an event or occurrence of X , given the occurrence of Y . So, conditional probability can be stated as [48],[71],[73]: P [XY ] P [Y ]

P [X | Y ] = where P [Y ] > 0.

(2.10)

Now, consider the sample vectors x and y of the stochastic processes X and Y respectively. The posterior probability density function (pdf) of x conditioned on y is: p[y|x]p[x] . p [y ]

p[x|y] = This is also known as Bayes' theorem.

(2.11)

If the random vector x follows a multivariate gaussian pdf px (x), then it can be written: px (x) = 1 (2 ) |Qxx |
L 2 1 2

e- 2 (x-µx )

1

H Q-1 (x-µ ) x x

(2.12)

where |Qx | is the matrix determinant.
Ergodic Process

A stochastic process is termed to be ergodic if its statistical properties can be deduced from a single, sufficiently long sample of the process. In other words, it is the process when the time average of the samples approaches the ensemble average. For example, in signal processing the process can be considered ergodic if the mean of the snapshot
43

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

of the process is equal to the true mean of that process for all of the snapshots when - < t < .
Independence, Correlation, and Disjoint

The random events x and y are said to be independent if and only if their joint pdf can be written as: pxy (x, y) = px (x)py (y) If x and y have non-zero probabilities, then this implies: pxy (x|y) = px (x) and pyx (y|x) = py (y). In the case of disjoint events, it may be considered that: pxy (x  y) = 0. (2.16) (2.15) (2.14) (2.13)

In probability, disjoint and independence do not mean the same thing. However, when either px (x) or py (y) is zero, then disjoint and independence are the same. Finally, random variables x and y are said to be uncorrelated if they satisfy the following relation: E[xy]H = E[x]E[y]H . (2.17)

2.3.3

ML and MAP

Maximum Likelihood Estimator (MLE) is a sample-based method of estimating nonrandom parameters, maximizing the known likelihood distribution based on a given
44

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

statistic [48],[71],[74]. It requires a distributional assumption for the purpose of summarizing observations.

Using Bayes' law, posterior density function can be stated as: p(x|w).p(w) p(x) likelihood.prior posterior = evidence Using the property of probability function: p(w|x).p(x) p(x|w) = p( w) posterior. evidence likelihood = prior p(w|x) =

(2.18)

where evidence x consists of independent observations {x1 , x2 , .....}. In MLE, the value of w (prior) is considered to be fixed, which maximizes the likelihood of Eq. (2.18). Therefore, a prior w needs to be considered that will give the largest possible value of p(x|w). Hence, ^ M L = Max p(x|w) w
w

ML solution can be obtained: dp(x|w) = 0. dw

(2.19)

On the other hand, Maximum a Posterior (MAP) is the corresponding estimate of the random parameter that maximizes the posterior probability density function. Therefore, MAP is represented by: ^ M AP = Max |p(x|w)p(w)|. w
w

(2.20)

45

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

2.3.4

Databases

In this dissertation, facial images from two public databases, the "Put Face Database" and the "Indian Face Database", are used [75],[76]. The sizes of the two databases are presented in Table 2.1. The "Put Face Database" is a highly nonlinear and heterogeneous 3D facial database. It contains approximately 20 images per person with a total of 200 people, and stores 2048 × 1536 pixel images [77]. The main motivation for using the "Put Face Database" is that the diversity of the image subsets allows them to be easily used for training, testing, and cross-validation processes. This can occur because the images in this database have more than 20 orientations for each individual using various lightings, backgrounds, and facial expressions. In addition, the images in this database contain 2193 landmarked images [78]. On the other hand, images in the "Indian Face Database" are less influenced by the facial expression, position orientation, and illumination effects. There are 40 subjects, each having 11 images with the same homogeneous background. The size of each image is 640× 480 and 256 gray level per pixel. The main reason for using two types of databases is to find out the combined effects of two different environments. As well, it is important to show that the proposed method is the optimal solution for not only the images highly influenced by the underlying challenges, but also for the images that are less obstructed by them. Furthermore, fingerprint images from the public database "CASIA-Fingerprint Version 5.0" have also been used in the proposed method. In this case, 40 fingerprint images of eight fingers were used, each finger with 5 images. All fingerprints are 8-bit gray-level with 328 × 356. 2.3.5 Nonlinear, Nonstationary, and Heterogeneous Noise

Typically, the presence of any unwanted objects in observations or measurements can be considered noise. Biometrics deals with large volumes of datasets that are
46

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 2.1: Two Databases Databases Put Face Indian Face Original Image Size (Pixels) 2048x1536 (gray) 640x480 (gray) Modified 256x256 (gray) 256x256 (gray)

obstructed by various noise. The illuminations, position orientations, misalignments, facial expression, noncooperativeness, and induced modalities (multimodal) introduce noise to these datasets in the time domain (change over time). In this dissertation, the noise under consideration is not referring to the classical definition of noise (i.e. Gaussian, Poisson) used in communication and signal processing. Rather it refers to image and feature artifacts caused by these effects. In most cases, the associated noise in the datasets is considered to be linear, stationary, and homogeneous. But, there is very likely to be nonlinear, nonstationary, and heterogeneous noise instead due to misalignment, illumination, position orientation, and facial expression effects. The principal challenge in biometrics is to mitigate the effects of these interferences while extracting quality features from these datasets. This section addresses the biometric system in this regard and systematically investigates the noise associated with the proposed MultiBiometrics authentication and encryption method.

2.3.5.1

Nonlinear

Biometric features are often corrupted by nonlinear noise during feature extraction and processing. This nonlinearity is caused by combining the features with different modalities, deformable templates, noncooperativeness, inter-class similarities, intraclass variations, environmental noise, and randomness of data acquisition systems [79],[80]. These dynamics are one of the most challenging obstructions in the field
47

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

of biometric authentication processes. In the context of the proposed method, nonlinearity consideration comes from the use of the several biometric modalities (i.e. multimodality), randomness of data acquisition systems (multi-source, multimodal), and associated variability of the biometrics over time. Nonlinearity adversely effects the noise covariance matrix and hence the reliability and accuracy of the proposed MultiBiometrics method. Furthermore, this noise implies that the output is the nonlinear function of input. Thus, it deteriorates the prediction and estimation process based on the inputted dataset, and hence the performance of the systems.

2.3.5.2

Nonstationary

Nonstationary refers to a process where the statistical properties of a system change over time, which is usually indicative of a dynamic system. In this dissertation, facial images from two public databases have been used [75],[76]. These images have been taken with different orientations and facial expressions. It is a challenge to extract quality biometric features since features availability and accessibility are interrupted due to these effects. In the context of the proposed method, variations of position orientations and facial expressions are being considered in the time domain. This nonstationary image property affects the intra-class similarities and inter-class variations of the extracted features, resulting in variability in mean and covariance estimations over time [81]. This time variant process deteriorates the feature quality and hence the performance of the authentication process. Therefore, consideration of the effects of these interferences on the extracted features due to nonstationary noise is of paramount importance to the proposed method. The variabilities of facial image orientations and expressions (snapshots taken at different times) from time t1 to t6 are shown in Fig. 2.3. These captured images over the time period of time t1 to t6 are being compared with the stored images in the database system in order to verify the authenticity of
48

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Changing Position Orientations

(b) Changing Facial Expressions and Position

Figure 2.3: Images in Time Variant Domain -Put Face Database

49

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the subject of interest.

2.3.5.3

Heterogeneous

Heterogeneity refers to the non-uniformity or diversification of a system, where the constituents are of a diverse nature [71-73]. In particular, a heterogeneous entity is the integration of the diverse nature of the dataset, and the data integration process is used to provide uniformity in the heterogeneous dataset. In biometrics, heterogeneous authenticity involves comparison of images from different modalities (i.e. multimodalities). In this case, the stored (or training) and test images are populated with images from different sources [60]. The biometric modalities, previously discussed in Section 1.1.3, refer to the integration of biometric traits (multimodality) collected from images with different backgrounds, samples, sensors, and features. Heterogeneous systems play a vital role in biometric applications, including forensics and surveillance. Interferences in the dataset are largely unavoidable, since in many circumstances only a limited number of images from a particular modality (i.e. due to illumination effects or image collection from different sources) are available for query. In the context of the proposed method, images have been taken from different backgrounds and sources. Multimodal (i.e. MultiBiometrics) biometrics has been used where features from the two different modalities, facial and fingerprint, have been collected and fused. Therefore, heterogeneity is an intrinsic property of extracted features that could largely influence the performance of the proposed MultiBiometrics authentication and encryption method. A sample of heterogeneous images from the public "Put Face Database" is given in Fig. 2.4. The information theory of biometrics states that the data structure of the extracted features is inherently dynamic in nature, resulting in a higher probability of nonlinearity and heterogeneity in the biometric features. During most of the authentication, the requirements of an independent and identically distributed (i.i.d) sample
50

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Facial Images -Put Face

(b) Fingerprint Images -CASIA v5.0

Figure 2.4: Heterogeneous Images -Multimodal and Milt-Background

dataset increase with the dimension of the covariance matrix. However, in a nonlinear, nonstationary, and heterogeneous operating environment, it would be a challenge for biometric systems to obtain a sufficient number of i.i.d data in the sample dataset. Biometrics are measurable human physiological and behavioral attributes that satisfy the properties stated in Section 1.1.4. These properties change over time and are highly susceptible to the nonlinear and heterogeneous noise associated with biometric features due to effects from illuminations, facial expressions, object orientations, and misalignments. This demonstrates that the nonlinear, nonstationary, and heterogeneous assumptions are extremely important in real world scenarios, especially in the method proposed in this dissertation.
51

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

2.3.6

Noncooperative Target

This method (Chapter 5) is designed under the assumption that the moving target in the surveillance zone is noncooperative. It also assumes that the received biometric features from a noncooperative (introduced nonlinearity) moving target contain noise due to background noise, illumination, change in target orientation, misalignment with associated features, and the unawareness or unwillingness of the target. On the other hand, it has also been considered that the cooperative target would have noise due to background noise, illumination, change in orientation, and misalignment effects as well. Thus, this model may also be implementable for cooperative targets. The relation between cooperative and noncooperative considerations can be stated as follows: Zco = s + n Znco = s + n +  = Zco +  (2.21)

where Zco and Znco are biometric features extracted from cooperative and noncooperative targets respectively, n is the underlying noise associated with the cooperative target, and  is the additional noise due to unawareness or the unwilling nature of the noncooperative target. 2.3.7 Privacy, Security, and Unlinkability

Biometrics deals with sensitive physiological information that is extremely private for an individual. This information is unique and cannot be revoked or reissued once compromised. Security measures to protect an individual's privacy are an extremely important component of biometric systems. The MultiBiometrics encryption method proposed in this dissertation has the objective of providing multilayered protection
52

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

for these biometric templates from security, privacy, and unlinkability attacks. The fundamental concepts of this protection in the context of biometrics are presented in this section.
2.3.7.1 Privacy

The term privacy has many meanings in different contexts. The most general is freedom from interference and intrusion. It implies that the collected information cannot be intercepted (i.e disclosed) without valid consent. In the context of the biometric system, privacy settings allow all authorized personnel to update data and access updated data. The purpose of obtaining the collected data must also be reasonable (i.e. lawful) and it must not be used for any reason other than that for which it was collected [82],[83]. It is especially important that the sensitive human physiological information collected for biometrics must not be allowed to be released to or intercepted by unauthorized personnel. Unauthorized retrieval or access to that sensitive information, and identification of an individual using that information, not only intrudes on the privacy of that individual immediately, but also poses immediate threats to the biometric systems [83]. Therefore, protection of privacy along with a guarantee that one cannot be identified is the vital issue for biometric systems, hence the proposed method.
2.3.7.2 Security

Security implies the protection of an object from destruction and the unwanted actions of unauthorized users. As mentioned previously, biometrics offers greater security than any other traditional methods, since a biometric system contains attributes that exclusively represent an individual's identity. These properties are unchangeable, undeniable, and difficult to lose or fake. However, just like any other system, there are security issues inherent to biometrics. Not only are there standard security issues
53

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

such as insecure databases or data transmission media, but the presence of a biometric scanner invites other forms of data manipulation. Furthermore, if someone were to gain access to the biometric database systems, the intruder could potentially access a person's unique physiological and biographic information, which an individual needs to keep extremely private [84]. Therefore, the main concern for the exploration of biometric systems is the security protection of these unique features. This cannot be neglected otherwise it can revert the overall process in the opposite direction, since the damage to this system is irreversible and may cost more than the system it is used for.

2.3.7.3

Unlinkability

Unlinkability is the privacy property that holds when an imposter cannot establish the relationship between objects. It is crucial to protect privacy in an authentication system [85]. True anonymity requires unlinkability, which is the ability of the system to perform multiple operations anonymously. Unlinkability also implies the incapability of retrieving the information of one individual based on the information of another. It is the measurement of the strength of a system (or object) to be unlinkable, and is the core property for any authentication process, making it difficult for a third party recipient to be associated with the unauthorized information. More importantly, the emergence of information technology along with the widespread increase in technological abilities poses unprecedented threats to the privacy and security of legitimate users. There is a very high possibility that unauthorized users would be able to overcome the challenges associated with breaking the infrastructure of a traditional unlinkable system. As a result, attacks on the unlinkability of the system have become an important concern in recent years [86]. It has become an especially important phenomenon for biometric systems, because if the system becomes compromised it could lead to unprecedented privacy and security breaches of biometric
54

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

systems [see Appendix - A].

2.3.8

Data Analysis

Acquiring useful information from the abundance of information sources and protecting its own privacy and security are vital issues for biometric systems. Data analysis is the process of transforming and modeling the data in this regard. This technology would enable the system to explore, visualize, and evaluate very large databases at a high level of abstraction without having any specific hypothesis. Some of the important data analysis techniques are stated in the following subsections [82],[87],[88].

Data Mining

Data mining has attracted a great deal of attention in all areas of research, from business to science; biometrics being no exception. Typically, it is a stochastic data analysis technique that is used for knowledge discovery and evaluation. With advancements in computer technology, the data mining process is able to dig through, analyze, extract, and transform enormous raw data sets into a meaningful set of data. Technically, it allows the system to analyze data received from different perspectives and dimensions and find the correlations or patterns among them. Biometric data mining is the computer-extensive knowledge discovery technique of biometric features used to analyze and recognize underlying patterns. The overall goal of this data mining is to extract images or signals of interest from the background and the sources and transform them into a useful and understandable structure for further use. In general, data mining techniques use algorithmic formulations based on a decision tree, statistical tools, the nearest neighbor, neural networks, and the database system for completing this transformation cycle [87],[88].
55

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Data Segmentation and Foreign Key

Data segmentation is known as data grouping, and is a branch of the data mining operation. It is the process of extracting and segmenting data in such a way that the system would be able to factorize data, reduce data volume, and classify data. It is also capable of storing data in different locations of the database system with the purpose of increasing overall system performance and security. However, prior to carrying out a data segmentation analysis, appropriate care should be taken to decide which key parameters could be used for the segmentation process. This is especially important, since the failure of biometric segmentation means that the system could not detect useful biometric features. Indexing is another technique that can be used in the data segmentation process to put segmented data in order. In addition, a foreign key is used in conjunction with the indexing process to create a link and establish a relationship amongst the segmented data within the database system [see Appendix - B ]. 2.3.9 Tensor

A tensor is the linear transformation or mapping of vector(s) to vector(s). It could be mono or multi dimensional array(s). The rank of the tensor is determined by the dimensionality required to represent the array. A matrix is an example of rank-2 and a vector is an example of a rank-1 tensor [89]. A linear transformation of vectors by rotational angle or projection is an example of a tensor, and the mathematical formulation responsible for this transformation is called tensor algebra. For example, if a linear transformation function T (.) is employed on the vectors S and produces the output vectors A, then: A = T (S ) where the linear transformation function T (.) performed the tensor operation.
56

(2.22)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

2.4

Discussions and Conclusions

This chapter presents a comprehensive literature review related to the proposed method as well as its prerequisites before examining the detailed analysis and formulation of the method. It is apparent from these studies that most biometric systems have been developed under the assumption that extracted biometrics and the nature of their associated interferences are linear, stationary, and homogeneous. Addtionally, it is found that the vulnerability of the extracted features to security, privacy, and unlinkability attacks is also a vital issue for biometric systems. The core arguments in favor of biometric authentication and cryptography revolve around the quality of extracted features, their uniqueness, and their robustness, to protect privacy and security. Therefore, a more sophisticated authentication and encryption method needs to be developed to deal with the underlying challenges. The proposed MultiBiometrics authentication and encryption method is being developed based on these underlying noise assumptions and vulnerabilities.

57

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

58

Chapter 3

Sequential Subspace Estimator
3.1 Introduction

A biometric system often encounters situations that involve manipulation of a very large number of datasets (features). Robustness and performance of the authentication method are largely dependent on the quality of information in these extracted features; their intra-class similarities and inter-class variations. However, it is very likely that the subset of these extracted data is highly correlated and contaminated by the nonlinear, nonstationary, and heterogeneous noise. Furthermore, in most cases, extracted biometric features and their associated noise is modeled as a linear, stationary, and homogeneous system. The performance of the system deteriorates when these underlying considerations are violated due to nonlinear, nonstationary, and heterogeneous noise. On the other hand, it also introduces computational complexity, redundancy, and deteriorates the overall authentication accuracy [2],[90]. As a result, the principal challenge in biometric authentication is to mitigate the effects of any noise while extracting the biometric features for template generation. Therefore, a vital issue of biometrics is to develop a sophisticated authentication method that would address the underlying challenges associated with the biometric system.
59

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

The most commonly used method for biometric authentication, especially for facial biometrics, is the Principal Component Analysis (PCA) [91-93]. Generally, it is a linear transformation under the supposition that an adequate number of independent and identically distributed (i.i.d) data is present in the received dataset. PCA is an optimal method under the assumption that the operating environment is linear, time-invariant, and homogeneous. But, in a realistic operating environment it is very likely that the data model is contaminated by nonlinear, nonstationary, and heterogeneous noise. This leads to a higher probability of the characteristics of the dataset deviating from the underlying assumptions. In this situation, the generated output from the PCA-based technique preserves misleading data that severely distort the data model. This distorted data model in turn affects the detection, recognition, and authentication accuracy. Thus, a more complex system needs to be designed so the system can adapt to challenges due to noise contamination [36].

There are other popular methods for biometric authentication. Maximum Likelihood Estimator (MLE) is a sample-based parameters estimation method which maximizes the known likelihood distribution based on a given statistic. However, it requires a distributional assumption for the purpose of summarizing the observations. As well, it is only optimal for homogeneous and time-invariant systems, and is highly biased with a small amount of error on the initial assumption. The Linear Discriminant Analysis (LDA) method is also used as a linear classifier that maximizes the inter-class variation and intra-class similarities [38]. In the case of the Bayesian Estimator (BE), the likelihood function is combined with the prior density function, which is also known as a posterior density function. Unlike MLE, in the Bayesian method the prior value is not fixed but allows for injection of (likely) prior values during the estimation process. The main challenge of the Bayesian Estimator is to express the prior in the form of a distribution. If the number of sample datasets for a
60

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

specific class is limited, the performance of the Bayesian Estimator deteriorates significantly [48]. Least Mean Square (LMS) is a direct gradient descent method. This is an iterative process, where the input data sample is considered to be stochastic. The basic idea of this method is to update the filter weight to find the gradient of the mean square error [74]. In contrast, the Recursive Least Squared (RLS) filter minimizes the linear least square error recursively where the input data sample is considered to be deterministic [35],[94]. Although RLS can be used to solve most of the adaptive filtering problems, it involves more complicated mathematical operations and thus is computationally inefficient [38]. Finally, Wiener is a linear and time-invariant filtering technique which minimizes the Mean Square Error (MSE) between the estimated and the desired dataset. Typically, the LDA, MLE, Bayesian, LMS, and Wiener filters are optimal for linear and time-invariant systems. The integration of these methods with PCA is used as a solution for adapting to the nonlinear, nonstationary, and heterogeneous noise environment. Another promising solution is the sequential estimator, which has also the capability of adapting to the diverse nature of noise. It is a recursive process and works based on prediction, adaptation (update or adjustment), and estimation [91]. However, the sequential state estimator is computationally inefficient for a higher dimensional dataset since it needs to compute the covariance matrix and perform a matrix inversion operation. This chapter addresses the predominant deficiency of the biometric system in this regard. It also systematically investigates a biometric authentication in a nonlinear, nonstationary, and heterogeneous noise environment. Importantly, this authentication method is made independent of the biometric traits. The performance of this approach is being tested on facial images from two public databases: the "Put Face Database" and the "Indian Face Database". In the experiment, the facial image is analyzed in the image subspace to mitigate its noise levels before it is encoded and the
61

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

biometric template is created. Afterwards, the facial biometric features such as facial area, and size and relative positions of eyes and lips are extracted, analyzed, and encoded to create the biometric template. This template is then stored to compare with the other encoded facial biometrics. The noise associated with this feature is considered to be nonlinear, nonstationary, and heterogeneous due to position orientation, facial expression, and illumination effects. It will be shown that the proposed SSE method outperformed its counterparts: PCA, PCA-Wiener, PCA-MLE, and the sequential estimator; both in linear and homogeneous systems, and nonlinear and heterogeneous systems. In this chapter, a new recursive sequential estimator algorithm in the image subspace is developed. This method addresses the challenges associated with the extracted features due to nonlinear, nonstationary, and heterogeneous noise (i.e., noise covariance matrix). As well, a subspace method is implemented in the image subspace to overcome the underlying computational complexity and reduce the execution time significantly. The proposed subspace method transforms higher dimensional image space into a set of linearly independent image spaces (image subspace) so that the dimensionality of biometric features reduces from N × N to M × M , where M << N . Using PCA analogy, this method distributes the principal biometric feature vectors to the image subspace. Moreover, in this recursive approach, the extracted data and the associated noise (i.e. noise covariance) update in every iteration using the biometric features (dataset) from the immediate previous state. The SSE approach is based on the minimization of noise and maximization of information contained in the received data, in MSE sense. Therefore, this method would be able to make a close approximation of the desired dataset, which would otherwise be contaminated by nonstationary and heterogeneous noise. The remainder of the chapter is organized as follows: Section 3.2 introduces the problem formulation and briefly reviews PCA, MLE, Bayesian, and Wiener methods.
62

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Section 3.3 presents the detail analysis and methodology for the proposed solution. Experimental results, analysis, and discussions are presented in Section 3.4. Finally, conclusions are drawn in the final section.

3.2

Problem Formulation and Filtering with Principal Component Analysis

Principal component analysis is a statistical method used to analyze extracted biometric features. It uses orthogonal transformation to convert a set of observations of correlated variables to a set of linearly uncorrelated variables [93]. The purpose of PCA is to reduce the dimensionality of the dataset while retaining as much information as possible. In PCA, each image can be represented as a weighted sum of a small collection of images that define an image basis or eigenimage. The main objective is to calculate the principal components such that they account for the largest possible variance in the extracted dataset. During this process, there is no limit on the value of the weight vector for having the largest possible variance in the dataset, therefore a constraint must be added to the weight vector w in order to introduce consistency in the estimation process. Furthermore, this methodology is developed under the assumptions that the operating environment is stationary and linear and there are an adequate number of linearly independent variables available in the extracted feature vectors. On the other hand, due to the nonlinear, nonstationary, and heterogeneous noise environment, extracted data always deviate from the underlying assumptions, resulting in poor authentication accuracy. In this section, problem formulation, the PCA architecture, the Wiener filter, the MLE, and the Bayesian Estimator (BE) are examined.
63

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.2.1

Principal Component Analysis (PCA)

The main operational principles and formulation of PCA are stated below [93]: 1. Receive dataset of size m (vectorized image N × 1 and m << N) at time t, x = x 1 x 2 x 3 ......x m . 2. Estimate the zero mean, eigenvalues, and corresponding eigenvectors; and then construct feature vectors with the principal components of size n (n < m). Covx = xxT Covx V = V w = (w1 w2 w3 .....wn ). (3.1)

Therefore, the new dataset with principal components: z = wT x (3.2)

where w is the n-dimensional weight or loading vectors, mapped to each row vector of x; z is considered to be inherited data with the maximum possible variance from the x dataset; and each weight vector w is constrained to a unit vector. Now, the estimation of initial weight vectors that maximize the variance of individual variables of z can be formulated as the following optimization problem:

w = Max
w =1

wT xT xw wT w

.

(3.3)

Therefore, the PCA estimator can also be formulated as the following optimization problem:
64

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

zP CA = Max{var (xw)} subject to wT w = 1. (3.4)

^ respecMoreover, if measured and estimated observations can be defined as x and x tively; then the PCA optimization problem can also be defined as: ^ )T (x - x ^ )} zP CA = Min{(x - x subject to wT w = 1. (3.5)

The PCA algorithm is optimal under the assumption that there are an adequate number of independent and identically distributed data in the dataset. In this approach the system is considered to be time-invariant and there is no heterogeneity or non-linearity in the data sample. However, an environment where the characteristics of the data deviate from the underlying assumptions is inadequate and results in poor authentication accuracy. Thus a complex dynamic filtering system needs to be modeled that can deal with the nonlinear and heterogeneous noise while also maximizing the amount of useful features in the dataset. Now, consider that the received biometric feature is the sum of the desired biometric features and the noise. Then the received data sample can be written as: x = s+n Therefore using Eq. (3.2), z = wT s + wT n (3.6)

where n is the noise, and s represents the noise-free data or the desired dataset. So, the main objective is to minimize the noise n while maximizing the useful information
65

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

content in the desired dataset.

3.2.2

PCA with Wiener Filter (PCA-Wiener)

The classical Wiener filter is a linear optimal discrete time filter. It is optimal under the assumption that the operating environment is linear and stationary [38]. A schematic presentation of the adaptive Wiener filter is shown in Fig. 3.1.

Figure 3.1: Adaptive Wiener Filter

In PCS-Wiener, PCA puts constraints on weight vectors so that the sum of their squared values equals one. Now, the output of the filter at time t can be written as
66

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

follows: y(t) = wT (t)x(t) (3.7)

where x represents observation dataset, w = (w1 , w2 , . . . , wn ) are the weight vectors and (.)T is the transpose operation. But it is very likely there is noise in the observed data x. If the system considers that the observed sample x contains desired sample data s and noise data n, then by using Eq. (3.6) the above equation can be restated as: y(t) = wT (t)s(t) + wT (t)n(t). (3.8)

If the operating environment is stationary, linear, and homogeneous, then the estimate ^ (t) of the desired data d(t) at time t can be stated as: y ^ (t) = w ^ T (t)x(t) y Due to a stationary system, it can be assumed: ^ T (t + 1) = w ^ T (t). w The Mean Squared Error (MSE) is given by: MSE = E[e2 (t)] = E[(d(t) - wT (t)x(t))2 ] = E[d2 (t) - wT (t)x(t)d(t) - d(t)xT (t)w(t) +wT (t)x(t)xT (t)w(t)] = E[d2 (t)] - 2wT (t)E[d(t)x(t)] +wT (t)E[x(t)xT (t)]w(t). (3.10) The Wiener solution of the optimal weight vector can be found by taking the
67

(3.9)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

second order derivation of Eq. (3.10) with respect to the weight vector w, and equating it with zero. Therefore, the solution for the optimal weight vector wopt :

 2 (MSE ) = 0.  w2 The above equation is known as the Wiener Hopf equation.

(3.11)

The main advantage of the Wiener filter is its computational simplicity and ability to suppress noise in linear and stationary cases. Furthermore, the optimal solution of the Wiener filter involves only second order statistics, which in fact leads to a useful theory of linear filtering for many applications. The main goal of the Wiener is to filter out noise based on the statistical properties. Furthermore, the Wiener filter is an optimal filter under the assumption that the data model and additive noise are stationary and linear stochastic processes. As well, their behavioural characteristics, or auto and cross correlation, are also considered to be known. But, it is very likely to have a time varying nonlinear system with unknown data structure and noise properties; in this case, the Wiener filtering solution is inadequate to deal with this system and its associated noise. However, PCA-Wiener might be an alternative solution to overcome these challenges. It will be shown that the performance of the proposed SSE method is outstanding in comparison to PCA-Wiener.

3.2.3

PCA with Maximum Likelihood Estimator (PCA-MLE)

The objective of PCA with the Maximum Likelihood Estimator (MLE) is to maximize the likelihood of the principal components in the dataset without sacrificing useful information. Using the analogy of section 2.3.3, the PCA-ML estimator needs to maximize the probability density function in order to reduce the noise level. This can
68

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

be stated as follows. ^ M L = Max p(x|w) w
w

ML solution can be obtained: dp(x|w) = 0. dw

(3.12)

But, noise is very likely to occur in the observed sample dataset, and hence in the distribution. Therefore, the PCA-ML optimization problem can also be formulated as:
1 ^ )T Q- ^ )} wP CAM L = Min{(x - x x (x - x

subject to wT w = 1

(3.13)

^ are noise covariance, measured and estimated observations, rewhere Qx , x and x spectively. The MLE is optimal for the linear, homogeneous, and time-invariant system. On the other hand, the PCA-MLE addresses the challenges associated with the PCA estimator due to noise present in the received dataset. In this case, the prior is fixed and this estimator doesn't allow for injection of the prior knowledge during the estimation process. The PCA-MLE method might be a solution to deal with the nonlinear, nonstationary, and heterogeneous noise environment.

3.2.4

PCA with Bayesian Estimator (PCA-BE)

Unlike the Maximum Likelihood Estimator, in the Bayesian Estimator (BE) observable and non-observable quantities are random in nature. If x and w are the observations and the weight vectors respectively, then using Eq. (2.18), the posterior density
69

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

function can be stated as follows: p(w|x) = p(x|w).p(w) . p(x) (3.14)

The probability density function p(w) is considered to be a prior density function of unknown quantity w. But, in contrast to MLE, the prior is a random quantity. Furthermore, the Bayesian Estimator can incorporate the external knowledge or prior beliefs in the likely values of w during the estimation process [45],[48]. Using the analogy and data reconciliation stated in sections 2.3.3, 3.1.1, and 3.1.3, the PCA-BE estimator can be formulated as the optimization problem:
AP ^M w P CABE = Max |p(x|w)p(w)|

subject to wT w = 1.

(3.15)

One of the main complexities of the Bayesian Estimator is the probability of evidence, stated by the denominator p(x) in Eq. (3.14). The main goal is to maximize (i.e. p(x)  1) the probability of evidence under the implied constraint. If it is possible to estimate the numerator with good approximation and a well defined prior, then it might be possible to replace the probability of evidence with a normalized constant value. It is found that for a large data sample and a well behaved prior, MLE and BE methods converge to the same point. The PCA-Bayesian Estimator overcomes challenges associated with the PCAMLE. The Bayesian method is an optimal estimator for a linear, stationary, and homogeneous environment. However, if the amount of sample data in the extracted biometric features is limited, the performance of the Bayesian Estimator deteriorates significantly. On the other hand, PCA-Bayesian is being used as an alternative solution to overcome the challenges associated with a nonstationary, nonlinear, and heterogeneous noise environment.
70

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.2.5

Extended Kalman Filter (EKF)

The Extended Kalman Filter (EKF) is an extended version of the Kalman Filter (KF), used for nonlinear, nonstationary, and heterogeneous systems. It is recursive and a branch of the sequential estimator process, so new measurements can be processed as they arrive. Now, assume that a dynamic system can be modeled by the state equation [95],[96]: x(t + 1) = F (t)x(t) + v (t) Q(t) = E[v (t)v (t) ] (3.16)

where x is the state at time t, F(t) is the state transition matrix, v(t)represents the processed noise, and Q(t) is the covariance of the processed noise.

If observations of the state are made using a set of measurements, then the measurement equation can be stated as follows: z (t) = H (t)x(t) + n(t) R(t) = E[n(t)n(t) ] (3.17)

where z(t) is the measurement made at time t, H(t) is the measurement matrix, n(t) is the measurement noise, and R(t) represents the covariance of measurement noise.

Now, given a set of observations z1 , z2 , ......z (t + 1), if an estimate of the state x(t+1) is x ^(t + 1), namely x ^(t + 1)|z (t), then the expectation of the squared-error
71

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

function can be written as: xer (t + 1) = E[|x(t + 1) - x ^(t + 1)|2 ] Estimate of predicted covariance: P (t + 1|t) = F (t)P (t|t)F T (t) + Q(t) Measurement Residual: zer (t + 1) = z (t) - h(^ x(t + 1)|t) Innovation: S (t + 1) = H (t)P (t + 1|t)H T (t) + R(t) Gain for Extended Kalman Filter: K (t + 1) = P (t + 1|t)H (t)T S -1 (t) State Update: x ^(t + 1|t + 1) = x ^(t + 1|t) + K (t + 1)zer (t + 1) (3.19) The objective is to adjust K (t +1)zer (t +1) to minimize Eq. (3.18). The sequential estimator EKF is computationally inefficient for large values of datasets, since it needs to perform extensive matrix operations including matrix inversions. (3.18)

3.3

Model Formulation and Sequential Subspace Estimator

The challenges posed by the Wiener, MLE, BE, and EKF can be overcome by the proposed Sequential Subspace Estimator (SSE). The SSE has the ability to deal with estimation challenges in a nonstationary, nonlinear, and heterogeneous operating environment and its associated computational complexity. It is a recursive method based on prediction, adaptation (update or adjustment), and estimation. In other words, the proposed SSE method is the extension of the Wiener, MLE, and Bayesian
72

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

approaches, where the operating environment (i.e. SSE) is nonstationary, nonlinear, and heterogeneous. The integration of PCA with these methods is widely used for this type of environment. The relationship between the SSE and the Wiener (or MLE, Bayesian, PCA) can be stated as follows: SSE = Wiener + nonlinear or nonstationary (3.20)

This is the core section of the proposed method. In this section a Sequential Subspace Estimator algorithm is being designed to address the underlying challenges and their associated computational complexities.

3.3.1

Subspace

The main objective of this method is to address the challenges associated with extracted biometric features due to nonlinear, nonstationary, and heterogeneous noise. Classical PCA, LDA, MLE, Bayesian, LMS, and Wiener methods are inadequate to overcome these challenges. The sequential estimator and the integration of PCA with Wiener and MLE are widely used when dealing with this type of environment. However, the sequential estimator is computationally inefficient for a higher dimensional dataset since it needs to compute the covariance matrix, perform the matrix inversion operation, and execute the data interpretation process [35],[95],[96]. As well, vectorization of the image would also be a huge computational burden, since a size N × N

(8-bit) matrix becomes a vector of dimension N 2 , and thus a size N 2 × N 2 covariance matrix needs to be computed. These inadequacies led to a proposal of a new subspace technique. The SSE subspace method proposed here would overcome the challenges associated with noisy extracted data and the computational complexity. In this subspace method, an image of L - bit is considered; here the image would be a 2L × 2L matrix of (L - bit) intensity values in the image space.
73

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Considering that each value of a 2L × 2L matrix is a uniquely characterized data point in the image subspace, the collection of these data points is the representation of an image. In this method, image has been segmented into L×2, L, and L/2 datasets in the image subspace by using Eq. (3.21). However, it is also possible to use other segmented datasets in the image subspace in order to achieve different performance and efficiency levels. Under these assumptions, the dimension of 2L × 2L is reduced in the image subspace by a factor of L×2, L, and L/2. In the case of an 8-bit image, the dimension of 28 × 28 (L=8) is reduced by a factor of 16, 8, and 4 in the image subspace, respectively. In this study, the proposed SSE method using these three datasets is represented by SSE-16 × 16, SSE-32 × 32 (or SSE), and SSE-64 × 64, respectively. The subspace method is the segmentation of an N ×N dataset into an L (or L/2, or L×2) number of linearly independent datasets of dimension M × M (where M=N/L or M=N/(L/2), or M=N/(LX2)). Later in Section 3.4.3, a comparison between subspace datasets L/2 (i.e. SSE-64X64), L (i.e. SSE-32X32 or SSE), and L×2 (i.e. SSE-16X16) will be presented, and it will be shown that the proposed SSE method with L subspace datasets outperforms the subspace datasets L/2 and L×2. Therefore, in most cases, the model formulation, experimental analysis, comparisons, and discussions used in this study are based on the L number of segmented datasets in the image subspace. In this segmentation process, homogeneity and linearity are considered during the segmentation process, but data points within each of the L datasets are considered to be nonlinear, nonstationary, and heterogeneous. The relationship between the original and segmented datasets can be stated as follows: N=
L i=1

Mi

(3.21)

where a sparse or segmented dimension = (R + rM ) × (C + cM ). Here, M = ceil(N/L); R = 1, 2, ...., M ; C = 1, 2, ...., M ; r = 0, 1, 2, ...., (L - 1); and c =
74

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

spectively, and the  ceil operation rounds up the value (N/L) to the nearest integer

0, 1, 2, ...., (L - 1). r and c increase by 1 for every complete cycle of R and C, re-

greater than or equal to (N/L). Hence, the estimation of the dataset reduces from N × N to L number of linearly independent datasets of dimension M × M . If the image is considered to be a vector of dimension N 2 , then an image of size 8-bit (N=256) would need a vector of dimension 65, 536. In contrast, the proposed subspace approach would need a point in M × M (i.e. 32 × 32 = 1024) dimensional vector subspace. This is an iterative process which continues L (L=8) times using the same vector subspace. Therefore, using the subspace method, an ensemble of images and maps for a collection of points created in the image space leads to huge dimensional (and computational) savings. The SSE algorithm is being designed to implement the segmented datasets in the image subspace. This method estimates the principal feature vectors of the datasets and distributes them in the image subspace in order to mitigate the underlying noise level. Afterwards, the segmented (and filtered) image datasets concatenate in order to reconstruct the desired image. The subspace transformation process is shown in Fig. 3.2, where the corresponding subset of data (column vectors) is represented by color codes. Consider an 8-bit 2D image, which has an N × N array of 8-bit intensity values.

3.3.2

Model Formulation

^ (t) at The main objective of this section is to design a filter that given an estimate y time t of the desired biometric feature vectors d(t), using the observed data sample x(t). In this case, constraints are added to the weight vector w to mitigate the noise in MSE sense [95]. The complete operational block diagram of the Sequential Subspace Estimator (SSE) is shown in Fig. 3.3. According to the figure, the estimated processor ^ (t) can be stated as: output y ^ (t) = wT x(t). y
75

(3.22)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Data Segmentation

(b) Subspace, Filtering, and Concatenation

Figure 3.2: SSE Subspace -Transformation Process

76

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

and the Mean Squared Error (MSE): ^ (t) = d(t) - wT (t)x(t) e(t) = d(t) - y MSE = E[e2 (t)] = E[(d(t) - wT (t)x(t))2 ] = E[((d(t) - wT (t)x(t))(d(t) - wT (t)x(t))T ] = E[d2 (t) - wT (t)x(t)d(t) - d(t)xT (t)w(t) +wT (t)x(t)xT (t)w(t)] = E[d2 (t)] - 2wT (t)E[x(t)d(t)] +wT (t)E[x(t)xT (t)]w(t)
T T = 2 d - 2w (t)Pxd + w (t)Q(t)w(t)

(3.23)

where Q(t) = noise covariance matrix, 2 d = Variance of the desired dataset, Pxd = Cross correlation between x(t) and d(t) = E[x(t)d(t)] = E[x(t)xT (t)]wc (t) Therefore, using the same analogy stated in section 3.2, the optimization problem can be formulated as:
T T min MSE = 2 d + w (t)Q(t)w(t) - 2w (t)Pxd

subject to: wT w = 1 Eq. (3.24) is the expected outcome or objective function of the proposed SSE.

(3.24)

77

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.3: Sequential Subspace Estimator (SSE)

78

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.3.3

Working Principle

In the SSE authentication method, facial area and size and relative positions of eyes and lips have been extracted as biometric features. These features were selected because they are more visible, easy to extract, less changeable over time, and have the ability to authenticate an individual with greater accuracy in comparison to other features [68],[77]. The proposed SSE method is performed in three cycles. In its first cycle of operation, the main objective is to mitigate the noise and computational complexity associated with the large volume of biometric datasets. The steps involved in this SSE cycle are given below and in Fig. 3.4:

3.3.3.1

Extract Quality Facial Image

· Capture image · Implement subspace method in order to segment the image in the image subspace (see Section 3.3.1) · Perform SSE filtering method to mitigate the noise level · Concatenate segmented images · Train the system (See Section 3.3.6) · Implement SSE method to detect the face · Extract quality facial image · Process extracted image for feature detection and extraction method (for next cycle)

79

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.4: Extract Quality Facial Image

80

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.3.3.2

Detect and Create Biometric Template

In the second cycle, the main objective is to detect and extract the participating biometric features from the extracted facial image. The steps that are involved are given below and in Fig. 3.5: · Train the system (See Section 3.3.6) · Implement SSE to detect facial boundary, eyes, and lips · Extract features · Estimate facial area, size of eyes, and lips (See Fig. 3.5 and Appendix -C for Sample Data) · Measure middle point between the two eyes as reference point · Measure relative positions of eyes and lips from this reference point · Use these extracted features as test biometric features (template) The method of training the system has been discussed in Section 3.3.6.
3.3.3.3 Biometric Template Matching

The proposed method is made independent of biometric traits; however the algorithm is being tested on facial images from the public nonlinear and heterogeneous "Put Face Database" [75] and less hetero-nonlinear "Indian Face Database" [76]. All image sizes have been considered (customized) to be 256 × 256 (8-bit). Afterwards, image is segmented in image subspace by a factor equal to the bit size. Therefore, 8 segmented datasets, each of size 32 × 32, are being constructed in the image subspace. The SSE algorithm is being developed to be implemented into each of the segmented datasets to mitigate the noise under consideration; thus there would be 8 iterative processes
81

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Feature Detection (Location)

(b) Feature Extrcation

Figure 3.5: Create Biometric Template

82

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

using the same vector space. The concatenate operation is performed on the filtered datasets in order to reconstruct the original image, hence the biometric template. The final step of the SSE authentication method is the verification process, where the test biometric template is compared with the template stored in the database system. In this comparison (matching process), the Euclidean distances of the stored biometric template (i.e. facial area, and size and relative positions of the eyes and lips) are compared with the biometric template generated from the received live image. This matching process can be seen in Fig. 3.6. The steps involved in the matching process are stated below: · Use the test template as an input to the system · Compare the test template with the stored template in the database system · Compare with the threshold values · Make the authentication decision

3.3.4

Sequential Subspace Estimator

The proposed method is executed under the assumption that the associated noise in the received facial image is nonlinear, nonstationary, and heterogeneous. In this approach, the system performs a sequential recursive filtering process in the image subspace to cancel out the nonlinear and heterogeneous noise. Afterwards, it extracts and estimates the size of the facial area, as well as the relative positions and size of the eyes and lips, in order to encode and create the biometric templates. This template is then stored in the biometrics database to be compared with other encoded biometrics. Using Eq. (3.8), the data received at the output of the processor can be stated as: y(t) = wT (t)x(t) = wT (t)s(t) + wT (t)n(t).
83

(3.25)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.6: Template Matching

84

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

The main objective is to determine the minimum value of the Mean Squared Error (MSE), i.e. Minimum Mean Squared Error (MMSE). Once this value is obtained, the desired features from the underlying noise environment can be encoded to maximize the mutual information I (^ y; d). The proposed SSE optimization problem can be restated as follows:
T T min MSE = 2 d + w (t)Q(t)w(t) - 2w (t)Pxd

(3.26)

subject to: wT j wj = 1, and j = 1, 2, ...., M. The conditional mean is an optimal MMSE estimator and is computationally efficient; since it is recursive, it can process the features as they arrive. For linear and homogeneous systems, the Kalman Filter (KF) estimate of the conditional mean and the MMSE is optimal. Unfortunately, KF is an inadequate solution for the nonlinear and heterogeneous environment and EKF is conditionally inefficient. The proposed method is the promising alternative to overcome these challenges. Now, consider an unknown dynamic system with state vectors wc (subscript c implies constraint to vectors) where the system is driven by random noise. If the system can be modeled as a filter, then the proposed state equation can be written as [95-103]:
i wi c (t + 1) = F (t)wc (t) +  (t)

R = 2 pI

(3.27)

where F (t + 1|t) is the state transition matrix, which is a function of time and relates the state vector from t to t + 1, and  (t) is processed noise. The covariance matrix of the processed noise is represented by R [95],[96]; where I may assume as an identity matrix, t is the time index, and the superscript  i (i = 1, 2, ..., L) represents the number of linearly independent datasets of dimension M × M in the
85

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

image subspace. For convenience, the  i may be ignored for the rest of the cases. If the operating environment is considered to be linear, stationary, and homogeneous, then the state vectors wc would be fixed or a function of any arbitrary constant. In this case, the state transition matrix F (t + 1|t) is considered to be an identity matrix. However, for a nonlinear, nonstationary, and heterogeneous noise environment, a more complex method for F (t + 1|t) needs to be developed so that the model can track the changes in response to environmental fluxes. Now, the measurement equation can be represented by [95],[98]:

d(t) = x(t)T wc (t) + (t) = H [t, wc (t)] + (t) (3.28)

where (t) is measurement (observation) noise, considered to be linear, stationary, and homogeneous with zero mean, and covariance is given by: E[(a)(b)] = 2 m (t)ab (3.29)

In the proposed method, the associated noise in the extracted dataset is considered to be nonlinear, nonstationary, and heterogeneous. Therefore, the proposed measurement from Eq. (3.28) under these assumptions can be restated as:

dnon (t) = h[t, wc (t), (t)] where h[.] is the Jacobian evaluation of H [.].

(3.30)

Eqs. (3.27) and (3.30) are the state and measurement equations respectively, designed for the proposed SSE. These equations are being used to model the SSE method in the image subspace based on the proposed constraints given in Eq. (3.26).
86

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

^ (t) of the desired dataset d(t) can be stated as [95],[99]: Now, the estimate y

^ (t) = h[t, w ^ c (t)]. y

(3.31)

The MSE between the desired features and the estimated output can be defined by using Eq. (3.26) as follows:

^ (t) e(t) = d(t) - y
^j w c =1

(3.32)

min MSE = E[|e(t)|2 ] ^T ^ c (t) = 2 d+w c (t)Q(t)w ^T -2w c (t)Pxd . (3.33)

An initial estimate of the weight vector starts with the relation stated in Eq. (3.3) and uses the estimated covariance matrix calculated with Eq. (3.1) from sample ^ c would be converged to the optimal value in MSE sense. dataset. Thus, using SSE, w The innovation or the measurement residue may now be stated as [95],[96],[98]: ^ (t|t - 1).  (t) = d(t) - y Hence, the updated state becomes: ^ c (t + 1|t + 1) = w ^ c (t + 1|t) + k(t + 1) (t + 1) w (3.35) (3.34)

where k(t) is the filter gain. Now, k(t) can be written in terms of the first order (Jacobian) measurement matrix [95]: k(t + 1) = P (t + 1|t)[ ^ c (t)) -1 h(t, w ]M (t + 1)  wc (t)
87

(3.36)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

and the estimated (predicted) conditional covariance matrix [95-98]: P (t + 1|t) = F (t)P (t|t)F T (t) + R(t). Measurement Innovation covariance: M(t + 1) = 2 m (t + 1) + [ ^ c (t)) T h(t, w ]  wc (t) h(t,^ wc (t)) .P (t + 1|t)[ ].  wc (t) (3.37)

(3.38)

The covariance update [95],[96]: P (t + 1|t + 1) = P (t + 1|t) - k(t + 1)M (t + 1)k(t + 1)T . Using the Matrix Inversion Lemma [95], it can be written as: P (t + 1|t + 1)-1 = [(P (t + 1|t))]-1 + ^ c (t)) h(t, w  wc (t) ^ c (t)) T -1 h(t, w [2 ] . m] [  wc (t) (3.39)

(3.40)

If the first term [(P (t + 1|t))]-1 is neglected due to the large initial value condition, then the above equation may be restated as [95],[99,[100]]: P (t + 1|t + 1)-1 = ^ c (t)) T ^ c (t)) 2 -1 h(t, w h(t, w [m ] [ ] .  wc (t)  wc (t) (3.41)

This is a recursive process beginning with Eq. (3.27) that stops once the stop criteria are met. The algorithmic diagram of the SSE model can be seen in Fig. 3.7 and its associated computational complexities have also been shown (i.e. marked by arrow) in the diagram. The differences shown in Eq. (3.34) represent the differences between the desired
88

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.7: SSE Algorithm - One Cycle of Operation

89

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

output and the actual output, estimated using the weight vector and the asymptotic covariance matrix. If the desired output d(t) can be interpreted as an approximation of the actual desired dataset using the constraint, then the actual data sample a(t) and the approximated desired data sample d(t) with an approximation error  (t) can be related as follows:

a(t) = d(t) +  (t).

(3.42)

If a(t) and  (t) are assumed to be linear, homogeneous, and uncorrelated, then 2 (t) = MMSE + E[ 2 ]. (3.43)

In the proposed SSE method, the measurement d(t) in Eq. (3.28) is generated using the realistic approximation (i.e. training dataset) of the desired dataset. So, 2 (t) could be approximated based on the MMSE achieved by an observed dataset, the approximation of the constraint weight vector wc (t), and the filtering model as stated above.

3.3.5

Selection of Parameters

The state transition matrix F (t + 1|t) and covariance R of Eq. (3.27) has a more complex form in a nonlinear, nonstationary, and heterogeneous system. For that reason, the parameters of the state equation must be chosen in such a way that the system model can track and adapt changes caused by the diversity of the environment [73],[91],[95]. Under these assumptions, the state transition matrix is not an identity matrix [i.e. F (t + 1|t) = I ], which may make the state equation unstable; the stability of the filter may be assured by the observability condition. The state covariance matrix R is the total uncertainty from adapting the linear and stationary environment assumption represented by the identity state transition matrix in equations (3.27) and
90

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(3.37). The effect associated with this deviation due to a nonlinear and nonstationary environment [ (t) = 0 and F (t + 1|t) = I ] prevents the proposed Sequential Subspace Estimator from minimizing the objective function in Eq. (3.33) to values that drive the estimation and detection accuracy to an optimal level. Furthermore, the estimate ^c is also able to follow variations in the weight vector of the optimal weight vector w due to a nonlinear, nonstationary, and heterogeneous noise environment. In this experiment, the range of parameters selected for the observation noise, state transition matrix, and the covariances are based on the estimation models discussed in [48],[70],[74],[93],[95],[96],[98]. The PCA is an orthogonal transformation method based on the estimation of the zero mean, eigenvalues and corresponding eigenvectors for constructing the principal components of the feature vectors from the extracted features. Parameters were selected for the PCA method based on the method outlined in [93] and Section 1.2.1. In the PCA-Bayesian and MLE methods, the parameters for the noise covariance matrix were modeled based on the method given in [48],[74]. Parameters for the PCA-Wiener have been selected based on the method stated in [95] and [96]. Finally, the parameters used for the proposed SSE and Extended Kalman Filter have been selected based on [70],[95],[96],[98]. In both cases, three parameters for the transition matrix (0.5, 0.75, and 1) and three parameters for the process noise (10-4 , 10-3 , and 10-2 ) have been chosen. Afterward, in using these parameters, a looping operation has been performed and has taken the average from the outcome of this operation. The data obtained from this experimental is included in Appendix-C . The list of parameters used in these experiments is given in Table 3.1:

3.3.6

Training Using MLP-SSE

A Multilayer Perception (MLP) is a feed forward neural network model with one or more hidden layers between the input and output. In theory, a neural network is an arbitrary mapping method that maps one vector space to another vector space using
91

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.1: List of Parameters Used for The Experiment Methods Proposed SSE Extended Kalman Filter PCA PCA-Wiener PCA-MLE Transition Matrix 0.5, 0.75, and 1 0.5, 0.75, and 1 Not Applicable Not Applicable Not Applicable Process Noise 10-4 , 10-3 , and 10-2 10-4 , 10-3 , and 10-2 Not Applicable 10-2 10-2 Observation Noise 0.1 0.1 Not Applicable 0.1 0.1

some a priori unknown information hidden in the data. The process of capturing unknown data by adjusting the weight coefficients under certain constraints is known as the training of the neural network. This multilayer neural network training can be considered state estimation problems and is based on prediction and correction [70],[71],[73]. Therefore, a supervised training framework using the proposed SSE algorithm can be used to train this network. In this case, output values are compared with the target to compute the value of the error function as stated by Eq. (3.33) in Section 3.3.5. This error then feeds back through the network. Finally, based on this information, the proposed SSE algorithm can be used to adjust weight vectors and reduce the value of MSE. The summary of the SSE algorithm for training the MLP is presented as follows: · Initialize of parameters, as has been done in the SSE filter method. · Input the vectors (matrix) data in the MLP network. · Compare the values (output from the network, Eq. 3.31) with the desired one (Eq. 3.30) and compute the correction factor given in Eq. (3.32).
92

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Estimate the gain using Eq. (3.36). · Correction factor is then fed back to the network. · Update estimate of the state using Eq. (3.35). · Update the covariance using Eq. (3.39). · MLP with weight vectors using Eq. (3.35) operates on the input to produce the actual output, and the predicted y ^(t) operates on the current desired response to produce the estimate of the weight vectors w ^ (t). · Check with the threshold values (pre-assigned) to see if it fulfills the conditions. · Stop the process if it fulfills the stop criteria, otherwise continue the next iteration.

3.3.7

Computational Complexity

Computational complexity is an important issue for the proposed Sequential Subspace Estimator (SSE) model. Starting from Eq. (3.30), the SSE's computational complexity for Jacobian evaluation is O(N 2 ). The complexity of Eq. (3.31), for estimating the desired dataset, is O(N 2 ). The computational bottleneck for computing the inverse of the updates covariance at each cycle is O(N 3 ). The complexity for updating the weight vector in Eq. (3.35) is O(N 2 ), the gain in Eq. (3.36) is O(N 3 ), and the predicted covariance in Eq. (3.37) is O(N 2 ). The computational cost for innovation covariance stated in Eq. (3.38) is O(N 2 ); the covariance update in Eq. (3.39) is O(N 2 ) and in Eq. (3.41) is O(N 3 ).
93

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.8: A Sample from Test Data (Put Face Database)

94

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.9: A Sample from Training (Put Face Database)

95

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.10: A Sample from Test Data (Indian Face Database)

96

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 3.11: A Sample from Training Data (Indian Face Database)

97

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.4

Experimental Results and Analysis

The proposed subspace sequential state estimation method is considered to be a general method for a biometric authentication system. It was tested on two public databases: the "Put Face Database" (nonlinear and heterogeneous) and the "Indian Face Database" (less hetero-nonlinear). In the experiment, we used the "Put Face Database" to create three sets of image databases: dB 1, dB 2, and dB 3; with 20, 40, and 60 subjects, respectively. As well, we used the "Indian Face Database" to create two more sets of image databases, dB 4 and dB 5, with 10 and 20 subjects respectively. The parameters used in this experiment are discussed in Section 3.3.5 and listed in Table 3.1. The data obtained from this experiment is included in Appendix - C . Each of the dB 1, dB 2, and dB 3 databases contains 10 images of each subject. Therefore, there are 200, 400, and 600 images in databases dB 1, dB 2, and dB 3, respectively. In this process, 7 out of 10 face images from each subject were used to train the system. The rest of the three subjects images were used for testing purposes. Images of different orientations and facial expressions were taken under different lighting conditions, as a function of time. Furthermore, the original size of each image in the database (3-D) is 1536 × 2048 ×3, but all the images are considered to be 8-bit 2-D images of size 256 × 256. Furthermore, each of the dB 4 and dB 5 databases contains 5 images of each subject; thus there are 50 and 100 images in databases dB 4 and dB 5, respectively. In this process, 3 out of 5 face images from each subject were used to train the system. The rest of the two subjects images were used for testing purposes. Images were taken from the same frontal position, using the same lighting conditions and background (i.e. less nonlinear and less heterogeneous). Furthermore, the original size of each image in the database was 640 × 480, but all of the images were considered to be 8-bit 2-D images of size 256 × 256.
98

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

The conversion to 256 × 256 image size was done by taking every 6th or 3rd (i.e. 1536/256=6 or 640/256=3) row and 8th or 2nd (i.e., 2048/256=8 or 480/256=2) column datapoints from the original datasets. This conversion process has already been discussed in Section 3.3.1. The size of the images from the two databases are presented in Table 3.7, and the maximum size of the training dataset was approximately 19MB. In both cases, Microsoft Access in conjunction with MatLab database design architecture was used to implement the system. Two sample datasets (test and training) from the "Put Face Database" are shown in Fig. 3.8 and Fig. 3.9, respectively; and those from the "Indian Face Database" are shown in Fig. 3.10 and Fig. 3.11, respectively. Since the proposed biometric authentication method has two parts­identification and verification­the performance evaluation of the proposed method was conducted based on these two modes.

3.4.1

Identification

The experiment for the identification process was conducted using databases dB 1, dB 2, dB 3, dB 4, and dB 5, based on the ability of the system to correctly classify an identification request. In this process, the received image was compared with all of the stored images in the database. During the comparison cycle, the Euclidean distances of the two feature vectors (biometric templates) were measured, and the smallest Euclidean distance was labeled as the closest identity of the subject. There were 200, 400, 600, 50, and 100 samples in databases dB 1, dB 2, dB 3, dB 4, and dB 5, respectively; therefore there were 200, 400, 600, 50, and 100 identification attempts. The identification process can be stated as follows: mink =  - k (3.44)

where  is the biometric template of the received live image, and k represents
99

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the stored biometric templates (images or feature vectors) in the database system. Here, k = 1, 2, .....p; where p is the total number of stored subject images or templates in the database system.

The performance of the identification process was evaluated using CRR as stated in Section 1.1.4. The experimental results rendered a percentage of CRR for each of the databases, and their averages were recorded. Comparisons of the proposed SSE method with the state-of-the-art algorithms EKF, PCA, PCA-MLE, and PCAWiener were also recorded and shown in Table 3.2, Table 3.3, and Fig. 3.12. A comparison of the proposed SSE method using L/2 (64 × 64), L (32 × 32), and 2XL (16 × 16) datasets in the image subspace has also been presented in Table 3.11. The parameters used in this experiment are discussed in Section 3.3.5 and listed in Table 3.1. The data obtained from this experiment is included in Appendix - C .

Table 3.2: Performance Evaluation in (%) - CRR Comparison (Put Face Database) Methods Proposed SSE EKF PCA PCA-Wiener PCA-MLE dB 1 96.49 96.57 67.55 74.25 72.95 dB 2 94.35 95.25 61.83 69.50 68.85 dB 3 89.67 92.25 49.95 52.25 51.80 Average 93.50 94.69 59.78 65.33 64.53

100

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Identification -Performance Evaluation
100 90 80 70

Efficiency (%)

60 50 40 30 20 10 0

SSE EKF PCA PCA-Wiener PCA-MLE 0 100 200 300 400 500 600 700

Number of Images

(a) PUT Face Database
Identification -Performance Evaluation
100 90 80 70

Efficiency (%)

60 50 40 30 20 10 0

SSE EKF PCA PCA-Wiener PCA-MLE 0 20 40 60 80 100 120

Number of Images

(b) Indian Face Database (With Less Hetero-Nonlinear Dataset)

Figure 3.12: Identification - Performance Comparison
101

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.3: Performance Evaluation in (%) - CRR Comparison (Indian Face Database) Methods Proposed SSE EKF PCA PCA-Wiener PCA-MLE dB 4 97.12 97.88 84.53 86.57 85.43 dB 5 96.25 96.91 81.93 83.77 82.95 Average 96.68 97.35 83.21 85.17 84.19

3.4.2

Verification

In the verification process, the received feature vectors that comprise the biometric template only need to be compared with the biometric template of the claimed individual. The verification of a genuine person was conducted by comparing the face image of each person with their other face images. Imposter processing was conducted by comparing the face image of one person with the face images of other persons. During the comparison cycle, the Euclidean distance was computed and compared with the threshold value to determine the legitimacy of the claimed individual. There were 60, 120, 180, 20, and 40 testing samples for databases dB 1, dB 2, dB 3, dB 4, and dB 5, respectively; therefore there were 60, 120, 180, 20, and 40 genuine matches. The verification process can be stated as follows: T rue = where  is the threshold value. The performance of the verification was evaluated using the Equal Error Rate
102

 - k < 

(3.45)

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(EER) stated in Section 1.1.4. The lower the point of EER, the higher the verification performance. The percentages of FAR and FRR and the corresponding EER points were determined and the experimental results recorded. The experimental results, based on the proposed SSE method for each of the five databases, are presented in Tables 3.4-3.6 and Table 3.10. The graphical outcomes of these results are also presented in Figs. 3.13-3.16 and Figs. 3.18-3.20. The parameters used in this experiment are discussed in Section 3.3.5 and listed in Table 3.1. The data obtained from this experiment is included in Appendix - C .
Table 3.4: Performance Evaluation in (%) - FAR and FRR Comparison (Put Face Database) Methods dB 1 FAR Proposed SSE EKF PCA PCA-Wiener PCA-MLE 1.25 1.18 11.86 7.81 8.93 FRR 2.09 4.17 9.70 8.54 9.21 dB 2 FAR 1.96 1.78 17.87 10.06 14.18 FRR 6.24 6.12 9.55 13.67 17.25 dB 3 FAR 4.86 3.70 21.09 18.74 20.08 FRR 9.87 8.96 38.86 38.79 38.75

3.4.3

Comparisons

In this experiment, two important aspects of the biometric authentication method have been addressed: the extraction of quality features from a nonlinear, nonstationary, and heterogeneous environment leading to authentication accuracy, and computational complexity (execution time). These two elements are considered to be the
103

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR (dB1)
1 0.9 0.8 SSE EKF PCA PCA-Wiener PCA-MLE

False Acceptance Rate

0.7 Surveillance zone 0.6 0.5 Top level security 0.4 0.3 0.2 0.1 0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR -dB1
ROC Curve -Performance Evaluation (dB1)
1 0.9 0.8
False Error Rate

0.7 0.6 EER 0.5 0.4 0.3 0.2 0.1 0 0 10 20 30 40 50 60 70 80 FAR FRR

SSE EKF PCA PCA-Wiener PCA-MLE

90

100

Threshold

(b) ROC -dB1
ROC Curve -Performance Evaluation
0.14 0.12 0.1 SSE EKF PCA PCA-Wiener PCA-MLE

False Error Rate

0.08 0.06 0.04 0.02 0 40 42 44 46 48 50 52 54

Threshold

(c) ROC -Zoom (dB1)

Figure 3.13: Verification - Performance Evaluation
104

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR (dB2)
1 0.9 0.8 SSE EKF PCA PCA-Wiener PCA-MLE

False Acceptance Rate

0.7 Surveillance zone 0.6 0.5 0.4 Top level security 0.3 0.2 0.1 0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR -dB2
ROC Curve -Performance Evaluation (db2)
1 0.9 0.8
False Error Rate

0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 0 10 20 30 40 50 FAR

EER

FRR

SSE EKF PCA PCA-Wiener PCA-MLE

60

70

80

90

100

Threshold

(b) ROC -dB2
ROC Curve -Performance Evaluation
0.3

0.25

False Error Rate

0.2 SSE EKF PCA PCA-Wiener PCA-MLE

0.15

0.1

0.05

45

50

55

60

65

70

Threshold

(c) ROC -Zoom (dB2)

Figure 3.14: Verification - Performance Evaluation
105

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR (dB3)
1 0.9 0.8 SSE EKF PCA PCA-Wiener PCA-MLE Surveillance zone

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 0.2 0.1 0

Top level security

0

0.2

0.4

0.6

0.8

1

False Rejection Rate

(a) FAR and FRR-dB3
ROC Curve -Performance Evaluation (dB3)
1 0.9 0.8
False Error Rate

EER

0.7 0.6 FRR 0.5 0.4 0.3 0.2 0.1 0 0 10 20 30 40 50 60 70 80 FAR SSE EKF PCA PCA-Wiener PCA-MLE

90

100

Threshold

(b) ROC -dB3
ROC Curve -Performance Evaluation

0.25 SSE EKF PCA PCA-Wiener PCA-MLE

0.2

False Error Rate

0.15

0.1

0.05

0 40 45 50 55 60 65 70 75

Threshold

(c) ROC -Zoom (dB3)

Figure 3.15: Verification - Performance Evaluation
106

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR (dB5)
1 0.9 0.8 SSE EKF PCA PCA-Wiener PCA-MLE

False Acceptance Rate

0.7 0.6 Surveillance zone 0.5 0.4 0.3 Top level security 0.2 0.1 0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR -dB5
ROC Curve -Performance Evaluation (dB5)
1 0.9 0.8 0.7

False Error Rate

FRR 0.6 0.5 EER 0.4 0.3 FAR 0.2 0.1 0 0 10 20 30 40 50 60 70 80 90 100 SSE EKF PCA PCA-Wiener PCA-MLE

Threshold

(b) ROC -dB5
ROC Curve -Performance Evaluation
0.12 0.1 0.08

False Error Rate

0.06 0.04 0.02 0 -0.02 -0.04 35

SSE EKF PCA PCA-Wiener PCA-MLE

40

45

50

55

Threshold

(c) ROC -Zoom (dB5)

Figure 3.16: Verification - Performance Evaluation (With Less Hetero-Nonlinear Dataset)
107

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.5: Performance Evaluation in (%) - EER Comparison (Put Face Database) Methods Proposed SSE EKF PCA PCA-Wiener PCA-MLE dB 1 1.87 1.81 10.82 7.22 8.79 dB 2 3.32 3.15 17.75 12.86 14.65 dB 3 6.11 5.14 27.85 24.79 25.71 Average 3.76 3.37 18.80 14.96 16.38

measurements for the acceptability of biometric authentication system implementation. The execution time to complete a total authentication transaction plays the most vital role in biometric systems within an acceptable authentication accuracy range (based on the required security level, preferably within 90%). This is because biometrics always deals with a large scale database in which huge numbers of transactions are performed. Each transaction involves data manipulation, searching, retrieval, and data transferring operations within the large system. A lower execution time is highly desirable; otherwise, the execution time can cause the system to be inappropriate for real time applications, even with a higher authentication accuracy. The data obtained from this experiment is included in Appendix - C . The parameters used in this experiment are discussed in Section 3.3.5 and listed in Table 3.1. First, the performance of the authentication process for the proposed SSE method has been evaluated using EER and CRR rates, and compared with four state-of-theart methods: PCA, PCA-Wiener, PCA-MLE, and EKF. It is apparent from the experimental results that the SSE method outperformed its counterparts, the PCA, PCA-Wiener, and PCA-MLE algorithms, and was very close to the EKF algorithm.
108

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.6: Performance Evaluation in (%) - FAR, FRR and EER Comparison (Indian Face Database -dB 5) Methods Proposed SSE EKF PCA PCA-Wiener PCA-MLE F AR 1.24 1.25 6.86 4.56 5.30 F RR 1.56 1.49 8.75 5.32 6.45 EER 1.76 1.73 8.15 4.80 5.65

Table 3.7: Databases Used for This Experiment Databases Put Face Indian Face Original Image Size (Pixels) 2048x1536 (gray) 640x480 (gray) Modified 256x256 (gray) 256x256 (gray)

Secondly, we evaluated and compared the execution time of the SSE method with PCA, PCA-Wiener, PCA-MLE, and EKF. We recorded the execution times of the identification and verification processes for each of the methods in Tables 3.8 and 3.9, respectively. The simulation results are presented in Fig. 3.17. It is apparent from the experimental results that the execution time of the proposed SSE method is 2.0 times lower than the EKF method and is very close to the PCA, PCA-Wiener, and PCA-MLE algorithms. Therefore, the performance and efficiency (execution time) of the SSE method is outstanding compared to its counterparts PCA, PCA-Wiener, and PCA-LME with a slightly higher execution time, as well as its counterpart EKF with very adjustable EER and CRR rates.
109

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.8: Average Execution Time in Seconds -Identification Authentication Proposed SSE EKF PCA PCA-Wiener PCA-MLE dB 1 44.30 89.07 42.59 43.58 43.66 dB 2 70.16 156.45 68.27 69.31 69.42 dB 3 81.24 194.78 79.19 80.20 80.33 dB 4 18.75 59.21 18.63 18.68 18.65 dB 5 23.68 72.34 23.49 23.56 23.54

Furthermore, the performance of the authentication process of the SSE method using three segmented datasets in the image subspace SSE-64×64 (i.e. L/2), SSE32×32 (i.e. L), and SSE-16×16 (i.e. L×2) (discussed in Section 3.3.1) have been presented in Figs 3.18-3.20. We also recorded the data of EER and CRR in Table 3.10 and Table 3.11, respectively. It is evident from the experimental results that the performance of the SSE method using SSE-32×32 is outstanding in comparison to the SSE method using 16×16, and is close to the SSE method using 64×64 datasets in the image subspace. We also evaluated and compared the execution time of the SSE method in the image subspace using the three segmented datasets discussed above. The simulation results are presented in Fig. 3.21, and experimental data is recorded in Table 3.12 and Table 3.13. It is apparent from the experimental results that the execution time of SSE using SSE-32×32 subspace datasets is outstanding compared to SSE-64×64, and is very close to SSE-16×16. In this experiment, facial images from two different sets of public databases, the "Put Face Database" with highly nonlinear and heterogeneous noise and the "Indian Face Database" with less nonlinear and less heterogeneous noise, have been used.
110

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.9: Average Execution Time in Seconds -Verification Authentication Proposed SSE EKF PCA PCA-Wiener PCA-MLE dB 1 7.07 15.67 6.79 6.92 6.94 dB 2 8.45 17.91 7.92 8.22 8.23 dB 3 9.38 21.53 8.81 9.06 9.10 dB 4 3.25 7.95 3.08 3.17 3.16 dB 5 4.10 10.13 3.88 4.01 3.99

The main objective when using two different sets of databases is to show that the proposed method is not only the optimal solution for the nonlinear, nonstationary, and heterogeneous environment, but is also the optimal solution for the nearly linear and nearly homogeneous environment. In this experiment, it has also been shown that the proposed SSE method is the promising alternative to the widely used optimal PCA method for the linear and homogeneous system. In summary, according to the experimental outcome and comparisons presented above and considering both the authentication performance and efficiency (execution time), the SSE subspace using 32×32 segmented datasets (i.e. SSE-32 × 32) in the image subspace is the optimal solution to ensure the quality of the biometric features while maintaining the outstanding performance and efficiency of the biometric authentication method.

3.4.4

Discussions

The experiment of the proposed system was conducted based on the combined effects of nonlinear, nonstationary, and heterogeneous noise on the extracted biometrics from
111

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Identification -Execution Time
200 180 160 140 SSE EKF PCA PCA-Wiener PCA-MLE

Time (seconds)

120 100 80 60 40 20 0

0

100

200

300

400

500

600

700

Number of Images

(a) Identification
Verification -Execution Time
25

20

Time (seconds)

15

10

SSE 5 EKF PCA PCA-Wiener PCA-MLE 0 0 100 200 300 400 500 600 700

Number of Images

(b) Verification

Figure 3.17: Efficiency Evaluation -Execution Time
112

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 0 20 40 60 EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

80

100

Threshold
(a) ROC -dB1

ROC Curve -Performance Evaluation
0.07 EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

0.06

False Error Rate

0.05

0.04

0.03

0.02

43

44

45

46

47

48

Threshold
(b) ROC (Zoom) -dB1

Figure 3.18: Performance Evaluation -Verification
113

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 0 20 40 60 80 100 EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

Threshold
(a) ROC -dB2

ROC Curve -Performance Evaluation
0.08

0.07

False Error Rate

0.06

0.05

0.04

EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

0.03

0.02 52 53 54 55 56 57 58

Threshold
(b) ROC (Zoom) -dB2

Figure 3.19: Performance Evaluation -Verification
114

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 0 20 40 60 80 100 EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

Threshold
(a) ROC -dB3

ROC Curve -Performance Evaluation
0.14

0.12

False Error Rate

0.1

0.08

0.06

EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64

0.04

0.02 50 52 54 56 58 60

Threshold
(b) ROC (Zoom) -dB3

Figure 3.20: Performance Evaluation -Verification
115

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Identification -Execution Time
200 180 160 140

Time (seconds)

120 100 80 60 40 20 0

EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64 0 100 200 300 400 500 600 700

Number of Images

(a) Identification
Verification -Execution Time
25

20

Time (seconds)

15

10

5

EKF SSE-16X16 SSE-32X32 or SSE SSE-64X64 0 100 200 300 400 500 600 700

0

Number of Images

(b) Verification

Figure 3.21: Efficiency Evaluation -Execution Time
116

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.10: Performance Evaluation in (%) - EER Comparison Methods EKF SSE -16x16 SSE -32x32 or SSE SSE -64x64 dB 1 1.81 3.16 1.87 1.85 dB 2 3.15 4.39 3.32 3.24 dB 3 5.14 7.85 6.11 5.79 Average 3.37 5.13 3.76 3.62

Table 3.11: Performance Evaluation in (%) - CRR Comparison Methods EKF SSE -16x16 SSE -32x32 or SSE SSE -64x64 dB 1 96.57 91.25 96.49 96.52 dB 2 95.25 88.59 94.35 94.81 dB 3 92.25 83.61 89.67 90.38 Average 94.69 87.82 93.50 93.89

the public database "Put Face Database". According to the simulation outcomes shown in Fig. 3.12(a) and Figs. 3.13-3.15, the proposed sequential subspace approach achieves the best authentication accuracy. The parameters used for this experiment are discussed in Section 3.3.5 and listed in Table 3.1. The data obtained from this experiment is included in Appendix - C . In the experiment, three different databases dB 1, dB 2, and dB 3 containing 20, 40, and 60 subjects, each with 10 images, were used. The identification performance was analyzed based on the CRR. The efficiency versus databases (no. of samples) graph is shown in Fig. 3.12(a). The average execution time of the identification process for
117

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 3.12: Average Execution Time in Seconds -Identification Authentication EKF SSE -16x16 SSE -32x32 or SSE SSE -64x64 dB 1 89.07 43.89 44.30 62.53 dB 2 156.45 69.48 70.16 87.45 dB 3 194.78 80.55 81.24 98.78 dB 4 59.21 18.70 18.75 26.27 dB 5 72.34 23.61 23.68 38.14

Table 3.13: Average Execution Time in Seconds -Verification Authentication EKF SSE -16x16 SSE -32x32 or SSE SSE -64x64 dB 1 15.67 6.98 7.07 10.15 dB 2 17.91 8.31 8.45 11.42 dB 3 21.53 9.15 9.38 13.27 dB 4 7.95 3.22 3.25 4.69 dB 5 10.13 4.05 4.10 6.85

dB 3 using MatLab 2008 and Microsoft Access on a i5-2.4GHz CPU with 8 GB RAM was 81.24 sec, which is almost 2.5 times lower than the EKF. The average execution times for each database and method are presented in Table 3.8, Table 3.9, Table 3.12, and Table 3.13. The results displayed in Table 3.2 and Fig. 3.12(a) show that the proposed subspace method (identification) outperforms its counterparts PCA, PCA-Wiener, and PCA-MLE estimator, and is very close to the EKF. As well, experimental results of the verification process were recorded and presented in Table 3.4, Table 3.5, Table 3.10, Figs. 13-15, and Figs. 18-20. The receiver operating curves (ROC) of the proposed method, based on the three databases dB 1,
118

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

dB 2, and dB 3, are presented in Figs. 3.13-3.15 and Figs. 18-20. These ROC curves measure the performance of the verification system, and are plotted as a function of threshold values. FAR and FRR presented in the ROC curve characterize the verification accuracy, and the point EER represents the performance of the verification system. The average execution time for the verification process using dB 3 was 9.38 sec, which is almost 2.5 times lower than the EKF. More importantly, the performance of the proposed method was analyzed and compared with four state-of-the-art algorithms, namely: EKF, PCA, PCA-Wiener, and PCA-MLE. Experimental results show that the proposed SSE method outperforms the PCA, PCA-Wiener, and PCAMLE algorithms, and is very close to the EKF algorithm with a promising EER of 1.87% and an average EER of 3.76%. Furthermore, the experiment of the proposed model was also conducted using less hetero-nonlinear images from the public database "Indian Face Database". In the experiment, the two different databases dB 4 and dB 5, containing 10 and 20 subjects with 5 images each, were used. According to the simulation outcomes shown in Fig. 12(b) and Fig. 3.16, the proposed sequential subspace approach achieves the best authentication (verification and identification) accuracy. The experimental results of the identification and verification were recorded and presented in Table 3.3 and Table 3.6, respectively. It is also apparent from the outcomes of the experiment that the proposed SSE method outperforms its counterparts, the PCA, PCA-Wiener, and PCA-MLE methods, and is very close to EKF. However, significant improvement in the performance of the PCA, PCA-Wiener, and PCA-MLE algorithms was observed. In this study, three subspace datasets­16 × 16, 32 × 32, and 64 × 64­have also been used to evaluate, analyze, and compare the performance and efficiency of the SSE proposed method. However, other forms of segmented datasets can also be used in this experimental evaluation and analysis. The experimental outcomes for the authentication and efficiency (execution time) have been presented in Figs. 3.18-3.21,
119

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

and their data has also been recorded in Tables 3.10-3.13. Considering the results of both the authentication performance and the execution time, it is apparent from the experimental results that the proposed SSE method using 32×32 segmented datasets has shown outstanding performance and efficiency in comparison to the segmented datasets 16×16 and 64×64.

The execution times of the identification and verification for each method have been estimated and recorded in Table 3.8, Table 3.9, Table 3.12, and Table 3.13. Simulation results of these execution times have also been presented in Fig. 3.17 and Fig. 3.21. It is apparent that the efficiency of the proposed method is outstanding in comparison to EKF and is very close to the PCA, PCA-Wiener, and PCA-MLE methods.

The slight deviation in performance of the proposed SSE from EKF and the slight deviation of efficiency (execution time) from PCA, PCA-Wiener and PCA-MLE are due to the use of the subspace technique. In the proposed SSE method, the features segmentation, estimation, and reconstruction processes have been performed in the image subspace. According to the results, these deviations are negligible for small sized databases and are within the acceptable range for large databases. In this experiment, we also found that the performance of the proposed SSE method is outstanding compared to the optimal PCA algorithm in a linear and homogeneous environment (i.e. "Indian Face Database"). The subspace technique allows the system to simplify the dimensional complexity, and it was found that the efficiency (i.e. lower execution time) of the proposed method was almost 2.5 times higher than the EKF method.
120

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

3.5

Conclusions

The properties of biometrics are always dynamic in nature. There are many situations where the quantities and properties of useful information in the extracted biometric features are not fixed during processing. This dynamic data structure also leads to the fact that the characteristics of the extracted features are highly influenced by the surrounding environment and are a function of time. The efficiency and accuracy of biometric authentication systems are also dependent on the quality of the extracted features, their consistency, and their mutual relationship. In this situation, linear, stationary, and homogeneous assumptions are insufficient to produce good results. Typically, LDA, MLE, Bayesian, LMS, and Wiener are inadequate methods to cater to the nonlinear, nonstationary, and heterogeneous noise environment. The integration of PCA with these methods allows the biometric authentication system to overcome the challenges associated with nonlinear and heterogeneous noise. Another promising alternative, the sequential estimator, also has the capability of adapting to the diverse nature of noise; however it is computationally inefficient, as it needs to perform extensive matrix operations. In this chapter, a new recursive sequential subspace method is being developed. The proposed method addresses the challenges of the extracted biometrics due to nonlinear, nonstationary, and heterogeneous noise (i.e. noise covariance matrix). It also overcomes the computational burden associated with sequential estimation. This is a recursive method, so the extracted data and its associated noise update in every iteration using the biometric features (dataset) from the immediate past state. SSE design is based on the minimization of noise and maximization of information content in the received data, in MSE sense. Thus, the method would be able to make a close approximation of the desired data model, which would otherwise be contaminated by nonlinear, nonstationary, and heterogeneous noise. After mitigation
121

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

of the noise level, the dataset is normalized in the image subspace; then the normalized datasets concatenate to reconstruct the biometric template. This method is being tested on facial images from two public databases: the hetero-nonlinear "Put Face Database" and the less hetero-nonlinear "Indian Face Database". In this study, the experiment of the proposed method has also been performed in the image subspace using three segmented datasets. Considering both the performance (authentication) and the efficiency (execution time), it is apparent that the SSE-32 × 32 method demonstrates superiority in comparison to the SSE-16 × 16 and SSE-64 × 64 methods. Finally, the performance and efficiency of the identification process is analyzed and compared using the percentage of the Correct Recognition Rate (CRR). The performance and efficiency of the verification process is also analyzed and compared using the percentage of the Equal Error Rate (EER). More importantly, the performance and efficiency of the proposed model is compared to the four state-of-the-art algorithms, namely: EKF, PCA, PCA-MLE, and PCA-Wiener. It is found that the performance and efficiency of the proposed method outperforms its counterparts.

122

Chapter 4

MultiBiometrics Encryption and its Management System
4.1 Introduction

Biometrics is a rapidly growing branch of information technology that automatically authenticates an individual based on two basic properties of human biometric features: distinctiveness and permanence. The effectiveness and strength of the biometric authentication and cryptography (or encryption) systems are dependent on the extent to which they can hold these two properties. As a result, fingerprint, face, iris, hand geometry, and gait have been used as primary biometric traits, since soft or auxiliary biometric characteristics including age, weight, height, and race lack distinctiveness and permanence [104-113]. A limited number of biometric traits possess sensitive human information that is also unique and cannot be revoked or reissued once compromised. Furthermore, the features extracted from the biometric traits are stored in the database during enrollment in order to compare (match) and authenticate the legitimacy of the subject of interest. Typically, this comparison performs in the unencrypted domain, since
123

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the authentication accuracy can be largely influenced by a small variation in the feature properties if it takes place in the encrypted domain. More importantly, after biometric data acquisition, the method of biometric data manipulation and representation techniques is almost the same as any other traditional data management system. Therefore, concerns about the security and privacy of biometric features (templates), and their data management architecture are of paramount importance in the exploration of biometric systems. Ideally, the security and privacy of the template is accomplished based on mathematical algorithms which must be difficult to decrypt by the unintended recipients. In addition, a template protection algorithm should be irreversible, robust, and revokable [112-114]. In this chapter, a novel MultiBiometrics encryption algorithm is proposed that protects the stored and dynamic biometric templates against security, privacy, and unlinkability attacks. Unlike current biometric encryption, the proposed method uses cryptographic keys in conjunction with extracted MultiBiometrics to create cryptographic bonds, called "BioCryptoBond". Importantly, to further enhance the security and privacy protection during the comparison process and to improve authentication accuracy, a multilayered Biometrics Data Management System (BDMS) is also proposed. The theoretical foundation of the proposed method along with the model evaluation and experimental results have also been presented in this chapter. The performance of the method is being analyzed based on the FAR, FRR, EER, and CRR. In the method proposed in this chapter, the cryptographic system is designed to deal with two categories of people: user and subject. In this case, user and subject biometric templates are considered to be stored in the local and central databases, respectively. Multiple 32-bit digital cryptographic keys are generated and securely bond with the MultiBiometrics (i.e. face and fingerprint) features, creating cryptographic data blocks known as BioCryptoBonds. Neither the biometric features nor
124

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the secret keys can be retrieved from these BioCryptoBonds without a successful user authentication in the presence of the subject. In this case, the facial area; facial biometrics such as the size and the relative positions of the eyes and lips; and fingerprint biometrics features such as ridge patterns, minutiae points, and code points, are considered for biometric template generation. The motivation for the proposed MultiBiometrics encryption method is the protection of stored and dynamic biometric information from security, privacy, and unlinkability attacks, using multilayered encryption and its management system. The method will also address the diversity, revocability, and performance of the system. In this cryptographic model, successful user authentication in the presence of the subject will be required in order to access subject databases. The remainder of the chapter is organized as follows. Section 4.2 studies the features extraction process and its associated challenges. The detailed analysis and algorithmic formulation of the proposed biometric encryption, enrollment, and authentication systems are presented in Section 4.3. Section 4.4 presents the Biometrics Data Management System (BDMS). Section 4.5 studies the performance evaluation of the proposed method. Experimental results and discussions are given in Section 4.6. Finally, the conclusions are presented in Section 4.7.

4.2

Filter Design

Biometrics, especially fingerprint and facial features, are always contaminated by noise; including misalignments, position orientation, illumination, and environmental noise. Thus, there are some dissimilarities between the received biometric features and the desired one [5],[115]. In this section, a mathematical formulation of the proposed filtering or estimation method for minimizing these dissimilarities has been
125

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

discussed. The main objective is to extract quality biometric features for the biometric enrollment and authentication process. More importantly, this method would optimize to produce consistent output from biometric features, tolerate position orientation and illumination effects on facial biometric features as well as misalignment effects on fingerprint features, and produce a lower Equal Error Rate (EER). Now, consider that the facial or fingerprint images (dataset) have been received as vectors of matrix ­x. Each row and column of the received dataset ­x represents an observation and a particular type of datum, respectively. If the received dataset is contaminated by noise, then the received images can be written as: x=s+n where n is the noise matrix, and s is the noise-free or desired dataset. Principal components can be derived from the x dataset, and these derived components can be written as [93]: z = wT x Therefore using Eq. (4.1): z = wT s + wT n (4.2) (4.1)

where w represents weight vectors which map to each row vector of x, z is considered to be inherited (data) with maximum possible variance from the x dataset, and each of the weight vectors w is constrained to be a unit vector [91],[93]. So, the main objective is to minimize the noise n and estimate the image of interest. In addition, the features of interest are extracted in order to create and compare biometric templates. The Sequential Subspace Estimator (SSE) has been used to minimize the dissimilarities between the received images and the desired one
126

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[91],[93],[100]. Furthermore, the SSE method has also been used to extract and compare the biometric templates in order to authenticate the legitimacy of an individual. In this case, noise associated with the extracted features is considered to be nonstationary, nonlinear, and heterogeneous due to misalignments, position orientation, illumination, background, and environmental noise. The detailed analysis, algorithmic formulation, and operational principle of the Sequential State Estimator method have already been discussed in Chapter 3.

4.3

MultiBiometrics Encryption and Enrollment

The biometric templates created from the images received at the output of the filter studied in Section 4.2 are the desired templates. These templates will be stored (enrollment) in the databases for the authentication process. The security and confidentiality of the stored and dynamic biometric features are dependent on the protection of the filtered biometrics against security, privacy, and unlinkability attacks. Therefore, the objective of the proposed encryption method is to develop a secure, robust, and reliable encryption algorithm to protect these templates. Now consider that h(t) represents the filtered biometric templates used in the biometric enrollment and authentication process in the time domain. So, the objective of the encryption method presented in this chapter is to protect the template ­h(t) against security, privacy, and unlinkability attacks. In contrast to current biometric encryption systems, the proposed method generates a 32-bit digital secret key and creates a cryptographic data block, BioCryptoBond. The secret key, and facial or (and) fingerprint biometric features (i.e. h(t)), are monotonically bonded in order to create this MultiBiometrics cryptographic bond. The goal is to protect the stored or dynamic biometric features and key in such a way that neither the biometric features nor the secret key can be retrieved without a successful authentication process. The
127

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

method of creating a MultiBiometrics template using the fusion of facial and fingerprint features is stated below. Afterwards, the detailed analysis and formulation of the Encryption and enrollment method are discussed.

4.3.1

MultiBiometrics Template

In this experiment, fingerprint and facial biometrics have been used to create MultiBiometric templates. The facial images from the public "Put Face Database" and "Indian Face Database" have been extracted and fused with fingerprint images taken from the public "CASIA Fingerprint Version 5" database. These three databases contain images of different individuals. There is no relationship between individuals in the fingerprint database and those in the facial database; individuals in one database are not in the other. Therefore, for the formation of each MultiBiometrics template, a set of fingerprint images from a particular individual in the fingerprint database has been assigned to a particular individual from the facial database. A set of facial images of an individual and the corresponding assigned set of fingerprint images are shown in Fig. 4.1. A detailed analysis, complete algorithmic formulation, implementation of the proposed cryptographic bond BioCryptoBond, and the enrollment method have been studied in the following subsections.

4.3.2

BioCryptoBond

The cryptographic architecture of this method is being designed to deal with two categories of people: the authorized user and the subject (target). The user cryptographic bond, BioCryptoBondu , is being created based on user fingerprint biometrics (i.e. minutiae points, code point, and orientation angle (Fig. 4.3)) in conjunction with the digital secret key. Conversely, three subject cryptographic bonds­BioCryptoBondF ,
128

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) PUT Face Database

(b) CASIA Fingerprint Version 5.o

Figure 4.1: A Set of MultiBiometrics Template

BioCryptoBondF P , and BioCryptoBondF F ­are being created using facial, fingerprint, and the fusion of facial and fingerprint biometrics, respectively. The three subject cryptographic bonds are being created here with the objective of providing multilayered security protection for the subject's biometric features. The detailed analysis, implementation, and execution of this multilayered security protection system is presented in Chapter 5. A detailed system diagram and processing method for generating user and subject BioCryptoBond bonds based on facial, fingerprint, and the fusion of facial and fingerprint (i.e. MultiBiometrics) biometrics is presented in Fig. 4.2. Furthermore, in the proposed method, tensor and orthogonal operations are implemented on biometric features and digital secret keys at different stages. The algorithmic architecture and formulation for creating four cryptographic bonds have been stated below.
129

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.2: System Architecture -BioCryptoBond

130

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

4.3.2.1

BioCryptoBondu

The steps involved in creating the user cryptographic bond BioCryptoBondu , are stated below: (i) Extract and compute orientation angle () (Fig. 4.3) from received user fingerprint features [7],[8],[108],[110], [115]. (ii) The tensor operation is performed on the user filtered fingerprint biometric template h(t) (minutiae points) as a function of orientation angle. (iii) Output from the tensor operation is converted into an orthogonal matrix . (iv ) A digital random key K u for the user is generated (Fig. 4.2) and fused with an orthogonal matrix of vectors , creating the user cryptographic bond, BioCryptoBondu . This cryptographic bond binding process can be formulated as follows: T =  × (s)  = Tor BioCryptoBondu =  × K u (4.3)

where T is the output from the tensor operation; the subscript or is the orthogonal operator; and (s) is the fourier transform of h(t).

4.3.2.2

BioCryptoBondF P

The steps that are involved in creating the subject cryptographic bond BioCryptoBondF P using h(t) fingerprint features (minutiae points (Figs. 4.1 and 4.2)) are stated below. (i) Randomly generated key K s is transformed into the orthogonal matrix f p . (ii) Matrix f p is fused with the filtered fingerprint output h(t), creating the cryptographic bond BioCryptoBondF P .
131

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

This bond binding process can be formulated as follows:
s f p = Kor

BioCryptoBondF P = f p × (s)

(4.4)

4.3.2.3

BioCryptoBondF

The steps that are involved in creating the subject cryptographic bond BioCryptoBondF using subject facial biometrics (i.e. facial area, size and relative positions of eyes and lips (Figs. 4.2 and 4.4)) are stated below: (i) An arbitrary interface pointer  is received. This interface pointer is generated by the system upon successful user authentication. (ii) Tensor operation is performed as a function of  on received filtered facial biometrics h(t). (iii) Output of tensor operation is converted into the orthogonal matrix f . (iv ) Matrix f is fused with the same randomly generated digital key K s used to create the subject's BioCryptoBondF bond. This bond binding process can be formulated as follows: T =  × (s) f = Tor BioCryptoBondF = f × K s (4.5)

132

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering



(a) Original Image

(b) Ridge Orientation

Core point (185, 178)

50

100

150

200

250

300 50 100 150 200 250 300

(c) Core Point

(d) Minutiae Points

Figure 4.3: Fingerprint Biometrics ­Features Extraction

133

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(a) Put Face Database

(b) Indian Face Database

Figure 4.4: Facial Biometrics -Feature Extractions

134

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

4.3.2.4

BioCryptoBondF F

The steps that are involved in creating the subject cryptographic bond BioCryptoBondF F using MultiBiometrics (the fusion of facial and fingerprint biometrics) are stated below: (i) Subject filtered fingerprint and facial biometrics are concatenated (or fused), and a MultiBiometrics template is created. (ii) Concatenated matrix or MultiBiometrics is converted to orthogonal matrix f f . (iii) Orthogonal matrix is fused with a randomly generated digital secret key K s (Fig. 4.2), and a BioCryptoBondF F bond is created. This bond binding process can be formulated as follows: c(t) = c[h1 (t) + h2 (t)] C(s) = (c(t)) f f = Cor (s) BioCryptoBondF F = f f × K s
 

(4.6)

where h1 (t) and h2 (t) represent filtered outputs for fingerprint and facial biometrics, respectively; c(t) represents the concatenate operation; C(s) represents the fourier transformation of the concatenate operation.

4.3.3

Enrollment

The next stage of the proposed biometric cryptographic method is the enrollment process. The common steps involved during the user and subject enrollment process are stated below: (i) Digital secret key is fused with BioCryptoBond.
135

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

(ii) Outcome is hashed with primary biometric features and generates 16-bit reference pointer [see Appendix - B ]. The enrollment process can be formulated as follows: R = H[(BioCryptoBond × Sk )(Ip )] (4.7)

where H, R, and Ip are the hash function, reference pointer transformation, and primary biometric features, respectively. Sk represents the digital key.

4.3.3.1

User

The system architecture of the user enrollment process is depicted in Fig. 4.5 and the steps involved in the user enrollment process are stated below: (i) User template is processed and verified with the stored template in User Database (dBu ) using reference pointers given in Eq. (4.7). (ii) Upon activation of the positive verification signal (if user not enrolled), reference pointers along with the biometric template and description of the user are stored in respective user databases Encryptionu and User Database (dBu ), as shown in Fig. 4.5.

4.3.3.2

Subject or Target

The subject enrollment process includes additional steps, which are executed after generating the reference pointers stated in Eq. (4.7). The main objective of these additional steps is to provide multilayered security protection for subject biometric templates. The system architecture of the subject enrollment process is presented in Fig. 4.6, and additional steps are stated below: (i) Outputs of reference pointers are hashed and fused with a 32-bit composite foreign key to create a link function termed a Hot-Key function (hk ). This function
136

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.5: User Enrollment Process

137

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.6: Subject Enrollment Process

138

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

is required to develop a map for the proposed biometrics information infrastructure [see Section 4.4 and Appendix - B ]. (ii) Biometric template is verified with the stored template at Subject Database (dBs ) using the Hot-Key function (Fig. 4.6 and Fig. 4.8). (iii) Upon activation of a positive verification signal (if subject not enrolled), a reference table is created (link list); the intra data segmentation technique has been developed as shown in Fig. 4.6 and Figs. 4.9. The segmentation process can be formulated as follows: hk = H[F × Rs ]  = Rs × hk × (s) (4.8)

where F and Rs are the foreign key and reference pointer, respectively, and  represents segmented data. (iv) Hot-Key function in conjunction with the reference table and data segmentation process develops a Biometric Data Management System (BDMS) [Section 4.4]. (v) Finally, the biometric template and description of subject are stored (enrolled) in respective subject databases EncryptionF , EncryptionF P , EncryptionF F , and dBs as shown in Figs. 4.5 and 4.8.

4.3.4

Authentication

In the case of the user authentication process, fingerprint biometric features received from the authorized user are combined with the cryptographic bond, BioCryptoBondu , and the digital secret key is released. In this stage, authentication is performed to ensure the legitimacy of the user and to release the user secret key K u . The user authentication process is shown in Fig. 4.7. During the user authentication cycle, the same algorithmic operation stated in
139

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.7: User Authentication Process

140

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Eq. (4.3) is performed on the live user fingerprint features, generating the matrix . Afterwards,  is combined with the previously stored BioCryptoBondu to release the key K u . This process can be stated as follows: T =  × (s)  = Tor K u =  × BioCryptoBondu (4.9)

Once the secret key is activated and released, it is hashed with the user biometric features and generates the reference pointers required to complete the final level of authenticity of the user. This reference pointer along with the secret key then allows the user to access the system. This process can be formulated as follows: Ru = H[K u × Ip ] Required Info = Ru [dBu ] where Ru is the user reference pointer. (4.10)

Finally, a triggering signal is processed to initialize an interface between user and subject, if the user authenticity is found positive. This interface allows the user to prepare a system platform for receiving subject biometric features as an input. Furthermore, the system also releases an interface pointer  , which is required to ensure that the system is ready to enroll, authenticate, and release subject information in the presence of the legitimate user and the subject of interest. The analysis, implementation, and execution process of the subject authentication system and its features protection method are presented in Chapter 5.
141

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

4.4

Biometrics Data Management System

The main objective of the Biometrics Data management System is to enhance the protection of the stored and dynamic biometric features against security, privacy, and unlinkability attacks. In this case, a multilayered and MultiBiometrics data management system has been proposed to protect the users and the subjects' biometric features. The cryptographic bonding architecture and its process have already been presented in previous subsections. The hash function, Hot-Key, and segmentation processes are integral parts of this management system, and are presented in the following subsections.

4.4.1

Hot-Key Function

The Hot-Key function is the compound function key generated from a combination of the reference pointer and foreign key [see Appendix - B ]. The foreign key (F) given in Section 2.3.7 is a 32-bit digital key generated from the primary indexed biometric features. The first step of this process is to create a reference pointer for the users (or subject) from the system generated 32 - bit digital key hashed with the primary features of the user (or subject) biometrics. This reference pointer is used to store the encrypted user biometrics features (enrollment) in the user databases, as shown in Fig. 4.5. In this case, the user biographical information is stored in the user database dBu (user database) and the encrypted biometric features are stored in the Encryptionu database. This reference pointer is used to establish a relationship between user databases. In the case of a subject database, the reference key is generated in the same way as the user. Afterwards, this reference key is hashed with the indexed foreign key generated from the subject biometric features as shown in Fig. 4.6. The output of this
142

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

hash function is called the Hot-Key (hk ) function, and its main objective is to create an extra-layer (multilayered) of security for the stored and dynamic biometric features of the subject. Furthermore, the subject's biographical information and biometric features are stored in the subject databases (dBs (subject database), EncryptionF , EncryptionF P , and EncryptionF F ) and the generated reference pointers (i.e. key or function) are used to create a link between the subject databases through the reference table and data segmentation process. The system architecture of this methodology is presented in Fig. 4.8. The theoretical aspects of the hash key, foreign key, and Hot-Key functions are stated in Appendix - B .

4.4.2

Segmentation Process

The main purpose of the segmentation (stated in Section 2.3.7) process is to cluster (or group) the subject biometric features and biographical information based on the address pointers created as shown in Fig. 4.8. This clustering process is done using the index biometric features of face, fingerprint, and MultiBiometrics (fusion of face and fingerprint). In this process, a hash key function in conjunction with the composite key and reference pointer are implemented to construct the Hot-Key algorithm. In addition, the data segmentation technique along with the Hot-Key algorithm are employed in order to develop a secure Biometrics Data Management System (BDMS ). A reference table is created which is basically a link list (or address pointer) to keep the reference addresses and to locate the records stored in the subject databases. Furthermore, the relationship between subject databases is also maintained by the reference table (along with the segmentation process) as stated in Fig. 4.6. The system architecture of this segmentation process is also presented in Fig. 4.9 [see Appendix - B ].
143

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.8: Key Generation Process

144

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 4.9: Segmentation Process

145

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

4.5

Evaluation

For example, if the same filter output (s) is generated by an authorized user and an imposter, then the two authentication processes can be shown using Eqs.(4.3), (4.9) and (4.10): Authorized user a (s) == r (s) and a  r r = T[rr × r ] = a r = [r ]or  a K u = r × BioCryptoBondu Ru = H[K u ] = Authentication Successful Imposter

a (s) == r (s) and a = r r = T[rr × r ] = a r = [r ]or = a K u = r × BioCryptoBondu = Authentication Failed where the subscripts a and r represent actual and received values, respectively; and other parameters carry the same meaning as given in Eqs.(4.3), (4.9) and (4.10). The biometric database is protected by the multilayered encryption method. The biometric information is segmented, and reference pointers are used to establish a link between the segmented biometrics. In this method, it isn't possible to obtain the original biometrics from these reference pointers and vice versa. As well, it isn't possible
146

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

to know the individual's identity or construct (or guess) original biometric features of an individual from the segmented biometrics stored in the databases. Database is segmented and information is transformed, so complete authorized processing is required in order to access the biometrics and biographic information. Therefore, this system is invincible to unlinkable attacks, and imposters cannot retrieve data based on information found in other parts of the system. Computational Complexity Computational complexity starts from Eq. (4.1), which is required O (N ), and both Eq. (4.2) and Eq. (4.3), which are required O (N 2 ). The computational complexities from Eq. (4.4) to Eq. (4.10) are O (N 3 ).

4.6

Experimental Results and Analysis

In this experiment, two types of authentication processes have been performed: i) user authentication, and ii) authentication and retrieval of the subject's information. The experimental results and resultant analysis presented here are based on these two processes. The data obtained from this experiment is included in Appendix - C . 4.6.1 User Authentication

In this experiment, two user encrypted databases were created for 30 users, then 10 users with fingerprint biometrics from the public database  CASIA Fingerprint Image Database Version 5.1". The encrypted database set containing 30 users has been used for authorized user fingerprints, and the encrypted database set containing 10 users has been used for imposter fingerprints. The main objective of this process is to authenticate the legitimacy of a user. An evaluation of the verification performance of the encryption method is also presented in this chapter. In this case, each of the 40
147

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

users has been tested against the encrypted users' biometrics stored in the databases. The performance of the verification process has been evaluated based on the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Equal Error Rate (EER). The experimental results of this verification process have been recorded in Table 4.1, and the graphical outcome of the FAR, FRR, and ROC are presented in Fig. 4.10.
Table 4.1: Performance Evaluation in (%) - FAR, FRR, and EER (User Fingerprint Biometrics) Database User -CASIA Fingerprint F AR 1.20 F RR 3.50 EER 2.40

4.6.2

Authentication and Retrieval of the Subject's Information

The performance of the proposed Biometric Encryption (BE) method has been evaluated based on the images of the public databases: "Put Face Database" [75], "Indian Face Database" [76], and "CASIA Fingerprint Image Database Version 5.1". The experimental results presented here are based on the authorized users' authentication processes using fingerprint biometric features in the presence of the respective subjects. In this experiment, two sets of encrypted user databases and four sets of encrypted subject databases have been created from the original image databases. The user databases were created for 20, then 10 users with fingerprint biometrics from the fingerprint images. In this case, the set containing 20 users has been used for imposter fingerprints and the set containing 10 users has been used for authorized user fingerprints. These encrypted user databases were created from the fingerprint images from the public database: "CASIA Fingerprint Image Database Version 5.1". Two of the four encrypted databases contain facial biometrics of 20 and 40 subjects, respectively. These databases were created from the facial images of the public
148

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 To Level Security

Surveillance Zone

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 FAR FRR EER 2.4%

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 4.10: User Fingerprint Biometrics -Verification Process
149

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

database: "Put Face Database". The other two sets contain facial biometrics of 10 and 20 subjects, respectively, created from the facial images of the public database: "Indian Face Database". Each subject's biometrics along with their biographies have been stored in their respective databases as stated in the above sections. In this experiment, the retrieval of the subject's information from their databases has been attempted by legitimate and illegitimate users, with and without the presence of the subject. The retrieval by each legitimate user has been conducted by comparing the encrypted fingerprint biometrics of each user with another fingerprint biometric of the same user, with and without the presence of the subject. Imposter processing has been conducted by comparing the encrypted fingerprint biometrics of one user with the encrypted biometrics of the other users. The percentages of Correct Recognition Rate (CRR), False Acceptance Rate (FAR), False Rejection Rate (FRR), and Equal Error Rate (EER) have been determined, and experimental results have been recorded. The experimental results of this authentication process have been recorded in Table 4.2 and Table 4.3. Simulation results from the legitimate (and illegitimate) user verification process to retrieve the subject biometrics in the presence (and without the presence) of the respective subjects are shown in Figs. 4.11 - 4.14. As well, the performance of the identification process has been shown in Fig. 4.15, and this result has been recorded in Table 4.4 and Table 4.5.

Table 4.2: Performance Evaluation in (%) - FAR, FRR, and EER (Put Face Database) No. of Subjects 20 Subjects 40 Subjects F AR 1.45 1.75 F RR 8.50 9.30 EER 4.70 5.10

150

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 Surveillance Zone 0.5 0.4 0.3 Top Level Security 0.2 0.1 0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 EER 4.7% 0.3 0.2 0.1 0 FAR FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 4.11: MultiBiometrics Encryption ­Put Face Database(20 subjects)
151

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 Surveillance Zone 0.6 0.5 0.4 0.3 0.2 0.1 0 Top Level Security

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 EER 5.1% FAR FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 4.12: MultiBiometrics Encryption ­Put Face Database(40 subjects)
152

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 Top Level Security 0.2 0.1 0 Surveillanec Zone

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR

ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0

FAR FRR

EER 3.1%

0

10

20

30

40

50

60

70

80

90

100

Threshold
(b) ROC Curve

Figure 4.13: MultiBiometrics Encryption ­Indian Face Database (10 subjects)
153

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 Surveillance Zone 0.4 0.3 Top Level Security 0.2 0.1 0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 EER 3.45% 0.4 0.3 0.2 0.1 0 FAR FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 4.14: MultiBiometrics Encryption ­Indian Face Database (20 subjects)
154

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Identification -Performance Evaluation
100 90 80 70

Efficiency (%)

60 50 40 30 20 10 0

0

5

10

15

20

25

30

Number of Images

(a) CRR -Indian Face Database
Identification -Performance Evaluation
100 90 80 70

Efficiency (%)

60 50 40 30 20 10 0

0

5

10

15

20

25

30

35

40

45

50

Number of Images

(b) CRR -Put Face Database

Figure 4.15: MultiBiometrics Encryption -Identification Process
155

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 4.3: Performance Evaluation in (%) - FAR, FRR, and EER (Indian Face Database) No. of Subjects 10 Subjects 20 Subjects F AR 1.50 1.86 F RR 4.60 5.40 EER 3.10 3.45

Table 4.4: Performance Evaluation in (%) - CRR (Put Face Database) Database Put Face 20-Subject 91.68 40-Subject 88.35 Average 90.02

4.6.3

Analysis and Discussions

The experiment for the encryption method presented in this chapter has been performed based on the encrypted user fingerprints and subject facial biometrics. The experimental results for this authentication process are recorded in Tables 4.1 - 4.5, and simulation results for this experiment are shown in Figs. 4.10 - 4.15. First, the experiment for this method has been conducted for the encrypted user fingerprint biometric databases. Fingerprint images from the public fingerprint database "CASIA Fingerprint Image Database Version 5.1" were used to create two encrypted user databases with 30 and 10 users, respectively. The performance of the verification process for this encryption method with fingerprint biometrics has been analyzed and evaluated. In this case, there were 30 legitimate user records, and therefore there were 30 genuine matches. An EER of 2.4% has been achieved, and a FAR of 1.2% at the cost of FRR 3.5% has been achieved using this proposed method. Afterwards, user encrypted biometrics databases with 10 and 20 users were created using fingerprint images of the public fingerprint database "CASIA Fingerprint
156

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 4.5: Performance Evaluation in (%) - CRR (Indian Face Database) Database Indian Face 10-Subject 96.20 20-Subject 95.55 Average 95.87

Image Database Version 5.1". The encrypted database set with 10 users contained authorized users, and the set with 20 users contained imposters. As well, two subject encrypted facial database sets, each of 10 and 20 subjects, have been created using the public facial image database "Indian Face Database". Two more subject encrypted facial database sets, each of 20 and 40 subjects, have also been created using the public facial image database "Put Face Database". The Receiver Operating Curve (ROC) of the proposed method, based on the legitimate (and illegitimate) user authentication in order to retrieve the subject biometrics in the presence (and without the presence) of the subject, has been presented in Figs. 4.11 - 4.14. This ROC curve measures the performance of the verification system, and has been plotted as a function of threshold values. FAR and FRR presented in the ROC curve characterize the verification accuracy, and the point EER represents the performance of the encryption method. Experimental results for the verification process have been recorded in Table 4.2 and Table 4.3. In this experiment, an EER of 3.1% and FAR of 1.5% at the cost of 4.6% FRR have been achieved. In addition, the performance of the identification process has also been analyzed using CRR. The results are recorded in Table 4.4 and Table 4.5. The simulation result is shown in Fig. 4.15. It was found that a CRR of 95.87% has been achieved using the proposed encryption method.
157

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

4.7

Conclusions

A biometrics system contains attributes that exclusively represent an individual's identity. These properties don't change and are difficult to lose or fake. Therefore, the main concern for the exploration of the biometric system is to protect the security and privacy of these biometric features. This cannot be neglected otherwise it can revert the overall process in the opposite direction, since the damage to this system is irreversible and may cost more than the system it is used for. In this chapter, a MultiBiometrics encryption and management system have been presented that protect biometric features against security, privacy, and unlinkability attacks. In this encryption method, secure cryptographic bonds have been created to protect not only the stored biometric features but also the dynamic biometrics, as the comparison during the authentication process is performed in the unencrypted domain. In addition, to further enhance the authentication accuracy and to protect the biometric features, a Biometrics Data Management System has been developed. The main objective of this data management system is to protect the biometrics from unlinkability attacks. In this method, the encrypted biometrics are segmented before being stored in the biometric databases. The relationship between the segmented biometrics and their databases is maintained by the reference pointers, which contain the addresses of the location where the biometric features will be stored. It isn't possible to retrieve the biometrics and the identity of an individual from these reference pointers. This is a clustered operation and every point of the operation has to be performed successfully to establish a link between all of the reference pointers necessary to retrieve the biometric and biographic features. Furthermore, the proposed MultiBiometrics BioCryptoBond is secure and efficient, since a 1.5% FAR has been achieved at the cost of 4.6% FRR. According to the experimental results, the proposed method is also found to be robust with a promising
158

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

EER of 3.1%. As well, this method provides multilayered protection against security, privacy, and unlinkability attacks for the dynamic and stored biometric features in the databases. It can also be concluded that the encryption method presented in this chapter is heuristic, robust, and reliable in comparison to its counterparts. This is because, unlike other key binding encryption systems, the biometric data management architecture is implemented to enhance security protection and improve authentication accuracy. Without a successful authentication process, neither the secret key nor the biometric features can be retrieved independently from the cryptographic bond. In addition, even if the secret key or the transformed biometric features are intercepted at any point of operation by the imposter, the original biometric features are not obtainable. Finally, top level security has also been maintained for subject biometric templates, since the retrieval of the subject's biometric features would also require the physical presence of the subject along with (release of pointer  ) a successful user authentication process.

159

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

160

Chapter 5

Implementation and Execution
5.1 Introduction

It is of paramount importance for government and private organizations including airport security, the Lottery and Gaming Corporation (or Casino self-exclusion program), Secret Service, civil aviation, border security, and military to establish a robust, reliable, and accountable surveillance zone for their field of view (FOV). Organizations are often required to track people in motion; for example, they may need to verify if a particular individual is the same person who had entered a room or crowd. As a result, biometrics is considered to be the most effective method of verification, since it offers undeniable physiological and behavioral attributes for authenticating an individual. However, dynamic targets in the surveillance zone are always noncooperative and vulnerable, and are obstructed by nonlinear, nonstationary, and heterogeneous noise. Therefore, as an organization grows, the threat of attacks to security and privacy also evolve. The Sequential Subspace Estimator (SSE) in conjunction with the MultiBiometrics encryption method presented in Chapter 3 and Chapter 4 can be used to overcome these challenges. This integrated method is an ideal system for protecting, authenticating, and tracking a single individual in the surveillance zone.
161

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Potential places for implementation of this system include airport security checkpoints and the self-exclusion program of the Lottery and Gaming Corporation (or Casino). In this system, the SSE method is used to extract quality biometric features and create biometric templates, while the MultiBiometrics encryption method protects these biometrics from security, privacy, and unlinkability attacks. The proposed MultiBiometrics authentication and encryption method may also have an important impact on the military, civil aviation, and Secret Service; particularly if they are targeting a noncooperative individual (i.e. suspect) within their favorable surveillance zones. This method can be used to track and authenticate a subject while also protecting the security and privacy of the subject's biometric features. Furthermore, certain institutions including museums, nuclear facilities, and those in the financial sector may want to use a surveillance zone to restrict an unauthorized personnel from accessing certain sections. Proper implementation of this integrated method would allow them to track and authenticate the legitimacy of existing personnel in order to control unauthorized access. To enhance the authentication system of a noncooperative moving target, gait biometrics along with facial biometrics have been fused to create a MultiBiometrics template. In this system, the received facial and gait images at the input terminal are analyzed, quality biometrics features are extracted, and biometric templates are stored. This MultiBiometrics can be used to establish a sophisticated top level biometrics surveillance system. The implementation process presented here is based on the challenges associated with the Lottery and Gaming Corporation's self-exclusion program and the airport security checking system. However, these programs don't require a 24/7 rigorous monitoring system; in most cases these security systems are dedicated to verifying the authenticity of an individual in their limited CCTV zone in the presence of the authorized person. Furthermore, in this environment the system needs to extract biometric features from the semi-dynamic individuals for which the system also has
162

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

an inexpensive processing time. Since there is little information to be gained about an individual's identity from the gait biometrics, they are considered as a unity (i.e. identity matrix) and don't play any role in the tracking and authentication process. In this implementation process, the main focus has been the self-exclusion program. Therefore, a brief description of the fundamental structure of the self-exclusion program used by the most of the Lottery and Gaming Corporations, and the detailed analysis, implementation, and execution process of the proposed integrated system based on this program are presented below.

5.1.1

Lottery and Gaming Corporation (Self-Exclusion Program)

Most Casinos (or Lottery and Gaming Corporations) offer a self-exclusion program, which allows the self-defined "problem individuals" to voluntarily opt their names out of Casino gaming sites. There are thousands of self-excluded members that have already been enrolled in the program. In this case, the enrollees of this program will be restricted from visiting the Casino. The surveillance area is monitored by cameras that can capture facial images without having any interaction with an individual. The authorities continuously track and authenticate self-excluded members in order to maintain the security and privacy of their patrons. If for any reason self-excluded members are found in the Casino sites, authorities will escort them off the premises [28],[29]. This self-exclusion program is an identification (1 to many) problem, which means they would be able to track and identify the suspect under surveillance. The integrated biometrics system presented here has addressed two important goals of the Lottery and Gaming Corporation: (i) authenticate a self-excluded member amongst the crowd, and (ii) protect the security and privacy of the members. However, the viability of its implementation based on the Casino's existing technology hasn't been addressed. Furthermore, it has also been considered that surveillance cameras have the ability to capture an individual's facial image. In this chapter, the detailed
163

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

implementation, execution, and performance evaluation of the proposed integrated method for the self-exclusion program of the Lottery and Gaming Corporation (or Casino) is presented. The remainder of the chapter is organized as follows: Section 5.2 outlines the detailed system overview, operational principle, implementation, and execution process of the proposed integrated method for the Casino self-exclusion program; Section 5.3 contains the experimental results and analysis; discussions are presented in Section 5.4; and conclusions are given in Section 5.5.

5.2

MultiBiometrics Authentication and Encryption ­Integrated System

In this section, a parallel and decentralized biometric tracking system based on facial and fingerprint physiologies and gait behavioral characteristics is presented. The objective of this biometric system is to implement a tracking system that can authenticate an individual in the surveillance zone, while also protecting their security and privacy. The detailed system overview and operational principle of this implementation method is presented in Fig. 5.1. 5.2.1 Operational Principle

In this case, the received facial and gait (i.e. speed and step size) biometrics of the subject are compiled separately as templates. These templates are then verified against the stored templates or pointer from the temp tracking database as shown in Fig. 5.1. If there are no stored templates in the database, the database pointer processes a positive Null signal and allows the tracking system to store the newly created templates in the temp database as a new entry. Otherwise, the new templates undergo the subject verification process (at matching score level fusion) using the
164

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 5.1: MultiBiometrics Authentication and Encryption -Integrated System

165

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

previously stored templates. If the matched score level is positive (if match found), then the new templates replace the old. Moreover, the tracker works like a close loop, continuously searching or tracking the moving subject (i.e. self-excluded member) within the surveillance region.

A trigger pulse for the authentication process is generated by the tracking system once in a complete tracking cycle to request biographic information regarding the subject of interest from the central terminal. This authentication signal is processed parallel to the tracking signal, and is initiated by the Null pointer when the Null verification pointer output is positive. The encryption method presented in Section 4.3.1 is implemented on the processed facial biometric template sent from the tracking section, and is compared with the stored encrypted face template. This comparison is essentially an initial identification process amongst biometric templates in the local database. The local database sends a biometric signal to the central station to perform a searching operation using the incoming face template, and complete a second layer of authentication for the subject if the initial authentication signal is positive. If a positive match is found at the second level, another triggering signal initiates additional layers of authentication processes to provide a description of the subject. The description is encrypted and fused with the user encrypted fingerprint biometrics at the central terminal before they are sent to the local station through the transmission line. The subject information received from the central databases is stored in local and temp tracking databases which then can be decrypted by the authorized user at the local terminal.

The overall process of this integrated system is divided into the following subsections.
166

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

5.2.2

Enrollment Process

As mentioned in Chapter 4, the enrollment and authentication processes of this integrated method are designed for two categories of people: user and target (selfexcluded member or suspect). In this process, the fingerprint and facial biometrics of the suspected member are enrolled using the same method studied in Chapter 3 and Chapter 4. Authorized users are enrolled using only fingerprint biometrics as stated in Chapter 3 and Chapter 4. This enrollment process can be completed in the central terminal and the information can be stored in the databases. The system includes the extraction of quality biometrics from users and targets, and the generation of secret cryptographic bonds (BioCryptoBonds), the Hot-Key function, and the data segmentation process discussed in Chapter 4. The execution process of the enrollment system is presented in Fig 5.2 (see also Figs. 4.4 and 4.5), and the steps involved in this enrollment process can be stated as follows:
5.2.2.1 User Enrollment

The user under consideration is an authorized staff member of the Lottery and Gaming Corporation. · Capture user fingerprint features. · Extract physiological features from areas of interest (i.e. ridges, minutiae points, and core point). · Implement Sequential Subspace Estimator (SSE) method and generate biometric template. · Extract orientation angle   . · Generate 32-bit cryptographic key K u .
167

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 5.2: MultiBiometrics Encryption and Authentication -Enrollment Process

168

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Implement tensor operation on fingerprint biometric features as a function of orientation angle, and also perform orthogonal operation (see Eq. (4.3)). · Implement encryption algorithm using output received from the previous stage and secret key K u , and generate cryptographic bond, BioCryptoBondu , for the user. · Perform hash key operation and fuse with the encrypted template along with the user biographic information, and generate index pointer. · Verify user authenticity with stored templates. · Store templates (if user not found) into user databases dBu and Enryptionu , and complete the enrollment process.
5.2.2.2 Subject or Member Enrollment

The subject under consideration is a self-excluded member of the Lottery and Gaming Corporation. · Receive interface pointer  upon successful user authentication. · Capture subject's facial geometry and fingerprint features. · Implement Sequential Subspace Estimator (SSE). · Extract biometrics from facial physiology (i.e. face area; relative locations and size of lips and eyes), and fingerprint (i.e. ridge, minutiae points, and core point). · Generate three separate templates (i.e. facial, fingerprint, and fusion of face and fingerprint). · Generate two cryptographic keys, K s and K s .
169


PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Implement tensor operation on facial biometrics as a function of  (see Eq. (4.5)). · Perform orthogonal operation. · Implement encryption algorithm using output received from the previous step. · Generate first cryptographic bond BioCryptoBondF . · Implement tensor operation on same cryptographic key K s . · Implement encryption algorithm using transformed key K s and fingerprint template (see Eq. (4.4)). · Generate second cryptographic bond BioCryptoBondF P . · Fuse fingerprint and facial templates to create MultiBiometrics. · Implement tensor operation on MultiBiometrics template. · Implement encryption algorithm using transfomed MultiBiometrics and cryptographic key K s . · Generate third MultBiometrics cryptographic bond BioCryptoBondF F (see Eq. (4.6)). · Perform hash operation and fuse with encrypted biometrics along with the member's biographic information. · Generate and share reference pointers among templates. · Implement Hot-Key method. · Generate reference data table to track and link data flow. · Verify member authenticity (if not enrolled).
170


PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Implement data segmentation method. · All together create a Biometrics Data Management System (BDMS). · Store template (if member not found) into databases: dBs , EncryptionF (face), EncryptionF P (fingerprint), and EncryptionF F (MultiBiometrics). 5.2.3 Tracking Process

The main objective of the tracking process is to track the member within the area of interest. The system includes the features extraction from the captured image, the data mining operation, and verification process. The execution process of the tracking system is presented in Fig. 5.3, and the steps involved in this tracking process can be stated as follows: · Capture face and gait (gait is considered to be unity). · Implement Sequential Subspace Estimator (SSE) method. · Extract face and gait biometric features. · Generate face and gait templates, respectively. · Verify these generated templates with pointers, or templates previously stored in the  T emp T racking Database as shown in Fig. 5.3.

· A positive Null pointer output indicates a new tracking process. · Activate a new tracking signal and store both templates as a new entry in


T emp T racking Database , if Null pointer is positive.

· Send a triggering signal (required once in a complete tracking process) along with interface pointer  and facial biometric features to the central terminal through the local database  EncryptF  , and request the subject's biographic (identification) information.
171

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 5.3: MultiBiometrics Encryption and Authentication -Tracking Process

172

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Otherwise, a negative Null pointer output indicates the continuation of the existing tracking process, thus no triggering signal is needed for processing in the central terminal. · Tracking process continues. · Verify subject with stored templates in  T emp T racking Database . · Positive verification (match found) indicates the same member, so the tracking process continues; otherwise, the searching operation continues.

5.2.3.1

Verify if member is in T emp T racking Database or Not

The method for creating the encrypted databases implemented here has already been discussed, and the steps involved in this process can be stated as follows: · If a member match is found in  T emp T racking Database , then the same subject is found; the tracking and verification processes continue. · If a member match is not found in  T emp T racking Database , the same subject is not found; the searching and verification processes continue.

5.2.3.2

T emp T racking Database is NULL

· No subject is processed yet. · Store current subject templates in  T emp T racking Database . · Generate a triggering signal and send the signal to local database  EncryptF  for authentication. · Follow steps stated in tracking process.
173

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

5.2.3.3

T emp T racking Database is Not NULL

· Tracking process already in progress, no triggering signal is needed to process the local database  EncryptF  .

· Verify if same subject is in  T emp T racking Database or not. · If verification is positive, a subject match is found in  T emp T racking Database ; tracking and verification continue for the next scanning cycle. · If verification is negative, a subject match is not found in  T emp T racking Database ; searching and verification continue for the next scanning cycle.
5.2.3.4 Member Not in (or in) Local Database EncryptF

The method for creating the encrypted database EncryptF implemented here has already been discussed, and the steps involved in this process can be stated as follows: · If subject is not in the  EncryptF  database, the subject hasn't been enrolled in central databases. · Subject or target is not known. · Tracker will not process identification request signal to central station or terminal. But, if member is in the database go to Section 5.2.4 and also do the rest of the steps (in this section) in parallel. · Tracking or searching process continues using steps stated in the tracking process. · Verify subject of interest with templates previously stored in  T emp T racking Database . · If match score at matching level fusion is positive, the same subject is found and tracking continues.
174

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Otherwise, the searching process continues. 5.2.4 Tracking and Authentication Process

The identification system is designed to authenticate the member under surveillance once an authentication request is received from the tracking system. In this stage, the authentication system provides multilayered data security protection for the member databases. As well, the authentication request must also pass through a multilayered security protocol. Otherwise, a signal is generated indicating that the member is unknown, at which point the tracking process continues for the next suspected members. The MultiBiometrics encryption method developed in Chapter 4 has been implemented as an integral part of this system. The method for creating the encrypted databases and cryptographic bonds have already been discussed in Chapter 4 and previous sections. The execution process of the identification system is presented in Fig. 5.4, and the steps involved in this authentication process can be stated as follows: · If the member is in the local database  EncryptF  , the subject has already


been enrolled in central databases  EncryptF F  ,  EncryptF  ,  EncryptF P  and Subject Database .

· Self-excluded member or subject is known (or recognized). · Receive member facial template and interface key  . · Implement tensor operation with the same algorithm used during the subject enrollment process involving facial biometrics. · Fuse and compare (1 to many) with a previously stored member's cryptographic terminal.
175

bond, BioCryptoBondF , in the member facial database,  EncryptF  , at the local

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure 5.4: MultiBiometrics Encryption and Authentication -Tracking and Authentication Process

176

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Release secret key, K s , if a match is found; and perform the tensor operation on the released secret key with the same algorithm used during the member enrollment process involving fingerprint biometrics. · Search for cryptographic bond, BioCryptoBondF P , corresponding to the transHot-Key function. · Fuse BioCryptoBondF P with the transformed secret key, and retrieve the member fingerprint biometric features. · Fuse or concatenate facial and fingerprint biometric features to create a MultiBiometrics template with the same algorithm used during the MultiBiometrics member enrollment process. · Implement tensor operation with the same algorithm used during the subject enrollment process involving MultiBiometrics member biometric features. · Fuse the MultiBiometric template from the previous stage with the secret MultiBiometrics cryptographic bond, BioCryptoBondF F , and release the secret key, Ks . · If a positive match is found, the secret key in conjunction with the Hot-Key function (reference and composite foreign key) locates and retrieves member identification information stored in the Subject Database in the central terminal. · Fuse and encrypt member identification with the user secret key, K u , at the central terminal before sending through transmission line. · Send encrypted fused data to local terminal through transmission line.
177


formed secret key, in  EncryptF P  database in the central terminal, using the

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

· Verify user authenticity, then authorized user can retrieve or decrypt member identification information at local terminal. · MultiBiometrics authentication and tracking system executes this authentication process in parallel to the tracking process once in a complete cycle. Authentication and retrieval of the requested information at the central terminal can be formulated as follows:

T =  × 1 (s) f = Tor K s = f × BioCryptoBondF [EncryptionF ]
s 2 (s) = Kor × BioCryptoBondF P [EncryptionF P ]

C(s) = C([1 (s)][2 (s)]) f f = Cor Ks


= f f × BioCryptoBondF F [EncryptionF F ]


Requested Info = Hot - Key (K s ) [dBs ]

(5.1)

5.3

Results and Analysis

The proposed integrated tracking and authentication method is a sophisticated system for establishing a top level surveillance zone in order to authenticate a single individual. This method uses MultiBiometrics, a fusion of facial and gait biometrics, for this purpose. It has been tested on a model being developed for the the Lottery and Gaming Corporation using 30 self-excluded members. In this experiment, the gait biometrics have been considered as a unity (i.e. identity matrix), and therefore
178

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

don't play any role in the tracking and authentication process. The integrated system has been divided into two parts: tracking and authentication; and the results and analysis presented here are based on these two parts. The data obtained from this experiment is included in Appendix - C . 5.3.1 Tracking

The tracking system is basically an automated authentication process performed in the local terminal. In the case of verification, the tracking system had to compare the captured facial biometric template of the suspected member with the biometric template stored in the "T emp T racking Database". Identification was performed by comparing the captured template with the stored templates from the "EncryptionF " database. The "T emp T racking Database" is a temporary biometric database created at the time of subject tracking. The encrypted facial database "EncryptionF " was created using 30 different members, each member having one biometrics template. The performance of the verification process for the tracking system has been evaluated based on the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Equal Error Rate (EER). The experimental results are recorded in Table 5.1, and the graphical outcome is presented in Fig. 5.5. The performance of the identification process has also been analyzed based on the Correct Recognition Rate (CRR), and the experimental result of this identification system is recorded in Table 5.2. Finally, upon successful identification, a cryptographic key K s has been released.

5.3.2

Tests and Results

The tracking system deals with two subject databases, T emp T racking Database and EncryptionF , and one user database: User Database (dBu ). The T emp T racking Database is a temporary database whose information is being deleted at the end of the tracking
179

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 5.1: Performance Evaluation in (%) -FAR, FRR, and EER (Integrated System) Database T emp T racking Database EncryptionF P EncryptionF F Subject Database Average FAR 6.5 7.3 1.5 1.1 4.10 FRR 5.8 4.8 4.6 4.3 4.87 EER 5.6 4.25 3.1 3.8 4.19

Table 5.2: Performance Evaluation in (%) -CRR (Integrated System -EncryptionF ) Database EncryptionF CRR 72.5

cycle. On the other hand, the EncryptionF database is being created with facial biometrics of 30 different subjects (self-excluded members) and the user database dBu contains 20 user accounts. The tests and their results from attempting to retrieve the user fingerprint and subject facial biometric features from dBu and EncryptionF databases, respectively are presented in Table 5.3:

5.3.3

Authentication

The authentication system for this integrated biometrics method is essentially an automated multilayered verification process. The entire authentication process has been performed in the central terminal. In this stage, three verifications of the databases EncryptionF P , EncryptionF F , and "Subject
180

Database" were performed. These

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 Top Level Security 0.2 0.1 0

Surveillance Zone

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate
(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 EER 5.6% 0.3 FAR 0.2 0.1 0 FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 5.5: Integrated System -Tracking (T emp T racking Database)
181

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table 5.3: Test Results -dBu and EncryptionF Databases Retrieval from Input Attempts Successful EncryptionF By user with subject 40 38 EncryptionF By unauthorized user with subject 40 0 EncryptionF EncryptionF dBu dBu By user with unauthorized subject When both are unauthorized By user By unauthorized user 40 40 40 40 3 0 39 0

three encrypted databases have been created for 30 self-excluded members using the methodology stated in the enrollment section of this chapter. In the first verification process, the released cryptographic key K s from the previous stage was compared to the encrypted fingerprint template stored in the EncryptionF P database, in order to release the member's fingerprints. Afterwards, the received facial (from the tracking part) and fingerprint biometrics from the previous two authentication processes were fused to create the MultiBiometrics template. This template was verified against the MultiBiometrics stored in the encrypted database EncryptionF F in order to release the reference key K s for the suspected member. The reference key was then validated using the key stored in the "Subject Database" database, and the member's information was released. Thus the requested information was sent and the authorized Casino user could retrieve the member's information at their terminal. The performance of these three layers of the verification process was evaluated using the Equal Error Rate stated in Section 1.1.4. The percentages of FAR and FRR, and the corresponding EER points, were determined and experimental results were recorded. The experimental results based on the proposed method for the Lottery and Gaming Corporation are presented in Table 5.1. The graphical outcome of these results is also presented in Figs. 5.6 - 5.8.
182


PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

5.3.4

Tests and Results

The authentication system deals with three subject databases: EncryptionF P , EncryptionF F , and Subject Database (dBs ). The tests and their results from attempting to retrieve the subjects' (self-excluded members) biometrics and biographic information from these subject databases are presented in Table 5.4:
Table 5.4: Test Results -EncryptionF P , EncryptionF F , and dBs Retrieval from Input Attempts Successful EncryptionF P Received from previous stage 40 37 EncryptionF P Received from outside (unauthorized) 40 1 EncryptionF F Received from previous stage 40 39 EncryptionF F Received from outside (unauthorized) 40 0 dBs dBs Received from previous stage Received from outside (unauthorized) 40 40 39 2

5.4

Discussions

In this experiment, a system for the Lottery and Gaming Corporation involving 30 self-excluded members has been presented. This system is the integration of the MultiBiometrics authentication and encryption methods presented in this dissertation. In this automated method, two important aspects of the Lottery and Gaming Corporation's self-exclusion program­the extraction of facial biometrics from the noisy environment and the information security and privacy-have been addressed. In this system, the combined effects of nonlinear, nonstationary, and heterogeneous noise due to illumination, position orientation, and background interferences of the extracted facial biometrics from the members under surveillance have been considered. The Sequential Subspace Estimator method presented in Chapter 3 has been implemented to overcome the noise associated with these extracted features. As well, the MultiBiometrics encryption method studied in Chapter 4 was implemented in
183

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR 1 0.9 0.8 0.7

False Acceptance Rate

0.6 0.5 0.4 0.3 Top Level Security 0.2 0.1 0 Surveillance Zone

0

0.1

0.2

0.3

0.4 0.5 0.6 False Rejection Rate

0.7

0.8

0.9

1

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 EER 4.25% 0.4 0.3 0.2 0.1 0 FAR FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 5.6: Integrated System -Authentication (EncryptionF P Database)
184

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 Top Level Security 0.2 0.1 0 Surveillance Zone

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 EER 3.1% 0.3 FAR 0.2 0.1 0 FRR

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 5.7: Integrated System -Authentication (EncryptionF F Database)
185

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Performance Evaluation --FAR and FRR
1 0.9 0.8

False Acceptance Rate

0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Top Level Security

Surveillance Zone

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

False Rejection Rate

(a) FAR and FRR
ROC Curve -Performance Evaluation
1 0.9 0.8 0.7

False Error Rate

0.6 0.5 0.4 0.3 0.2 0.1 0 FAR FRR EER 3.8%

0

10

20

30

40

50

60

70

80

90

100

Threshold

(b) ROC Curve

Figure 5.8: Integrated System -Authentication (Subject Database)
186

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

order to address security and privacy issues, allowing the system to be able to protect the biometric features against attacks. This system was developed under the assumption that the Lottery and Gaming Corporation has the technical and logistic ability to implement this integrated system. In this experiment, the extracted gait biometrics are being considered as a unity (i.e. identity matrix).

In the proposed integrated system, the enrollment process outlined in Section 5.2.2 is basically the enrollment process studied in Chapter 4. In this case, a step by step implementation and execution process has been presented. The tracking process presented in Section 5.2.3 is designed for a sophisticated top level surveillance zone. This integrated system has two main parts. In the case of the tracking system, the two databases "T emp T racking Database" and EncryptionF were created. Verification and identification processes were performed based on the extracted facial features as stated in the previous section. For the authentication system, three databases EncryptionF P , EncryptionF F , and Subject Database were created. In this case, three levels of verifications were performed before the requested member information was sent. This information can then be decoded at the local terminal by the Casino's authorized personnel. The experimental results for the verification process were recorded in Table 5.1 and the graphical outcome is presented in Figs. 5.5-5.8. According to the experimental results, an average EER of 4.19% and FAR of 4.10% at the cost of FRR 4.87% have been achieved. Furthermore, a CRR of 72.5% has been achieved for the identification process performed with the facial biometrics stored in the EncryptionF database. As this is a model for the Lottery and Gaming Corporation, based on a sample of 30 members, the results could vary in a real life scenario as these institutions deal with a large volume of datasets.
187

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

5.5

Conclusions

The importance of a reliable, secure, robust, and cost-effective tracking and authentication system is of paramount importance for the Lottery and Gaming Corporation's self-exclusion program. This is especially important since the self-excluded members are always dynamic and mixed in amongst the crowd of other loyal patrons. Therefore, a step in the direction of facial and gait biometrics is being regarded as the promising solution for this program, since they facilitate the extraction of biometrics without intruding on the subject. In this chapter, a detailed implementation and execution process for the proposed MultiBiometrics authentication and tracking system for the Lottery and Gaming Corporation's self-exclusion members has been presented. The main objective of this integrated method is to locate and verify the identities of the members, while protecting the biometric features from security, privacy, and unlinkability attacks. This method is being developed under the assumption that their surveillance cameras are able to capture images of an individual. In addition, it is assumed that the Lottery and Gaming Corporation would be able to provide technological support in order to implement this biometrics self-exclusion system. This system is being designed using 30 self-exclusion members. However, in a real life scenario, the Lottery and Gaming Corporation deals with large-scale databases. In this automated tracking method, facial physiology in conjunction with gait behavioral characteristics has been used to enhance the authentication accuracy of the suspect in the surveillance zone. However, in this experiment, only facial biometric features have been used, while gait biometric features are considered as a unity. The extraction process of the facial biometric features is being designed based on the proposed Sequential Subspace Estimator method, while the MultiBiometrics encryption method presented in Chapter 4 has been implemented to protect the biometric features. From the experimental outcome, it is evident that the proposed integrated
188

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

system is efficient, robust, and heuristic, since an average EER of 4.19% has been achieved in this integrated multilayered environment. This system is also highly secure, since multilayered, MultiBiometrics security management architectures have been implemented to protect against attacks. Furthermore, all the stored extracted target biometrics will be erased permanently from the system (temp database) at the end of the tracking process. The security and privacy of the transmitted data through communication channels have also been considered. More importantly, there is no direct link between the tracking and main systems. Tracking is completed in the local terminal and multilayered MultiBiometrics authentication and security agreements need to be fulfilled by the authorized user in the presence of the subject before they are granted access into the system and the member's information is released.

189

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

190

Chapter 6

Conclusions and Future Work
6.1 Conclusions

Biometric systems rely on extracted human measurable physiological and behavioral features. These features are unique and sensitive, and are not irrevocable or reissuable if compromised. The performance of biometric systems is largely dependent on the quality of these extracted features. Acceptance and exploration of the biometrics are dependent on the security and privacy of these extracted features. This dissertation has addressed the two important aspects of the biometric system; namely the quality of the extracted biometric features to ensure an efficient authentication, and their associated computational complexity, security and privacy issues. Most biometric systems are modeled under the assumption that the associated noise that obstructs the biometric features is linear, stationary, and homogeneous. But this assumption weakens the performance of the systems as they often deal with a nonlinear, nonstationary, and heterogenous noise environment. In addition, the biometric traits that are selected as potential candidates for the biometric systems are vulnerable to security, privacy, and unlinkability attacks. Most situations dealt with by biometric systems involve managing databases that contain higher dimensional
191

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

datasets. This makes computational complexity a vital issue, as the performance of the system is largely dependent on this factor. This dissertation addresses the deficiency in this regard and systematically investigates a biometric authentication and encryption process in the nonlinear, nonstationary, and heterogeneous environment.

In this dissertation, a Sequential Subspace Estimator (SSE) algorithm in the image subspace has been proposed. Typical, PCA, LDA, MLE, LMS, Bayesian, and Wiener methods are inadequate to deal with nonlinear, nonstationary, and heterogeneous noise; however they are optimal methods in a linear and stationary environment. The integration of PCA with Wiener, Bayesian, and MLE methods is being used to over these challenges. The other promising alternative for dealing with this situation is the sequential estimator. The main concern with the sequential estimator is its inadequacy when dealing with higher dimensional datasets. These datasets pose a problem for the sequential estimation method, since it needs to compute the covariance matrix and perform the matrix inversion operation. As a result, the proposed SSE algorithm is modeled in the image subspace under the assumption that the associated noise with the biometric features is nonstationary, nonlinear, and heterogeneous. In this case, the subspace algorithm is modeled in the image space to deal with the challenges associated with the sequential estimator. In the proposed SSE method, higher dimensional image space is transformed into L linearly independent images so that the dimension of the biometric features reduces from N × N to M × M , where M << N .

This dissertation also proposed a MultiBiometrics encryption algorithm to guard biometric features from security, privacy, and unlinkability attacks. The encryption method is based on Biometric Encryption (BE), since this method provides more protection for security and privacy compared to its counterpart, the Feature
192

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Transformation-based method. In this method, fingerprint and facial biometric features are used to create a cryptographic bond, called a "BioCryptoBond". Furthermore, a data management system is also proposed to enhance security protection and to improve performance and accuracy. The proposed MultiBiometrics encryption method is designed to deal with two categories of people: user and subject (target). In this method, one cryptographic bond "BioCryptoBondu " for the user and three cryptographic bonds "BioCryptoBondF ", "BioCryptoBondF P ", and "BioCryptoBondF F " for the subject are created. Furthermore, an orthogonal tensor projection method and its detailed algorithmic structure as a function of fingerprint orientation angle are developed. In addition, the system generates a random private key, which is monotonically bound to the extracted facial and fingerprint biometric features. This creates a cryptographic bond in such a way that neither the cryptographic key nor the biometric features can be released or decrypted independently without a successful biometric authentication. The Hot-Key algorithm and data segmentation techniques are implemented in order to develop a secure Biometrics Data Management System (BDMS). Three subject cryptographic bonds are created with the objective of providing multilayered security protection for the subject biometric features. It is evident that the neither the secret key nor the biometric features can be retrieved from this cryptographic bond. Moreover, to gain access to the subject's biometrics, both an authorized user and the subject are required to be present during the authentication process. An integrated system based on the proposed MultiBiometrics authentication and encryption method has also been presented in this dissertation. The main objective of this integration is to track and authenticate a noncooperative moving target while protecting the security and privacy of the biometric features under consideration. This integrated system is being implemented in the Lottery and Gaming Corporation's selfexclusion program. Facial biometrics in conjunction with gait (gait is considered to be
193

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

unity) behavioral features of the moving target are used to track and authenticate the self-excluded members. In this case, the tracking system locates the moving target under surveillance and sends the request for the target identification information to the central system. Then the proposed multilayered MultiBiometrics encryption method authenticates the legitimacy of the the received request before the requested information is sent back to the local terminal. The proposed method has been compared with the other state-of-the-art methods and its performance has been evaluated based on the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Correct Recognition Rate (CRR). The experimental results found that the proposed method outperformed its counterparts. The main highlights of the chapters included in this dissertation are given below: · Chapter 1: This chapter presents introductory information in regards to the biometric system and its associated challenges. The motivations and objectives of the proposed dissertation have also been included in this chapter. · Chapter 2: A comprehensive literature review and associated challenges, along with supporting statements in favor of the proposed MultiBiometrics authentication and encryption method are presented in this chapter. This chapter also outlines several prerequisites required for the proposed method before getting into the detailed analysis, formulation, implementation, and execution process. · In Chapter 3: The proposed Subspace Sequential Estimator (SSE) method is presented in this chapter. The main objective of this method is to ensure the quality of the biometric features and reduce the computational complexity in the estimation process, which would otherwise be obstructed by the nonstationary, nonlinear, and heterogeneous noise. This is one of the core chapters of this dissertation. At the beginning of this chapter, the SSE method is compared to other state-of-the-art methods, such as PCA, MLE, Bayesian, Extended Kalman, and
194

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Wiener methods. The problem generation and formulation methodology are also included in this chapter. In the middle of this chapter, model formulation and detail methodology of the subspace process are included. An algorithmic flowchart and the analysis of the computational complexity of the proposed SSE method are also discussed. The proposed method is made independent of the biometric traits; however, the SSE method is tested using the facial images of two public databases "Put Face Database " and "Indian Face Database". The performance of the proposed algorithm is evaluated by the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Correct Recognition Rate (CRR). Finally, the experimental results and analysis, and comparisons to its counterparts are presented at the end of this chapter. It is apparent from the experimental analysis and outcome that the proposed SSE method outperformed its counterparts. · Chapter 4: This chapter is another core chapter of this dissertation. In this chapter, the proposed MultiBiometrics encryption method and its management system are presented as a solution for protecting biometric features against security, privacy, and unlinkability attacks. This chapter is divided into encryption, enrollment, and the authentication process for two categories of people: user and subject. The method of developing the user's and subject's cryptographic bonds is presented at the beginning of this chapter. As well, a detailed user and subject enrollment process and its biometrics information management system are also presented in this chapter. The user authentication process and its management architecture are also discussed. The model evaluation and computational complexity of this encryption method are included in the middle of this chapter. Finally, the performance of the proposed method is analyzed based on the facial images of two public databases, the "Put Face Database" and "Indian Face Database", and fingerprint images from the "CASIA Fingerprint Image
195

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Database Version 5.1" database. The performance of the proposed algorithm is evaluated by the False Acceptance Rate (FAR), False Rejection Rate (FRR), and Correct Recognition Rate (CRR). · Chapter 5: The implementation and execution process of the integrated MultiBiometrics authentication and encryption method is presented in this chapter. This integrated system can be utilized by the Lottery and Gaming (or Casino) Corporation, airport security, and surveillance zones. However, the implementation and execution process presented here is based on the Lottery and Gaming Corporation's self-exclusion program.

6.2

System Vulnerability and Failure

The proposed MultiBiometrics authentication and encryption method is being developed to provide security protection for two categories of people: user and subject. The user's fingerprint biometric features are being extracted and transformed as a function of orientation angle to create a user template in the orthogonal domain. Afterwards, the data segmentation method is implemented to store user biometrics and biographic information into two user databases: Encryptionu and dBu , respectively, and a reference pointer is used to create a link between these databases. In the proposed system, the user biometric system is vulnerable to two types of attacks: i) attack on the reference pointer and ii) attack on the data or stored information. The attack on the reference pointer is a vital issue, since this pointer is the key to accessing and completing the system operation for the proposed method. Any changes to the reference pointer may cause interruption or failure of the system. On the other hand, attacks on user data include deletion or modification of stored information, and addition of new information to the database systems. These attacks should be a crucial consideration, since they may also cause system failure or interruption of
196

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

system operations. But, both attacks cannot affect the security and privacy of the user's biometric features. Obtaining or creating a system specific reference point is tedious work, since passing the multifactor authentication requests is a requirement. The user system is unlinkable, so even if the attacker is able to create or obtain a reference pointer, they won't be able to get the complete user information unless the attacker can establish a link between two segmented user databases. Attempts to delete or modify the reference pointer are also tedious for the same reasons stated above. Attacks on user data or stored information may only serve to modify or delete an anonymous user record. But, the ability to cause the complete system or specific record to fail is not possible without having the system specific reference pointer in addition to establishing a relationship between two segmented user databases. In the worse case scenario, where the attacker deletes or modifies the system, system operation would be partially interrupted but the security and privacy of the user biometrics would not be affected. The subject biometric system is more secure than the user biometric system. The subject biometrics and biographic information are being segmented and stored in four databases: dBs , EncryptionF , EncryptionF P , and EncryptionF P . The Hot-Key function discussed in Chapter 4 (Section 4.4.1) is being used as a reference pointer to establish the relationship among these subject databases. In this case, the subject biometrics system is unlinkable and protected by the multilayered and MultiBiometrics encryptions. It is almost impossible for the attacker to obtain complete information about the subject from these segmented databases, since the retrieval of the subject's biometric features also requires the physical presence of the subject along with a successful user authentication process. The only vulnerability that may be considered here, is an attack on the subject data or stored information. In this case, an attack on the subject data may only cause the modification or deletion of an
197

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

anonymous record. It won't be possible to make the complete system fail or to target a specific subject record without having the Hot-Key function and establishing the relations between the four subject databases. Obtaining the reference pointer and establishing the relationship are very tedious tasks, since the system is segmented, unlinkable, and multifactor transactions have to be processed to verify the legitimacy of the authentication request. Finally, no system is 100% secure. The proposed system is vulnerable to system attacks as well as attacks to obtain reference pointers, which may allow the attacker to modify the anonymous data. The resultant effect may cause system interruption and may also fail to show the system performance and efficiency. However, the system is unlinkable, so access to specific user and subject biometrics information is not possible without having the reference pointers and without successfully completing the MultiBiometrics authentication process. But, obtaining a system specific reference pointer and completing the multifactor authentication process would be very tedious work for an unauthorized individual as per the reasons stated before. Administrative security and network access control systems can be implemented to avoid these system attacks. However, implementation of these securities is beyond the scope of this study.

6.3

Future Work

This dissertation has investigated two important aspects of the biometric system: the quality of biometric features leading to computational complexity and the authentication process, and Biometric Encryption (BE). In addition, the methodology of its integrated implementation and execution process is also presented in Chapter 5. However, in the implementation process, one aspect that is not vigorously defined is the protection of the extracted biometric features from the moving subject. It may be possible that the extracted features are vulnerable to security and privacy
198

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

attacks. In these circumstances, it is recommended to ensure that these features are protected during the implementation cycle studied in Chapter 5. However, this protection hasn't been considered since it is a time-consuming process and the extracted features of the moving target would be erased at the end of the tracking process. The implementation process developed here is for tracking and authenticating one target in a single tracking cycle; but in some cases, surveillance systems may need to deal with multiple targets. Therefore, an interesting option might be to make the proposed method able to locate multiple targets in the surveillance zone in a specific time slot. More importantly, the implementation, execution, and testing processes for tracking and authenticating the Lottery and Gaming Corporation self-excluded members are based on the small database of 30 self-excluded members. However, in a realistic environment, the Lottery and Gaming Corporation always deals with large dimensional datasets. So, the reader might be interested in testing the system in an operating environment that uses large dimensional datasets. Furthermore, according to the proposed theory, the dissertation also claimed that the proposed Sequential Subspace Estimator (SSE) is independent of the biometric traits. However, since the testing is performed on the public fingerprint image database "CASIA Fingerprint Image Database Version 5.1", and two public facial image databases "Put Face Database " and "Indian Face Database", the reader may wish to see further tests using different biometric traits, including iris and hand geometry, in support of this claim. In addition, the execution time for the verification process presented in Chapter 3 is slightly higher (but within the acceptable range) for facial recognition. The main reason for this longer execution time is due to the use of Microsoft Access databases in conjunction with Matlab. In this process, the system needs to search and locate the record of a person that contains the biometric features that need to be verified. However, the biometrics verification (1:1) process has been performed only
199

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

with the biometric features that the individual claimed to have. More observations and adjustments of the filter parameters as well as changing the combination of the training dataset may be useful to reduce the execution time of the verification process, even though the execution time of the identification process is within the promising range. Furthermore, in Chapter 4, the encryption method is tested using the "CASIA Fingerprint Image Database Version 5.1" database in conjunction with the two facial image databases discussed previously. Further testing of the method using other public databases is also encouraged. The proposed method has been tested on a facial image database with a maximum size of 600 images. A tracking system in conjunction with the authentication and encryption method is being proposed to implement in large institutions including the Lottery and Gaming Corporation (or Casino), museums, airport security, and those in the financial sector who want to use a surveillance zone to restrict unauthorized personnel from accessing certain sections in real time. These types of institutes always deal with massive database systems, so it may also be an interesting option to test the method within a large range of database environments. Moreover, file structure also plays an important role in system performance; and the acceptability and feasibility of a biometrics system in a realistic operating environment are also largely dependent on it. In this dissertation, Microsoft Access database architecture in conjunction with Matlab have been used. Matlab is an efficient scientific program for the research community because of its simplistic and predefined coding structure. For the implementation of the biometric system in the real time domain, especially in the case of large scale databases, Object Oriented Programming language is recommended for use in the front end with the SQL or Oracle based database architecture in the back end. However, the details of the Object Oriented database architecture, implementation, and its processing methodology are beyond the scope of this dissertation.
200

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Finally, the proposed Sequential Subspace Estimator (SSE) method has been tested with four state-of-the-art algorithms, namely the Kalman Filter, PCA, PCAMLE, and PCA-Wiener. As well, it has been tested with the nonlinear (heterogeneous and nonstationary) "Put Face Database" and the less nonlinear (less heterogeneous and less nonstationary) "Indian Face Database". The experimental results have been presented and it is apparent from their outcome that the proposed method outperformed its counterparts. As well, the proposed MultiBiometrics encryption method is highly secure, since a multilayered authentication in the presence of the subject and authorized user must be performed in order to retrieve the biometrics and biographic features.

201

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

202

Appendix A

Possible Attacks
The main objective of this study is to extract quality biometric features that would otherwise be obstructed by nonstationary, nonlinear, and heterogeneous noise. It is also to protect the stored and dynamic biometric features against security, privacy, and unlinkability attacks. The following subsections address the possible attacks and the methodologies for protecting biometric features and systems against these attacks.

A.1

User Enrollment

The user enrollment process has been carried out under favorable conditions using fingerprint biometric features (minutiae points) at the central teminal. Fig. A.1 is a snapshot of Fig. 4.5 presented in Chapter 4 and shows the possible attacks on the user enrollment system. In this process six different attacks have been considered. The details of these attacks and the security protections provided by the proposed MultiBiometrics method are discussed below:
203

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure A.1: Attacks on User Enrollment Process

204

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

A.1.1

Attack on Sensor

This type of attack is known as an attack on the biometric sensor. Here, the attackers present a fake biometrics that can imitate the authenticity of an authorized individual [116],[117]. Security Protection: This attack is performed before the implementation of the fusion and encryption method (see Fig. A.1). As mentioned before, in the proposed method the user biometric template is processed along with the digital secret key to cerate an encrypted bond and genrate a reference pointer. This reference pointer is then verified against the stored reference pointer before storing the biometrics (enrollment) into the database systems. Therefore, even if the attacker is able to present the fake biometrics, the system won't allow the attacker to complete the enrollment process. This is because the attacker needs to have the system specific reference pointer in order to process and store the user biometrics. However, the creation of this reference pointer without knowing the digital secret key and methodology for doing that is very tadious task. In the worst case scenario, the attacker is able to complete the enrollment using fake biometrics, but will still only have access to their own information and not the other users or subjects. The system is unlinkable as well, so access to the subject's information would require the physical presence of the subject in front of the authorized user. A.1.2 Attack on Communication Channel

Sometimes this attack is combined with an attack on the biometric sensor. However, this attack is being considered to be an attack on the raw biometrics between the scanner and the feature extraction method. In this case, the attacker can intercept and relay the intercepted (i.e. stolen) biometrics to the feature extractor in order to bypass the biometric scanner [116],[117]. Security Protection: The proposed system is also protected against this type
205

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

of attack for the same reasons stated for attacks on sensors. A.1.3 Attack on Feature Extraction Method

In this case, an attacker can replace the biometric features extraction method and implement a remotely controlled methodology to generate biometric templates [116],[117]. Security Protection: This attack is conducted before the implementation of the fusion process and encryption method. So, the system is also protected against this type of attack for the same reasons stated for attacks on the sensor. A.1.4 Attack on Encrypted Domain

This attack is considered to be an attack on the cryptographic bond, which is the most vital stage of the MultiBiometrics encryption method. In this case, attackers can replace the encryption method with thier own remotely controlled method or can decrypt the encrypted bond to obtain the biometric features. Security Protection: This attack can be performed in the encrypted domain at the time of encryption to replacee the encryption method, afterwards to decrypt the bond. If the encryption method is replaced by the attacker at the time of the encryption process, the newly created bond would be different. The resultant effect would be the creation of a system specific reference pointer required to process and store the user biometric template. If the attacker tries to decrypt the bond, they still won't be able to complete the enrollment process. To complete the enrollment process, the attacker has to recreate the encrypted bond using the proposed methodology. Even if the attacker is able to obtain the biometrics and other information from their unauthorized decryption process, they won't be able to obtain the original biometric features. This occurs because, in this encryption process, user fingerprint biometrics have been transformed as a function of orientation angle in the orthogonal domain. Afterwards, this tranformed biometric template is fused with the digital secret key
206

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

before the encrypted bond is created.

A.1.5

Attack on Enrollment Status

During attacks on the enrollment verification process, the attacker can override the user enrollment status or decisions made by the proposed system. In this case, the attacker can override two types of decisions: show the enrolled user hasn't been enrolled yet, and show the unenrolled user has already been enrolled. Security Protection: This is another vital stage of the enrollment process. If an attacker is able to override the first decision and complete the enrollment process, they won't be able to use this enrolled user to access the system. In this case, the attacker just overrides the dicision, not the reference pointer, even if the attackers use the fake reference pointer to create a new enrollment. It might be possible to have a duplicate entry for the user, but this duplicate entry won't effect the system's security and privacy. The system cannot read that reference pointer and the attacker cannot have access to the system, because the structure of the reference pointer generated during the authentication process would be completely different than the fake reference pointer. To override the second decision by the attacker would be long and tedious. Even if the attacker is able to generate fake reference pointer and tries to override the second decision, the system won't allow it, since the reference pointer has to match with the reference pointer stored in the system. In order to match, the attacker must have the authorized user fingerprint and successfully pass through the all of the attacks mentioned above. Therefore, this attack won't affect the system performance or the security and privacy of the biometrics. The worst case scenario would be if the enrollment status was successfully attacked; in this case, they would still only have access to their own information, not other users or subjects, for the same reasons discussed in Section A.1.1.
207

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

A.1.6

Attack on Database

Attacks on user biometric templates stored in the database system include the addition of a new template, modification of an existing template, or deletion of a template [116],[117]. Security Protection: In the proposed method, user information is being segmented and stored in two user databases: User Database (dBu ) and Encryptionu . The dBu and Encryptionu databases contain the user biographic and biometrics information, respectively. The link between two databases has been established by the reference pointer. This linking process is essential in order to have the complete user information. In this case, the attacker cannot add a new recond, since in order to do so, the attacker has to gererate a reference pointer through the process outlined in Chapter 4, and also must have the authorized user biometrics and biographics information. The attacker cannot modify or delete the existance or targeted template, since each user has two templates stored in two different databases. Without the reference pointer, the attacker cannot establish the relationship between the two databases, and without this relationship the attacker cannot locate and delete the the targeted templates. The system is unlinkable and multifactor authentication processes have to overcome this to access the database systems. A single point entry would not allow the attacker to access the system in order to add, modify, and delete the user.

A.2

Subject Enrollment

The subject enrollment process has been completed using the facial, fingerprint, and MultiBiometrics features. Possible attacks on the subject enrollment system are shown in Fig. A.2. Fig. A.2 is a snapshot of Fig. 4.6 presented in Chapter 4. Possible attacks and security protection of the subject's biometrics are the same that
208

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

for the user. As well as the user's security protection, an authorized user must also be in the presence of the subject at the time of subject enrollment. In this case, the unlinkable multilayered encryption method is protected by a 32-bit digital key in conjunction with the reference pointer. Even if the attackers are be able to access the digital key and reference pointer, the original biometrics are not retrievable from the cryptographic bond. The extracted biometric features need to be transformed as a function of  before the bonding process occurs. In addition, the retrieval of subject information from the databases again requires the presence of the subject in front of the authorized user. The segmentation method is used to store subject biometrics and biographic information in the four subject databases. The Hot-Key function (see Chapter 4, Section 4.4.1) is used as a reference pointer to link between the subject databases. Furthermore, the reference table that contains the reference pointers only has address information representing the locations of the segmented subject record, not subject information. This makes the system unlinkable so that a single point entry would not allow the attacker to access unauthorized information from the databases or distinguish the identity of the subject from the received information.

A.3

Authentication

The possible attacks on the user authentication process are shown in Fig. A.3. Fig. A.3 is a snapshot of Fig. 4.7 presented in Chapter 4. The subject authentication is dependent on a successful user authentication process, and the types of attacks on it are almost the same. The details of the possible attacks and the security protection against these attacks have already been addressed in above sections. In addition, the experimental results of the subject (and user) authentication process are presented in Section 4.6. User fingerprint biometrics have been used during
209

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure A.2: Attacks on Subject Enrollment Process

210

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

the authentication process. If attackers are able to intervene at the sensor or communication channel, they still won't be able to access the system, since the biometric features need to be transformed as a function of the user fingerprint orientation angle before authentication occurs. Even if the attackers are able to obtain access to the system through a single point, they won't have the right to access other users' or subjects' information, since the biometric systems are unlinkable and the physical presence of the subject is required along with the user in order to retrieve the biometrics and biographic information. The databases are protected by multilayered encryption; hence single point access ability won't allow the attacker to retrieve unauthorized information or distinguish the identity of the subject (or user) from the received information. Furthermore, the biometric information is segmented, and reference pointers are used to establish a link between them. In this method, it is not possible to obtain the original biometrics from these reference pointers and vice versa. As well, it is not possible to know the individual's identity or construct (or guess) the original biometric features of an individual from the segmented biometrics stored in the databases. Databases (or information) are segmented and transformed, and complete authorized processing is required in order to access the system. Therefore, this system is invincible to unlinkable attacks, and imposters cannot retrieve data based on information found in other parts of the system.

A.4

Tracking and Authentication

Fig. A.4 is a snapshot of Fig. 5.4 presented in Chapter 5. This tracking and authentication request is considered to be processed from a highly unfavorable environment, typically from a local terminal. In the case of the tracking system, the extracted biometric features from the
211

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure A.3: Attacks on User Authentication Process

212

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure A.4: Attacks on Tracking and Authentication Process

213

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

moving target (attack on the tracking system) are vulnerable to security, privacy, and unlinkability attacks. These attacks won't effect the privacy and security of the moving target in the surveillance zone, since the extracted information won't be permanently stored in the databases but will be deleted at the end of the tracking cycle. Furthermore, access to the temporary biometric features of the moving target won't give the attacker access to other parts of the system. Only the authentication request along with the facial biometric features of the suspected subject are sent from the tracking to the authentication system, where they face the multifactor authentication process. Finally, the authentication system is protected by the multilayered and MultiBiometrics encryption method. The attacker cannot access the biometric system from any signal point entry. Even if the attackers are able to access the system, they cannot retrieve the original biometric features or distinguish the biometric information for the same reasons stated above. Furthermore, the requested biographic description of the subject sent through the communication channel is also protected from the attacks under consideration. The transmitted subject's information is unlinkable and encrypted by the user's transformed fingerprint biometrics at the central terminal before it is sent through the transmission channel. Therefore, attacks on the communication channel shown in Fig. A.4 could not allow the attackers to access the original biometrics information or other parts of the biometric system.

214

Appendix B

Hash-Function and Foreign Key
A hash function H is a mapping algorithm that projects an arbitrary length of a large data block to a data block of fixed (smaller) length. Typically, the hash system has two parts: bucket and directory [118]. A bucket is the physical address on the database that contains the records, and a directory contains the hash key and the reference pointer pointing to the bucket that contains the records. The hash function can be stated as follows: H(k ) = k % N (B.1)

where %, k, and N are the MOD operator, the key value, and the number of buckets respectively. In the proposed model, a 32 - bit randomly generated key is hashed with primary biometric key features to create 16 - bit reference pointers. Afterwards, reference pointers are used to access the database records. In this case, a one way cryptographic hash function is used, where the primary key features I are difficult to retrieve for I = I such that H(I ) = H(I). The structure of the reference pointer is presented in Table: 1: As previously mentioned, a primary key is a key that uniquely identifies a record or a subject (or user) in a database. The primary key is not shareable and cannot
215

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure B.1: Hashing Process

216

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Table B.1: Reference Pointer Generation Primary Features Subject/ User-1 Subject/ User-2 Subject/ User-3 32-bit Digital Key 011000...011 001011...010 101000...001 16-bit Pointer 1010...11 0010...01 1101...10

be used (or assigned) by the other subject (or user). On the other hand, a foreign key is a field or a collection of fields of the database that are used with the primary key to establish links among the tables in the database system. The establishment of this type of relationship among the tables in the database system is known as the relational database system. In this method, using the analogy of the relational database, the primary and foreign keys in conjunction with the reference pointers are used to create a link between the segmented databases. This structure allows the legitimate user to locate and access the database records without losing the data consistency, while at the same time protecting the security and privacy of the information. A typical structure of this relationship among the databases is presented in Fig. B.2 and Fig. B.3.

217

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure B.2: Relational Database -Reference Key

218

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure B.3: Relational Database -Hot-Key

219

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

220

Appendix C

Experimental Data

221

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.1: Experimental Data -Chapter-3 (Fig. 12)

222

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.2: Experimental Data -Chapter-3 (Fig. 13)

223

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.3: Experimental Data -Chapter-3 (Fig. 14)

224

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.4: Experimental Data -Chapter-3 (Fig. 15)

225

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.5: Experimental Data -Chapter-4

226

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.6: Experimental Data -Chapter-5

227

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

Figure C.7: Sample of Extracted Data (Grayscale) -Chapter-3 (Section-3.3)

228

Bibliography
[1] A. Jain and A. Kumar, "Biometrics history", Available:

http://www.biometrics.gov-documents-biohistory.pdf, pp. 127, Oct. 2012. [2] D. Stinson, "Cryptography: theory and practice", Ed.: 3rd, Chapman Hall/CRC Press Inc., Jan. 2006. [3] D. Moss, "FBI techs shy away from facial recognition: spends 40 years losing face", Internet: www.theregister.co.uk-2009-11-03-fbio-face-recognition, [Nov. 2012]. [4] J. Klontz and A. Jain, "A case study of automated face recognition: The Boston Marathon bombings suspects", IEEE Security and Privacy, Nov. 2013. [5] A. Menezes, P. Oorschot, and S. Stone, "Handbook of applied cryptography", Ed.: CRC press, Mar. 2006. [6] Y. Imamverdiev and L. Sukhostat, "A method for cryptographic key generation from fingerprints", Automatic Control and Computer Sciences, vol. 46, no. 2, pp. 66-75, Apr. 2012. [7] D. Maltoni, D. Maio, A. Jain, and S. Prabhakar, "Handbook of fingerprint recognition", Ed.: 2nd, Springer, Sep. 2009. [8] B. Rosistem, "Fingerprint feature extrcation", Internet:

http://www.barcode.ro/tutorials/biometrics/fingerprint.html, [Dec. 2011].
229

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[9] J. Lee, "Technical definition and description: Fingerprint identification", Internet: http://www.personal.psu.edu/jbl5036/blogs/engl202c/technical-definition-

description.html, [Dec. 2011]. [10] Griaule net: Biometrics, "Orientation map extraction", Inter-

http://www.griaulebiometrics.com/en-us/book/understanding-

biometrics/types/feature-extraction/orientation, [Nov. 2012]. [11] "Fingerprint singular points detection", Internet:

http://biostar.fe.up.pt/Projects.html, [Nov. 2012]. [12] E. Kremic and A. Subasi, "The implementation of face security for authentication implemented on mobile phone", The International Arab Journal of Information Technology, pp. 1-6, Sep. 2011. [13] C. Le and R. Jain, "A survey of biometrics security systems", Internet: http://www.cse.wustl.edu/ jain/cse571-11/ftp/biomet/, [Oct. 2013]. [14] M. Kelly, "Biometric Identification", Internet: http://vceit.com/p/biometricindex.htm, [Oct. 2013]. [15] E. Chabrow, "Iris recognition: Available: NIST computer scientist patric grother",

http://www.bankinfosecurity.com/interviews/iris-recognition-nist-

computer-scientist-patrick-grother-i-368, Nov. 2009, [Oct. 2013]. [16] M. Veen, T. Kevenaar, G. Schrijen, T. Akkermans, and F. Zuo, "Face biometrics with renewable templates", SPIE Proceedings-Security, Steganography, and wantermarking of Multimedia, vol. 6072, pp. 1-12, Jan. 2006. [17] K. Bowyer, K. Chang, P. Flynn, and X. Chen, "Face recognition using 2-D, 3-D, and infrared: Is multimodal better than multisample?", IEEE Proceeding-Invited Paper, vol. 94, no. 11, Nov. 2006.
230

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[18] "Facial recognition biometrics", Internet: http://www.myfingerprintreader.com/category/facial recognition-biometrics, Oct. 2011, [Jan. 2012]. [19] M. Lane, "BBC News: Can you tell who it is yet?", Available:

http://news.bbc.co.uk/2/hi/uk-news/magazine/6981500.stm, Sep. 2007, [Jan. 2011]. [20] "Detection, Inspection, and Enforcement", Internet: Oct.

http://www.nist.gov/mml/mmsd/security-technologies/dietbiom.cfm, 2012, [Jan. 2013].

[21] B. Bhanu and X. Zhou, "Feature fusion of side face and gait for video-based human identification", ELSEVIER Journal of Pattern the Recognition Society, vol. 41, pp. 778-795, Feb. 2008. [22] H. Lu, J. Wang, and K. Plataniotis, "A review on face and gait recognition: system, data, and algorithms", Department of electrical and Computer Engineering University of Toronto, Canada, Apr. 2008. [23] H. Lu, K. Plataniotis, and A. Venetsanopoulos, "A layered deformable model for gait analysis", Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition, Southampton, UK, pp. 249-254, UK, Apr. 2006. [24] J. Boyd and J. Little, "Gait Recognition", Internet: [Oct.

http://www.springerreference.com/docs/html/chapterdbid/70822.html, 2013].

[25] "Biometrics France", Internet: http://www.contemplas.com/motion-analysispartner/biometrics-france.aspx, [Nov. 2013]. [26] "Gait", Internet: http://fingerchip.pagesperso-

orange.fr/biometrics/types/gait.htm, [Nov. 2013].
231

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[27] D. Royer, "A study on PKI and biometrics:

Soft biometrics", Internet:

http://www.fidis.net/resources/deliverables/hightechid/int-d32000/doc/21/, [Jan. 2014]. [28] A. Cavoukian and T. Marinelli, "Privacy-protective facial recognition: biometric encryption proof of concept", Information and Privacy Commissioner, Ontario, Canada. Nov. 2010. [29] A. Cavoukian and A. Stoianov, "Biometric encryption: A positive-sum technology that achieves strong authentication, security and privacy", Information and Privacy Commissioner Ontario, Mar. 2007. [30] G. Salvendy and M. Smith, "Human Interface and the management of information: Information and interaction", Springer, Sep. 2009. [31] S. Mayhew, "Special report: Biometrics and national security", Biometrics Research Group Inc., Mar. 2014. [32] T. Sabareeswari and S. Stuwart, "Identification of a person using multimodal biometric system", International Journal of Computer Applications", vol. 3, no. 9, pp. 12-16 Jul. 2010. [33] M. Elalami, A. Amin, and A. El-alfi, "A personal identification framework based on facial image and fingerprint fusion biometric", International Journal of Computer Application, vol. 51, no. 7, pp. 41-48, Aug. 2012. [34] S. Prabhakar, S. Prankanti and A. Jain,"Biometric recognition: security and privacy concerns ", IEEE Security and Privacy, Published by IEEE Computer Society, pp. 33-42, Last Update Oct. 2013.
232

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[35] D. Zizhe, Z. Xianda, and Z. Xiaolong, "Nonlinear Principal Component Analysis using Strong Tracking Filter", Tsinghua Science and Technology, vol. 12, no. 6, pp. 652-657, Dec. 2007. [36] "A face recognition", National Science and Technology Council, Tech. Rep., Apr. 2006. [37] "Biometrics", Internet: www.bromba.com/faq/biofaqe.htm, [Jul. 2011]. [38] L. Chan, S. Salleh, and C. Ting, "Face biometrics based on Principal Component Analysis and Linear Discriminant Analysis", Journal of Computer Science, vol. 6, pp. 693-699, Jul. 2010. [39] P. Selvi and N. Radha, "Multimodal biometrics based authentication against dictionary attacks", International Journal on Computer Science and Engineering, vol. 2, pp. 2652-2658, May 2010. [40] G. Lakshmi, "Fingerprint identification system combined with cryptography for authentication", International Journal of Engineering, Science and Technology, vol. 2, pp. 3054-3077, Mar. 2010. [41] C. Nandini, C. Ashwini, M. Aparna, N. Ramini, P. Kini, and K. Sheeba, "Biometrics authentication by dorsal hand vein pattern", International Journal of Engineering and Technology, vol. 2, pp. 837-840, Jan. 2012. [42] H. Lu, K. Plataniotis, and A. Venetsanopoulos, "Uncorrelated multilinear Principal Component Analysis for unsupervised multilinear subspace learning", IEEE Transactions on Neural Networks, vol. 20, no. 11, pp. 1820-1836, Nov. 2009. [43] M. Law and A. Jain, "Incremental nonlinear dimensionality reduction by manifold learning", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 28, no. 3, pp. 377-391, Aug. 2006.
233

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[44] J. Suo, L. Lin, and S. Shan, "High-resolution face fusion for gender conversion", IEEE Transactions on Systems, Man and Cybernetics, vol. 41, no. 2, pp. 226-237, Sep. 2011. [45] E. Carlos, D. Gillies, and R. Feitosa, "A new covariance estimate for Bayesian classifiers in biometric recognition", IEEE Transactions on Circuits Systems and Video Technology, vol. 14, no. 2, pp. 214-223, Mar. 2004. [46] L. Lin, T. Wu, J. Porway, and Z. Xu, "A stochastic graph grammer for compositional object representation and recognition", Pattern Recognition, Elsevier, vol. 42, no. 7, pp. 12971307, Feb. 2009. [47] K. Nandakumar, "Integration of multiple cues in biometric systems", Masters thesis, Michigan State University, Department of Computer Science and Engineering, Oct. 2005. [48] M. Nounou, B. Bakshi, P. Goel, and X. Shen, "Bayesian Principal Component Analysis", Journal of Chemometrics, vol. 11, pp. 576-595, Jun. 2002. [49] K. Martin, H. Lu, F. Bui, K. Plataniotis, and D. Hatzinakos,"A biometric encryption system for the selfexclusion scenario of face recognition", IEEE Systems Journal: Special Issue on Biometrics Systems, vol. 3, no. 4, pp. 440-450, Mar. 2009. [50] W. Zhang, X. Wang, and X. Tang, "Lighting and Pose Robust Face Sketch Synthesis", Proceedings of European Conf. Computer Vision, Nov. 2010. [51] K. Nandakumar and A. Jain, "Multibiometric template security using fuzzy vault", Proceedings of 2nd IEEE International Conference on Biometrics: Theory, Applications, and Systems, pp. 1-6, Jun. 2008.
234

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[52] A. Jain, "Hiding biometric data", IEEE Transaction on Pattern Analysis and Machine Intelligence, vol. 25, no. 11, pp. 1449-1498, Nov. 2003. [53] A. Ross, K. Nandakumar, and A. Jain, Handbook of multibiometrics, Springer, Chapter 2, Mar. 2006. [54] B. Klare, Z. Li, and A. Jain, "Matching forensic sketches to mugshot photos", IEEE Transection Pattern Analysis and Machine Intelligence, vol. 33, no. 3, pp. 639-646, Mar. 2011. [55] X. Wang and X. Tang, "Random sampling for subspace face recognition", International Journal of Computer Vision, vol. 70, no. 1, pp. 91-104, Oct. 2006. [56] S. Bucak, R. Jin, and A. Jain, "Multiple kernel learning for visual object recognition: A review", IEEE Transaction on Pattern Analysis and Machine Intelligence, vol. 36, no. 7, pp. 1354-1369, Jul. 2014. [57] U. Park, H. Choi, A. Jain, and S. Lee, "Face tracking and recognition at a distance: A coaxial and concentric PTZ camera system", IEEE Transaction on Information Forensics and Security, vol. 8, no. 10, pp. 1665-1677, Oct. 2013. [58] N. Srinivas, G. Aggarwal, P. Flynn, and W. Bruegge, "Analysis of facial marks to distingush between identical twins", IEEE Transactions on Information Forensics and Security, vol. 7, no. 5, pp. 1536-1550, Oct. 2012. [59] A. Paulino, F. Jianjiang, and A. Jain, "Latent fingerprint matching using descriptor-based hough transform", IEEE Transactions on Information Forensics and Security, vol. 8, no. 1, pp. 31-45, Jan. 2013. [60] B. Klare and A. Jain, "Heterogeneous face recognition using kernel prototype similarities", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 35, no. 2, Feb. 2013.
235

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[61] F. Hao and C. Chan, "Private key generation from on-line handwritten signatures", Information Management and Computer Security, no. 2, pp. 159-164, Aug. 2002. [62] A. Teoh, T. Connie, O. Ngo, and C. Ling, "Remarks on biohash and its mathematical foundation", Information Processing Letter, no. 4, pp. 145-150, Sep. 2006. [63] C. Lee, J. Choi, K. Toh, S. Lee, and J. Kim, "Alignment-free cancelable fingerprint templates based on local minutiae information", IEEE Transactions on Systems, Man and Cybernetics, Part B, vol. 37, no. 4, pp. 980-992, Oct. 2007. [64] O. Song, A. Teoh, and D. Ngo, "Application specofic key release scheme from biometrics", Intenational Journal of Network Security, vol. 6, no. 2, pp. 127-133, Mar. 2008. [65] Y. Wang, "Changeable and privacy preserving face recognition", PhD Thesis, University of Toronto, Sep. 2010. [66] M. Savvides, B. Kumar, and P. Khosla, "Cancelable biometric filters for face recognition", Proceedings of the 17th International Conference on Pattern Recognition, pp. 922-925, Aug. 2004. [67] D. Maio and L. Nanni, "Multihashing, human authentication featuring biometrics data and tokenised random number: a case study", Elsevier Neurocomputing, vol. 69, no. 1, pp. 242-249, Jun. 2006. [68] A. Goh and D. Ngo, "Computation of cryptographic keys from face biometrics", Communications and Multimedia Security, Security Lecture Notes in Computer Science. Springer Berlin / Heidelberg, pp. 1-13, Jun. 2003. [69] R. Gonzalez and R. Woods, Digital Image Processing, Ed.: 3rd Singapore: Prentice Hall, Nov. 2008.
236

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[70] Y. Bar-Shalom, X. Li, and T. Kirubarajan, Estimation with Applications to Tracking and Navigation, New York, NY, USA: John Wiley & Sons, Inc., Sep. 2002. [71] S. Haykin, Kalman Filtering and Neural Networks, Wiley-Interscience, Oct. 2001. [72] O. Malek, A. Venetsanopoulos, and A. Anpalagan, "A comparison study between wiener and adaptive state estimation (STAP-ASE) algorithms for space time adaptive radar processing", Proceedings SPIE: Mathematics of Data/Image Coding, Compres- sion, and Encryption with applications XII, vol. 7799, no. 6, pp. 1-10, Aug. 2010. [73] S. Haykin, Adaptive Filter Theory, Upper Saddle River, NJ, USA: Prentice-Hall Inc., Ed.: 4th, Sep. 2001. [74] A. Kak, "ML, MAP and Bayesian - The holy trinity of parameter estimation and data prediction", Purdue University, Technical Report, Jul. 2013. [75] A. Kasiski, A. Florek, and A. Schmidt, "The PUT Face Database", Image Processing and Communications, vol. 13, no. 3-4, pp. 5964, 2008. [76] V. Jain and A. Mukherjee, "The Indian Face Database", Avaiable:

http://www.cs.umass.edu/ vidit/IndianFaceDatabase/, 2002, [Dec. 2012]. [77] "Facial recognition", recognition/, [Feb. 2014]. [78] S. Milborrow, J. Morkel, and F. Nicolls, "The MUCT Landmarked Face Database", University of Captown, Oct. 2009. [79] C. Bouman, "Digital image processing -Nonlinear filtering", Internet: Internet: http://findbiometrics.com/solutions/facial-

http://biometricjournalweb/papers/nolinerafiltering.pdf, Jan. 2014, [Mar. 2014].
237

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[80] G. tering

Arce, for

J.

Bacca,

and

J. and

Paredes,

"Nonlinear

fil-

image

analysis

enhancement",

Internet: Jan. 2009,

http://biometricjournalweb/papers/essencial/20guide/20wmf.pdf, [Mar. 2014].

[81] V. Balakirsky, A. Ghazaryan, and A. Vinck, "An algorithm for biometric authentication based on the model of nonstationary random processes", [Apr. 2014]. [82] S. Bowker, "White paper -A guide to data analysis and segmentation", Publish by Legal, Data and Best Practice Hub, DMA Email Marketing Council, Jun. 2011. [83] "Data protection act", Internet: http://www.getsafeonline.org/business/dataprotection-act/, [June 2014]. [84] A. Delehanty, "Security issues in biometric identification", Internet:

https://wiki.umn.edu/pub/ummcsciseniorseminar/spring2011talks /anthonydelehanty.pdf, Apr. 2011, [Dec. 2013]. [85] M. Bruso, K. Chatzikokolakis, S. Etalle, and J. Hartog, "Linking unlinkability", Available:http://hal.archives-ouvertes.fr/doc/00/76/01/50/pdf/unlinkability.pdf, 7th International Symposium on Trustworthy Global Computing, Dec. 2012, [June 2014]. [86] A. Pfitzmann and M.Hansen, "Anonymity, unlinkability, pseudonymity, and identity management-A consolidated proposal for terminology", Available: http://dud.inf.tu-dresden.de/Anon-terminology.shtml, version v0.25, Dec. 2005, [Aug. 2013]. [87] L. Khan and B. Thuraisingham, " Data mining applications in biometrics systems", Technical Report UTDCS-05-05, Department of Computer Science, The University of Texas at Dallas, Feb. 2005.
238

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[88] J. Jackson, "Data mining: A conceptual overview", Communications of the Association for Information Systems, vol. 8, pp. 267-296, Oct. 2002. [89] J. Sun, D. Tao, S. Papadimitriou, P. Yu, and C. Faloutsos, "Incremental tensor analysis: Theory and applications", Journal of ACM Transections on Knowledge Discovery from Data, vol. 2, no., 3 Oct. 2008. [90] J. Pato and L. Millett, "Biometric recognition: challenges and opportunities", The National Academies Press, 2010. [91] O. Malek, D. Androutsos, A. Venetsonoupoulous, and L. Lian, "Subspace state estimator for facial biometric verification", IEEE Proceedings of The International Conference on Computational Science and Computational Intelligence, Las Vegas, USA, vol. 1, pp. 137-143, Mar. 2014. [92] O. Malek, D. Androutsos, A. Venetsonoupoulous, and L. Lian, "Sequential subspace estimator for biometric authentication", ELSEVIER-Neurocomputing, Accepted June 2014, To Appear 2014. [93] L. Smith, "A tutorial on Principal Components Analysis", Technical Report, 2002. [94] B. Kozminchuk, "A comparison of Recursive Least Squares and Kalman Filtering excisors for swept tone interference", Technical Note 92-14, Defence Research Establishment Ottawa, Ottawa, Ontario, Canada, Tech. Rep., 1992. [95] Y. Bar-Shalom, X. Li, and T. Kirubarajan, Estimation with Applications to Tracking and Navigation, Chapters 6 and 10, New York, NY, USA: John Wiley & Sons, Inc., Sep. 2002. [96] I. Reid, "Estimation II", Internet: http://biometricjournalsweb/papers/lecturenotes2.pdf", [Mar. 2013]
239

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[97] H. Lai, Y. Pan, C. Liu, L. Lin, and J. Wu, "Sparse learning-to-rank via an efficient primal-dual algorithm", IEEE Transactions on Computers, vol. 62, no. 6, pp. 1221-1233, Jun. 2013. [98] A. El-Keyi, T. Kirubarajan, and A. Gershman, "Robust adaptive beam forming based on the Kalman Filter", IEEE Transactions on Signal Processing, vol. 53, no. 8-2, pp. 3032-3041, Aug. 2005. [99] D. Simon and T. Chia, "Kalman Filtering with state equality constraints", IEEE Transactions on Aerospace and Electronic Systems, vol. 39, pp. 128-136, Mar. 2002. [100] C. Wikle and N. Cressie, "A dimension-reduced approach to spacetime Kalman Filtering", Biometrika, vol. 86, no. 4, pp. 815-829, Jul. 1999. [101] G. Schoenig, "Contribution to robust adaptive signal processing with application to space-time adaptive radar", Ph.D. dissertation, Faculty of Virginia Polytechnic and State University, 2007. [102] S. Brown and S. Rutan, "Adaptive Kalman Filtering", NBS Journal of Research, vol. 90, pp. 403-407, Mar. 1985. [103] Internet: https://www.ics.uci.edu/ welling/teaching/KernelsICS273B/MatrixCookBook.pdf, [Feb. 2013]. [104] M. Khan, Internet: http://www.cs.ubc.ca/ emtiyaz/Writings/MILandIF.pdf, [Dec. 2012] [105] A. Jain and A. Kumar, "Biometric of next generation: An overview", To Appear in Second Generation Biometrics Springer, Aug. 2010.
240

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[106] B. Bhanu and X. Zhou, "Feature fusion of side face and gait for video-based human identification", ELSEVIER Journal of Pattern the Recognition Society 41, pp. 778-795, 2008. [107] H. Lu, J. Wang. and K. Plataniotis, "A review on face and gait recognition: system, data and algorithms", Apr. 8 2008. [108] C. Le and R. Jain, "A survey of biometrics security system", Available: www.cse.wustl.edu/ jain/cse571-11/fpt/biomet/, Nov. 2011, [Oct. 2012]. [109] A. Jain, A. Ross, and U. Uludag, "Biometric template security challenges and solutions", Available: www.biometrics.cse.msu.edu, Apr. 2005, [Jan. 2013]. [110] "Fingerprint ridge orientation angle", Internet: www.google.ca/search?q/fingerprint/orientation/angle, [Aug. 2013]. [111] A. Jain, K. Nandakumar, and A. Nagar, "Biometric template security", EURASIP Journal of Advances in Signal Processing, vol. 2008, pp. 1-17, Mar. 2007. [112] F. Hao, R. Anderson, and J. Daugman, "Combining crypto with biometrics effectively", IEEE Transactions on Computers, vol. 55, pp. 1081-1088, Jun. 2006. [113] K. Nandakumar and A. Jain, "Multibiometric template security using fuzzy vault", To Appear in BTAS, Nov. 2008. [114] A. Jain and U. Ulugad, "Hiding biometric data", Pattern Analysis and Machine Intelligence, IEEE Transactions, vol. 25, pp. 1494-1498, Jun. 2003. [115] J. Chang and K. Fan, "A new model for fingerprint classification by ridge distribution sequences", The Journal of the Pattern Recognition Society, vol. 35, pp. 1209-1223, Nov. 2002.
241

PhD Dissertation - Obaidul Malek

Ryerson - Electrical & Computer Engineering

[116] M. Kaur, S. Sofat, and D. Saraswat, "Template and database security in biometrics systems: A chanllenging task", International Journaal of Computer Applications, vol. 4, no. 5, Jul. 2010. [117] A . Zamboni, "Attacking biometric access control systems", Internet: www.miskatoniclabs.com/biometrics/, [Dec. 2013]. [118] E. Navathe, "Extendible Hashing: ternet: Advanced Database Systems", In-

http://www.smckearney.com/adb/notes/lecture.extendible.hashing.pdf,

[May 2013].

242


