Constraint Satisfaction Problems in the Logic LFP+Rank

by

Aklilu Habte Bachelor of Science, Ryerson University, 2013 Bachelor of Engineering, Ryerson University, 1998

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Science in the Program of Applied Mathematics

Toronto, Ontario, Canada, 2015 c Aklilu Habte 2015

Author's Declaration
I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my thesis may be made electronically available to the public.

ii

Abstract
Constraint Satisfaction Problems in the Logic LFP+Rank Master of Science 2015 Aklilu Habte Applied Mathematics Ryerson University Constraint satisfaction problems (CSPs) are one of the central topics in theoretical computer science, in particular, in the area of artificial intelligence. Their computational complexity is due to relatively recent results from areas of mathematics, including finite-model-theory, algebra and graph homomorphisms.

The main conjecture by Feder and Vardi states that any CSP over a finite relational template is either in P or is NP-complete. Further, it amounts to showing that every non NP-complete CSP can be expressed as an extension of first-order logic.

A finite template is Mal'tsev, a compatible algebraic operation, which is closely related to an affine space over a finite field. The so-called Bulatov-Dalmau algorithm, a natural generalization of the Gaussian elimination on vector spaces, shows such CSPs are tractable. In this work, we prove that CSPs described over a finite template Mal'tsev are expressible in logic LFP+rnk , providing a logical proof that such CSPs are tractable. iii

Acknowledgements
Over the years, Ryerson University has been a second home for me. Thank you Ryerson for offering me valuable career paths. In particular, I would like to thank the departments of Engineering, Computer Science and Mathematics.

My deepest thanks go to my supervisor Dr. Dejan Deli´ c. I have never met such a person who is so organized, skill-full and yet very knowledgeable about the field. I have learned so much that can not be found in any text books or class rooms. Thank you Dr. Deli´ c.

In completing my graduate studies, the faculty and staff members of the Department have been of great support. I would like to thank Dr. Anthony Bonato, Dr. Jean-Paul Pascal, Dr. Katrin Rohlf, Dr. Pawel Pralat, Dr. Pablo Olivares, Dr. Sebastian Ferrando and Dr. Silvana Illie for shaping my knowledge.

I would like to thank Steve Kanellis, department IT specialist, for trouble-shooting all computer related issues. Also, I would like to thank Kathy Peter, Luisa Chan and Teresa Lee for their relentless service.

From the Department of Computer Science, I would like to thank Dr. Mikhail Soutchanski for shaping my interest on the field early on; and Dr. Jelena Misic & Dr. Vojislav Misic for their support.

Thank you fellow graduates for being part family, part friend.

In closing, I would like to thank my entire family for their unconditional love and support. You are always my heroes. iv

Dedication

To

my mother Lul Amare my father Hailemichael Habte and my sister Tsehay Habte.

v

Contents

1 Introduction 1.1 1.2 1.3 Constraint Satisfaction Problem . . . . . . . . . . . . . . . . . . . . . . . . . CSP and Relational Structures . . . . . . . . . . . . . . . . . . . . . . . . . . Mal'tsev Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 2 9 11 15 15 23 24 25 25 25 26 27 29 30 32

2 Least Fixed-Point, Rank 2.1 2.2 Relation to FO Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Other Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Bulatov-Dalmau's Algorithm 3.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1.1 3.1.2 3.2 Projection of a Tuple . . . . . . . . . . . . . . . . . . . . . . . . . . . Signature of Relation . . . . . . . . . . . . . . . . . . . . . . . . . . .

Its Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 3.2.2 3.2.3 3.2.4 Procedure Solve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Procedure Nonempty . . . . . . . . . . . . . . . . . . . . . . . . . . . Procedure Fix-values . . . . . . . . . . . . . . . . . . . . . . . . . . Procedure Next-beta . . . . . . . . . . . . . . . . . . . . . . . . . . .

vi

3.2.5 3.3

Procedure Next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

34 36 39 39 43 45 51 51 52 55

Illustration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Algorithm via LFP+rnk 4.1 4.2 4.3 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Supporting Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Procedures via logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 Conclusion and Open Problems 5.1 5.2 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Bibliography

vii

Chapter 1 Introduction
In general, the constraint satisfaction problem (CSP) is NP-complete. The motivating problem is to find under what circumstances one can design a polynomial time algorithm for solving it. Tractable cases can be achieved by restricting the relation that appear in a constraint to belong to a given set . Identifying all sets  of relations over a finite domain leads to a class instance of CSP() that guarantees tractability [2, 3]. Hence, we focus on restricted CSP in which an algorithm decides whether there is a solution or not in polynomial time. Restricted CSPs that are now widely studied, includes 2-SATISFIABILITY, GRAPH H-COLOURABILITY. Constraint satisfaction problems cover a wide range of areas of study. It arises in the areas of algebra, combinatorics, artificial intelligence (AI), graph theory, logic and other domains. For further discussion on various approaches to the study of constraint satisfaction problems, see [7].

In Chapter 4, we provide an original work, a logical proof to the so called Bulatov-Dalmau algorithm, that decides whether an instance of CSP has a solution or not in polynomial time. As a result, we show an implementation of the algorithm on finite CSP, via least fixed-point 1

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

(LFP) logic with matrix rank (rnk ) operator.

The details of LFP, an extension of first-order (FO) logic, and the expressive power of the rank of a matrix is discussed in Chapter 2. The chapter also discusses, LFP logic together with rank operator (LFP+rnk ) in relation to finite model theory (FMT).

The outline of the Bulatov-Dalmau algorithm is given in Chapter 3. In addition, the chapter provides an illustration of the algorithm of fixed CSP, a system of linear equations, defined over the field of two elements, F2 .

In addition to a summary, Chapter 5 includes some open problems in relation to few subpowers [13]. The chapter also discusses how the k -edge operation and its template can be extended to the original work shown in Chapter 4.

Next we present some examples of CSPs in relation to some of the domains mentioned above. However, we shall first define the preliminaries to the CSPs in general, the related relational structures and the ternary template Mal'tsev.

1.1

Constraint Satisfaction Problem

A constraint satisfaction problem (CSP) consists of a set of variables, a set of values for each of the variables and a set of constraints on those variables. Constraints are relations among the variables, in which they restrict the values that these variables may simultaneously be assigned. A solution to a CSP specifies values for all the variables in which the constraints are satisfied. As a result, finding a global assignment to all the variables while satisfying 2

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

all of the constraints is NP-complete. Consequently, it motivates researchers in the field in devising an algorithm where CSPs can be determined in polynomial time.

In general, CSPs can be categorized into two main classes namely Satisfiability and Optimization type of problems [17]. The former deals with finding an assignment of values to variables that satisfies some constraints. However, assignment of values often require optimal assignment. That is, each assignment of a value to each variable has a related cost or an objective value to it. Optimization type of problems deal with finding such an assignment with the least cost or with the highest objective value. However, often algorithms are designed with the intent purpose for both satisfiability and optimization.

In this writing by constraint satisfaction problem means a finite CSP, in which the constraints are fixed over a finite domain. The goal is to find a value for each of the variables in which all the constraints are satisfied. Hence, if there are n variables, where each variable can take k values in the domain, then there are k n possible assignments. That is , each variable xi has a domain Ai , which is the set of possible values that the variable can take. The following definition describes the content of a typical instance of a finite constraint satisfaction problem.

Definition 1.1. A constraint satisfaction problem (CSP) contains a finite set of variable, written V , a finite set of values (or domain) for each of the variables and a finite set of constraint, denoted by C , on those variables. Hence, let V = {x1 , . . . , xn }, A be a domain of values and C = {C1 , . . . , Cm }. In addition, let a CSP instance P = (V, A, C ), in which all constraint relations, denoted by S , belongs to the set of relations .

3

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

The problem is whether P has a solution. The solution to a CSP instance involves a mapping of f : V  A, which satisfies each constraint in C .

The CSP representation allows analysis of the problem structure. That is, CSP states can be defined by values of a fixed set of variables, while goal tests (or allowable values) can be defined by constraints on variable values. The following example is a typical CSP representation of a system of linear equations (algebra).

Example 1.1. A CSP representation on a system of linear equations, over any algebraic field: C1 : a11 x1 + a12 x2 + · · · + a1n xn C2 : a21 x1 + a22 x2 + · · · + a2n xn . . . . . . = b1 = b2 . . .

Cm : am1 x1 + am2 x2 + · · · + amn xn = bm

The problem could then be defined as assigning values to all the variables xi , where [n] is the set {1, . . . , n} and i  [n], while satisfying all the constraints Cl , where l  [m]. For instance, the familiar tool for solving system of linear equations is through Gaussian elimination. This means there is an algorithm that decides if such a system has a solution in polynomial time [6]. In particular, the algorithm accepts a linear system of size s as input and its running time is bounded by f (s), where f is polynomial. We say that the particular system is an instance of CSP of LINEAR SYSTEM. Although systems of linear equations are 4

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

in P, in contrast there is no known polynomial time algorithm for nonlinear, that is NONLINEAR SYSTEM. The above computational complexities indicates that certain CSPs are not solvable in polynomial time.

The conjecture presented by Feder and Vardi illustrates that a constraint satisfaction problem over finite domains are either in P or is NP-complete [9]. We adopt a computational complexity notation from [6] in describing an asymptotic upper bound running time of functions. That is, problems that can be solved in O(nk ), where k is a constant and n is the size of the input, are considered to be in class P. However, NP-complete problems are very unlikely to be solvable in polynomial time. The work of [12] shows a methodology, by way of polynomial time reductions, in proving a given problem is not solvable in polynomial time. This notion of polynomial time reduction is mostly known as Cook-Levin Theorem [1].

Informally, a problem P1 is in class NP-complete if it is as hard as every other problem P2 in the class NP. A solution to either of these problems in turn can be verified in polynomial time. The existence of intractable cases is a compelling evidence that P = NP. That is, if any NP-complete problem is solvable in polynomial time then every problem in NP can be solved in polynomial time, which means P = NP. However, to date no polynomial time algorithm exist for problems of class NP-complete. Further, since NP-complete is the maximal member of class NP, assuming P = NP, then there must be problems in NP \ P that are not in NP-complete. For details of the subject and related proof we refer the reader to [12, 17].

Identifying a problem posed to belong to a certain complexity class is a powerful tool used in searching and or devising an efficient algorithm. In general, algorithms designed for 5

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

specific problems perform better. We illustrate a CSP instance by posing a simple system of linear equations.

Example 1.2. Consider the following system of linear equations defined over F2 , a field with two elements. Let a finite set of variables, V = {x1 , x2 , x3 , x4 } with a finite domain, A = {0, 1} and a finite constraint relations, Si for each line of equation. Let the relation containing all the variables be denoted by R.

x1 + x 3 = 0 x2 + x3 + x 4 = 1

Problem: find a relation R that satisfies the entire system simultaneously.

The solution to each constraint, representing each line of equation, is as follows: S1 = {(x1 , x3 ) : (0, 0), (1, 1)}; and S2 = {(x2 , x3 , x4 ) : (0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 1, 1)}.

The system can simultaneously be satisfied with the following relations: R = {(x1 , x2 , x3 , x4 ) : (0, 0, 0, 1), (0, 1, 0, 0), (1, 0, 1, 0), (1, 1, 1, 1)}.

The solution obtained above can easily be verified by substituting the corresponding values into the given system of equations. For instance take R(x1 , x2 , x3 , x4 ) = (0, 0, 0, 1) as a solution to the system. That is, by substituting the values into the first and second line of equations, respectively, we get the L.H.S.  x1 + x3 = 0 + 0 = 0  R.H.S.; and similarly 6

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

the L.H.S.  x2 + x3 + x4 = 0 + 0 + 1 = 1  R.H.S. (L.H.S. and R.H.S. denotes the left and right hand side of an equation, respectively.)

Next we give another CSP example from the propositional logic. That is, let a boolean formula , consist of the variables x1 , . . . , xn and the logical operators AN D(), OR() and N OT (¬). For instance, (x1  x2 )  (x2  x3 ) is a boolean formula. Hence, let (v ) represent the value of the formula in relation to the variables assigned from the domain A, where v  A. In general, a formula  is satisfiable if there exists some assignment v such that (v ) is TRUE, otherwise the formula is not satisfiable.

Further, a formula  is said to be in conjunctive normal form (CNF) if it has a conjunction of clauses, where a clause is a disjunction of literals [1]. That is, in logical term, a formula in CNF contains an AN D() of OR s() of variables or their negation. In general, a formula in CNF has the conjunction of disjunction of the form: i (j uij ), where uij are literals and the terms `(j uij )' are clauses of the formula with distinct literals. That is, each uij is either a variable xk or its negation ¬xk .

In addition, a k CNF is a CNF formula in which all clauses contain at most k literals [1]. As a result, if we denote all satisfiable CNF formulae as SAT problems then, for instance, 3SAT problem is in reference to all satisfiable 3CNF formulae with 3 distinct literals. The following is an example of a 3CNF formula.

Example 1.3. Let the boolean formula  be an instance of 3CNF problem with one clause. That is, let  be defined over the variables V = {x1 , x2 , x3 } and the domain A = {0, 1},

7

CHAPTER 1. INTRODUCTION

1.1. CONSTRAINT SATISFACTION PROBLEM

where 0 is FALSE and 1 is TRUE. Let a finite constraint relations, Si represent each disjunction of literals (a clause). Hence, let the boolean formula is defined as follows:

 = (x1  ¬x2  x3 ).

Problem: is the formula  satisfiable?

If we consider each clause in a given formula as a relational constraint, Si then  is satisfiable if all the clauses are evaluated to TRUE. That is, if S1  S2  · · ·  Si = TRUE.

The solution to the constraint (clause) in the formula  is as follows: S1 = {(x1 , x2 , x3 ) : (0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)} and hence,  is satisfiable.

Note that, in the above simple example the formula  is expressed over a single clause, which in turn contains only three variables . It can easily be verified, say using a truth table, that is requires at most 23 steps in verifying if the given formula is satisfiable. However, if a formula in 3CNF is expressed with more than one clause, and possibly more distinct variables between each constraints, verifying the satisfiability of all possible outcomes require much greater than polynomial time.

In general, if a formula  contains n number of variables, there are 2n possible assignments. Checking every assignment requires (2n ) time. As a result, over the length of , determining whether the formula is satisfiable does not run in polynomial time [6]. This demonstrates that 3CNF is indeed NP-complete. In fact, satisfiability of boolean formu8

CHAPTER 1. INTRODUCTION

1.2. CSP AND RELATIONAL STRUCTURES

las is NP-complete. The polynomial reduction due to Cook and Levin, introduced above, is a useful tool in proving other problems of being NP-complete. For instance, satisfiable problems or SAT can be reduced to 3SAT. In turn it can be used to prove to more restricted language of boolean formulas, without restricting the language itself, by considering fewer cases as in satisfiability of 3CNF. For details and proof of reducibility see [1, 6, 12].

Similarly, from the domain of graph theory, graph colouring is another example of a widely studied class of satisfiability problem. One such application is the colouring of a geographical map with minimum possible number of colours, in which neighbouring regions would have distinct colours and hence, the constraint. The following is an example of a typical graph colouring problem over a given graph.

Example 1.4. k -colouring problem [6]. Let G be an undirected graph and without any isolated vertices. Let V and E be a nonempty set of vertices and edges, respectively. Hence, for a graph G = (V, E ), let f : V  C is a k -colouring function such that f (u) = f (v ) for every edge (u, v )  E , where C = {1, 2, . . . , k } containing a set of distinct number of colours. The task is to find the minimum number of distinct k colours that can satisfy the constraints imposed on a graph.

1.2

CSP and Relational Structures

Constraint satisfaction problem (CSP) is a relational homomorphism problem [11]. Recall that homomorphism preserves adjacency by mapping vertices between graphs. For instance, consider two graphs G and H . If G is homomorphic to H then there is a mapping of vertices in which f : V (G)  V (H ) such that f (u)f (v )  E (H ), where uv  E (G). In addition, if a 9

CHAPTER 1. INTRODUCTION

1.2. CSP AND RELATIONAL STRUCTURES

homomorphism of G to H exists then graph G is H -colourable. If graph H is k -colourable then we say G is H -colourable and hence, GRAPH H-COLOURABILITY. In fact, homomorphism generalizes graph colourings. As shown in Example 1.4 above, a mapping of vertices of a graph G to k -colouring preserves that f (u) = f (v ), where uv  E (G). Therefore, CSP can be treated as a relational homomorphism problem. For more on the complexity of the graph colouring problem, the reader is directed to [11].

The following definition describes a homomorphism between a pair of relational structures A and B.

Definition 1.2. Let A = (A; R) and B = (B ; R ) be a pair of finite relational structures, where R and R are of the same type. That is, they both contain the same number of relations of the same arity. A homomorphism,

h:AB

is a function which for every k -ary relation symbols Ri in the common type of A and B satisfies,
A B if and only if (h(a1 ), . . . , h(ak ))  Ri . (a1 , . . . , ak )  Ri

We write A  B to indicate that there is a homomorphism h : A  B.

In general, given a pair of relational structures, (A, B) determining the presence of a solution is homomorphism [2, 3]. In which, each relation of A contain tuples of variables. The corresponding relation B contain tuples of values in which the variable tuples may take. 10

CHAPTER 1. INTRODUCTION

1.3. MAL'TSEV OPERATION

Analogous to homomorphism relation, the tuples of variables in A maps to the tuples of values in B. As a result, we have the following definition of CSP in relation to finite relational structure.

Definition 1.3. Let A = (A; R) and B = (B ; R) be a pair of finite relational structures,
A B where R is finitely defined over each structures, as in Ri and Ri , respectively. We define

the relational CSP over B, CSP(B), by:

CSP(B) = {A | A  B}

The homomorphic definition of the CSP, as shown above, gives rise to the relational CSP defined over a particular structure. That is, if we consider a homomorphic from G to H as H -colouring, then according to the definition the problem is equivalent to CSP(H ) [2]. Similarly, if we consider a 3SAT problem with a relational structure A3SAT = (A; Rt1 , . . . , Rt8 ) we have CSP(A3SAT ), where A = {0, 1} and t1 , . . . , t8 are the eight 3-tuples on A.

The Dichotomy Conjecture presented by [9], discussed above, is also applicable to CSPs of relational structures. That is, for any finite structure B, the problem CSP(B) is either NP-complete or solvable in polynomial time. In addition, the method of polynomial time reduction, discussed above, can also be applied to relational structures.

1.3

Mal'tsev Operation

As discussed above, given two general relational structures, a constraint satisfaction problem is a homomorphism problem among the structures. For instance, the truth assignment in 11

CHAPTER 1. INTRODUCTION

1.3. MAL'TSEV OPERATION

satisfying the 3CNF problem discussed above is homomorphism. That is, each clause requires several ternary relations of boolean values that satisfy the formula, .

Let us consider a CSP defined over two general relational structures S and T , in which the homomorphism relation is defined as f : S  T , where T is fixed with a template P . It requires to check, if an input S with template P admits a homomorphism to T [11].

Over the years, researchers in the field have devised several templates in relation to operations like near-unanimity, majority-minority, edge. The edge (or as its known the k -edge) operation is discussed in Chapter 5. In this writing, we consider the ternary operation, Mal'tsev. Hence, we give the following definition over a finite set A.

Definition 1.4. Consider a finite set A and an operation, . A 3-ary operation,  : A3  A, is said to be Mal'tsev if it satisfies the following template, such that:

(x, y, y ) = (y, y, x) = x, for all x, y  A.

The use of the Mal'tsev operation over a finite set invariant under , satisfying all x, y in A, leads to a class of instances of CSP solvable in polynomial time [3]. That is, the constraint problem over the invariant, Inv() or CSP(Inv()) is tractable. For a detailed proof see [3]. As a result, we assume that Mal'tsev operation, as defined above, preserves the relation.

A complete example of a system of linear equations, over a finite field with two elements F2 , is given in Chapter 3. The example also illustrates the use of the Mal'tsev operation 12

CHAPTER 1. INTRODUCTION discussed here.

1.3. MAL'TSEV OPERATION

Several real world constraint satisfaction problems are NP-complete [1]. As a result, much research effort has been put forth in relation to the conjecture made by Feder and Vardi. In closing the chapter on the preliminaries, we give a list of some known CSP instances of class P and NP-complete and related areas of domain, respectively. For details see [1, 6, 12].

Example 1.5. CSP instances of tractable and intractable cases. P, (or polynomial time) problems: LINEAR SYSTEM - A system of linear equations. 2-COLOURABILITY - A complete bipartite graph Km,n , where m and n represents the number of vertices in each set of the partition. 2SAT - The set of satisfiability formulas as in 2CNF.

NP-complete problems: NONLINEAR SYSTEM - A system of nonlinear equations. 3-COLOURABILITY - See Example 1.4 above on k -colouring. 3SAT - The set of satisfiability formulas as in 3CNF. See Example 1.3 above. HAMPATH - A Hamiltonian path in a graph, in which a path visits all vertices exactly once. 13

CHAPTER 1. INTRODUCTION

1.3. MAL'TSEV OPERATION

kCLIQUE - The problem of determining whether a finite graph contains a clique with at least k vertices. For more examples, see [1, 6, 12].

14

Chapter 2 Least Fixed-Point Logic with Rank Operators
In this chapter, we introduce the least fixed-point (LF P ) logic, with rank (rnk ) operators applied on matrices. Further, we discuss the expressiveness of LF P logic with rank operators, LF P +rnk , in comparison to other similar operators like least fixed-point logic with counting, LF P + C . The main source for this chapter is, "Logics with Rank Operators," by Dawar, Grohe, Holm and Laubner [8].

2.1

LFP+rnk and its relation to First-Order Logic

One of the main open problem in descriptive complexity and database theory is the question whether there exist a logic which captures polynomial time [5, 10]. By this we mean, a logic in which precisely those properties which are decidable in polynomial time can be defined. As an initial point, it is reasonable to assume that such a logic must be an extension of first-order (FO) logic, which also admits recursive definitions. We begin by defining a finite

15

CHAPTER 2. LEAST FIXED-POINT, RANK set of relations of a given vocabulary.

2.1. RELATION TO FO LOGIC

Definition 2.1. A vocabulary  is a finite set of relation symbols of R1 , . . . , Rn . Every relation symbol has an arity and a natural number associated to it. That is, an m-ary relational symbol R may be denoted by R(x1 , . . . , xm ).

For simplicity, we assume that a vocabulary can contain constraints and function symbols. Hence, let a vocabulary, containing a finite set of relational symbols, is defined by the set  = {R1 , . . . , Rn }, where Ri is an m-ary relation symbol. Similarly, let the structure of
A A ), where A is a finite domain set and , . . . , Rn the vocabulary ( -structure) be A = (A; R1

Ri is an m-ary relation on A, the interpretation of Ri .

We assume the basic familiarity with first-order (FO) logic, including the basic notation. See [15] for details on the subject. Now, let S be a k -ary predicate symbol not in the ¯ = (x1 , . . . , xk ), vocabulary,  . Next, let the first-order formula, in which S is positive and X ¯ S ). Assuming that A is a finite  -structure, we set the be expressed by the formula (X, initial of the k -ary predicate S to an empty set. The subsequent k -ary predicate is then determined, knowing the fact that the first-order formula , in which the previous k -ary S , is satisfied the structure A ( -structure). Therefore, we define the k -ary predicate S , so that S 0 =  and S i+1 = {a ¯ : A |= (¯ a, S i )}. It is clear that, S 0  S 1  . . .  S i  . . .  A. Since A is a finite set, eventually for some i 0, we have that, S i = S i+1 . Hence, we define S 

¯ S ). As a result, the to be this particular S i and here we call it the least fixed-point of (X, following holds: A |= S  (¯ a) if and only if (¯ a, S  ). 16

CHAPTER 2. LEAST FIXED-POINT, RANK

2.1. RELATION TO FO LOGIC

That is, the least fixed-point obtained by the predicate S (S is not in  ) is satisfied in the structure A ( -structure), if and only if, it is defined by the first-order formula, . It is easy to see the relation between fixed-point and first-order logic (more on this follows). The following example applied on a graph G, demonstrates the concept we have just discussed. It illustrates, the connection of vertices through edge binary relation, E in relation to the first-order formula,  defined above.

Example 2.1. Let G be a finite graph with vocabulary  , containing an edge relation, E . That is,  = {E }. The first-order formula then can be defined as follows:

(x, y, S ) : xEy  z (xEz  S (z, y )).

The first-order formula, expresses that vertices x and y are connected through edge binary relation E , or there exist some vertex z connected to x by an edge relation and z is connected to y through binary predicate relation S . Therefore, S  defines the binary connectedness relation on G and hence the first-order formula, . It is a well-known fact that connectedness in graphs, because of the Compactness Theorem, cannot be expressed in first-order logic [15].

The least fixed-point (LFP) shares some properties with first-order logic. It can be generalized to a finite collection of formulas with distinct positive relational symbols. Consider two relational symbols, S and R, not occurring in  . Next, consider two first-order formu¯ S, R) and 2 (X, ¯ S, R), in which both relational symbols in the formulas las, namely 1 (X, occur positively. Initially, the two relational symbols are empty. By applying simultaneous

17

CHAPTER 2. LEAST FIXED-POINT, RANK

2.1. RELATION TO FO LOGIC

recursion on both symbols, S and R, we obtain the following:

S0 =  R0 =  S i+1 = {a ¯ : A |= 1 (¯ a, S i , Ri )} Ri+1 = {a ¯ : A |= 2 (¯ a, S i , Ri )}

It can easily be observed that, for a sufficiently large i (as i  ), S i = S i+1 and Ri = Ri+1 . Therefore, S  and R can be defined as simultaneous least fixed-points of ¯ S, R) and 2 (X, ¯ S, R), respectively. 1 (X,

Definition 2.2. Suppose, the Least Fixed-Point (LFP) logic consists of relations that are de¯ S1 , . . . , Sk ), for i = 1, . . . , k , are first-order formulas fined as follows. That is, suppose i (X,
   , . . . , Sk ) be the simultaneous least fixed-point , S2 and positive in S1 , . . . , Sk . Now, let (S1   ¯ S1 , . . . , Sk ). Hence, such fixed-points, S1 of first-order formulas of i (X, , . . . , Sk are in LFP.

As a result, the following theorems captures the relation between first-order logic and least fixed-point, and consequently PTIME. Theorem 2.1. [16] (1.) first-order logic  LFP (2.) LFP  PTIME (3.) LFP is closed under the , , , , ¬, substitution and relativization.

18

CHAPTER 2. LEAST FIXED-POINT, RANK

2.1. RELATION TO FO LOGIC

For example, by (1.), we mean that every problem on finite relational structures that can be expressed in first-order logic can be expressed in the logic LFP, and similarly for (2.).

Theorem 2.2. [14, 18] On ordered structures, LFP = PTIME.

In the late 1980s, as an extension of fixed-point logic, Immerman [14] introduced fixedpoint logic with counting operator, FP+C. It seemed to be a suitable candidate for capturing polynomial time. That is, the least fixed-point logic with counting, LFP+C was promising in capturing polynomial time on several classes of structures including planar graphs, structures of bounded tree width. However, the following is true about LFP+C.

Theorem 2.3. [4] LFP+C does not capture polynomial time on all finite structures.

The result of Theorem 2.3 is deep and relies heavily on the construction of the so called CFI-property (after Cai, F¨ urer and Immerman) and used to distinguish LFP+C from polynomial time. As a result, we define an even more expressive expansion of LFP, the logic LFP+rnk . It provides the capability in computing the rank (rnk ) of a given matrix over a general finite field of Fp , defined by a formula over n-tuples, where p is a prime number and n is a positive integer.

Recall, the  -structure discussed above, is defined by A = (A; R1 , . . . , Rm ). We shall equip the structure with an additional integer sort. As a result, we give a general definition of a two sorted structure as follows.

19

CHAPTER 2. LEAST FIXED-POINT, RANK

2.1. RELATION TO FO LOGIC

Definition 2.3. A structure A is a two sorted structure in a finite vocabulary {R1 , . . . , Rm }, where Ri is the ki -ary relation, if A is the union of two disjoint nonempty sets A1 and A2 so that Ri  B1 × , . . . , × Bki where B1 , . . . , Bki  {A1 , A2 }.

Hence, we define A+ , as an extension of A, by the standard model of arithmetic, such that: A+ = (A, , {Ri }i k , +, ·, , 0, 1).

In addition, symbols like `+' and `·' are the usual mathematical operators of addition and multiplication of integers, respectively; and the symbol ` ' is the usual linear order. We shall distinguish the variables coming from A-sort and  -sort. Hence, we will use small letters from the Greek alphabets (like , , , . . .) for the latter case,  -sort. In addition, quantifiers over numerical variables must be bounded in order to prevent undecidability with logical values of 0 (false) and 1 (true).

Note that since 1 (one) is a constant, every n   is definable. Although, the logical formulas are dependent on their truth values, which takes values of 0 (false) or 1 (true). However, it is more convenient to treat the values as numerical terms. As a result, the following definition expresses the concept behind the treatment of the values mentioned.

Definition 2.4. Let  (¯ x, y ¯) be a numerical term defined using both numerical and Avariables (i.e. x ¯ is a tuple containing variables of both sorts, as is y ¯).

Hence, for each pair of tuples a ¯, ¯ b, which may contain elements of both sorts, we define:
A ma a, ¯ b). We consider, M = [ma ¯,¯ b =  (¯ ¯,¯ b ], as an integer-valued matrix, whose rows are

20

CHAPTER 2. LEAST FIXED-POINT, RANK

2.1. RELATION TO FO LOGIC

indexed by |x|-tuples and columns by |y |-tuples, respectively. So, for a prime number, p, let Mp be the matrix, such that: Mp = M (mod p). That is, we can think of Mp as a matrix over the field Fp with p elements and rnkp Mp will be its corresponding rank. Hence, we define LFP+rnkp to the extension of LFP by the operator rnkp . Therefore, if we extend LFP by all rnkp , for p 2, we obtain the extension

LFP+rnk (least fixed-point logic with operator that computes the rank of a definable matrix). The following example, for p = 2, proves that LFP+rnk2 is at least as expressive as LFP+C.

Example 2.2. We show that LFP+rnk2 is at least as expressive as LFP+C. Let (¯ x) be a formula whose free variables x ¯ are of A-sort. In order to determine the number of tuples in A for which (¯ a) is true, we consider the following formula:

(¯ x, y ¯) : (¯ x)  x ¯=y ¯.

Clearly, rnk2 (¯ x, y ¯) will output the number of all a ¯ for which A |= (¯ a).

Hence, we define the following theorem, concluding the expressive power of LFP+rnk over LFP+C. In addition, we make similar list to Theorem 2.1, in relation to the rank of a matrix.

21

CHAPTER 2. LEAST FIXED-POINT, RANK Theorem 2.4. [8] (1.) LFP+C  LFP+rnk (2.) LFP+rnk  PTIME

2.1. RELATION TO FO LOGIC

(3.) LFP+rnk is closed under the , , , , ¬, substitution and relativization

For example, by (1.), we mean that every problem on finite relational structures that can be expressed in logic LFP+C can be expressed in the logic LFP+rnk , and similarly for (2.).

Next, we define a predicate ( ), used in determining the smallest (minimum) value of  , as shown in equation (4.4). For details and descriptions of  , see Chapter 4.

Definition 2.5. Let ( ) be a predicate with a free variable, for some    . Hence, we define min ( ), to be the numerical term (function) in which outputs the smallest value of


   for which ( ) holds.

Therefore, as shown in Theorem 2.1, least fixed-point (LFP) logic is an expressive power extension of first-order (FO) logic. In addition, LFP allows inductive definitions simultaneously, as in recursive functions, while still shares some properties with FO. Note that FO logic uses quantified variables over some non-logical objects. Further, in a topological space, S to contain fixed-point property (FPP), for any continuous function, f : S  S , there must exist s in S , where f (s) = s. Thus, the FPP is a topological invariant and expressed by any homomorphism.

22

CHAPTER 2. LEAST FIXED-POINT, RANK

2.2. OTHER OPERATORS

2.2

Other Operators

The extension of LFP with rank operators, LFP+rnk , has the property that the truth of a formula in any finite structure can be verified in polynomial time. However, instances of similar complexity are not definable in LFP with counting operators, LFP+C. Further, LFP+rnk is equipped with counting capability the dimension of a definable matrix, over a definable vector space. However, the operation of LFP+C just counts the cardinality of a definable set, in which it is already included in LFP+rnk . As a result, LFP+rnk is a generalization of the counting operations, including the operation through matrix determinants. In addition, whenever the fixed-point operations are not present, the rank operator still remains as expressive, as in system of linear equations (linear algebra ).

Further, a chosen type of rank (rnk ) operator defines the rank of a particular matrix over a finite field Fp , where p is a prime number. The variation over n-tuples and the values of p, where n is a positive integer, leads to several possible expressive power of logic that can be defined, as in LFP+rnkp . For instance, in Chapter 4, for p = 2, the least fixed-point logic together with the rank operator, LFP+rnk2 , is used in counting the nonzero entries (rows) of a given matrix. That is, the rank (rnk2 ) is defined over the field F2 over n-tuples. For more details on the properties of the logic LFP+rnk , see [8].

23

Chapter 3 Outline of Bulatov-Dalmau's Algorithm
In this chapter, we present the outline of the "Bulatov-Dalmau's" algorithm as depicted in [3]. The algorithm in consideration depends on five main procedures namely: Solve, Next, Next-beta, Nonempty and Fix-values. The algorithm, together with the sub-procedure calls, provides tractable cases where any finite constraint satisfaction problem (CSP) defined over a finite domain, can be solved in polynomial time. Further, using the procedure Next, it extends to handle general cases where any CSP can be solved in polynomial time. Procedure Next is designed with the intention that the algorithm would handle any cases. Hence, we defer its details while giving priority to the other remaining procedures.

We shall also maintain similar variables, symbols and relative relationships as shown in [3]. As a result, the procedures are reproduced for discussion purposes. We begin by introducing the preliminaries and some basic background in which the algorithm is expressed. We refer the reader to [3] for correctness and proof of the procedures. 24

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.1. PRELIMINARIES

3.1

Preliminaries to the Algorithm

The constraints, for positive integers n, are defined over an n-ary tuple, t = (t1 , . . . , tn ) of elements i1 , . . . , ij in [n] and i  {1, . . . , n}.

3.1.1

Projection of a Tuple

The projection of a tuple over the elements is denoted by (ti1 , . . . , tij ). In addition, for all n-ary relation R defined over a finite domain A and for all elements in [n], the j -ary relation over the projection R is the set defined by {pri1 ,...,ij t : t  R}, where t is a j -ary tuple. In particular, having t and t of two n-ary tuples, the tuples (t, t ) witness (i, a, b) if pr1,...,i-1 t = pr1,...,i-1 t , pri t = a and pri t = b, where (i, a, b)  [n] × A2 .

3.1.2

Signature of Relation

The signature of the relation R is the set containing all those relations witnessed by tuples. That is, the signature of R, denoted by SigR  [n] × A2 , is a set containing tuples (t, t ) that witness (i, a, b), such as:

SigR = {(i, a, b)  [n] × A2 : t, t  R such that (t, t ) witnesses (i, a, b)}.

Note that, every relation R has a compact representation, denoted by R , if |R |

2|SigR |.

In addition, a compact representation R , in which R  R, is a representation of R if SigR = SigR . That is, the existence of tuples in R , in which such tuples witness (i, a, b) means such tuples are also in R, and hence its signature.

25

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

To illustrate the above, consider the projection of a tuple e on j (j -ary relation) satisfying:    a if i = j =   d otherwise, where d  A and (i, a)  [n] × A.

prj ed i,a

2 d That is, the tuples (ed i,a , ei,b ) witnesses (i, a, b), for all (i, a, b)  [n] × A . The compact

representation over the relation An is the set of tuples {ed i,a : i  [n], a  A}. Observe that, a process by the tuples (t, t ) that witness (i, a, b) requires the ternary operation Mal'tsev on all relations on A invariant under .

The following lemma shows that the ternary operation Mal'tsev and the representation of the relation R are the focal points on the construction of the algorithm.

Lemma 3.1. (Bulatov and Dalmau [3]) Let a Mal'tsev operation, over a finite set of domain A be defined as  : A3  A. Let R be a representation of R, where the relation R on A is invariant under . Hence, let R invariant under . Then R = R. The proof to Lemma 3.1 uses the fact that the projection of R and R on i, applied


be the smallest relation R that contains R in which

inductively for all i  {1, . . . , n}, is equivalent. That is, for each tuple in the relation R, having (i, pri t, pri t ) is in SigR means it is also in SigR . See [3] for details.

3.2

Algorithm Detail and its Complexity

The algorithm Solve, as proposed in Theorem 1 of [3], decides correctly whether a constraint satisfaction problem instance invariant under , CSP(Inv()), has a solution in polynomial 26

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

time. The input to the algorithm is a CSP(Inv()) instance, equipped with a set of finite variables, V = {v1 , . . . , vn }, a finite set of domain A and a finite set of constraints, C = {C1 , . . . , C m }. A typical input P , an instance of CSP, is invariant under , where P = (V, A, C ). In addition, the n-ary relation on the domain A is denoted Rl = {(s(v1 ), . . . , s(vn )) : s is a solution of Pl }, where l  {0, . . . , m} and Pl = ({v1 , . . . , vn }, A, {C1 , . . . , Cn }). As a result, initially P0 does not have a constraint and similarly for l = 0, R0 is just An . Note that, a compact representation R0 of R0 is initially encoded almost everywhere, as illustrated above, with an arbitrary value d an element of the domain. A subsequent compact representation Rl+1 of Rl+1 is obtained iteratively, using the procedure Next, in which its input is the current Rl and the constraint relation Sl+1 . The entire algorithm depends on the iterative calls to procedure Next, from with in procedure Solve. We look into each procedure and its related complexity, independently. Finally, we shall conclude that the algorithm is indeed decides correctly if such a solution is found, in polynomial time. We begin our analysis on the outline of procedure Solve.

3.2.1

Procedure Solve

The input to the procedure Solve is described above. Its output is the compact representation of the relation, R after m iterations. That is, if Rm is not empty it returns `yes' (step 4), otherwise it returns `no' (step 5), in which the CSP instance has no solution.

27

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

Procedure Solve({v1 , . . . , vn }, A, {C1 , . . . , Cm }) Step 1 Step 2 Step 3 select an arbitrary element d in A set Ro := {ed i,a : (i, a)  [n] × A} for each l  {0, . . . , m - 1} do let Cl+1 be ((vi1 , . . . , vil+1 ), Sl+1 ) Step 3.1 set Rl+1 := Next(Rl , i1 , . . . , il+1 , Sl+1 ) end for each Step 4 Step 5 if Rm =  return yes otherwise return no

Initially, the compact representation R0 (step 2) is set as illustrated above. Further, for each iteration in step 3, subsequent compact representation Rl+1 is set to a call to procedure Next(Rl , i1 , . . . , il+1 , Sl+1 ). Note that, the return of the calls made to Next is the set, such that: Rl+1 = {t  Rl : pri1 ,...,il+1 t  Sl+1 } where l = 0, . . . , m. As a result, the total running time of the algorithm is polynomial and is related to the size of the input. That is, the total running cost of the call is O(n9 + (n + |Sl+1 |)4 |Sl+1 |n3 ). For proof of correctness and its related time complexity of the algorithm, which is procedure Solve, see [3].

A call to Next, in procedure Solve, makes subsequent calls to Nonempty from procedures

28

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

Next-beta and Fix-values. Hence, next we focus on the procedure Nonempty.

3.2.2

Procedure Nonempty

This procedure takes a compact representation R , of relation R invariant under , a sequence of elements i1 , . . . , ij  [n], (n-arity of R) and a j -ary constraint relation S , also invariant under . The procedure returns either an n-ary tuple t  R, where pri1 ,...,ij t  S or such a tuple does not exist.

Procedure Nonempty(R , i1 , . . . , ij , S ) Step 1 Step 2 Step 2.1 set U := R while t1 , t2 , t3  U such that pri1 ,...,ij (t1 , t2 , t3 )  / pri1 ,...,ij U do set U := U  {(t1 , t2 , t3 )} end while Step 3 Step 4 if t in U such that pri1 ,...,ij t  S then return t else return "no"

Initially, the compact representation R , input to the procedure, is set to U (step 1). As a result, the number of iterations (step 2) is bound by the size of U . The cardinality of U increases by one during the iterative loop in step 2. Thus, U is updated (increased) every time some tuples exist in U invariant under . Hence, at the end of the execution of the procedure, the size of U is different from step 1. Therefore, the number of iteration can be bounded by the size |U |.

29

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

The process of checking the existence of some tuples t1 , t2 , t3 in U (step 2), in which the projection of such tuples invariant under  not in U , is the dominating cost during each iteration. That is, trying all possible combinations of n-tuples found in U , requires |U |3 steps, where each step in turn requires of O(|U |) times. In addition, a sequential search process, in which checking if tuples (t1 , t2 , t3 ) are already in U , requires O(|U |) times. As a result, step 2 has total running time of O(|U |4 n). Recall that, this procedure returns a tuple t in U satisfying pri1 ,...,ij t  S applied on n-ary constraint relations, (step 3). Hence, step 3 has a running time of O(|U ||S |n). Therefore, the procedure has a total running time of O(|U |5 n + |U ||S |n), in which it can be bound by O(|U |5 |S |n). In step 2, as discussed above, the size of the projection of U increases during each iteration. However, it is bounded by the size of the projection of the relation R. Also, recall that the cardinality of the compact representation R is bounded by 2n|A|2 (or |R | 2|SigR |), where A is a finite domain. Since the size of A is fixed, the cardinality of R is of O(n). As a result, the procedure can be bounded by O((n + |pri1 ,...,ij R|)5 |S |n). The output of procedure Nonempty plays a major role throughout the algorithm. In particular, procedures Fix-values and Next-beta depends on the outcome of this procedure, and hence the algorithm. For proof of correctness of procedure Nonempty and its related time complexity, see [3].

3.2.3

Procedure Fix-values

This procedure, unlike the other procedures, takes two sets of objects. That is, a canonical representation of the relation R invariant under  and a sequence of elements of A, a1 , . . . , am , where m n and n is the arity of R. It returns a compact representation of the relation

R, in which initially R is set to Uj (for j := 0). At the end of the iteration, procedure

30

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

Fix-values returns the set Um such that {t  R : pr1 t = a1 , . . . , prm t = am }.

Procedure Fix-values(R , a1 , . . . , am ) Step 1 Step 2 Step 2.1 Step 2.2 Step 2.2.1 set j := 0; Uj := R while j < m do set Uj +1 :=  for each (i, a, b)  [n] × A2 do if t2 , t3  Uj witnessing (i, a, b) and (we assume that if a = b then t2 = t3 ) and Nonempty(Uj , j + 1, i, {(aj +1 , a)}) = "no" and i > j + 1 or a = b = ai then let t1 be the tuple returned by Nonempty(Uj , j + 1, i, {(aj +1 , a)}) set Uj +1 := Uj +1  {t1 , (t1 , t2 , t3 )} end for each Step 2.4 set j := j + 1 end while Step 3 return Um

As described above, in step 1 U0 is set to R , input to the procedure. The iteration starts in step 2 for m n times. Further, a sub-loop (step 2.2) follows for each (i, a, b)  [n] × A2 .

Hence, step 2.2 requires a total iteration of n|A|2 times. However, the most dominating cost during each iteration is the call to procedure Nonempty, in which tuples (t2 , t3 ) in com31

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

pact representation Uj (step 2.2.1) that witness (i, a, b). Recall that, procedure Nonempty returns a tuple, say t1 , where the projection of the tuple is the constraint relation S . The compact representation then updated using the fact that t1 and (t1 , t2 , t3 ) are tuples in the relation R and witnesses (i, a, b). As a result, the cost for each iteration of the loop is O((n + |A|2 )4 n) = O(n5 ). Therefore, the running cost of the procedure can be bounded to O(n7 ).

The correctness of the procedure follows from the fact that a compact representation, Uj = Rj = {t  R : pr1 t = a1 , . . . , prj t = aj }, and proved inductively, for j = 0, . . . , m. For complete proof see [3].

3.2.4

Procedure Next-beta

This procedure is similar to procedure Next and has the worst running time. In addition, it has similar structure to procedure Fix-values. It takes the compact representation R , a sequence of elements of i1 , . . . , ij  [n] and a constraint relation S . In relation to its input size, the procedure might have exponential running time. The procedure returns a compact representation U , in which initially set to empty.

32

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

Procedure Next-beta(R , i1 , . . . , ij , S ) Step 1 Step 2 Step 2.1 set U :=  for each (i, a, b)  [n] × A2 do if Nonempty(R , i1 , . . . , ij , i, S × {a}) = "no" then (let t be Nonempty(R , i1 , . . . , ij , i, S × {a})) Step 2.2 if Nonempty(Fix-values(R , pr1 t, . . . , pri-1 t), i1 , . . . , ij , i, S × {b}) = "no" let t be Nonempty(Fix-values(R , pr1 t, . . . , pri-1 t), i1 , . . . , ij , i, S × {b}) set U := U  {t, t } end for each Step 3 return U

The iteration in step 2 processes each tuple in which (i, a, b)  [n] × A2 . The procedure makes use of the tuples returned by the call to procedures Nonempty and Fix-values (step 2.2). Recall that procedure Nonempty returns a tuple t in the relation R where the projection of t  S . In particular, step 2.1 returns a tuple for (i, a) where pri t = a. Similarly, step 2.2 returns a tuple t in which the projection of t  S for (i, b), where pri t = b. Note that, a sub-call to Fix-values, by Nonempty in step 2.2, returns the compact representation where pr1,...,i-1 t = pr1,...,i-1 t. Hence, if the condition holds then (t, t ) witnesses (i, a, b). Otherwise, (i, a, b) is not in SigR , where R = {t  R : pri1 ,...,ij t  S } invariant under  (discussed in procedure Next). See [3] for details and the necessary conditions. That is,

33

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

conditions for the existence of a tuple t in which (i, a, b)  SigR .

As discussed above, procedure Next-beta is dependent on the outputs of Nonempty and Fix-values. As a result, the running cost of Next-beta is mainly the consequence of these two procedures, also discussed above. The iteration through each tuple in step 2 is n|A| times. The cost of invoking to procedure Nonempty (step 2.1) is O((n + r)4 |S |n), where r = |pri1 ,...,ij R|. However, in step 2.2, Fix-values is called from Nonempty. Hence, it requires the sum of the calls already established above. As a result, the total running time of procedure Next-beta is O((n + r)4 |S |n2 + n8 ). Note that, in addition to step 2.1, a call to Fix-values (step 2.2), which in turn invokes Nonempty (see procedure Fix-values). Hence, it is easy to see that procedure Next-beta has the worst running time. See [3] for details.

3.2.5

Procedure Next

Procedure Next, as discussed above, is designed for general cases of constraint satisfaction problems. Hence, we limit the details of this procedure to the extent where the algorithm in discussion is solvable in polynomial time. See [3] for details.

As shown in procedure Solve above, Next is initially encoded from the compact representation relation R. The input to the procedure includes, the canonical representation R of relation R invariant under , a sequence of elements i1 , . . . , ij  [n] (n-arity of R) and a j -ary relation S , also invariant under . It returns the compact representation U , after some iterative calls to procedure Next-beta.

34

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.2. ITS COMPLEXITY

Procedure Next(R , i1 , . . . , ij , S ) Step 1 Step 2 Step 2.1 set l := 0, Ul := R while l < j do set Ul+1 := Next-beta(Ul , i1 , . . . , il+1 , pri1 ,...,il+1 S ) end while Step 3 return Uj

The procedure makes a series of calls to Next-beta providing Ul , il , . . . , il+1 and its corresponding projection of S , as input. Initially U is set to R (for l := 0). Each iteration in step 2 has the running time of O(n8 + (n + |S |)4 |S |n2 ), in which r is bounded over a fixed A, where r = |pri1 ,...,il S ||A|. Since the possible set of constraint relation S that can appear in instance P is infinite, it is difficult to bound the value of j (j -ary relation). As a result, in the worst case the value of r = |pri1 ,...,ij R| can be exponential. The solution would be to bound the value of j where r can be polynomial over a finite constraints invariant under , CSP(Inv()), see [3] for details.

In Chapter 4, similar approach has been applied over a fixed set of constraints. Hence, let m be the number of constraints and S  be the largest constraint relation occurring in P , instance of CSP invariant under . As shown in Corollary 1 ([3]), the algorithm decides correctly where P is solvable in O(mn8 + m(n + |S  |)4 |S  |n2 ) times. In addition, throughout the algorithm, procedure Nonempty plays the centre of decision making process of the existence of tuple (t, t ) that witnesses (i, a, b).

35

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.3. ILLUSTRATION

We have concluded the sketch of the algorithm. As a result, the details of the procedures clearly shows that the algorithm Solve is indeed tractable. For details see [3]. We conclude the chapter by providing an illustration of the Bulatov-Dalmau's algorithm.

3.3

Example - Illustration of the Bulatov-Dalmau's Algorithm

Next, we provide a simple example of solving a system of linear equations defined over F2 (field with two parameters, 0 (false) and 1 (true)). We assume some basic familiarity with boolean arithmetic over the defined field.

Example 3.1. Consider the following system of three linear equations expressed using four variables, namely x, y, z and u over F2 :

x+z+u=1 y+z =0 y+u=1

We remark that for Mal'tsev polymorphism on F2 , we can take, for instance:

(x, y, z ) = x + y + z.

The above system can be translated into a constraint satisfaction problem (CSP) as a

36

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.3. ILLUSTRATION

pair of Ci (constraints) and Si (constraint relations), defined over a finite domain, as: C1 : (x, z, u), {(1, 1, 1), (1, 0, 0), (0, 1, 0), (0, 0, 1)} S1 = {(1, 1, 1), (1, 0, 0), (0, 1, 0), (0, 0, 1)}

C2 : (y, z ), {(1, 1), (0, 0)} S2 = {(1, 1), (0, 0)}

C3 : (y, u), {(1, 0), (0, 1)} S3 = {(1, 0), (0, 1)} Note that, the number of variables, n = 4 and the number of constraints, m = 3. The compact representation has a solution, if after some iteration Rm = . This is achieved using subsequent calls to procedure Nonempty, as shown in the algorithm.

Initially, we set almost everywhere to d = 0, as shown in procedure Solve, to get initial compact representation, R as:

R0 = {(1, 0, 0, 0), (0, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1)}. Applying iterative process on subsequent relations, we get the next compact representations, as: R1 = {(1, 0, 0, 0), (0, 0, 1, 0), (0, 0, 0, 1), (1, 0, 0, 0)} R2 = {(1, 0, 0, 0), (0, 0, 0, 1), (0, 1, 1, 0)} R3 = {(0, 0, 0, 1), (0, 1, 1, 0)}

37

CHAPTER 3. BULATOV-DALMAU'S ALGORITHM

3.3. ILLUSTRATION

R3 generates the set of all solutions via the Mal'tsev polymorphism. However, it can be easily checked that (0,0,0,1) and (0,1,1,0) are the only solutions and, in fact, the only elements in the subuniverse of (F2 )4 , generated by these two 4-tuples.

38

Chapter 4 Bulatov-Dalmau Algorithm via LFP+rnk
In this chapter, we translate the Bulatov-Dalmau's algorithm in the logic least fixed-point (LFP) with matrix rank (rnk) operator, LFP+rnk . As a result, we show such CSPs are expressible in logic LFP+rnk providing a logical proof such CSPs are tractable. The procedures mentioned below are referring to the original algorithm as shown in [3]. However, we begin by introducing the necessary variables and the corresponding structure of the language in relation to the fixed constraint problem.

4.1

Preliminaries

Recall that constraint satisfaction problem (CSP) consists a finite set of variables V , a finite set of values A, for each of the variables and a set of constraints C between several collections of variables.

39

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.1. PRELIMINARIES

Hence, let V = {x1 , . . . , xk } and C = {C1 , . . . , Cm } with constraints Cl , so that l  [m], where [m] denotes the set {1, . . . , m}. The constraint scope, {x1 , . . . , xk }, corresponds to k -ary relation on the domain A. Each constraint then contains a tuple of variables and the corresponding values in relation to A.

We assume that the structure A admits a 3-ary Mal'tsev polymorphism (x, y, z ). In addition, we assume that  is compatible for all relations in A; namely S1 , . . . , Sm .

Now consider a constraint satisfaction problem C as a finite "initial segment" of  over a two-sorted structure defined as A+ = (, A), where  = {+, ·, <, 0, 1, rnk2 }. An initial segment means that only finitely many elements of  appear in the constraints. The encoding of the constraint satisfaction problem is given in its general form. That is, as a two sorted structure, C can be constructed in logspace and therefore, in polynomial time [16]. The rank of a given matrix, rnk2 is an integer, where rnk2 0 over F2 (the field with two

elements of binary numbers, 0 and 1). Also, A is a finite relational structure which contains the relation S1 , . . . , Sk and all of its elements are constants. Therefore, the constraint pair of the form (x1 , . . . , xk , S1 , . . . , Sk ) is a 2k -ary relation.

We want to construct a sentence (formula without free variables) A , which can contain constants (parameters) from A, such that C |= A if and only if the instance constraint satisfaction problem coded as C has a solution. Thus,  is a 6-ary formula in the two-sorted language and has the following format:

(, y, z, u; , x).

40

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.1. PRELIMINARIES

It contains two variables  and  from the sort of natural numbers and four variables (u, x, y and z ) from the sort A, corresponding to the domain A. The formula  is a compact matrix representation of the solution i  [n], where [n] is a positive integer denoting the set {1, . . . , n}. In particular, (i, a, b, a(or b); , x), for all i n, and a, b  A obtained by

replacing  with parameters 1, . . . , n and y, z, u with values from the domain A. That is, either the assigned parameters to y and u are equal or the parameters assigned to z and u are equal. Hence, a witness for (i, a, b) is referring to the i-th coordinate of a matrix in which it contains the value of a or b. Further, a given matrix then contains 1 whenever the -th coordinate of the tuple is x and 0 otherwise, where  is at most n. The value of n can be obtained by utilizing the counting ability of the logic LF P + rnk , as explained in Chapter 2.

In general, (i, a, b, a(or b); , x) is the n-tuple, where a witness for (i, a, b) contains a or b in the i-th coordinate of a given matrix. Thus, for each i-th coordinate of a matrix, having assigned a or b, it requires 2n overall possible values.

Every time a constraint is processed,  is updated accordingly, and produces a compact representation of the relation R. Hence, let R be the compact representation of the relation, where R  R. The compact representation for the solution requires the processing of two matrices over the values of the domain A. We define the following constant K , representing the number of 4-tuples of parameters i, a, b, and c, where c  {a, b}, such that:

K = 2n|A|2 .

Hence, the collection of K formulas encodes a compact representation for the solution, R . Therefore, as defined above, K is the number of 4-tuples that maintains R . 41

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.1. PRELIMINARIES

We shall define a bijection g from all 4-tuples (i, a, b, c), where c = a or c = b to the set {1, . . . , K }, in the logic LF P + rnk . That is, by using the natural ordering of  and some

fixed ordering (for example, lexicographic) of all triples (a, b, c) from A × A × A, which is independent of n.

Let d be some fixed element in A. Initially, for each matrix we set all those n-tuples which are almost everywhere equal to d, as follows:

(a, d, (d, a, . . .

d, d,

. . . , d) . . . , d)

(b, d, (d, b, . . .

d, d,

. . . , d) . . . , d)

(d, d, . . . , (d, d, . . . ,

a, d,

d) a)

(d, d, . . . , (d, d, . . . ,

b, d,

d) b)

Similarly, the formula (, y, z, u; , x) will consist of, for all values of a and b, if u = a, then:

(i, a, b, a; , x) : ( = i  x = a)  ( = i  x = d) and analogously, if u = b where a replaced with b in the formula (4.1).

(4.1)

Now, consider the following function g , an instance of a bijection from ordered pairs N × N to N: g (i, j ) = ((i + j )(i + j + 1)/2) + i. We can iterate the function g (i, j ) in order to obtain a bijection between N × N × N and 42

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.2. SUPPORTING PREDICATES

N. Further, we can alter this bijection in order to obtain a bijection f , such that, there is a function f which constitutes a bijection between all ordered triples of elements N and N. Hence, we get a bijection f , an instance of ordered triples of a bijection between N and N:

f : N × N × N  {K + 1, K + 2, . . .}.

By iterating this bijection, where K is as described above, we can enumerate the ordered triples in the procedure Nonempty.

We are now in a position to implement the procedures as described in Bulatov-Dalmau's algorithm. However, we shall begin by implementing the preliminaries to the procedures.

4.2

Implementation of Supporting Predicates

Recall that, we have a compact representation of the relation R, denoted by R together with a collection of K tuples as described above. We have also defined some given j integers i1 , . . . , ij and some relation S . Implementation of the procedures requires defining two more relations, namely U ( ) and Coord( ; , x).

Hence, U ( ) applies to integers while Coord( ; , x) applies to integers ,  and an element x  A. These two relations will define the enumeration process of the tuples that can be constructed from the existing elements of U and the ternary Mal'tsev operation . That is, according to the procedure Nonempty, U ( ) will be true if the tuple indexed by  winds up being in U . Similarly, the relation Coord( ; , x) will be true if the -th coordinate of the tuple indexed by  is x. Note that in the logic LFP, we can define several relations

43

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.2. SUPPORTING PREDICATES

simultaneously using least fixed-point iteration. See [16] for details of LFP logic in relation to system of recursions.

The relation U ( ) is defined using the following facts:  = 1, . . . , K or there exists 1 , 2 , 3 less than some  , where such  is equivalent to value found by f (1 , 2 , 3 ). Further, for all  less than  , if U ( ) is true then, for some   {i1 , i2 , . . . , ij } and for all x  A, the tuples indexed by  and  disagree in the  -th coordinate. That is, a tuple indexed by  is in U if it is also in R. Thus, either it is indexed (marked) by one of 1, . . . , K , or it is generated by some three formulas already in U and it does not agree in coordinates i1 , . . . , ij with any of the tuples already in U . The following is then its logical implementation described above: U ( ) :
K

 = i  1 2 3
i=1

(1 <  )  (2 <  )  (3 <  )   = f (1 , 2 , 3 )
j

  <  U ( )  

 = il  x  A
l=1

(4.2)

¬ Coord( ; , x)  Coord( ; , x)

The relation Coord( ; , x) is also defined using the following facts: the coordinate agrees with R if  = 1, . . . , K and the bijection is equivalent to  for the first tuples within 1, . . . , K . Otherwise,  is referring to K +1, K +2, . . . tuples. That is, there exist some 1 , 2 , 3 , where the bijection of such  's is equivalent to  ; and the -th coordinate of the tuples indexed by such  's also agree on x. It is obvious that, the value of x must have been obtained by using the ternary operation, . Further, the second half of the above statement expresses that, if the tuple indexed by  is not one of the original 1, . . . , K found in R, then it must be formed 44

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.3. PROCEDURES VIA LOGIC

using  from some tuples already in U . The logical format of the statement expressed above follows: Coord( ; , x) :
K

 = i  g (i, a, b, c) =   Coord( ; , x)  (i, a, b, c; , x)
i=1



1 2 3 U (1 )  U (2 )  U (3 )   = f (1 , 2 , 3 )  Coord(1 ; , x1 )  Coord(2 ; , x2 )  Coord(3 ; , x3 )  x = (x1 , x2 , x3 )

(4.3)

Note that, the formula  in equation (4.3) was previously defined above, see equation (4.1), also c  {a, b}.

The two relations, namely U ( ) and Coord( ; , x), handles the enumeration process of the tuples as discussed above. Further, the procedures described in the algorithm invokes these two predicates during the process. Next, we implement (translate) the procedures, namely Solve, Nonempty, Next-beta and Fix-values in the logic LFP+rnk .

4.3

Implementation of the Procedures via Logic

We begin by implementing the procedure Solve. We shall implement this procedure from the fact that A satisfies over the two sorted structure if and only if the encoded constraint has a solution over the same structure.

45

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.3. PROCEDURES VIA LOGIC

Solve{x1 ,...,xn },A,{C1 ,...,Cm } : it takes an instance of the constraint satisfaction problem, CSP. The CSP contains a list of variables, the value that the variables takes and the list of the constraints. We aim to construct A , such that:

(, A) |= A if and only if CSP encoded as (, A) has a solution.

That is, the construction of  will satisfy if and only if the constraint over the two sorted structure has a solution. The constraint C , as shown above, is defined over the two sorted structure. In addition, the compact representation of the relation R, denoted by R , contains almost everywhere d  A. That is, initial R0 is encoded as (i, a)  [n] × A, where the rest is d. Hence, let m be the number of constraints, in which it can be obtained by counting all distinct kj -tuples in the numerical (constant) variables that appear during the encoding of the constraints. As shown above, the conjunction of the formula A counts the value of m for which the rank of the matrix, rnk2 is greater than 0. That is, there exists a  up to including K , that satisfies the formula A , where the -th coordinate is x. That is,  K y z u rnk2 ((R, m)(, y, z, u; , x)) > 0. Further, for k = 0, 1, . . . , m the next

(R, k )(, y, z, u; , x) can be recursively defined as follows: · for k = 0, (R, 0)(, y, z, u; , x) is the disjunction of matrix formulas which define n-tuples, which are almost everywhere d; and · for k = k + 1, we have (R, k + 1), such as: ­ an input to the procedure: Next-beta((R,k),i1 ,...,ik+1 ,sk+1 ) (, y, z, u; , x); and ­ a subsequent constraint, where Ck+1 = ((xi1 , . . . , xik+1 ), Sk+1 ).

46

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.3. PROCEDURES VIA LOGIC

Note that, Sk+1 is first-order definable from the encoding of the constraint Ck+1 within the structure (, A). Hence, rnk2 (NonemtyR ,i1 ,...,ij ,S (, x)) > 0 if and only if the matrixconstruct, A contains a non-zero rows in which the encoded CSP has a solution. Similarly, at the end of the iteration where k = m, if Rm is not empty.

We also need to check whether there are tuples in U , which are also in the constraint relation S , when projected on to i1 , . . . , ij . It is clear that, using the ordering (sort) of N, we can find M , the maximum  , for which the relation U ( ) holds. The procedure Nonempty checks if a witness to such tuple exists. If such a tuple does not exist, this particular tuple will be filled with 0(false) at every entry of the matrix.

Next, we implement the procedure Nonempty, for which the tuple witness the above, by defining a new relation formula .

NonemptyR ,i1 ,...,ij ,S (, x) : it takes the compact representation of the relation R, sequence of elements {i1 , . . . , ij }, and a constraint relation S , where the element of the -th coordinate is x. It will be of the form:

1  2

(4.4)

The definition of each of the relation formulas in equation (4.4) follows:

1 :  2 : ¬

M ( )  0 = min( )  Coord(0 ; , x), and


M ( )  ( =   x = x).

47

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.3. PROCEDURES VIA LOGIC

The formula ( ) in the above formulas is the relation defined by:

( ) : i1 , . . . , ik x1 , . . . , xj

U ( )  Coord( ; ik , xk )  S (x1 , . . . , xj ) .

The formula 1 defines the existence of a  fewer than M , where 0 is the minimal for which the assumption (witness) holds, with an element x in the -th coordinate. That is, we select the one with smallest index for tuple that witness this. Similarly, the formula 2 defines that if the relation defined by 1 fails (false), then it is false for all  and x. The formula  is then verifies the existence of such  for the element x.

Next-betaR ,i1 ,...,ij ,S : it takes compact representation R, sequence of elements i1 , . . . , ij  [n] and the constraint relation S ; and produces the updated K formulas for the compact representation.

Now, let the compact representation,  for the relation which consists of all the tuples in R, which have a1 , . . . , am in its first m coordinates, be defined by (m, i, a, b, a(or b); , x). Also note that, for a given matrix P , ai is the element x for which P (i, x), where i = 1, . . . , m. Hence, we construct the formula (k, i, a, b, a(or b); , x) for k = 0, 1, . . . , m.

Note that, for k = m, the formula  is simply . Initially, U0 is equivalent to  and R . That is (0, i, a, b, a(or b); , x) will be (i, a, b, a(or b); , x), in which U0 =  (l := 0, Ul := R ). The next j +1 is expressed from the fact that, if (j, i, a, b, a(or b); , x)

48

CHAPTER 4. ALGORITHM VIA LFP+RN K is defined (true) then (j +1, i, a, b, a(or b); , x), for 0 j m i n  n a, b, x, y, z  A

4.3. PROCEDURES VIA LOGIC j m, will also be true as follows:

(j, i, a, b, a; , x)  (j, i, a, b, b; , y )  rnk2 Nonemptyj ,j +1,i,{(aj+1 , a)} (, z ) > 0  i > (j + 1)  a = b = ai  (j + 1, i, a, b, a; , z )   j + 1, i, a, b, b; , (z, x, y )

The output of the procedure is then the compact representation of the K formulas. Note that, the above formula also includes procedure Fix-values. In which, it takes the compact representation of the relation R, originated from the K tuples over the formula  and an m-tuples (m n) encoded matrix with elements from the domain A.

Hence, the constructed formula  will be satisfied in A if and only if the constraint C over the two sorted structure have a solution. Initially, the compact representation of the relation R0 , encoded as (i, a)  [n] × A, contains almost everywhere d  A. The number of constraints m, can be obtained by counting all distinct kj -tuples that appear during the encoding of the constraints. That is, the conjunction of the formula A counts the value of m for which the rank of the matrix is greater than 0. Further, for k = 0, 1, . . . , m and for  fewer than K , the next constraint relation is defined using (R, k )(, y, z, u; , x), that satisfies the formula A , in which the -th coordinate is x. As a result, Rm will have a solution if and only if the matrix-construct, A contains a non-zero (true) rows.

Therefore, we have shown constraint satisfaction problems defined over a finite Mal'tsev operation are expressible in the logic LFP+rnk . We have also shown a logical proof that such

49

CHAPTER 4. ALGORITHM VIA LFP+RN K

4.3. PROCEDURES VIA LOGIC

CSPs are solvable in polynomial time. Hence, we conclude that Bulatov-Dalmau's algorithm can be formulated in the logic LFP+rnk .

50

Chapter 5 Conclusion and Open Problems
We conclude by providing the summary on the materials discussed so far and open problems in relation to the subject area, constraint satisfaction problem (CSP). Hence, we begin by highlighting the major points discussed in the previous chapters.

5.1

Summary

In Chapter 1, we started by defining the concept behind the constraint satisfaction problem over a finite relational template. We also illustrated the concept by presenting several examples.

The content of Chapter 2 was mainly concerned with the introduction of a natural extension of first-order (FO) logic. In particular, the chapter is more focussed on least fixed-point (LFP) logic, which can express the concept of recursively definable relations on finite structures. In addition to recursion, we gave a basic overview of a further expansion of the expressive power by introducing a two-sorted logic, LFP+rnk . Further, the expansion al-

51

CHAPTER 5. CONCLUSION AND OPEN PROBLEMS

5.2. OPEN PROBLEMS

lows for basic matrix arithmetic over finite fields, including the computation of the rank function (or rank of a matrix).

The outline of the so-called Bulatov-Dalmau algorithm, for solving constraint satisfaction problems on finite templates with Mal'tsev polymorphism, was given in Chapter 3. The exposition of this chapter, in turn, summarizes the results of Bulatov-Dalmau [3]. In addition, at the end of Chapter 3, we provided an example of the application of Bulatov-Dalmau's algorithm on a system of linear equations defined over F2 .

Finally, by putting all of this together, in Chapter 4 we have demonstrated the original work. As a result, we have given the proof that Bulatov-Dalmau algorithm can be formulated in the logic LFP+rnk . Thus, providing a logical proof that Mal'tsev templates gives rise to tractable constraint satisfaction problems. As a result, we concluded the chapter, in which a formula A in LFP+rnk such that, A |= A if and only if CSP(A) is in P. Also note that, it is not known if such formulas exist whenever A is not Mal'tsev or "bounded width".

5.2

Open Problems

The open problems discussed is in relation to the constraint satisfaction problems presented in this writing. That is, a finite CSP invariant over the Mal'tsev operation. Hence, we look into other templates as a natural extension for further research area. The work of [13] shows the application of a k -edge operation (defined below) on Bulatov-Dalmau's algorithm. As a result, we rely on [13] as a primary source over the relational template discussed above. See [13] for further details.

52

CHAPTER 5. CONCLUSION AND OPEN PROBLEMS

5.2. OPEN PROBLEMS

Definition 5.1. ([13]) Let a k -edge operation  on a finite template A be the identities, such that:

(x, x, y, . . . , y )  (x, y, x, y, . . . , y )

 y,

(y, y, y, x, y, . . . , y )  (y, y, y, y, x, y, . . . , y )  · · · · · ·  (y, y, y, . . . , y, x)  y.

If a finite relational template A admits a polymorphism, a k -edge operation for some k > 1, then we say that A has few subpowers.

The Mal'tsev operation (defined in Chapter 1) and near-unanimity are special instances of k -edge operations. In general, a k -edge operations requires a k + 1-ary operations satisfying the identities shown above. A recent algebraic result establishes that every template with few subpowers is tractable.

Theorem 5.1. ([13]) For any finite relational templates A, if A has few subpowers CSP(A) is in P.

The proof of this deep fact relies on the fact that Bulatov-Dalmau algorithm can easily be adopted. Recall that, procedure Fix-values takes pair of objects as input (see Chapter 3). The compact representation can still be maintained, while only modifying the Fix-values in order to accommodate the changes, template A.

Thus, we strongly believe that the answer to the following problem is affirmative. 53

CHAPTER 5. CONCLUSION AND OPEN PROBLEMS

5.2. OPEN PROBLEMS

Problem 5.1. Is the CSP(A) for any finite template with few subpowers expressible in the logic LFP+rnk ? A more general problem is associated with the main open problem in the area, the socalled Dichotomy Conjecture, due to Feder and Vardi. Conjecture. (Dichotomy Conjecture [9]) Every CSP with a finite relational template is either in P or it is NP-complete. To date, all available evidence points to the affirmative answer to this conjecture.

Problem 5.2. Is every CSP which is not NP-complete expressible in logic LFP+rnk ? If the answer to Problem 5.2 is "yes", then the Dichotomy Conjecture holds. That is, every CSP expressible in LFP+rnk is necessarily tractable.

NP-complete CSPs with finite relational templates can be characterized algebraically. That is, CSPs whose templates admit a particular algebraically weak polymorphism, can be reformulated algebraically as the following problem. Problem 5.3. Is the CSP for any finite relational template admitting a weak unanimity polymorphism, in which a polymorphism with the property such that:

w(xx . . . xxy ) = w(xx . . . xyx) = . . . = w(yx . . . xxx),

definable in LFP+rnk ?

54

Bibliography
[1] S. Arora and B. Barak, Complexity: A Modern Approach, Cambridge University Press (2009). [2] A. Bulatov, Mal'tsev constraints are tractable, Technical report PRG-RR-02-05, Oxford University Computing Laboratory (2001). [3] A. Bulatov and V. Dalmau, A simple algorithm for Mal'tsev constraints, SIAM J. Comput. 36(1) (2006), 16­27. [4] J. Cai, M. F¨ urer and N. Immerman, An optimal lower bound on the number of variables for graph identification, Combinatorica 12(4) (1992), 389­410. [5] A. Chandra and D. Harel, Structure and complexity of relational queries, J. Compute. Syst. Sci. 25 (1982), 99­128. [6] T. H. Cormen, C. E. Leiserson, R. L. Rivest and C. Stein, Introduction to Algorithms (2nd Ed.), Massachusetts Institute of Technology (2007). [7] N. Creignou, P. Kolaitis and H. Vollmer (Eds.), Complexity of Constraints: An Overview of Current Research Themes, LNCS 5250, Springer (2008).

55

BIBLIOGRAPHY

BIBLIOGRAPHY

[8] A. Dawar, M. Grohe, B. Holm and B. Laubner, Logics with rank operators, Proceedings of the 24th IEEE Symposium on Logics in Computer Science, IEEE Computer Science Press (2009). [9] T. Feder and M. Y. Vardi, The computational structure of monotone monadic SNP and constraint satisfaction: a study through Datalog and group theory, SIAM J. Comput. 28(1) (1998), 57­104. [10] Y. Gurevich, Logic and the challenge of computer science, in E. B¨ orger (Ed.), Current Trends in Computer Science, Computer Science Press (1988), 1­57. [11] P. Hell and J. Ne set ril, Graphs and Homomorphisms, Oxford Lecture Series in Mathematics and its Applications 28, Oxford University Press (2004). [12] J. Hopcroft, R. Motwani and J. Ullman, Introduction to Automata Theory, Languages and Computation (3rd Ed.), Pearson (2006). [13] P. Idziak, P. Markovi´ c, R. McKenzie, M. Valeriote and R. Willard, Tractability and learnability arising from algebras with few subpowers, SIAM J. Comput. 39(7) (2010), 3023­3037. [14] N. Immerman, Expressibility as a complexity measure: results and directions, in Second Structure in Complexity Theory Conference (1987), 194­202. [15] C. C. Leary, A Friendly Introduction to Mathematical Logic, Prentice Hall (2000). [16] L. Libkin, Elements of Finite Model Theory, Texts in Theoretical Computer Science (an EATCS Series), Springer (2010). [17] D. Poole, A. Mackworth and R. Goebel, Artificial Intelligence: A Logical Approach, Oxford University Press (1998). 56

BIBLIOGRAPHY

BIBLIOGRAPHY

[18] M. Y. Vardi, The complexity of relational query languages, in Proc. of the 14th ACM Symp. on the Theory of Computing (1982), 137­146.

57

