DEVELOPMENT AND DEMONSTRATION OF AN ENERGY FEEDBACK RESEARCH PLATFORM IN A FIELD STUDY WITH REAL-TIME SOCIAL COMPARISONS

By Kevin Trinh Master of Applied Science University of Toronto, 2010 Honours Bachelor of Applied Science University of Waterloo, 2005

A thesis presented to Ryerson University

In partial fulfillment of the requirements for the degree of MASTER OF APPLIED SCIENCE In the program of Building Science

Toronto, Ontario, Canada, 2016 © Kevin Trinh, 2016

Author's Declaration

I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final versions, as accepted by my examiners.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

Kevin Trinh

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my thesis may be made electronically available to the public.

Dated: ___________________

Kevin Trinh

ii

DEVELOPMENT AND DEMONSTRATION OF AN ENERGY FEEDBACK RESEARCH PLATFORM IN A FIELD STUDY WITH REAL-TIME SOCIAL COMPARISONS

Kevin Trinh Master of Applied Science Program of Building Science Ryerson University, Toronto, Ontario, Canada, 2016

Abstract
Providing residential tenants with feedback on their energy use can be an effective intervention, promoting savings ranging from 4-12%. However, advancements in feedback design have been hindered by methodological limitations, the lack of specification of visual feedback designs, and a poor understanding of the behaviour changes that are induced by feedback. This thesis presents the design and demonstration of an Internet-of-Things-based feedback research platform, which was intended to help address these issues, and which will be made freely available for re-use and reconfiguration. Configured for a rental apartment building in Toronto, Canada, the platform was a central component of a conservation program and field study examining the efficacy of real-time social comparisons. Results showed a statistically significant effect of the conservation program with a relative year-over-year, weather-normalized savings of approximately 11%. An encouraging, but non-significant, finding of a 3.5% relative improvement with real-time social comparisons warrants future large scale studies.

iii

Acknowledgements

This thesis would not have been possible without the help of many people. First I would like to thank my supervisors Prof. Alan Fung and Prof. Vera Straka for providing guidance and a tremendous and timely opportunity. I would also like to thank the members of my project team: Dr. Sara Alsaadani, Samira Zare Mohazabieh. To Danilo Yu, Gabriel Leong, and Edward Vuong, thank you for your friendship and technical assistance in setting up this study. To the ever hospitable staff at Phoenix Place, Predrag Milenkovic and Glenda Moore: I only hope to have demonstrated your cooperation and trust in me was wise. A special thank you to Dr. Winnie Chen for more than refreshing me on statistical analyses. I would like to acknowledge our project sponsors: Canada Mortgage and Housing Corporation (CMHC), Ontario Ministry of Municipal Affairs and Housing (MAH), City of Toronto, Enbridge Gas Distribution Inc., and MITACS. To Wendy: as I've written before, I cannot say thank you enough. Your unfailing support made this journey possible. Finally, to Amber: I hope this work may one day demonstrate and instill in you the values of courage and perseverance.

iv

Contents
AUTHOR'S DECLARATION ...................................................................................................................................... II ABSTRACT ............................................................................................................................................................. III ACKNOWLEDGEMENTS ......................................................................................................................................... IV CONTENTS ............................................................................................................................................................. V LIST OF FIGURES..................................................................................................................................................VIII LIST OF TABLES ...................................................................................................................................................VIII LIST OF ABBREVIATIONS ....................................................................................................................................... IX 1. 2. INTRODUCTION ............................................................................................................................................. 1 LITERATURE REVIEW ..................................................................................................................................... 5 2.1 2.1.1 2.1.2 2.1.3 2.2 2.2.1 2.2.2 2.2.3 2.2.4 2.3 3. ENERGY BEHAVIOURS.........................................................................................................................................5 Behaviour Taxonomies ........................................................................................................................5 Behaviour Change Challenges .............................................................................................................7 Behavioural Models .............................................................................................................................8 ENERGY FEEDBACK ..........................................................................................................................................11 How feedback works .........................................................................................................................11 The different dimensions of energy feedback ....................................................................................12 Feedback in context: Frameworks and Complementary Engagement Strategies .............................14 Summary of literature review on good feedback ..............................................................................19 WHERE DO WE GO FROM HERE? ........................................................................................................................20

FEEDBACK RESEARCH PLATFORM DESIGN ................................................................................................... 22 3.1 3.2 3.2.1 3.2.2 3.2.3 3.2.4 3.2.5 3.2.6 3.3 3.4. PLATFORM TECHNICAL REQUIREMENTS ...............................................................................................................22 OPEN SOURCE PROJECTS AND FREE UTILITIES .......................................................................................................26 The Open Energy Monitor Project .....................................................................................................26 SafePlugs ...........................................................................................................................................30 Open Data Kit for Surveys ..................................................................................................................31 Android App .......................................................................................................................................32 Web / Android Analytics ....................................................................................................................33 Weather Data ....................................................................................................................................33 SYSTEM ARCHITECTURE ....................................................................................................................................34 IMPLEMENTATION AND MAINTENANCE SKILLS REQUIREMENTS ................................................................................34

v

4.

PROJECT IMPLEMENTATION AT PHOENIX PLACE ......................................................................................... 36 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.7.1 4.7.2 4.7.3 MURBS CONTEXT ..........................................................................................................................................36 PHOENIX PLACE ­ HISTORY AND FACTS ...............................................................................................................38 RESULTS FROM A POST OCCUPANCY EVALUATION AT PHOENIX PLACE .......................................................................40 THE CBSM FRAMEWORK IN APPLICATION ...........................................................................................................41 SUMMARIZING THE FEEDBACK DESIGN CONTEXT, OBJECTIVES, AND CONSTRAINTS ......................................................43 MEASURING THE IMPACT OF THERMAL COMFORT .................................................................................................44 FEEDBACK DESIGN PROCESS ..............................................................................................................................45 Iteration 1 ­ Heuristic Design ............................................................................................................46 Iteration 2 ­ Usability Test Prototype based on Initial Feedback ......................................................52 Iteration 3 ­ Final Prototype for Field Study ......................................................................................54

5.

FIELD STUDY DESIGN AT A MURB IN TORONTO ........................................................................................... 58 5.1 5.2 5.3 5.4 5.5 5.6 5.7 HYPOTHESES ..................................................................................................................................................58 EXPERIMENT DESIGN .......................................................................................................................................59 RECRUITMENT AND PARTICIPANTS ......................................................................................................................59 PROCEDURE ...................................................................................................................................................60 EQUIPMENT AND INSTALLATION .........................................................................................................................62 MEASURES ....................................................................................................................................................65 THERMAL COMFORT MEASURES ........................................................................................................................65

6.

RESULTS AND DISCUSSION .......................................................................................................................... 67 6.1 6.2 6.3 6.4 6.5 6.5 6.6 SYSTEM PERFORMANCE ....................................................................................................................................67 PARTICIPANT NOISE AND VARIABILITY ..................................................................................................................67 CONSERVATION PROGRAM: ENERGY SAVINGS ......................................................................................................68 TEST OF HYPOTHESIS 1 ­ THE EFFECT OF THE CONSERVATION PROGRAM...................................................................69 TEST OF HYPOTHESIS 2 ­ THE EFFECT OF SOCIAL COMPARISONS ..............................................................................72 EXPLORATORY ANALYSIS OF ENGAGEMENT...........................................................................................................74 EXIT SURVEY RESULTS ......................................................................................................................................75

7.

CONCLUSIONS ............................................................................................................................................. 77 7.1 7.2 CONTRIBUTIONS .............................................................................................................................................78 FUTURE WORK ...............................................................................................................................................79

APPENDIX A ­ RECRUITMENT POSTER ................................................................................................................. 83 APPENDIX B ­ CONSERVATION PROGRAM CONSENT FORM ................................................................................ 85

vi

APPENDIX C ­ FIELD STUDY CONSENT FORM ....................................................................................................... 88 APPENDIX D ­ CONSERVATION PROGRAM PRESENTATION SLIDES ...................................................................... 93 APPENDIX E ­ ENERGY TRACKING PRESENTATION SLIDES.................................................................................... 98 APPENDIX F ­ NEP AND DEMOGRAPHICS SURVEY ............................................................................................. 101 APPENDIX G ­ PLEDGE FORM............................................................................................................................. 105 APPENDIX H ­ THERMAL COMFORT SURVEY ..................................................................................................... 107 APPENDIX I ­ ENERGY AUDIT SAMPLE RESULTS ................................................................................................. 112 APPENDIX J ­ USABILITY TEST SCRIPT ................................................................................................................ 114 APPENDIX K ­ EXIT SURVEYS .............................................................................................................................. 120 APPENDIX L ­ RESEARCH ETHICS BOARD APPROVAL LETTERS ............................................................................ 123 REFERENCES....................................................................................................................................................... 126

vii

List of Figures
Figure 1-1: Examples of different feedback approaches .............................................................................. 1 Figure 2-1: Heuristic model of environmentally relevant behavior.............................................................. 8 Figure 2-2: Simplified default construal-time relationship based on temporal construal theory .............. 10 Figure 2-3: Household savings broken down by feedback type ................................................................. 13 Figure 3-1: Open Energy Monitor system components and connectivity .................................................. 27 Figure 3-2: emonTx V3 ruggedized power and temperature sensing now ................................................ 29 Figure 3-3: emonTH temperature and humidity, battery-powered sensing node ..................................... 30 Figure 3-4: SafePlug Home Energy Manager Kit ......................................................................................... 31 Figure 3-5: System architecture for the feedback research platform ........................................................ 34 Figure 4-1: Typical floor plan at Phoenix Place ........................................................................................... 39 Figure 4-2: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 1 ................................... 46 Figure 4-3: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 1 ..................................... 47 Figure 4-4: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 2 ................................... 52 Figure 4-5: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 2 ..................................... 53 Figure 4-6: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 3 ................................... 55 Figure 4-7: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 3 ..................................... 55 Figure 4-8: Basic Feedback Display 1 of 2 ­ Total Suite Energy Use ........................................................... 57 Figure 4-9: Basic Feedback Display 2 of 2 ­ Fan Coil Unit - Energy Use...................................................... 57 Figure 5-1: Architecture for the system installed at Phoenix Place ............................................................ 63 Figure 5-2: Rich-picture diagram of feedback hardware ............................................................................ 63 Figure 6-1: Aggregated year-over-year savings by feedback condition ..................................................... 69 Figure 6-2: Error bar graph of experimental condition on savings percentage.......................................... 70 Figure 6-3: Box plot of experimental conditions on savings percentage ................................................... 71 Figure 6-4: Error bar graph of feedback condition on savings % ................................................................ 72 Figure 6-5: Savings and Engagement by Quarter........................................................................................ 74

List of Tables
Table 2-1. Energy Behaviors as a Function of Frequency and Cost............................................................... 6 Table 2-2. Distinguishing Low-Level and High-Level Construals. ................................................................ 10 Table 2-3. Selecting Tools Based on Barriers and Benefits. ........................................................................ 15 Table 4-1. Johnson Controls Enviro-Tec Model VFE Size 20. 115 Volts. ..................................................... 45 Table 5-1. Participant breakdown by Experimental Group, Gender, Place of Birth, and Age ................... 60

viii

List of Abbreviations
ANCOVA API CBSM CMS COP CT EE FBRP FCU FOSS GSHP HEMS HCI HF HLC HVAC IDE IoT LLC MECHanisms MURB NEP POE TCT Analysis of Covariance Application Programming Interface Community-Based Social Marketing Content Management System Coefficient of Performance Current Transformer Energy Efficient Feedback Research Platform Fan Coil Unit Free and Open Source Software Ground Source Heat Pump Home Energy Management System Human-Computer Interaction Human Factors High-Level Construals Heating, Ventilation, and Air Conditioning Integrated Development Environment Internet of Things Low-Level Construals Make Energy Change Happen Multi-Unit Residential Building New Environmental Paradigm Survey Post Occupancy Evaluation Temporal Construal Theory

ix

1. Introduction

Research in energy conservation behaviours for building inhabitants burgeoned during the 1970's energy crisis to reduce dependence on foreign oil. As climate change has emerged on the political agenda in recent years, energy conservation has also regained traction; and is now acknowledged as perhaps the most cost-effective way of reducing greenhouse gas emissions (IEA, 2010). In the field of residential energy conservation, providing tenants with feedback on their energy use has been demonstrated as an effective intervention with savings ranging from 4-12% (Ehrhardt-Martinez, Donnelly, & Laitner, 2010). When considering that Canadian residential sector consumes 410 TWh of energy per year (Government of Canada, 2012), a 4-12% savings amounts to approximately 16-49 TWh. In Toronto, Canada, the current flat-rate, post-tax, marginal price for delivered electricity is approximately 0.14 $/kWh. This means with feedback there is a potential to save residential consumers $2.3B to $7.0B. In addition to the political and social influences on energy conservation research, technological advances have also enabled new ways to promote conservation, with feedback as a key strategy. In the past several years, on the strength of the smart grid technology and advanced metering infrastructure, industry has produced many feedback instruments on the market. These have ranged from smart bills, in-home displays, to web-based dashboards. Figure 1-1 shows an example in each of these categories.

Figure 1-1: Examples of different feedback approaches (From left to right). OPOWER paper bill shows neighborhood comparisons. Aztech In-Home Display shows aggregate home energy consumption. LucidDesign Building Dashboard is a web-based portal offering interactive views of energy use.

1

However, despite the many commercial implementations of feedback and a plethora of studies on the efficacy of feedback approaches, researchers (Ehrhardt-Martinez et al., 2010; Fischer, 2008; Flemming, Hilliard, & Jamieson, 2008) have pointed to two key challenges that have limited our understanding of how best to design feedback. First, methodological problems have hindered consolidation of the literature. In her review of 26 original feedback projects Fischer (2008, p. 87) writes: "[Feedback projects] differ markedly with respect to study design, sample, and method of data gathering, differences occurring both in substance and in scientific elaborateness. What is more, results are not always reported quantitatively or in sufficient detail to make a comparison. And if they are reported, studies use very diverse reporting schemes. They vary in baseline, in time and duration of measurement, and in the unit for which savings are reported." Second, there is no consensus on how best to visually design feedback. Feedback designs range from traditional quantitative representations (e.g., charts and graphs) to artistic, data-driven renderings of energy. Furthermore, design decisions on graph choice, measurement units, or wording may also impact user satisfaction, and overall adoption of the feedback. Unfortunately, very few studies have focussed on evaluating such design decisions. While it could be argued that this second challenge is being addressed through the success or failure of commercial products, market capitalization can often mask the underlying reasons for these outcomes ­ with the design of a product being only one such reason. Business models, marketing campaigns, regulatory landscape, and strategic partnerships are often major factors that can impact the wide adoption of a company's product. For example, while OPOWER's paper bills commercial success can be attributable to their science-driven design, it has also been written how they have been able to navigate the regulatory landscape in the US requiring utilities to cost-effectively induce energy conservation (e.g., St. John (2014), Tweed(2015)) A third challenge, identified by Ehrhardt-Martinez (2012), reflects the lack of details known about behaviours induced by feedback. As will be detailed later, a popular dichotomization of behaviours distinguishes between efficiency and curtailment behaviours. However, this dichotomy does not describe the variety of ways in which technology can be used, maintained, or interchanged (ibid). Without a clear understanding of how feedback can be designed to shape behaviour, it is likely difficult

2

to make optimal design choices. As utilized in Ehrhardt-Martinez's study, surveys are an effective method to understand these nuanced behaviour changes. Any one of these challenges described above is worthy of further exploration. Interestingly, a common theme in all three is that they fundamentally point to methodological limitations of past feedback research. What appears problematic is that these limitations have also made it difficult for feedback researchers to advance the state of the art and science on feedback design and on maximizing the potential of feedback strategies. While there is no straightforward solution to any of these challenges, it is clear that a common platform on which feedback research was conducted could help advance the field more rapidly and with coherence. The goal of the feedback research platform would be to afford a systematic approach to evaluating feedback designs given the wide variety of contexts possible. Having the platform freely available should also help it grow a community of researchers to further support this agenda. The development of such a feedback research platform is the purpose of this thesis. While on the surface this may appear overly ambitious (and perhaps it is!) and the platform unwise to freely share (and perhaps that is the case too!) there are two key socio-technical developments that have helped enable and inform this objective: The Internet of Things (IoT), and free and open source software (FOSS). The IoT refers to the interconnection of electronic devices (e.g., energy or indoor environment sensors) through the Internet. The movement towards an IoT has increased access to sensors and wireless communication technologies enabling the cost-effective collection of real time and disaggregated energy data amongst other applications. In conjunction with web-enabled mobile devices (i.e., smart phones, tablets), energy feedback can be as easily delivered as a consumer phone app is to download. FOSS (e.g., Linux, GIMP) is software available to use, copy, study, and modify for free. This is in contrast to proprietary software (e.g., Windows, Photoshop), which is restricted under copyright and has source code hidden from users. FOSS communities have developed with the belief that their approach fosters learning, collaboration, community, and innovation. As will be discussed in Chapter 3, the feedback research platform leverages several FOSS projects with an IoT focus. So it is with the same spirit, that the feedback research platform will be shared back to the FOSS community and to the energy feedback research community. In addition to helping address the three challenges discussed above, the FOSS-IoT-based platform developed in this thesis will be tailored to provide near real-time social comparisons. Real-time social

3

comparisons, to the author's knowledge, has not been evaluated in conjunction with feedback. As will be described later, this focus was enabled due to the homogenous nature of the suites at the target building. For the purposes of a larger project initiative the feedback research platform was customized to measure the impact of thermal comfort and relevant feedback on energy use. Thermal comfort is an important topic because it is both visceral and energy intensive; heating and cooling related energy use accounts for 65% of energy use in Canadian homes (Government of Canada, 2012). To accommodate this objective, the platform incorporated in-situ surveys to help understand thermal comfort related behaviours as well as a complementary dashboard on fan coil unit (FCU) usage as the FCU is the primary way participants maintain comfort in their suites. Chapters 4 and 5 include descriptions of the design aspects of the platform related to thermal comfort as was implemented in the field study; however, the analysis of thermal comfort data was outside this thesis's scope. The rest of this thesis is outlined as follows. Chapter 2 summarizes a literature review of feedback research to help provide guidance on the requirements and also inform best practices for feedback design and delivery. Chapter 3, based on the identified requirements, describes an architecture and design for the platform. This is followed by a matching of open source projects. Chapter 4 then describes an implementation of the platform as part of an energy conservation program in a multi-unit residential building (MURB). Chapter 5 details the field study methodology used in the study. Chapter 6 reports the results of the field study. Finally, Chapter 7 reviews the contributions from this work and outlines a way forward.

4

2. Literature Review

The purpose of this chapter is to review the literature surrounding energy feedback to provide a better understanding of its history, target behaviour changes, the different characteristics of feedback, as well as how it can be supplemented by or used to supplement other motivators for conservation. This bulk of literature review draws from several key reviews on feedback (Abrahamse, Steg, Vlek, & Rothengatter, 2005; Darby, 2006; Ehrhardt-Martinez et al., 2010; Fischer, 2008) amongst others. A brief overview of the various topics and a summary of key takeaways are discussed in the forthcoming sub-chapters.

2.1

Energy Behaviours

This chapter reviews the predominant views on behaviour including taxonomies, challenges to eliciting behaviour changes, and models that can guide feedback design.

2.1.1 Behaviour Taxonomies
To encourage residential energy conservation, it is useful to first identify and understand the different types of conservation behaviours. Gardner and Stern (1996) divide these into two categories: efficiency and curtailment behaviours. Efficiency behaviours are one-time behaviours associated with initial capital investment in energy saving technologies such as home insulation or energy efficient appliances. Curtailment behaviours involve repeated or frequent efforts to reduce energy consumption, such as turning off lights or unplugging appliances when not in use. While the bulk of past studies target curtailment behaviours it is worth noting that efficiency behaviours are considered to have greater energy-savings potential (Ehrhardt-Martinez et al., 2010). For example, installing compact fluorescent light bulbs will likely save more electricity than promptly turning incandescent bulbs off when they are not in use. However, efficiency behaviours do not necessarily result in net energy savings if, for example, energy efficient appliances are used more frequently than less-efficient models. This is an example of the rebound effect (Moezzi & Diamond, 2005): the often counter-productive behavioural response to the introduction of new, more efficient technologies.

5

Ehrhardt-Martinez et al. (2010) provide a more detailed breakdown by frequency and cost as shown in Table 2-1. They define habitual behaviours as frequent and low-cost. Energy stock-taking behaviours are infrequent but are still low-cost. Finally, consumer behaviours such as upgrading windows and appliances happen infrequently but are higher in cost.
Table 2-1. Energy Behaviors as a Function of Frequency and Cost. Adapted from (Ehrhardt-Martinez et al., 2010)

Infrequent Actions Low-Cost / No Cost Energy Stocktaking Behavior Install CFLs, Pull fridge away from wall, Inflate tires adequately, Install weather stripping Higher Cost / Investment Consumer Behavior New energy efficient (EE) windows New EE appliances Additional insulation New EE AC or furnace

Frequent Actions Habitual Behaviors and Lifestyles Slower highway driving Slower acceleration Air dry laundry Turn off devices

In a more recent study, Ehrhardt-Martinez (2012) argues for a need for further classification based on the multitude of ways in which technology can be used, maintained, or interchanged. In so doing, this classification provides a more nuanced perspective by which householders can achieve feedbackinduced energy savings. The nine classes of actions include: 1. alternative technology choices 2. conservation behaviour 3. conservation settings 4. enhanced control 5. investment 6. low cost investment 7. turn off 8. unplug

6

2.1.2 Behaviour Change Challenges
While having a grasp of behaviours that feedback can influence is essential, it is also necessary to review why behaviour change can be difficult. With this context, designers can begin thinking about how such obstacles may be overcome when designing feedback. In this chapter, five key behavioural challenges are reviewed. 1. Energy is invisible. Energy use is embedded in our buildings, our food and our transportation systems. Yet it is largely invisible; most people do not think or talk about the energy they use. This makes it difficult to consciously save energy. The operating hypothesis of feedback is that it helps to make energy use visible. However, it does not help that feedback on energy use has been typically infrequent, delayed from the time of consumption, and only reaches those who pay the energy bills. 2. Energy is cheap. In Toronto, Canada, the current flat rate, marginal price for delivered electricity is about $0.14/kWh. This puts the cost of watching an hour of television on a modern 42" LCD HDTV at about three cents. It can be argued that unless prices rise substantially, it will be tough to motivate people to conserve. 3. Split incentives do not foster conservation behaviours. In rental housing situations, there is no direct financial motivation for tenants to conserve since they pay only flat rental rate regardless of their energy usage. Landlords may be reluctant to invest in energy efficient appliances as those have higher upfront costs. In many cases if there is nothing broken, it will not be fixed or upgraded. 4. The invisibility of energy leads to poor mental models and habits. The invisibility of energy use can lead to poor energy use habits (Verplanken & Wood, 2006) because the environment was not at the forethought at the time those habits were developed. This is especially problematic because most residential energy is consumed through routine and habitual behaviour (Lutzenhiser, 1993; Sauer, Wiese, & Ruettinger, 2003). Ordinary people may also develop faulty mental models of how energy is consumed; relying instead on folk theories that often lead to sub-optimal energy use (Karjalainen & Vastamaeki, 2007; Kempton, 1986). Kempton (1986) found that between 25-50% of Americans believe that a thermostat works like a valve, in that a higher temperature setting will deliver heat at a faster rate than a lower setting. However, many conventional residential heating and air conditioning systems produce or remove heat at a constant rate, and can only be turned on or off by the thermostat. 7

5. Visceral Influences compete against conservation goals. Even if residents can be made conscious of their energy consumption, visceral influences can compete with conservation behaviours at the point of consumption (Trinh & Jamieson, 2014). Visceral influences (Loewenstein, 1996) such as inconvenience, fatigue, or physical discomfort focus attention on the immediate and direct hedonic impact of behaviours rather than long term objectives. At sufficient intensity, visceral influences can cause people to act contrary to their proenvironmental attitudes in favour of impulsive behaviours. This effect is compounded as many energy consuming technologies are intentionally designed to be viscerally attractive to use (Norman, 2004).

2.1.3 Behavioural Models
If designers are to address the behavioural challenges identified above, it is helpful to have a theoretical basis on how decisions and behaviours are formed. Toward this end, environmental psychology researchers have developed models to understand how environmentally relevant behaviour change can be obtained. One such heuristic model, as shown in Figure 2-1, is discussed by Fischer (2008).

Figure 2-1: Heuristic model of environmentally relevant behavior Adapted from Fischer (2008)

This heuristic model distinguishes between habits and conscious decisions and recognizes that habits, while not reflected upon consciously, influence the decision making process. What is particularly useful 8

in this model, is the acknowledgement that for new norms to be activated, they must be consciously reflected on. This reflection process has three parts. First, the person must realize there is a problem. Second, the person must realize that his/her behaviour is relevant to the problem. Third, the person must have a sense of control, acknowledging the possibility to have influence. Once this norm activation process is completed, the person enters an evaluation process where he/she must weigh various motives that may be in conflict with one another. Such motives may include personal norms, social norms, or other motives such as comfort or convenience. What is not explicit in the model is that considerable amount of information is necessary to perform the decision process. However, this is why feedback can have such an influential role. Feedback can interject the process with information to raise awareness to inform new norms and break old habits. Some caution should be identified with this model, though, as it assumes a rational decision-making process. From the field of behavioural economics, we learn that decisions are not always consistent as the rational model would have us believe. Rather, cognitive biases and decision-making heuristics are known to lead to sub-rational decisions. As Trinh and Jamieson (2014) identify, the outcomes of the decisionmaking process vary, also in part, as a function of temporal distance. For example, one might make deliberate plans to take the stairs for health or environmental reasons; but, at the moment of decision for convenience, succumb to using the elevator. Trinh (2010) adopted temporal construal theory (TCT) (Liberman & Trope, 1998) to help characterize the effect of visceral influences. TCT describes how temporal distance systematically changes people's mental representations (i.e., "construals") and associated valuations of future events. TCT posits that an increased temporal separation from an event or activity shifts preferences to more abstract goals. Conversely, more temporally immediate events are associated with contextualized features that are more concrete. These features are examples of high level construals (HLCs) and low level construals (LLCs), respectively (see Figure 2-2). HLCs are relatively simple, decontextualized representations that consist of general, superordinate (i.e., goal relevant, "why" features), and essential features of events (Trope & Liberman, 2003). By contrast, LLCs are akin to visceral influences in that they are more concrete and include subordinate, contextual, and incidental features of events. For example, composting may bring about HLCs such as environmental preservation or financial benefits (reasons why

9

one would want to compost) but may also evoke LLCs such as negative thoughts of dirt and odors (contextual factors associated with the act of composting).
Table 2-2. Distinguishing Low-Level and High-Level Construals. Adapted from Trope and Liberman (2003)

Low-level Construals (LLCs) Concrete Complex Unstructured, Incoherent Contextualized Secondary, Surface Subordinate ("how") Goal Irrelevant

High-level Construals (HLCs) Abstract Simple Structure, Coherent Decontextualized Primary, Core Superordinate ("why") Goal Relevant

Figure 2-2 shows a highly simplified time-construal function, depicting the conflicting impacts of HLCs and LLCs on decisions over time. In the near future, LLCs spurred by visceral influences have more impact on decisions than HLCs. In the distant future, HLCs representing one's attitudes towards conservation have more influence than LLCs. For stubborn or habitual consumption behaviours Trinh and Jamieson (2014) posit that the default time perspective is typically near term, as represented in Figure 2-2 by the dotted line in the near future.
Time perspective held when making decisions for near-future behaviors Goal-aligned HLCs influence decisions of distant-future behaviors more than LLCs

Influence on Decision

(near future)

(distant future)

Goal-conflicting LLCs influence decisions of nearfuture behaviors more than HLCs

Time from Decision
Figure 2-2: Simplified default construal-time relationship based on temporal construal theory Adapted from Trinh and Jamieson (2014)

The visual representation of TCT in Figure 2-2 leads to some distinct insights. First, it suggests an explanation for a related finding in energy conservation research; that attitudes do not necessarily predict behaviours (Gatersleben, Steg, & Vlek, 2002; McKenzie-Mohr, 2011). Second, the representation

10

forms the basis of a conceptual framework to help characterize four strategies for behavioural interventions in energy conservation (Trinh, 2010) When considering both Fischer's and Trinh's models together, one can begin envisioning how feedback might operate. From Fischer's model she points that feedback can direct attention towards a problem and increase the consciousness of the relevance of one's behaviour. It may also motivate, for example, a sense of competition or incent behaviours through the use of comparison or goal settings, respectively. Trinh's model points to the importance of frequent feedback. It also points to how feedback can be framed to target conservation motives. The following chapter was dedicated to providing a more full characterization of energy feedback. In the meanwhile and in agreement with Fischer (2008), from these considerations, one can deduce the hypotheses that feedback is most effective if:    It successfully captures the user's attention Draws a close link between specific behaviours and their effects Activates various HLCs or motives that may appeal to different user groups, such as cost savings, resource conservation, emissions reduction, competition and others.

2.2

Energy Feedback

Chapter 2.1.3, through a review of decision-making models, identified the potential for how conservation behaviour challenges can be addressed with feedback. This chapter deals with how feedback works, its different dimensions, and how it has been used in context.

2.2.1 How feedback works
As mentioned earlier energy feedback has been demonstrated as an effective intervention with savings ranging from 4-12% (Ehrhardt-Martinez et al., 2010). To justify the approach and explain findings, much of the early feedback research sought to describe the psychological mechanisms that feedback supported. The most predominant of these is that feedback facilitates learning by making the invisible visible (Abrahamse et al., 2005; Benders, Kok, Moll, Wiersma, & Noorman, 2006; Darby, 2006; Holmes, 2007; Katzev & Johnson, 1987). While some aspects of energy use in the home are highly visible, other aspects are largely hidden from view. For example, the energy consumed from a television set or from room lighting are much more salient than energy lost due to poor insulation in the attic or from water heating. By making such consumption visible, it is argued that one is then able to understand and address the challenge of conservation (Trinh, 2010). 11

A subset of the studies following the learning perspective aimed to specifically improve conservation competence. In one study looking at the control of a simulated central heating system, participants were asked to maintain thermal comfort in the home while minimizing energy waste using a feedback system (Sauer, Schmeink, & Wastell, 2007). Results showed participants improved conservation competence when provided with additional energy use information. Van Raaij and Verhallen (1983) extend the learning perspective by suggesting that feedback works through a three-step process: learning, habit formation, and internalization of behaviour. In the learning phase, households observe or become aware of the specifics of their consumption patterns and learn about how their specific actions affect their consumption levels. They respond by making small changes in their behaviour, initially to view the effects on the feedback they received and over time as a way to maintain a lower consumption level. These changes that persist become habit that may work even with the withdrawal of feedback. The third phase is the internalization of behaviour. As energy-conserving behaviour becomes habit, an individual's attitude will also change to reflect the adjustment in behaviour. Ehrhardt-Martinez, Donnelly and Laitner (2010) found evidence showing the effect of feedback to be persistent. Taking a different approach, Seligman et al. (1981) argue that feedback works by providing goal-relevant information. Given the important precondition that one is motivated to conserve, increased effort can be triggered by showing when actual conservation is below the level the person wants to achieve. They identify that setting a performance goal and providing feedback relevant to that goal are basic elements in self-control. From the explanations above, the central rationale of feedback is that people are hampered by an information deficient world. Furthermore, if this information became available in a timely and comprehensible way then motivated individuals would be enabled to make more competent decisions.

2.2.2 The different dimensions of energy feedback
Darby (2001) distinguishes between direct and indirect feedback. Direct feedback refers to feedback that is available on demand in the form of a real-time meter or electronic display. Indirect feedback, by contrast, is typically processed by the electrical utility and sent out in the form of a bill. Currently, direct feedback strategies are receiving increased attention as a result of continuing proliferation of new information and communications technologies that facilitate the effective delivery of feedback. Over the 12

past decade, researchers have been exploring feedback delivered over the internet via personal computers (Benders et al., 2006; Petersen, Shunturov, Janda, Platt, & Weinberger, 2007) and on mobile devices (e.g.,Froehlich et al., 2009). Based on these recent advances in feedback delivery mechanisms, the Electric Power Research Institute (EPRI) expanded Darby's feedback spectrum (see Figure 2-3) to offer greater resolution of the type and frequency of information provided (Ehrhardt-Martinez et al., 2010). The trade-off with the additional information availability and resolution offered by direct feedback strategies is the associated costs of implementation and maintenance of the feedback systems.

Figure 2-3: Household savings broken down by feedback type Adapted from Ehrhardt-Martinez et al. (2010)

In Trinh's (2010) assessment, indirect feedback may be more appropriate for efficiency than curtailment behaviours because they are not time sensitive and implementation costs are also kept minimal. On the other hand, direct feedback may be more appropriate for curtailment than efficiency behaviours because information needs to be provided more frequently to support learning and performance tracking specific energy-related activities. As shown in Figure 2-3, Real-Time Plus Feedback has been

13

shown to promote the most savings of feedback types. Chapter 3 details the development of such a platform. By aiming for this level of feedback, other forms can be easily derived through subtraction of features (e.g., lowering the frequency, or making print-out "bills" rather than showing feedback online.

2.2.3 Feedback in context: Frameworks and Complementary Engagement Strategies
Feedback strategies seldom work alone in a conservation program. That is because without goals, baselines for comparison, or clear objectives for example, feedback is just information. Consideration must be given to the sociotechnical context for which conservation programs with feedback are designed to help ensure optimal program implementation. One line of thought is that for behaviours to become habitual, they require community support and reinforcement. To guide the development of conservation programs there are two prominent behaviour change frameworks: Community-based Social Marketing (CBSM) and the Make Energy Change Happen (MECHanisms) Toolkit. This chapter reviews each in turn while comparing their broad similarities and differences. It then dives into engagement strategies that are often used to complement an effective feedback approach. 2.2.3.1 Community-Based Social Marketing (CBSM) CBSM (McKenzie-Mohr, 2011) is a sustainability program design process that draws from research in social psychology, which indicates that behaviour change is most effective when they are implemented interactively at the community level. It leverages from the observation that raising awareness of sustainability issues is alone insufficient to evoke behaviour changes. In addition, CBSM emphasizes direct and personal contact with community members using many of the occupant engagement strategies reviewed later in this chapter. McKenzie-Mohr (2011) reviews these strategies with examples in agriculture & conservation, energy, transportation, waste & pollution, and water. CBSM also pragmatically emphasizes the identification and removal of barriers that may impede change. It is only by understanding these barriers, that a program designer can effectively implement change. Barriers include: lack of motivation, social pressure, or knowledge; forgetfulness or structural barriers. To help address these barriers, CBSM offers guidance on pairing tools with barriers as summarized in Table 2-3.

14

Table 2-3. Selecting Tools Based on Barriers and Benefits. Adapted from McKenzie-Mohr (2011)

BARRIERS Lack of Motivation

TOOLS Commitment Norms Incentives

Forget to Act Lack of Social Pressure Lack of Knowledge

Prompts Norms Communication Social Diffusion

Structural Barriers

Convenience

To ensure program success, CBSM recommends small-scale piloting and refinement before broad implementation to the target community. This follows from well-known cyclical design patterns for any successful product or program development. In summary, the CBSM process prescribes five steps: 1) Select behaviours 2) Identify barriers and benefits 3) Develop strategies 4) Pilot 5) Broad-scale implementation 2.2.3.2 Make Energy Change Happen (MECHanisms) Toolkit The MECHanisms Toolkit (Changing Behaviour, 2013) is designed for project managers who are looking to promote energy conservation with small energy end-users such as households, housing managers, small businesses and local communities. It is based on both practice and research and was established by the European-led Changing Behaviour project. Its objective is to support the development of programs for enduring energy conservation. Similar to CBSM, MECHanisms focuses on change at the community level rather than with specific individuals, acknowledging the importance of the socio-technical context. As such, it also encourages an interactive program design approach working with the target group. It offers guidance to develop a deep understanding of target groups and their socio-technical context. Within the MECHanisms Toolkit are detailed descriptions for individual tools (e.g., competitions, using fun activities, feedback, etc.) intended 15

for the practitioner. Furthermore, guidance is provided for its best use along with caveats of which to be mindful. In addition, detailed, printable checklists are provided to facilitate the implementation of the tools. Compared to CBSM, MECHanisms emphasises a broader approach to change and energy conservation and this difference is highlighted in the breakdown of Steps in Stage A (see below). Inherently, the MECHanisms process appears to cater more to project managers who are open to either a top-down (driven by the program's agenda) vs a bottom-up (driven by community needs through participation in design) approach. Whereas CBSM presumes a target community in mind and targets specific behaviours, MECHanisms takes a more abstract initial stance to challenge the program designer to consider the higher project objectives. Doing so, it encourages thinking about the context, the timing, and relevant stakeholders, and possible barriers before specific conservation behaviours. Furthermore, it suggests using broad interventions such as energy audits and information campaigns and only after some initial testing, supporting them with engagement strategies, many of which are described later in this chapter. By contrast, in CBSM these engagement strategies are the core of the proposed intervention. The MECHanisms process is executed by following these fourteen steps divided into three stages: Stage A: Understand 1) Pinpoint your problem 2) Get to know your target group 3) Understand your context 4) Determine if the time is right 5) Identify relevant stakeholders Stage B: Plan and Do 6) Define goals 7) Plan with your target group 8) Select and adapt your instruments 9) Test your ideas 10) Engage your target group 11) Motivate through feedback Stage C: Evaluate and Learn 16

12) Get some feedback 13) Evaluate and improve 14) Develop a learning culture 2.2.3.3 Information and Prompts Curtailment campaigns provide consumers with information in an attempt to change their attitudes or highlight economic benefits. McKenzie-Mohr (2011) posits that for a message to be effective and influential, it should (to name a few): capture the reader's attention; be vivid and captivating; be tailored to the attitudes and beliefs of the intended audience, and their perceived barriers and benefits to taking action; cite a credible source; frame the message to highlight a potential loss; provide actionable solutions when highlighting something that may threaten the reader; keep instructions clear, specific, and easy to remember; and be combined with other approaches. While providing information may change attitudes, it does not necessarily change related behaviours (McKenzie-Mohr, 2011; Verplanken & Wood, 2006) or lower energy consumption (Abrahamse et al., 2005). For example, Sauer, Wiese, and Ruettinger (2003) found that knowledge of environmental impacts did not predict environmental performance in the use of consumer appliances. However, if the information is delivered at the point of consumption, it can prompt specific behaviours. The purpose of such prompts is to spur people to do something they are already predisposed to do but may have forgotten (McKenzie-Mohr, 2011). Effective prompts are noticeable, specific, and actionable. Prompts placed around taps and showers displaying the environmental impacts of water use decreased water consumption by 23% (Kurz, Donaghue, & Walker, 2005). Prompts placed over waste bins produced a 50% reduction in litter(Kort, McCalley, & Midden, 2008). 2.2.3.4 Goal Setting and Commitments Setting a performance goal and providing feedback relevant to that goal are basic elements in selfcontrol (Seligman et al., 1981). However, goals should be achievable and challenging to have an impact on energy conservation (Becker, 1978). Goals are effective when they are clear, agreed upon, and measureable and when frequent feedback is available (Changing Behaviour, 2009). Commitment strategies can be used to promote a variety of sustainable behaviours. Becker (1978) showed that both feedback and goal setting were responsible for motivating individuals to reduce electricity use. In particular, the more difficult the goal, the more effort the individuals put into meeting that goal. In his study, Becker found that subjects who chose to reduce their energy consumption by

17

20% conserved significantly more than those who chose to reduce by only 2%, even if their goals were not reached. However, for commitments to be most effective, they should be made publicly and written rather than non-public and verbal (Shippee & Gregory, 1982). 2.2.3.5 Comparisons Comparisons can also motivate conservation behaviours. There are two types of comparisons: historic comparisons (e.g., with one's past consumption); and normative comparisons (i.e., social comparisons; e.g., with one's neighbor). Using energy consumption from a previous billing period is an effective historic comparison (S. Darby, 2006). However, weather and occupancy fluctuations may make this form of comparison less meaningful unless normalizing factors are modeled. Social comparisons often happen in the form of competitions. Competitions can be effective but it is unclear whether their effects persist once they end (Ehrhardt-Martinez et al., 2010). Social comparisons also suffer from the perception of unfair comparison groups (Darby, 2006). However using "injunctive" norms, which describe how one should behave, rather than "descriptive" norms, which describe how others have behaved, can prolong the effect of social comparisons (McKenzie-Mohr, 2011; Schultz, Nolan, Cialdini, Goldstein, & Griskevicius, 2007). Perhaps the champion of social comparisons has been Opower (https://opower.com/), who have developed a commercially viable business around their proprietary home energy reports. Their home energy reports (See Figure 1-1) combined with customer data mining has led to documented energy savings from 1.4-3.3% (Allcott, 2011) (on average 2%) and persistence (Allcott & Rogers, 2012). However, in agreement with Froehlich (2009), more research is needed to understand how social comparisons can be effectively integrated with feedback information. This is especially challenging in real-time applications where providing an individual's feedback in near real-time has been costly (i.e., relative to monthly home energy reports). 2.2.3.6 Rewards and Incentives Incentives, rewards, and disincentives provide extrinsic motivation to perform existing, or learn new, behaviours that consumers would otherwise be indifferent or resistant to (Abrahamse et al., 2005; McKenzie-Mohr, 2011). Implemented correctly, incentives foster sustainable behaviours. For example, introducing bottle deposits in Oregon, Vermont, and Michigan, saw decreases in litter of 68%, 76%, and 82%, respectively (Syrek & Legislature, 1980). A program in California that charged residents for the amount of waste they put out on the curb, saw a 46% reduction in landfill-bound waste and a 158% increase in recycling (Federation of Canadian Municipalities, 1996). However, Abrahamse et al. (2005) 18

found that while rewards produce large effects, these effects quickly diminish once the reward is discontinued.

2.2.4 Summary of literature review on good feedback
Fischer (2008) concludes in her review that successful feedback that stimulates conservation and is satisfying to users are likely: 1) Based on actual consumption 2) Given frequently (ideally, daily or more) 3) Involves interaction and choice for households 4) Involves appliance-specific breakdown 5) Is given over a longer period 6) May involve historical or normative comparisons 7) Is presented in an understandable and appealing way. Trinh (2010) summarizes feedback visual design heuristics and best practices to encourage conservation behaviours. They are listed as follows. 1) Make visible important but normally imperceptible information (the basic premise of providing feedback). 2) Design the message carefully to filter out unimportant information (Gardner & Stern, 2002). This is related to the data-ink ratio concept by Tufte (1983) who proposed that a high proportion of a graphic's ink should be devoted to the non-redundant display of data information. 3) Consider the audience; be specific and personalized (Benders et al., 2006; Brandon & Lewis, 1999; Gardner & Stern, 2002). The information needs to be tailored to the environment for which it is intended, the task that it supports, and the users who will need to act on the information. 4) Benchmark in a meaningful and fair way (Abrahamse et al., 2005; Egan, 1999; Seligman et al., 1981). If feedback is to be comparative, comparisons should be perceived as equitable. Comparisons of consumption of one house to the average house in one's neighborhood may seem unfair if the home has more occupants than the average. Similarly, comparisons of total home energy consumption by month may not show actual conservation improvements if warmer weather required more air conditioning usage. 19

5) Average feedback over meaningful intervals (Seligman et al., 1981). There is little purpose, even if possible, to report energy consumption by the second if target activities take place at a slower time scale. On the other hand, monthly averages may not be specific enough to promote learning. 6) Make the feedback information task relevant (Sauer et al., 2007) or related to behaviour in an intelligible way (Winett, Neale, & Grier, 1979). When possible, feedback should be related to specific behaviours of interest. 7) Use concrete consequences by framing consumption data using tangible equivalents (Pierce, Odom, & Blevis, 2008). It is useful to explain measurements in alternative equivalents to which users can relate. For example, while energy is reported in kilowatt-hours (kWh), an average homeowner is more likely to understand that amount in terms of light-bulb equivalents. Trees are recommended as equivalent units of carbon offsets (Katzev & Johnson, 1987) since people have positive feelings towards trees and they are also public symbols of carbon sinks. Another alternative is to allow users to select their own frames as Schott et al. (2012) proposed with options ranging from the empathic to data driven. While the above two lists represent the best practices from literature, there is no guarantee that adhering to these will be best for any given community of users. The review of CBSM and MECHanisms, indicated that an interactive approach can help feedback designers identify barriers and develop sound strategies (even if not with feedback) to address them. In fields such as Human Computer Interaction (HCI) or Human Factors (HF), this approach is analogous to a user-centered design (UCD). A UCD approach recommends an iterative design philosophy beginning with perhaps surveys or interviews to understand the context. This is often followed by design iterations with prototypes of increasing fidelity. An example of this approach is Stragier et al's (2013) work developing a Home Energy Management System (HEMS) by involving input from end users in the design phase.

2.3

Where do we go from here?

This literature review has shown the various dimensions of feedback design and the variety of feedback interventions programs. Given this space, it is not surprising that there have been a breadth of studies in this field. However, as introduced earlier, the advancement has been hindered without a standard way of designing and delivering feedback. Thus, the following seven functional requirements were identified for the feedback research platform. 20

1. It should allow for the implementation of feedback on a multitude of design dimensions such as visual design, frequency, and delivery format. 2. It should allow for aggregated and disaggregated feedback data. 3. It should allow for historical and social comparisons to be integrated with feedback. 4. It should support researchers by not only delivering feedback but also standardizing how data is collected and managed. 5. The data collected should not be limited to simply energy measurements, but should be widened to include survey data, thermal comfort data and data related to energy use. 6. It should allow for data to be collected with a common structure and data format, to afford cross-experiment data analysis. 7. Finally, because the platform is built on open-source technology it should be freely available for others to use and customize. In Chapter 3, this thesis explores the detailed design of the feedback research platform.

21

3. Feedback Research Platform Design

This chapter describe the design and integration of a near real-time feedback platform for research applications. This platform is informed by the best practices identified in Chapter 2, and is motivated by challenges that have plagued the feedback design community as identified in Chapter 1. This chapter may be especially useful for research project managers and designers.

3.1

Platform Technical Requirements

When reviewing the list of seven functional requirements for the platform identified in Chapter 2.3, it can be taken for granted that a web-based solution is critical for content management, experimental configuration, and robust deployability. The promise of a connected world is premised on the internet as a common communications platform. Web-based technologies have been in rapid development since the early 90's. Today, many of the world's key communications services (e.g., email, telephone, video conferencing, news, television) are delivered over the internet. Online data storage and web-hosting for content management is also become more cost-efficient and reliable. Moving towards a web-based solution for content management is also practical from an administration standpoint as it allows remote and shared access amongst team members. A web-based platform also allows deployment over a range of internet-connected devices such as smart phones, tablet, laptops, or desktop computers. In addition to being web-based, the author determined 12 technical requirements that guided the design of the platform and selection of components to meet the platform's functional requirements: 1. Manages content. A content management system (CMS) is a necessary and arguably the core component for the platform. According to Wikipedia, a CMS is a computer application that allows publishing, editing and modifying content, organizing, deleting as well as maintenance from a central interface. Such systems of content management provide procedures to manage workflow in a collaborative environment. In this context, the content is referring to the energy and energy-related data and all its attributes that will be collected from sensors in the field. As

22

such, it will need to effectively handle data feeds at fixed (i.e., time series data (e.g., from temperature sensors)) and variable (e.g., survey data) intervals. 2. Fieldable sensors. At a minimum, the platform should integrate sensors for power, temperature, and humidity measurement. Power measurements should be able to be captured using both clamp-on style (non-invasive) current transducers (CTs) or from electrical plugs. CT sensors must be able to sample every 10 seconds to support precise power measurements of high wattage appliances with short duty cycles (e.g. electric kettles, microwaves). Temperature and humidity sensors must be able to sample every minute to capture changes in the ambient space due to power and FCU use. The sensors should have the option to be battery-powered, support a low-power wireless transmission (e.g., Zigbee, Z-wave), and have at least a year of data sensing and transmission function if battery powered. Each sensor must be uniquely identifiable. 3. Data processing. The key differentiating requirement for the CMS is its ability to process time series data as this is what separates the requirements of this CMS from those that handle news feeds or blogs. The CMS should be able to perform basic data manipulations such as addition, subtraction multiplication, and division of data feeds. This should allow for averaging of data feeds, which is important for historical and social comparison applications. They should also support conversion of time stamped power measurements in watts (W) to energy units (e.g., kWh) and to kWh/day to afford visualizations on demand. 4. Efficient data storage and transfer. It is important for any software, especially one that is intended for real-time data monitoring, to have a smooth user interface and interaction. Ensuring that data is stored and transferred to and from the CMS is an important objective in this regard. Amongst other things, this means storing time series data using time series database technology that leverages the fixed interval nature of time series to minimize data transfer. Data must also be available to be downloaded on demand for analysis. 5. Supports up to 50-100 users. While there is no specific upper limit for the maximum number of homes that this platform should accommodate, it should be noted that utility-scale implementations (i.e., hundreds to thousands of users) are not the intended use case. Rather, this platform is intended for the testing of feedback designs that have passed the stage of Wizard-of-Oz prototypes and usability studies and are ready for a high-fidelity field implementation and piloting. 50-100 users were deemed appropriate for this scale.

23

6. Allows visual design customization. As discussed earlier, the need for this platform extends from methodological issues that have surfaced in the literature. A key part of the problem has been the lack of detail when describing technical feedback implementations. Quintessentially, this includes the specification of visual feedback design and testing of design variations. Such a platform should not only support the customization of feedback, but also sharing of the design specification for ease of replicability. 7. Clearly specifies accuracy and precision of collected data. Ideally sensors will produce accurate and precise data. Due to manufacturing tolerances, wear and tear, this cannot always be guaranteed. This is especially the case for low-cost sensors that are not certified, but are likely to be used in anticipated implementations due to budget considerations. In some cases, ensuring a high precision (with a wider tolerance for accuracy) is acceptable if social comparisons are the focus for example. Manual calibration efforts may also be required to bring accuracy to within an acceptable range. 8. Has an open Application Programming Interface (API). At present the IoT world is still in its infancy. As such, there are few dominant standards for communication. However, wifi and the internet via Hypertext Transfer Protocol (HTTP) are quickly becoming the lowest common denominator with which many IoT devices can interoperate. The platform should have an API to accept data feeds (e.g., from various IoT sensors and surveys), manipulate existing values, and to export data for analytical purposes or visualization. 9. Allow for in-situ surveys to be designed, deployed and filled. Not all data can be captured with sensors and often times it is useful to ask participants what they feel, think, and why they held those thoughts or acted a certain way. Such a tool would be useful to immediately gauge information about issues like thermal comfort, which are very subjective. A good survey tool would allow for the design of surveys with multiple question types and response types. In comparison to printed and manually entered surveys, electronic equivalents are quick and convenient to disseminate and complete. Completed surveys should be time stamped and stored securely on the CMS. It should allow individual surveys to be delivered through an app on the Android platform. 10. Web analytics. Since the days of web page hit counters, web analytics have given administrators insightful information to the usage of their webpage. Nowadays, web analytics has exploded in capability and can now track information on users' devices, location, visit frequency and duration, and conversion rates if the web site is for commercial use. To ensure adequate 24

interaction, and to potential track confounds on the efficacy of feedback, the platform should support usage analytics. At a minimum, it should be able to track how frequently and duration with which the feedback tool is being utilized. The same analytics may also be used to track any usability issues to help improve future iterations of feedback tools. 11. Tablet and software. While, the platform is designed to be robust and capable to deliver energy feedback information on multiple devices, for experimental purposes it is helpful to provide a common device to help ensure the same user experience. A tablet was considered the best choice as it could be used equivalently as a typical home energy monitoring display would (e.g., Aztech In-Home Display). Furthermore, a tablet can also be used as part of a reward for participation since they are also able to connect to the internet for browsing purposes or to play games, etc. This should not preclude other forms of feedback delivery such as printed statements, or traditional website portals. Rather, by developing a tablet app, the platform is robust to the most demanding of feedback implementations. For cost and availability, the Android platform was selected for development of an app. However, to minimize platformspecific development, the concept for the app could be to simply display web content from the CMS. 12. Data security and privacy considerations. Data security and privacy are important considerations when running any web-based service and when collecting personal data from participants. As a first line of defense, researchers should aim to keep personally identifying information in a separate database, preferably kept only on local storage. This will help ensure privacy if data is illicitly retrieved from the CMS database or during transmission. To enable this, the platform should be able to accommodate arbitrary participant identifiers. The CMS should offer standard login security for administrators and participants. To allow write access to the CMS database from third party devices (e.g., SafePlugs, and online weather data feeds), the CMS should support specially coded read/write API keys. To allow tablets and other web-enabled devices to display data from the CMS, the CMS should support read-only API keys. These keys should be kept private at all times in the same way passwords would. Given the time and technical resource constraints for this thesis, commercial-off-the-shelf solutions were considered for building sensing infrastructure. Several options were considered from manufacturers/vendors including National Instruments (http://canada.ni.com/), BlueLine (http://www.bluelineinnovations.com/), LaCrosse (http://www.lacrossetechnology.com/), and SensorSuite (www.sensorsuite.com). With the exception of National Instruments, no solution fully met 25

the sensing requirements. National Instruments solutions, while technically feasible were dismissed due to cost prohibits. Additionally, commercial solutions were dismissed for two broad reasons. First, they can be difficult or impossible to customize in an agile fashion needed for scientific exploration and rigor. Second, commercial solutions are often based on business models that keeps ownership of the data within the manufacturer; this is not acceptable for research purposes. As will be explained later, SafePlugs were the one exception to this policy and there were no FOSS equivalents to its capabilities. In general however, with the broad requirements identified above, an IoT-FOSS approach was decided upon to allow for flexibility in design and full ownership of the data collected.

3.2

Open Source Projects and Free Utilities

Open source hardware such as Arduinos and Raspberry Pis, were an appealing starting point for this feedback research platform because of the flexibility of the hardware to build `Internet of Things' solutions. The Arduino platform in particular is well known to undergraduate engineering and computer science students as a rapid prototyping platform for many Do-It-Yourself (DIY) style of projects such as graphing thermostats, power meters, or home automation applications (e.g., http://playground.arduino.cc/projects/ideas). Raspberry Pi projects are often geared towards low-cost computer applications to serve speciality purposes. For example, there are a multitude of Raspberry Pi projects to build media centres or computer network servers. (http://www.raspberrypi.org/forums/viewforum.php?f=15). While Arduino and Raspberry Pi boards themselves serve as a platform for rapid prototyping and DIY projects, there is considerable amount of work required to scale the platform for larger data-centric applications as is required for the current project. In the following sub-chapters, two open source projects used as a basis for the feedback research platform are discussed. The Open Energy Monitor project serves as the core technology behind the platform. The Open Data Kit project was leveraged for survey deployments. Google Analytics and Piwik were used to provide usage data, while Weather Underground was leveraged for real-time weather data.

3.2.1 The Open Energy Monitor Project
Through a search of open source projects based on Arduino or Raspberry Pis, the Open Energy Monitor project surfaced quickly as a robust platform for energy monitoring applications. The Open Energy Monitor system comprises of wireless sensor nodes that send data at periodic intervals to a web26

connected base-station. From there data can be visualized locally using the base station as a server, or the data can be sent to an online content management software (CMS). Figure 3-1 illustrates how these components are connected.

Figure 3-1: Open Energy Monitor system components and connections Adapted from www.openenergymonitor.com

Given that the OEM platform is free and highly configurable it was an obvious choice on which to base the feedback research platform. At the time of writing, with the OEM platform it was possible to sense: AC electricity (apparent power, current, voltage, real power, power factor), temperature, humidity, pulses (from pulse output utility meters), Elster IrDA (direct utility meter interface) and solar PV power diversion; thus, the sensing requirements for the feedback research platform were met. Furthermore, there is ongoing work to extend this list to include CO2 and other air quality measurements. Below, detailed components of the platform are reviewed as they relate to the requirements specified in Chapter 3.1. Emoncms content management software (CMS) Emoncms is an open-source web-app for processing, logging and visualising energy, temperature and other environmental data. It has an open API to accept inputs from any data source, and out-of-the-box it can accept inputs from sensing devices offered from OEM. By leveraging the TimeStore database

27

technology (Sterling, 2014), it meets the requirements for efficient data processing and storage from Chapter 3.1. Data feeds can also be visualized through a dashboard creation tool. A full and public installation of Emoncms (can be accessed at www.emoncms.org; or, the source code may be freely downloaded and installed on a separate server. For research purposes it is important to have ownership and complete control of the data set so Emoncms was installed on a separate server. As will be detailed later, there were several modifications made to this platform for it to be more amenable for research. Raspberry Pi base station The purpose of a gateway is to bridge two networks: the low-powered radio-based network for local data sensors and, wifi for relaying data to the internet. There are two options for base station gateway in the platform: NanodeRF or Raspberry Pi. The Raspberry Pi (currently using Model B, the latest model as of this writing) was selected because it offered the potential to have wireless internet connectivity via wifi USB dongle and because it provides options for local back-up, and the flexibility of control that a Linux-based machine provides. Having wifi access to the internet also makes for a less-intrusive installation. A ready-to-go software configuration of the Raspberry Pi can be found on OEM's website (http://emoncms.org/site/docs/raspberrypigateway) to forward the data to the CMS. This configuration file has been modified for research and reliability purposes. As listed above from the OEM site, there are a multitude of relevant sensors that have been configured to work with the platform. In particular electric current, voltage, temperature, and humidity were identified as the part of the core requirement. However, other sensors to aid in measuring air quality, information from utility meters, and occupancy would be helpful for a more comprehensive research or home automation application. Conveniently, the emonTXv3 and emonTH sensor nodes were available to meet the core requirement. emonTx V3 (http://openenergymonitor.org/emon/modules/emonTxV3) As of this writing, the emonTx V3 was the latest generation of the emonTx low power wireless energy monitoring node. See Figure 3.2. It was designed for monitoring AC electrical power on up to four separate household electrical circuits using non-invasive clip on current transformer (CT) sensors and an AC-AC Voltage adaptor to provide a voltage signal for full real power calculations. One of the unique advantages of this device is that it can be powered by a standard 5V Universal Serial Bus (USB) cable or

28

with 3 AA batteries for simplicity of installation. With standard alkaline batteries, the device is rated to last for approximately one year.

Figure 3-2: emonTx V3 ruggedized power and temperature sensing now Imaged adapted from http://openenergymonitor.org/emon/modules/emonTxV3

Using the ATmega328 microprocessor the emonTx V3 runs standard Arduino programs (i.e., sketches) and is fairly easy to customise and upload code using the standard Arduino integrated development environment (IDE) and a USB to Universal Asynchronous Receiver/Transmitter (UART) cable. The data from the emonTx V3 is transmitted via a 433 MHz radio to an the Raspberry Pi Gateway with similar radio, which then posts the data onto an Emoncms server for logging, processing and graphing. emonTH (http://openenergymonitor.org/emon/modules/emonTH) The emonTH is an open-source, battery powered (2xAA), temperature and humidity monitoring wireless node and was designed to be an easy to deploy tool. See Figure 3-3. Like the emonTx V3, the emonTH uses an ATmega328 chip, runs standard Arduino sketches, and is easy to customise and upload code using the Arduino IDE and a USB to UART cable. The data from the emonTH is transmitted via 433 MHz radio signals to the Rasbperry Pi gateway.

29

Figure 3-3: emonTH temperature and humidity, battery-powered sensing node Imaged adapted from http://openenergymonitor.org/emon/modules/emonTH

3.2.2 SafePlugs
One limitation with the OEM platform is the lack of a convenient sensor for capturing plug loads. Disaggregated feedback gives task-relevant feedback and if delivered in real-time can quickly allow users to draw connections between their behaviour and environmental impact. The SafePlug (www.safeplug.com) is a commercial-off-the-shelf product that meets this requirement. The SafePlug is a power receptacle placed overtop standard wall receptacles. Out of the box, it provides fire protection, shock protection, and power protection aimed to help keep family members and property safe. When configured as part of the Home Energy Manager Kit (see Figure 3-4), it also can be used for energy monitoring and automation applications. Each kit comes with a gateway device, two SafePlugs, and a collection of RFID tags. The SafePlugs themselves incorporate safety and energy metering circuitry. They also have actuators to control power flow to plugs and Zigbee radios to relay data and controls to and from the gateway. The gateway device serves a bridge between Zigbee and Ethernet networks allowing connected SafePlugs to be tracked and controlled wirelessly over the internet. It also has internal storage for energy use data. The RFID tags are used to help the system uniquely identify appliances.

30

Figure 3-4: SafePlug Home Energy Manager Kit Imaged adapted from www.safeplug.com

The key enabling feature of the SafePlug Energy Manager Kit is its open API, allows full access to the SafePlugs. Using this API, software hooks were developed to allow the SafePlugs to integrate into the Emoncms platform. Technically there are a couple of limitations of the SafePlug. First, as with many other power meters, it cannot reliability detect power draws below 20W. This limitation may be critical if power draw from phantom loads is important. Second, due to the nature of the Zigbee network, data cannot be collected more frequently than every 20 seconds. High frequency sampling rate is an important consideration for some load disaggregation calculations. Also, if high draw, short cycle appliances are used (e.g., microwave ovens), this could be problematic.

3.2.3 Open Data Kit for Surveys
In a search of free or open source tools for this purpose, Open Data Kit surfaced as the de facto candidate. As mentioned a key criteria for such a tool is its deployability in the field with a tablet. Open Data Kit allows researchers to design custom surveys with a range of question types and response types using templates based in Microsoft Excel. Using a tool called XLSForm and ODK Collect, survey designs are then transformed into deployable format. ODK Aggregate is both a server and data repository for completed surveys. Administrators can download data for analysis or see basic descriptive visualizations of results within ODK Aggregate. Ideally, the ODK Aggregate server would be fully integrated with the Emoncms. However, this is not presently the case due to different underlying server and database technologies. This is not surprising 31

given the separate nature of both projects. Integrating the platforms would require a porting of one platform to the other's technology base. With a common platform from which researchers could design tools and collect data, new feedback opportunities would arise. For example, one could imagine an adaptive form of feedback that provides tailored recommendations based on a survey response. However, the integration of functionality between services was not determined to be a priority at this time. Despite the separate back-end technologies between Emoncms and OpenDataKit, it was determined that having a coherent front-end software application was the minimum level of integration necessary. As will be discussed later, this was achieved through the development of an Android app to integrate data from both sources.

3.2.4 Android App
To help control for the effectiveness of feedback, it was important to ensure a common user experience. Laptops have different sized screens, different operating systems, and different web browsers. Smartphones suffer similar issues but are further constrained by screen size. It was determined that it was important to not only provide a common user experience, but to also provide it on a common hardware device. The OEM platform incorporates a desktop LCD display (called emonGLCD ­ see Figure 3-1) and this was one such option. It was determined early on in the development of the research platform, however, that this would not be sufficient to test a variety of feedback designs due mainly to its screen limitations. It was black and white, had a low resolution, and was smaller than most smartphones. Instead, a tabletbased solution was decided upon. For cost and hardware selection considerations, the Android platform was chosen. In particular, the feedback app was designed for the ASUS MemoPad 7 HD, an Android 4.1 (Jellybean) based tablet. It should be noted that, with additional effort, the same app may be scoped for a wider range of mobile devices. To maintain central control over the feedback design and delivery, it was determined early on that the Android app would not contain code for visualization but rather leverage from the OEM dashboard tool. In this vein then, the app would essentially serve as a window into the web. However, much of the usability design around the app would function to give the user the feel of an app. For example, 404 error pages would be replaced with tablet-styled pop-ups. Also, the app would simplify navigation between different sub-dashboards as required. Furthermore, the app would handle login credentials.

32

3.2.5 Web / Android Analytics
There were two freely available options from which to choose from this purpose: Piwik and Google Analytics. Google Analytics is the de facto standard in the web analytics field and is a free solution for small-scale applications. It comes with many standard visualization widgets and a tool for designing custom dashboards. Its primary advantage for the FBRP is that it can also be used to track analytics from Android devices. This allows the tracking of app-specific interactions like user login and interface clicks. However, any analytics data collected resides on Google servers and incoming data often takes several minutes to days to appear on dashboards. Piwik is an open source web analytics solution that can be freely installed on any server. At the time of writing it was not as fully featured ad Google Analytics, however it appears to have an active and growing user community. With its current test installation on the FBRP server, there are no limits to the number of feeds or database size. Furthermore, because of the small-scale installation, it can provide real-time analytics. Both Google and Piwik analytics solutions were installed with concurrent data collection since they were both free to use, their co-existence would not introduce any conflicts, and each had their unique benefits. Besides minor bandwidth concerns, there was very little disadvantage to this approach.

3.2.6 Weather Data
Obtaining live weather data is important to help homeowners manage their HVAC-related energy use. Weather Underground is an online, commercial weather data source with more than 34,000 weather stations around the world (www.wunderground.com). Its API can be used to gather weather data such as temperature, humidity, wind speed and direction, pressure, etc. It is free to use for small-scale applications; API calls are limited to a frequency of approximately five minutes for the free usage tier. This was deemed acceptable for the intended application within the feedback research platform as it was determined that only hourly API calls were required for the purposes of this platform. This allows up to 12 cities (i.e., at a frequency of one hour) to be monitored at a time.

33

3.3

System Architecture

Overall, the FOSS and commercial products described in Chapter 3.2 were sufficient in meeting the requirements for the feedback research platform specified in Chapter 3.1. With some integration and configuration work, a system architecture was developed as depicted in Figure 3-5. The architecture emphasizes the flow of data between the major components. It also distinguishes between physical devices and components that are virtual and lie within the internet cloud. However, it should be noted that as depicted, its scope is not meant to be rigid and exhaustive, but rather flexible and configurable to the scope of a given project. For example, display devices can be limited to simply tablets, and more sensors can be integrated to communicate through the base station. In this sense, the architecture proposed in Figure 3-5 can be viewed as a framework.

Figure 3-5: System architecture for the feedback research platform

3.4.

Implementation and Maintenance Skills Requirements

As expected, when leveraging open source projects, considerable work is still required to integrate and customize the feature-set to your requirements. There are many details to the integration of the components; a description for which is better suited for a technical report and is outside the scope of

34

this thesis. However, to summarize the corresponding skillset and tools required to customize the platform, the following is a list of key software technologies that are leveraged: HTML and CSS for general web development and front-end design; Advanced Javascript including JQuery, AJAX for core web development with Emoncms; PHP for Emoncms server-side scripting and customizing the Raspberry Pi gateway behaviour; JSON for data interchange with Weather Underground, Emoncms, SafePlugs; XML for data interchange format for OpenDataKit; MySQL for Emoncms administration; WAMP for configuring a local instantiation of Emoncms for testing Java for Android development in the Eclipse-based Android Development Tools integrated development environment (IDE); C++ for Arduino sketch development; Linux for working with Raspberry Pi and web servers; and Python for big data processing and analysis

Further implementation details and source code for the feedback research platform will be made available here: https://github.com/kevinci29/fbrp/.

35

4. Project Implementation at Phoenix Place

This chapter describes an implementation of a real-time feedback solution as part of a tenant engagement program in a MURB, leveraging the aforementioned feedback research platform presented in Chapter 3. This implementation process was not linear, but rather cyclical. This was necessary in order to find a solution that met technical challenges, accommodated and leveraged existing building infrastructure and involved the target user community of tenants. As would be expected, much coordination was needed between various stakeholders. Fortunately, this thesis work extended from an existing and on-going relationship between Ryerson University and Phoenix Place, the target site for this research. Furthermore, this work was also part of a larger tenant engagement program with a team consisting of the author, Dr. Sara Alsaadani, Samira Zare Mohazabieh, Professor Alan Fung, and Professor Vera Straka, all from Ryerson University. This chapter begins with a review of the general MURBs context and the efforts previously conducted at the target site for the current study. This background is leveraged as part of a Community-Based Social Marketing approach for the design of a tenant engagement program intended to promote energy conservation. The chapter concludes with a discussion on the iterative design process for the visual feedback design ­ the focus of this research.

4.1

MURBs Context

Approximately 30% of the Canadian households reside in MURBs (Government of Canada, 2012). With an overall aging of the stock of MURBs there has been a growing effort on the part of industry and government to develop measures to improve their efficiency. The City of Toronto's Tower Renewal project is an example of one such initiative. However, while there are many conventional approaches to improving MURB energy, water and indoor environmental performance, most are directed at improving the building itself. It can be argued that reducing energy consumption in buildings and enhancing their

36

performance is equally a social problem and technical one. Proponents of this vantage point argue that "buildings don't use energy: people do" (Janda, 2011). Rental MURB dwellers tend to be of a lower or working class relative to their peers in single family homes. This likely results in energy use per tenant to be lower and it can be argued that there is less savings to promote. Neilsen (1993, from Fischer, 2008) found that savings were harder to tease out. However, it can be argued that low income households have most to gain since, low-income households spend about twice the percentage of their income on energy as compared to middle- or upper-class homes (Tweed, 2013). This sentiment appears to corroborate the view that feedback is not as effective for affluent homes where the cost of energy is low relative to income. (Geller et al., 1982, via Froehlich, 2009) Likely less contentious is the negative effect that split incentives have in motivating energy conservation. Split incentives take rise in scenarios where the building occupant, who consumes utilities, does not pay (or directly pay) the utility bill. This is often the case in rental MURBs or in condominiums that have utilities built into flat monthly fees. The result is that there is very little external incentive reward (cost savings, or fee decrease) for inhabitants to conserve. There has also been very little investment by the HEMS industry to MURB renter demographic. Split incentives are one reason, but these tenants are less likely to have the same level of discretionary funds to allow for the purchase of the latest energy efficiency gadget ­ even if the anticipated savings would more than recover the upfront costs. For similar reasons, or perhaps as a consequence of the above, very little is still known about the efficacy of energy interventions on this demographic. Nonetheless, there is a strong case for why MURBs can be an invaluable backdrop for field study research. First, rental units in such buildings are relatively homogenous in size and, naturally, in vintage and construction. In addition, major white appliances (i.e., stove, fridge) are often provided and they too are of the same vintage. Second, such buildings often attract a relatively homogenous tenant-base. Taken together, such conditions lend themselves well to controlled studies close to what may be simulated in a laboratory, but in the field.

37

4.2

Phoenix Place ­ History and Facts

Given a pre-existing and longstanding relationship, this research was set at Phoenix Place, a mid-rise MURB in Toronto's Parkdale community. Phoenix Place is an affordable housing project built by the Parkdale United Church Foundation in 1976. According to the Green Phoenix website (www.greenphoenix.ca): "These apartments are home to many who would otherwise find housing too expensive or difficult to obtain, including persons who are new to Canada, who have been living in shelters or sub-standard housing, or who lack the resources to find decent shelter elsewhere." Directed by the Parkdale United Church Foundation (PUCF) and its congregation, Phoenix Place underwent retrofits based on principles of sustainability and green construction. Completed in the summer of 2010, the retrofits included: An upgrade to double-glazed, argon filled, low-e coated, fibreglass framed windows; An upgrade of wall assemblies using exterior insulation and finish system (EIFS); An upgrade from electric-baseboard heaters in each suite to hydronic fan-coil units; An upgrade of makeup air-handling unit with enthalpy recovery; An upgrade to high efficiency gas boilers that replaced the original atmospheric boilers; The installation of flat plate solar thermal collectors with capacity to fully meet domestic hot water demands during the summer, reducing the need for natural gas to run the existing boilers; and The installation of ground source heat pumps as the source of heating and sole system of cooling; however, with a resultant air supply of 17-19oC during the cooling season there have been complaints that this is insufficient (Prada, 2013). The tower itself contains 136 suites; 134 of which are nearly identical bachelors each with approximately 20.5m2 of space. Figure 4-1 shows a typical floor plan in the 11 storey tower. The near-identical units are intended for single occupancy and also contain the same standard fridges, stoves, range hoods, and light fixtures ­ all of the same vintage as well.

38

Figure 4-1: Typical floor plan at Phoenix Place

Additionally, the electrical wiring in each suite was isolated from others allowing for energy submetering as is currently being conducted by the property manager. The sub-metering system afforded two key enablers for the field study. First, it allowed for a validation of measurements captured with the feedback research platform since both systems were running concurrently during the study. Second, it provided approximately three years of historical data with which to establish a baseline of energy use. As will be discussed in Chapters 5 and 6, the analysis of savings in the field study was done using the sub-metering data as it was deemed more consistent and reliable than the data captured with the feedback research platform. The limitation of the sub-metering data, however, was that it could not be used for the real-time feedback ­ so the sensors from the feedback research platform were still required for that functionality. Overall, given the homogeneity of suites and the electrical isolation and sub-metering of each suite, Phoenix Place was an excellent test-bed for social comparisons strategies since many normalization estimates (e.g. home size, appliances, occupants) were not required to ensure fair comparisons.

39

4.3

Results from a Post Occupancy Evaluation at Phoenix Place

In their survey of energy use by tenants at Phoenix Place, Roque, Straka and Fung (2012) sought to understand relationships between household energy use and demographic information amongst other variables. The survey was comprised of questions on ownership, usage of various consumer appliances, and the frequency in which occupants turned appliances off when not in use. The questions were grouped by usage categories like heating/cooling, cooking, and lighting. Additionally, it posed questions on satisfaction with the indoor environment focussing on thermal comfort. The survey results helped provide insight to the demographics at Phoenix Place and where potential energy savings may lie. Of the 48 tenants who completed the survey the following demographics information were reported: 80% of respondents were male, 56% of respondents were over the age of 46, 45% of respondents had lived in this MURB for over 7 years, 49% of respondents reported spending between 9-13 hours a day at home (including sleep), 45% of respondents reported growing up in Africa, and 66% of respondents have a total annual household income below $29,999.

In a meta-analysis of the survey results, Dr. Sara Alsaadani found several statistically significant correlations between suite-metered energy use and specific energy use behaviours as defined in (Roque et al., 2012). By prioritizing these behaviours, a set of 27 energy conservation tips were developed to inform the energy conservation program's information campaign. These tips were reinforced within the feedback dashboard: 1. "Switch off your TV and cable boxes when you are not watching TV.", 2. "Make sure the brightness of your TV is just how you need it for your room. Factory settings brightness is usually brighter than necessary.", 3. "If you own both a desktop and a laptop, try to use your laptop more often as a laptop is generally more energy-efficient.", 4. "Switch off your computer when you are not using it.", 5. "When you are cooking put your lid on the pot or pan.", 6. "Use your microwave, rather than your stove, especially to heat already cooked food.", 7. "When boiling foods on the stove (e.g., pasta, potatoes, eggs, etc.) switch off the stove burner a few minutes early.", 40

8. "Stove ­ use the correct sized burner for the pot or pan.", 9. "Turn the heat down to the minimum setting required to cook your food.", 10. "Use the minimum amount of water when boiling your food.", 11. "Increase the amount of food you cook to that you can refrigerate or freeze it, and re-heat it later.", 12. "Cutting food into smaller pieces reduces cooking time.", 13. "Thaw your frozen food in the refrigerator rather than the microwave or the oven.", 14. "Use an electric kettle to boil water for coffee or tea (or even cooking) instead of a stove-top kettle or pan.", 15. "Turn off your fan-coil unit when you are not at home.", 16. "Use window shades or blinds to reduce or completely block sun and heat during the summer, especially if you receive direct sunlight.", 17. "Use your hairdryer sparingly and don't use the maximum heat setting to save energy.", 18. "Remember to switch off the lights when you are not in the room.", 19. "Install Compact Fluorescent Lights (CFL) rather than incandescent bulbs.", 20. "Dust your bulbs and light fixtures with the power off.", 21. "Only do your laundry when you are ready to load your washing machine to full capacity.", 22. "Use lower temperature settings on washing machines ­ use warm or cold water for the wash cycle rather than hot water, and only use cold water for rinses.", 23. "When drying, separate your clothes and dry similar types of clothes together.", 24. "Don't over-dry your clothes. Take your clothes out of the dryer while they are still slightly damp if you intend to iron them immediately, to reduce energy.", 25. "When possible, dry full loads.", 26. "Consider hang-drying clothes when/if possible.", 27. "If you live on the lower floors, consider taking the stairs rather than the elevator."

4.4

The CBSM Framework in Application

Given that this research was being conducted with a known target community (i.e., tenants at Phoenix Place), the team had arrived at a set of conservation behaviours, and considered CBSM as an appropriate framework to follow. As outlined in Chapter 2.2.3, the CBSM process consists of five steps. This sub-chapter details each in application. 41

1. Select behaviors. Target behaviours include simple electricity savings tips in and around the home. As listed above these behaviours were identified to have a significant correlation to measured energy use. Additionally, this work focussed on thermal comfort related behaviours for a couple reasons. First, heating and cooling are a large component of overall MURB energy use. Second, as was identified by Prada (2013), cooling was deemed a concern at Phoenix Place due to the circulation of cold water from the ground loop without using the heat pump. 2. Identify barriers and benefits. Given the MURBs context, lack of motivation was determined to be a key barrier against conservation. This is partly due to split incentives since tenants do not directly pay for their electricity use. The lack of knowledge on their energy use and how best to conserve is another barrier. While tenants' energy use has been sub-metered since 2010, they have not been shown this use, nor do they have a point of reference to know whether their use is above or below average neighbors or if it has gone up or down from past use. 3. Develop strategies. Several strategies were applied in this project. First, to provide motivation, an information campaign was launched to raise awareness and make a case for the need for energy conservation at Phoenix Place. This was combined with community goal of 10% in overall savings and written individual commitments to help reach that goal. This was deemed a reasonable initial target given similar approaches to feedback. Since this value was essentially set through software it was possible to change it mid-way through the study if needed. To help improve energy conservation knowledge, specific tips were provided as part of campaign materials. These were reinforced through their inclusion in a feedback implementation ­ the subject of this thesis. The feedback implementation would also focus on providing historical and social comparisons to provide energy use in context, further improving user knowledge. As noted in Chapter 2.2.3.5, the efficacy of motivating through real-time social comparisons has been under-explored. Furthermore, given the homogenous nature of suites within Phoenix Place, this field study offered an excellent opportunity to evaluate a social comparisons strategy. Naturally, the evaluation of social comparisons approach to feedback was of key interest in this field study. 4. Pilot. Design is not a linear, but a cyclical process with an evaluation stage at the end of each cycle. As will be discussed in the following chapters, the visual feedback design underwent several iterations. Similarly, the information campaign materials underwent considerable internal review with the project team and with the property manager. While the efforts in this 42

program were of considerable scale, they may also be considered a pilot in the larger context of MURBs in general. 5. Broad scale implementation. The larger purpose of this project is to provide knowledge on how such interventions may be replicated in other MURBs. Thus, the focus of this thesis was to ensure that success could first be demonstrated within the current MURB. Towards this goal, the next chapter clarifies the detailed objectives and constraints for this project.

4.5

Summarizing the Feedback Design Context, Objectives, and Constraints

Thus far, this chapter has reviewed some recent history and facts at Phoenix Place as well as POE efforts to understand the demographic and personas within the community. Those POE efforts have been used to grasp how electricity is being used and subsequently leveraged to identify a set of tips that are relevant to the community as a whole. Chapter 3 also outlined technical details of the feedback research platform. Building from that, this sub-chapter reviews the thought process behind the tailoring of the feedback displays specifically. The implications of the visual feedback design cascaded naturally to requirements for the customization of the rest of the feedback research platform. The objectives of the feedback at Phoenix Place is to engage users to learn about their energy use and motivate them to conserve and reach individual target savings of 10%. That is, if all participants were to share in the same individual goal, the collective 10% savings would be achieved. From the literature review and analysis of the Phoenix Place context, the key strategies to achieving this objective include the following goal setting, written commitments, and historical and social comparisons. Thus, the design will: Focus on benchmarking. Providing appropriate comparisons and showing them visually can be an effective way to inform, frame, and motivate energy conservation. Aim to keep a simple message. This was decided early on to accommodate understandability and to be approachable given the sample demographic. Provide reasons for users to explore their data on a regular basis, but at a minimum on a weekly basis. It is important to keep users engaged and benefiting from the feedback information. Compare the effectiveness of design details. The purpose of this study is not only to design an effective feedback display for wide consumption. Rather, given the gaps identified in the literature,

43

it is to test which detailed design choices are most appropriate. In particular, this thesis explores the efficacy of delivering real-time social comparison data. There were two key design decisions that were made early in the process. The first was to omit the SafePlugs from the current study. There were several reasons for this. The main reason was that plug load disaggregation was not prioritized for this study. Additionally, it was important for the installation to be minimally invasive. Given the size of apartment suites at Phoenix Place, the SafePlugs would also have required more hardware and considerable installation effort. Second, to limit the scope of development of the feedback dashboards, only out-of-box dashboard tools available from Emoncms (current version was v8.0.3). Theoretically though, given that this is an open source product, a multitude of dashboard widgets and visualizations are possible. Data-Driven Documents (http://d3js.org/) for example, offers many visualization examples. However, this decision was made given time and resource constraints and also because developing a polished product was not a priority at this time. Where appropriate, minor customizations were made to the existing visualization source files.

4.6

Measuring the Impact of Thermal Comfort

For the purposes of a larger project initiative the feedback research platform was customized to measure the impact of thermal comfort and relevant feedback on energy use. This thesis details the platform customization of meeting this objective for demonstration purposes. However, detailed analysis on thermal comfort data is outside the scope. Towards providing relevant feedback on thermal comfort, the feedback dashboard was configured with separate, but navigable, displays for the total suite and FCU energy use. FCUs, while not solely responsible for, are a key contributor in delivering thermal comfort. The decision to disaggregate the FCU energy use was to draw special attention to heating and cooling energy use and raise awareness for how electrical energy use was tied to an occupant's thermal comfort. It was important to build in the flexibility to calculate or estimate the true energy draw from the FCU at a later time. As is, the sub-metering at Phoenix Place for each suite measures the plug loads, lighting, and oven and FCU electricity use. This does not include the energy required to heat or cool the liquid in the radiators inside the FCU. Currently, in the cooling season, the liquid circulated through the ground

44

loop. In the heating season, it is heated by the GSHP along with the gas-fired boilers. To account for this energy use, estimates can be made measuring the hot/cold output from the FCU and multiplying by a simple COP factor. For example, GSHPs have an approximate Coefficient of Performance (COP) of 5 in the cooling season and 3 for the heating season (Safa, Fung, & Kumar, 2015). While the flexibility has been retained, detailed modelling was not prioritized in the dashboard because a precise absolute FCU energy use was not deemed as important as the relative energy use when compared to neighbors. Furthermore, it would mean considerable effort obtaining measures from building wide equipment and more overhead cost. Instead, while less ideal, it was decided simply to provide feedback on what could be directly and precisely measure, and this was the electrical power draw from the FCU and its heating/cooling output as measured using a temperature probe. From the manufacturer's specification the fan has the following rated properties:
Table 4-1. Johnson Controls Enviro-Tec Model VFE Size 20. 115 Volts.

Fan Speed Low Medium High

Rated CFM 250 550** 1200

Rated Power Draw 33 39 57

Measured Draw* 33 42 89

* Average measurements from 3 different suites ** Estimated through linear interpolation using rated CFM and rated power draws

Section 4.7 details how both the total suite and FCU energy dashboards evolved through three design iterations as part of the CBSM process.

4.7

Feedback Design Process

With the context, objectives, and constraints in mind an iterative design process was used to hone in on an appropriate visual feedback design for the field study. The field study used two types of feedback: real-time feedback with historical comparisons (herein called basic feedback); and the same with additional social comparisons (herein called basic feedback + social comparisons). This chapter focusses on the feedback + social comparison designs since the basic feedback versions were simply derived by subtracting the social comparison features. While considerable description on process could be provided for any given iteration, the intent with each was simply to generate improvements in relative quick

45

succession. As will be detailed in Chapter 5, a detailed evaluation was planned for the field study and this is where a more rigorous scientific approach was followed.

4.7.1 Iteration 1 ­ Heuristic Design
The first design iteration was guided by the project objectives and strategies earlier and largely informed from the design heuristics identified in Chapter 2.2.4. The result of this analysis led to the prototypes shown in Figures 4-2 and 4-3. This chapter first explains the layout and functioning of each widget in the dashboards. Then it reviews how the feedback design heuristics were applied, or not.

Figure 4-2: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 1

46

Figure 4-3: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 1

Data to populate this dashboards in this iteration were simulated using a PHP script attached to a Linux cron job that would trigger as frequent as every 10 seconds on the server. The large trends in the simulated data were determined by the time of day using trigonometric functions. Random noise was built in to the simulated data to provide some realism. A limitation to the approach was that there was no memory in the model to capture transient effects. For example, as the FCU was turned on in heating season, the temperature in the room did not gradually rise over time. Rather, it rose only during the late afternoon and fell at night. Thus, the data shown in the following prototypes should not be taken literally. 4.7.1.1 Android App and Design Template As shown, the dashboards were designed to fit within an Android application. The title and navigation bar on top shows the two dashboard tabs. Users can click on these two tabs to navigate between the dashboards, or they may simply use a swipe gesture between them. On the right of the title bar there are buttons to complete a comfort survey, to refresh the data, and to enter some administrative and preference settings.

47

The comfort survey can be completed at any time. However, the app was designed to also raise a notification every eight days to prompt users to complete this. The reasoning behind the 8-day interval was to capture the user's thermal comfort on different days of the week to remove possible scheduling confounds. The notification appeared similar to what a voice mail notification would be like. Details of the comfort survey will be shown later. Users could always click to refresh the entire dashboard to ensure the latest data is retrieved from the server. In case of any crash, the entire dashboard was also set to reload every five minutes. However, the dashboard widgets were also designed to refresh as soon as data was received on the server in asynchronous fashion (i.e., without reloading the entire dashboard). This helped ensure an overall smooth user experience. 4.7.1.2 Feedback Design Walkthrough Within the dashboard itself (i.e the centre panel of the app with a white background) there were 5 distinct regions. the top-left moving clockwise, there are "Last 7 Days", "Last 24 Hours", "Right Now", a comparison widget, and finally the dashboard title. Energy savings tips were not prepared for this iteration. This layout reflects a chronological ordering of information from left to right. Power draw (and current indoor temperature from FCU dashboard) dials emphasize the real-time nature of the dashboard. The analogy of dials is most similar to what be found in cars. This data is converted to energy use and shown as part of the daily cumulative energy graph. The cumulative energy graph was chosen for its ability to summarize the total energy use for the day (height of curve), while also showing when energy was most or least consumed throughout the day (slope of curve). The color coding of dials and curves were meant to show linkages of data between the graphs. For example, the red temperature dial corresponds to the red temperature curve in the FCU dashboard. Each day at midnight, the cumulative energy graph was set to reset, at which point, concretizing that day's bar in the Last 7 Days bar graph. Both the Last 24 Hours and 7 Days graphs showed moving windows of data as their name implies and these were in fact updated every 10 seconds, asychronously along with the Right Now dials. The comparator at the bottom of each dashboard was intended to portray the key takeway from the dashboard. For the Total Suite dashboard, this was whether or not the user had surpassed the target limit for the day and by how much. For the bulk of any day, this comparator would return a green smiley. Otherwise, a peach colored sad face would sppear. Similarly on the FCU dashboard, the

48

comparator returned a smiley or sad face. However, in this case, it depended on whether or not they were above or below the cumulative usage when compared against their neighbors average. Note how the FCU graph did not have an absolute goal line. This was because a historical baseline from which to draw was not available in contrast to the baseline for the Total Suite dashboard. 4.7.1.3 Heuristics in Application Chapter 2 introduced seven feedback design heuristics. While it would be ideal to address all seven heuristics, for practical reasons only the first five were implemented. The following points highlight the considerations for each. Design the message to filter out unimportant information. This heuristic was especially applicable to utility bills which often contained non-relevant clutter and even advertising materials. Here, just about every graphical widget and label was tailored to providing useful data or clarification of them. Consider the audience; be specific and personalized. A lot of legwork to tailoring this display took place before even this first design was conceived. The feedback information provided on both displays are by definition personalized to the user. Benchmark in a fair and meaningful way. The focus of this feedback is to provide not only real-time data for users to learn from, but also to provide clear and motivational points of references. The goal of the conservation program was to encourage 10% savings building-wide; a goal that is designed to cascade down to individual tenants. In the Total Suite display, the suite baseline curves (red lines) were determined based on the average monthly data from over three years' worth of data from the sub-metering system. The Suite Goal curve (green lines) reflect a 90% value from that goal (here it showed an 80% goal because 20% was the target initially). Average feedback over meaningful intervals. When real-time feedback is first introduced it was anticipated that the "Right Now" power use dial would be most useful. However, as users begin learning about the energy impact from specific behaviours and appliances, they will likely want to see this data averaged over a longer period to more effectively track savings. In anticipation of this trend, the Daily Cumulative Energy Use chart for the "Past 24 Hours" was also provided. Similarly this was the rationale for the Last 7 Day graphs. It could be argued that weekly or monthly levels of aggregation would be useful as well; however, they were not included for a couple reasons. First, they would have required more display real-estate or more interactivity, possibly overcomplicating the dashboard given the nature of the study demographic. Second, having such displays might condone less frequent checks into the dashboard, providing less reason to check in at least weekly. 49

If users did not check in weekly, they would miss data. The third reason extends to the next heuristic with the intent of keeping users focused on their task of saving energy today and not necessarily dwelling on the distant past. Make the feedback information task relevant. The overall task for the user is to keep their total suite energy use within their target upper limit of 90% of their baseline energy use (i.e., achieving a 10% overall reduction in their energy use). We also wanted to see how social norming may motivate them to conserve. As mentioned, specific comparisons were made to summarize these in the form of the happy or sad faces. As reflected in the list of tips, there were multiple target behaviours. While it could be useful to disaggregate the feedback to individual appliances, as stated earlier, such details would not necessarily significantly contribute to overall savings goals. However, to demonstrate and explore the efficacy of the disaggregated approach FCU energy use data were included as it related to the task of achieving thermal comfort. Frame feedback data using concrete, tangible equivalents. Currently, energy and power use are communicated in kW and kWh. Using better units of measure is an area that could be useful to help users understand the data. However, it was not clear what equivalent would resonate with users best. An easy solution would be to show the equivalents in terms of its cost in dollars. However, with tiered pricing, and time of use factors, this calculation was not trivial. Estimations could have been completed, but introduces sources of confusion and inaccuracy that may complicate matters. As mentioned earlier, deriving a polished dashboard was not deemed a requirement for this study so this was left out. However, to help overcome the obstacles of understanding standard energy units, the measures were explained as part of the information campaign. In future, evaluating different units would be a worthwhile endeavor. In the meanwhile, though, for the purposes of historical and social comparisons and goal setting, the unit of measure is of less importance. This is especially the case with visual comparisons of data as is used heavily in these dashboards. In summary, this heuristic was not as critical to meet. Use feedback to support a distant future retrospect. As would be expected, this form of feedback requires a considerable amount of modelling to show the future impact of savings. While such feedback offers an additional layer of motivation potential, it was not critical for this study since historical and social comparisons were already utilized as well as goal setting. However, follow-up studies to compare sources of motivation would be worthwhile.

50

4.7.1.4 Internal and Informal Design Review The first prototype was shopped around to the project members and to the author's peers for internal review and informal critiquing. As necessary, details of the project background and usage context (see Chapter 4.5) were explained in advance. The prototype was demonstrated on the target Android tablet (Asus MemoPad 7 HD) with live, albeit simulated, data. The following is a summary of the three main criticisms from this review. First, the Last 24 Hours graphs were perceived to be too data dense and it was unclear how the curves were intended to be related to one another. Thus this display required considerable explanation. Part of the problem is that such a cumulative energy graph, while very information rich, is not typically used. Given that the target user community was not expected to perform a detailed interrogation of the graphs, a simpler solution was recommended. Second, it was not clear to the reviewers how useful it would be to correlated temperature with FCU energy use. The original intent was to draw that linkage visually to help users better rationalize their comfort-related energy use. However, it was reasoned that users could already sense their thermal comfort and such an explicit display would be redundant at best and most likely insufficient given that thermal comfort is comprised of several additional factors such as relative humidity and air speed. Since it was not the goal of this feedback display to dive deep into thermal comfort, further simplification was recommended. Third, the overlapping bars in the Last 7 Days graph were difficult to distinguish. This was due to additional colors that were produced due to transparency effects. Thus, some respondents initially perceived the bars as stacked and wondered why such colors were not shown on the legend. This particular overlapping design was chosen, initially because it was the default format using the Emoncms multigraph tool. Alternatively, line graphs were considered. However, line graphs tend to suffer from visual peculiarities as viewers attempt to interpret and compare line slopes. For that reason, line graphs are also better tuned for presenting time series data (e.g., the cumulative energy use graph); here, the data points were discrete and aggregated. Overlapping bars is certainly atypical, but rather than dismissing it for that purpose alone, the following factors were considered. The main benefit of overlapping bars is that they draw a direct comparison while taking less visual real-estate in comparison to side-by-side bars, which are the standard. Also, it was believed that the live data being shown would clarify this relationship over time as users experience the dynamics of the graph ­ something that was not possible during the present design review. Thus, this design was retained. 51

4.7.2 Iteration 2 ­ Usability Test Prototype based on Initial Feedback
With the results from the first design review, a second prototype was created. This second iteration was prepared for a more formal usability test with two volunteer participants from the target user population. The two volunteers were identified by the property manager at Phoenix Place. The purpose of this usability test was not to collect quantitative data on readability, or users satisfaction or preferences as is typically done (Cialdini & Goldstein, 2004). Rather, it was intended as a sanity check to ensure that representative users from the target community could understand and appreciate the data presented within the displays. The prototypes shown in Figure 4-4 and 4-5 were presented to the users. The test followed the script shown in Appendix J.

Figure 4-4: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 2

52

Figure 4-5: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 2

4.7.2.1 Design Walk Through Based on comments received from the first review, the Last 24 Hours graph was removed in favor of a simpler, though less informative, comparative bar graph display. These bars now only showed the cumulative energy use for current day without any further information on how the bars arrived there. There is no longer any historical temperature data shown here. The benefit of the side-by-side bars is that they more intuitively link with the bars shown in the last 7 days. In fact, in this example, the Today bars are intentionally redundant with the most recent bars in the Last 7 Days. This visual relationship benefits from the Gestalt principle of common fate (Todorovic, 2008), which states that objects that move in a similar direction are perceived to be related. To provide further task relevant information, a daily quota gauge was provided in the Right Now section. This was color coded green to match the green curve in the Last 7 Days and Today graphs. This gauge essentially served as a fuel gauge in a car. The comparator at the bottom of this dashboard in this version showed comparisons against your neighbours' average. On the FCU dashboard, temperature was represented as a numerical figure with a thermostat to denote that it is the measured indoor temperature. Live weather data was shown just below it with a numerical indication out outdoor temperature and an icon corresponding to the sky condition (i.e., here shown as

53

sunny). By showing both indoor and outdoor temperatures, the idea was to promote smarter FCU behaviours such as opening windows to cool the apartment when cooler outside. A placeholder for daily tips was also created to serve as prompts and reinforcement of target behaviours from the information campaign. 4.7.2.2 Results from Usability Test Overall, both participants were able to read and comprehend the information shown in the dashboards. As intended, the bars served as useful means in comprehending relative performance. For example, the participants were able to see how some days consumption was higher or that their consumption was higher (i.e., in Total Suite dashboard) or lower (i.e., in FCU dashboard) than their neighbours' average. Interestingly, it appears that goal-related figures were more important to the users than comparisons against neighbours. One participant commented that he probably uses less than his average neighbor because his work schedule has him away for large portions of the day. There were three friction points however. First, there were issues in understanding the units of measure (i.e., kWh and kW) and explanations of these were required. Some explanation was required. Second, the two temperature figures in the FCU dashboard were not understood from just the graphic icons. It was clear that more labelling was required. Third, the users did not immediately understand the difference between the Total Suite and FCU dashboards. This was likely due to the similar color coding between the displays. The two participants in this usability test confirmed that they did not user their FCU very much.

4.7.3 Iteration 3 ­ Final Prototype for Field Study
Using the results of the usability test, the prototypes were refined resulting in the iterations shown in Figures 4-6 and 4-7. These prototypes were used as part of the field study detailed in Chapter 5.

54

Figure 4-6: Basic Feedback + Social Comparisons ­ Suite Dashboard ­ Iteration 3

Figure 4-7: Basic Feedback + Social Comparisons ­ FCU Dashboard ­ Iteration 3

55

4.7.3.1 Design Walkthrough As per the results from the usability test, textual labels were included to clearly distinguish weather data from indoor readings. To improve clarity, a color coding was applied to visually distinguish Total Suite (now grey colored) from FCU energy and power use. This color coding should be pre-attentively processed faster than reading a title label. With this coding, the title was deemed no longer necessary so it was removed. Removing the title should not create confusion as there are legends or labels on all charts and widgets and on top for each dashboard. To further reduce clutter, a standard refresh icon was used instead of the textual Refresh label. Space was dedicated for goal-related comparators under the heading of "How You're Doing". The wording for this title was chosen to align with the purpose of this section, which is to summarize the key task-related results in a friendly way. In this section for the Total Suite dashboard, both social and goalrelated comparisons are shown. As will be discussed in the next chapter, this was done deliberately to examine the impact of real-time social norming. Finally, the day of week labels were added to the last 7 days to help improve recall of energy related behaviours for that date. 4.7.3.2 Basic Feedback Design From the basic feedback + social comparison dashboard designs the following basic feedback displays, as shown in Figures 4-8 and 4-9, were derived simply by subtracting the social comparison features from Figures 4-6 and 4-8, respectively.

56

Figure 4-8: Basic Feedback Display 1 of 2 ­ Total Suite Energy Use

Figure 4-9: Basic Feedback Display 2 of 2 ­ Fan Coil Unit - Energy Use

57

5. Field Study Design at a MURB in Toronto

This chapter describes the methodology for a yearlong field study (run from September 2014 through August 2015) intended to both demonstrate the feedback research platform (FBRP) and evaluate the visual feedback design described in chapters 3 and 4, respectively. As introduced in Chapter 4, the field study was conducted at Phoenix Place, a MURB in the Parkdale community in Toronto, Ontario, Canada.

5.1

Hypotheses

The purpose of the development of the feedback research platform was to afford the testing of a multitude of visual feedback designs. A limitation of past feedback studies has been the lack of testing of real-time social norming strategies. Given, the homogenous layouts of suites within the target building was very amenable to testing social norming strategies. Thus, the primary research question was: Can combining real-time feedback with real-time social comparisons help communities of users reach individual and collective energy conservation goals? In the context of a broader conservation program, described later in this chapter, this led to the following two hypotheses for the study: Hypothesis 1: The conservation program comprised of an information campaign, participant commitment, an energy audit, and real-time feedback promotes energy conservation. Hypothesis 2: Real-time feedback with social comparisons promotes more energy conservation than with just real-time feedback alone for total home energy use. As mentioned, another objective of the larger project was to understand the impact of thermal comfort and relevant feedback on energy usage. However, the analysis of this data was outside the scope of this thesis.

58

5.2

Experiment Design

The conservation program's objective was to help participants collectively reach 10% in electricity savings from the previous year's energy use. To achieve this, the program was comprised of four interventions: 1) An information campaign which outlined reasons for saving energy and providing energy saving tips. 2) A personal pledge to save 10% of their own energy use from the year prior. 3) An energy audit of electrical appliances within the suite 4) Real-time feedback for a full year. The first three interventions were common across all actively recruited participants. However, feedback was treated as a sole between-subjects variable in the univariate study design. There were two levels of feedback: basic feedback (which contained real-time feedback with historical comparisons), and basic feedback + social comparisons (the same with additional social comparisons). The rationale for these designs was described in depth in Chapter 4.6 and in particular Chapter 4.6.3. Participants were randomly assigned to a feedback condition.

5.3

Recruitment and Participants

With permission and collaboration of the board and property management at Phoenix Place, tenants were first recruited to take part in an information session to kick-start the program. The conservation program recruitment poster is shown in Appendix A. Prior to attending, each participant signed an informed consent form (see Appendix B). As part of the recruitment for this study, a short presentation was given twice on separate weeknights ­ see presentation slides in Appendix D. After the initial recruitment phase, additional canvassing took place in the building lobby for a week to reach a wider audience. Interested tenants were given the same information, but on a one-on-one basis. Eligible participants fulfilled the screening criteria of having lived at Phoenix Place for at least one year prior, being 18 or older, and having working knowledge of the English language. Of the 134 tenants at Phoenix place, 28 participants were recruited. The remaining 106 tenants in the building were not actively participating. However, with permission, their energy usage data from the building's sub-metering system was used for comparative purposes, effectively as part of a control group. As detailed in Section 6.2, only 24 participants met the final eligibility requirements. Table 5-1 59

outlines the breakdown of the participants in each experimental group by gender, place of birth, and age.
Table 5-1. Participant breakdown by Experimental Group, Gender, Place of Birth, and Age

Experimental Group

Basic Feedback Gender

Basic + Social Feedback

Male Female

10 2 Place of Birth

7 5

Canada Europe Africa Asia Central or South America

3 1 5 1 2 Age Range

4 -6 1 1

18-30 31-45 46-60 61+

2 3 4 3

1 3 5 3

5.4

Procedure

Following the initial canvassing and recruitment phase, those interested in participation took part in an information session early in August 2014. In this session they were provided with energy saving tips, presented by Dr. Sara Alsaadani, and introduced to the conservation program goal of saving 10% of energy use throughout the building (see Appendix D). Additionally, led by Samira Zare Mohazabieh, they were asked to complete the New Environmental Paradigm (NEP) questionnaire and demographics survey (see Appendix F), which can be used to provide further insights into user personas through their attitudes toward the environment. The results of this survey were used first, as part of a separate study to advance a predictive model of energy conservation, and second, as a potential covariate for this study. For their attendance and completion of the survey, they were remunerated $20. In total, there were 50 participants in this portion of the study.

60

The same participants in attendance were then introduced to the energy conservation study involving feedback. This presentation (see Appendix E) was delivered by the author and served as part of the recruitment. They were informed about the level of commitment required, should they be interested in participating in this portion of the study, and the hardware that would be installed in their suites. Additionally, they were also asked to commit, in writing, to saving the 10% (see Appendix G). For their participation in this portion of the study, they were informed that they would receive an Android tablet with a high-speed internet connection for the duration of the study as remuneration. They were also informed that the tablet would be used to deliver the feedback information but could also be used for personal purposes (e.g., games, internet surfing). However, caution was given not to transmit sensitive information. We intended to allow participants to keep the tablets at the completion of the yearlong study; however, to avoid deliberate drop-outs, they were not informed of this at the on-set of the study. Collectively, they were walked through the basic feedback dashboard (i.e., the version without the realtime social norming) and the thermal comfort survey (see Appendix H). Following the information session, hardware installations were scheduled with participants in the following two weeks. This was conducted alongside a basic energy audit of electrical appliances (see Appendix I) to help further understand energy use and potential areas for savings within the suites. In total, the hardware and installation and energy audit took on average 40 minutes to complete. Before proceeding with installation of any hardware, tenants signed an informed consent form ­ see Appendix C. Prior to the distribution of tablets, two days of data had been collected, to ensure proper installation and to provide data for the first contact with the feedback. Participants were randomly grouped into one of the two experimental feedback conditions. Regardless of their experimental condition, participants were given a one-on-one walkthrough and tutorial. As part of the walkthrough, their FCU and a readily available appliance (e.g., floor lamp, or oven) were power cycled to show the impact of its power use on the display. This was followed by a basic hands-on quiz intended to ensure they understood the information being displayed and how to navigate through the app. Participants were reminded of the overall 10% savings goal for the program and how the feedback dashboards showed how much kWh per month that goal meant for them given their own historical energy use from the year prior to the study. Participants in the feedback + social norming condition had the additional comparative information explained. However, to avoid adding external motivation, these participants were informed that such 61

information and comparisons were for their knowledge only, and that being better than average was not a program objective. At the onset of the study, all participants were informed their level of engagement with the app would be tracked by the research team. It was also recommended to them that they check their dashboards daily and that their participation required them to check at least weekly. Similarly, they were asked to fill the thermal comfort survey on a weekly basis. A software reminder on the tablet would notify them when the survey should be filled. If they had any questions, they could always call or email the author or another member of the research team. Also, any specific concerns could be conveyed through the openended question at the end of their thermal comfort survey. They were also informed that check-ins would happen approximately every two months by the author to ensure proper functioning of equipment and to answer any questions or concerns about the study. Participants were reminded that their participation was voluntary and that they may withdraw from the study at any time. The feedback portion of the study ran from September 2, 2014 through August 31, 2015. At the conclusion of the study, participants were asked to complete an exit survey (see Appendix K) to get their opinions on the usefulness of the dashboards and their experience in the study.

5.5

Equipment and Installation

The system architecture implemented for this study (see Figure 5-1) was a modification from the general FBRP architecture shown in Figure 3-5. Each suite was fitted with the following components: A battery-powered emonTXv3 installed inside the FCU to measure its fan power draw and output temperature measured at the top diffusing grate of the unit. Data were sampled every 10 seconds. A battery-powered emonTH installed in the "neck" of the apartment where the corridor opens up to the main living space. A Raspberry Pi gateway to relay the data collected for the suite to the content management system on-line. Additionally, Android Tablets (ASUS MemoPad 7 HD with Jellybean 4.2) were given to each participant for three purposes: to view their own energy feedback dashboards, to complete in-situ thermal comfort surveys on a weekly basis, and for general internet browsing as part of the compensation for their participation. Figure 5-2 offers a rich-picture illustration of these devices in the context of an empty suite. 62

Figure 5-1: Architecture for the system installed at Phoenix Place

Figure 5-2: Rich-picture diagram of feedback hardware

63

The Emoncms CMS was installed on a private virtual server on the internet to manage data for the study. Data from all sensors in the study were stored on the same account and database to afford centralized data management. Weather data was pulled in from the Weather Underground service to the same database. Finally, tailored feedback dashboards were created for each user using the CMS. In addition to the hardware installed in suites, there were components installed in the main hallway corridors and in electrical cabinets. emonTHs were installed in the hallway corridor of each floor. Inside the electrical cabinets, emonTXv3s were installed to measure up to two suites' total energy use (i.e., with each suite requiring two 120V lines). Raspberry Pi gateways were installed in the same electrical cabinets to relay all data collected from sensors in these spaces. A building-wide internet connection was provided to allow all sensor data to be forwarded to the online CMS and for data to be downloaded to tablets. To enable this building-wide internet connection, a series of wired and wireless Wi-Fi repeaters from OpenMesh (2014) were utilized. Access to this network was restricted via MAC address to only the Raspberry Pis and tablets associated with this study. Transfer speeds were throttled to meet minimum data transfer requirements for the purposes of this study while ensuring equal and maximum benefit of the shared internet to all participants. With any Internet of Things application, data privacy is a major concern. In this study, data privacy was handled through data confidentiality at all times and data security when possible. While data being transmitted over radio was not encrypted it was specially coded without linking the data to a specific participant; thus, keeping the data anonymous to those outside the research team. Due to the nature of the data collection scheme, it was necessary for all data to be collected on a single user account (an account only the researchers have full access to through password protection). Similarly data collected from Google Analytics and OpenDataKit are password protected. Through the Android application, participants only had access to their own dashboard (through a special 10-digit code assigned to them by the researchers). Even if they became aware of another dashboard code through trial-and-error or other means, the dashboard itself would not identify the participant to which it belongs; thus, maintaining anonymity. While it is impossible to provide full data security, the use of passwords and coding schemes were deemed adequate to protect the participants' privacy.

64

5.6

Measures

The primary dependent measure of interest is the total suite percentage energy use difference between the study period and the year prior. To ensure consistency between historical and study measures, the building's sub-metering system, which was installed by Intellimeter (http://intellimeter.on.ca/) and Measurement Canada certified, was used for this purpose. To form a stronger basis for determining energy use savings or increases, all energy use data was weather-normalized using climate data obtained for Toronto since 1978 from the Government of Canada (http://climate.weather.gc.ca). For statistical analyses, savings would be measured at the individual level. However, for overall program performance, aggregate savings percentage would be calculated for each experimental condition and from the entire study population. There are several potential covariates that will be examined to understand how they modify the dependent variable: Environmental attitudes using NEP scores, Engagement (via dashboard page view statistics), and Pre-study average daily energy use (Examining pre-use as a covariate acknowledges its potential impact on absolute savings.)

5.7

Thermal Comfort Measures

Fan coil energy usage and related thermal comfort data (from surveys, and temperature readings), while important for platform demonstration purposes, were not the primary focus for this experiment. Thus, the analysis of this data is outside the scope of this thesis. However, this sub-chapter offers how that data might be leveraged. To capture thermal comfort related behaviours and strategies, the following could be used: FCU average daily energy use, FCU thermostat set points (see Appendix H, Thermal Comfort Survey page 3), Clothing levels (see Appendix H, Thermal Comfort Survey page 4), and Alternative behaviours (see Appendix H, Thermal Comfort Survey page 5).

The ASHRAE Predicted Mean Vote (PMV) model for thermal comfort utilizes six parameters that were directly measured or estimated in this study: 65

-

Self-reported comfort level (see Appendix H, Thermal Comfort Survey page 2), Ambient temperature from emonTH device, Ambient relative humidity from emonTH device, Clothing levels (see Appendix H, Thermal Comfort Survey page 4), Assumed MET value of seated position (see Appendix H, Thermal Comfort Survey page 1), Estimated average air speeds from FCU usage from the manufacturer, and Assumed radiant temperature from indoor temperature readings.

These parameters could help provide a comprehensive picture of thermal comfort and its impact on FCU and total suite energy use.

66

6. Results and Discussion

6.1

System performance

Outside of a server issue from October 20 ­ November 14, 2014, the system was up approximately 90% of the time. The 10% downtime was attributable to a combination of internet outages, building-wide power outages, sensor battery outages, and wifi and wireless connection drops between the sensors, gateways and router. The sensors were pre-calibrated to within +/- 5% of a `Watts Up? Pro' power meter. However, in the field monthly aggregated energy measurements were within -8 to +18% of the Intellimeter readings with an average measurement of approximately +6%. This discrepancy was likely in large part due to the limitation of the platform's power readings which were deduced using a fixed voltage of 120V, not taking into account voltage drops in the building. While these error figures are not ideal, as they hamper trust and confidence in the system, they were reasonable for the purposes of the pilot. It is worth noting that this discrepancy impacted just the feedback delivered to the participants and not the data that was used for analysis later in this chapter, which was gathered from the Intellimeter readings for year-over-year consistency.

6.2

Participant noise and variability

At the onset of the study, it was discovered that two of the 28 tenants recruited had not been tenants at Phoenix place for a full year prior to the study. While historical comparisons were provided from data gathered for previous tenants living in these suites, it was determined that their data was ineligible for use in the analyses. Nonetheless, their feedback on the platform was taken. Data from another two participants were deemed unacceptable and were effectively removed from the analysis due to extended periods of abnormal energy usage; one participant had a life partner cooccupying the suite at the study's onset and another was using an unsafe personal space heater, which the property manager had disallowed halfway through the study. In general, however, noise factors 67

including vacations, and temporary changes in living arrangements with family members, and significant others were not specially treated despite the temptation to omit periods of known vacation, for example. The reasoning is that such life factors are bound to take place in any field study of such duration. Furthermore, while these events were noted for the study year, they may have as likely happened the year prior. Of the 28 participants recruited, data from only 24 were considered as part of the quantitative analysis. This included data from two other participants who had moved out of the building 9 months into the study; their data set was truncated at that point.

6.3

Conservation Program: Energy Savings

As mentioned earlier, one objective of the conservation program was to achieve an overall 10% in energy savings year-over-year. Naturally, this program-wide objective cascaded to individual tenants, who were asked to save 10% of their own year-over-year energy use. Figure 6-1 illustrates the findings looking at percentage savings of actual group-aggregated kWh use and normalized group-aggregated kWh use across the three groups of participants. The average actual savings percentage between the two feedback groups was 10.8% compared to an increased use of 4.4% for those outside the study. This led to a net delta of 15.2% in relative savings. Similarly for normalized savings percentage, the average for those with feedback was 8.4% compared to an increase of 5.1% for those outside the study for a net delta of 13.5% in relative savings. It appears that the program was successful in surpassing the 10% savings target.

68

14 12 Actual Normalized

Year-Over-Year Savings %

10 8 6 4 2 0 -2 -4 -6 Basic Basic + Social

No Feedback

Feedback Condition

Figure 6-1: Aggregated year-over-year savings by feedback condition

In addition to the conservation program objectives, this thesis also sought to test whether the savings would be statistically significant and thus reliable; and whether providing real-time social comparisons would achieve improved savings in a similarly reliable fashion. The results shown in Figure 6-1 would suggest that there was a small normalized savings improvement between the feedback conditions of approximately 9.4% and 7.3% in favor of having real-time social comparisons. The next chapter describes the results of the hypothesis testing.

6.4

Test of Hypothesis 1 ­ The Effect of the Conservation Program

As introduced in Chapter 5.1: Hypothesis 1: The conservation program comprised of an information campaign, participant commitment, and real-time feedback promotes energy conservation. To test Hypothesis 1, a 2-level (participation type: feedback, no feedback) between subjects ANCOVA was run for the weather-normalized, annual savings percentage dependent variable. Individual participant's energy use (in kWh) for the year prior to the study was entered as a covariate.

69

There was a significant difference in savings between participation type (F(1,128)=3.938, p=.049*). Figures 6-2 and 6-3 illustrate the effect; those who participated and received feedback saved 8.4% on average, whereas those without feedback used 5.1% more for a 13.5% difference between the groups. Note that the group averages in these figures are calculated by averaging each participant's savings percentages (kWhs reduced compared to kWh used the previous year), whereas the group aggregated figures from Figure 6-1 represent savings percentages calculated based on the entire participant group's combined kWh savings. There was also a significant effect for the Baseline energy use covariate (F(1,128)=5.085, p=.026*). This indicated that the higher the baseline energy use, the more savings potential there was concurring with Allcott's (2011) finding with Opower home energy reports.

20

15

10

Savings %

5

0

-5

-10

-15 No Feedback Feedback

Experimental Condition

Figure 6-2: Error bar graph of experimental condition on savings percentage Note: Error bar graphs represent 95% confidence intervals

70

100

50

Savings %

0

-50

-100

-150 No Feedback Feedback

Experimental Condition
Figure 6-3: Box plot of experimental conditions on savings percentage

This result is encouraging and provides further evidence that the conservation program surpassed its 10% savings target. Furthermore, when enlarging the perspective of the field study, this is a very encouraging result for a couple reasons. First, the participants were not financially motivated to save since their monthly rent would be flat regardless of their performance. Second, many of the participants could be considered low power users with a baseline from which there was very little excess to trim. In a study with participants from a broader sample of home owners in townhomes, semi- or detached homes, it could be reasonably expected that such participants would save more. However, this test does not allow us to make any conclusive statements on the efficacy of feedback since the experimental condition was additionally comprised of an information campaign, a personal commitment to save 10%, and an energy audit. Additionally, an overall limitation of the field study was that the self-selection bias makes it difficult to discern whether energy savings are attributable to the participant's characteristics or due to their reaction towards the feedback and conservation program. Unfortunately, a randomized control trial, where we might have recruited twice as many participants and randomly denied half, was not possible given the small overall study population.

71

6.5

Test of Hypothesis 2 ­ The Effect of Social Comparisons

Compared to Hypothesis 1, the experimental design was more deliberately intended for the testing of Hypothesis 2 with the type of feedback provided as the sole controlled difference between the two groups. All participants who received feedback, observed the information campaign, pledged to save 10%, and had an energy audit. To recap: Hypothesis 2: Real-time feedback with social comparisons promotes more energy conservation than with just real-time feedback alone for total home energy use. To test Hypothesis 2, a 2-level (feedback type: basic, basic+social comparisons) between subjects ANCOVA was run for the weather-normalized annual savings percentage dependent variable. NEP scores (a proxy for environmental attitudes), page views (a proxy for engagement), and pre-study energy use were entered as subject level covariates. There were no significant findings on normalized savings percentage for NEP scores (F(1,19)=.485, p=.50, n.s.) , page views (F(1,19)=.568, p=.46, n.s.), pre-study energy use (F(1,19)=.094, p=.76, n.s.) or feedback (F(1,21)=.114, p=.74, n.s.). Thus, hypothesis 2 was rejected. Figure 6-4 illustrates this non-significant effect.

30 25 20 15 10 5 0 -5 -10 Basic Feedback Basic + Social

Savings %

Feedback Condition

Figure 6-4: Error bar graph of feedback condition on savings % Note: Non-significant effect. Error bars represent 95% confidence intervals

72

This non-significant effect is not unexpected given the wide variability of energy savings observed yearover-year, the relatively small difference in savings between the two feedback conditions of 3.5% (i.e., 6.6% vs 10.1%) and the relatively small sample size for each feedback condition. Given the effect size between the two conditions is rcontrast = .072, a power analysis (using an alpha = .05, beta = .8) suggests that a study sample size of 1,516 participants would have been required to obtain significant results. While a sample of this size may not be feasible for a pilot study, at a utility scale, this may be realistic. The trends shown in these results may warrant future consideration on that front. Interestingly, this improvement in savings was in line with findings from several Opower studies (Allcott, 2011) leveraging their home energy reports as part of large scale utility projects. However, there are two key differences to consider between those utility projects and the current field study. The first difference is in the intervention design. Homeowners either received Opower's home energy reports (with social comparisons data and energy saving tips) or nothing; whereas the current field study compared feedback dashboards differing only in the availability of social comparisons data. Because the difference in treatment conditions in the current field study and analysis were smaller (basic feedback data vs basic feedback with social comparisons), it could be expected that the social comparisons data design had more net impact than Opower's solution. The second difference deals with the feedback delivery mechanism and frequency. Opower's study was essentially a paper-based report delivered either monthly, bi-monthly, or quarterly. In the current study, the feedback was delivered electronically and in near real-time. However, one would anticipate that real-time feedback should be more effective than less frequent home energy reports (Darby, 2006). As a more fair basis for comparison between the current field study and Allcott's findings, we might compare savings between the basic+social feedback treatment group (n=12) and the control group (n=104). From Figure 6-1, the difference between average treatment savings was 14.5% (i.e., 9.4% vs 5.1% in normalized savings). Compared to Allcott's findings of savings averaging 2%, the large improvement here is most likely attributable to the delivery of social comparisons feedback in real-time. As a reminder, the treatment group in the current field study was, however, also exposed to the information campaign, commitment, and energy audit interventions. As also mentioned, there may have been self-selection bias in play. Finally, it should be noted that the Opower studies were conducted at the utility scale with tens of thousands of participants, whereas the current field study had a sample of just 12 with social comparison data. Nonetheless, this finding warrants further work exploring the

73

efficacy of real-time social comparisons. As suggested above, one way forward would be to pursue the solution at a larger scale.

6.5

Exploratory Analysis of Engagement

At the onset of the hypothesis testing, it was important to assess whether year-over-year savings were sufficient to capture trends. In addition to year-over-year analyses, all results were binned by season ­ Fall, Winter, Spring, and Summer. Analyses of covariance (ANCOVAs) were run with seasons as withinsubject variables; however, it was determined that the results were not necessarily more insightful than year-over-year analyses ­ so only year-over-year results were reported earlier in Chapter 6. The one exception was the noticeable drop in dashboard views beyond the Fall months, which applied to both feedback groups as shown in Figure 6-5. Interestingly, despite this trend, there was not a significant change in seasonal savings. This suggests that while feedback was of more interest for the first few months, the benefit may persist despite lower engagement.
Savings % 20 18 16 14 12 10 8 6 4 2 0 Fall Winter Spring Summer Basic Feedback Engagement 70 20 18 16 14 12 10 8 6 4 2 0 Fall Winter Spring Summer Basic + Social Feedback Savings % Engagement 70 60 50 40 30 20 10 0

Actual Energy Savings %

60
50 40 30 20 10 0

Figure 6-5: Savings and Engagement by Quarter

Interestingly, the levels of engagement appeared to be higher for the Basic + Social feedback group. However this difference was not statistically significant due to the wide variability in page views across all users and the small sample sizes in each group. However, the trend in higher engagement levels

74

Dashboard views / Month

among basic + social feedback participants may warrant further investigation on whether having social comparison data improves overall user interest and usage experience.

6.6

Exit Survey Results

Of the 24 eligible participants, only eight returned their exit surveys (See Appendix K). Thus, rather that attempting inferential statistics on the dataset, it was deemed reasonable to simply provide qualitative insight as to what worked and what did not. Not surprisingly, many of the respondents were also of the most engaged in the study judging by their number of dashboard views. Overall (Questions 1 and 2), respondents commented that the dashboards raised their awareness of their energy use. Additionally, one respondent stated that "[It] was a good experience and I enjoyed the competition with my neighbors". Another user liked "[being] able to compare my usage to what I thought I was using". This suggested that the comparative elements were engaging. However, other users seemed to find it difficult to reach their targets as suggested by the following comments: "It's not easy to change lifestyle to save energy", and "The target limit was not appropriate". On the negative front (Questions 3 and 6), users commented about being frustrated at times with slow or inconsistent internet connection. One user also commented on "a constant feeling the readings were incorrect". Taken together, these comments would suggest that there is work to be done to improve the reliability of the system. For the dashboard widgets (Question 4), users with basic feedback found the "LAST 7 DAYS" charts and the historical and daily target lines to be the most useful. Interestingly, those with social comparisons valued the "TODAY" widget and seeing their neighbors' usage most. The "RIGHT NOW" and "HOW YOU'RE DOING" widgets were found least useful overall. The daily tips appeared to be most polarizing amongst respondents ­ they appeared to be either liked the most or least. As for top savings strategies (Question 9), comments appear to fall into either cooking related strategies (e.g., cooking for multiple days, or reheating with the microwave) or being more diligent about turning appliances off when not in use. Reassuringly, all respondents were able to estimate their savings to within one neighboring 10% bin on the survey (Question 8). This included a participant, who had used 33.6% more than the previous year, who had estimated he had used 10-20% more. 75

Overall, the results of the exit survey suggest that the feedback dashboard was useful and achieved the intended effect of raising awareness, and motivating users to save energy. This observation corroborated the statistical results presented earlier in the chapter, which demonstrated the efficacy of the feedback intervention. However, it should be noted that there is bias in these survey results due to only having eight responses from some of the most engaged users in the study.

76

7. Conclusions

The purpose of this thesis was to design, develop, and demonstrate a feedback research platform (FBRP) to afford a systematic approach to evaluating feedback designs. The implementation of this platform leveraged heavily on the advancement of Internet of Things (IoT) and free and open source software (FOSS). The FOSS-IoT-based platform developed in this thesis was tailored to demonstrate three key features: disaggregated feedback, real-time social comparisons, and in-situ surveys to help understand user behaviours. Evaluating the efficacy of real-time social comparisons ­ something that, to the author's knowledge, has not been evaluated in conjunction with feedback ­ was the analytical focus of this thesis. Feedback interventions should not and do not exist in a vacuum. For this reason, the energy conservation program presented in this thesis employed several interventions in addition to feedback, including an information campaign and participant pledges to save 10% towards a collective 10% savings for the program. The program was framed in a Community-Based Social Marketing (CBSM) program implemented at Phoenix Place, an affordable housing project in Toronto, Canada comprised of 136 nearidentical bachelor suites. The conservation program was also designed as a field study to examine the efficacy of two feedback designs. In total, 28 participants were recruited to receive a feedback condition; however, only 24 of those were deemed eligible for the statistical analysis. The results showed a statistical significant effect of the conservation program with a relative year-over-year, weather-normalized savings of approximately 11%, surpassing the goal of 10%. While there was a 3.5% difference in savings favoring an enhanced feedback with social comparisons (vs basic feedback), this was not statistically significant. The non-significant findings were not unexpected as the sample sizes in the study were of a pilot scale rather than a utility-wide implementation across hundreds or thousands of customers. By evaluating the efficacy of social comparisons feedback from the current field in a similar fashion as Opower's home energy reports were evaluated in Allcott's (2011) work, there was a 12.5% discrepancy

77

(i.e., 14.5% savings improvement vs 2%). The improvement in the current field study may be largely attributable to the delivery of the social comparisons data in real-time. However, this finding is unclear due to confounding factors from the study design and limited sample size. While the benefit of real-time social comparisons is unclear, it would be prudent to still ask the question: Would such a feedback strategy be worth the cost? The cost side of this questions is less of an unknown and, on a superficial inspection at least, may not be too large for utilities who already have existing smart meter infrastructure in place. Through the government organized GreenButton initiative (http://www.greenbuttondata.org/), much of this data is accessible. The main component missing is software comparison algorithms. Ensuring a fair social comparison would be perhaps the most difficult, but far from impossible, challenge. While atypical, the benefit of conducting the present study at Phoenix Place was that such complexities were circumvented by virtue of the homogenous nature of the suites and tenant population. Other than requiring the design and processing of software algorithms and visual feedback design, there would be very little added technical cost to such a system. However, the timeliness and frequency of the feedback is still an open question worth answering. To the author's knowledge, GreenButton data is still laggy by a full day.

7.1

Contributions

There are three main contributions from this work; they are detailed in order of significance. First, a feedback research platform was developed with intentions to release the specifications and source to the open source community. It will be made available here: https://github.com/kevinci29/fbrp/. To the author's knowledge, this is the first time such a platform would be openly released in this fashion for the wide public benefit. By releasing the specifications and source for the platform, the author hopes to build a community of researchers who can more easily build off each other's work to discover more effective feedback designs. The platform can help form a common methodological approach to delivering feedback and especially real-time feedback. Being widely and freely available, it should also help clarify the specifications of feedback designs. This will help results be more comparable and reproducible. Through an Internet of Things approach this platform enables some key benefits that have been difficult to produce in the past. For example, it supports disaggregated feedback (i.e., multiple appliances around

78

the home) as well as real-time social comparisons as was demonstrated in this study. Furthermore, insitu surveys allows researchers to better understand energy related behaviours in the home. The second contribution of this work naturally extends the first contribution by demonstrating the platform in action. The implementation of the platform at Phoenix Place in Toronto as part of a field study also allowed the research team to develop a program of research to easily examine the efficacy of a variety of feedback designs and techniques. Additionally, it allowed for the exploration of thermal comfort on energy use. Furthermore, through the literature review, it was identified that there has been a dearth of studies focussing on MURBs. Through this research the author hopes to have demonstrated why they can be quite beneficial for progressing research from lab studies to field studies. Last but not least, this research demonstrated a novel approach to feedback design that leveraged the advantages of the research platform and the MURBs context at Phoenix Place. By implementing realtime social comparisons, this thesis demonstrated how such an approach can help further motivate energy conservation beyond levels shown in past studies. The author has argued that, while the measurable benefit of real-time social comparisons may still be unclear, the cost of implementing it at a wide scale is probably reasonable given existing metering infrastructure. The design of the dashboards in this thesis followed an iterative design cycle. Designs were first informed by theory (i.e., using design heuristics proposed by Trinh and Jamieson (2014), then by usability testing, and now field testing, the author hopes to raise the standard to which feedback designs are rigorously specified and thusly advanced. Such an approach is not unique in the Human Factors or Human Computer Interaction communities, but historically has been lacking in the energy feedback realm. Conversely, perhaps those communities may also benefit from post occupancy evaluations that are often conducted by building engineering firms; and one of which was leveraged for this study.

7.2

Future Work

While the formal study at Phoenix Place has concluded, the sub-metering system is still in place. With permission, the research team will be pursuing follow-up analyses with that data to measure the persistence of savings from both the conservation program and feedback implementation. This will provide insight into the necessity for continual conservation interventions.

79

While the feedback research platform was configured to capture data to help understand the impact of thermal comfort on energy use, it was out scope in this thesis to fully explore that area. Analyses should be conducted to assess perceived thermal comfort from the in-situ surveys as well as measured energy draw from appliances and, in particular, the FCUs. Furthermore, engagement data was collected on the FCU dashboards which can provide insight on the efficacy of disaggregated feedback information. To date, the feedback research platform was configured with a subset of features but it may be reconfigured to meet different applications and research questions. Another benefit of the platform is that it can be scaled for use in a single family home, or for multiple homes in a MURB. Larger implementations are possible with enough server processing and bandwidth. However, the feature set of the platform is rather limited when considering the foreseeable growth areas possible as will be discussed in this chapter. There are several key features worth pursuing in future versions of the platform. Firstly, in the short term, it is important to ensure a higher rate of feedback up-time and feedback accuracy. In the study, there was an estimated a 90% uptime. However, it is not unusual to see industry strive for 99.99% uptime (approximately 1 hour of downtime per year). Improved uptime might be achieved through land-powered sensors vs relying on battery power. Providing a tighter mesh of wifi-repeaters may also help ensure sensor readings are not lost. Also the impact of downtime may be thwarted if sensors could locally store data when there are server connection issues and post them when reconnected. Upgrading power meters to account for voltage measurements would help reduce the discrepancy between official sub-metering systems. More effort in calibrating sensors in the field is also warranted. Such changes would help promote trust and confidence in the system. Second, there may be benefit in fully integrating the Open Data Kit survey tool. Having survey responses in the same database as sensor data affords a more adaptive feedback approach. For example, in the context of the current field study with the thermal comfort survey data collected, it is possible show, in the form of a recommendation, the most popular strategies others had used to achieve their thermal comfort. Or to show empathy, one could show how neighbors were experiencing similar levels of thermal discomfort. To help users understand their energy consumption better, feedback can be framed in terms of how FCU energy use correlates negatively with their thermal comfort. This list is not intended to be exhaustive as there are likely many more possibilities when such data becomes available for feedback.

80

Third, push notifications may be used to alert or inform tenants when key thresholds have been crossed. For example, to warn a tenant when 90% of a daily energy use quota has been reached, or to provide acknowledgement when a monthly savings goal has been achieved. Notifications may also be used to prompt users to perform specific tasks. For example, if the weather forecast indicates a cool day is ahead, a notification can be used to recommend users open the window and turn off their fans or air conditioners. Fourth, another feature would be to incorporate time of use (TOU) pricing. This can be an important feature because lower energy use does not necessarily equate to lower energy costs. Furthermore, it is well known that managing peak demands by shifting energy use to lower peak times can save utilities and the general public billions of dollars in infrastructure costs. TOU optimization algorithms can help tenants save energy and money by recommending or even automating the shifting of high intensity appliances. TOU Services from companies like Bidgely (www.bidgely.com) may enable such a feature. Fifth, another popular trend in the HEMS industry are the integration of controls and automation functionality. At present, the feedback research platform serves mainly a monitoring function, relying on the tenant to manually actuate changes within the environment to reach conservation goals. By implementing controls in the system users can, with a simple click of a button on any internet-enabled device, turn the lights off or program the dishwasher to start when energy costs are lower. At present, the SafePlugs have built into their API the ability to control the power flow to such appliances. Setting a schedule to un-power devices, especially those known to have large phantom loads, when not in use can save more than half of their total daily consumption (Fung, Aulenback, Ferguson, & Ugursal, 2003). In the same vein, programmable thermostats have aimed to save energy by allowing tenants to keep HVAC systems use to a minimum when they are away. Rather than keeping the human as an essential part of the feedback-control loop, automation approaches relieve users from their manual tasks and place them instead in a supervisory role. Such strategies may be built and tested on this platform. Sixth and finally, another emerging trend in the HEMS industry is the shift towards managing microgeneration from solar and wind power generation. The Open Energy Monitor platform was premised on enabling the monitoring of such generation capabilities. Conceptually, given the ideas presented above (i.e., for push notifications, time of use pricing, controls and automation) that one could shape the platform to one which ensures that a home operates on net-zero energy; that is, a home that uses only as much energy as it generates. Such a system could enable homes to be sustained off the grid. Many other technologies would obviously be required to turn this vision into a reality ­ for example, large 81

batteries like the Tesla Power Wall (http://www.teslamotors.com/powerwall) and passive housing designs come to mind. Perhaps with small steps such a vision can be realized. In combination with demonstrations like the one presented in this thesis, the author hopes to have shown how a sustainable future is closer than we might have imagined.

82

Appendix A ­ Recruitment Poster

83

84

Appendix B ­ Conservation Program Consent Form

85

RYERSON UNIVERSITY CONSENT AGREEMENT Research Study: Tenant Engagement and Energy Conservation, Toronto
You are being asked to participate in a research study. Before you give your consent to participate, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do and the degree of your involvement. 1. Investigators:      Prof. Alan Fung, Associate Professor, Department of Mechanical and Industrial Engineering. Prof. Vera Straka, Associate Professor, Department of Architectural Science. Dr. Sara Alsaadani, Post-Doctoral Fellow, Department of Architectural Science. Kevin Trinh, Graduate student supervised by Prof. Vera Straka and Prof. Alan Fung. Samira Zare Mohazabieh, Graduate student supervised by Prof. Vera Straka and Prof. Alan Fung.

2. Purpose of the Study: The purpose of this study is to promote energy literacy and conservation, and to gain an understanding of whether there is a relationship between energy-conscious attitudes and energy consumption. 3. Description of the study: Participation in the study entails completing the attached survey. This survey consists of a fifteen questions documenting your opinions and perceptions about energy use and the environment, as well as a few short questions about yourself. Completion of this survey should take no more than 10 minutes. 4. Risks or discomfort: There is very little risk involved in participating in this study. You may be concerned that someone else may find out your responses to the questions. Please note that there is no right or wrong answer to the questions, we are seeking your individual opinions to each of the statements in the questionnaire. Please note that we will not be collecting any names and will not publish information in any reports that will identify you by unit number or by any other kind of personal information. When we publish reports from this research project, we will be using only general information, not individual information and your confidentiality will be protected. 6. Benefits of the study: The following are potential benefits of the research:    To engage and educate tenants about environmental issues. To promote a community and teamwork spirit. To gain access to valuable information about energy-conscious attitudes, and whether they have an impact on energy consumption.

While this project promises benefit for social good, individual benefit to any of the tenants cannot be guaranteed. 7. Confidentiality: All data collected will be handled confidentially. We will not be collecting any names. Unit numbers will be collected to enable us to link energy consumption data, data from the thermal comfort survey and data from the attitude survey, and to enable

86

us to provide you with feedback about your individual energy consumption. We will not publish unit numbers or specific information about individuals in any publication or report. 8. Voluntary nature of participation: Participation in this study is voluntary. Participation in the study is completely voluntary, will not be coerced by any undue influence from any party and will not influence your present or future relations with Ryerson University or the Property Manager. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time. If you choose to withdraw your participation, any data gathered to that point, provided by you, would be destroyed. At any particular point in this study, you may refuse to answer any particular question or stop participation altogether. 9. Compensation: You will be compensated with $20 for your time and participation. 10. Questions about the study: If you have questions about the research, you may contact Prof. Vera Straka by email: vstraka@ryerson.ca or by phone at 416-979-5000 extension 6495. If you have any questions regarding your rights as a participant in this study, you may contact the Ryerson University Research Ethics Board for information: Research Ethics Board, c/o Office of the Vice President, Research and Innovation, Ryerson University, 350 Victoria Street, Toronto, ON M5B 2K3, 416-979-5042. 11. Agreement: By signing the following agreement and returning it to us, you are indicating that: 1. 2. 3. 4. You have read the information in this agreement You have had a chance to ask any questions you have about the study You understand that you can change your mind and withdraw your consent to participate. You are providing your consent to take part and have your information used in our study.

-------------------------------------------------------------------------------------------------------------------------------------------I, ____________________________________ consent to participate in the study conducted by Dr. Sara Alsaadani, Kevin Trinh and Samira Zare Mohazabieh, and supervised by Prof. Vera Straka and Prof. Alan Fung, Ryerson University. Signed: _______________________________

Date: _________________________________ ----------------------------------------------------------------------------------------------------------------------------- ---------------

87

Appendix C ­ Field Study Consent Form

88

RYERSON UNIVERSITY CONSENT AGREEMENT Research Study: Energy Conservation and Feedback Study, Toronto
You are being asked to participate in a research study. Before you give your consent to participate, it is important that you read the following information and ask as many questions as necessary to be sure you understand what you will be asked to do and the degree of your involvement. 1. Investigators:      Prof. Alan Fung, Associate Professor, Department of Mechanical and Industrial Engineering. Prof. Vera Straka, Associate Professor, Department of Architectural Science. Dr. Sara Alsaadani, Post-Doctoral Fellow, Department of Architectural Science. Kevin Trinh, Graduate student supervised by Prof. Vera Straka and Prof. Alan Fung. Samira Zare Mohazabieh, Graduate student supervised by Prof. Vera Straka and Prof. Alan Fung.

2. Purpose of the Study: The purpose of this study is to investigate the effects of real-time feedback on energy conservation. 3. Description of the study: Participation in the study entails the following: a) Agreeing that equipment is installed in your unit to capture your energy consumption data over a twelve month period, and agreeing to long-term monitoring of the energy consumption from your unit for a twelve-month period (June 2014-May 2015). Equipment installed in your unit will consist of:   

A battery-powered sensor installed in the fan coil unit to measure its power draw and air temperature output. A battery-powered sensor installed in the suite to measure ambient temperature and relative humidity. A free internet connection to allow energy data collected via the afore-described sensors to be transmitted back to the research group. You will also be able to use this internet connection for casual web-browsing1.

1

Note that the provided internet connection should be treated as a public network like you would find at a coffee shop

or hotel. We strongly discourage its use for sensitive information such as online banking. If your participation terminates prior to the completion of the study, we will be collecting the tablet for redistribution. Will encourage you to make any backup of your data. In your presence, we will clear all data from its local memory.

89

The time taken to complete the installation in you unit will be approximately 20 minutes. We will complete the installation at an agreed time that is convenient for you. You do not need to be physically present in your unit during the time of installation. Installation of this equipment will enable us to provide with you with direct feedback about your energy consumption for a two-month period. This feedback will include information about your energy consumption over the last 24 hours and over the last 7 days. In addition to information about your own consumption, you will also receive feedback about your neighbours' average energy consumption over the last 24 hours. You will receive feedback through an application designed specifically for this purpose and installed on an Android Tablet, which will be given to you once you sign this agreement.

b) Completing a short thermal comfort survey approximately once per week:

This thermal comfort survey is also to be completed through your Android tablet. This survey consists of seven short questions about the means undertaken to maintain your thermal comfort during different weather conditions. You will receive a prompt on your tablet once every eight days asking you to complete your thermal comfort survey. You will be receiving this prompt for a total period of two months. Completion of this survey should take less than 2 minutes each time. If you have any questions about this consent or require any technical support or training on how to use you Android tablet, members of the research team will be available in the Lobby at the times posted on the Notice Board to answer your questions and assist you. 4. Eligibility criteria: Before giving your consent to participate in this study, you must satisfy the following eligibility criteria:    Be aged 18 or above. That you have a basic level of English literacy to allow you to understand the research material and to complete the surveys required as part of your participation in the study (see section 3 above). That you intend to reside in your unit in Green Phoenix for at least the twelve-month period between June 2014May 2015.

5. Risks or discomfort: There is little risk in participating in this study. You may also be concerned that someone else may find out your responses to the thermal comfort survey. Please note that the responses are individual to you; there is no `right' or `wrong' answer. In addition, we will not be collecting any names and will not publish information in any reports that will identify you by unit number or by any other kind of personal information. When we publish reports from this research project, we will be using only general information, not individual information and your confidentiality will be protected. You may have concerns about data privacy and security; particularly as the data is going to be transmitted over the internet. We assure you that the data will be completely confidential, and is going to be password-protected and specially coded

90

before it is transmitted over radio. Only members of the research team will be able to link coded data to the participating individual. A final concern you may have is that the internet we have installed for the purpose of our study may affect your own private internet subscription and connection. It will not. 6. Benefits of the study: The following are potential benefits of the research:    To design and aid a system that will help reduce energy consumption To potentially reduce energy consumption and thus help to save money. To promote a community and teamwork spirit.

While this project promises benefit for social good, individual benefit to any of the tenants cannot be guaranteed. 7. Confidentiality: All data collected will be handled confidentially. We will not be collecting any names. Unit numbers will be collected to enable us to link energy consumption data, data from the thermal comfort survey and data from the attitude survey, and to enable us to provide you with feedback about your individual energy consumption. We will not publish unit numbers or specific information about individuals in any publication or report. 8. Voluntary nature of participation: Participation in this study is voluntary. Participation in the study is completely voluntary, will not be coerced by any undue influence from any party and will not influence your present or future relations with Ryerson University or the Property Manager. If you decide to participate, you are free to withdraw your consent and to stop your participation at any time. If you choose to withdraw your participation, any data gathered to that point, provided by you, would be destroyed. At any particular point in this study, you may refuse to answer any particular question or stop participation altogether. Please note that, in the event of withdrawing your participation from the study, we would require you to return the Android tablet that was provided to you as a research instrument. We would also need access to your unit to remove the installed equipment. The time taken to remove the installed equipment would be approximately 5 minutes. Should you choose to withdraw, we will remove the equipment at an agreed time that is convenient for you. Again, you do not need to be physically present in your unit during this time. 9. Compensation: You will be allowed full use of the Android tablet assigned to you as a research instrument for the purpose of this study. You will also be given access to an internet connection for a full twelve-month period. 10. Questions about the study: If you have questions about the research, you may contact Prof. Vera Straka by email: vstraka@ryerson.ca or by phone at 416-979-5000 extension 6495.

91

If you have any questions regarding your rights as a participant in this study, you may contact the Ryerson University Research Ethics Board for information: Research Ethics Board, c/o Office of the Vice President, Research and Innovation, Ryerson University, 350 Victoria Street, Toronto, ON M5B 2K3, 416-979-5042. 11. Agreement: By signing the following agreement and returning it to us, you are indicating that: 5. 6. 7. 8. You have read the information in this agreement You have had a chance to ask any questions you have about the study You understand that you can change your mind and withdraw your consent to participate at any time You are providing your consent to take part and have your information used in our study.

Please feel free to keep a copy of the following agreement for your own records before submitting it.

----------------------------------------------------------------------------------------------------------------------------- --------------I, ____________________________________ consent to participate in the study conducted by Dr. Sara Alsaadani, Kevin Trinh and Samira Zare Mohazabieh, and supervised by Prof. Vera Straka and Prof. Alan Fung, Ryerson University.

Signed: _______________________________

Date: _________________________________ ----------------------------------------------------------------------------------------------------------------------------- ---------------

92

Appendix D ­ Conservation Program Presentation Slides

93

94

95

96

97

Appendix E ­ Energy Tracking Presentation Slides

98

99

100

Appendix F ­ NEP and Demographics Survey

101

RYERSON UNIVERSITY
Energy Conservation and the Green Phoenix
General Information Please complete all questions below. CHECK OFF  the appropriate option.

1. Are you male or female?
 Male  Female

2. What is your age?
    18-30 years old 31-45 years old 46-60 years old Over 60 years old

3. What part of the world did you grow up in? Canada USA Europe South or Central America or Caribbean South Asia (e.g. India, Pakistan, Sri Lanka) East Asia (e.g. China, Japan, Korea) Southeast Asia (e.g. Vietnam, Philippines, Malaysia) West Asia & Middle East (e.g. Lebanon, Iran) Africa (e.g. Ethiopia) Australia, New Zealand or the South Pacific Other, please specify._______________ Prefer not to answer. 4. How many years have you been living in Phoenix Place? 0 to 1 year 2 to 4 years 5 to 7 years More than 7 years
5. How many people live in your household? 1 person 2 persons 3 or more persons

102

Environmental Attitudes: To the best of your understanding, please answer whether you agree or disagree with the following statements by checking the box on the following scale: Strongly Agree Agree Neither Agree nor Disagree 1. We are approaching the limit of the number of people the earth can support. 2. Humans have the right to modify the natural environment. 3. When humans interfere with nature it often produces disastrous consequences. 4. Human ingenuity will ensure that we do NOT make the earth unlivable. 5. Humans are severely abusing the environment. 6. The earth has plenty of natural resources if we just learn how to develop them. 7. Plants and animals have as much right as humans to exist. 8. The balance of nature is strong enough to cope with the impacts of modern industrial nations. 9. Despite our special abilities humans are still subject to the laws of nature. 10. The so-called 'ecological crisis' facing humankind has been greatly exaggerated. Disagree Strongly Disagree

103

11. The earth is like a spaceship with very limited room and resources. 12. Humans were meant to rule over the rest of nature. 13. The balance of nature is very delicate and easily upset. 14. Humans will eventually learn enough about how nature works to be able to control it. 15. If things continue on their present course, we will soon experience a major ecological catastrophe.

104

Appendix G ­ Pledge Form

105

ENERGY CONSERVATION PLEDGE

I (first name, last name)_________________________________________, understand that energy consumption affects our natural environment, human health and overall well-being.

Therefore, to show my support for the tenant engagement program at Green Phoenix, I pledge to make every effort to reduce my energy consumption at home as much as possible, and to contribute toward the buildingwide energy reduction goal of 10%.

106

Appendix H ­ Thermal Comfort Survey

107

Figure 1: Thermal Comfort Survey Page 1 of 8.

Figure 2: Thermal Comfort Survey Page 2 of 8.

108

Figure 3: Thermal Comfort Survey Page 3 of 8.

Figure 4: Thermal Comfort Survey Page 4 of 8.

109

Figure 5: Thermal Comfort Survey Page 5 of 8.

Figure 6: Thermal Comfort Survey Page 6 of 8.

110

Figure 7: Thermal Comfort Survey Page 7 of 8.

Figure 8: Thermal Comfort Survey Page 8 of 8.

111

Appendix I ­ Energy Audit Sample Results

112

Suite No. A A A A A B B B B

Appliance Refregerator Electric Kettle TV Laptop Desk Lamp Microwave Toaster Electric Kettle Rice Cooker

Make LG Rival Insignia Toshiba

Model GR-292R RV-KE5754o NS-39D310NA15 PSCFWC-005002

Year

Rated Pwr(W) 1000 120v - 1.5A 19v - 2.37A 30

On Pwr (W) 16.4 1070 49.6 62.7 15

Stdy Pwr (W) 1.5 0 0 0 0

#Hrs on .Wk 0.35-0.583 28-35 Jul-14

Black and Decker Samsung Samsung Cisco Logitech Toshiba Canon Intertek Sharp Magic Chef Danby Sony RCA Acer

RC426C T23A360 BDH5100 4642HD LSH-00035 PSCDW-005002 MX452 PTC-700 R-2428C 2011

500 50 9 15 5 875 1500 1030

490 32 4.5 14.4 1.8 12.5 5.2 1800 1057

52 0 2.2 13.7 1.5 0 0 0 1.4 0 168

1.5 35 2.5 42 168 0.02083

B B B B B B B C C C C C C C C C D D D D E E E E E

TV BluRay Cable box Speaker Laptop Printer Heater Microwave Refrigerator Toaster TV DVD Laptop Fan Curling Iron Straightening Iron Toaster Laptop Clock/radio Humidifier TV Cable box Modem Land phone Desk Lamp

168 0.25 KDL-32DX420 115 8 Aspire 3680 1 month old 49.8 5.4 29.7 42 167 267 0 1.5 2 0.5 0.5 0 3.8 1.5 2.7 0 15 0 21 0.583 96 on standby 21 0 56 56 168 0

Proctor Silex Acer Sylvannia Air o Swiss Samsung Motorola Bell Panasonic Sylvannia (CFL) KXT94771C UH32EH5300F (from bell) Aspire 357354401

900 45.98 12 69

937 31.8 1.8 2.8 41.3 17.2 8.6

2.75 13

0 13

113

Appendix J ­ Usability Test Script

114

Introduction Thank you for helping me with your participation. I am exploring ideas to improve my energy dashboard for use by tenants like yourself at Green Phoenix, and I am very interested in your feedback. Today I will be exploring some concepts visualizing the energy usage of home heating and cooling systems. Discuss Privacy I am not collecting any information that can be used to personally identify you, such as name, age, gender, etc. I will only collect your verbal answers, and we will not share these outside of my research team. Session Procedure This is how the testing session will work: Using my computer, I will show you some prototypes and ask you to tell me how you interpret an screen elements, or an entire screen. Please say whatever comes into your mind. There are no wrong answers. We are evaluating the concepts, not you. You can end the test at any time you choose, for whatever reason.

115

Questions Introduction: You're a tenant who is participating in our energy conservation study and are given a tablet to help you track your energy use. You just opened the dashboard application to take a look at the energy usage data. (Show Screen 1).

1. Please look at this screen closely and tell me what you think of the information you see. Possible probes (asked if users don't mention anything specific):  What is your initial reaction upon seeing this screen?



What does the information under "Last 7 Days" mean to you?



What does the information under "Today" mean to you?



What does the information under "Right Now" mean to you?



What does the "Tip" mean to you?



What information makes sense to you?



What information doesn't make sense to you?

116

2. Your Fan Coil Unit (FCU) can account for a large portion of your suite's total energy use. Please look at this screen closely and tell me what you think of the information you see. Possible probes (asked if users don't mention anything specific):  What is your initial reaction upon seeing this screen?



What does the information under "Last 7 Days" mean to you?



What does the information under "Today" mean to you?



What does the information under "Right Now" mean to you?



What does the "Tip" mean to you?



What information makes sense to you?



What information doesn't make sense to you?

117

3. Here is a variation of the first screen "Total Suite Energy Use" I showed you. Please look at this screen closely and tell me what you think of the information you see. Possible probes (asked if users don't mention anything specific):         How is this screen different from the first version? What is your initial reaction upon seeing this screen? What does the information under "Last 7 Days" mean to you? What does the information under "Today" mean to you? What does the information under "Right Now" mean to you? What does the "Tip" mean to you? What information makes sense to you? What information doesn't make sense to you?

4. Here is a variation of the second screen "FCU Energy Use" I showed you. Please look at this screen closely and tell me what you think of the information you see. Possible probes (asked if users don't mention anything specific):         How is this screen different from the first version? What is your initial reaction upon seeing this screen? What does the information under "Last 7 Days" mean to you? What does the information under "Today" mean to you? What does the information under "Right Now" mean to you? What does the "Tip" mean to you? What information makes sense to you? What information doesn't make sense to you?

118

Overall 5. Overall, what do you think of what you've seen today?

6. What information do you find valuable? Why?

7. What information do you find useless? Why?

8. Would you use this information on a regular basis? If yes, with what frequency? Would you come back and look at this information again?

9. Does the information motivate you to make changes to your energy use?

119

Appendix K ­ Exit Surveys

120

Research Study: Tenant Engagement and Energy Conservation, Toronto EXIT SURVEY
Name: ______________________ Suite #: _____ OVERALL EXPERIENCE 1. What was your overall impression of the experience using the energy dashboard app on the tablet?

2. What did you like most about using the dashboard?

3. What did you like least about using the dashboard?

4. Please rank the usefulness of the following features on the "Suite Dashboard": (1 = most useful, 6 least useful) ___ "LAST 7 DAYS" Energy Use Chart ___ Historical Use and Daily Targets (Red and Green lines) ___ "TODAY" Energy Use Chart ___ "RIGHT NOW" Power Meter ___ "HOW YOU'RE DOING" Faces ___ "DAILY TIP" 5. Please rank the usefulness of the following features on the "FCU Dashboard": (1 = most useful, 6 least useful) ___ "LAST 7 DAYS" FCU Energy Use Chart ___ "TODAY" FCU Energy Use Chart ___ "RIGHT NOW" Power Meter ___ "Weather and Indoor Temperature" ___ "DAILY TIP" 6. How would you change the presentation of the information, if at all?

7. Do you have any other comments about the feedback system, the tablet, the internet connection?

SAVINGS STRATEGIES 8. Compared to the year before, how much energy do you think you used during this study? Circle the option you feel is most accurate. I used I used I used I saved I saved I saved 20%+ more 10-20% more 0-10% more 0-10% 10-20% 20%+ 9. Please list the top 2-3 changes you made to save energy this past year. 121

Research Study: Tenant Engagement and Energy Conservation, Toronto EXIT SURVEY
Name: ______________________ Suite #: _____ OVERALL EXPERIENCE 1. What was your overall impression of the experience using the energy dashboard app on the tablet?

2.

What did you like most about using the dashboard?

3. What did you like least about using the dashboard?

4. Please rank the usefulness of the following features on the "Suite Dashboard": (1 = most useful, 7 least useful) ___ Historical Use + Daily Target (Red & Green lines) ___ Neighbour Comparisons (Yellow bars) ___ "LAST 7 DAYS" Energy Use Chart ___ "TODAY" Energy Use Chart ___ "RIGHT NOW" Power Meter ___ "HOW YOU'RE DOING" Faces ___ "DAILY TIP" 5. Please rank the usefulness of the following features on the "FCU Dashboard": (1 = most useful, 7 least useful) ___ Neighbour Comparisons (yellow bars) ___ "LAST 7 DAYS" FCU Energy Use Chart ___ "TODAY" FCU Energy Use Chart ___ "RIGHT NOW" Power Meter ___ "Weather and Indoor Temperature" ___ "HOW YOU'RE DOING" Faces ___ "DAILY TIP" 6. How would you change the presentation of the information, if at all?

7. Do you have any other comments about the feedback system, the tablet, the internet connection?

SAVINGS STRATEGIES 8. Compared to the year before, how much energy do you think you used during this study? Circle the option you feel is most accurate. I used I used I used I saved I saved I saved 20%+ more 10-20% more 0-10% more 0-10% 10-20% 20%+ 9. Please list the top 2-3 changes you made to save energy this past year. 122

Appendix L ­ Research Ethics Board Approval Letters

123

124

125

References
Abrahamse, W., Steg, L., Vlek, C., & Rothengatter, T. (2005). A review of intervention studies aimed at household energy conservation. Journal of Environmental Psychology, 25(3), 273­291. http://doi.org/10.1016/j.jenvp.2005.08.002 Allcott, H. (2011). Social norms and energy conservation. Journal of Public Economics, 95(9­10), 1082­1095. http://doi.org/10.1016/j.jpubeco.2011.03.003 Allcott, H., & Rogers, T. (2012). The Short-Run and Long-Run Effects of Behavioral Interventions: Experimental Evidence from Energy Conservation (Working Paper No. 18492). National Bureau of Economic Research. Retrieved from http://www.nber.org/papers/w18492 Becker, L. J. (1978). Joint effect of feedback and goal setting on performance: A field study of residential energy conservation. Journal of Applied Psychology, 63(4), 428­433. http://doi.org/10.1037/0021-9010.63.4.428 Benders, R. M., Kok, R., Moll, H. C., Wiersma, G., & Noorman, K. J. (2006). New approaches for household energy conservation­In search of personal household energy budgets and energy reduction options. Energy Policy, 34(18), 3612­3622. Brandon, G., & Lewis, A. (1999). Reducing household energy consumption: A qualitative and quantitative field study. Journal of Environmental Psychology, 19(1), 75­85. Changing Behaviour. (2009). Interaction Schemes For Successful Energy Demand Side Management (No. Deliverable 5). Europe. Retrieved from http://www.energychange.info/component/content/article/67-deliverables/191-d5interaction-schemes-for-successful-energy-demand-side-management Changing Behaviour. (2013). MECHanisms | Make Energy Change Happen Toolkit. Retrieved August 22, 2013, from http://mechanisms.energychange.info/ Cialdini, R. B., & Goldstein, N. J. (2004). Social Influence: Compliance and Conformity. Annual Review of Psychology, 55(1), 591­621. Darby, S. (2001). Making it Obvious: Designing Feedback into Energy Consumption. In D. P. Bertoldi, D. A. Ricci, & P. A. de Almeida (Eds.), Energy Efficiency in Household Appliances and Lighting (pp. 685­696). Springer Berlin Heidelberg. Retrieved from http://link.springer.com/chapter/10.1007/978-3-642-56531-1_73 Darby, S. (2006). The effectiveness of Feedback on energy Consumption: A Review for DEFRA of the Literature on Metering, Billing and direct Displays. Environmental Change Institute, University of Oxford. Egan, C. (1999). Graphical displays and comparative energy information: What do people understand and prefer? In Proceedings of the Summer Study of the European Council for an Energy Efficient Economy (pp. 2­13).
126

Ehrhardt-Martinez, Donnelly, K. A., & Laitner, J. A. (2010). Advanced Metering Initiatives and Residential Feedback Programs: A Meta-Review for Household Electricity-Saving Opportunities (Research Report No. E105). Washington, DC: American Council for an Energy-Efficient Economy. Retrieved from http://aceee.org/research-report/e105 Ehrhardt-Martinez, K. (2012). A Comparison of Feedback -Induced Behaviors from Monthly Energy Reports, Online Feedback, and In-home Displays. In Proceedings of 2012 ACEEE Summer Study on Energy Efficiency in Buildings. Retrieved from http://www.aceee.org/files/proceedings/2012/data/papers/0193-000244.pdf#page=1 Federation of Canadian Municipalities. (1996). A Municipal Guide on Economic Instruments to Support Municipal Waste Management Programs. Toronto, ON: Resource Integration Systems Ltd. (RIS). Fischer, C. (2008). Feedback on household electricity consumption: a tool for saving energy? Energy Efficiency, 1(1), 79­104. http://doi.org/10.1007/s12053-008-9009-7 Flemming, S. A., Hilliard, A., & Jamieson, G. A. (2008). The Need for Human Factors in the Sustainability Domain. Human Factors and Ergonomics Society Annual Meeting Proceedings, 52, 748­752. Froehlich, J. (2009). Promoting energy efficient behaviors in the home through feedback: The role of human-computer interaction. In HCIC 2009 Winter Workshop. Froehlich, J., Dillahunt, T., Klasnja, P., Mankoff, J., Consolvo, S., Harrison, B., & Landay, J. A. (2009). UbiGreen: Investigating a Mobile Tool for Tracking and Supporting Green Transportation Habits. In Proceedings of CHI2009 (pp. 4­9). Boston, MA, USA: ACM. Fung, A. S., Aulenback, A., Ferguson, A., & Ugursal, V. I. (2003). Standby power requirements of household appliances in Canada. Energy and Buildings, 35(2), 217­228. http://doi.org/10.1016/S0378-7788(02)00086-5 Gardner, G., & Stern, P. C. (2002). Environmental problems and human behavior (2nd ed. Boston MA: Pearson Custom Pub. Gardner, G. T., & Stern, P. C. (1996). Environmental Problems and Human Behavior (1st ed. Allyn & Bacon. Gatersleben, B., Steg, L., & Vlek, C. (2002). Measurement and determinants of environmentally significant consumer behavior. Environment and Behavior, 34(3), 335­362. Government of Canada, N. R. C. (2012). Report to Parliament Under the Energy Efficiency Act 2010-2011. Retrieved August 2, 2014, from http://oee.nrcan.gc.ca/publications/statistics/parliament10-11/chapter1.cfm?attr=0 Holmes, T. G. (2007). Eco-visualization: combining art and technology to reduce energy consumption. In Proceedings of the 6th ACM SIGCHI conference on Creativity & Cognition (pp. 153­162). Washington DC. IEA. (2010). Energy Technology Perspectives 2010. Retrieved from http://www.iea.org/publications/freepublications/publication/name,26100,en.html
127

Janda, K. B. (2011). Buildings don't use energy: people do. Architectural Science Review, 54(1), 15­22. http://doi.org/10.3763/asre.2009.0050 Karjalainen, S., & Vastamaeki, R. (2007). Occupants Have a False Idea of Comfortable Summer Season Temperatures. In Proceedings of Clima 2007 WellBeing Indoors. Helsinki (Finland): FINVAC. Retrieved from http://www.irb.fraunhofer.de/CIBlibrary/searchquick-result-list.jsp?A&idSuche=CIB+DC7482 Katzev, R. D., & Johnson, T. R. (1987). Promoting energy conservation: An analysis of behavioral research. Kempton, W. (1986). Two theories of home heat control. Cognitive Science, 10(1), 75­90. Kort, Y. A. W. de, McCalley, L. T., & Midden, C. J. H. (2008). Persuasive Trash Cans: Activation of Littering Norms by Design. Environment and Behavior, 40(6), 870­891. http://doi.org/10.1177/0013916507311035 Kurz, T., Donaghue, N., & Walker, I. (2005). Utilizing a Social-Ecological Framework to Promote Water and Energy Conservation: A Field Experiment. Journal of Applied Social Psychology, 35(6), 1281­1300. http://doi.org/10.1111/j.1559-1816.2005.tb02171.x Liberman, N., & Trope, Y. (1998). The role of feasibility and desirability considerations in near and distant future decisions: A test of temporal construal theory. Journal of Personality and Social Psychology, 75(1), 5­18. Loewenstein, G. (1996). Out of Control: Visceral Influences on Behavior. Organizational Behavior and Human Decision Processes, 65(3), 272­292. Lutzenhiser, L. (1993). Social and Behavioral Aspects of Energy use. Annual Review of Energy and the Environment, 18(1), 247­289. http://doi.org/10.1146/annurev.eg.18.110193.001335 McKenzie-Mohr, D. (2011). Fostering Sustainable Behavior: An Introduction to CommunityBased Social Marketing (Third Edition). Gabriola, BC, Canada: New Society Publishers. Moezzi, M., & Diamond, R. (2005). Is Efficiency Enough? Towards a New Framework for Carbon Savings in the California Residential Sector. Lawrence Berkeley National Laboratory: Lawrence Berkeley National Laboratory. Norman, D. A. (2004). Emotional design: Why we love (or hate) everyday things. New York, NY, USA: Basic Civitas Books. Petersen, J. E., Shunturov, V., Janda, K., Platt, G., & Weinberger, K. (2007). Dormitory residents reduce electricity consumption when exposed to real-time visual feedback and incentives. International Journal of Sustainability in Higher Education, 8(1), 16­33. Pierce, J., Odom, W., & Blevis, E. (2008). Energy aware dwelling: a critical survey of interaction design for eco-visualizations. In Proceedings of the 20th Australasian Conference on Computer-Human Interaction: Designing for Habitus and Habitat (pp. 1­8). New York, NY, USA: ACM.

128

Prada, J. (2013). Comparing Occupant Self-assessed Behaviour to Actual Metered Consumption (Unpublished Masters thesis). Ryerson University, Toronto, Canada. Raaij, V., F, W., & Verhallen, T. M. M. (1983). A behavioral model of residential energy use. Journal of Economic Psychology, Journal of Economic Psychology, 3(1), 39­63. Roque, M., Straka, V., & Fung, A. (2012). Survey of Household Energy Use in a Toronto Rental High-rise Multi-unit Residential Building (MURB). In In Proceedings of the 2nd World Sustain. Forum (Vol. 2). Safa, A. A., Fung, A. S., & Kumar, R. (2015). Comparative thermal performances of a ground source heat pump and a variable capacity air source heat pump systems for sustainable houses. Applied Thermal Engineering, 81, 279­287. http://doi.org/10.1016/j.applthermaleng.2015.02.039 Sauer, J., Schmeink, C., & Wastell, D. G. (2007). Feedback quality and environmentally friendly use of domestic central heating systems. Ergonomics, 50(6), 795­813. Sauer, J., Wiese, B. S., & Ruettinger, B. (2003). Designing low-complexity electrical consumer products for ecological use. Applied Ergonomics, 34(6), 521­531. http://doi.org/10.1016/j.apergo.2003.07.001 Schott, M., Long, N., Scheib, J., Fleming, K. B., & Brackney, L. (2012). Progress on Enabling an Interactive Conversation between Commercial Building Occupants and Their Building to Improve Comfort and Energy Efficiency. In ACEEE Summer Study on Energy Efficiency in Buildings (Vol. 7, pp. 250­265). Retrieved from http://aceee.org/files/proceedings/2012/data/papers/0193-000234.pdf Schultz, P. W., Nolan, J. M., Cialdini, R. B., Goldstein, N. J., & Griskevicius, V. (2007). The constructive, destructive, and reconstructive power of social norms. Psychological Science, 18(5), 429­434. http://doi.org/10.1111/j.1467-9280.2007.01917.x Seligman, C., Becker, L. J., & Darley, J. M. (1981). Encouraging residential energy conservation through feedback. In A. Baum & J. Singer (Eds.), Advances in Environmental Psychology Energy Conservation: Pyschological Perspectives (Vol. 3). Hillsdale, NJ: Erlbaum Associates. Shippee, G., & Gregory, W. L. (1982). Public commitment and energy conservation. American Journal of Community Psychology, 10(1), 81­93. http://doi.org/10.1007/BF00903306 Sterling, M. (2014). Timestore. Retrieved August 17, 2014, from http://www.mikestirling.com/redmine/projects/timestore St. John, J. (2014, August 18). Data Analytics: What Utilities Are Investing In Now. Retrieved September 27, 2015, from http://www.greentechmedia.com/articles/read/dataanalytics-what-utilities-want-now Syrek, D. B., & Legislature, M. (1980). Michigan litter: after: a study of the impact of beverage container deposit legislation on street, roadside and recreation area litter in Michigan. Retrieved from http://books.google.com/books?id=PpIQAQAAMAAJ
129

Todorovic, D. (2008). Gestalt principles. Scholarpedia, 3(12), 5345. http://doi.org/10.4249/scholarpedia.5345 Trinh, K. (2010). Temporal De-biasing of Behaviour in Residential Energy Consumption: Supporting Conservation Compliance Through Feedback Design (Unpublished Masters thesis). University of Toronto, Toronto. Trinh, K., & Jamieson, G. A. (2014). Feedback Design Heuristics for Energy Conservation. Ergonomics in Design: The Quarterly of Human Factors Applications, 22(2), 13­21. http://doi.org/10.1177/1064804613516761 Trope, Y., & Liberman, N. (2003). Temporal construal. Psychological Review, 110(3), 403­421. Tufte, E. R. (1983). The Visual Display of Quantitative Information (Reprinted edition. Cheshire: CT: Graphics Press. Tweed, K. (2013, October 7). Can Low-Income and Multi-Family Households Benefit From Energy Efficiency?: Greentech Media. Retrieved August 17, 2014, from http://www.greentechmedia.com/%20articles/read/Can-Low-Income-and-Multi-FamilyHouseholds-Benefit-From-Energy-Efficiency Tweed, K. (2015, May 13). Opower Books $90M Contract With PG&E--Its Biggest Ever. Retrieved September 27, 2015, from http://www.greentechmedia.com/articles/read/opower-books-90m-contract-with-pge Verplanken, B., & Wood, W. (2006). Interventions to break and create consumer habits. Journal of Public Policy & Marketing, 90­103. Winett, R. A., Neale, M. S., & Grier, H. C. (1979). Effects of self-monitoring and feedback on residential electricity consumption. Journal of Applied Behavior Analysis, 12(2), 173­ 184.

130

