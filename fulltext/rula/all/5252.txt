Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

Asynchronous Computer Conferencing in the MBA Classroom
Catherine A. Middleton Schulich School of Business, York University, Toronto, Canada, M3J 1P3 cmiddlet@yorku.ca Abstract
Two asynchronous conferencing systems were used in subsequent years in a management skills course. These systems had comparable technological features but were not equally effective in supporting the course. This paper examines differences in the systems and their deployment that led to the success of one and the failure of the other. Data from student surveys show differences in user behaviors and attitudes toward the two systems. Qualitative data help to reveal the importance of pedagogy, technology, systems implementation and user behavior as determinants of successful technological innovation. A model for technological innovation in the classroom is proposed. The conferencing system was expected to enable classroom expansion in ways that would encourage the development of a learning community. The system was designed to create a "collaborative learning environment, ... in which, through conversations, discussion, and debate, participants offer explanations, interpretations, and resolutions to problems." (p. 1323) [1]. This would be achieved by enabling interaction among students who were not in the same class sections, and encouraging fuller, more open discussion of key concepts and issues. The conferencing system would make it easier for student groups to work together on assigned projects, and could be used to distribute course materials, including handouts and copies of instructors' overhead transparencies. The system would be helpful in providing consistent information to students, as questions could be asked and answered in a public forum. This would encourage prompt responses to student queries from instructional team members who were monitoring the system. System usage was not mandatory, but it was anticipated that the system would prove to be of sufficient value to students that they would choose to use it of their own accord. There were no participation grades assigned to contributions to the course that were made on the system. The decision to adopt a conferencing system was based on the benefits expected for the students. The fact that an easily accessible, reliable conferencing system was already in place in the university was also influential in this decision, as little effort would be required to make it available to MBA students. Some members of the instructional team had used the system previously and enthusiastically supported its integration into the management skills course. The system is described below.

1. Introduction
This paper compares two asynchronous computer conferencing systems used in an MBA-level management skills course over a two year period. The initial system was not available after the first year of use, so a switch was made to a second system. Both conferencing systems were commercially available, widely used products. The course content, instructional team and objectives for using technology did not change from the first year to the second, thus it was expected that the systems would be equally effective. This was not the case. The first system was enthusiastically adopted by instructors and students, while the second system was used only minimally. This paper compares the two systems and the circumstances surrounding their adoption and usage. It outlines reasons why the systems were not equally effective and offers a model for successful technological innovation.

1.1 Background
This study looks at the use of asynchronous conferencing in a management skills course. The course was taken by all first semester MBA students in the business faculty of a large public university. Key learning objectives included developing the ability to reflect upon management skills and sharing these insights. Computer conferencing was a logical addition to the course, as it could provide a forum for ongoing reflection and information sharing.

1.2 System 1
System 1 was operated by the campus writing center. The mission of the writing center was to improve students' academic writing skills, but the center made its conferencing system available to other groups in the university for purposes not directly related to this mission. When the system was introduced into the course (in autumn 1996) it was already in use in several other courses in the MBA program, but it was not used by all MBA students. Students were provided with system

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

1

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

access while they were enrolled in the management skills course, but were not guaranteed continued access after the course ended. Each student was given an account and password for System 1. The system could be accessed from computer labs on campus, or by modem from off campus locations. The system offered a command line interface (similar to a DOS environment) for those who did not have sufficient computing resources to support the graphical interface, but most users were able to access the system in its graphical user interface mode. The graphical interface required free client software. Students were encouraged to install this software on their home computers so they could access the system from off campus. Remote access was advantageous, as students could participate in class discussion when it was convenient for them, not just when they were at the university. Public areas on System 1 included conferences for online help, software distribution and campus wide discussion. (Conferences are discussion areas open to multiple users. Messages sent to a conference could be read by anyone with access to the conference. Messages and responses to them are saved in the conference. Users can browse through messages at their own pace, create new messages, and reply to existing ones.) A private area of the system, accessible only to those in the management skills course, was designed by the instructional team. It featured conferences for handouts, discussion, submitting assignments and online help. In addition to accessing the course conferences, students were able to send e-mail and files to each other, check the history of e-mail and conference messages (a feature that showed who had read a given message), read the résumés of other users (if users had provided information in their résumés), see who else was logged into the system and participate in online chats. The online chat feature allowed multiple users to communicate synchronously in a shared space by typing messages to one another. A training session was provided for all students in the second week of the course. At this session students were provided with their own system accounts, shown how to log into the system, and given instructions for installing the software on their home computers. The instructional team encouraged students to use the system regularly, and made course materials available on the system that were not available elsewhere.

Several systems were considered. An option favored by the management skills instructional team was the installation of an in-house version of System 1. In the end, however, a second system was chosen. The intent was to implement System 2 throughout the faculty, making it available to all students, staff and instructors. Given that the management skills course had already experimented with conferencing software, it was decided to pilot the new system in this course. Thus, in the fall of 1997, System 2 was introduced in the skills course. The idea was to provide access to System 2 to all new MBA students, with the understanding that access to this system would be continued throughout their MBA program.

1.4 System 2
System 2 was an educational version of a widely used groupware system. It was administered by the computing support staff within the faculty, and the system was used only by management students. No one on the instructional team had any direct experience with System 2, although some team members were familiar with the non-educational version of the software. The faculty's computing staff had not administered or even used the system before it was implemented. System 2 could be accessed in two ways, via client software, or via an internet browser. The simpler form of access was the internet browser, which was used by students to access the system. The client software, which offered additional features not available via the browser interface, was available to the instructional team. System 2 was designed for use in university courses, and thus had some preset configurations for presenting information. The system had four separate areas for group discussion and interaction. Only two were used in this course: i) a forum for general discussion of all issues related to the course, and ii) a file area for distribution of course materials. A profiles area (where individuals could enter personal information on their academic interests, work experience and hobbies) was not used, although it was not disabled. The scheduling area was not activated. Additional features available in System 2 included online testing and survey administration, but these were not useful in the context of the management skills course and were not used. In addition to the general discussion forum (open to all system users), there were also private discussion areas for each student learning team (5-8 members per team). The only students able to access these private area were the team members, but these groups were also accessible by all members of the instructional team. Students were aware that all messages on the system could be read by the entire instructional team. System 2 did not allow the establishment of a separate area for submitting assignments, nor did it allow assignments to be addressed or directed to individual instructors. However, provided that the student addressed the assignment to instructors only, it was not accessible by other students. Although

1.3 Transition from System 1 to System 2
After System 1 had been in use for two semesters the writing center indicated it was no longer able to provide system access for the management skills course. MBA students had become accustomed to using the system however, and wanted access to a conferencing system on an ongoing basis. Recognizing this demand, the administration committed itself to providing a conferencing system for use throughout the MBA program.

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

2

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

electronic mail was supported by System 2, it was not enabled for this course. System 2 did not provide online chatting, nor was there any way for users to determine who was logged into the system at any given time. There was no feature to indicate who had read a message posted in the discussion area. As with System 1, students were provided with their own accounts and passwords for the system. A training session was given for all students in the second week of the course, at which students were shown how to access the system and how to send messages and share files.

2. Research Questions and Methodology
System 1 was introduced to the management skills course to enable group conferencing and to facilitate information exchange among students and the instructional team. At that time, it was expected that System 1 would be available for usage on an ongoing basis. The instructional team was interested in understanding whether students found this system to be a useful and effective addition to the course, thus a simple survey was designed to gather this information. A year later, when System 1 was replaced by System 2, an unexpected opportunity arose to compare the two systems. The existing survey (modified where necessary to account for different system functionalities) was used again, and provided adequate data to establish that usage patterns and student attitudes toward the two systems were significantly different. Thus, the data reported here were not collected in experimental conditions. In retrospect, it is clear that a more controlled environment would have enabled more rigorous analysis of the data and stronger conclusions regarding user motivations and behaviors. However, rather than dismissing the data because of these limitations, an excellent opportunity to learn from this experience arises. Indeed, it is essential to learn from actual experiences when implementing new technologies, as it is difficult to anticipate and control for the sequence of events that may occur in an implementation process. What is of interest here then is what insights can be gained from the two systems implementations. The analysis focuses on the student users of the systems. There is a considerable literature on information systems success and effectiveness [e.g. 2, 3, 4, 5] but it will not be reviewed here. In the context of this research, the key issues defining success and effectiveness are simple: Was the system used regularly by a majority of the students? Did students like using the system? Did the system enhance the learning opportunities in the course? Did the users think the system was effective? Approximately 70% of the students registered in the course completed the survey (252 respondents to the System 1 survey, 202 for System 2), which asked questions about usage of and attitudes toward the conferencing system they were using. Data from the two surveys allowed for a quantitative comparison of systems usage across two samples, one using System 1, the other

using System 2, with both systems used for the same purposes. Additional data on system usage patterns were gathered directly from the systems, although these data were somewhat incomplete. (For example, there was no way of knowing how many people had read messages posted to System 2, information that was recorded by System 1. As private messages on System 1 really were private there was no way of knowing how many messages were being sent within groups, information that was available on System 2.) Qualitative data were gathered in open ended questions on the survey, and from observations of the two systems in use. These data provide insights as to what is important in introducing a conferencing system into a classroom. The first question of interest concerns the systems users, students enrolled in the course in the two semesters under investigation. How do the users compare? Are the two groups relatively similar? This is an important consideration as research has suggested that user characteristics have an impact on user behaviors and attitudes [6, 7, 8, 9, 10]. If there are no significant differences in user characteristics, then differences in systems usage and attitudes toward the systems are attributable to other factors (e.g. functionality of the technology as it was actually implemented, instructors' attitudes toward the technology, the implementation process). In both samples students were in their first semester of the MBA program, and it was expected that the age and gender composition of these two groups, and their levels of computing skills would be similar. These expectations can be summarized as hypotheses: Hypothesis 1a: The age compositions of the two samples are not significantly different. Hypothesis 1b: The gender compositions of the two samples are not significantly different. Hypothesis 1c: The students' computing skill levels reported in the two samples are not significantly different. Both systems provided a forum for information exchange and for general discussion of course materials. Although the systems had different interfaces and were accessed in different ways, both had the functionality to meet the basic conferencing needs for the course, and were expected to be of equal effectiveness in providing conferencing services. Thus, it was expected that there would be no differences between the systems in terms of systems usage, the ease with which the systems could be accessed, and the perceived effectiveness of the systems. These expectations are outlined in the following hypotheses: Hypothesis 2a: The proportion of students in each sample who used the system does not differ significantly. Hypothesis 2b: The frequency of system usage in each sample does not differ significantly. Hypothesis 2c: The number of messages sent to each system on a weekly basis does not differ significantly.

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

3

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

Hypothesis 3: The ease of accessing each system was not significantly different. Hypothesis 4a: The perceived effectiveness of each system was not significantly different. Hypothesis 4b: The proportion of students in each sample in favor of continued system access was not significantly different. The data used to test hypothesis 2c were drawn from a week by week analysis of postings to the course discussion areas in the two conferencing systems. The data used to test all other hypotheses were collected through the student surveys. Each hypothesis corresponded to a specific question on the survey. For instance, data for hypothesis 2a were provided by responses to the question "Have you logged into [system name]?". Data for hypothesis 2b came from the question "How often do you log into [system name]?", while data for hypothesis 4b were supplied by responses to the question "Would it be helpful for you to have access to [system name] throughout your MBA?". Data were analyzed by using tests for differences in means and differences in proportions. These are simple statistical tests, but they are appropriate to determine whether there are differences between the two data samples. The results of the analysis are outlined below.

equally easy to access, is also rejected. Additional data that lead to the rejection of Hypothesis 2c, and support the conclusion that System 1 was used more frequently than System 2 come from comparing the number of messages sent to each system's public course discussion area. Looking at the data on a weekly basis, it is observed that more discussion took place on System 1 than on System 2. These data are summarized in Figure 1, and indicate a significant difference in mean message totals. Although both systems experienced similar patterns over the first 8 weeks, weeks 9 to 12 are of particular interest. In both cases, there was some initial activity, then a two week period with no messages, followed by a stable period of 5 to 7 messages per week. However, between weeks 8 and 9 the usage patterns diverge, with System 1 peaking at 30 messages in week 10 and usage remaining high in weeks 11 and 12, compared to no usage of System 2 in week 10 and minimal usage beyond that point.
30

# messages sent

25 20 15 10 5 0 1 2 3

System 1 System 2

4

5

6

7

8

9

10

11

12

13

3. Results
3.1 User Characteristics
As expected, there were no significant differences in the overall age or sex composition of students in the two groups, thus hypotheses 1a and 1b were supported by the data. Interestingly, the students using System 2 did report a statistically significant higher mean level of computing skills, indicating that hypothesis 1c must be rejected. The higher skill level may be explained by improvements in computing skill levels that occurred in the student population in one year. It is suggested that the second group's skill level was probably reflective of an average group of students entering an MBA program in 1997, whereas the first group's skill level was reflective of the average skill level of students entering an MBA program in 1996. Comparative statistics for the two groups are provided in Table 1.

Week

3.2 User Behaviors and Attitudes
The survey data does show significant differences in usage of the two systems. For example, while only 5% of surveyed students had never logged into System 1, 23% of potential users did not ever log into System 2. Individuals logged into System 1 more frequently than into System 2, despite noting that it was more difficult and time consuming to access System 1. Tests of the significance of these numbers show that both hypothesis 2a and 2b must be rejected, indicating that usage behaviors did differ for the two systems. Hypothesis 3, that the systems were

Figure 1. Weekly message totals System 1 was judged to be significantly more effective than System 2 as a means of communicating with course instructors and sharing information about the course. Furthermore, only 51% of System 2 users indicated they would value continued access to the system, compared with 90% of System 1 users. The findings are significant, and indicate that System 1 and System 2 were not considered to be equally effective. As such, hypotheses 4a and b must be rejected. Table 1 (on the next page) summarizes the analysis of system usage and user behavior data. Qualitative data also support the conclusion that there were differences in the two systems, in terms of user attitudes and behaviors. In response to open-ended questions on the surveys, System 1 is described as "fast", "accessible", "convenient", "very user friendly" and "easy to use", while System 2 is labeled "unwieldy", "cumbersome", "graphics heavy" and "too complicated". While there is some difference of opinion amongst users of each system (e.g. some users described System 1 as tedious to access, some users found System 2 easy to use), System 1 users generally found it to be helpful in sharing information, encouraging cohesion amongst group members, adding relevance to the course and making the instructional team accessible. In contrast, System 2 users reported that the system didn't work, it crashed frequently, it didn't meet expectations, it added no value to the course and that it was not used by the instructional team or most students. A summary of the qualitative data is available at www.yorku.ca/academics/middletn/tables.html.

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

4

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

Table 1. Comparative statistics a
Sex Age Skill Level System User Frequency of Use Weekly Message Totals Difficulty of Access System Effectiveness Continued Access?
a

System1 p=.40 =1.57  = 2.29 p=.95 =4.30 =7.94 p=.36 =1.83 p=.90

System2 p=.45 =1.68 =2.45 p=.77 =2.74 =2.54 p=.19 =2.34 p=.51

Testb z=-.96 t=-1.74 t=-2.18* z=5.40*** t=11.62*** t=2.32* z=3.04** t=-4.70*** z=7.59***

Conclusion accept H1a accept H1b reject H1c reject H2a reject H2b reject H2c reject H3 reject H4a reject H4b

see www.yorku.ca/academics/middletn/tables.html for a full explanation of these statistics b two-tailed test, z test used for difference between proportions, t test used for difference between independent means, *p <.05, ** p <.01, *** p <.005

In summary then, the only hypotheses supported by the data are Hypotheses 1a and 1b, that there are no differences in the sex or age composition of the two samples. This is an important finding. Given that user characteristics in the two samples are not significantly different, it is reasonable to assume that the observed differences in usage of the systems are attributable to other factors (e.g. technology, implementation) which are explored below.

4. Discussion
What can be learned from these results? The data show that there were significant differences in the usage of and attitudes toward the two systems, systems that were expected to perform equally well in meeting the conferencing needs of students and instructors in the skills course. But although it is interesting to know that one system was used frequently and favored by students while the other system wasn't, it is more important to understand the reasons for the differences in usage and acceptance of the systems. An understanding of why the systems were not equally effective can provide useful guidance for introducing computer conferencing and other technologies into the classroom. Based on the data reported here, and on the experience and insight gained in using these two systems, four distinct factors are identified to explain the observed outcomes: pedagogy, technology, system implementation and user behavior.

capacity. Before any decisions are made as to the types of technologies to be introduced into a classroom, it is first necessary to have a clear vision of why technology of any sort is desirable. While this seems obvious, it is often the case that technology is introduced without a good understanding of how it can contribute to the learning objectives of a particular course. In an ideal situation it is only once the objectives are clear that the process of selecting an appropriate technology should begin. But technology decisions are often out of the hands of individual academics or faculties. There is frequently no choice in the type of technology available, the only choice is whether to adopt the technology or not. Regardless of how the available technology is selected, it should only be adopted if there are strong pedagogical reasons for doing so. For example, it is important to understand how a specific technology can be integrated into the existing course curriculum and structure. Even if the technology will help in achieving set objectives, unless it can also be integrated into the course, it may not be effective. If a technology is set up to deliver materials in a predetermined way, this must be congruent with course objectives and structure. This was one of the differences between System 1 and System 2. System 1 was much more flexible, and had no built-in structure. Instructors could (and did) modify the course area on System 1 as needed, but System 2's interface was fixed. The course was taught the same way with both systems, but although both systems provided conferencing functionality they differed in the extent to which they could be customized. System 2 was less supportive of the teaching style of the course than System 1. It is important to establish clear criteria by which to evaluate the technological innovation. Without such criteria it is difficult to know whether stated objectives are being met or not. In deciding to implement System 1 the objectives were to encourage interaction amongst students in all sections of the course, enable discussion of key issues and concepts, facilitate group work, distribute course materials and provide a forum for announcements and information dissemination. No explicit evaluation criteria were set out when this project began, thus it was necessary to cobble together a variety of indicators to assess the impact of the systems used. Had clearer evaluation criteria been established for both systems, more focused, specific data on usage patterns and users' attitudes toward the systems could have been gathered, using appropriate measuring devices.

4.2 Technology Issues
Technological issues are often considered to be of greatest importance when implementing technology in the classroom. These issues, which include the nature of the computing system to be adopted, the type of computers required to run the system and the reliability of the system, are easy to identify and address. Yet experiences

4.1 Pedagogical Issues
It is suggested that the most important determinant of success when using technologies in teaching is a goodness of fit between pedagogical objectives and technological

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

5

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

here show that two systems that appeared comparable in terms of technological features alone were not equally effective in the context of the classroom. Features and functionality of the system are important, but so too is the ability of the system to actually deliver the features and functionality promised. Technology must respond quickly and be reliable. User comments on the two systems make it clear that the two systems were not the same in terms of reliability or speed. It is particularly interesting to note that System 1 (whose users were less skilled), was described in much more positive terms than System 2, despite the fact that System 1 was considered more difficult to access. This highlights the importance of non-technological factors in introducing computers into the classroom. It appears that System 1 users were willing to overcome initial difficulties in accessing the system in order to gain the benefits the system could offer. This is consistent with research by Davis and colleagues [11, 12] that suggests that perceived usefulness is more important than ease of use in determining actual usage of a system. Another technological issue relates to assumptions about access to equipment. In this course it was important to adopt systems that assumed the lowest common denominator, that is systems that could be accessed with minimal computing power and lower skill levels. Although some MBA programs have had success in using leading edge technology (e.g. the GEMBA program at Duke [13]) there were no minimum computing standards in place for this MBA program. Students who had low end computers had difficulty accessing System 2, which required a minimum of 16 Mb of RAM and worked best with 32 Mb or more. In contrast, System 1 required DOS or Macintosh System 6, available on most computers manufactured in the past ten years. Final points to consider are the availability of technical support, the flexibility and adaptability of the technology, and the ease with which it can be adapted to support pedagogical objectives. A highly structured technology that requires skilled technicians to modify its features may be suitable in specific circumstances, but if the circumstances change (e.g. additional course content is added or the order in which material is covered is altered) then the system may not be able to accommodate such changes. A related issue is the question of who actually controls the system. Can the instructor modify the system at will (provided he or she has the technical knowledge to do so) or is the system under the supervision of computing staff or others? If so, the presence of a strong technical support function is crucial. This was an issue with System 2, which could only be modified by computing staff. Unfortunately, the computing staff available for this task were overworked, undertrained and slow to respond to requests for assistance. In contrast, System 1 could be modified by any member of the instructional team, without any additional help from computing staff.

4.3 Implementation Issues
It would be easy to assume that if pedagogical and technological issues were clearly thought out a systems implementation would be a success. But implementation requires more than good reasons for using a system and selection of a system that meets the stated needs. An implementation strategy must ensure that the potential of a given technology is realized. It must take a system that `looks good on paper' and make it work as intended in the specific context where it will be used. Even basic technologies may not be used to their full potential if a strong implementation plan is not in place. For instance, it is important to validate the technology by establishing its expected contributions to the overall learning objectives of the course. This will help motivate users to try using the system. But motivation is not enough either. Users must be introduced to the technology they are expected to use, and shown how to use it. It should not be assumed that students or instructors will immediately be able to adopt new systems, even if the underlying technologies are simple. Training is required, not only in using the system, but in getting access to the system from a remote location. Ongoing technical support is also needed. Training sessions may not answer everyone's questions and if people don't use the technology immediately they are likely to forget how to access some of its features. One of the objectives of using asynchronous conferencing in the course was to enable people to participate in discussions when and where it was convenient for them. As such, reliable remote access was essential. Both systems did allow remote access, but System 2 was extremely slow, cumbersome and unreliable (see www.yorku.ca/academics/middletn/tables. html for student descriptions of the system). In contrast, although some System 1 users found it difficult to access, the technical requirements were minimal and students logged in remotely at all times of day and night. (It was not uncommon for students to send messages at midnight or 6 a.m., times when the computer labs were closed.) In terms of actual implementation then, System 1 provided much more reliable remote access than System 2, which was hampered by frequent crashes, slow loading graphics and difficulty in transferring files. From an administrative perspective a key issue in effective implementation is ongoing systems maintenance. The conferences must be monitored regularly to ensure messages are posted in the appropriate locations, duplicated information is removed, and questions are answered. An informal code of conduct should be adhered to, ensuring that messages posted to the discussion area are appropriate in tone, use gender neutral language and respect the diversity of system users. Offensive material should be removed from the system, and those responsible for posting offensive material should be contacted so that they understand why a given posting was deemed inappropriate. The author was responsible for maintaining

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

6

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

both systems. Maintenance of System 1 was a simple task, as messages could easily be moved into the appropriate locations, inappropriate messages could be deleted, and specific queries could be forwarded to the member of the instructional team best qualified to answer them. System 2 was more difficult to maintain, because of the actual structure of the conferencing program. Messages were occasionally posted to parts of the system that were not in use, thus it could take some time before they were `found' and responded to. Without e-mail, it was difficult to forward messages to the appropriate respondents. Deleting inappropriate messages was a cumbersome and time consuming process. As a result, System 1 was better maintained than System 2.

4.4 User Behavior Issues
To achieve widespread usage of a new system, positive user behaviors must be encouraged. There must be reasons for potential users to become regular users. If the system offers no valuable information, if there are few other users, or if it is perceived that the system offers no benefit then it is not likely to be a success. A critical mass of users will help ensure success. Markus [14] outlines four conditions required to achieve critical mass: i) appropriate infrastructure must be in place (i.e. the system must be accessible and reliable), ii) users must have access devices to use the system, iii) users must have the knowledge and skills needed to use the system, and iv) users must exercise `communication discipline'. Conditions i), ii) and iii) have been addressed, but iv) requires some explanation. Communication discipline requires that users check the system regularly, whether they are contributing to the discussion or not, and that they respond to messages they receive in a timely manner. Without communication discipline, the system might be accessible by all potential users, but not fully utilized, and thus it would be ineffective. One means of developing a critical mass of users is to encourage system `champions' [15], users who actively promote the system and tell others of the benefits of using it. Research suggests that perceived usefulness is an important determinant of user acceptance of a system [16], thus champions can be very valuable in guiding and influencing others' perceptions of a given system. In the context of this course, the initial champions were the instructional team members. Each teaching assistant worked directly with several student learning teams and was influential in encouraging teams to use the system. The professors also encouraged systems usage by responding to queries posted on the system and making course materials available electronically. System 1 was championed by the instructional team, and a critical mass of student users quickly got online. At least two thirds of the students used System 1 at least once a week, compared to only 25% of System 2 users. Figure 1 also shows that System 1 was used more frequently than System 2. System 2 was not popular with the instructional team. The system was not available for their use until classes

began and only minimal training was provided. The majority of teaching assistants did not have computers that could access the system remotely, a big disadvantage for those who usually worked from home. System 2 passwords didn't always work and the software crashed frequently. Although some team members continued to use the system throughout the semester, many gave up and recommended that their students use e-mail to communicate with them and their group members. The team did not champion System 2, and in fact discouraged behaviors that would have led to a critical mass of users getting online. In addition, as System 2 was unreliable an alternative means of meeting the pedagogical objectives of sharing files and information was developed. A very simple web page was created to distribute materials available on System 2. It did not duplicate the discussion area but did provide all course handouts, thus contributing to the dearth of system users.

4.5 A Model for Effective Technological Innovation in the Classroom
Based on experiences with Systems 1 and 2 it is suggested that all the factors outlined above must be addressed if the introduction of a new technology for teaching is to be successful. Not only must all factors be considered, it is noted that there is a hierarchical relationship among them. Pedagogical issues must form the foundation of any technological implementation strategy. Without a strong pedagogical foundation, no system, regardless of its other characteristics, can be an effective teaching tool. Technological issues should be considered next. Once a suitable technology is in place, appropriate implementation strategies are needed. To encourage usage of a pedagogically sound, robust, wellimplemented technology, positive user behaviors should be encouraged. Thus, the innovation process can be thought of as a ladder, as Figure 2 shows. Each rung in the ladder must be strong. To get to the top (i.e. successful innovation) each step must be taken in order. Using the ladder analogy, both systems have strong first rungs (pedagogy). But progress up the ladder shows that System 2 has very weak subsequent rungs. In contrast, System 1 has solid technology, implementation and user behavior rungs, thus explaining why System 1 was more successful than System 2.
User Behavior Implementation Technology Pedagogy

Figure 2. Ladder of Innovation

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

7

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

Table 2 compares the two systems on the four factors (rungs) proposed as determinants of successful technological innovation. Table 2. Systems 1 and 2 compared System 1 System 2 User Behavior · champions yes no · critical mass of users yes no · perceived value in system yes no Implementation · regular conference yes no maintenance · ongoing technical support yes no · easy remote access yes no · user training yes yes Technology · extra features yes no · flexible yes no · controllable by instructors yes no · adequate technical support yes no · caters to lowest common yes no denominator · reliable yes no · easy to use yes* yes · meets minimal functionality yes yes Pedagogy · clear evaluation criteria no no · technology supportive of yes no teaching style · integration with curriculum yes yes · clear objectives yes yes
*36% of respondents described access to System 1 as difficult and time consuming, but qualitative data suggest that many users found System 1 easy to use.

Proposition 3: The presence of a strong implementation plan that ensures users are adequately trained and have access to technical support will increase the likelihood of successful innovation. Proposition 4: Creating perceived value in the system and encouraging a critical mass of users will increase the likelihood of successful innovation. Proposition 5: The extent to which a technological innovation is successful will be directly related to the achievement of all of pedagogical integration, effective technology, planned implementation and positive user behaviors. The innovation will be less successful if not all factors are achieved simultaneously.

4.6 Other issues
An underlying assumption of the model proposed here is that the process of adopting technology in the classroom is a rational one (see [17] for an overview of the systems rationalist perspective of technological implementation). This model does not account for nonrational issues and behaviors that can occur in organizations and have an impact upon the adoption and implementation of technologies. For instance, the instructors tried to use System 2 in good faith. Handouts were still posted and the few messages that appeared were answered long after it was clear that the system was not being adopted by the majority of students. But there was some resentment that a system that had worked so well (System 1) had been replaced by one that was so ineffective. No doubt some aspects of this resentment spilled over into instructors' attitudes toward System 2, and hampered their abilities to assess the technology rationally or follow rational implementation strategies. Although this was reflected in their reluctance to champion System 2, the `user behavior' component of the model may not fully capture non-rational behaviors. There were also underlying issues of power and politics in play in this case, issues that are not neatly categorized into the model proposed here. For instance, it would have been possible to continue using System 1, as it was transferred from the writing center's control to the university's central computing support center. But the faculty's computing support people wanted to have some control over a new system, a valid concern that was reflected in the decision to go with System 2 which was controlled in-house. There was also an issue regarding the symbolic nature of the system. There was a perception among administrators in the faculty that System 1 was not a legitimate business tool. It had a reputation as a product used in schools, not the work place. System 2 was a widely used business system, and the decision to adopt it was perceived to confer legitimacy on the faculty. This legitimacy quickly dissipated however, as it became obvious that the system, as it was implemented, was seriously flawed. Issues of power and politics are common in information systems implementations [18, 19, 20], as

Table 2 also provides a basis for future research in this area, by outlining specific aspects of the model that can be tested in other contexts. Systems can be compared, or assessed individually, by considering how well they meet or deliver each criteria or feature listed in the table. Starting from the bottom of the table, the criteria are outlined in order of expected importance (e.g. the first step is to outline clear objectives for using technology, then the technology must be integrated into the course ...). The order is based on the data presented here but should be tested in other settings. Five specific propositions can be derived from the model and used to guide future research.: Proposition 1: The success and effectiveness of an innovation will be directly related to the presence of strong pedagogical reasons for introducing the technology. Proposition 2: Functional technology alone is not a sufficient condition for successful innovation. Adoption of technology that is flexible, reliable and easy to use will increase the likelihood of successful innovation.

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

8

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

they are elsewhere in universities. Faculty members should be prepared to acknowledge and address these issues when considering technological innovations. Another issue not fully captured by the model is a macro view of technologies available to potential users. The students had an abundance of technological resources available to them. In addition to e-mail provided by System 1, students had access to two additional e-mail accounts. Full internet access was available and some professors made course materials available through the faculty's local area network. In both years, students were overloaded with computer accounts, passwords and different login protocols. Thus, the importance of providing value in a conferencing system is reinforced when it must compete with other technological means of achieving desired pedagogical and communication objectives. The model proposed in this paper does not take into account individual user preferences and attitudes toward technology. It considers the behavior and attitudes of users as a group (e.g. the importance of a critical mass of users), outlines factors that should be considered in introducing new technologies into the classroom and offers a means of understanding collective responses to a technological innovation. But it does not consider that individual users have different perspectives and approaches to technology. While the issues discussed in the context of encouraging positive user behaviors were identified by the users as being important, and should be considered, there is much to learn from a more detailed analysis of individual users' responses to the introduction of new technologies in the teaching context. Educational research has documented the importance of understanding that students vary in terms of their learning styles and preferred learning behaviors [21, 22]. Information systems research shows that learning styles should be considered when designing computer training programs [23] and there is no reason to believe that learning style preferences do not extend to all learning that is facilitated by technology. Thus, some learners may find technology enhances the learning environment, others may find that technology is a distraction. The needs of those learners who are less favorably disposed toward technology should be carefully considered. Different technological and pedagogical approaches may be necessary to accommodate students with varied attitudes toward computers in the classroom.

diversity, whether it be diversity of cultures, attitudes toward technology, life experiences, skill and ability levels or professional interests. Research is needed to fully understand the impacts of each of these factors in enabling positive uses of technology in the classroom and beyond. Research should build on what already has been done in disciplines like education, computing science and information systems. Much is known about expected behaviors when using various computing technologies [1, 24, 25, 26, 27, 28, 29], but this research should be extended. Specifically, research can build on previous work, seeking to learn from others' experiences, and continuing to build and test models that offer general guidance on technological innovation. This paper proposed a four stage model of effective technological innovation which should be tested in other contexts. The roles of power and politics, the overall technological environment experienced by students, and individual students' personal preferences toward technologically supported teaching and learning also require investigation.

5. Conclusions
This paper compares the usage of two computer conferencing systems. The data provided here support the conclusion that one system was more effective than the other, but the value in this paper arises from the investigation of the reasons for the differences in the two systems and in what this illustrates about implementing conferencing systems. The key finding is the importance of four factors in adopting technology: pedagogy, technological capacity, implementation and positive user behaviors. Each factor must be assessed critically, with a view to achieving a goodness of fit between learning objectives and technological choices. The hierarchical nature of the assessment and adoption process should also be reiterated. Factors build on one another, and strong bases in each category must be established before moving on to the next.

4.7 Future Research
There is much work to be done to improve the uses of technology in teaching, in business schools and elsewhere. The role of individual behaviors and attitudes toward technology must be better understood. A `one size fits all' approach is unlikely to be successful in most instances. Uses of technology must fit with educators' pedagogical and personal objectives, but this is just the beginning. Technology should be used in a facilitative, empowering capacity, one that accommodates student

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

9

Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999 Proceedings of the 32nd Hawaii International Conference on System Sciences - 1999

References
[1] M. Alavi, Y. Yoo, and D. R. Vogel, "Using Information Technology to Add Value to Management Education," Academy of Management Journal, vol. 40, pp. 1310-1333, 1997. [2] W. H. DeLone and E. R. McLean, "Information Systems Success: The Quest for the Dependent Variable," Information Systems Research, vol. 3, pp. 60-95, 1992. [3] W. J. Doll and G. Torkzadeh, "The Measurement of EndUser Computing Satisfaction," Management Information Systems Quarterly, pp. 259-274, 1988. [4] B. Ives and M. H. Olson, "User Involvement and MIS Success: A Review of Research," Management Science , vol. 30, pp. 586-603, 1984. [5] S. M. Lee, Y. Kim, R, and J. Lee, "An Empirical Study of the Relationships among End-User Information Systems Acceptance, Training, and Effectiveness," Journal of Management Information Systems , vol. 12, pp. 189-202, 1995. [6] R. Corston and A. M. Colman, "Gender and Social Facilitation Effects on Computer Competence and Attitudes Toward Computers," Journal of Educational Computing Research , vol. 14, pp. 171-183, 1996. [7] P. A. Houle, "Toward Understanding Student Differences in a Computer Skills Course," Journal of Educational Computing Research , vol. 14, pp. 24-48, 1996. [8] R. Kraut, W. Scherlis, T. Mukhodaphyay, J. Manning, and S. Kiesler, "The HomeNet Field Trial of Residential Internet Services," Communications of the ACM, vol. 39, pp. 55-63, 1996. [9] J. Oderkirk, "Computer Literacy - A Growing Requirement," Education Quarterly Review, vol. 3, pp. 9-29, 1996. [10] R. L. Thompson, C. A. Higgins, and J. M. Howell, "Influence of Experience on Personal Computer Utilization: Testing a Conceptual Model," Journal of Management Information Systems , vol. 11, pp. 167-187, 1994. [11] F. D. Davis, "Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology," Management Information Systems Quarterly, vol. 13, pp. 319-340, 1989. [12] F. D. Davis, R. P. Bagozzi, and P. R. Warshaw, "User Acceptance of Computer Technology: A Comparison of Two Theoretical Models," Management Science, vol. 35, pp. 9821003, 1989. [13] G. DeSanctis, "Curricular Strategies For Teaching Communication Technology," Boston, MA: Academy of Management, 1997. [14] M. L. Markus, "Toward a "Critical Mass" Theory of Interactive Media," in Organizations and Communication Technology , J. Fulk and C. W. Steinfield, Eds. Newbury Park, CA: Sage, 1990, pp. 194-218. [15] J. M. Howell and C. A. Higgins, "Champions of Technological Innovation," Administrative Science Quarterly, vol. 35, pp. 317-341, 1990. [16] F. D. Davis, "User Acceptance of Information Technology: System Characteristics, User Perceptions and Behavioral Impacts," International Journal of Man-Machine Studies, vol. 38, pp. 475-488, 1993. [17] R. Kling, "Social Analyses of Computing: Theoretical Perspectives in Recent Empirical Research," ACM Computing Surveys , vol. 12, pp. 61-110, 1980. [18] H. G. Levine and D. Rossmoore, "Politics and the Function of Power in a Case Study of IT Implementation," Journal of Management Information Systems , vol. 11, pp. 115-133, 1995. [19] M. L. Markus, "Power, Politics, and MIS Implementation," Communications of the ACM, vol. 26, pp. 430-444, 1983. [20] M. D. Myers and L. W. Young, "Hidden Agendas, Power and Managerial Assumptions in Information Systems Development," Information Technology & People , vol. 10, pp. 224-240, 1997. [21] J. Hayes and C. W. Allinson, "The Implications of Learning Styles for Training and Development," British Journal of Management, vol. 7, pp. 66-73, 1996. [22] E. Sadler-Smith, "'Learning Styles' and Instructional Design," Innovations in Education and Training International, vol. 33, pp. 185-193, 1996. [23] R. P. Bostrom, L. Olfman, and M. K. Sein, "The Importance of Learning Style in End-User Training," Management Information Systems Quarterly , pp. 101-116, 1990. [24] M. Alavi, B. C. Wheeler, and J. S. Valacich, "Using IT to Reengineer Business Education: An Exploratory Investigation of Collaborative Telelearning," Management Information Systems Quarterly, vol. 19, pp. 293-312, 1995. [25] D. Bilimoria, "Management Educators: In Danger of Becoming Pedestrians on the Information Superhighway," Journal of Management Education, vol. 21, pp. 232-243, 1997. [26] D. E. Leidner and S. L. Jarvenpaa, "The Information Age Confronts Education: Case Studies on Electronic Classrooms," Information Systems Research, vol. 4, pp. 2454, 1993. [27] D. E. Leidner and S. L. Jarvenpaa, "The Use of Information Technology to Enhance Management School Education: A Theoretical View," Management Information Systems Quarterly, vol. 19, pp. 265-292, 1995. [28] J. Webster and P. Hackley, "Teaching Effectiveness in Technology-Mediated Distance Learning," Academy of Management Journal, vol. 40, pp. 1282-1309, 1997. [29] M. B. Young and C. Gilson, "Management Education with Computer-Mediated Communication: Classroom Experiences, Organizational Lessons," Journal of Management Education, vol. 21, pp. 58-72, 1997.

0-7695-0001-3/99 $10.00 (c) 1999 IEEE

10

