RunningHead:SOCIABLECOMPANIONROBOT  Towards a communication model for a sociable companion robot Lauren Dwyer



Supervisor: Dr. Frauke Zeller Second Reader: Dr. Robert Clapperton Ryerson University

SOCIABLECOMPANIONROBOT  Author's Declaration: AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A MAJOR RESEARCH PAPER I hereby declare that I am the sole author of this Major Research Paper and the accompanying Research Poster. This is a true copy of the MRP and the research poster, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this major research paper and/or poster to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this MRP and/or poster by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my MRP and/or my MRP research poster may be made electronically available to the public.



ii

SOCIABLECOMPANIONROBOT  Abstract Anxiety has a lifetime prevalence of 31% of Canadians (Katzman et al. 2014). In Canada, psychological services are only covered by provincial health insurance if the psychologist is employed in the public sector; this means long wait times in the public system or expensive private coverage (Canadian Psychological Association). Currently, social robots and Socially Assistive Robots (SAR) are used in the treatment of elderly individuals in nursing homes, as well as children with autism (Feil-Seifer & Matari, 2011; Tapus et al., 2012). The following MRP is the first step in a long-term project that will contend with the issues faced by individuals with anxiety using a combined communications, social robotics, and mental health approach to develop an anxiety specific socially assistive robot companion. The focus of this MRP is the development of a communication model that includes three core aspects of a social robot companion: Human-Robot Interaction (HRI), anxiety disorders, and technical design. The model I am developing will consist of a series of suggestions for the robot that could be implemented in a long-term study. The model will include suggestions towards the design, communication means, and technical requirements, as well as a model for evaluating the robot from a Human-RobotInteraction perspective. This will be done through an evaluation of three robots, Sphero's BB-8 App Enabled Droid, Aldebaran's Nao, and the Spin Master Zoomer robot. Evaluation measures include modified versions of Shneiderman's (1992) evaluation of human-factors goals, Feil-Seifer et al.'s (2007) SAR evaluative questions, prompts for the description of both the communication



iii

SOCIABLECOMPANIONROBOT  methods and the physical characteristics, and a record of the emotional response of the user when interacting with the robot. Keywords: Communication, Anxiety, Human-Robot Interaction, Technical Design, Socially-Assistive-Robot, Social Robot.



iv

SOCIABLECOMPANIONROBOT  Acknowledgements This MRP would not be possible without the guidance of my supervisor Dr. Frauke Zeller, who went above and beyond in her role. I would like to thank Dr. Zeller for her constant support, and for bringing the extraordinary world of robotics into my life. Thank you for being such an influential person in my life as my supervisor, mentor, and friend.

I would also like thank Dr. Robert Clapperton as the second reader of my MRP. Thank you for your comments, suggestions, and the recommended readings.

Finally, I would like to thank Leanne Simpson, without whom this MRP would not exist. Thank you for reminding me that sometimes it's okay to take a break, and that commas exist for a reason.



v

SOCIABLECOMPANIONROBOT  TABLE OF CONTENTS ABSTRACT........................................................................iii ACKNOWLDGEMENTS.........................................................v 1. INTRODUCTION..............................................................10 2. LITERATURE REVIEW......................................................12 2.1 Anxiety................................................................12 2.2 Human-Robot Interaction...........................................16 2.3 Technical Design.....................................................19 2.4 Summary...............................................................23 3. RESEARCH QUESTIONS...................................................24 4. METHODS......................................................................24 4.1 Evaluation Development...........................................25 5. RESULTS......................................................................29 5.1 BB-8...................................................................29 5.2 Nao....................................................................33 5.3 Zoomer............................................................... 36 6. DISCUSSION................................................................. 39 6.1 Research Question 1................................................39 6.2 Research Question 2................................................42 6.3 Research Question 3................................................44 6.4 Evaluation Construction...........................................47 7. ETHICAL CONSIDERATION........................................... 48 8. FUTURE RESEARCH...................................................... 49



vi

SOCIABLECOMPANIONROBOT  9. CONCLUSION..............................................................51 APPENDICES...................................................................61 APPENDIX A: EVALUATION TEMPLATE.....................61 APPENDIX B: BB-8 EVALUATION..............................65 APPENDIX C: NAO EVALUATION..............................77 APPENDIX D: ZOOMER EVALUATION........................86 APPENDIX E: USER MANUALS.................................93 REFERENCES...................................................................95



vii

SOCIABLECOMPANIONROBOT  LIST OF TABLES Table 1.0 Emotional Response of the User LIST OF FIGURES Figure 1.............................................................................53 Figure 1.1 Landing/title page when opening the App.......................53 Figure 2 ............................................................................53 Figure 2.1.........................................................................53 Figure 2.2.........................................................................54 Figure 2.3.........................................................................54 Figure 2.4.........................................................................54 Figure 2.5.........................................................................54 Figure 2.6.........................................................................54 Figure 3.1.........................................................................55 Figure 3.2.........................................................................55 Figure 3.3.........................................................................55 Figure 3.4.........................................................................55 Figure 4...........................................................................55 Figure 4.1.........................................................................56 Figure 4.2.........................................................................56 Figure 4.3.........................................................................56 Figure 5............................................................................56 Figure 5.1.........................................................................56 Page 72



viii

SOCIABLECOMPANIONROBOT  Figure 5.2........................................................................57 Figure 5.3........................................................................57 Figure 5.4........................................................................57 Figure 5.5........................................................................57 Figure 5.6........................................................................57 Figure 5.7........................................................................58 Figure 6...........................................................................58 Figure 6.1........................................................................58 Figure 6.2........................................................................58 Figure 6.3........................................................................58 Figure 6.4........................................................................59 Figure 6.5........................................................................59 Figure 6.6........................................................................59 Figure 6.7........................................................................59 Figure 6.8........................................................................59 Figure 7.0........................................................................60 Figure 8.0........................................................................60 Figure 9.0........................................................................52



ix

SOCIABLECOMPANIONROBOT  Introduction Anxiety can turn everyday life into an uphill battle. In Canada, psychological services are only covered by provincial health insurance if the psychologist is employed in the public sector; this means long wait times in the public system or expensive private coverage (Canadian Psychological Association). My Major Research Project (MRP) is the first step in a long-term project that will contend with these issues by using a combined communication, social robotics, and mental health approach. The long-term goal is the development of a socially assistive robot (SAR) companion for individuals suffering from anxiety. In order to accomplish this, I will continue this research at the doctoral level. Virtual prototyping, physical prototyping and user studies are all possibilities for this research. Anxiety has a lifetime prevalence of 31% of the general population (Katzman et al. 2014) and is one of the most common mental health disorders effecting Canadians. With an SAR as the end goal, my preliminary research will focus on a communication model that includes three core aspects of a social robot companion: Human-Robot Interaction (HRI), anxiety disorders, and technical design. To do this I have conducted a literature review and worked with an evaluation model, combining and modifying current evaluative measures. In this MRP, I will focus on the anxiety disorders that the robot will help cope with. As anxiety is a broad term that covers multiple disorders I will, briefly, discuss the ways in which an SAR companion could be helpful and for which it should be considered. I will be focusing on the communication patterns and



10

SOCIABLECOMPANIONROBOT  irregularities exhibited by people suffering from anxiety. These irregularities include vocal differences, facial expressions, and avoidance behaviours (Fuller, Horii & Conner, 1992; Harrigan & O'Connel, 1996). I will also examine what the best practices would be to support the user (Muris, Merckelbach, & Rassin, 2000). In part two of this MRP I will examine social robots and SARs as a subfield of HRI through the work of researchers such as Breazeal (2005) and FeilSeifer and Matari (2011). I will investigate the methods of communication used to eliciting emotional responses in previous studies as well as in current videos of social robot and SAR interactions with users. As a companion for people suffering from anxiety disorders, responding to the user's mood, eliciting the correct emotional response, and employing mimicry and emotional communication will be essential components of the anxiety-SAR. Reik, Paul, and Robinson (2010) examine mimicry and as such will be a principal source for this area. Finally, the third area will be technical, focusing on the design and physical aspects of a sociable robot companion. Here I will investigate the current research to determine how the robot will communicate. I will establish what technologies and main design features will be required to make the robot run and complete the proposed interaction functions required of it. I will evaluate the benefits and disadvantages of a humanoid design using Reichardt's (1978) study as a point of departure. In this area I will also be reviewing communication aspects and the basics of the robot's interaction and physical design (Norman, 2004). As focus will not be given to the mechatronic details of the anxiety-SAR, I



11

SOCIABLECOMPANIONROBOT  will instead highlight some physical features that might be useful for the anxietySAR. This paper will test evaluation methods for the future testing of an anxietySAR while examining the current state of sociable robotics. Specifically, I will be developing a model for the anxiety-SAR that consists of suggested communication means, design features, and technical requirements based on current social robots and socially assistive robots. The present study will use modified versions of robot evaluation scales to assess robots' communication methods in the evaluations of Sphero's BB-8, Aldebaran's Nao, and Spin Master's Zoomer, gaining first hand experience with the robot.

Literature Review Anxiety The terms "anxiety" and "anxiety disorder" currently cover a wide range of symptoms and specialized disorders. In this MRP, the term "anxiety" will be defined as any diagnosed disorder that "shares features of excessive fear and anxiety and related behaviour disturbances" as defined by the Diagnostic and Statistical Manual of Mental Disorders ­Fifth Edition (DSM-V) (American Psychiatric Association, 2013, p. 189). Generalized anxiety disorder can be characterized by "persistent and excessive anxiety and worry about various domains that the individual finds difficult to control" and can be recognized through the following physiological symptoms: restlessness, appearing to be on edge, irritability, fatigue, difficulty concentrating, muscle tension, and



12

SOCIABLECOMPANIONROBOT  disturbances in sleep (American Psychiatric Association, 2013, p. 190). From a communications standpoint anxiety can be recognized through changes in speech (vocal pitch, tension, and jitters), facial expression, and behaviours (Fuller, Horii, & Conner, 1992; Harrigan & O'Connell 1996). One problem that I face when defining a model is the number of disorders that fall under the anxiety umbrella. From social to separation, phobia to general, the variations in anxiety are as different as the individuals themselves. In order to assist individuals suffering from a variety of anxiety disorders, the commonalities between them must be addressed. Anxiety disorders have been found to be highly comorbid meaning the symptoms of each are quite similar; the presence of one disorder often may mean the presence of another (American Psychiatric Association, 2013). Because of this, the differences in the variations of anxiety disorders are found less in the avoidance behaviour or cognitions of individual persons, but rather in the situations that induce their anxiety (American Psychiatric Association, 2013). A prevalent and easily recognizable symptom, and a source of comorbidity across anxiety disorders, is the panic attack. According to the DSMV, panic attacks can be identified as "an abrupt surge of intense fear or intense discomfort that reaches a peak within minutes and during which time four (or more) of the following symptoms occur: 1. Palpitations, pounding heart, or accelerated heart rate 2. Sweating 3. Trembling or shaking 4. Sensations of shortness of breath or smothering 5. Feelings of choking 6. Chest pain or discomfort 7. Nausea or abdominal distress 8. Feeling dizzy, unsteady, light-



13

SOCIABLECOMPANIONROBOT  headed, or faint 9. Chills or heat sensations 10. Paresthesias (numbness or tingling sensations) 11. Derealization (feelings of unreality) or depersonalization (being detached from oneself) 12. Fear of losing control of "going crazy" 13. Fear of dying" (American Psychiatric Association, 2013, p. 214). Some of the aforementioned symptoms of panic attacks could be monitored by an anxietySAR through visual monitoring systems, however many of the technical symptoms would require self-report in order to be effectively assisted. After receiving a diagnosis, individuals with clinical anxiety have a variety of treatment options available to them. For many, psychological and pharmacological treatments are used either independently or in conjunction with one another to manage the daily symptoms, with equal levels of effectiveness (Swinson et al., 2006; Roshanaei-Moghaddam et al., 2011; Bandelow et al., 2007). The most common psychological treatments include Cognitive Behavioural Therapy (CBT) and Mindfulness Based Cognitive Therapy (MBCT), both of which are designed to encourage addressing and controlling anxiety related thoughts and behaviours and require rapport to be built between the administrator and the patient (Roshanaei-Moghaddam et al., 2011). Pharmacological treatments most often include antidepressants such as selective serotonin reuptake inhibitors (SSRIs), selective norepinephrine reuptake inhibitors (SNRIs), and benzodiazepines (Katzman et al., 2014). With this knowledge of the illness at hand, we can establish how a robot could best perceive and process communications of the user's anxiety and respond accordingly. Facial expressions are a common form of communication



14

SOCIABLECOMPANIONROBOT  used to indicate an individual's current perceived mental state. When considering an anxiety-SAR, facial expressions could be monitored and evaluated as a form of communication indicating the user's level of anxiety. Monitoring software has been used as a method for observing anxiety; in a study by Harrigan and O'Connell (1996) researchers videotaped participants being interviewed about previous stressful life events that have caused them anxiety. The goal was to determine what facial cues are consistent with anxiety (levels of anxiety were recorded using self-report measures). Fear related expressions and eye blinks were found to increase with the level of anxiety as well as the presence of nonenjoyment based or "fake" smiles (Harrigan & O'Connell, 1996). One finding of Harrigan and O'Connell's (1996) study that is of particular interest to the present research is that facial movements overall tended to increase during periods of anxiety. Facial expressions as a form of communication could be monitored by an anxiety-SAR, however, it would be important for the sociable companion robot to determine the nuanced differences between genuine and non-genuine expressions as forms of communication. Another symptom of anxiety that is prevalent across the varying disorders is trigger avoidance (behaviour that involves systematically avoiding potential panic attack triggers). Trigger avoidance is often measured through selfmonitoring and a robot could potentially help with the monitoring and warning for potential triggers. Muris, Merckelbach, and Rassin (2000) completed a study that focused on self-monitoring of panic attack symptoms, including agoraphobic avoidance, in people suffering from chronic panic attacks and anxiety. The self-



15

SOCIABLECOMPANIONROBOT  monitoring of bodily functions related to panic attacks and anxiety was found to aid in the reduction of anxiety as opposed to exacerbating anxiety (Muris, et al., 2000). For my research user self-monitoring could be used to create a basis from which a companion robot could measure future anxiety related behaviours. Finally, a sociable companion robot could partake in speech analysis in order to monitor anxiety communication patterns. Individuals suffering from stress-provoked anxiety have been found to demonstrate vocal jitters, tenseness, and pitch changes as a result of increased anxiety levels (Fuller, Horii, & Conner, 1992). These changes in speech could be monitored by an anxiety-SAR in order to effectively help the user. Speech monitoring for mental health is not unheard of; Chang (2012) used non-invasive methods to collect speech data as a way of measuring the status of participants' mental health. The study led to the development of the Affective and Mental Health Monitor (AMMON) library (Chang, 2012). The AMMON library uses mobile phones to analyze stress, affect, and general mental health and is meant to determine users' emotional states (Chan, 2012). A mental health companion robot could use AMMON to monitor and deliver feedback on the patient's mental state in real time. Human-Robot Interaction Human-Robot Interaction (HRI) is a multidisciplinary field of study, intersecting social sciences, robotics, and natural language programming, and focuses on the interaction between humans and robots. Socially Assistive Robotics (SAR) makes up a subfield of HRI and is defined by Feil-Seifer and Mataric (2005) as an intersection between assistive and sociable robots. The



16

SOCIABLECOMPANIONROBOT  primary goal of an SAR is to support the user in everyday tasks through social interaction. These robots are classified further based on their operating mode, appearance, interaction intelligence and modality, and their cask capability (Nestorov et al., 2014). The field of SAR has grown in recent years, with a focus on SARs developed specifically for elderly users, often those suffering from dementia. In particular, SARs with zoomorphic structures (robots designed in the form of animals) have become popular, working as accessible replacements for pet-therapy. An example of this is Paro, the robotic seal making its way through nursing homes. Wada et al. (2004) found that interaction with Paro had a positive effect on both the nurses and the elderly, reducing stress levels and increasing social interaction in the homes where it was introduced. Social robotics as a subfield of Human-Robot Interaction (HRI) research has been pioneered to a great extent by the work of Breazeal. In her research, Breazeal (2002) highlighted the need for robots that could communicate, interact, relate, and be personable with humans. Such robots could offer opportunities for assisting with human anxiety through their life-like quality, human-awareness, ability to be understood, socially situated learning, and physical embodiment (Breazeal, 2002). Much of Breazeal's earlier work focuses on one robot in particular, Kismet. Kismet is a social-robot, with humanoid features such as eyes, eyebrows, a mouth, and ears that can demonstrate a range of facial expressions. Breazeal (2003) gives detailed depictions of the studies used to evaluate Kismet's facial expressions, real-life interactions with humans in task-oriented settings with the



17

SOCIABLECOMPANIONROBOT  major difference being the static or dynamic nature of the studies. Breazeal (2003) makes reference to two of her previous studies in which responses to communication of affective intent with Kismet were examined. In both studies tone of voice was used to elicit various responses - the participants noted Kismet's vocal, facial, and postural changes, each of which could be used as a communication method for my model (Brezeal, 2003). On the subject of communication between the robot and user, non-verbal communication should be considered too. In a study by Breazeal, et al., (2005) researchers noted that non-verbal communication positively impacts the human's ability to understand robots, complete joint (human-robot) tasks efficiently, and correctly identify and attend to any communication errors that arise (Breazeal, et al., 2005). The study of non-verbal communication, as well as implicit communication (where the subjects were able to tell what the robot was going to do through observing cues and inferring a mental status) as a method for the reduction of misunderstanding will inform the future development of my model. Designing a sociable robot with the intention of assisting with anxiety requires that a relationship of rapport be built between the user and the robot. Nomura and Kanda (2016) stress the importance of rapport building between social robots and humans with their development of the Rapport-Expectation with a Robot Scale (RERS). In their experiment Nomura and Kanda (2016) found that robots demonstrating relational behaviour (asking the user what tasks needed to be completed and treating the user as a colleague throughout the tasks) improved the rapport-expectations of the user. The scale developed by Nomura and Kanda



18

SOCIABLECOMPANIONROBOT  (2015), which includes questions such as "This robot may understand me" and "This robot could devote itself to me" (answered on a seven-choice scale) may be considered for future user testing of my anxiety-managing robot (p 24). Following the concept of imitation as a rapport building exercise, Riek, Paul, and Robinson (2010) used variations in robot facial expressions to determine if the degree of mimicking had an effect on perceived interactional satisfaction. Riek et al. (2010) based their findings on a combination of gestural analysis and self-report questionnaires. Participants' responses often echoed the same concept ­ the robot was not believable (Riek et al., 2010). From the robot's mechanical movements to its difficult-to-understand responses the results of this study emphasized the importance of more fluid movements and responses for future robots. While considering non-verbal communication, orientation must also be considered. Brave, Nass, and Hutchinson (2005) studied the interactions between an embodied computer program and human participants to determine if selforientated behaviour or other-orientated (empathic) behaviour has an effect on participants. Researchers found that empathic behaviours lead to more positive ratings among participants (Brave et al., 2005). Perceptions of trustworthiness and caring, as well as likeability were also found to be increased in the empathetic program, emphasizing the need for empathy when designing a sociable robot. The affect of orientation on the expressed emotion and believability of the robot must be considered. Technical Design



19

SOCIABLECOMPANIONROBOT  A pressing debate in the development of sociable robots is whether or not the design should be representative of a human form. In determining the degree to which the model robot should be humanoid I will take into account Norman's (2004) notion that form should follow function. The robot's degree of humanlikeness will depend on whether a humanoid form is necessary to convey the emotional responses that the social robot is required to perform. One potential predicament with designing a humanoid robot is Masahiro Mori's concept of the Uncanny Valley (Reichardt, 1978). The "uncanny valley" refers to a dip in the otherwise positive linear graph describing the relationship between the similarity of a robot to a human and the degree of familiarity or affection that the user feels towards it (Reichardt, 1978). The theory follows that the more a robot looks and behaves like a human, the more likely we are to feel trust towards it with the exception of a robot falling the uncanny valley: when a robot looks realistically human, but not quite human enough to be real, resulting in an uncanny feeling on the part of the user. In order to fulfill its need to elicit human emotion, the sociable companion robot may require human features. Lakatos et al. (2014) found in an observational study the need for non-humanoid robots to convey intentionality and emotions in order to increase believability when interacting with humans. One experiment, employing the wizard-of-oz technique1, examined at humans' ability to recognize "happiness" and "fear" behaviours in the companion robot. The results showed  1The wizard-of-oz technique involves an unseen human "behind the curtain" controlling the behaviour of the robot while the user perceives the robot as acting on its own.   20

SOCIABLECOMPANIONROBOT  that people readily attribute emotions to the robot and interact accordingly (Lakatos, et al., 2014). The social companion robot for anxiety would help manage emotional aspects of a human's behaviour. The robot will require a degree of emotional output in order to build rapport and empathy with the user. Norman (2004) discusses the need for an emotional personality in future robots noting that, at a minimum, simple emotions such as concern for the robots' own physical safety must be taken into consideration. For the model robot, further emotions will be required. One problem that Norman (2004) notes is that emotions that do not appear genuine may not be believable, and as such may not elicit the appropriate response from the users. As eliciting empathy and joy in the user is one of the model robot's primary goals, the development of a believable emotional personality is of paramount importance. As a field, form factor refers to the shape and size of various computer and hardware technologies, considering the specific physical components required for each. Norman (2004) discusses how, when considering the design of everyday items (electronics included) we must first focus on the function that the item will perform before considering how the object will appear in space. This follows the form factor field, particularly when it comes to electronics, specifically robots. Preece, Rogers, and Sharp (2015), note the four basic principles to consider when developing an interactive program: first identifying the needs of the users, next considering alternate designs, building interactive versions of the alternate designs so they can be adequately tested, and evaluating the design of the interactive item.



21

SOCIABLECOMPANIONROBOT  In order to consider the specific design of an anxiety-SAR we must first determine what is required of it. With the "form follows function" (Norman, 2004, p. 175) model in mind we must consider the primary functions that will be necessary for the model robot. In order to be an effective companion for users with anxiety the robot will need to be able to monitor the anxiety patterns (communication patterns, behaviour, physiological symptoms, etc) presented by the user. Monitoring technologies for the physiological symptoms associated with anxiety (increased heart rate, perspiration, breathing rate, and blood pressure) are abundant however these symptoms are not always indicative of anxiety and may be the result of physical activity, for example. Robotics software has been developed in the last year that can recognize approximate age and gender of individuals, running scripts to respond based on the recognized user (Pierluigi et al., 2015). One particularly helpful technology was created and tested by McColl and Nejat (2012). The robot used full upper-body thermal and 2D scanning of users to monitor and interpret motion and postural recognition. Other studies have focused on real-time face motion tracking and voice recognition, both of which could be used in an anxiety-SAR (Bhattachariee et al., 2015). The size and mobility of such a robot should also be taken into account. Since panic attacks (a common symptom across anxiety disorders) can be triggered at any time the robot must be mobile in order to perform its functional duties. Physically, there are certain human-factors goals that the model robot must achieve. According to Shneiderman (1992) there are five factors that must



22

SOCIABLECOMPANIONROBOT  be considered when evaluating the design of a machine through user testing. The first is the time that it takes a user to learn how to interact with the robot successfully though commands etc (Shneiderman, 1992). In the case of the model robot, this would involve the understanding the interaction features such as emotion recognition and appropriate reaction, monitoring communication patterns, and auditory communication. The second measure is the speed of the machine's performance (Shneiderman, 1992). This would encompass the robot's ability to respond to the user's needs in a timely fashion. Measure three is the rate of errors by users while measure four is the amount of information retained by the user over time (Shneiderman, 1992). Summary Research has been conducted surrounding anxiety and the communication patterns of people suffering from anxiety. Specifically recent research has shown the significance of vocal, facial, and eye blink changes in the patterns of communication for people suffering from anxiety (Fuller, Horii, & Conner, 1992; Harrigan & O'Connell 1996). There has also been a focus on the importance of rapport building in anxiety treatments such as CBT and MCBT (RoshanaeiMoghaddam et al., 2011). This rapport building is not unheard of in terms of HRI research, with Nomura and Kanda (2016) developing a scale (the RERS) to measure human-robot rapport levels. The development of a communication model for an anxiety-SAR requires research across the disciplines of HRI, anxiety, and technical design. Currently, in the field of HRI, sociable robots and SARs are being used as social companions



23

SOCIABLECOMPANIONROBOT  and aids for people suffering from autism or dementia. Research highlighting the communications types of robots such as Kismet has shown the need for communication types that go beyond standard voice recognition and natural language speech (Breazeal et al., 2005). The importance of non-verbal communication (facial expressions, sounds, lights, etc) and robot orientation behaviour is noted in the literature (Riek et al., 2010). Finally, research in the area of technical design has shown the technological advancement of monitoring technologies such as voice and facial recognition, as well as the advantages and disadvantages of humanoid robot shape. Research Questions Based on my review of the literature I have devised a series of research questions to consider when developing my own model. RQ1: Which types of robot communication (verbal communication, gestures, and nonverbal auditory communication) can be used in eliciting empathy and reduce anxiety in people suffering from anxiety disorder? RQ2: Which design features (such as humanoid facial features) are necessary for the development of rapport and trust between the user and the robot? RQ3: Which functional physical characteristics are necessary for an anxiety-SAR, taking into account the need for mobility? Methods



24

SOCIABLECOMPANIONROBOT  I will be performing observational case studies on three sociable companion robots. I will evaluate each robot's communication methods, how the robot interacts and responds to user input, the physical characteristics of the robot itself, and the emotional responses that the robot elicits from the user. For the purposes of my research I will be studying the Disney BB-8 app-enabled droid by Sphero, the Nao Humanoid Robot by Aldebaran, and the Zoomer companion dog by Spin Master. It is important to note the bias associated with having a single researcher perform these evaluations. To reduce the bias I will be following the evaluation sheet provided (see Appendix A). Future studies could include multiple observers to increase validity. Sphero's BB-8, Aldeberan's Nao, and Spin Master's Zoomer were evaluated using the measures listed in Appendix A (p. 61). These specific robots were chosen due to their sociable (and in the case of the Nao, assistive) functions, as well as their availability. Testing occurred over two sessions each, with sessions lasting approximately two hours, where the first was used to learn the commands and familiarize myself with the robot, and the second was used to perform the evaluation and test for my ability, as the user, to effectively remember commands. The length and number of sessions was determined based on the robots' availability and the timeline available to the researcher. Evaluation Development: The evaluation template combines multiple evaluation approaches from various aspects of HRI and SAR research to address my research questions. For the purposes of this study the following evaluative measures will be adapted and used in conjunction with one another:



25

SOCIABLECOMPANIONROBOT  Sections I and II - Prompts for the description of both the communication methods and the physical characteristics: These aspects of the evaluation allow the researcher to explicitly determine how the robot communicates with the users prior to determining the effectiveness of each communication method. Here the researcher can elaborate on the physical form of the robot in question as well as how its form can be used to communicate with potential users. Section III. Feil-Seifer et al.'s (2007) SAR evaluative questions (Social Interaction Evaluation): This evaluation measure was chosen to evaluate the robots from an assistive perspective. As an anxiety-SAR will be an assistive robot, I wish to determine which factors (scalability of environments, autonomy, imitation, privacy, social success, understanding of domain, success relative to a human caregiver, cost/benefit analysis, existing quality of life measurements, and impact on the user's role in the community) are present in the current robots that could be applied to an anxiety-SAR. Section IV - Shneiderman's (1992) evaluation of human-factors goals: This evaluation more so than the others is focused on the user's abilities in relation to the robot as opposed to the robot's capabilities. Determining the user's time to learn the commands, speed of performance, rate of error, retention over time, and subjective satisfaction is important when considering the development of a robot



26

SOCIABLECOMPANIONROBOT  as it speaks to the robot's ease of use and its overall effectiveness as an SAR. Section V: A record of the emotional response of the user when interacting with the robot: This area is used to determine what the robots do to elicit emotion in the user as well as what emotions are effectively elicited by the robot. This record is useful for determining how the robots can make the user feel and which actions should be considered (or not considered) based around the emotions best elicited in a person with anxiety. Section VI: Nomura and Kanda's (2016) Rapport-Expectation with a Robot Scale (RERS): This 7-point scale evaluates the development of rapport the robot has with the user. The areas that each robot that is being evaluated excels in may be able to offer insight into features that could be useful for an anxiety-SAR. Robots will be assessed using a modified version of Shneiderman's (1992) evaluation of human-factors goals in order to determine each robot's overall effectiveness as user-friendly machines. Shneiderman's (1992) evaluation has previously only been used for website and software evaluation. As my research relies heavily on the user's ability to quickly gain a working knowledge of the robot they are interacting with, the human-factors goals considered by Schneiderman (1992) will be used to evaluate the relative ease of interaction that is occurring. It is important to note that for the purposes of this study I will be the



27

SOCIABLECOMPANIONROBOT  only one completing the evaluation and therefore the results are not representative or indicative of the general population. An adaptation Feil-Seifer et al.'s (2007) evaluative questionnaire will then be used to examine the robots' social interaction methods. The areas addressed by Feil-Seifer et al. (2007) are specific to SAR with special consideration given to the user and the user's caregiver. Previously the questions asked by Feil-Seifer et al. (2007) were specific to SAR companions for users with dementia with caregivers. As such, some of the questions have been modified to suit users with anxiety that do not necessarily have caregivers. When assessing the sociable robot and SAR this evaluation will be modified specific to the robot under assessment. Measuring rapport built between robots and humans is a recent development in HRI research. Nomura and Kanda (2016) have developed and tested the Rapport-Expectation with a Robot Scale (RERS). The scale measures user's expectations for rapport, determining if users intend to form human-like relationships with their robot. The communication methods will be recorded in the following categories: use of colour and light, sounds (verbal/nonverbal), head/body movements, and voice-recognition response. Finally, the physical characteristics of the robots will be recorded and the emotional responses the robots elicit from the user through a table, modified for each robot. With the observational data I collect from the different robots I will perform a qualitative analysis. Here I will determine which of the evaluative questions (found in Appendix A p. 61) will be applicable for the future testing of



28

SOCIABLECOMPANIONROBOT  an anxiety companion robot. Findings will also be used to determine which human-factors goals, physical characteristics, and social interaction methods would be applicable for the design of an anxiety companion robot. From my results, I will propose the aforementioned model for the anxiety companion with a specific focus on the communications aspect of the robot.

Results The results of the evaluation are detailed below. Each robot is introduced, described, and its evaluation is summarized. An assessment of the literature review and individual robot evaluations can be found in the discussion section. BB-8 by Sphero: (Figure 1.0, p. 53) Appendix B Sphero's BB-8 App Enabled Droid is the latest in the world of sociable robotics. Taking the appearance of the popular Disney droid from the Star Wars franchise, this social robot is advertised as a companion for children and adults alike (Chuang, 2015). Sphero's BB-8 is a sphere (7.3 cm in diameter), with a hat/head (sphere and head combined stand at 11.4cm tall) weighing approximately 200 grams. The robot can be controlled by the user's smart phone and features both controlled and autonomous behaviours as well as an adaptive personality that develops with interaction. BB-8 also features different pre-set emotions that the user can implement, from "happiness" to "frustration." The adaptive personality and preset emotions will be assessed in this research project, as they would be useful for an anxiety-SAR. Presently there is little research



29

SOCIABLECOMPANIONROBOT  surrounding BB-8 and its interaction abilities with users and it's adaptive personality. An observational analysis of the BB-8 app enabled android was performed. The robot connects to a smart-phone app that allows users to interact with the robot through three distinct modes: DRIVE, MESSAGE, and PATROL. DRIVE MODE: (Figures 2 ­ 2.6). When using BB-8 in DRIVE mode there are multiple ways that the user can control and interact with the robot. BB-8 is controlled using the analog control shown on the left side of the screen in Figure 2.1. The further the user drags the directional arrows towards the outside of the circle, the faster BB-8 moves in that direction. The image on the right side of the screen in Figure 2.1 is spun in order to calibrate BB-8 with the aid of a blue "tail-light." There is also an option on the far right screen to adjust BB-8's top speed so that it does not go too fast when maneuvering on different surfaces. When "driving," BB-8 responds to the driving style and movements of the user by making a variety of beeps. For example, when driven into another object it will make "sad" or "frustrated" noises and shake its head in a downward direction. While in DRIVE mode the user is also able to manually control BB-8's 12 pre-set emotional responses, which can be seen in Figures 2.3, 2.4, and 2.5 and are discussed in the evaluation below. MESSAGE MODE: (Figures 4 ­ 4.3). The message mode is designed to appeal to early Star Wars fans that enjoy the holographic projection message relay system used by R2D2 in the first Star Wars film. In the app one is able to record a message (up to 12 seconds) or use one of the pre-set messages (by characters such



30

SOCIABLECOMPANIONROBOT  as Phasma, C3P0, R2D2 etc). When a message has been chosen the user holds the smartphone with the camera facing BB-8, lining it up with the outline of the robot. The "hologram" appears to be projected by BB-8 on the user's screen. PATROL MODE: (Figures 5 ­ 5.6). By hitting the "play" button the user relinquishes control of BB-8 and allows the droid to go off on its own and explore. BB-8 then reports back various stats on its journey such as internal temperature, acceleration, and the gyroscopic balance, all while recording its surroundings so that it doesn't run into the same thing twice - though it often runs into the same thing twice. The user can switch the panels on their device to see the stats displayed in different orders. BB-8 is supposed to "learn" during this mode about its surroundings. When observing BB-8's behaviour it was found that the robot continued to drive into stationary objects multiple times, unless left on patrol for extended periods of time (over 5 minutes). During this mode BB-8 uses its beeps and head motions, and occasionally colour, to convey emotion and to communicate. For example, if BB-8 runs into a solid object with enough speed it will glow red for 2 seconds and make a "sad" or "frustrated" series of beeps before continuing on it's way. BB-8 frequently stops to swivel its head around as if scanning the surrounding area, a function that it does not actually have. This serves as a form of communication that makes it possible for the use to empathize with the robot, as it is an action the user may recognize. Evaluation Results:



31

SOCIABLECOMPANIONROBOT  In sections I and II- Communication mode evaluation and Physical evaluation (which can be found in Appendix B page 65) BB-8 was shown to communicate through a combination of colours/lights, non-verbal sounds, head and body movements, and voice recognition. Of these communication types it was found that gestures (head and body movements) were best understood when combined with non-verbal sounds (beeps). When used separately the two were difficult to understand and the message was often misinterpreted. Section III - Social Interaction Evaluation for BB-8 revealed that the robot's mobility is limited due to its shape and size, and that, while it does possess a degree of autonomy, it is unable to complete structured tasks on its own. It was also found that the user was not always sure of BB-8's capabilities, as often the robot would behave unpredictably or in a way that was difficult to interpret. On the note of privacy, the app's requirements for personal information were found to affect the user's perceived sense of trust and therefore satisfaction. As BB-8 was unable to perform tasks required of an SAR (it is not an assistive robot) its success and cost/benefit ration relative to a human caregiver is low. Section IV ­ Human factors goals shows BB-8's commands were relatively simple to learn and were not easily forgotten. The simplicity of the robot was clear in the user's ability to remember the commands in the second session. The emotional responses of the user were recorded in Section V - Table 1.0 (page 72). For each pre-set emotion (affirmative, negative, joy, perimeter patrol, quad 1, figure 8, threat probability, anger, frustration, and search) the



32

SOCIABLECOMPANIONROBOT  perceived emotion that the robot conveyed was recorded as well as the user's reaction to the robot's emotional projection. It was found that in most cases the emotions were clearly conveyed and a sense of happiness/joy was elicited in the user at the ability to understand the emotions of the robot. Finally, BB-8 was evaluated using section VI - the RERS. The results of the scale showed that overall trust levels were high, however the robot was not relied upon for tasks and would not be treated like a human companion. Despite this, the user was found to care for the robot, even though it could not provide high levels of feedback and companionship. Nao by Aldebaran: (Figure 7.0) Appendix C Aldebaran's Nao Humanoid Robot is a 58cm tall humanoid robot with the primary function of social interaction and assistance, depending on the user. Research featuring the Nao Humanoid Robot's ability to convey emotion through posture and body movement has shown mixed results. Erden (2013) found that users often have difficulty discerning the intended emotion of the Nao Humanoid Robot, while Beck et al. (2013) showed that even children could discern emotions based on the Nao Humanoid Robot's head placement. As an anxiety-SAR will need to be clear in its ability to convey emotion and assist in the management of the user's emotions this is an important feature to consider. Presently the Nao Humanoid Robot is being used and tested for assisting children with autism spectrum disorders through various motor and communication functions (Tapus et al., 2012; Ismail et al., 2012).



33

SOCIABLECOMPANIONROBOT  Ryerson University currently houses two Nao Robots, Robert and Max. Both of the Nao robots are fully programmable. This means that Robert, despite being the same model as Max, has different capabilities and functions based around the programs and behaviours that have been coded for it. The individual differences between Nao robots are important to take into account when evaluating as some of the results may be skewed due to the programming of the robots examined. Max is currently being programmed with various games for children with autism, while Robert is fully programmed with games and reactions/responses. This research focused on one mode that all Nao robots are programmed for, Autonomous Life Mode. In this mode the Nao sways back and forth, gently "blinking" to simulate human behaviour. In this mode the Nao is scanning the room looking for human faces using its recognition software. Once the Nao has found a face it fixates, the LEDs surrounding its eyes turn dark blue to indicate that it is listening, and it waits for commands from the user. The Nao may, at this point, try to start a conversation based on its programming/coded behaviour. The Nao robot has sophisticated natural language processing abilities. In this state the user can also touch the Nao's sensor as a method of interaction, triggering other scripts. One problem I encountered when physically interacting with the Nao was determining the degree of force needed to activate the sensor on the robot's head. I was unsure of the sensitivity of the sensor and as such tried pushing it like a button when only the slightest touch is required. The Nao robot is also able to adapt to its surroundings/setting over each session, using



34

SOCIABLECOMPANIONROBOT  the sensors in its feet to adjust the pressure and maintain balance. This allows the Nao to walk, gesture, dance, and even kick a small soccer ball. Evaluation Results: The detailed evaluation results for Aldebaran's Nao can be found in Appendix C (page 77). In section I - Communication mode evaluation the Nao was found to use colours/lights (specifically LEDs around its eyes and chest), non-verbal sound effects, natural language, head and body movements/gestures, and voice recognition to communicate with the user. As the Nao is fully programmable its ability to communicate effectively is dependent on the skill level of the programmer in charge of the robot. All forms of communication were found to be effective, however gestures were found to be more effective when accompanied by sound. Section II revealed that physically, the Nao is humanoid, with a moving head, jointed arms (with shoulders, elbows, wrists, and three fingers), a mobile torso and hips, jointed legs (knees and ankles), and pressure sensitive feet. It is approachable, with orange and white colouring and is able to respond to physical touch through sensors on its chest, hands, head, and feet. Movement is fully programmable; the Nao is capable of walking, dancing, gesturing, and sitting up and moving to a standing position. Section III, the Nao's Social Interaction Evaluation, showed the robot's mobility is limited to flat, open spaces: while the robot is able to adjust its balance and learn from its environment, it is not suitable for all environments and is too large to be truly portable. Unlike the BB-8 sociable robot, the Nao is an SAR and



35

SOCIABLECOMPANIONROBOT  is able to participate in assistive activities and games for its target user group (children with autism spectrum disorders). Due to its facial recognition and video monitoring technology the Nao is able to imitate human movement (but not facial expressions as it's face is static). As the Nao does not collect user data the sense of privacy can be maintained. Socially the Nao achieves its desired identity through its personality, physical characteristics (and colouring), and assistive behaviours. Its understanding of human behaviour comes as a direct result of its customizable programming, allowing the Nao to have relative success as an SAR, however it cannot take the place of a human caregiver. One problem with the Nao that was noted in the Social Interaction Evaluation is the cost. At approximately $8000.00 the Nao is not affordable for many users. Despite this it still has a positive impact on the quality of life of the user. Section IV - human-factor goals, showed the Nao is much more difficult to learn than the previous BB-8 robot. Given its complexity as a fully programmable robot, the time to learn commands as a user depends on the programmed responses. For the purposes of this study, I focused only on Autonomous Life mode, in which the Nao searched for and responded to faces and commands from a resting state. As such, the speed of performance of the user is slower and the time to learn commands is longer. It was also found that the user retained the commands and decreased errors over time, lending to the overall subjective satisfaction for interaction with the Nao.



36

SOCIABLECOMPANIONROBOT  Section VI, the Nao's evaluation using the RERS, yielded higher results than that of the BB-8 robot. Empathy and understanding both scored high, with trust and rapport prevalent throughout the evaluation. Spin Master's Zoomer: (Figure 8.0) Appendix G Spin Master's Zoomer robot is a zoomorphic robot that takes the shape of a small black and white dog. It features 4 jointed legs that allow the robot to sit, stand, and roll with ease as well as a ball joint in it's torso allowing for twisting movements to occur and a movable neck (Zoomer; Your real best friend training guide, 2006). The Zoomer robot was designed as a companion robot toy with two main modes: independent (where the robot roams around and performs tricks at random), and command (where the robot responds to the voice commands of the user) (Zoomer; Your real best friend training guide, 2006). For the purposes of this study both modes were observed however focus was given to the command mode. The Zoomer dog companion communicates through non-verbal communication (barking), movement (tail, legs, head, and torso movements), and through LED eyes that display symbols ("x" and "?") and eye movements. The Zoomer robot is a trainable companion with 28 pre-programmed commands (activated through touch and voice-recognition) and an "independent" mode in which Zoomer explores its environment. It is important to note again that the evaluations are completed with only one user and as such they are subject to bias. Evaluation Results:



37

SOCIABLECOMPANIONROBOT  The complete evaluation for Spin Master's Zoomer robot can be found in Appendix D (page 86). Section I showed that Zoomer uses orange LEDs in its eyes to communicate eye movement, "X" and "?" symbols. It uses dog-like sounds to "bark" and "howl" at the user as well as making flatulent noises when commanded. Zoomer is able to communicate through movement that is dog-like, moving its head and body in order to portray a puppy-like personality. It is complete with voice recognition technology however it is important to note that the 28 commands were often misinterpreted by the robot. The voice recognition was deemed to be poor. Physically Zoomer takes the form of a small white puppy with black spots, a mobile head, torso (that is capable of lateral, horizontal, and twisting motions), and jointed legs that allow for motions including sitting, standing, rolling, and lifting two "paws" off the ground, as demonstrated in section II. It is controlled through voice commands (activated when the user pushes down Zoomer's head) however these were not found to be effective. The robot appears approachable however its constant state of movement can often increase the users fear of stepping on or breaking the robot. While there are 28 commands they do not take long to learn, the issue rather lies with Zoomer's ability to recognize the commands themselves. As such the speed of performance for the user is fast, but for the robot it is slow. Similar effects are seen in the rate of error and retention over time. Because of this difficulty with commands the subjective user satisfaction is low.



38

SOCIABLECOMPANIONROBOT  Unlike with the previous two robots, Zoomer is fairly mobile, however it still cannot complete stairs. It does have an autonomous mode however it does not elicit trust from the user due to its inability to consistently respond to commands. Regarding privacy, Zoomer does not record or require any personal information. In this case, however, higher quality recognition technology, while providing less in the way of privacy, may be able to increase the robot's ability to respond to commands. As a sociable robot that does not function as assistive technology Zoomer does not increase the perceived quality of life of the user or compare to the success of a human caregiver. While the Nao and BB-8 both had high levels of rapport and trust, the Zoomer robot did not build a trusting relationship with the user. It was seen as an item to be taken care of as opposed to a companion or assistant. Discussion: The evaluations of the BB-8, Nao, and Zoomer robots will be analyzed here, in conjunction with my review of the literature, to provide insight for an anxiety-SAR and answer my research questions. RQ1: Which types of robot communication (verbal communication, gestures, nonverbal auditory communication, etc) can be used in eliciting empathy and reduce anxiety in people suffering from anxiety disorder? The first goal of this study is to determine which types of robot communication can be used for an anxiety-SAR. According to Brave et al. (2005) perceptions of empathy (trustworthiness, caring, and likability) can be found when embodied computer programs are able to express emotion



39

SOCIABLECOMPANIONROBOT  and are orientated towards the user. Users are more likely to trust and have positive interactions with an anxiety-SAR if it is able to demonstrate recognizable emotions (and recognize the emotions of the user) (Brave et al. 2005). One of the clearest ways to demonstrate empathy is through mimicking and imitating the emotions of the user (Riek, Paul, & Robinson, 2010). In order to communicate and recognize emotion (and as such elicit empathy in the user) an anxiety-SAR will need to clearly monitor and mimic the emotions of the user. The present study found the nonverbal auditory communication (beeps), and gestures (head and ball/body) demonstrated by BB-8 were effective in communicating emotion, despite some misunderstandings. BB-8's communication types allow for empathic behaviour (despite a lack of facial movements, verbal communication, and the mimicking abilities of other sociable and empathic robots). It is still able to elicit a feeling of understanding and a positive reaction from the user. My findings show that nonverbal communication (beeping) is most often used by BB-8 to convey its messages, however they are quite easy to misinterpret. For example, in its preset emotions, BB-8 can perform the "Joy" command, which is meant to demonstrate happiness on the part of BB-8 the beeps are difficult to interpret. One motion was clear for interpretation without sound: when BB-8 is lifted from the ground or moved without the use of the App enabled controller it attempts to right itself and moves its head in a frustrated manner. This finding is of



40

SOCIABLECOMPANIONROBOT  particular interest as: when combined, the gestures and sounds are much easier to interpret when presented together rather than separately. When developing an anxiety-SAR gestures and sounds should be used in conjunction with one another in order to ensure clarity and reduce confusion. Aldebaran's Nao uses verbal communication, non-verbal auditory communication (music, sound effects, etc), gestures, and coloured lights to effectively communicate emotion with its users. The Nao's ability to communicate in multiple languages is considered an asset for an anxietySAR. The speech used by the Nao comes across as very natural, its voice is welcoming and its language consistent. This is useful for eliciting empathy with the user as it allows for understanding that is more difficult to accomplish when the language is disjointed or unnatural. The gestures used by the Nao are human in nature, and, unlike BB8, they do not always require sound in order to be easily interpreted. The Nao can be programmed to wave, pick up materials, dance, perform various martial arts moves, wipe away "tears", and shake its fists (etc). As each Nao can be customized through programming, its communication types can be adjusted to best suit the needs of the user. This is particularly important when considering an anxiety-SAR as each individual may require a different form of assistance. Reducing anxiety is a difficult task to measure as different treatments work for different people. An anxiety-SAR must be able to



41

SOCIABLECOMPANIONROBOT  elicit calm and comfort in the user, neither of which BB-8 or Zoomer demonstrated in the above evaluations. The results showed that Zoomer was very poor at eliciting empathy. Its inability to understand the commands of the user elicited frustration as opposed to empathetic understanding. Zoomer's emotions, while oriented to respond to the user, were not effective in producing positive interaction experiences. While its puppylike emotions were recognizable, Zoomer was unable to distinguish between commands or tone of voice, which made responding to different emotions of the user impossible. Its simple communication in the form of lights and symbols is effective for only basic communication and does not allow for empathy to be demonstrated. RQ2: Which design features (such as humanoid facial features) are necessary for the development of report and trust between the user and the robot? Nomura and Kanda (2016) focus on the need for rapport in robot development, stating that robots that act with relational behaviour (treating the user as a colleague/companion) developed stronger bonds with the users. Physical communication features that allow robots to demonstrate and build rapport were demonstrated by Sphero's BB-8, Aldebaran's Nao, and Spin Master's Zoomer in the above evaluations. The development of rapport and trust between the user and the robot can be evaluated through the robot's ability to communicate



42

SOCIABLECOMPANIONROBOT  effectively with the user. BB-8's sounds, when combined with head and body movements, can be understood to convey emotions such as happiness and frustration while eliciting emotions in the user. These findings show that a potential anxiety-SAR would not necessarily be limited to facial movements and verbal communication. While facial movements have been used in previous SAR robots, such as Brezeal's (2003) Kismet robot, the static face of BB-8 can still elicit emotions in the user when combined with both gestures and sounds. Similarly, the Nao robot, whose facial features are static (with the exception of the colours around its eyes), is still able to communicate emotion. The Nao's ability to move it's head (nodding, shaking side to side, and rotating) also helps it convey emotion and respond to the user, enhancing the sense of rapport being built. The Nao can also be programmed with sound effects such as applause (for positive reinforcement), music, and even human emotional sounds such as crying or laughing. The later emotional non-verbal communication is useful for an anxiety-SAR as it allows users to further connect and build rapport, making the robot appear more relatable and human. Coloured LED lights are used by the Nao to communicate emotions as well as technical information (i.e. blue light around the eyes indicates that the Nao is listening, yellow light on the chest piece indicates that the Nao is low on battery).



43

SOCIABLECOMPANIONROBOT  Psychically the Nao, Zoomer, and BB-8 robots all have a "cute" factor that plays a role in the user's interaction. There was a certain degree of affection by the user for the robots, something that I did not anticipate feeling prior to the start of the study. This affection effected how I interacted with the robots and should be taken into account when designing an anxiety-SAR. Should the user feel affection towards their anxiety companion they way be more willing to interact with and listen to it. One physical characteristic of the Zoomer robot that would be useful for an anxiety-SAR is the eye LEDs that provide feedback for voice commands. Zoomer's ability to communicate that it is listening (through the use of the "?" symbol) or that it has misunderstood the user's command (the "x" symbol). This immediate feedback would be helpful in an anxiety-SAR for ensuring that the commands have been processed and understood. It is suggested that other symbols (such as an affirmative symbol) be incorporated. When combined with speech and gestures from the anxiety-SAR the LEDs could ensure another layer of understanding and clear communication. RQ3: Which functional physical characteristics are necessary for an anxiety-SAR, taking into account the need for mobility? When considering the physical characteristics of an anxiety-SAR the functionality must be considered before a design can be decided upon (Norman, 2004). One of the major decisions for the physical make-up of



44

SOCIABLECOMPANIONROBOT  an anxiety-SAR is whether to make it humanoid or not. Lakatos et al. (2014) noted that should the robot be non-humanoid it is important that the intentionality behind the robot's emotion be demonstrated and believable. Of the robots that I examined one was humanoid (the Nao), one was zoomorphic (Zoomer), and one was distinctly machine-like in appearance (BB-8). It was found, as expected based on the literature, that intentionality was more difficult to determine and more easily misunderstood in the non-humanoid robots. Based on this I would recommend that an anxiety-SAR be humanoid. The Nao robot is equipped with many functional physical characteristics that would be ideal in an anxiety-SAR. The Nao requires a flat open surface in order to operate, which can be difficult to accommodate. Its ability to emulate human gestures is helpful for user understanding and for building rapport. The ability to interact with the Nao through touch sensors is also helpful, however it is limited to the Nao's head and chest. One potential problem with the humanoid structure and touch interaction is that the joints on the Nao are a safety hazard (pinching) should the user try to lift or touch the Nao when it is turned on. In an anxiety-SAR being able to touch the robot or hold it may be a source of comfort, as such the joints/movement system would have to be considered. As the Nao's coloured LEDs were considered to be an effective form of communication both for emotion and technical information they are recommended for an anxiety-SAR.



45

SOCIABLECOMPANIONROBOT  An aspect of communication that requires a functional physical component on an anxiety-SAR is lights/LEDs capable of changing colour. When proving intentionality lights/colours can be useful when combined with gestures and sounds (Lakatos et al., 2014). When examining BB-8 the lights and colours described in the results section were used minimally, but were effective in conveying BB-8's emotions. In particular, the red light that appears (when BB-8 is frustrated or has "injured" itself by running into an obstacle) clearly conveys BB-8's anger and frustration to the user. Incorporating other colours and lighting systems could work for conveying emotions in an anxiety-SAR. When considering barriers, colours can also be used as a communicating emotion, however here cross-cultural differences must be taken into account. Mobility is one area where all three robots can provide both positives and negatives. BB-8 is small and compact which is great for portability, however the spherical shape means that rough or uneven surfaces are difficult to manage; stairs are impossible. The Nao requires open flat spaces which are impractical for an anxiety-SAR which would need to be portable based on the nature of the illness. Zoomer is able to keep up with the user and follow them using motion tracking, this is the most practical of the three as it does not require effort on the part of the user to keep the robot close. Voice recognition was noted in the literature review as a major area of technical design to be considered when developing an SAR (Pierluiji et



46

SOCIABLECOMPANIONROBOT  al., 2015). Research surrounding the use of monitoring technology has demonstrated the ability to monitor users and run varying scripts according to the user that is interacting with the robot (Pierluigi et al., 2015), The closest that the robots I examined came to this technology was the Nao, who is able to add new faces to its recognition database and react based upon the individual user. As noted in the review of the literature, anxiety affects each individual differently and would require personalized assistance. The ability to recognize one user from another is one that I would recomenf for an anxiety-SAR. All three robots demonstrated voice recognition technology. The Zoomer robot made clear the need for a functional voice recognition system in an anxiety-SAR. When interacting with Zoomer, difficulties with the robot understanding commands caused frustration for the user, something that would not help a user with anxiety. BB-8's voice recognition software was slightly more effective, however the Nao had the most effective voice recognition software of the three. Evaluation Construction When completing the evaluations for the three robots focused on in this study careful consideration was given to the value of each test. The first section, Communication Mode, highlights the various ways in which each robot could communicate with the user as well as the effectiveness of each. In the future of this study it is recommended that the communication modes be focused on as an evaluative measure as they allow for the



47

SOCIABLECOMPANIONROBOT  potential acknowledgement and addressing of the communication flaws in the robot. Similarly, the Physical Characteristics section allows for descriptive and evaluative free response and should be kept in for future user studies to achieve multiple users perspectives on the body of the robot. The Social Interaction Evaluation was found to be very SAR oriented which made the evaluation of sociable, but not assistive, robots rather difficult. This evaluative measure is recommended for the examination of an anxiety-SAR however, as the robot will be primarily assistive in nature. The human-factors goals as dictated by Shneiderman (1992) were an effective method for evaluating the user's ease of use with the robot. This came in handy when examining the Zoomer robot especially, as the user was able to learn the commands, however the robot was not. This tool will be kept in future user studies however it is recommended, for accuracy, that it be completed by the researcher about the user as opposed to a self-report measure. Finally, Nomura and Kanda's (2016) RERS was used in this study to evaluate the ability of each robot to build rapport with the user. I found this tool helpful for determining how I, as the user, felt toward the robot and how the robot made me feel. It would recommend keeping the scale for future user studies, however I would ask that the users elaborate on



48

SOCIABLECOMPANIONROBOT  their answers, explaining in more detail how the robot made them feel and why they believed those emotions were being elicited. Ethical Considerations One potential problem with the development of an anxiety-SAR comes from an ethical perspective. Sharkey and Sharkey (2012) consider ethics as they pertain to SARs that assist elderly populations, and have found six main areas for ethical concern: potential reduction in the amount of human contact, increased objectification of the users, privacy issues, loss of personal liberty, deception and infantilization, and the control of the robots. Some of these concerns are addressed by the Feil-Seifer et al. (2007) evaluative questionnaire (potential reduction in the amount of human contact, privacy and reduction of social contact) the others I will address here. Regarding increased objectification of the users, in the case of an anxiety-SAR the robot would allow the users more autonomy over their lives, assisting them in controlling their anxiety. This increased autonomy could allow for users to reduce their objectification and increase their dayto-day functioning. This also affects the ethical concern of loss of personal liberty. Introducing an anxiety-SAR could cause the users to feel dependent upon the robot, something that should be monitored for, in case the robot has to be removed from the user at any point. Users may also feel as though they are being deceived or belittled by the robot, something that can be mitigated through the potential mannerisms that the robot presents.



49

SOCIABLECOMPANIONROBOT  Finally, there is the issue of who would control an anxiety-SAR. Unlike in the demographic of elderly populations, users with anxiety may be able to control the robot on their own, with the control they have over the robot acting as a part of the assistance itself and eliminating the need for a primary human caregiver. Conclusion: After reviewing the literature surrounding anxiety communication, HRI (specifically the SAR subfield), and technical design and evaluating Sphero's BB-8, Aldebaran's Nao, and Spin Master's Zoomer I have devised the following suggestions for the development of an anxiety-SAR. Figure 9.0 highlights each of the factors from the literature review (grey) and the robot evaluations (orange) that are suggested for consideration when developing the communications design of an anxiety-SAR. When combined each circle's listed features represent communication features that should be present for an anxiety-SAR to effectively perform the tasks required of it.



50

SOCIABLECOMPANIONROBOT  Figure 9.0 Anxiety-SAR Suggestions

The grey sections of the above figure are representative of communication features recommended for an anxiety-SAR from a review of the literature. The first grey circle, located at the bottom right point of the anxiety-SAR triangle, represents anxiety. Research in the field of anxiety suggests that an anxiety-SAR should have the ability to monitor the following communications in individuals suffering from anxiety: facial expressions, eye blink, vocal jitters, and pitch changes. Should the anxiety-



51

SOCIABLECOMPANIONROBOT  SAR notice an increase or exaggeration in any of the monitored communication activities assistance would be provided. The second grey circle, located at the top point of the anxiety-SAR triangle, represents the field of HRI. Research in this area shows a need for an anxiety-SAR to be capable of mimicking facial expressions (such as those described in the above section regarding anxiety) and gestures, performing rapport building exercises, and demonstrating an empathetic orientation toward the user. The final grey circle focuses on the area of technical design. A review of the literature indicates a need for the anxiety-SAR to display human expression, track the motions of its user, recognize the user's vocal commands, and be capable of mobility for ease of use. Each of these technical features would ideally be incorporated into the final design of the anxiety-SAR. The orange sections in Figure 9.0 represent the desired features for an anxiety-SAR based on the evaluations of existing robots in the fields of social and assistive robotics. There is a certain degree of overlap in the features of the existing robots: colours and lights, nonverbal auditory communication, and gestures, were be found in all three of the robots and are highly recommended features in an anxiety-SAR. Other features exhibited by Sphero's BB-8 includepreset emotions and an adaptive personality. Aldeberan's Nao featured recognition software (as was suggested by the review of the literature for both



52

SOCIABLECOMPANIONROBOT  technical design and anxiety), and was fully programmable. Finally Spin Master's Zoomer featured an LED feedback symbol system. Future Research As noted in the introduction to this paper, this study is a part of a larger body of research aimed at the development of an anxiety-SAR. Future research in this area will include virtual prototyping and virtual user studies, followed by physical prototyping and user studies before bringing the robot to testing with a larger body of its intended user group. Research will be conducted using constructivist grounded theory, focusing on the analysis of data collected from users interacting with the robot or prototype. The first step in this research will be the development of a virtual prototype that can be evaluated using the measures dictated in this study. This will involve considerations for the appearance and physical mechanics of the robot so that users can provide feedback prior to actual construction. Current open simulation technology for virtual testing can be used to visualize environments and situations where the robot could be useful, without the users leaving the lab. This would allow users to see and interact with the robot using an avatar on an online platform. This study would make use of the evaluation template discussed in the present study, allowing the researchers to determine the effectiveness of the robot's communications and interactions with the intended users. Such a study would also allow for the modification of the current evaluation measures



53

SOCIABLECOMPANIONROBOT  to suit the anxiety-SAR and prepare for physical user studies. Following the virtual study the robot could begin physical prototype development and physical user studies in which further evaluation measures could be tested with the effected population. Further research could also be conducted in the area of anxiety and general mental health communication. Determining the best ways to monitor and evaluate the mental health of patients from a communications approach is an area of research that has not been fully developed as of yet.



54

SOCIABLECOMPANIONROBOT  List of Figures: Figure 1.0

Figure 1.1 Landing/title page when opening the App .

Figure 2



55

SOCIABLECOMPANIONROBOT  Figure 2.1

Figure 2.2

Figure 2.3

Figure 2.4

Figure 2.5

Figure 2.6



56

SOCIABLECOMPANIONROBOT 

Figure 3.1

Figure 3.2

Figure 3.3

Figure 3.4

Figure 4



57

SOCIABLECOMPANIONROBOT 

Figure 4.1

Figure 4.2

Figure 4.3

Figure 5

Figure 5.1



58

SOCIABLECOMPANIONROBOT 

Figure 5.2

Figure 5.3

Figure 5.4

Figure 5.5

Figure 5.6



59

SOCIABLECOMPANIONROBOT 

Figure 5.7

Figure 6

Figure 6.1

Figure 6.2

Figure 6.3



60

SOCIABLECOMPANIONROBOT 

Figure 6.4

Figure 6.5

Figure 6.6

Figure 6.7

Figure 6.8



61

SOCIABLECOMPANIONROBOT 

Figure 7.0

Figure 8.0



62

SOCIABLECOMPANIONROBOT  Appendix A Evaluation Template I. Communication mode evaluation: Please describe in detail each of the following and indicate how the robot employed them, if they were effective, and why. 1. Colours/lights 2. Sounds 3. Head movements 4. Body movements 5. Voice recognition II. Physical Characteristics: Please answer the following questions in as much detail as possible while describing the robot's physical appearance. 1. Is the robot humanoid? 2. Does the robot have a distinguishable head/body/limbs? 3. Through what method does the user control the robot? (ie voice commands, mobile app, remote control, etc). 4. Does the robot react to physical touch? 5. Is the robot's appearance approachable? 6. Describe the technical mechanics of the robot ­ how does the robot move? III. Human-Factors Goals 1. Time to learn commands (user) 2. Speed of performance (user) 3. Rater of error (user)



63

SOCIABLECOMPANIONROBOT  4. Retention over time (user) 5. Subjective satisfaction (user) IV. Social Interaction Evaluation 1. Scalability of environments: a. Can a robot go wherever its intended user can? 2. Autonomy: a. Is the robot able to participate in activities necessary for proper assistance? b. Can a user and caregiver put the necessary trust in a robot system for that robot to be able to perform effectively? c. How does imitation (and reciprocity) affect task performance? 3. Imitation: a. Does the interaction between the human and the robot reflect an accurate and effective impression of the robot's capabilities? 4. Privacy: a. Does the user's perceived sense of privacy relate to better robot performance? b. Does the user's perceived privacy impact user satisfaction? 5. Social Success: a. Does the robot successfully achieve the social identity desired for it by the user? 6. Understanding of Domain:



64

SOCIABLECOMPANIONROBOT  a. Does a robot's social understanding of human behavior help task performance? 7. Success Relative to a Human Caregiver: a. How does the robot perform relative to a human performing the same task? 8. Cost/Benefit Analysis: a. Does the use of the robot (a) change the cost/benefit ratio of providing such care or (b) make such care available where it was not previously possible? 9. Existing quality of life measurements: a. Does the robot result in a general increase in the user's perceived quality of life? 10. Impact on the User's Role in the Community: a. Does the robot increase or decrease the amount of socialization in its user community? b. Is the robot's overall impact on the community positive or negative?

V. Emotional Response of the User: This area is to be determined based on the individual robots with special attention to the interpretation of the communication methods employed by each robot. The following is an example of the evaluation chart for emotional responses to BB-8's communications.



65

SOCIABLECOMPANIONROBOT  VI. RERS (Nomura and Kanda, 2016). The following questions were answered on 7 point scale where 1: absolutely disagree, 4: undecided, and 7: absolutely agree). 1. It would be enjoyable to play with this robot 2. This robot is able to make flexible decisions 3. Even if the robot helps me, I won't do anything in return for it 4. If I see this robot somewhere, I'd talk to it even if I have no business with it 5. I would accept this robot to attend my family dinner 6. I will feel sad if I am ignored by this robot when talking to it 7. I'll never feel empathy for this robot 8. I believe my feelings could connect with this robots 9. The robot may understand me 10. I wish to talk with the robot about hobbies and arts 11. This robot could provide me with various advices 12. This robot could devote itself to me 13. This robot would be a good conversation partner 14. I would like to try to treat the robot as if it were a human 15. The robot may see into my mind and feelings, even if I concealed them 16. I will feel uncomfortable if I ignore this robot while it's speaking to me 17. If the robot has been staying with me since my birth, I will want to be together with it until m death 18. I can talk with the robot about serious things I cannot talk with others about



66

SOCIABLECOMPANIONROBOT  Appendix B BB-8 Evaluation: I. Communication mode evaluation: 1. Colours/lights: BB-8 uses colours when turning on and off (the body glows orange), when frustrated/after running into an obstacle (the body glows red), and when trying to calibrate it's direction (a blue dot is used to adjust BB-8's direction). 2. Sounds: BB-8 communicates through a variety of beeps that convey its emotional well-being. These are used in conjunction with head/body movements. When used independently the beeps are more difficult to understand and often are confused with other emotional responses. 3. Head movements: The head moves in multiple directions on the BB-8 and can be used as a communicative device, however it is also a source of some confusion. In order for BB-8 to roll around the head is moved to gain momentum. This means that it can sometimes be unclear if BB-8 is moving its head for emotional or simply driving means. Combining the motion with sound helps with this. 4. Body movements: The spherical body allows for some communication and the playful manner of BB-8 to shine through, however without sound (i.e. the beeps) it is very confusing and difficult to understand. 5. Voice recognition: Voice recognition is a feature that is available at all times (except in MESSAGE mode). By saying "Okay BB-8" users can activate the voice recognition software. From there they are able to use



67

SOCIABLECOMPANIONROBOT  pre-set commands to interact with BB-8. Commands include the iconic line "it's a trap" which sends BB-8 rolling away from potential danger. The voice recognition screenshots can be seen in Figures 3.1- 3.5. The voice recognition software does not always function fluidly and often BB8 will react to the wrong command. II. Physical Characteristics: 1. Is the robot humanoid? No. BB-8 is a sphere (7.3 cm in diameter), with a hat/head (sphere and head combined stand at 11.4cm tall) weighing approximately 200 grams. It is white, orange, and grey in colour and can be seen in Figure 1.0 (page 53). 2. Does the robot have a distinguishable head/body/limbs? BB-8 has a "head" that attaches via magnet to the "body" that is spherical in shape. 3. Through what method does the user control the robot? (ie voice commands, mobile app, remote control, etc). The robot can be controlled through a mobile app that also makes use of voice commands. 4. Does the robot react to physical touch? Yes. Should BB-8 be moved by hand (as opposed to controlling it via the app) it makes frustrated noises and attempt to adjust itself back to its previous position. 5. Is the robot's appearance approachable? Yes. BB-8 is small, with bright colours and approachable noises. 6. Describe the technical mechanics of the robot ­ how does the robot move? BB-8 moves using gyroscope, magnetic, and motor technology. The interior of the robot consists of a small motor and weight attached to 4



68

SOCIABLECOMPANIONROBOT  wheels that spin the ball when controlled by the app. The weight allows BB-8 to maintain a centre and control its direction. The "head" is attached via magnets in both the head and body. The head has small wheels to allow smooth movement across the body. III. Social Interaction Evaluation 1. Scalability of environments: Can a robot go wherever its intended user can? BB-8's size and spherical shape mean that it can travel almost anywhere, however stairs and certain material floors can be an issue. When rolling on carpet BB-8's design makes accelerating difficult. 2. Autonomy: Is the robot able to participate in activities necessary for proper assistance? The robot is able to function as a toy/companion however it has no "assistive" features. Can a user and caregiver put the necessary trust in a robot system for that robot to be able to perform effectively? The level of trust in BB-8's ability to perform tasks increased with each session, however it is not designed to complete structured tasks on its own. How does imitation (and reciprocity) affect task performance? As BB-8 does not rely on imitation, rather on the user's control of its emotional responses, this question does not apply. 3. Imitation:



69

SOCIABLECOMPANIONROBOT  Does the interaction between the human and the robot reflect an accurate and effective impression of the robot's capabilities? When interacting with BB-8 there were often times when I was unsure if the robot could do more than what I was asking of it. With each mode the user is missing out on the aspects of the other modes that could be combined. For example, in Drive mode, it would be useful if you could use the projection system used in messages. 4. Privacy: Does the user's perceived sense of privacy relate to better robot performance? One issue with the BB-8 robot is that its controls are completed from the user's phone. The app that is used to control the robot requires access to the user's camera in order to use the "Messages" mode to create holographic images, unfortunately they are somewhat difficult to align and project. This access to the camera may make some users uncomfortable, and while the holographic images provided by the robot have nostalgic appeal for fans of the Star Wars franchise, they do not offer functional assistance for the user. Does the user's perceived privacy impact user satisfaction? With BB-8, knowing that some data is collected by the app did not mean a decrease in user satisfaction as the data collected by the app was used to increase robot performance. However, by disclosing personal information users may experience a decrease in the level of trust and therefore satisfaction



70

SOCIABLECOMPANIONROBOT  that they have with the robot. This would require a larger study to properly evaluate. 5. Social Success: Does the robot successfully achieve the social identity desired for it by the user? As an icon from a popular Disney franchise BB-8 has a preconstructed social identity. While each user may have slightly differing perceptions of BB-8's desired social identity, there is already a certain personality that is associated with the robot (sassy but cute). To those users who are not familiar with the Star Wars persona of BB-8 some of its mannerisms may be interpreted differently. Further research into perceived personality traits needs to be considered. 6. Understanding of Domain: Does a robot's social understanding of human behaviour help task performance? While in "Patrol" mode and "Drive" mode (the two in which BB-8 is most interactive) the robot demonstrates an understanding and uses human movements (head nodding) to communicate. Its beeps come across as "conversational" which helps to build rapport with the user as they feel that BB-8 is responding directly to their actions. 7. Success Relative to a Human Caregiver: How does the robot perform relative to a human performing the same task? This question is more applicable to an SAR robot as BB-8 is not designed to take the place of a human caregiver. As a social companion



71

SOCIABLECOMPANIONROBOT  BB-8 is able to provide entertainment and company, however its lack of language makes companionship with the user difficult to obtain. 8. Cost/Benefit Analysis: Does the use of the robot (a) change the cost/benefit ratio of providing such care or (b) make such care available where it was not previously possible? Again, this question will be more applicable to an SAR. BB-8 does not provide care, but rather social companionship therefore its cost to benefit ratio will be rather low in terms of care giving. 9. Existing quality of life measurements: Does the robot result in a general increase in the user's perceived quality of life? As BB-8 was designed as a social companion its primary function increases the perceived quality of life of the user by providing joy and entertainment. Personally, when interacting with BB-8 I experienced joy, enjoyment, entertainment, and some frustration when commands would not work. So while it did not increase my perceived quality of life from a medical perspective, it did provide entertainment that I would otherwise not have. 10. Impact on the User's Role in the Community: Does the robot increase or decrease the amount of socialization in its user community? As the robot can only be controlled by one user at a time and does not interact with other robots of the same make I would argue that it decreases the amount of socialization of the user in their community.



72

SOCIABLECOMPANIONROBOT  Conversely, the novelty of the robot could increase the user's social capital with other individuals who are interested in the robot. Is the robot's overall impact on the community positive or negative? BB8's impact as a social companion is positive to the community of users, however there is no medical benefit as there would be with an SAR. IV. Human-Factors Goals 1. Time to learn commands (user): BB-8's commands and interface are clear and simple to use. There is a guide available for users that can be found on the Sphero website, however most of BB-8's commands require little background. In order to measure the "time to learn commands" I recorded each 30-minute session with BB-8 and noted the number of errors made or moments of confusion by the user. There were no moments of confusion after the 5-minute mark in the first session, and the 3-minute mark in the second. 2. Speed of performance (user): Due to the simplicity of the app the speed of performance for the user was high with little confusion evident. 3. Rate of error (user): In each recorded 30-minute session the number of errors, or moments of confusion, by the user were recorded. In session one, eight errors were made, while in the subsequent session only 3 moments of confusion/error were recorded. There were no moments of error or confusion in subsequent observations.



73

SOCIABLECOMPANIONROBOT  4. Retention over time (user): As the number of errors dropped drastically from the first session to the last it can be said that the usability is retained over time. 5. Subjective satisfaction (user): As the user I enjoyed being able to control BB-8 and communicate with it. There is a certain "cute" factor that makes the robot generally fun to have around. V. Table: 1.0 Emotional Response of the User: BB-8 Emotion Evaluation Pre-set Emotion Describe the emotion/expression How did it that BB-8 conveyed make you feel/what was your reaction? BB-8 moves it's head up and Happy and down in a vertical motion as if as though nodding "yes" while making a the series of corresponding beeps that commands end in by ascending. BB-8 is have been agreeing or is happy. This seems understood. to be able to be a response to a This user question. expression elicited a feeling of calm and reassurance. BB-8 moves its head horizontally This as if shaking it in a "no" motion expression while also moving lower elicited vertically. The series of beeps gets negative progressively lower in tone to emotions. I create a "sad" response. BB-8 is felt sad or disappointed. frustrated that BB-8 is disappointe d or upset in some way. The third is an exclamation in Happiness which BB-8 looks around, shakes elicited in

ACCESS_InteragatoryRouti ne...RESPONSE_Assessme ntAffirmative_100

ACCESS_InteragatoryRouti ne...RESPONSE_Assessme ntNegative_100

EVALUATE_PersonalityM atrix...RETURN_JoyModul



74

SOCIABLECOMPANIONROBOT  e_ENABLE the user and also confusion as the beeping was not clear and the message could be interpreted in multiple ways. This expression did not demonstrate BB-8's intentionalit y and was difficult to understand. The fourth mode, or "roll away" It is unclear mode is one in which BB-8 makes as to what a series of beeps then rolls away BB-8 is before making another series of trying to beeps. None of these are fast convey and passed or high pitched thus the therefore movement does not come across frustrating as panicked or fleeing in nature. to the user. Again, intentionalit y is missing and the user felt negative emotions such as confusion. In the fifth mode BB-8 simply The square moves in a square again while shape only making a series of works if "conversational" beeps. BB-8 is on a hard surface and therefore is causes frustration. Similarly it's head horizontally, rolls forward, spins its head completely around, and continues to shake it before turning around, rolling forward (this time toward the user) then shaking its head again. The beeps during this response can be described as "conversational" as they are neither positive, nor negative, rather they give off a sense of questioning ­ the beeps go higher in pitch towards the end of each "sentence." BB-8 is curious or excited.

MOVE_Assess...Perimiter_ Patrol_Activate_Patern_Sen try1_OPEN

MOVE_Assess...Patrol_Ar ea_Activate...Pattern_Quad 1



75

SOCIABLECOMPANIONROBOT  intention is unknown to the user and therefore it is difficult to interpret. MOVE_Assess...Patrol_Ar The sixth mode, much like the Similar to ea_Activate...Pattern_Figur fifth, involves BB-8 making a the reaction e8 figure 8 with the same beeps. above, though the happy noises do elicit joy and empathy in the user. QUERY_Self_Diagnostic... The seventh is BB-8's "adamant The user, RESPONSE_ThreatProb_85 no" in which it shakes both its for _SETALERT_Queued head and the ball before fleeing whatever quickly away. The beeps sound BB-8 is "frustrated" and peeved in nature, upset about, as though BB-8 is mumbling. experienced concern and worry, as well as frustration at the lack of intentionalit y. QUERY_ThreatAssess...R In the eighth mode BB-8 starts by The user is ESPONSE_AlertHigh_Enab saying its own name, or at least by happy but le exhibiting beeps that sound like confused: "bb8" while shaking it's head. the beeps The head then rotates around the are body while making a "wow" conversatio sound finishing off with another nal however head shake and beeps before the message making a sharp turn and beeps is not with tapering down pitch. always clear and intentionalit y is not indicated, RESPONSE_PersonalityMa Mode nine is the "laughter" or The user trix...RETURN_Anger_50 "anger" mode (depending on how interpreted



76

SOCIABLECOMPANIONROBOT  you interpret the beeps) in which BB-8 shakes backwards while rocking up and down with "laughter" beeps. this as laughter as opposed to anger and therefore was happy, however this is a misundersta nding. Confusion and joy on the part of the user. The noises are unclear but very cute, so dispite a lack of intentionalit y rapport is built. Joy and happiness for both user and robot. Curiosity and confusion on the part of the user however once again intentionall y is not indicated.

QUERY_NoResponse_Frus trationModule_Activate

Mode ten is "confusion" or "frustration" in which BB-8 makes a series of beeps that both ascend and descend as though asking for clarification.

EVALUATE_STIMULUS ...Response_Joy_High

The eleventh mode is "excitement" in which BB-8 makes a "wee" sound while moving in a wide circle. The final mode is exploratory and conversational in which BB-8 simply looks around and makes a series of conversational beeps.

QUERY_UnknownStimulo us...ACTIVATE_Routine_ SearchModule

VI. RERS (Nomura and Kanda, 2016). The following questions were answered on 7 point scale where 1: absolutely disagree, 4: undecided, and 7: absolutely agree). 1. It would be enjoyable to play with this robot ­ 7



77

SOCIABLECOMPANIONROBOT  2. This robot is able to make flexible decisions ­ 4 3. Even if the robot helps me, I won't do anything in return for it ­ 2 4. If I see this robot somewhere, I'd talk to it even if I have no business with it ­ 6 5. I would accept this robot to attend my family dinner ­ 3 6. I will feel sad if I am ignored by this robot when talking to it ­ 7 7. I'll never feel empathy for this robot ­ 3 8. I believe my feelings could connect with this robots ­ 3 9. The robot may understand me ­ 3 10. I wish to talk with the robot about hobbies and arts ­ 1 11. This robot could provide me with various advices ­ 1 12. This robot could devote itself to me ­ 6 13. This robot would be a good conversation partner ­ 2 14. I would like to try to treat the robot as if it were a human ­ 3 15. The robot may see into my mind and feelings, even if I concealed them ­ 2 16. I will feel uncomfortable if I ignore this robot while it's speaking to me ­ 1 17. If the robot has been staying with me since my birth, I will want to be together with it until m death ­ 7 18. I can talk with the robot about serious things I cannot talk with others about - 1



78

SOCIABLECOMPANIONROBOT  AppendixC NaoEvaluation: I. Communication mode evaluation: 1. Colours/lights: The Nao is outfitted with lights surrounding its eyes, "ears," and the centre piece/button (green, orange, and red) on its chest. The lights are red green blue (navy and light) white. The coloured LEDs have various meanings depending on their location and colour. For the chest button: blue means that a firmware update is required, green (during the boot process) means that it is stuck in the boot loader, white means that the robot is on and ready to use, green (when Nao is past the boot process) means that the charge is higher that 3/5, yellow means that the charge is between 1/5 and 3/5, and red means that the charge is less than 1/5. The eyes on the Nao also have coloured LEDs with various meanings (for example, the solid dark blue lights show that the Nao is listening to the user in order to pick up cues for its scripts). One function of the eye LEDs that is of importance is the "blinking" feature. The eyes flash to imitate human blinks, a feature designed to make the robot more relatable. 2. Sounds: the Nao robot is capable of communicating via music, non-verbal sounds (beeps and sound effects), and text-to-speech (the following language codes are available for the Nao: Arabic, Brazilian, Chinese, Czech, Danish, Dutch, English, Finnish, French, German, Italian, Japanese, Korean, Polish, Portuguese, Spanish, Swedish, Russian, and Turkish).



79

SOCIABLECOMPANIONROBOT  3. Head movements: The Nao is able to communicate through head movements that mimic natural human motion. The head is also equipped with LEDs in the Nao's "ears" and "eyes" that help with communication. The natural head movement's of the Nao and its ability to search for human faces through head movements add to its ability to function as a SAR. 4. Body movements: Functionally the Nao is very advanced with regards to its body movements. It is able to adjust its behaviour to the environment so that it can properly stand, walk, and dance. It's general structure and joints mimic those of humans and as such the Nao is able to perform many tasks that a human can. It's adaptability and functional joint systems make the Nao a mobile companion. The gestures used by the Nao to communicate can be difficult to interpret at times without the aid of speech or non-verbal (sound) communication to accompany it. These gestures and movements are not smooth and fast like human movements and as such require some effort to interpret. 5. Voice recognition: The Nao is able to recognize speech in all of the languages previously listed in the "sounds" section. When interacting with the Nao I found the speech recognition to be very effective, the Nao reacted to my commands and understood my speech without difficulty. On only one occasion, after a prompt from the Nao, I repeated a response. The voice commands and recognition software was very effective.



80

SOCIABLECOMPANIONROBOT 

II. Physical Characteristics: 1. Is the robot humanoid? Yes, Robert the Nao is humanoid, with a moving head, jointed arms (with shoulders, elbows, wrists, and three fingers), a mobile torso and hips, jointed legs (knees and ankles), and pressure sensitive feet. 2. Does the robot have a distinguishable head/body/limbs? Yes, the Nao has a head, arms, legs, hands, and feet, all with functioning joints. 3. Through what method does the user control the robot? (ie voice commands, mobile app, remote control, etc). The user controls the robot through a combination of voice commands, motion sensors/video motion detection, touch, and the computer program that runs the robot's scripts (choregraphe 2.1.4). 4. Does the robot react to physical touch? Yes, the Nao is equipped with sensors on its head, hands, and feet, and also has a functioning chest button. The sensors trigger different scripts depending on the robot, its programmed responses, and the mode that the robot is currently in. 5. Is the robot's appearance approachable? Yes, the Nao stands at 57.3 cm tall, its main body is white with orange accents (top of head, joints, hands). The colours are bright and inviting. One issue that I have with the Nao's appearance is that while it is "off" and there are no coloured lights around its eyes, the Nao is less inviting and the eyes look quite unnatural.



81

SOCIABLECOMPANIONROBOT  6. Describe the technical mechanics of the robot ­ how does the robot move? The Nao has a complex system of movement that makes use of its many joints and sensors. It is able to adapt to its surroundings through the sensors in its feet, adjusting for balance. The Nao's complex system allows it to walk, stand, sit, and even dance. Its joints also allow it to make hand motions with its 3 fingers. III. Human-Factors Goals 1. Time to learn commands (user): The Nao robot requires a much longer amount of time to understand commands compared to BB-8. While the games that it plays with its users are easy to learn and the interaction is natural, the set up and programming of the robot requires prior advanced knowledge. Each mode/game required a brief introduction and explanation in order to properly use/understand it. 2. Speed of performance (user): As the user gets used to the controls and the interaction methods the speed of performance increases. Some confusion was evident in the initial introduction to the controls. Once games were initiated the user speed of performance increased with each game. 3. Rate of error (user): In my first session with the Nao I made more errors than correct controls. This continued into the second session, with the rate of error decreasing slowly, however the controls are much the same for each game. While the intended user and controller are not the same, as a user understanding and game play I had fewer errors than when learning the controls.



82

SOCIABLECOMPANIONROBOT  4. Retention over time (user): The number of errors decreased with each interaction of the Nao, user control/interaction was retained over time. 5. Subjective satisfaction (user): While difficult to use at first there was a high level of satisfaction when the controls were mastered. The interactions I had with the Nao were all enjoyable, if frustrating while the controls were being learned. IV. Social Interaction Evaluation 1. Scalability of environments: Can a robot go wherever its intended user can? No, the Nao, while mobile, requires charging and a wide, flat space to interact in. 2. Autonomy: Is the robot able to participate in activities necessary for proper assistance? The Nao is able to play games and communicate with the intended users however it is not always stable and would be unfit for tasks that require unassisted movement. Can a user and caregiver put the necessary trust in a robot system for that robot to be able to perform effectively? The Nao robot has performed consistently and effectively in my interactions with it, however it does require prior knowledge in order to be used effectively. How does imitation (and reciprocity) affect task performance? While the robot cannot imitate facial expressions (the Nao's facial features are static) it can use colours in the area around its eyes to acknowledge and reciprocate various communications from the user. Previous studies have



83

SOCIABLECOMPANIONROBOT  evaluated how the Nao robot imitates human motion, however such imitation requires more technology and sensors than are available on the basic Nao. 3. Imitation: Does the interaction between the human and the robot reflect an accurate and effective impression of the robot's capabilities? The Nao's capabilities are limited only to the software that the user has available to them. Robert, the Nao that I examined, was outfitted with games meant to assist children with autism. In that capacity it is able to effectively interact with the intended users. 4. Privacy: Does the user's perceived sense of privacy relate to better robot performance? When using the Nao there is a high perceived sense of privacy despite its use of cameras and sensors. The Nao does not collect personal or identifying information from the user. The Nao is also directly under the control of the user/caregiver and is programmable, allowing for a higher degree of control over the robot's privacy levels. Does the user's perceived privacy impact user satisfaction? As there are few privacy concerns when using the Nao the perceived privacy had a positive impact on user satisfaction. 5. Social Success: Does the robot successfully achieve the social identity desired for it by the user? The Nao, through its assistive behaviours, achieves the desired



84

SOCIABLECOMPANIONROBOT  social identity as an SAR. Its "personality" and communication capabilities allow it to act as a social companion. An identity as a "cute" companion with high levels of functional ability is achieved through both its physical characteristics and its assistive behaviours. 6. Understanding of Domain: Does a robot's social understanding of human behaviour help task performance? The Nao is able to understand various human motions and speech cues in order to enhance its task performance and react to the user. 7. Success Relative to a Human Caregiver: How does the robot perform relative to a human performing the same task? In relation to a human caregiver the Nao, while capable of performing various games/tasks, is not able to replace the decision making capabilities or physical capabilities of a caregiver. 8. Cost/Benefit Analysis: Does the use of the robot (a) change the cost/benefit ratio of providing such care or (b) make such care available where it was not previously possible? The Nao currently retails at approximately $8,000.00 USD. Despite the many features that are useful for the users, the price point of SAR robots make them difficult to access for users. This cost makes the robot difficult to use in cases where care was not previously possible. 9. Existing quality of life measurements: Does the robot result in a general increase in the user's perceived quality of life? The Nao increases the user's perceived quality of life through its



85

SOCIABLECOMPANIONROBOT  assistance and its ability to increase communication and interaction through games. 10. Impact on the User's Role in the Community: Does the robot increase or decrease the amount of socialization in its user community? The Nao is used mostly for individual rather than group communication/games and as such does not increase socialization. VI. Rapport-Expectation of a Robot Scale (Nomura and Kanda, 2016). The following questions were answered on 7 point scale where 1: absolutely disagree, 4: undecided, and 7: absolutely agree). 19. It would be enjoyable to play with this robot ­ 7 20. This robot is able to make flexible decisions ­ 6 21. Even if the robot helps me, I won't do anything in return for it ­ 2 22. If I see this robot somewhere, I'd talk to it even if I have no business with it ­ 5 23. I would accept this robot to attend my family dinner ­ 5 24. I will feel sad if I am ignored by this robot when talking to it ­ 7 25. I'll never feel empathy for this robot ­ 2 26. I believe my feelings could connect with this robots ­ 6 27. The robot may understand me ­ 6 28. I wish to talk with the robot about hobbies and arts ­ 4 29. This robot could provide me with various advices ­ 7 30. This robot could devote itself to me ­ 4 31. This robot would be a good conversation partner ­ 5



86

SOCIABLECOMPANIONROBOT  32. I would like to try to treat the robot as if it were a human ­ 6 33. The robot may see into my mind and feelings, even if I concealed them ­ 2 34. I will feel uncomfortable if I ignore this robot while it's speaking to me ­ 6 35. If the robot has been staying with me since my birth, I will want to be together with it until m death ­ 7 36. I can talk with the robot about serious things I cannot talk with others about - 4



87

SOCIABLECOMPANIONROBOT  Appendix D: Zoomer Evaluation: I. Communication mode evaluation: 1. Colours/lights: Zoomer has orange LED lights in its eyes that display "?" to indicate that it is listening for commands, "x" to indicate that the command was misunderstood (or that Zoomer is playing dead), and moving eyes that are meant to follow the motions of the user. The LEDs were effective for communicating when Zoomer had misunderstood the user and as such were helpful for learning the commands. 2. Sounds: Zoomer communicates through "bark" and "howling" noises that emulate those of a dog. These barks can also be in the form of song when commanded. Zoomer is also able to make flatulent noises when commanded to "let it rip." 3. Head movements: Zoomer has a mobile head that moves to compliment its barks, its ears, however, are not motorized. Zoomer uses its head to convey its moods and understanding of the user. 4. Body movements: The robot's body consists of four legs (with wheels) and a jointed torso that allows Zoomer to stand, sit, roll on its side (and right itself), raise one leg in a "peeing" motion, and roll about. 5. Voice recognition: This is one area that I found to be difficult with Zoomer. Its 28 commands are voice activated; however Zoomer requires time to be "trained" with each command. This aspect was un-reliable and Zoomer often mixed up commands.



88

SOCIABLECOMPANIONROBOT  II. Physical Characteristics: 1. Is the robot humanoid? No, Zoomer takes the form of a small dog. 2. Does the robot have a distinguishable head/body/limbs? Zoomer has a mobile head, front and back torso (joined together by a joint that allows for lateral, horizontal, and twisting motions). with four legs that allow Zoomer to sit, stand, roll, and lift itself. 3. Through what method does the user control the robot? (ie voice commands, mobile app, remote control, etc). The user controls the robot through voice commands, and touch (a sensor in the robot's head when it is pushed and a button on the rear of the robot's lower torso). 4. Does the robot react to physical touch? The robot responds to the user pushing its head by listening for voice commands and to pressing the button on its lower torso by doing a random trick. 5. Is the robot's appearance approachable? The robot's appearance of a small dog is approachable and can be described as "cute." 6. Describe the technical mechanics of the robot ­ how does the robot move? Zoomer moves through motorized wheels on each of its legs as well as through the use of its knee, hip, torso, and neck joints. The motions are meant to emulate those of a puppy and are convincing/effective in that manner. III. Human-Factors Goals 1. Time to learn commands (user): The 28 voice-commands and two touch commands that are required of the user take minimal time to learn. The



89

SOCIABLECOMPANIONROBOT  "training" of Zoomer, however, requires time for the voice-recognition to become consistent. When "teaching" Zoomer the commands (such as "Stand Up") the user may have to repeat the command upwards of five times before Zoomer understands and reacts in the appropriate manner. 2. Speed of performance (user): User speed was quick, however, frustration with the robot's inability to understand voice commands was evident. 3. Rater of error (user): It is undetermined as to whether Zoomer's misunderstanding/inability to recognize the commands was due to user error or a shortcoming in the robot's technology. 4. Retention over time (user): Though there are a large number of voice commands, they are simple (2 words maximum), and as such are easy to remember and retain. Between sessions with the robot none of the commands were forgotten, though the robot did have difficulty "relearning" the commands after being turned off. 5. Subjective satisfaction (user): When Zoomer completes its tasks as commanded through the voice-recognition there is satisfaction for the user. This comes mostly from the number of failed attempts it takes before Zoomer recognizes a command. IV. Social Interaction Evaluation 1. Scalability of environments: Can a robot go wherever its intended user can? Zoomer can move across flat and slightly sloped surfaces, it cannot navigate rough surfaces or



90

SOCIABLECOMPANIONROBOT  stairs. Its speed allows it to keep up with the user when commanded to "Follow Me." 2. Autonomy: Is the robot able to participate in activities necessary for proper assistance? As Zoomer is not a SAR but is rather just a sociable robot its primary function is not assistance Can a user and caregiver put the necessary trust in a robot system for that robot to be able to perform effectively? With Zoomer the user cannot trust that the voice-command will always elicit the correct response. Often Zoomer mixes up commands such as "Stand Up" and "Sit Down" resulting in frustration for the user. How does imitation (and reciprocity) affect task performance? While Zoomer is unable to imitate human gestures and expressions it is equipped with sensors on its chest that can follow motions at a short range. This allows Zoomer's eyes to "follow" the motion and direction of the user. It is important to note that while this concept could be helpful for reciprocity Zoomer often made errors and it was unreliable. 3. Imitation: Does the interaction between the human and the robot reflect an accurate and effective impression of the robot's capabilities? The robot had a difficult time understanding the voice-commands from the user. This may have been due to user error or robot error; testing with a separate user is needed.



91

SOCIABLECOMPANIONROBOT  4. Privacy: Does the user's perceived sense of privacy relate to better robot performance? As Zoomer does not require personal user information and does not record the user the perceived sense of privacy is high. In this case better monitoring could improve the robot's effectiveness. Does the user's perceived privacy impact user satisfaction? As the Robot's monitoring abilities were not consistently accurate the privacy of the user negatively impacted robot effectiveness and in turn user satisfaction. 5. Social Success: Does the robot successfully achieve the social identity desired for it by the user? The robot, through its barks and dog-like movements, successfully achieves the intended social identity of a "trainable puppy". 6. Understanding of Domain: Does a robot's social understanding of human behavior help task performance? Zoomer's understanding of commands such as "Follow me" demonstrate some understanding of human behaviour, however its ability to follow commands is inconsistent. 7. Success Relative to a Human Caregiver: How does the robot perform relative to a human performing the same task? Zoomer does not perform any tasks that a human or SAR would be required to. 8. Cost/Benefit Analysis:



92

SOCIABLECOMPANIONROBOT  Does the use of the robot (a) change the cost/benefit ratio of providing such care or (b) make such care available where it was not previously possible? As Zoomer is a sociable robot companion and not an SAR this question is not applicable. 9. Existing quality of life measurements: Does the robot result in a general increase in the user's perceived quality of life? As a sociable robot, despite the user's difficulty with training, Zoomer does increase the perceived quality of life. 10. Impact on the User's Role in the Community: Does the robot increase or decrease the amount of socialization in its user community? Multiple people can use Zoomer at once (as long as they all are speaking the same language for commands). This means that Zoomer can used as a tool for socialization. Is the robot's overall impact on the community positive or negative? Zoomer has a positive impact on individual users however community impact cannot be determined in this study. VI. RERS (Nomura and Kanda, 2016). The following questions were answered on a 7 point scale where 1: absolutely disagree, 4: undecided, and 7: absolutely agree). 1. It would be enjoyable to play with this robot - 6 2. This robot is able to make flexible decisions - 1 3. Even if the robot helps me, I won't do anything in return for it - 6



93

SOCIABLECOMPANIONROBOT  4. If I see this robot somewhere, I'd talk to it even if I have no business with it ­ 6 5. I would accept this robot to attend my family dinner - 1 6. I will feel sad if I am ignored by this robot when talking to it - 7 7. I'll never feel empathy for this robot - 4 8. I believe my feelings could connect with this robots - 2 9. The robot may understand me - 4 10. I wish to talk with the robot about hobbies and arts - 1 11. This robot could provide me with various advices ­ 1 12. This robot could devote itself to me - 1 13. This robot would be a good conversation partner - 1 14. I would like to try to treat the robot as if it were a human - 3 15. The robot may see into my mind and feelings, even if I concealed them ­ 1 16. I will feel uncomfortable if I ignore this robot while it's speaking to me 4 17. If the robot has been staying with me since my birth, I will want to be together with it until my death - 2 18. I can talk with the robot about serious things I cannot talk with others about - 1



94

SOCIABLECOMPANIONROBOT  Appendix E: User manuals BB-8:
!

USER MANUAL
Product Information Guide This Important Product Information Guide contains safety, handling, disposal, recycling, and regulatory information as well as the limited warranty for BB-8 App Enabled DroidTM. Read all safety information and operating instructions before using BB-8 App Enabled Droid to avoid injury or harm. For a downloadable version of the BB-8 App Enabled Droid User and Product Guides, visit www.sphero.com/manuals. IMPORTANT SAFETY AND HANDLING INFORMATION Read the following warning before you or your child play with BB-8 App Enabled Droid. Failing to do so may cause injury. CAUTION: To reduce the risk of damage or injury, do not attempt to remove BB-8 App Enabled Droid's shell; please refer all non-routine servicing questions to Orbotix, Inc. No user-serviceable parts are contained inside. CALIFORNIA PROPOSITION 65 WARNING: THIS PRODUCT CONTAINS CHEMICALS KNOWN TO THE STATE OF CALIFORNIA TO CAUSE CANCER AND BIRTH DEFECTS OR OTHER REPRODUCTIVE HARM. General

·! ·! ·! ·!

Read all safety and operating instructions before operating BB-8 App Enabled Droid. Retain the safety and operating instructions for future reference. Follow all operating and use instructions. Do not attempt to service BB-8 App Enabled Droid yourself. Refer all non-routine servicing to Orbotix.

Seizure, Blackouts and Eyestrain A small percentage of people may be susceptible to blackouts or seizures (even if they have never had one before) when exposed to flashing lights or light patterns such as when playing games or watching video. If you have experienced seizures or blackouts or have a family history of such occurrences, you should consult a physician before playing video games or watching videos. Discontinue use of BB-8 App Enabled Droid and your smart device controller and consult a physician if you experience headaches, blackouts, seizures, convulsion, eye or muscle twitching, loss of awareness, involuntary movement, or disorientation. To reduce risk of headaches, blackouts, seizures, and eyestrain, avoid prolonged use, hold your smart device controller some distance from your eyes, use BB-8 App Enabled Droid in a well-lit room, and take frequent breaks. Repetitive Injury When you perform repetitive activities such as playing games on your smart device controller, you may experience occasional discomfort in your hands, arms, shoulders, neck, or other parts of your body. Avoid excessive play. It is recommended that parents monitor their children for appropriate play. Take frequent breaks and if you have discomfort during or after such use, stop use and see a physician. WARNING: Choking Hazards BB-8 App Enabled Droid has small parts inside its shell, which may present a choking hazard to small children and pets. Keep BB-8 App Enabled Droid and its accessories away from small children. Keeping BB-8 App Enabled Droid Within Acceptable Temperatures Operate and store BB-8 App Enabled Droid in a place where the temperature is between 0º and 40º C (32º to 104º F). Low or high-temperature conditions might temporarily shorten battery life or cause BB-8 App Enabled Droid to temporarily stop working properly. Avoid dramatic changes in temperature or humidity when using BB-8 App Enabled Droid, as condensation may form on or within BB-8 App Enabled Droid. Don't leave BB-8 App Enabled Droid in your car, because temperatures in parked cars can exceed this range. When you're using BB-8 App Enabled Droid or charging the battery, it is normal for BB-8 App Enabled Droid to get warm. The exterior of BB-8 App Enabled Droid functions as a cooling surface that transfers heat from inside the unit to the cooler air outside. Use and Maintenance WARNING: BB-8 App Enabled Droid is not suitable for use by children under 8years of age. Never:

·! ·!

Abuse, throw, drop, puncture, violently kick or step on BB-8 App Enabled Droid. This can damage the robot and compromise its safe operation. Operate BB-8 App Enabled Droid in dangerous, hazardous or public areas where use is not permitted (high voltage power lines, train stations, airports, trains). Check whether use of BB-8 App Enabled Droid is permitted before using it in public areas or public transport.

© & TM Lucasfilm Ltd.
!





95

SOCIABLECOMPANIONROBOT 

Nao: The Nao User Guide Documentation can be found at http://doc.aldebaran.com/21/nao/ Zoomer:
SPIN MASTER LTD., 450 FRONT STREET WEST, TORONTO, ON M5V 1B6 CANADA customercare@spinmaster.com 1-800-622-8339 Imported into EU by: SPIN MASTER INTERNATIONAL, S.A.R.L., 16 AVENUE PASTEUR, L-2310, LUXEMBOURG www.spinmaster.com TM & © Spin Master Ltd. All rights reserved. Adult supervision advised. The item inside this package may vary from the photographs and/or illustrations. Retain this information, addresses, and phone numbers for future reference. Please remove all packaging material before giving to children. An adult should periodically check this toy to ensure no damage or hazard exist if so, remove from use. Children should be supervised during play. Meets CPSC Safety Requirements. Spin Master reserves the right to withdraw the application at any given time and without notice. Spin Master reserves the right to discontinue the website www.zoomerpup.com at any time. Spin Master is not responsible for any damage caused to electronic devices through improper use. MADE IN CHINA
T14400_0043_20067404_GEN_IS_R1
TM

5+ years

your REAL best friend

TM

Training Guide
For more training tips go to zoomerpup.com
!

!

Warning: CHOKING HAZARD ­ Small parts.

1x LiPo

3.7V

BATTERY INCLUDED

CHOKING HAZARD -- Small parts. Not for children under 3 years.

WARNING:



96

SOCIABLECOMPANIONROBOT  References: American Psychiatric Association. (2013). Diagnostic and statistical manual of mental disorders (5th ed.). Washington, DC: Author. Bandelow B, Seidler-Brandler U, Becker A, Wedekind D, Rüther E (2007). Meta-analysis of randomized controlled comparisons of psychopharmacological and psychological treatments for anxiety disorders. World J Biol Psychiatry. 8(3):175-87. Bhattacharjee, A., Das, P., Kundu, D., Ghosh, S., & Gupta, S. D. (2015). A real time face motion based approach towards modeling socially assistive wireless robot control with voice recognition. International Journal of Advanced Computer Science and Applications, 6(10), 205-220. doi:10.14569/IJACSA.2015.061030 Beck, A., Cañamero, L., Hiolle, A., Damiano, L., Cosi, P., Tesser, F., & Sommavilla, G. (2013). Interpretation of emotional body language displayed by a humanoid robot: A case study with children.International Journal of Social Robotics, 5(3), 325-334. doi:10.1007/s12369-013-0193 Brave, S., Nass, C., & Hutchinson, K. (2005). Computers that care: Investigating the effects of orientation of emotion exhibited by an embodied computer agent. International journal of human-computer studies, 62(2), 161-178. doi: 10.106/j.ijhcs.2004.11.002. Breazeal, C. (2002). Designing sociable robots. Cambridge, MA: MIT Press. Breazeal, C. (2003). Emotion and sociable humanoid robots. International journal of human-computer studies, 59(1), 119-155. doi:10.1016/S1071  97

SOCIABLECOMPANIONROBOT  5819(03)00018-1 Breazeal, C., Kidd, C. D., Thomoaz, A. L., Hoffman, G., & Berlin, M. (2005). Effects of non-verbal communication on efficiency and robustness in human-robot teamwork. IEEE/RSJ International conference. (708-713). doi: 10.1109/IROS.2005.1545011. Canadian Psychological Association (n.d.). Retrieved June 20, 2016, from http://www.cpa.ca/public/decidingtoseeapsychologist/psychologistwhattoe xpect/ Canamero, L., & Fredslund, J. (2001). I show you how I like you - can you read it in my face? IEEE transactions on systems, man, and cybernetics-part A: Systems and humans, 31(5), 454-459. doi:10.1109/3468.952719 Chang, K. (2012). Speech analysis methodologies towards unobtrusive mental monitoring. Retrieved from http://ezproxy.lib.ryerson.ca/login?url=http://search.proquest.com/docvie w/1081729013?accountid=13631 Chuang, T. (2015). How boulder's sphero brought star wars'BB8 droid to life as a toy. Denver Post. Retrieved from http://ezproxy.lib.ryerson.ca/login? url=http://search.proquest.com/docview/1709593554?accountid=13631 Erden, M. S. (2013). Emotional postures for the humanoid-robot nao. International Journal of Social Robotics, 5(4), 441-456. doi:10.1007/s12369-013-0200-4 Feil-Seifer,D.,&Mataric,M.J.(2005).Definingsociallyassistiverobotics.9th



98

SOCIABLECOMPANIONROBOT  InternationalConferenceonRehabilitationRobotics,ICORR2005, 2005,pp.465­468. Feil-Seifer, D., & Matari, M. J. (2011). Socially assistive robotics. IEEE Robotics & Automation Magazine, 18(1), 24-31. doi:10.1109/MRA.2010.940150 Feil-Seifer, D., Skinner, K., & Mataric, M. J. (2007). Benchmarks for evaluating socially assistive robotics. Interaction studies, 8(3). 423-439. Fuller, B. F., Horii, Y., & Conner, D. A. (1992). Validity and reliability of nonverbal voice measures as indicators of stressor-provoked anxiety. Res. Nurs. Health, 15(379-389). doi:10.1002/nur.4770150507 Harrigan, J. A., & O'Connell, D. M. (1996). How do you look when feeling anxious? Facial displays of anxiety. Personality and individual differences, 21(2), 205-212. doi: 10.1016/0191-8869(96)00050-5. Katzman, M. A., Bleau, P., Blier, P., Chokka, P., Kjernisted, K., Van Ameringen, M. (2014). Canadian clinical practice guidelines for the management of anxiety, posttraumatic stress and obsessive-compulsive disorders. Canadian Anxiety Guidelines Initiative Group on behalf of the Anxiety Disorders Association of Canada/Association Canadienne des troubles anxieux and McGill University. BMC Psychiatry, 14 Suppl 1, S1S1. doi:10.1186/1471-244X-14-S1-S1 Lakatos, G., Gácsi, M., Konok, V., Brúder, I., Bereczky, B., Korondi, P., & Miklósi, Á. (2014). Emotion attribution to a non-humanoid robot in different social situations. PLOS ONE, 9(12). Retrieved from



99

SOCIABLECOMPANIONROBOT  http://ezproxy.lib.ryerson.ca/login?url=http://search.proquest.com/docvie w/1712595498?accountid=13631 McColl, D. and Nejat, G. (2012) `A socially assistive robot that can interpret affective body language during one-on-one human-robot interactions', Int. J. Biomechatronics and Biomedical Robotics, Vol. 2, No. 1, pp.39­49. Muris, P., Merckelbach, H., & Rassin, E. (2000). Monitoring trait anxiety and panic disorder symptomatology in normal subjects. Journal of behaviour therapy and experimental psychiatry, 31(1), 21-28. doi: 10.1016/S00057916(00)00005-7. Nestorov, N., Stone, E., Lehane, P., & Eibrand, R. (2014). Aspects of socially assistive robots design for dementia care. Paper presented at the 396-400. doi:10.1109/CBMS.2014.16 Norman, D. A. (2004). Design in practice. Emotional design: Why we love (or hate)everyday things. New York: Basic Books. Nomura, T., & Kanda, T. (2015). Rapport-Expectation with a robot scale. International Journal of Social Robots, 81(1), 21-30. doi:10.1007/s1007/s12369-015-0293-z Pandey, A. K., Ali, M., & Alami, R. (2013). Towards a task-aware proactive sociable robot based on multi-state perspective taking. International Journal of Social Robotics, 5(2), 215-236. doi:10.1007/s12369-013-01813 Pierluigi, C., Dario, C., Marco, D. C., Luigi, M. P., Marco, L., & Cosimo, D.



100

SOCIABLECOMPANIONROBOT  (2015). Soft biometrics for a socially assistive robotic platform. Paladyn: Journal of Behavioral Robotics, 6(1) doi:10.1515/pjbr-2015-0004 Preece, J., Rogers, Y., & Sharp, H. (2015). Interaction design: Beyond human computer interaction (Fourth ed.) John Wiley & Sons Ltd. Reichardt, J. (1978). Robots: Fact, fiction, and prediction. London: Thames & Hudson. Riek, L., Paul, P., & Robinson, P. (2010). When the model robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry. Journal on multimodal user interfaces, 3(1-2), 99-108. doi: 10.1007/s12193-009-0028-2. Roshanaei-Moghaddam B., Pauly MC, Atkins, D.C., Baldwin S.A., Stein M.B., Roy-Byrne P. (2011). Relative effects of CBT and pharmacotherapy in depression versus anxiety: is medication somewhat better for depression, and CBT somewhat better for anxiety? Depress Anxiety. 28(7):560-7. Shneiderman, B. (1992). Human factors of interactive software. Designing the user interface: Strategies for effective human-computer interaction (2nd ed.). Addison-Wesley Publishing Company. Swinson R, Antony M, Bleau P, Chokka P, Craven M, Fallu A, Kjernisted K, Lanius R, Manassis K, McIntosh D. (2006). Clinical practice guidelines. Management of anxiety disorders. Can J Psychiatry. 51:9S­91S.



101

SOCIABLECOMPANIONROBOT 

Tapus, A., Peca, A., Aly, A., Pop, C., Jisa, L., Pintea, S., David, D. O. (2012). Children with autism social engagement in interaction with nao, an imitative robot: A series of single case experiments. Interaction Studies, 13(3), 315-347. doi:10.1075/is.13.3.01 Wada, K., Shibata, T., Saito, T., & Tanie, K. (2004). Effects of robot-assisted activity for elderly people and nurses at a day service center. Proceedings of the IEEE, 92(11), 1780-1788. doi:10.1109/JPROC.2004.835378 Sharkey, A., & Sharkey, N., (2012). "Granny and the robots: ethical issues in robot care for the elderly," Ethics Inf Technol, 14,(1) 27­40 Zoomer; Your real best friend training guide (2006). Zoomer, Spin Master International, Luxembourg City, Luxembourg.



102

