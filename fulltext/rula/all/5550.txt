INTERNATIONAL CONFERENCE ON ENGINEERING DESIGN, ICED11 15 - 18 AUGUST 2011, TECHNICAL UNIVERSITY OF DENMARK

DESIGNER BEHAVIOUR AND ACTIVITY: AN INDUSTRIAL OBSERVATION METHOD
Philip Cash1, Ben Hicks1, Steve Culley1, Filippo Salustri2 (1) University of Bath, UK (2) Ryerson University, Canada ABSTRACT The relationship between laboratory based study and the actual practice of engineering design is very important. For research activity, laboratory based studies have an important role. The problem is the difficulty of relating laboratory study to practice, it is thus important to fully understand this relationship. To address this, an observational method is proposed that focuses on characterizing the activities and behaviors of designers in practice. The method has been developed to provide rich context, whilst avoiding information overload. The proposed method is then critically discussed with respect to the issues particularly affecting empirical design research, such as contextualization, validity and repeatability. Finally, the paper highlights the potential importance and impact of the method for developing the relationship between practice and laboratory based experiments. Keywords: research method, designer activity, designer behavior, pilot study 1. INTRODUCTION Design research is a field covering many different aspects of design practice and activity, and designer behavior. One particular area concerns the use of empirical studies to examine designer behavior or activity, for example Robinson's [1] and Goodman-Deane's [2] studies. One of the major issues to emerge from the studies undertaken within empirical design research is the need to link findings effectively to both industrial reality and underlying theory [3]. The resolution of this issue has been hampered by a perceived dichotomy between practice and laboratory based studies. This dichotomy broadly falls into one of three types: practice [4], intermediary [5] and laboratory [6](see Table 1). One way to differentiate these types is by what can be thought of as the level of contrivance experienced by the participants: Practice having no contrivance and the laboratory being highly contrived. Each type has different empirical strengths and weaknesses as well as various applications within the scope of empirical design research. Table 1 summarizes these types for the purposes of this paper.
Table 1: Different types of empirical design research.

Practice

Description Level of contrivance Strength Weakness

Intermediary

Description Level of contrivance Strength Weakness

Laboratory

Description Level of

Ethnographic or fully embedded non-interventionist studies of practitioners. No contrived elements. Equipment or researchers are fully embedded within the working environment. Gives realistic information on the behavior/activities of practitioners in their natural environment. Context dependant, complex, can only be used to understand the existing system, cannot establish causal relationships. Experimental studies using practitioners, varying little from normal practice. Few contrived elements. Typically varying a limited number of aspects such as tasks, participants, tools or environment. Information is easily related to practice due to the controlled variation from practice, can also be related to the laboratory. Difficult to carry out, limited scope for variation, limited scope for isolation of individual variables or mechanisms. Experimental studies potentially not using practitioners, typically in a customized environment. Numerous contrived elements. Typically using students, different

contrivance Strength Weakness

environments or methods. Highly constrainable, good for isolating individual variables or mechanisms, can explore causal relationships. Difficult to relate to practice due to highly contrived nature, complex to carry out, large setup and analysis requirements

Due to the differences in the level of contrivance it is a challenge to relate practice to laboratory studies [7, 8]. However, using intermediary studies such as experiments in practice, or laboratory studies using practitioners it is possible to indirectly bridge practice and laboratory. For the purposes of the work dealt with in this paper, the focus has been on developing relationships using behaviors and activities as building blocks. These two were selected as opposed to "emotional" or other possible relationships for methodological reasons (they can be qualified and measured) and pragmatic reasons (there is already an existing body of work within the field regarding behaviors and activities of designers). Figure 1 represents the three types and the possible links between them. The solidness of separating lines denotes the amount of difference due to contrivance whilst the arrows denote how strongly a logical link can be drawn based on existing work in terms of behaviors and activities.

Practice: No contrived elements

Experiments in practice: Few contrived elements

Laboratory experiments: Numerous contrived elements

Figure 1: Relationship between practice and the laboratory.

Despite the difficulties in relating findings from the laboratory to practice, the laboratory still provides a powerful tool for empirical researchers. Levitt [9] highlights this, concluding that although there are significant differences, the laboratory is still an essential tool for providing qualitative information about certain phenomena. This is particularly true for focused investigation of underlying mechanisms or causal relationships [9, 10]. Levitt finally emphasizes that the sharp dichotomy between laboratory and practice, often used to dismiss laboratory studies, is a false one. Briggs [10] also highlights the importance of laboratory studies in allowing focused study of specific mechanisms, a fundamental element for theory building and the development of causal relationships. The practicality of the laboratory is, however, limited by the difficulty in relating laboratory findings directly to practice without time consuming intermediary studies. Thus a key way to improve the practicality, validity and relevance of laboratory based research is to develop a detailed understanding of the relationship between laboratory study and practice. Developing this understanding in detail could allow strong and credible relationships to be quickly established, reducing the need for intermediary studies. Although developing these strong relationships is difficult, they would then be powerful tools for improving reliability and relevance in practice, and would aid theory building. This has been seen in the development of Duverger's Law in political science [11]. In another example, arguably a seminal work, Vygotski and Cole [12] discuss the tensions of practice focused research and developing what they call law-like (i.e. strong) relations in psychology. In this they highlight that the critical factors are a focus on practice and sound methodology. The research outlined here aims to take the first necessary step in developing measurable relationships between laboratory and practice for design research. This will be achieved in three stages, 1) characterizing situations in practice, 2) reproducing these as contrived situations in a laboratory and then 3) validating these laboratory situations in practice with practitioners. To enable this, it is first necessary to develop a detailed understanding of designers working in practice. This is undertaken

using a replicable method that can subsequently be adapted and validated for both laboratory and intermediate situations. This method forms the foundation of all subsequent stages and thus forms the focus of this paper. 2. METHOD ­ DESCRIBING PRACTICE There are several aspects relevant to the development of the method in this paper; how it fits into the wider methodology (the aforementioned three stages), mitigation of existing empirical problems and drawing valid information from the results. A review of empirical literature was conducted in order to identify common problems encountered and the optimum methods for mitigating these. The lessons taken from this review were then used to develop the method discussed here. Dyda and Dingsyr [13] summarize many of the problems identified during the review, highlighting eleven key metrics for assessing the quality of research. Nine of these metrics are particularly relevant at this stage of the research: · Wider research ­ Fitting the study into the wider methodology of the three stages (characterizing situations in practice, reproducing these as contrived situations in a laboratory then validating these contrived situations in practice with practitioners) · Aim ­ characterization of practice such that comparisons can be made in different contexts · Context ­ characterizing the context such that differences and generalizations can be qualified · Research design ­ effectively designing the research such that it can be replicated and validated · Sampling ­ sampling to avoid bias and produce an accurate representation of the population · Data collection ­ minimizing bias and giving rich data while avoiding information overload · Data analysis ­ minimizing bias while producing results that can be compared and validated · Reflexivity ­ effectively addressing the relationship between the research and participant to minimize bias and other experimental effects · Findings and value ­ defining the nature and role of the findings produced in the wider context The method outlined here draws on the wider literature as well as the specific works of Dyda and Dingsyr [13] and Blessing and Chakrabarti [14]. It is also important to note that the aim of this study was to characterize designers in practice as accurately as possible for a number of situations. However, in order to achieve this and provide sufficient information to allow subsequent relationships to be developed it was critical to richly contextualize the study as well as the participants. The next section outlines the major parts of the method used for the practice based study, highlighting effective contextualization, rigor in sampling and setup, data collection and analysis. 2.1 Contextualization Contextualization covers the recording of all types of context about the participant and the environment/situation in which they live and work. This can then be used to structure qualitative comparisons between different participants, situations or environments ­ an essential element in developing the relevance of, or building on a study. The company context was recorded through a series of questionnaires given to senior members of the selected company. These questionnaires were used to define a number of key attributes. To help understand the issues a number of answers from one of the collaborating companies are included in italics by way of illustration. · Annual turnover ­ £700,000 · The main funding sources/pressures on the company ­ charitable donations, income from production units and research council grants · The number of full time employees ­ 18 · The number of engineers as opposed to dedicated management and support staff ­ 7 · The companies aim(s) and scope: Developing products to help people with disabilities, and other medical/healthcare devices Medical engineering ­ mechanical design, electronics design, product evaluation and small volume production · If the company had any significant partners such as sister, parent or subsidiary companies or institutions ­ Closely linked to a university and a hospital (the site of the company offices) · The maturity of the company ­ 42 years Participant context was recorded in questionnaires issued to each participant. These questionnaires were used to define:

·

·

·

·

Sociometric context: Age, occupation, highest level of education, gross individual annual income, level of property ownership Postcodes were used to give sociometric information on where the participants lived. This was achieved using the ACORN rating system deployed through www.upmystreet.com Detailed educational context: A-levels or equivalents ­ subjects and grades Degree or equivalents ­ institution, subjects and a description of their focus Other professional or educational qualifications relevant to their work Professional context: Placement(s) (if applicable) ­ company, duration, job role, description of work Previous employment over 6 months ­ company, duration, job role, description of work Duration of current employment at the company Stage of development in terms of the company structure/professional development framework Environmental context: Still photos of pre study participant workstation and local working environment Assessment of working patterns based on participant interviews ­ home/office working mix, number of people in the office, operating system and various technical factors relating to the participants computer/workstation Use of resources outside of the participant's desk area ­ whiteboard, note pad, phone, bookshelves etc

2.2 Sampling and setup The participant population was selected from the pool of engineers available at the company (seven). This was done on a voluntary basis without prior screening by the researcher in order to avoid selection bias within the relevant group. Three participants were selected to give a cross section of the engineers. In addition, a sample size of three seemed to gave the optimum balance between data collection/analysis time and depth of coverage. Equipment selection was based on the recent work reported by McAlpine et al. [15]. This work identified a number of optimal technologies for capturing different participant situations/activities. These were then compared to an assessment of the selected participants commonly encountered situations/activities. From this assessment it was clear that the participants were primarily based in a single work-space (a different space for each) and used their individual computers for distributed meeting activities such as video or phone conferences. It was also apparent that a wide variety of tasks were undertaken using various types of software. These factors meant that a broad capture strategy would be necessary to account for all the activities undertaken by the participants.
Table 2: Technology break down.

Technology Panopto + Webcam 1 Panopto + Webcam 2 Panopto ManicTime Mobile camera Livescribe pen and pad Questionnaire Post study interview

What it is recording Source Front view of participants face and upper body ­ high Logitech HD pro resolution, low frame rate, collated using Panopto webcam C910 Wide view of participants whole work space ­ low resolution, high frame rate, audio, collated using Panopto Screen capture of participants computer ­ high resolution, www.panopto.com low frame rate, collated using Panopto Automatic recording of computer usage ­ usage, activates, www.manictime.com documents and applications Participants view of all situations away from the work Samsung digital station ­ low resolution, high frame rate camera HMX-U10 Participants notepad use and audio ­ writing and audio www.livescribe.com playback of notebook Participant feedback on any events not otherwise captured ­ Electronic form structured form Participant feedback on the collected data ­ how well they Semi structured felt it reflected their time interview

Table 2 gives an overview of the capture technology used for this study. This was broken down into a number of areas, which were each covered by at least two complementary techniques. In this way a robust record was produced, able to provide redundancy and support triangulation by giving a richly detailed overlapping record of participant activities. Also, in order to account for unexpected events taking place outside of the work environment participants were issued daily questionnaires and were interviewed at the end of the study. This overlapping capture strategy has been structured in part using the recent work of Cash et al. [16]. In summary the capture strategy breaks down as show in Table 3.
Table 3: Summary of capture areas and techniques

Capture area Collocated meetings and verbal collaboration Written communication Distributed communications Individual design work

Capture techniques Livescribe pen Mobile camera Panopto Panopto and webcam 2 Panopto Livescribe pen ManicTime Panopto ManicTime Panopto Panopto and webcam 1 Panopto and webcam 2 Daily questionnaire Post study interview

What is capture Meeting notes and audio of conversation Audio and video from the participants perspective E-mail and other messaging activity conducted on the computer Audio and visual of phone or computer use Computer based video conferencing Personal note making/working Overview of computer usage Detail of work carried out on computer Overview of computer usage Detail of work carried out on computer Visual of participant demeanor Audio and visual participant demeanor identifies events outside the office/work time related to work identifies events perceived by the participant to have been missed

Project management activities Participant detail Other

Figure 2 shows a plan view of the equipment setup in the participants' work-space and the different viewing angles for the two webcams. Between the webcams the whole work-space and the immediate vicinity was covered. The participant was captured in detail from the front and side. This setup allowed the capture of the participants' immediate environment such as book shelves, practical workspace, local conversations and notice boards as well as their overall demeanor.

Figure 2: Camera setup at participants work space

2.3 Data collection The total time for data collection was twelve consecutive weeks starting in November 2010 with each individual participant being involved for three to five weeks. This period was split into two phases; an acclimatization phase and the study phase. Each participant completed at least two weeks of

acclimatization before the study proper began. This was extended to four weeks in one case due to the need to setup equipment in their office an additional home work-space where the layout was the same as Figure 2. It was considered necessary to allow increased acclimatization in this case due to the larger disruption incurred by the changes to the home work-space. The acclimatization period achieved several important things: · It allowed the participants to become accustomed to the new technologies in their work-space. Two weeks was considered the minimum necessary for Hawthorne type effects to subside. A recent study noted that participants return to normal levels of activity after only ten observation sessions [17], however, two weeks was selected as a conservative figure. · It allowed the participants to become accustomed to using new technology such as the Livescribe pen. Again two weeks was the period considered optimum for allowing these to become habit, based on the technology study reported by McAlpine et al. [15]. · It allowed the participants to get used to the data saving procedure required at the end of each day. This was an important part of the method, reducing researcher contact to a minimum and reducing possible contamination effects. · It allowed the researchers time to customize the technology setup and address any issues raised by the participants. This also allowed trouble shooting as well as checks to be made. · It allowed the researchers to gather participant feedback on the perceived effectiveness of the capture strategy. Obtaining feedback in this way was an important consideration for improving the rigor of the study as highlighted by Robinson et al. [18]. Once the acclimatization phase was complete the participants were asked to continue for a five workday study phase, constituting the study proper. Before this five day study was started each participant was given the opportunity to talk through any remaining issues/questions with the researcher. However, during the study itself the researcher had no active contact with the participant. Once the five days were complete the researcher interviewed each participant and collected all the relevant study data. This data collection was carried out on the sixth day, ensuring that five full days were captured without disruption. The post study interview allowed the participant to explain any incidents reported in the daily questionnaires as well as any incidents they felt had not been accounted for. The interview was semi structured with a number of prepared questions based on the different aspects to be captured; nonetheless, it also offered the participants an opportunity to feedback to the researcher about their experience. 3. DATA ANALYSIS Due to the amount of data generated it was imperative that data analysis was approached in a systematic way allowing for the focused analysis of relevant data while avoiding information/analysis overload for the researcher. This was achieved by grounding this study in the wider framework outlined in Section 1. The research was focused on describing discrete situations commonly studied in a laboratory setting such a: meetings, brain storming and design development. 3.1 Coding To facilitate this focused analysis whilst still capturing important contextual information five sequential levels of analysis were developed. The five levels were structured in such a way that they represented increasing levels of detail. Of particular importance is that less relevant data is filtered out by the analysis as it passes through the levels. Figure 3 outlines the five levels, describing their coding focus and the filtering strategy (filtered elements are italicized). It is important to note that each level defines the data to be coded by the next and thus is most effective when used in sequence. 51 coding metrics were developed each comprising of one main measure/descriptor and several additional detailed sub-classes. This allowed two levels of detail ­ a broad analysis using the main metrics and then a detailed analysis of selected areas using the sub-classes (at level five, Figure 3). The coding metrics include both qualitative and quantitative elements, particularly with regard to the observations of the designer. It is not possible to include in this paper a full description of the choice of the coding metrics and the method of coding, but this information is freely available from the authors. This coding schema was developed from numerous existing works as well as significant in house development and testing by the authors [19-21]. Table 4 briefly outlines each main metric class. Detailed descriptions of how these

metrics have been coded have had to be omitted here for brevity. For each main class noted in Table 4 there are several additional descriptive sub-classes that are used at level 5 for the selected areas. Finally, participant feedback was also used to improve the rigor of the findings. This was conducted via interview where the participant was talked through any assumptions that had been made, especially with regard to participant motivations and feelings at different points during the study. This helped to ensure false assumptions were avoided and also allowed a degree of validation as the participant reflected on their own findings.

Figure 3: Five level coding strategy. Table 4: The coding metrics used at the different levels.
o.

Metric groups Situation

N

1 2 3 4

Metric groups Level 1 ­ Context description Individual/group Situation Synchronous/ asynchronous Co-located/distributed Subject Location

Main metrics

No.

Main metrics

5 6 7 8

Environment Exertion and tiredness Design process stage People/product/ process focus Opinion/ orientation/suggestion Agree/disagree Antagonism/solidarity Tension/tension release Recognizing need Seeking/requesting Interpretation Validation

Problem solving

9 10 11 12 13 14 15 16

Level 2 - Activities description Goal setting Giving/asking 17 Constraining Exploring Solving Evaluating 18 19 20 21

Info. transaction

Decision making 22 Reflecting Interpretation 23 Debating 24 Level 3 ­ Interaction description

Phone Books/reports Text/graphical 37 Videophone/webcam 38 Descriptions Audiovisual recording 39 Charts/diagrams Audio recording 40 Pictures Verbalization 41 E-mail Computer Conversation 42 Activity Logbook 43 Versioning Text/graphical Sketching 44 Environment Physical Note making 45 Intermediary objects Annotation Level 4 ­ Designer observances 46 Axiology 49 Ethnography External Internal 47 Contentedness 50 History 48 Personality 51 Ethics/values Internal Level 5 ­ Detailed descriptions Metrics 1 to 45 are revisited and coded for additional qualitative sub classes Audiovisual 3.2 Analysis The primary data source was the video recordings from the webcams and computer screen. These were combined and coded in VCode [22]. Figure 4 shows a sample of footage with the attendant codes on the far right hand side. Below the main view there is a time track where code data is displayed. VCode was used to form a master track for the whole study. This was used as the basis for combining the other sources (Table 3) in order to produce a single code. Coding in this way allowed for multiple information sources to be consistently combined and ensured that a complete and consistent timeline was produced for the whole study period. This was critical in the analysis phase where total time and total activity time for each activity code where important considerations.

27 28 29 30 31 32 33 34 35 36

allowed basic comparisons of overall time spent, on each type of activity code. Figure 5 shows the percentage of the total time for a sample dataset. From this information it is possible to identify the amount of time the participants spent working on different tasks, with different focuses, in meetings etc. Comparing and grouping these findings into allowed a detailed and comparable breakdown of the participants' activities to be constructed for each study.

Focus

Situation

Process stage

Activity

Transactions

Figure 5: Percentage of total time spent on each code for a sample dataset

Using Figure 5 as an example it is possible to see the different information that can be taken from the data. Without combining activity codes it is possible to find the proportion of time a participant spends in different states, such as, a particular focus, a design process stage, searching for information or time spent in groups. Combining the activity codes allows us to examine relationships such as when the participant is working in a group situation how much of this time is spent with a product focus v. a process focus. In this way it is possible to interrogate the data at many levels of complexity from basic overall proportions to complex relationships. This data was then combined to allow analysis at both the individual participant level and at the overall level. This permitted some measure of comparison between the participants and working contexts seen in this study. Applying this type of analysis in varying degrees of detail allowed for both focused breakdowns and overall patterns to be identified and discussed. This analysis can also be carried out for laboratory or other study types using the same coding strategy. Using this common coding and analysis approach comparisons can be made between the different contexts and ultimately allow the development of the links described in Section 1. For example, it is possible to describe differences between a participants level of focus in the laboratory compared to the real world by examining the total coded time v. the time spent focused on specific tasks. Thus both qualitative (such as identified patterns, particular quirks or unique activities) and quantitative (such as percentage time associated with each code in different situations) comparisons can be made across various empirical contexts. 4. DISCUSSION AND CRITIQUE The main aim of the work was to develop a method that could effectively capture a realistic representation of designers' behavior and activities in an industrial setting. Building on this, the method has been designed such that its capture and analysis elements can also be used in laboratory and intermediary contexts. This will subsequently allow the relationships between experiments in practice and experiments in the laboratory to be qualified in terms of behaviors and activities (arrows). Assessing each area in Figure 4 using the same root method will allow relationships to be built up

between the different areas using common metrics and ultimately lead to the development of quantifiable relationships between practice and laboratory (dashed arrow).

Practice: No contrived elements

Experiments in practice: Few contrived elements

Laboratory experiments: Numerous contrived elements

Figure 4: Study focus and outcomes.

In addition the use of multiple levels of analysis streamlines the analysis process, reducing researcher overload and allowing multiple perspectives to be rapidly identified and assessed. The allowance for multiple analysis perspectives forms an integral part of the method by supporting both rich contextualization and possible data reuse/reanalysis. 4.1 Critique of the method The method outlined in this paper addresses many of the issues identified by Dyba and Dingsyr [13] amongst others. The following points examine each of the areas highlighted in Section 2 and how they have been addressed by the method. · Wider research: The method can be adapted for different contexts: practice, laboratory and intermediary. This allows studies using this method to be fitted into the framework outlined in Figure 1, building on and linking to each other. · Aim: The aim of the research comes from the underlying framework outlined in Figure 1 and has been developed to answer specific questions about behaviors and activities in different contexts. This is supported by detailed contextualization as well as underlying theory. · Context: Both environment and participant context has been captured in several levels of detail. Broad social and historical context has been addressed using the questionnaires, while more detailed context has been captured through the acclimatization and study periods using overlapping capture technologies. · Research design: The method has been specifically designed such that the data can be revisited, validated or built upon by future studies. This has been achieved by the detailed and explicit break down of the method and analysis approach as well as the development of the underlying theory. · Sampling: Sampling bias has been avoided by identifying the proportions of relevant designers within the company population and randomization of test order, participant selection and analysis order. · Data collection: Minimization of information overload while maintaining a rich data set has been achieved primarily through the layered analysis protocol. Bias has been eliminated where possible through randomization. · Data analysis: Bias has been eliminated where possible by performing consistency checks, recoding data at different stages during the coding process to give a measure of coder reliability and consistency. Also the metrics and coding scheme have been developed explicitly in order to allow reanalysis and validation. · Reflexivity: Bias and other experimental effects caused by the relationship between the participant and the researcher have been minimized using two main approaches ­ the participant was given at least a two week acclimatization period during which their activity was monitored, and researcher interaction was minimized through the use of automated capture technologies and participant routines.

·

Findings and value: Finally the role and value of the findings from this study has been developed within the wider context through thorough contextualization and explicit detailing of the method and underlying theory driving the research.

4.2 Limitations Despite the precautions taken to eliminate bias and experimental effects there are several key limitations of the study. Firstly, the scope of the study is currently limited to one company. However, the rigorous definition of the method in this paper will allow the study to be repeated, developed and compared in different contexts. Secondly, the period of acclimatization provided to the participants was based on a conservative estimate obtained from a review of relevant literature. A possible improvement would be to carry out a series of studies to determine the extent of disruptive experimental effects, and how long they take to subside, in the specific context of this capture strategy. Thirdly, a possible improvement would be to use trained but otherwise research blind intermediaries to interact with the participants. Although this may offer some advantages it was considered impractical for this study and of limited importance due to the nature of the study ­ observation rather than intervention based. Finally, defining what elements to analyze further is, at present, a fuzzy process decided by the researcher based on the defined metrics. Although this has potential to reduce clarity it allows for a wide scope of possible reuse or reinterpretation scenarios. 5. CONCLUSIONS This paper outlines a method for conducting an observational study of designers in practice, focusing on understanding and characterizing their behaviors and activities, but particularly focusing on individual designer activity, in a holistic sense. This means attempting to understand the wide range of activities that individuals actually undertake in any busy working period. Although the method and examples described in this paper have been targeted at practice and then carried out in a specific industrial context, the capture and analysis methods have been designed to be adapted for both laboratory and intermediary settings such as experiments in industry. Another critical aspect of the method is its ability to support multiple analysis perspectives as well as reanalysis, validation or development. This has been achieved by detailed and defined contextualization and development of a layered analysis process. Another key feature is the layered analysis process that has important benefits for reducing information overload and allowing the researcher to rapidly focus on specific situations without sacrificing the rich context surrounding such events. The next step in the research program will be the completion of the industrial studies and from these the development of a series of laboratory based and intermediary (contrived situations carried out in industry) studies captured using the same capture and analysis methods outlined in this paper. With these studies completed using comparable methods and with detailed contextualization, possible relationships can then be identified between the different contexts. Although this study is currently limited to a series of specific contexts, by detailing the main points of the method in this paper it is hoped that this work can be built on and developed in a rigorous way to the benefit of the whole empirical design research community. ACKNOWLEDGEMENTS The work reported in this paper has been undertaken as part of the EPSRC Innovative Manufacturing Research Centre at the University of Bath (grant reference GR/R67507/0) and has been supported by a number of industrial companies. The authors gratefully acknowledge this support and express their thanks for the advice and support of all concerned. REFERENCES 1. Robinson, M.A., Work sampling: Methodological advances and new applications. Human Factors and Ergonomics in Manufacturing & Service Industries, 2010. 20(1): p. 42-60. 2. Goodman-Deane, J., Key influences on the user-centred design process. Journal of Engineering Design, 2010. 21(2): p. 345. 3. Cross, N., Forty years of design research. Design Studies, 2007. 28(1): p. 1-4. 4. Lethbridge, T.C., Studying software engineers: Data collection techniques for software field studies. Empirical software engineering, 2005. 10(3): p. 311.

5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15.

16. 17. 18. 19. 20. 21.

22. 23.

Cross, N., H. Christiaans, and K. Dorst, Analysing design activity. 1996: Wiley Chichester, UK. Torlind, P., et al., Lessons learned and future challenges for design observatory research, in ICED'09 International conference on engineering design. 2009: Stanford, CA, USA. Moreau, K.A., Improving the design process with information management. Automation in construction, 2000. 10(1): p. 127. Sheldon, D., A review on the relevance of design science in a global product development arena. Journal of Engineering Design, 2004. 15(6): p. 541. Levitt, S., What do laboratory experiments tell us about the real world? The journal of economic perspectives, 2007. 21(2): p. 153. Briggs, R.O., On theory-driven design and deployment of collaboration systems. International Journal of Human-Computer Studies, 2006. 64(7): p. 573. Reed, S.R., Structure and behaviour: Extending Duverger's Law to the Japanese case. British Journal of Political Science, 1990. 20(03): p. 335-356. Vygotski , L.S. and M. Cole, Mind in society: The development of higher psychological processes. 1978: Harvard Univ Pr. Dyba, T. and T. Dingsyr, Empirical studies of agile software development: A systematic review. Information and Software Technology, 2008. 50(9-10): p. 833-859. Blessing, L.T.M. and A. Chakrabarti, DRM, a Design Research Methodology. 2009. McAlpine, H., et al., A technology selection process for the optimal capture of design information, in ICORD'11 International conference on research into design. 2011: Bangalore, India. Cash, P., B.J. Hicks, and S.J. Culley, An information requirement strategy for capturing and analysing design activity and behaviour, in Design 2010. 2010: Dubrovnik, Croatia. Leonard, K., Outpatient process quality evaluation and the Hawthorne Effect. Social science & medicine, 2006. 63(9): p. 2330. Robinson, H., J. Segal, and H. Sharp, Ethnographically-informed empirical studies of software practice. Information and Software Technology, 2007. 49(6): p. 540. Blandford, A., Interacting with information. Synthesis Lectures on Human-Centered Informatics, 2010. 3(1): p. 1. Horvath, I., A treatise on order in engineering design research. Research in Engineering Design, 2004. 15(3): p. 155. Wasiak, J., et al., Understanding engineering email: the development of a taxonomy for identifying and classifying engineering work. Research in Engineering Design, 2010. 21(1): p. 43. VCode. VCode and VData homepage [Online]. 2011 January 2011]. Robinson, M.A., An empirical analysis of engineers' information behaviours. Journal of the American Society for Information Science and Technology, 2010. 61(4): p. 640-658.

Contact: Philip Cash University of Bath Department of Mechanical Engineering Bath, BA2 7AY UK Tel: Int +44 1225 384166 Email: P.J.Cash@bath.ac.uk URL: http://bath.academia.edu/PhilipCash Philip is a postgraduate research student in the Department of Mechanical Engineering at the University of Bath. He researches in engineering design and design research. He is interested in design research methods and techniques; in particular how design research can effectively be linked to real world impact and the development of new and novel approaches to design research.


