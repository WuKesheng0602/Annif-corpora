Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

Creating a Human-Centric Engineering Design Course
Filippo A. Salustri and W. Patrick Neumann
Department of Mechanical and Industrial Engineering, Ryerson University salustri@ryerson.ca, pneumann@ryerson.ca

Abstract ­In 2009, the Department of Mechanical and
Industrial Engineering at Ryerson University introduced a new course, MEC325: Introduction to Engineering Design, intended to address various perceived shortcomings in the Mechanical Engineering and Industrial Engineering undergraduate programs. The authors realized that there is very little literature on how human factors can be embedded ubiquitously in engineering design processes. As a result, MEC325 has become anchored on the concept of "human-centric engineering design." This paper will describe the course's initial state and summarize many of the efforts taken by the authors to tightly integrate engineering design and human factors, and to provide a valuable learning experience to both mechanical and industrial engineering undergraduate students. Keywords: design engineering, introduction to design, human factors, human-centred design, courseware, curriculum development.

1. INTRODUCTION
In the mid-2000s, and as a result of several departmental and faculty investigations, and studies by an ad-hoc departmental design committee, two particular concerns were noted in the curriculum of the Department of Mechanical and Industrial Engineering (DMIE) at Ryerson University. 1. The introduction to design as offered at the time was too light. It was limited to the equivalent of a half-semester worth of material (amounting to 1 lecture hour and 1 lab hour per week) interleaved into an existing first-year drafting/CAD course. 2. Mechanical Engineering (ME) students learned virtually nothing about human factors (HF), and Industrial Engineering (IE) students learned virtually nothing about design engineering (DE). This was seen a problematic as modern MEs often need some knowledge of how humans interact with the products they engineer, and IEs often become involved in the development of new products.

The DMIE undertook to address these problems by separating design from drafting/CAD, and creating a new second-year course, MEC325: Introduction to Engineering Design, that would be mandatory for both ME and IE students, and that would present both HF and design in an integrated fashion. The course was first offered in 2009. We note here the integral presence of humans in the roles of assembly, installation, operation, using and co-using, maintenance, and decommissioning of all engineering designs. Despite this integral role, humans have throughout the lifecycle of an DE, and hence the critical role that DE-Human interactions have in the success of a given design. Human Factors is notoriously absent from engineering education in general. Furthermore, there are currently no textbooks or models of how to integrate HF aspects into an introductory undergraduate engineering design course. This remains a gap in the engineering educational canon. The current authors were identified as co-instructors for MEC325, both having a strong design science background, and Neumann being a certified ergonomist. We were given essentially free reign (but no coursespecific funding) to develop MEC325 such that it would count for 100% design AUs per CEAB and include 50% HF aspects. The course was defined as having three lecture hours and two "laboratory" hours, which we prefer to think of as "studio" hours, per week. The goal of this paper is to share lessons learned during the development of this human-centred engineering design course.

2. INITIAL VERSION OF THE COURSE
The original goal of MEC325 was simply to present students with an introduction to both design and HF. The second-year class contained around 200 students at the time of MEC325's introduction (divided into eight sections), so we had to account for all the usual problems of large classes. Since the authors did not have a long history of working together at the time, we decided to begin with the least controversial possible course design: to simply teach "modules" on design and on HF, drawing only the most obvious connections between them. We recognized that introductory design knowledge is principally "know how"

CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

­ 1 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

knowledge while introductory HF knowledge is principally "know what" knowledge. We therefore laid out the course to cover design sequentially from project initialization through to detailed design, and interleaving modules of HF intended to have high relevance to each design task/activity. Over time these aspects have become more integrated as the HF aspects inform and influence our design methodological approach. The major elements of the design process as presented in MEC325 are: 1) project initialization covering strategic decisions, identification of a reference design, background research, and identification of user groups; 2) problem analysis, including usage scenarios, and requirements elicitation and specification; 3) systems design, establishing an architecture for the flows of mass, energy, and information through functional components and concept design, including ideation, creativity methods, concept space exploration, and concept evaluation. The second-year curriculum is such that students have insufficient engineering skills to conduct more than qualitative and intuitive analyses, so detailed design, though necessary, is not emphasized at this stage in the ME/IE programs. A top-down, hierarchical approach is taken, such that teams begin with their design as a "black box" system, then recurse over the basic design process once through the major systems only. Time does not permit further recursions. The instructors selected projects that would not contain more than two or three levels of system decomposition. The HF coverage in the initial course included: 1) Human-Machine Interactions, 2) The role of humans in the innovation process, 3) human sensory systems and limitations in vision, hearing, touch, balance and smell; 4) human cognitive processing, error making and situation awareness; and 5) human motor capability and limitations including anthropometrics, force application, and injury potential. These were supplemented with applied units on 6) design for assemblability, 7) controls and displays; and 8) design for maintainability. The principal deliverables by students were a semester-long, team-based, "paper design" project (including two milestone reports, a final written report, and an oral presentation), and two major tests. The first milestone report covered project strategy and problem analysis; the second milestone covered systems design and concept design. We developed very short (100-200 words) design briefs, one per class section, intended to promote exploring design problem spaces. While we allowed some refinement/reduction of the design space by teams, such reductions had to be cleared with the instructors and well justified in the final report. Typical projects might include: a hospital patient lift; a leaf blower; a pill dispenser; a lifeboat; etc. Tutorial sessions allowed students to carry out workshops and smaller assignments as well as seek the
CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

instructors' advice regarding their major projects. To help ensure consistency, we developed a set of four workshops, one for each of the four major design process components. Our intention was that teams could practice each design process component on the workshop project, and then, having learned from that experience, repeat the task on their major project. This amounted to having two, interleaved projects running in parallel through the course. A problem we immediately noticed (and have yet to fully resolve) is the selection of appropriate teaching assistants. Initially, we depended on our own graduate students to agree to take on those roles, but we never had enough for all sections of the course. To ensure all students had equal opportunity to receive help, the instructors undertook to attend all lab sessions (a practice we still continue today, though a rarity in the DMIE) - at least briefly - to answer questions and direct discussion. Teams are formed using a "personality temperament indicator" developed by Salustri over many years. The software is currently maintained by Ryerson to ensure data security and operational reliability. The software presents a 70-question survey to students, assessing which of the 16 Jungian temperaments (similar to the MBTI personality types) best represents them. Using rules taken from the literature [3], the software forms teams by balancing different complementary temperaments. We have anecdotal evidence over about 15 years that this approach lowers the amount of team dysfunction, freeing up more time to help those teams that do become dysfunctional, and to teach design. This software will be the subject of a future paper. Another distinctive feature of the course is that a specific method is used to give each team member an individual mark on their group work. The method is based on the instructors grading the final report as if a single person wrote it, then using self-reported amounts of "effort" by each student on each component of the project to introduce a variation of the report's grade. Details of this method are available elsewhere [5].

3. EVOLUTION OF THE COURSE
With each iteration of the course, we have continued to integrate the course material. Our initial observation was that the students would only attend to HF aspects where these were explicitly asked for, but would drop this aspect when using any of the general engineering design methods - resulting in an interleaved, but not integrated, HF element in the course. While we still do not have a completely cohesive whole, the course is much better integrated now than it was. (e.g., connecting requirements to personas and user needs assessment; better integrated tools and reporting requirements). Many changes and variations were attempted over the years as we sought to integrate design and HF fully. Indeed, over time, we came

­ 2 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

to recognize MEC325 as a course on human-centred engineering design. It is not possible to present a detailed history here, but we will cover what, at least in hindsight, have turned out to be our best improvements so far. Our primary focus in this regard has been in the early, requirements specification stage. The basic framework of requirements - attributes (what a product must be), functions (what a product must do), and constraints (quantitative limits on attributes and functions), all connected into a quasi-tree structure with attributes driving functions and both attributes and functions driving constraints - has remained unchanged. However, the direction by which requirements are identified has evolved. Originally, Salustri presented the requirements framework and a diagrammatic form to capture and justify them; Neumann presented information about how humans act and react when interacting with objects, including channels of information exchange from design object to human via sensory channels, cognitive processing, and physical motor interactions with the system leading to the next round of ongoing interaction. We found that students did not seem able to make the connection between human performance and behavior on the one hand and product requirements on the other. This led to designs that were easily shown to be entirely inadequate from an HF point of view, including, for instance, poorly designed/positioned grips, balancing problems, unnecessarily complex user interfaces, function creep, etc. Basically, students were designing products for their own use rather than for use by others. Moreover, the challenge was to get students to exhibit a more robust understanding of usage scenarios (i.e., users who are not themselves) throughout a product's complete lifecycle. For example, when considering a food blender design, students would typically focus on the operation of the blender, without considering the process of the user setting up before, or cleaning up after, its use. As is well known, failure to consider all stages of use can result in bad, if not outright dangerous designs. We note that we believe the connection between lifecycle and HF concerns is understated in typical mechanical engineering curricula. Over the years, and in response to this shortcoming in students' work, we have developed a more integrated approach, some of the more salient methodological aspects of which highlighted below. Given a design brief, each team must: Determine a Strategic "Direction." We direct teams to select one of three possible directions: (a) refinement, wherein an existing reference design is used as a foundation, and its shortcomings are to be identified and addressed, (b) market expansion, wherein an existing reference design is to be re-designed for appeal to a defined broader market and may not bear any similarity to the reference, or (c) re-conceptualization, wherein an existing reference design is used as a jumping off point for a radical/innovative design or new product class. In
CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

their deliberations, teams are reminded of the crucial importance of considering what users need and how each strategic direction can help them satisfy those needs. Identify a Reference Design. A reference design is a single, existing product that embodies how users achieve goals defined by the project brief. The reference design need not bear any structural resemblance to a team's eventual design concept. For instance, the reference design of the original Palm Pilot PDA was a leatherbound, paper agenda/organizer [4]. Teams are expected to find flaws in that reference design by reasoning about it in comparison to competing solutions, reviewing Consumer Reports and other available documentation, etc. Define User Groups based on a life-cycle understanding of the product. We provide students with conventional user group names (e.g., end users, manufacturers, supply chain personnel including shipping, sales and installation, end-of-life users, maintenance personnel, etc.). The students must flesh out key characteristics universal to all members of each group - range of ages, general cognitive levels, socio-economic status, etc. - including their needs and wants for their interaction of the product. Establish Personas. Personas are hypothetical individuals that represent a user group and exhibiting individual characteristics that one might reasonably expect to find in actual user groups of a product. In the context of MEC325, they are meant to demarcate the "edges" of their user groups - or the "envelope" of product use - and thus establish the extent to which inclusivity is exhibited by a product. Students are encouraged to explicitly include disabled and elderly users in their analyses. At this point, students are able to use HF information directly to define the extent of the abilities of their personas in terms of sensory, cognitive, and motor abilities and limitations. They are expected to justify their personas with respect to HF knowledge presented in class. Depending on the project brief, we encourage teams to delve deeper into specific HF concerns relevant to their brief. While in any real design scenario personas should be considered for all user groups, we found that time and workload constraints meant students only had the ability to focus on end users and co-users, such as the parents and the child in designing a child carrier. Develop Usage Scenarios. A usage scenario (US) is a flowchart-like diagram describing specific tasks undertaken by one or more personas using the reference design in a specific situation and context. It shares many features with Hierarchical Task Analysis, but we believe offers advantages to novice design students such as those in MEC325. Since each task may fail for any number of reasons, students are expected to identify those failures within their USs and describe how those personas would react to them; e.g., an able-bodied user may take the stairs if an elevator car does not stop at his floor, but a user in a

­ 3 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

wheelchair must find another solution. Another significant feature of USs is that they describe tasks functionally rather than structurally; for instance, not "push the UP elevator button" but rather "call an elevator to go up". This helps disconnect the reference design's form from its function, and helps students devise distinctive and possibly innovative solutions. Understanding the completeness or incompleteness of applied usage scenario - such as forgetting to consider cleaning a food blender - remains a struggle for both students and instructors in this course. The specifics of US diagrams will be the subject of a future paper. While methods like Hierarchical Task Analysis can help, these methods are rooted in observational approaches of existing systems, not in the mental work of considering hypothetical users in the design of innovative products. Finally, we note that "thinking functionally, not structurally" has become a major theme of MEC325 over the years. How can we encourage students to understand the functionality that their human users demand? This is a question we have yet to answer to our satisfaction. Derive Requirements. Finally, given the information developed in the preceding steps, teams must build a set of requirements for their product. The goal is to specify what a product would do to (a) satisfy the needs of the personas (b) in situations specified by USs, while (c) accommodating their diverse abilities, and (d) achieving all the other strategic goals each team sets for itself. Requirements are expected to be justified by recourse to personas and USs as well as general engineering knowledge, which in turn requires students to keep HF concerns at the forefront of their work. Here as well, we struggle to provide a systematic approach by which students can monitor and self-evaluate the quality of their thinking in this complex chain that has many dimensions: user groups X personas X usage scenarios X tasks. We recognize that teams may have to iterate over these steps. For instance, identifying a reference design, determining strategy, and defining user groups are heavily coupled tasks; as such teams are encouraged to revisit them several times to converge on a specification that they all agree are best for their overall goals. Our second major focus to integrate design and HF is in concept evaluation and refinement. During initial ideation and concept formation, we do not require teams to limit their concepts to only those that satisfy the human factors, because sometimes a "crazy" idea can beget, upon subsequent reflection, a brilliant one. Human factors return, however, during concept evaluation and refinement. Teams are expected to produce at least six distinctly different concepts during initial concept generation. Teams evaluate their concepts using a weighted decision matrix (WDM) [1] in which (a) attribute requirements are used as "bins" to group other requirements as criteria, (b) attribute weights are determined by teams using pairwise comparison [2], and
CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

(c) each concept is evaluated on each criterion with respect to the reference design. This is a fairly conventional approach. The authors originally expected teams to include HF concerns at this stage because the requirements, which are implied as criteria in the WDM, include HF. For instance, "durability" is a typical attribute requirement. In the requirement specification, a number of functions (e.g., "support the weight of passengers") and constraints (e.g., maximum weight of all passengers, per-passenger weight, etc.) would specify what "durability" means in that particular project. That is, the functions and constraints define durability for that particular team working on that particular project. As such, "durability," when used as a WDM criterion, would be defined by those same functions and constraints. Since the requirements must cover HF concerns, we expected teams to evaluate their concepts such that HF concerns were also covered. However, we found that teams were not reliably evaluating their concepts with respect to their requirements, even if they correctly used the attributes as criteria. Instead, they tended to take the criteria as defined in the general/common/lay-person's sense. This led to teams developing design concepts that rather obviously did not satisfy the requirements - a pattern that further aggravated the design flaw of missing critical human related constraints. For example, consider the design of a leaf collecting device for gardens and lawns to be used by elderly people. If a team decides to use bags to collect leaves, then one must wonder about the lifting capacity of the elderly user. While students can look up the relevant HF information, students are challenged by having to work through the implications of "lifting bags of leaves." What if the leaves are wet? Does that imply a change in bag size? Is lifting of the bags even necessary? Once a user has lifted the bag of leaves, then what? Furthermore, an entirely different set of questions arise if another team has decided to mulch leaves in situ (thereby eliminating the need for a bag). Indeed, some teams will change their concept entirely when confronted with these kinds of questions - because they assume the very existence of the questions implies their concept is inadequate - only to be confronted with a whole new series of questions about their revised concept. It seems that our students lack the skill of (1) identifying possible problems, and (2) conducting the research required to establish concrete criteria to evaluate each aspect of their concepts. We are attempting to address this problem in three ways: More detailed instruction for teams. Originally, we simply instructed students to evaluate each concept on each criterion with respect to the reference design. We now instruct students to refer directly to relevant functions and constraints on each step of the evaluation.

­ 4 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

For instance, if a team evaluates a design concept as facilitating reaching by elderly end users better than the reference design, then we expect them to explicitly mention those requirements when they justify their evaluation. To facilitate this, we will implement a convention for numbering/coding the requirements. We will also be introducing more detailed examples, showing how the functions and constraints can influence a particular concept evaluation. We will use "studio" (lab) sessions to provide unsolicited feedback. That is, we will visit with each team, ask them to briefly describe their concept, and then ask them relevant questions, pointing out flaws and benefits as they arise in conversation. Explicit assessment of HF concerns. Nothing motivates students like the risk of a failing grade, so the authors now explicitly evaluate the quality and extent of treatment of HF concerns in concept evaluation and refinement. Our first attempt was to develop a HF Checklist that would be used in tandem with milestone reporting by students and contribute directly to student grades. The problem with this approach is that HF is still treated as a "sidecar" issue to the design process, rather than an integrated concern. More recently, we have merged the Checklist directly into the evaluation rubrics, which we make available to students, that we use to assess their concept evaluation work. By having HF embedded deeply into the assessment structure, we expect students to recognize, or at least respond to, the inherent connectivity between HF concerns and good designs. Extending the standard Weighted Decision Matrix to explicitly refer to usage scenarios (thereby also including personas). The authors are still developing this idea, which would involve altering the structure of the standard weighted decision matrix (WDM), and the process by which it is completed, to explicitly reference HF by way of the usage scenarios (USs). Since a WDM can be thought of as a 2D structure comparing concepts to a reference on multiple criteria, one way we could extend it is to introduce a "3rd dimension" to capture different USs. One can imagine this implemented as a spreadsheet, where one sheet captures one design concept, and evaluates each criterion for each US. The total evaluation value of that concept would be a weighted sum of the evaluations for each US. USs would be weighted using pairwise comparison and based on the project scope as defined in the design brief. We are concerned, however, that such a tool would unreasonably burden the students as well as TAs and instructors (a team that has 10 USs must now generate the equivalent of 10 standard WDMs instead of just one, all of which must be reviewed and assessed). This idea remains to be implemented and evaluated in MEC325. We have also found that naming product classes for project topics tended to fixate students on those classes, so we moved to a more functional approach. Projects are now defined functionally rather than by product class, to
CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

help stimulate innovative thinking by students. For example, we now use leaf management system instead of leaf blower, hospital patient transfer system rather than patient lift, and maritime escape and life-support system instead of lifeboat. We find that even such apparently superficial changes can help promote broader and deeper thinking in our students. Another step we have taken recently is to eliminate separate in-lab workshops. This was in response to a perception by both TAs and students that they were unable to manage working and maintain proper focus on two, interleaved projects (the workshops on the one hand, and their major project on the other). The workshops were originally intended to give students a chance to "practice" methods on a separate problem before applying them to their projects. However, students received the workshops as if they were another, separate project. This was particularly evident with respect to HF; workshops would involve entirely different user groups and personas than the major projects, which led to students confusing the different user groups. Regardless of our intention of providing students with helpful practice exercises, the workshops did in fact distract teams from the projects (and vice versa), to the point that some teams were mistakenly submitting workshop deliverables within their project final reports. Our current approach is to informally inspect team progress toward each milestone during weeks when previously there were workshops. This also feeds into point #2 above on assessing HF aspects. These inspections are conducted by TAs and by at least one of the instructors, each of which spend 5-10 minutes with each team. We have found a particularly effective and efficient way of performing these inspections, which we call "Tell me one thing". Instead of asking to see specific work items, we put the onus on the team to "tell us one thing about your design." Whatever they tell us, we then ask questions about that aspect of their work to bring out key issues. While we do acknowledge when they show good understanding of the design and HF material, we most often end up pointing out shortcomings which we advise them to address by the time they submit their final report. These shortcomings are either conceptual (they do not understand what a system is, or the difference between a function and an attribute and the implications of that distinction on making design decisions), methodological (they are performing a task incorrectly with respect to the courseware, or they have missed key steps), or informational (they have not properly researched, specified, and understood information they need to execute a good design). The point of this approach is to demonstrate how to think critically about their designs while providing concrete feedback on their work. One final point of course evolution regards the way in which individual marks are generated for teamwork on

­ 5 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

the major project. Initially, we required students to selfreport the amount of "effort" each expended. Over the first few years, we noticed that teams did not have common conceptions of "effort" which resulted in arguments among teammates and problematic grade assignments. The authors then tried having students report number of hours expended on the project. The goal here was to mimic the industrial practice of "booking time" (or billable hours) on each of their project's elements. This too was not particularly successful. Students argued that since they were more capable than their teammates, it would take them less time to execute tasks, but that this would lower their grade rather than raise it. Although our analyses of suggested that this was not in fact happening, we could not dissuade students from believing it. In the interests of lessening distractions on students so they could focus better on learning about design, we abandoned the "booking time" approach. Neumann then proposed using responsibility to distinguish team member contributions. Thus, currently, we expect students to self-report the degree of responsibility they claim for each project element on a scale of 0 (no responsibility) to 3 (full responsibility), regardless of other factors like time or effort spent. Furthermore, we explicitly describe "responsibility" to include showing due diligence (per engineering ethics) to the future users of their designs, to help ensure that HF concerns remain at the forefront of their work; that is, we expect them to responsible both for their work and to their users. So far, we have noticed a substantive decrease in friction between teammates because of this approach. We will continue to observe team behavior in future years in the hope of reporting with greater confidence that "responsibility" is a suitable metric for this aspect of project assessment.

4. ISSUES AND OPPORTUNITIES
We continue to struggle with typical problems: a timetable that changes yearly requires annual tweaking of deadlines and the order in which material is presented, which in turn requires maintaining "slack" in our schedule; finding TAs that can properly tutor students on the design courseware is often doomed to failure; the nature of design as a "messy" process runs contrary to the expectations and experiences of the students; and a certain resistance, already in second year, for students to empathize with users and take up the human agenda in engineering design - students frequently leave these aspects out of their reports. Due to changes in course management policies, and swelling enrollment numbers, we are now allowed to use fourth-year students as teaching assistants in addition to the usual graduate students, but only if a justification acceptable to both university administration and the
CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

teaching assistants' Union. To do this, we test prospective TAs to determine their qualifications. This approach has been successful in several other courses. We will begin using seniors as TAs in Fall 2017. We hope that their direct experiences in MEC325 will help them both relate to students' experiences and better assist in providing a meaningful learning experience, particularly with respect to the HF elements of the projects. Enrollment has increased significantly (about 40% since the course was first offered). We continue to struggle with scalability of the tools and methods we teach, and the instruments used to assess the students. Greater automation can be beneficial (e.g., greater dependence on Google Apps for Higher Education) to streamline course administration and student work. We will be considering the development of a toolkit of spreadsheets intended to help students manage their work. However, ultimately, nothing can replace sitting with a team and talking with them about their design; as class size increases, the amount of time instructors can spend with each team drops to, in our opinion, dangerously low levels. In many ways, we are ourselves have to address the HF concerns of our students to design a better course. As MEC325 evolved, we found little if any other work on the embedding of HF into design processes. The authors note that most engineering design textbooks have a chapter about human aspects, but do not fully integrate that information into design processes. We saw this as an opportunity to develop both the discipline of engineering design and the inclusion of HF throughout the engineering enterprise, including planning to write a new engineering design textbook adopting a "human in the system" approach. This approach, we argue, is essential for the design of safe and effective engineering systems that meet the needs of the humans the build the design, the humans that install the design, the users and co-users of the design, the human maintaining the designed object, and the human responsible for dismantling the engineering design. With humans intimately involved throughout the lifecycle of a design, should not engineering design attend to their safety and performance?

5. CONCLUSIONS
This paper has reviewed the evolution of an introductory design course for mechanical and industrial engineering undergraduate students that incorporates a strong focus on human factors. As such, the authors think of the course as one on human-centric engineering design. It recounts the struggle of trading off effectiveness and efficiency of delivering valuable content to large classes with the need to tightly integrate two heretofore disparate fields. While we continue to improve the course every year, we believe we have identified a number of key features that can be folded out of our course and into other areas of engineering.

­ 6 of 7 ­

Proc. 2017 Canadian Engineering Education Association (CEEA17) Conf.

Because of the dearth of existing textbooks and literature on human factors in design (rather than as a "sidecar" issue addressed incidentally if not accidentally), we believe our effort constitutes a significant contribution to the engineering education literature ­ one that we expect and hope to pursue in the future.

References
[1] G. Dieter, Engineering Design. New York: McGraw-Hill: 1983. [2] C.L. Dym, "Rank ordering engineering designs: pairwise comparison charts and Borda counts," Research in Engineering Design, vol 13, pp. 236-242, 2002. [3] D.D. Jensen, J. Feland, M. Bowe and F. Self, "A 6-hats based team formation strategy: development and comparison with an MBTI based approach," in Proc. ASEE Annual Conf, 2000. [4] Charlie Rose. Jeffrey Hawkins, chairman of Handspring Inc., discusses the success of the Palm Pilot and handheld devices. 3 July 2000, https://charlierose.com/videos/1878. [5] F.A. Salustri and W.P. Neumann, "Assessing SemesterLong Student Team Design Reports in Large Classes to Provide Individual Student Grades," in Proc 2016 Conference of the Canadian Engineering Education Association. (Dalhousie University, Halifax, Nova Scotia; 19-22 June 2016), 2016.

CEEA17; Paper 001 University of Toronto; June 4 ­ 7, 2017

­ 7 of 7 ­

