ONLINE LTI SYSTEM IDENTIFICATION AND TIME DELAY ESTIMATION

by Seyed Hossein Rahnamaee Bachelor of Science Degree in Electrical Engineering Azad University of Najafabad, 2006

A Thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Applied Science in the Program of Electrical and Computer Engineering Toronto, Ontario, Canada

©

Seyed Hossein Rahnamaee, 2016

AUTHOR'S DECLARATION FOR SUBMISSION OF A THESIS

I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my thesis may be made electronically available to the public.

ii

Abstract
Online LTI System Identification and Time Delay Estimation
© Seyed Hossein Rahnamaee, 2016 Master of Applied Science Electrical and Computer Engineering Ryerson University

Model order selection for linear time-invariant (LTI) systems is an important system modeling concern and has been widely investigated through past decades. Different approaches of order selection such as Akaike information criterion (AIC), Bayesian information criterion (BIC), minimum description length (MDL) and reconstruction error LTI system identification (RE-LTI) propose different criteria to select the optimum order of a system. In many real life applications of model order selection the size of an observed data set is increasing. Thus, order selection methods need to adopt the best fit of a model as the data set size is increasing. This is our motivation to extend RE-LTI order selection for online application of order selection with lower computational cost and complexity. It has been shown previously that AIC, BIC, two-stage MDL and many existing order selection criteria are special cases of RE-LTI method. Our online order selection approach reduces the computational complexity of the offline approach from O(N 3 ) to O(N 2 ). It should be noted that RE-LTI and MNDL order selection methods have same fundamentals and consequently extending RE-LTI to online RE-LTI also extends MNDL to online MNDL. Another crucial issue in system identification and modeling is estimating the time delay of a system's impulse response (or determining the start of its non-zero part). This problem is addressed in various areas including radar, sonar, acoustic source tracking, multipath channel identification, as well as many automatic control applications. Utilizing fundamentals of RE-LTI approach, here we introduce a new time-delay estimator. Simulation results show advantages of the proposed method and its superiority to existing approaches in accuracy and robustness in terms of the FIT index.

iii

Acknowledgment

I would like to express my deepest gratitude to my supervisor, Dr. Soosan Beheshti, for her immense knowledge, great patience and support. It was my privilege and honor to work under her supervision. My sincere gratitude goes to my thesis committee members, Dr. Lian Zhao, Dr. Xiao-Ping (Steven) Zhang and Dr. Vadim Geurkov for their insightful comments and feedback. I would also like to give my special thanks to my beloved father, mother and wife for their support and love.

iv

Contents
Author's Declaration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Acknowledgment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii iii iv

List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii List of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x xi

1

Introduction 1.1 Thesis Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1 5

2

Background 2.1 System Identification and Online Order selection . . . . . . . . . . . . . . . . . . 2.1.1 2.1.2 System Identification . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6 6 6

Order Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 v

2.1.3 2.2

Reconstruction Error (RE) . . . . . . . . . . . . . . . . . . . . . . . . . . 15

Time Delay Estimation (TDE) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

3

Online RE- LTI Order Selection 3.1 3.2 3.3 3.4 3.5 3.6

22

Online Parameter Estimation Sm (N + 1) . . . . . . . . . . . . . . . . . . . . . . 24 Online RE-LTI Order Selection Procedure . . . . . . . . . . . . . . . . . . . . . . 27 Complexity Order of Online RE-LTI Order Selection Procedure . . . . . . . . . . 28 Online RE-LTI System Identification and Slowly Varying Systems . . . . . . . . . 28 Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 Practical Application in Power System . . . . . . . . . . . . . . . . . . . . . . . . 35 3.6.1 Power System Simulation Results . . . . . . . . . . . . . . . . . . . . . . 37

4

Optimal Time Delay Estimation 4.1

41

RE Time-Delay Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 4.1.1 Estimation of Model Parameters in Subspaces of m . . . . . . . . . . . . 43

4.2

Simulation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 4.2.1 Comparison between Proposed and Existing Methods . . . . . . . . . . . . 47

5

Conclusions and Future Works

50

Bibliograghy

52

vi

List of Tables
3.1 3.2 3.3 Online RE-LTI vs. Offline RE-LTI Procedure . . . . . . . . . . . . . . . . . . . . 35 AGC Control Loops' Time Duration . . . . . . . . . . . . . . . . . . . . . . . . . 36 Elapsed Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

4.1

Comparison of Time Delay Estimation Techniques - Noise-Free FIT(%) and nk Values [2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

vii

List of Figures
2.1 Typical behavior of data error as the function of m . . . . . . . . . . . . . . . . . . 10

3.1 3.2

True Impulse Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=10 dB. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.3

Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=15 dB. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

3.4

Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=40 dB. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

3.5

Optimum subspace order m as a function of data length N for three different SNRs of 10 dB, 15 dB, and 40 dB. . . . . . . . . . . . . . . . . . . . . . . . . . . 33

3.6

Normalized reconstruction error zSm as the function of data length for three different SNRs of 10 dB, 15 dB, and 40 dB. . . . . . . . . . . . . . . . . . . . . . . 34

3.7 3.8

Ontario Demand At 12:00pm EST July 26, 2016 [1] . . . . . . . . . . . . . . . . . 36 Transfer function model of an interconnected two-area Hydro-Nuclear system [41] 38

viii

3.9

Reconstruction error as a function of m , for data length N = 3000 and three different SNRs of 10 dB, 15dB and 40dB. . . . . . . . . . . . . . . . . . . . . . . 38

3.10 Optimum subspace order m as a function of data length N for three different SNRs of 10 dB, 15 dB, and 40 dB. . . . . . . . . . . . . . . . . . . . . . . . . . . 39 3.11 Normalized reconstruction error zSm as the function of data length for three different SNRs of 10 dB, 15 dB, and 40 dB. . . . . . . . . . . . . . . . . . . . . . . 40

4.1

True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 25 . . . . . . . . . . . . . . . . . . . . . . . . 44

4.2

True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 25 . . . . . . . . . . . . . . . . . . . . . . . . 45

4.3

True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 24 . . . . . . . . . . . . . . . . . . . . . . . . 46

4.4

Reconstruction error zSm as the function of m for three different SNRs of 10 dB, 15 dB, and 40 dB. and Td=23 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

ix

List of Acronyms
AGC AIC BIC CRLB ED EEF ESPRIT GIC GPR KIC LSE LTI MDL MNDL MLE PDF RE-LTI SNR SVM TDE TWR Automatic Generation Control Akaike Information Criterion Bayesian Information Criterion Cramer-Rao Lower Bound Economic Dispatch Exponentially Embedded Family Estimation of Signal Parameters via Rotational Invariance Technique Generalized Information Criterion Ground Penetrating Radar Kullback Information Criterion Least Square Estimator Linear Time-Invariant Minimum Description Length Minimum Noiseless Description Length Maximum Likelihood Estimator Probability Density Function Reconstruction Error-Linear Time-Invariant Signal-to-Noise Ratio Support Vector Machines Time-Delay Estimation Through Wall Radar

x

Notations
ASM : ASm : ASdm : d : d: y [n] : y [n] : y ^[n] : u[n] : w[n] : w : m : m: ai : .
2

An N × M Toeplitz matrix generated by the input First m columns of ASM An N × m Toeplitz matrix generated by the input Optimum estimated time delay True time delay Noiseless data Noisy data Data estimate Input data i.i.d. white Gaussian noise Noise standard deviation Optimum subspace order Subspace order Real-valued coefficients of the system's impulse response

:

L2 norm Parameter estimate of order M True parameter Reconstruction error Data error Validation probability Confidence probability Vector of length N - m, corresponding to unmodeled coefficients Normalized reconstruction error Stop-ID threshold

SM :  : zSm : xSm : Q() : Q( ) : Sm : N zSm : :

xi

Chapter 1 Introduction
System modeling and identification is an important subject with various applications [3], [4]. One crucial subject in this type of modeling that has received much attention in the literature is model order selection. In model order selection the number of parameters involved in modeling is not known. Over the past years, many different criteria and prior assumptions have been proposed for this important question. [5]. It has been shown that reconstruction error is an order selection method that is consistent and can cover many other order selection approaches such as AIC and two-stage MDL [6].The first focus of this thesis is on online order selection. Online order selection aims to find the system order and identify the system as more and more data becomes available. With the fast developments in technology and consequently the fast growth of the amount of data to be processed, a consistent online order selection approach is highly desirable as it would be the answer to many applications needing real-time processes. Model order selection has a rich history. Back in 1970s, Akaike, a pioneer in model selection, introduced a minimum information criterion estimate (MAICE) based on the previously proposed minimum information criterion (AIC) to provide an objective judgment among the competing models [7]. Although AIC has received much attention in literature, it tends to overestimate as data set size increases or when noise variance is very small. Consequently, AIC is not consistent [8]. How1

ever, some other works have tried to solve the AIC inconsistency issue by modifying its penalty term to achieve a more generalized information criterion (GIC) [9], [10], [11]. Nevertheless, the true model being a subset of the estimated model set is an unrealizable assumption of AIC and the other methods expanding AIC to more consistent criteria. A more parsimonious criterion in comparison with AIC is Bayesian information criterion (BIC) [12]. It has the same structure of penalized likelihood as AIC but penalizes the model order more than AIC. Therefore, for underlying models with finite number of parameters BIC outperforms AIC, but the problem is we do not have such information of true model in real application . This method like AIC leads to overestimation and as a result many modifications such as e-BIC, lp-BIC, and h-BIC in literature have been proposed as the better understanding of BIC framework with more consistency in high signal to noise ratios (SNRs) [13], [14]. Another well-known and more recent criterion of model selection is minimum description length (MDL). It measures the probability of models' goodness considering a code length that must be minimized [15]. Among all code length formulations, two-stage MDL as the best criterion has the same form of penalized likelihood as BIC. Although MDL is consistent for large data set sizes, in high SNRs it tends to overestimate the model and like AIC is inconsistent [8]. In [5] an informative review of previously mentioned criteria is presented. Exponentially embedded family (EEF) is another method of model selection for linear models [16]. Even though the high SNR consistency of EEF is shown in the literature [8], the asymptotic behavior of EEF is like BIC that means its consistency is met under the assumption of large enough data sizes compared to the number of parameters. This assumption is not always realizable in real applications [17]. Kullback information criterion (KIC) and its different variants as model selection criteria, based on Kullback divergence, have been investigated in [18]. They are used for autoregressive models. It has been shown that KIC outperforms AIC for large samples in that KIC overestimates less. However, KIC and its variants like the AIC have the assumption of the true model being a member of a family of searched estimated models, that cannot be fulfilled.

2

Reconstruction error model order selection introduced in [6] has solved the shortcomings of all previously mentioned methods. This approach has utilized a different type of error along with feasible assumptions. This method has proved its consistency and unwillingness to overestimation in different scenarios for data set size and SNR. Despite the rich history of order selection, to our knowledge none of the most used order selection approaches mentioned above has been modified for fast and efficient online procedures. The second focus of this thesis is on time delay estimation (TDE). Several TDE methods are investigated in literature for different applications. A review of some of these methods is provided here. Ground penetrating radars (GPR) or through wall radars (TWR) localize hidden targets behind the wall or in subsurfaces of the ground by estimating the time delay between backscattered echoes from different layers. In [19] a model-based method of TDE, Estimation of Signal Parameters via Rotational Invariance Techniques (ESPRIT), is used for the purpose of subsurface investigations by GPR. This method has two preprocessing steps prior to time delay estimation procedure . First, a deconvolution of the transmitted pulse in frequency domain is done to eliminate the effect of ESPRIT's assumption of time-shifted Dirac echoes and then to create the correlation matrix a subband smoothing method (ISS) is applied to prevent the failure of ESPRIT in the case of strongly correlated GPR echoes. The support vector machines (SVMs) in [20] have been chosen among supervised machine learning algorithms to estimate the time delays of correlated GPR signals with low computational time. Estimation results of this algorithm have shown good accuracy when signals are correlated. In [21] a time delay estimation method based on compressive sensing (CS) along with a clustering principle to enhance the echoes received in GPRs has been investigated. In this paper, weak noisy correlated echoes are enhanced with the Karhunen-Loeve transform (KLT) and then the estimation problem is done by an optimization. To identify channel characteristics in wireless communications, the overlapped signals must be recovered. In [22] to estimate the time delay of overlapped signals, the least squares estimator with

3

two preprocessing steps is proposed.The preprocessing steps, under-sampling and interpolation, are used to compensate errors caused by low sampling rate in ultra-wideband systems. It has been shown that the proposed time domain algorithm has a good performance in terms of lower mean square error for different SNRs. In biomedical applications, artificial time delays resulted from artifacts (e.g. coughing, sneezing, choking) must be estimated. This is an important part of intensive care to decrease the discomfort of patients. This kind of time delay during ICU anesthesia has been estimated in [23] by using a cross-correlation analysis over a sliding window. The sliding window provides an online way of considering the changes in time delays. Considering a signal corrupted by different types of additive independently and identically distributed (i.i.d) noise (like uniform, Gaussian, mixed Gaussian), [24] has estimated its time delay by using maximum likelihood function. This method has shown that the variance of its estimator satisfies the Cramer-Rao lower bound (CRLB) to prove better performance of maximum log-likelihood estimate over the other methods. In [25] a time delay estimation methods in the frequency domain has been introduced. The method estimate the time delay between two received band-pass signals by averaging their phase differences or their different frequency components in the pass-band. In [26] a detailed review of methods for estimating the time delay has been presented. These methods are classified into four groups as time delay approximation methods, explicit time delay estimation, area and moments and finally higher order statistics methods. Different goals of time delay estimation have been determined by the author as well. It has been specified that in some applications the estimation of true time delay is needed while in some other applications the most suitable time delay for a given model is estimated. Another objective of time delay estimation has been defined in [2]. This objective is estimating a time delay that provides the best fit of a model in terms of the system identification process. In this thesis, we are focused on the type of time delay estimation that gives the best fit of a model in the system identification process.

4

1.1

Thesis Contributions

Considering two crucial issues, online order selection and time delay estimation, in Chapter 3 we develop an online reconstruction error linear time-invariant (RE-LTI ) model order selection procedure. We show the one order decrease in the complexity order of our online procedure compared with RE-LTI offline procedure. Stop-ID threshold is defined in this chapter to validate our online model order selection method. In Chapter 4 using RE-LTI model order selection, we propose a method of time delay estimation with respect to the definition of system identification and we show its superiority compared with existing methods by using the FIT index. The remainder of this thesis is arranged as follows. In Chapter 2 a review of popular model order selection criteria is presented. Also, there is a brief study of RE-LTI order selection as the state of the art and basis of our online procedure. This chapter ends with a short review of the time delay estimation concept with respect to te the definition of system identification. In Chapter 3 our online RE-LTI order selection has been introduced. The simulation results are provided to show the consistency and fast computational time of our online procedure. This chapter ends with a case study and its simulation results. We start chapter 4 by proposing a time delay estimation method based on RE-LTI reconstruction error. The simulation results are presented at the end of this chapter. Finally, in Chapter 5 we come to our conclusions and suggest some future works.

5

Chapter 2 Background

2.1
2.1.1

System Identification and Online Order selection
System Identification

In system identification, a mathematical model is formulated based on prior knowledge of a system. In many cases, the available input and output of the system play the critical role in this procedure. Applications of system identification in various fields of science and engineering are in numerous examples [4]. For instance, in signal processing, applications of this field are such as fault detection, pattern recognition, and spectral analysis. The applications are also extended in other areas such as biology and econometrics that require predictions or decisions based on the system identification models [3]. As the exact underlying system is not available in this scenario, the aim of system identification is finding the best fit of a true system which is analytically well-defined. Generally, a system identification approach requires the following:

6

1. Recording input-output data of the system to be modeled. 2. Considering a set of model structures that can define the relationship between input and output such as linear difference equation. 3. Some assessment criteria like the least squares or maximum likelihoods to find the best model in the set.

Going through the steps of the above procedure we reach to a model that needs to pass a validation test to be accepted as a good enough and true description of the system, otherwise the procedure must be repeated until the validation test is satisfied [4]. Due to wide applications of system identification, linear or non-linear, in different fields such as automatic control, biology, economics, geology and many others on one hand, and on the other hand the need to deal with more complicated systems as a result of rapidly developing technology, this topic has received much attention in the literature and has been developed through past decades. In [5] a review of system identification methods is provided. Methods including least squares and maximum likelihood are the well-studied traditional methods for linear system identification while neural networks, fuzzy logic, genetic algorithm, swarm intelligence optimization algorithms are modern system identification methods of non-linear systems [5,27,28,29,30,31,32]. Linear time-invariant (LTI) systems as the idealizations of real-life processes are the most important model structures considered in the field of system identification; while time-varying and nonlinear models also have their uses in describing systems. Representing LTI systems is through their impulse responses or their transfer functions and determining these definitions could be done with selecting a finite set of parameters as the best fit for a system or directly without a set of possible models, known as parametric or nonparametric identification methods respectively [4]. LTI system identification field has an important role yet still has its own challenges. The focus of this thesis is on LTI system identification. However, proposing an online approach for this type of system identification is also beneficial in slowly varying scenarios. In the following one general 7

formulation of LTI system identification, which is used in this thesis, is derived. The input-output relation of a causal and finite impulse response duration (FIR) LTI system can be defined by its impulse response in the discrete time domain as:
M -1

y [n] =
i=0

ai u[n - i] + w[n]

(2.1)

where u[n] , y [n], ai s, w[n] and M are input, observed output, impulse response coefficients, ad2 ditive white Gaussian noise with zero mean and variance of w , and number of impulse response's

coefficients or system's order respectively. In this situation, if M in (2.1) is assumed to be known the optimum parameter model order selection is typical of parametric approaches of system identification while it is not the case in nonparametric methods because they do not use finite-dimensional vectors to find the best model for a system [5]. Since maximum likelihood (ML) estimates of a system parameters has been proved to be asymptotically efficient [33], it is usually used in parameter estimation and consequently, order selection methods are mostly tied to it. In ML estimate, a likelihood function of observed data y depending on a parameter vector  = [a0 , a1 , ..., am-1 ]T is maximized to obtain the estimate of , as [6]: ^ = arg max f (y ; ) 


(2.2)

when f (y ; ) is the probability density function (PDF) of observed data y depending on the parameter . If the assumptions are such that observed data of length N , y N , is normally distributed or in other words its PDF is: f (y ; ) = 1
-
y N -AS  2 2 M 2 2 w

where ASM

e (2.3) (2 2 )N/2 is an N × M Toeplitz matrix generated by the available input data of finite length N ,

uN = [u[1], ..., u[N ]]T , and the observed data, y N , is the noisy data as: y [n] = ASM  + w[n] (2.4)

consequently, the ML estimate in (2.2) is reduced to the form of least square (LS) estimate as: SM = arg min y N - ASM 
 2 2

(2.5)

8

-1 T N = (AT SM ASM ) ASM y

(2.6)

This system identification problem becomes much more challenging if no information on the value of M is available. In this scenario, if absolutely no information on this value is available, M can grow up to data length N . In this case, the parameter estimate for the different values of m is calculated as follows:
N -1 T Sm (y N ) = (AT Sm ASm ) ASm y

(2.7)

where ASm is the matrix with the first m columns of Toeplitz matrix ASM . Using the available data error defined as: xSm =
N is: where yS m N yS = ASm Sm m

1 N N y - yS m N

2 2

(2.8)

(2.9)

combining the order selection with maximum likelihood estimator provides the following known solution: ^ N = arg min min y N - ASm 
m  2 2

(2.10)

This is a well-known problem with using only ML estimator and data error. Illustration of this is given in Figure (2.1) which shows a typical behavior of this error as a function of m that is 1  m  M . As the figure shows in this case that N = 100 even though the true order M = 50, ML estimation and using the data error as a criterion picks m = 100 as the order of the system since the data error is zero at that point.

So while data error is an important available value to be used in order selection, by minimizing itself it will not provide the best fit of a system. Consequently, the following section concentrates on the methods answering the order selection problem. 9

140

120

100

80

xsm
60 40 20 0 0 10 20 30 40 50 60 70 80 90 100

m

Figure 2.1: Typical behavior of data error as the function of m

2.1.2

Order Selection

Choosing the best model among the estimated models of different orders based on a set of observed data or in other words model order selection has been investigated for years. Model order selection has many practical applications. Well-known methods of order selection in literature are Akaike information criterion (AIC) [7], Bayesian information criterion (BIC) [12], the Minimum Description Length (MDL) [15] and generalized information criterion (GIC) [9]. The common part of all these methods is the ML estimator as an unbiased efficient estimate of a defined likelihood function depending on an unknown vector of parameters, namely true parameters, for which occurrence of the observed data has the highest probability. The next step in these methods which is the part that makes the difference among them is the way of finding the optimum order among the subspaces of different orders estimated for the set of observed data of a system. Maximum likelihood estimator as the basis of the above methods looks for the best estimate of a model parameters by minimizing the estimation error. Estimation error is a decreasing function 10

of model order,therefore, minimizing this error does not help us with choosing the optimum order. Thus a penalty term ,which is an increasing function of the model order, must be added to create the bias-variance tradeoff [34] that leads to the optimum choice. A general form, penalized log likelihood (PLL), of AIC, BIC, GIC and two-stage MDL is: - 1 ^m ) + P (m, N ) ln fm (y,  N (2.11)

^m ) is the likelihood function of observed data and  ^m is its maximizer in different where fm (y,  subspaces of order m. The second term of this general form, P (m, N ), is the penalty term as a function of subspace order m and data length N . The penalty term of each rule is derived differently as [9]: m N ln N BIC : P (m, N ) = N +1 GIC : P (m, N ) = N m log N MDL(two - stage) : P (m, N ) = 2N AIC : P (m, N ) = (2.12) (2.13) (2.14) (2.15)

All these rules are based on two important assumptions. First, the data length, N , is large enough in comparison with subspace order, m, and then they assume that true model,  , is a subset of estimated models: m << N   Sm (2.16) (2.17)

In many real applications, the set of available observed data has a finite length which means that the first assumption is not always met. On the other hand because true model is unknown the second assumption is not fulfilled. Obviously, out of the scope of these assumptions mentioned methods are not consistent [35]. The inconsistency problem in high SNR conditions when data set size is finite and noise variance tends towards zero has been addressed by many recent works. Seminal article [8] has explored inconsistency or overestimation of MDL and AIC in case of
2 finite data sample sizes or when the noise variance is very small w  0, in other words in high

11

SNR conditions. Authors defined the probability of choosing model order Hj when the true model order is Hp as the probability of wrong model order, Pe . They introduced a lower bound of the probability of choosing the wrong model order in case of MDL and AIC. They proved this lower bound is fixed by the size of observed data and is not dependent on noise variance in case of MDL. In terms of AIC, this lower bound is constant for all different data sizes which shows the inconsistency of AIC for both finite and infinite data set sizes. Inconsistency of BIC when the length of available data, N , is finite and noise variance is very small was discussed in [14] and then considering two different conditions of large N and small
2 noise variance, w << 1, authors introduced a proper form of BIC for only high SNR cases as

BICSNR (n). Since this form of BIC is only valid for high SNRs and fails in case of large N to estimate the model order, n, authors tried to combine the BICSN R (n) with its basic form BICN (n) to obtain a compact form BICN,SN R (n). In the combined form, the penalty term is the largest one between BICN and BICSN R penalty terms. Although, in different combinations of observed
2 data size, N , and noise variance,  ^w , they have shown acceptable choice of penalty term in their

method, in a small N and low SNR case their method is equal to BICN (n) which is not a good choice. With the basis of BIC, in [13] another supplement to proper forms of BIC studied in [14] has been presented by introducing three model order selection methods, namely empirical BIC (eBIC), hyper BIC (h-BIC) and laplace BIC (lp-BIC). Estimating the hyperparameter g of the g-prior when the SNR is unknown yields e-BIC, considering g as a random variable with a defined pdf out of a marginal likelihood results in h-BIC, and Laplace approximation for ln g shows the lp-BIC, all has been illustrated as improvements to BICN,SN R which perform well under conditions of high or low SNRs. In [36] the consistency of penalized likelihood order selection methods and their limitations in the absence of a prior upper bound of model order with respect to penalty terms of different orders have been explored and showed that penalty terms of order log log n are minimal while penalties of order n are maximal. Necessary and sufficient conditions to provide penalty functions for PLL based order estimation approaches such as AIC,BIC and MDL, that result in high SNR consistency 12

are looked for in [11]. Achieving this goal, authors considered two events of overestimation (O) and underestimation (U) and investigated conditions that make the probability of occurring these two events zero when the variance of noise is very small (high SNR conditions). Satisfying the following assumptions is the necessary and sufficient conditions proposed in [11]: h(k,  2 ) - h(k0 ,  2 ) -   as  2  0; for k > k0  2 h(k0 ,  2 ) - h(k,  2 ) -  0 as  2  0; for k < k0
P P

(2.18) (2.19)

where h is the penalty function, k0 is true order and  2 is noise variance which is known. In [10] a review of information theoretic criteria (ITC) such as AIC, BIC, MDL or more generally generalized information criterion (GIC) has been presented and analyzed the performance of those criteria with respect to the probability of correct detection of model order for different SNRs: Pc = Pc (q, SN R,  ) = 1 - Pover - P - under
qmax -q

(2.20) (2.21) (2.22)

Pover

P
i=1 q

{IT C (q + 1) < IT C (q )} P
i=1

Punder

{IT C (q - 1) < IT C (q )}

where q is the model order,  is the parameter of GIC which must be selected properly, and Pover and Punder are probabilities of overestimation and underestimation respectively. As they have proved for high SNR underestimation probability is almost zero and consequently due to non-zero overestimation probability these criteria always select the model order incorrectly. Based on the assumption that true model is a member of the estimated model set, to overcome this shortcoming in case of finite sample sizes authors proposed setting the parameter  in GIC as:
M AX  ~ = arg max max Pover (q, SN R,  ) | Pover  Pover  q,SN R

(2.23)

Another approach to model order selection proposed in [16] is done by embedding exponentially two or more probability density functions, pi (X ), (PDFs) into a family of pdfs: pi (x;  ) = exp  ln pi (X ; i ) - ln p0 (X ) 13
1- p 1 (X )p0 (X )dx + ln p0 (X )

(2.24)

where i is a vector of unknown model parameters, 0   < 1, and p0 (X ) is given. Thus the model order selection method is choosing the maximum pi (X ;  ^) among all models: EEF(i) = max  ln


1 pTi (t(X ); 0)

- K0 ( )

(2.25)

A detailed study on the performance of EEF as an order selection criterion with a generalized likelihood ratio (GLR) base has been presented in [17] where authors illustrated that estimating ^(n) which is defined as: model order, n, is through maximizing f  ^(n) = 2 ln max f
n



p ^n+1 p ^1

2 ln

- n 1 + ln 

p ^n+1 p ^1

  (2.26)

n

In this work, it has been shown that the asymptotic behavior of EEF is like BIC and similarly this method holds as long as the observed data size is large enough compared to the model order or in the other words N >> n. From what have been discussed so far, we can understand that underestimation or overestimation issue of model order selection's forefathers, AIC, BIC and MDL, is because of their penalty terms. Therefore, many works have been done during the past years in literature to address these problems by modifying the penalty terms used in those criteria. These modifications have led to many variants of previously mentioned methods. However, a novel approach to model order selection has been introduced in [6], namely reconstruction error model order selection (RE). This method unlike the previous criteria, instead of using data error and then trying to find a penalty term to create the tradeoff between the estimated fit goodness and its complexity, has used another error. The error used in [6] has the desired tradeoff in itself, therefore, it does not need an additional penalty term. The error used in this method is the difference between the observed output data and the noiseless output. Since the noiseless output as the representative of the true model is not available, this error has been bounded probabilistically. Furthermore, unlike the above order selection criteria, this method does not consider the true model to be a subset of estimated model sets, which is a realizable assumption. Last but not least, this approach has proved that AIC, BIC, and two-stage MDL are its special cases. Considering these specifications, RE-LTI model order 14

selection is the state of the art to the best of our knowledge and we develop our online procedure based on this method.

2.1.3

Reconstruction Error (RE)

Here we briefly review RE as the one powerful method of model order selection. Note that this method is closely related to the MNDL approach [37] :
2 N N 2 (y ; y ) ^S MNDL(y N , w ) = min DLw m Sm

(2.27)

where description length (DL) is:
N DL(y N ; y ^S ) = log2 m 2 + 2w

log2 e zSm 2 2w

(2.28)

and reconstruction error, zSm , is: zSm = 1 N N y -y ^S m N
2 2

(2.29)

In the absence of noise if we consider a class of estimated model sets with different orders for an LTI system, obviously the highest order among them would introduce the least estimation error while in the presence of noise estimating more parameters of impulse responses, in other words models with higher orders, always do not result in smaller estimation errors since they are noisier than the lower orders [6]. As a result, to compare model sets with different orders a metric which shows parameter estimation error as a decreasing function of model sets orders by using available noisy finite-length input-output data of the system is needed. Considering the input-output relation for a causal LTI system with finite length impulse response as follows:
M -1

y (n) =
i=0

a i u[n - i]

(2.30)

where u[n] is the input and independent of additive noise with length N ,a i represents the realvalued coefficients of the impulse response which has the maximum length of M and y is the 15

noiseless output of length N which is not available. Available noisy version of the output is: y [n] = y [n] + w[n]
2 . w[n] is additive white Gaussian noise with zero mean and variance of w

(2.31)

To write (2.30) as a linear transformation using Toeplitz matrix, we consider the vector of impulse response coefficients as:
  T   = [a 0 , a1 , ..., aM -1 ] ,   SM

(2.32)

where  , true parameter, is a member of a compact set SM which is a subset of RM . It is assumed that M is an upper bound for the order of the true parameter. Then: y N = ASM  (2.33)

^S as the parameter estimate of order M , a Maximum Likelihood estimator Now considering  M of  as previously defined in (2.6) is:
-1 T N SM (y N ) = (AT SM ASM ) ASM y = -1 T N (AT SM ASM ) ASM (y + w )

(2.34)

which is the projection of y N , the sum of noiseless output and additive Gaussian noise into the parameters space. As we can see in (2.34) when wN = 0 ,in the absence of noise, the parameter estimate is true parameter. On the other hand, when wN = 0, some amounts of additive noise are added to the elements of true parameter which must be especially noted when the amount of each element is zero or much smaller than the amount of corresponding fitting element of noise, in this case in order to reduce the effect of noise and decrease the estimation error, it would be better to look for an estimate of a subset of true parameter which means setting those elements to zero or in other words having them unmodeled. When estimating in subspaces of SM , we can rewrite true parameter vector as :   = 
 S m

  (2.35)

Sm 16

 where S is the vector of true parameter in the subspace Sm with length m, 1  m  M , and m

Sm is a vector of length M - m for the rest of parameters not modeled in the subspace Sm . Therefore, elements of each subspace Sm would be:  = [a0 , a1 , ..., am-1 , 0, ..., 0]T  Sm , Sm  SM (2.36)

Now, looking at the first m columns of ASM matrix as ASm and the rest of M - m columns as BSm , we can rewrite (2.33) as :  y N = ASm BSm 
 S m

  = AS  + BS S m Sm m m (2.37)

Sm

and for parameter estimate of order m in subspace Sm we just replace ASm instead of ASM in (2.34):  Sm (y N ) = 
N -1 T  + ( AT S Sm ASm ) ASm (BSm Sm + w ) m

  (2.38)

0(N -m)×1 and using estimation of true parameter in subspace Sm we can define estimate of observed output data as:
N yS = ASm Sm = ASm BSm Sm = m

(2.39)  

 

 ASm (S m

+

-1 T ( AT Sm ASm ) ASm (BSm Sm

+ w ))

N

0(N -m)×1 To compare the estimates of true parameter in subspaces with different lengths of m and choose the optimum number of elements to be estimated, we can use the parameter estimation error. Since unmodeled coefficients are not available, parameter estimation error cannot be calculated with available data. In each subspace, observed output and its estimate are available so a possible error to calculate is data error, xSm , (2.8). As it has been shown in Figure (2.1) data error is a decreasing function of m or in other words it cannot be used as a comparing error among the subspaces to find the optimum length of true parameter estimate. According to this error the lowest amount of error is obtained for the highest amount of m which is the length of true parameter itself. Obviously, 17

an increasing function of m as a penalty term must be added to this error then it could be used as a comparing measurement. Having data error available and knowing its distribution we can find lower and upper bounds for parameter estimation error that is our comparing criterion to find the optimum m. In order to get to that point another error which is the transformation of parameter error into the output space by using Toeplitz matrix ASM is defined and called reconstruction error: 1 N N y - yS m N 1 ASM ( - Sm ) N
2 2

zSm =

2 2

=

2 2

=

(2.40)

1 GSm BSm Sm + CSm wN N where

-1 T GSm = I - ASm (AT Sm ASm ) ASm

(2.41)

-1 T CSm = ASm (AT Sm ASm ) ASm

(2.42)

are projection matrices with ranks N - m and m respectively. Bounding ZSm in order to compare the competing model sets, we have to consider the worst case value of this error which is the upperbound of zSm . zSm (Q( ), xN , y N , Q())  zSm  zSm (Q( ), xN , y N , Q()) (2.43)

Using available observed data and data error the probabilistic bounds of zSm are possible to be calculated and its upperbound as the worst case is:  m 2m 2 2 zSm (Q( ), xN , y N , Q()) = USm (Q(), xN , y N ) + w + N N where USm an upperbound of unmodeled coefficients effect is defined as: USm (xN , y N , Q()) = xSm - mw + 22 w 2 + KSm () N (2.45) (2.44)

and xSm is the available data error and KSm and mw are: w KSm () = 2  N 2  2 1 + xSm - mw N 2 m 2 mw = 1 - w N 18 (2.46) (2.47)

Q() and Q( ) are chosen confidence and validation probabilities such that:  2m 2 Q( ) = P r | ZSm - E (ZSm ) |   N w Q() = P r | XSm - E (XSm ) |  varXSm

(2.48) (2.49)

Confidence and validation probabilities are desired to be as high as possible but under certain conditions to provide tight bounds on zSm [6], therefore conditions are:
N 

lim N =  lim N =  = 0 = 0

(2.50) (2.51) (2.52) (2.53)

N 

N lim  N  N N lim  N  N

Setting the confidence and validation probabilities to zero causes the upper and lower bounds converge together therefore an estimate of the reconstruction error is: zSm  xSm + ( 2m 2 - 1)w N (2.54)

which in this format is like AIC defined by data error and a penalty term as a function of model order and data length. On the other hand setting the confidence probability to zero and setting  as  m log(N ) for the validation probability will make the upper bound of reconstruction error like the criterion used in BIC or two-stage MDL. The bias-variance tradeoff in zSm can be illustrated with its expectation and variance: E (zSm ) = m 2 1 w + GSm BSm Sm 2 2 N N 2m 2 2 V ar(zSm ) = 2 (w ) N (2.55) (2.56)

Sm as the effect of unmodelled coefficients would be zero for orders greater than true parameter's order where only the first term of E (ZSm ) is not zero which is like a penalty increasing by m. But in the limit this term would become zero as well which means in the limit for subspaces of orders greater than true parameter's order E (ZSm ) is zero. 19

Finally, summarizing the proposed method in [6] to choose the optimum subspace order, m, would be as follows: Sm = arg min zSm (Q( ), xN , y N , Q())
Sm

(2.57)

where m is the optimum order and Sm is its corresponding least noisy estimated impulse response.

2.2

Time Delay Estimation (TDE)

As discussed in Chapter 1, many methods of time delay estimation (TDE) are available in literature. Time delay can be estimated in different domains such as time domain or frequency domain. If the time delay is not an explicit parameter of a model, the model parameters must be estimated first and then the time delay is estimated. Otherwise, the time delay and model parameters can be estimated at the same time [26]. In the time domain, a delayed impulse response has a zero part at its beginning. Therefore, some methods such as Cumulative Sum (CUSUM) [2] try to detect the beginning of non-zero part. These methods need to first estimate the impulse response parameters. Then, they use some techniques to reduce the uncertainty of the estimated parameters and finally, some thresholding methods are applied to detect the delay at the beginning of the impulse response. In the frequency domain, the real part of the Fourier transform of an impulse response consists of a sinusoid with the frequency of time delay and a phase shift. The spectrum of this real part has a peak at the frequency of time delay [26]. Having described the above time delay estimation methods, we are going to estimate the time delay in the time domain when it is not an explicit parameter of a model. Therefore, in Chapter 4 we use RE-LTI order selection to estimate the delayed impulse response. Then, we propose a method to estimate the number of zero taps at the beginning of the estimated impulse response. The estimated time delay is going to provide the best fit of the model. In order to show that estimated

20

delay leads to the best fit of the model, we use fit index [2] as: f it = 100 1 - y ^-y y-y (%) (2.58)

21

Chapter 3 Online RE- LTI Order Selection
How should the least noisy estimated parameters or order of a linear time-invariant system be modified when the available data set enlarges? The above question would be addressed through online model order selection. Among the information theoretic criteria discussed in Chapter 2, we have chosen the RE-LTI model order selection method [6] as it outperforms the other criteria in finding the best fit of a true model from the available data set. Utilizing (2.57) for an online model order selection would be time-consuming and cannot be implemented in an online procedure. Therefore, in order to be able to keep up with the incoming information flow we should introduce a recursive function of previously defined Sm (N ) and newly arrived data as:

Sm (N + 1) = f (Sm (N ), u[N + 1], y [N + 1])

(3.1)

In this way, f should be defined as a recursive function with small and simple steps as possible that responds fast to the changes of input data set size, especially when the data set size becomes extremely large. A metric providing an upper bound on the growth rate of a function is big O notation. This notation is used in the following sections of this chapter to show the proposed 22

online algorithm improvement. According to (2.57), the optimum m is the one that minimizes the upper bound of reconstruction error, zSm , for all nested subspaces m , 1  m  M . As the data length grows, using this equation to find the least noisy estimate is time-consuming in particular when the data length becomes extremely large. Considering the upper bound of zSm with respect to the computational complexity order, we find that computing the data error, xSm , is the most complicated part due to finding the estimate of true parameter for every m as data length grows. Thus to achieve a fast online model order selection algorithm, we should estimate SM (y N +1 ) recursively. But prior to that, we go briefly through the definition of SM (y N ). Parameter estimate of order M, SM (y N ) is defined in (2.6) as: SM (y N ) = AT SM (N )ASM (N )
-1 N AT SM (N )y

(3.2)

where ASM is the N × M Toeplitz matrix generated by the available input uN as:   u1 0 0 0 ... 0      u2  u 0 0 . . . 0 1      u3  u u 0 . . . 0 2 1      .  . . . ... .       . . . ... .  .       .  . . . ... .   uN uN -1 uN -2 uN -3 . . . uN -M +1 and y N is the observed output.

(3.3)

When the length of available data is increased by one, uN becomes uN +1 and yN becomes yN +1 , the new Sm (y N +1 ) can be calculated by using Sm (y N ) in a recursive manner. In this way, the number of steps to calculate new Sm (y N +1 ) will be decreased substantially and consequently, as shown in the next section, we will reach a lower complexity order in comparison with simply defining all matrices from the beginning and using (2.57). 23

Important Notation: In the following sections, Sm (y N +1 ) is denoted by Sm (N + 1) and also Sm (N ) represents Sm (y N ) to simplify notations.

3.1

Online Parameter Estimation Sm (N + 1)

Increasing data length by one adds a new row and column to ASM (N ) and AT SM (N ) respectively. Instead of multiplying the new matrices of ASM (N + 1) and AT SM (N + 1), we can add to the previously multiplied ASM and AT SM a new matrix as the added new row and column effect, and find the same result. Therefore, the complexity order of matrix multiplication of the size of ASM and its transpose in each increasing data length step, N to N + 1, reduces from O(N 3 ) to O(N ) as shown in the following: FN = AT SM (N )ASM (N ) (3.4)

Now adding a new row and column to ASM (N ) and AT SM (N ) respectively, and then multiplying them to find the FN +1 can be shown as:    uN +1     u  N      u   N -1       uN -2    u FN +1 = FN +   N +1 uN uN -1 uN -2 . . . uN -M +2   .       .       .     uN -M +2 and if we define an M × 1 column vector U as: U T = uN +1 uN uN -1 uN -2 . . . uN -M +2 then FN +1 is: FN +1 = FN + U U T = 24 (3.7) (3.6)

(3.5)



u2 N +1

uN +1 uN

uN +1 uN -1

. . . uN +1 uN -M +2 ... ... ... ... ... ...



   uN uN +1 u2 uN uN -1 N    uN -1 uN +1 uN -1 uN u2 N -1   FN +  . . .    . . .     . . .  uN -M +2 uN +1 uN -M +2 uN uN -M +2 uN -1

  uN uN -M +2    uN -1 uN -M +2     .    .     .  2 uN -M +2

where FN is an M × M matrix defined by u1 to uN and an M × M matrix with rank one. As (3.5) indicates, updating FN to FN +1 needs N multiplications at most. Although FN +1 is done in N steps as the data length goes to infinity, its inverse still has a com-1 -1 plexity order of O(N 3 ). So the lemma is to calculate FN +1 based on FN .

As proved in [38], because the rank of matrix U U T is one:
-1 -1 T -1 FN = FN - +1 = (FN + U U )

1 -1 -1 FN U U T FN 1+g

(3.8)

where
-1 g = trace(U U T FN )

(3.9)

g = -1
-1 Updating the inverse of FN by using (3.8) and finding FN +1 decreases the complexity order of

matrix inversion from O(N 3 ) to O(N 2 ) [38], which decreases the processing time of our online order estimation procedure significantly.
N Finally, calling the previously calculated AT SM (N )y as matrix CN : N CN = A T SM (N )y

(3.10)

25

we can define CN +1 as: u y  N +1 N +1     uN yN +1       uN -1 yN +1       = CN +  .       .         .   uN -M +2 yN +1  

CN +1 = CN + U yN +1

(3.11)

N U yN +1 is the effect of the new column and row added to AT SM (N ) and y respectively in their

multiplication. It decreases the big O notation of CN +1 from O(N 2 ) to O(N ).
-1 Now substituting FN +1 and CN +1 in SM (N ) we have: -1 SM (N + 1) = FN +1 CN +1 = -1 FN -

1 -1 F -1 U U T FN (CN + U yN +1 ) 1+g N

(3.12)

SM (N + 1) =

1 F -1 U U T SM (N ) + 1+g N 1 -1 I- F -1 U U T FN U yN +1 1+g N I-

(3.13)

and consequently, parameter estimate in subspaces of order m, 1  m  N , is as follows: Sm (N + 1) =   0(N +1-m) Getting back to Chapter 2, the reconstruction error upper bound, as the worst case is used to compare subspaces of different orders. To calculate zSm recursively we should also define data error, xSm , y ^Sm and Sm (N ) recursively. Replacing (3.14) and ASM (N + 1) in (2.37) we have: y ^Sm (N + 1) = ASM (N + 1)Sm (N + 1) 26 (3.15) I-
1 -1 T (AT Sm ASm ) Um Um 1+g

(3.14)
-1 (AT Sm ASm ) Um yN +1

Sm (N ) + I -

1 -1 T (AT Sm ASm ) Um Um 1+g

 

and then updated xSm would be: xSm (N + 1) = substituting (3.16) in (2.44):  2m 2 m 2 + zSm (Q( ), uN +1 , y N +1 , Q()) = USm (Q(), uN +1 , y N +1 ) + w N +1 N +1 where USm (N + 1) is: USm (uN +1 , y N +1 , Q()) = xSm (N + 1) - mw (N + 1) + 22 w 2 + KSm (, N + 1) (3.18) N +1 (3.17) 1 N +1 N +1 y -y ^S m N
2 2

(3.16)

3.2

Online RE-LTI Order Selection Procedure

Through the previous sections we derived the reconstruction error upper bounds based on its previous amounts for subspaces of different orders when the data set size increases by one . Now, putting all those equations together we can modify the proposed offline model selection process in [6] to get the online RE-LTI order selection procedure as follows:

· Step 1: Optimum subspace order, m , is chosen for any data length of N through RE-LTI system identification approach (2.57). · Step 2: For any new data point arrived, any subspace's impulse response is updated using (3.14). Then y ^Sm (N + 1), xSm (N + 1) and zSm (N + 1) are calculated using (3.15), (3.16), and (3.17) respectively. · Step 3: Optimum subspace order, m , is updated for any new data point arrived, by comparing the probabilistic worst cases for all subspaces of S1 , S2 , ..., SM : Sm (N + 1) = arg min zSm (Q( ), uN +! , y N +1 , Q())
Sm

(3.19)

where m is the updated optimum order and Sm is its corresponding least noisy estimated impulse response. 27

· Step 4: Go to step 2.

As discussed in Chapter 2, MNDL and RE-LTI model order selections are closely related in that MNDL and RE-LTI use the same reconstruction error, zSm . Therefore, following the above steps also make the MNDL online. Important Notation: In terms of zSm , because the worst case is its upper bound which is the basis of all decisions in RE-LTI, in the remainder of this thesis zSm is denoted by zSm .

3.3

Complexity Order of Online RE-LTI Order Selection Procedure

In Section 3.1, we showed that updating Sm (N ) to Sm (N + 1) is done through a recursive function 3.14 with the complexity order of O(N 2 ). As a result, updating xSm (N ) to xSm (N + 1) through 3.16 also has the complexity order of O(N 2 ) because y ^Sm (N + 1) can be updated recursively as in 3.15. The upper bound of reconstruction error, zSm , is calculated through 3.17 and 3.18. In these equations, the highest complexity order is for updating data error which is O(N 2 ). Finally, since the optimum order, m , in online procedure is chosen based on the upper bound of reconstruction error 3.19, the complexity order of our online procedure is O(N 2 ) which shows one order decrease compared with the offline RE-LTI order selection algorithm.

3.4

Online RE-LTI System Identification and Slowly Varying Systems

As it was described, RE-LTI system identification approach chooses the optimum m for any data of length N . In this chapter, we have shown how to update the value of m as the data length 28

grows. The procedure for each N provides an m (3.19) and consequently a value of zSm (3.17). In online system identification our confidence in the calculation of m will improve as the data length increases. Where should be the stopping point of identification depends on the application. Defining the normalized reconstruction error as follows: N zSm = zSm y 2 2 (3.20)

for each given data set of length N , the optimum normalized reconstruction error is calculated as follows: N zSm = arg min N zSm
m

(3.21)

We call the tolerance for this error Stop-ID threshold. Stop-ID threshold is provided by the user to be an value. Once the normalized zSm becomes less than this value the online system identification procedure will halt. Consequently, another potential application of this method will be for slowly varying LTI systems. The online system identification procedure keeps searching for the optimum system until the normalized reconstruction error is reached. Then the procedure uses

that estimated system until the value of normalized reconstruction error becomes larger than . This indicates that the system has slowly been changed . Note that up to this stage the zSm will be updated using the already estimated parameters. At this point, the system identification procedure gets activated till the normalized reconstruction error again becomes less than . The following steps summarize this procedure:

· Step 1: Value of Stop-ID threshold, , for the optimum normalized reconstruction error, zSm , is selected by the user. · Step 2: Optimum subspace order, m , is chosen for any data length of N through RE-LTI system identification approach (2.57). · Step 3: Optimum subspace order, m , is updated through online RE-LTI order selection procedure (3.2) for any new data point.

29

· Step 4: At the end of each iteration of online RE-LTI order selection procedure, the normalized reconstruction error is calculated (3.20) and then the optimum normalized reconstruction error is obtained by (3.22) · Step 5: If N zSm < then the online procedure will halt at this point to update the parameters and optimum order. From now it just updates the zSm for new arriving data points using the already estimated parameters up to the stopping point and as soon as N zSm becomes larger than the online procedure gets back to its full operation. Otherwise, the online procedure keeps searching for the optimum system.

3.5

Simulation Results

Considering an independent identically distributed (i.i.d.) Bernoulli sequence of ±1 with increasing length from N = 50 to N = 400 data samples and three different SNRs of 10 dB, 15 dB, and 40 dB as the input data of an LTI system with the following structure:
M

y [n] =
i=0

ai u[n - 1] + w[n]

(3.22)

where ai s are the coefficients of an FIR filter, h[n], of length 50 as: ai = 0.3(0.5)i-1 + 3(i - 1)(0.8)i-1 , 0  i  50 (3.23)

Figure 3.1 shows the impulse response as defined in (3.22). Reconstruction error simulation results of such a system are provided in Figures 3.2, 3.3, and 3.4 when  and  used in validation and confidence probabilities are chosen as:  = 15 ln(ln(N ))  = 25 ln(N ) (3.24) (3.25)

Different data lengths and SNRs are used for these figures to illustrate the asymptotic behavior and the robustness of our online order selection method. As m increases, more noise is fitted and the 30

number of unmodeled coefficients is decreased. Therefore, we see the zSm bias-variance tradeoff behavior which helps us to find the optimum order. For example, in Figure 3.3, when data length has arrived to N = 400 estimating more than 20 taps will increase the zSm as a result of fitting more noise. Comparing these three figures, reveals that when data length is increased because of noise effect reduction (2.55) reconstruction error is decreased. Figure 3.5 shows optimum order as a function of data length for three different SNRs. This figure illustrates that for higher SNRs the chance of choosing the correct order is higher. Furthermore, this figure shows the convergence of the optimum order to the true model order as data length and SNR are increased. Figure 3.6 shows the minimums of normalized reconstruction error as a function of data length for three different SNRs (3.20). N zSm decreases as data length and SNR are increased because of noise effect reduction. On this figure, the is 10-2 as an example to show the Stop-ID definition. When SNR is 40dB, the N zSm is less than our defined threshold by arriving only 50 samples so the online procedure should be stopped after arriving 50 samples. For 10 dB SNR, the N zSm passes the threshold after arriving 250 samples.

5

4.5

4

3.5

3

h[n]

2.5

2

1.5

1

0.5

0 0 5 10 15 20 25 30 35 40 45 50

n

Figure 3.1: True Impulse Response

31

10

4

N=200 , SNR=10dB N=300 , SNR=10dB N=400 , SNR=10dB

zsm

10 3

10 2

0

5

10

15

20

25

30

35

40

45

50

m

Figure 3.2: Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=10 dB.

10 3
N=200 , SNR=15dB N=300 , SNR=15dB N=400 , SNR=15dB

zsm

10

2

10

1

0

5

10

15

20

25

30

35

40

45

50

m

Figure 3.3: Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=15 dB.

32

10

3

N=200 , SNR=40dB N=300 , SNR=40dB N=400 , SNR=40dB

10 2

zsm

10 1

10 0

10 -1

0

5

10

15

20

25

30

35

40

45

50

m

Figure 3.4: Reconstruction error as a function of m , for data lengths N = 200, N = 300, and N = 400 when SNR=40 dB.

40
SNR=10dB SNR=15dB SNR=40dB

35

30

25

m*

20

15

10

5

0 50

100

150

200

250

300

350

400

N

Figure 3.5: Optimum subspace order m as a function of data length N for three different SNRs of 10 dB, 15 dB, and 40 dB. 33

10 0
SNR=10dB SNR=15dB SNR=40dB

10 -1

10 -2

NzSm

10 -3

10 -4

10 -5

10 -6 50

100

150

200

250

300

350

400

N

Figure 3.6: Normalized reconstruction error zSm as the function of data length for three different SNRs of 10 dB, 15 dB, and 40 dB.

In Table (3.1), the performance of the proposed online procedure is illustrated in terms of elapsed time as data samples arrive. In this table, is 10-2 and the number of data points needed to pass the and their corresponding optimum orders are shown. Four last columns of this table are the and at N = 200. To show the low complexity and fast computational time of

elapsed times at

our online procedure, we used the offline RE-LTI order selection in an online manner. Although for larger data sizes the time gap between online and offline algorithm would be greater, still we can see our online procedure is almost 1.7 times faster than the offline algorithm.

34

Time Time Stop-ID SNR (dB) Threshold Stop-ID Threshold at N m at Passed at Stop-ID (Online) Threshold (Sec.) 10 15 40 10-2 10-2 10-2 254 178 50 16 19 24 0.9205 0.4922 0.0122 (Sec.) (Sec.) 1.7054 0.9804 0.0122 2.0029 2.015 2.0062 (Offline) (Online) Passed at N = 200 Time Passed at

Time Passed at N = 200 (Offline) (Sec.) 3.4209 3.4032 3.4173

Table 3.1: Online RE-LTI vs. Offline RE-LTI Procedure

3.6

Practical Application in Power System

In a power system, electrical loads vary considerably throughout the day. These variations are shown in load curves such as in Figure 3.7. Therefore, the load of a power system is not constant that leads to a mismatch between real power generated at the power system and the amount of power consumed at the load side. In power systems, load variation is detected by monitoring the variations in frequency. For instance, when load increases the power system frequency would decrease. Thus additional generation is needed to supply required power to consumers [39]. To overcome the mismatch problem, an adjusting system for the output power of interconnected generators is designed. This unit is known as automatic generation control (AGC). AGC has three kinds of control loops, namely primary, secondary and tertiary ( [39]). Each control loop has different time duration as shown in Table 3.2. There is a primary control loop or governor for every generator. The primary loop controls the variations of frequency around a specified frequency which is defined by the secondary control loop. The secondary control loop or AGC has a proportionalintegral (PI) controller which resets frequency droops to maintain a balance between generation and load. A group of generators which are controlled by a regulation unit and have the same frequency variations is named an area. 35

Figure 3.7: Ontario Demand At 12:00pm EST July 26, 2016 [1]

Control Loop Primary (or Governor) Secondary (or AGC) Tertiary (or ED)

Time Duration A few seconds Less than one minute More than 12 minutes and less than an hour

Table 3.2: AGC Control Loops' Time Duration

An area is controlled by AGC that is located on the regulation unit. AGC should update PI controller parameters because of load changes in an area. These parameters depend on load-generation scenario which is determined by the third control loop. The tertiary control loop or economic dispatch (ED) determine the generation scenario for every generator based on the amount of load [40]. Therefore, PI controller parameters should be updated at least every 12 minutes. 36

Due to the nonlinearity of power systems, the system is tried to be linearized around its operating point [40]. Then the linear model is used in designing the AGC controller parameters. Although, there are methods of designing robust automatic generation controllers against the changes, another way is designing controller parameters through online algorithms. Considering the second solution, there is a need for an online procedure capable of linearly modeling the changes in system frequency caused by load variation in a fast and consistent enough way.

3.6.1

Power System Simulation Results

In this section we are going to prove the ability of our online procedure in a practical application which is a system of two interconnected power plants, hydro and nuclear. This system has a transfer function model as shown in Figure 3.8. We simulated this system in MATLAB/Simulink with a 10% load variation in hydro plant and we collected the frequency variations as the output data from both plants. Having this input and output data available, we can apply our online RE-LTI order selection procedure to estimate a linear model which is used by AGC to redesign its controller parameters over the period of arriving new data. As an example, we consider the frequency variation at hydro plant and we show the simulation results. Figure 3.9 illustrates zSm as a function of m when length of data is 3000 and for three different SNRs. For example, when SNR is 40 dB, zSm starts increasing after 35 estimated parameters of the system impulse response. This tradeoff in behavior of the reconstruction error for lower SNRs can be seen for a smaller number of estimated impulse response taps, which mean some coefficients are set to zero in order to reduce the effect of the noise in the estimated model while achieving the best fit. Figure 3.10 provides us with a better understanding of the SNR and data length effects on the estimated optimum order. This figure shows the convergence of the optimum order to the true model order as more data becomes available. As SNR grows, this figure shows that the optimum

37

order goes faster towards the true model order.

Figure 3.8: Transfer function model of an interconnected two-area Hydro-Nuclear system [41]

10

3

10 2
N=3000 , SNR=10dB N=3000 , SNR=15dB N=3000 , SNR=40dB

zSm

10 1

10 0

10 -1

0

5

10

15

20

25

30

35

40

45

50

m

Figure 3.9: Reconstruction error as a function of m , for data length N = 3000 and three different SNRs of 10 dB, 15dB and 40dB. 38

40

35

30
SNR=10dB SNR=15dB SNR=40dB

25

m*

20

15

10

5

0 0 500 1000 1500 2000 2500 3000 3500

N

Figure 3.10: Optimum subspace order m as a function of data length N for three different SNRs of 10 dB, 15 dB, and 40 dB.

Normalized reconstruction error as a function of N is shown in Figure 3.11 for three different SNRs. An ,as the Stop-ID threshold defined by the user, on this figure can validate the estimated model and stop the online procedure after arriving a number of samples. According to Table 3.2, in tertiary loop we should be able to update the PI controller parameters in less than an hour. While Table 3.3 shows that our online procedure needs almost 16 minutes to model 10000 data samples. On the other hand Figure 3.11 shows after arriving 3000 data samples N zSm is very small meaning that the PI controller parameters have been updated fast enough to control the frequency deviation.

39

10

0

SNR=10dB SNR=15dB SNR=40dB

10

-1

10 -2

10 -3

NzSm
10 -4 10
-5

10 -6

10 -7

0

500

1000

1500

2000

2500

3000

3500

N

Figure 3.11: Normalized reconstruction error zSm as the function of data length for three different SNRs of 10 dB, 15 dB, and 40 dB. Number of Samples Arrived (N) 3000 5000 10000 Table 3.3: Elapsed Time Elapsed Time at N 85.97 Sec. 235.48 Sec. 983.21 Sec.

40

Chapter 4 Optimal Time Delay Estimation
We reviewed different classifications and concepts of time delay estimation in Chapter 1 . Some of the methods looked for the true time delay estimation such as time delay estimated in radars target localization [42], channel equalization in communications [43], echo cancellation [44] and ultrasonic ranging [45]. A few of them looked for the most suitable time delay of a given model. The others estimated the time delay that provides the best fit of a model [2]. As we mentioned in Chapter 2, in this chapter, we propose a method of estimating time delay which results in the best fit of a model. Considering the model structure in (2.1), if the impulse response of this model has a number of zero coefficients at its beginning, then the input-output relation of that model would be as follows:
M -1 M -1

y [n] =
i=0

h[n - d]u[n - i] + w[n] =
i=0

h[n]u[n - d - i] + w[n]

(4.1)

where h[n - d] is the impulse response with delay as: h[n - d] = [0, . . . , 0, a0 , a1 , . . . , aM -1-d ]
d

(4.2)

uN and y N are available data, d is the true delay, and w[n] is additive white Gaussian noise with
2 zero mean and variance of w . Here the definition of time delay is the starting point of impulse re-

41

sponse or the beginning of non-zero part. Employing RE-LTI model order selection, we introduce a process of estimating optimum time delay as: d = arg min zSdm (Q( ), uN , y N , Q())
d

(4.3)

where d is the optimum estimate of true delay d, Sdm s for 1  dm  m are the competing subspaces with different delays of 0  d  m - 1, Q() and Q( ) are chosen such that conditions in (2.51), (2.52), (2.53), (2.54) are satisfied, uN and y N are available data, and m is the optimum order of the model structure with delay as in (4.1) chosen by RE model order selection in (2.57).

4.1

RE Time-Delay Estimation

If Sm is the optimum parameter estimate of order m for model structure in (4.1) obtained by minimizing the reconstruction error over all subspaces, we are going to seek in subspaces of m for an optimum estimate of delayed parameter, Sdm using (4.3). In other words, the proposed process is twofold:

· Step 1: Estimating an optimum order and parameters of the delayed model based on (2.57). · Step 2: Estimating the optimum number of zero taps at the beginning of the estimated model in Step 1.

Step 1 has been studied in detail in [6]. In this section, we go through details of step 2 as our contribution to the time delay estimation problem.

42

4.1.1

Estimation of Model Parameters in Subspaces of m

To estimate the optimum delay, d , we consider subspaces of optimum estimated order m as 1  dm  m , with the following structure of Sm :   dSd Sm =  m  Sdm

(4.4)

where dSdm is a zero vector of length d and Sdm is a vector of non-zero parameters of the optimum estimated delayed model with the length of m - d. In order to estimate the number of zero coefficients, d, and consequently the non-zero parameters of Sdm we use the least square estimator as in (2.38). Thus, we define the Toeplitz matrix generated by the input, uN , with the following format: 0 0  u1   u2 u1 0   = u2 u1  u3   ··· · · · · · ·  uN uN -1 uN -2  ... ... ... ··· 0 0 0 ···
+1

           

ASdm

(4.5)

. . . u N -m

when ASdm is an N × m matrix, it can be represented as: ASdm = ASdm BSdm (4.6)

where ASdm is the first d columns of Toeplitz matrix ASdm and BSdm is the rest of m - d columns of that Toeplitz matrix. Now the estimated parameters of delayed model would be:   0(d×1)  Sdm =  T -1 T N (BSdm BSdm ) BSdm y

(4.7)

BSdm matrices for different dm s are like Toeplitz matrices generated by delayed version of uN s for different lengths of delay, d.Therefore, the results of least square error correspond to dm coefficients of non-zero part of the delayed true impulse response. The rest of d coefficients at the beginning of each vector of estimated impulse response corresponds to the number of zero taps which is the estimated delay. 43

4.2

Simulation Results

To generate Figures 4.1, 4.2, 4.3, and 4.4 Our true model is the delayed version of FIR filter in (3.23) for 23 taps. We considered an i.i.d. Bernoulli sequence of ±1 with length N = 300 and three different SNRs. The true impulse response and its estimates for three SNRs of 10 dB, 15 dB and 40 dB are shown in Figure 4.1, 4.2 and 4.3. As it has been shown, the optimum estimated delay for SNR=10 dB and SNR=15 dB is 25 and for SNR=40 dB is 24. Obviously, for SNR=40 dB our optimum estimated delay is closer to the true time delay than the two other SNRs. This is the result of noise effect reduction. However, it does not mean that our method is not accurate for low SNRs. It must be noted that this method looks for the time delay which results in the best fit of the true model in the presence of the noise. In the next section, we use an index to illustrate our method accuracy or superiority better.

6
True h[n] with Delay of length 23 Optimum Estimation of True h[n] with Delay SNR=10 dB

5

4

h[n]

3

2 Optimum Delay=25 1

0

0

10

20

30

40

50

60

70

n

Figure 4.1: True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 25

44

6
True h[n] with Delay of length 23 Optimum Estimation of True h[n] with Delay SNR=15 dB

5

4

h[n]

3

2

Optimum Delay=25 1

0

0

10

20

30

40

50

60

70

n

Figure 4.2: True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 25

In Figure 4.4, reconstruction errors as functions of m for both steps of time delay estimation are illustrated. There are two graphs for each SNR in this figure, one graph corresponds to the zSm used in model order selection step and the other corresponds to the zSm used in time delay estimation step. For example, the black graph with SNR=15 dB shows that more than 40 taps estimation increases the reconstruction error as the effect of fitting more noises. The red graph with the same SNR as the black one shows the calculated reconstruction error in step 2 of time delay estimation. The red graph has its minimum at m = 23 which is the number of zero taps at the beginning of the estimated impulse response.

45

5
True h[n] with Delay of length 23 Optimum Estimation of True h[n] with Delay SNR=40 dB

4.5 4 3.5 3

h[n]

2.5 2 1.5 Optimum Delay=24 1 0.5 0

0

10

20

30

40

50

60

70

n

Figure 4.3: True Impulse Response and Optimum Time Delay Estimated Impulse Response with N = 300, T d = 23, and d = 24

10 3

10 2

zsm

10 1

N=300 N=300 N=300 N=300 N=300 N=300

, , , , , ,

SNR=10dB SNR=15dB SNR=40dB SNR=10dB SNR=15dB SNR=40dB

10 0

10 -1

0

10

20

30

40

50

60

70

80

90

100

m

Figure 4.4: Reconstruction error zSm as the function of m for three different SNRs of 10 dB, 15 dB, and 40 dB. and Td=23 46

4.2.1

Comparison between Proposed and Existing Methods

An index to measure the quality of an estimated time delay as the best fit in a system identification scenario is presented in [2] as follows: f it = 100 1 - y ^-u y-y (%) (4.8)

where y is the observed output, y ^ is the estimated output and y is the noiseless output. Some timedelay estimation methods investigated thoroughly in [26], such as the Cumulative Sum (CUSUM), delayest algorithm and separating time delay from dynamics in the frequency domain, are compared in terms of the fit index when the process model is: G(n) = 0.256(0.909)n u(n) - 0.333(0.815)n u(n) (4.9)

when the true time delay at the beginning of (4.9) is 11. To excite this model, 1000 samples of a pseudo-random binary sequence (PRBS) are used. Three scenarios are considered. First, the order of (4.9) is identified correctly by all methods. Second, A wrong order for our considered model is identified by all methods. Finally, an output error model with correct order is applied. In these three scenarios considered methods are: CUSUM-CrossCorr, CUSUM-FIR and CUSUM-ARXHigh, frequency domain technique, delayest and OPT which are studied completely in [26] and [2]. CUSUM-CrossCorr use crosscorrelation to estimate the impulse response, CUSUM-FIR uses an FIR model to model the impulse response and CSUM-ARX-High uses a high order autoregressive to model the impulse response. OPT is a two-step optimization problem which first tries to predict the best model and then it estimates the time delay. All techniques are applied when the true time delay, nk is 11. Data in Table 4.1 are adopted from [2]. The last row of this table shows the estimation of the time delay for the same settings as the other methods by our proposed RE timedelay estimation method. Since our method is not order dependent and it selects the best order

47

using reconstruction error, therefore the second and third scenario does not apply to our method and just SNR variations make changes in our results. In the absence of the noise, like OPT and delayest, our method provides the true delay as the best fit. In case of SNR=3 dB and SNR=30dB, RE-LTI order selection method will set some impulse response parameters to zero in order not to fit too much noise to parameters which are too small. Therefore, the estimated result will not fit 100% the true model and as we mentioned earlier, it would be the best fit of the model. As the results show, RE time-delay estimation method would provide better fit for low SNRs than OPT and delayest.

48

Example 1 - ARX [na nb ]T = [22] SNR  SNR 30 nk FIT -14.5 34.3 20.3 20.3 20.3 34.3 -14.5 19.1 96.29 15 20 11 -11.1 11.1 67.23 12 6.41 12 11 21 12 15 2.33 14 14 4.96 14 5.27 5.27 14.9 -26.6 7.60 96.29 15 2.33 14 5.27 13 25.0 12 14.9 11 14 14 14 12 11 11 12 11 -11.1 18 7.76 11 98.1 98.1 61.3 61.3 61.3 65.3 98.1 98.1 96.29 FIT FIT FIT 11 12 14 14 14 12 11 13 12 nk nk nk SNR 3 SNR30 SNR 30 nk FIT 100 100 23.5 23.5 23.5  100 100 100 11 11 14 14 14 12 11 11 11 [na nb ]T = [11] [nb nf ]T = [22] SNR 3 nk 11 11 15 14 15 12 11 11 15 FIT 94.0 94.0 60.6 61.0 60.6 65.2 94.0 94.0 67.23

Example 2 - ARX

Example 3 - OE

nk0

nk

CUSUM-CrossCorr

49

CUSUM-FIR

CUSUM-ARX-High

Freq-Domain

delayest

OPT

RE

Table 4.1: Comparison of Time Delay Estimation Techniques - Noise-Free FIT(%) and nk Values [2]

Chapter 5 Conclusions and Future Works
In this thesis, we studied one powerful method of model order selection: RE-LTI order selection. We started Chapter 1 with an overview of information theoretic criteria such as AIC, BIC, two-stage MDL and we discussed some of their variants that have been proposed to improve their performances. We continued this chapter with the review of time delay estimation methods. In Chapter 2 we presented a short review of system identification. We studied existing model order selection criteria more in detail and we discussed their shortcomings. In this chapter, we provided a brief review of RE-LTI model order selection as the basis of our contributions. At the end of this chapter, we stated the type of time delay we wanted to estimate. In Chapter 3 we proposed our Online RE-LTI Order Selection method. In our online procedure, we updated the optimum order and its corresponding estimated parameters recursively. We showed one order decrease, from O(N 3 ) to O(N 2 ), in complexity order of our online procedure compared with the offline RE-LTI order selection method. Stop-ID threshold as a criterion to validate our online order selection procedure was introduced in this chapter. Stop-ID threshold defined by the user can halt the procedure and restart it. We discussed the advantages of our online procedure in case of slowly varying systems. Our simulation results showed the improvement in consistency and computational time of our online procedure compared with offline RE-LTI method. Estimating 50

the impulse response of an AGC in a power system of two interconnected hydro and nuclear plants was presented at the end of this chapter. We suggested updating the controller parameters of AGC by using our online RE-LTI order selection procedure to improve the power system dynamic performance. In Chapter 4 we used the RE-LTI order selection in two steps to estimate the time delay that provides the best fit of a true model. First, we estimated the optimum order of the true model and then we estimated the number of zero taps at the beginning of the estimated model. We compared the simulation results of our method with the existing methods in the literature, in terms of FIT index, and showed the superiority of our proposed method. Applying RE-LTI online order selection procedure to updating orders of real-time applications would lead to great results in future.

51

Bibliography
[1] The Independent Electricity System Operator, "Ontario demand at 12:00pm est august 26." http://www.ieso.ca/pages/power-data/default.aspx, 2016. [2] V. A. O. Alves, R. J. C. de Godoy, and C. Garcia, "Optimal time delay estimation for system identification," in 2013 American Control Conference, pp. 95­100, June 2013. [3] T. Soderstrom and P. G. Stoica, System Identification. Prentice Hall, 1989. [4] L.Ljung, System Identification, Theory for the User. Prentice Hall, 1999. [5] L. Fu and P. Li, "The research survey of system identification method," in Intelligent HumanMachine Systems and Cybernetics (IHMSC), 2013 5th International Conference on, vol. 2, pp. 397­401, Aug 2013. [6] S. Beheshti and M. A. Dahleh, "Noisy data and impulse response estimation," IEEE Transactions on Signal Processing, vol. 58, pp. 510­521, Feb 2010. [7] H. Akaike, "A new look at the statistical model identification," IEEE Transactions on Automatic Control, vol. 19, pp. 716­723, Dec 1974. [8] Q. Ding and S. Kay, "Inconsistency of the mdl: On the performance of model order selection criteria with increasing signal-to-noise ratio," IEEE Transactions on Signal Processing, vol. 59, pp. 1959­1969, May 2011.

52

[9] P. Stoica and Y. Selen, "Model-order selection: a review of information criterion rules," IEEE Signal Processing Magazine, vol. 21, pp. 36­47, July 2004. [10] A. Mariani, A. Giorgetti, and M. Chiani, "Model order selection based on information theoretic criteria: Design of the penalty," IEEE Transactions on Signal Processing, vol. 63, pp. 2779­2789, June 2015. [11] S. Kallummil and S. Kalyani, "High snr consistent linear model order selection and subset selection," IEEE Transactions on Signal Processing, vol. 64, pp. 4307­4322, Aug 2016. [12] G. Schwarz, "Estimating the dimension of a model," The Annals of Statistics, vol. 6, pp. 461­ 464, 1978. [13] J. K. Nielsen, M. G. Christensen, and S. H. Jensen, "Bayesian model comparison and the bic for regression models," in 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 6362­6366, May 2013. [14] P. Stoica and P. Babu, "On the proper forms of bic for model order selection," IEEE Transactions on Signal Processing, vol. 60, pp. 4956­4961, Sept 2012. [15] A. Barron, J. Rissanen, and B. Yu, "The minimum description length principle in coding and modeling," IEEE Transactions on Information Theory, vol. 44, pp. 2743­2760, Oct 1998. [16] S. Kay, "Exponentially embedded families - new approaches to model order estimation," IEEE Transactions on Aerospace and Electronic Systems, vol. 41, pp. 333­345, Jan 2005. [17] P. Stoica and P. Babu, "On the exponentially embedded family (eef) rule for model order selection," IEEE Signal Processing Letters, vol. 19, pp. 551­554, Sept 2012. [18] A. K. Seghouane, "Vector autoregressive model-order selection from finite samples using kullback's symmetric divergence," IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 53, pp. 2327­2335, Oct 2006.

53

[19] L. Qu, Q. Sun, T. Yang, L. Zhang, and Y. Sun, "Time-delay estimation for ground penetrating radar using esprit with improved spatial smoothing technique," IEEE Geoscience and Remote Sensing Letters, vol. 11, pp. 1315­1319, Aug 2014. [20] C. L. Bastard, Y. Wang, V. Baltazart, and X. Drobert, "Time delay and permittivity estimation by ground-penetrating radar with support vector regression," IEEE Geoscience and Remote Sensing Letters, vol. 11, pp. 873­877, April 2014. [21] J. Li, C. L. Bastard, Y. Wang, G. Wei, B. Ma, and M. Sun, "Enhanced gpr signal for layered media time-delay estimation in low-snr scenario," IEEE Geoscience and Remote Sensing Letters, vol. 13, pp. 299­303, March 2016. [22] F. Fereidoony, M. A. Sebt, S. Chamaani, and S. A. Mirtaheri, "Model-based super-resolution time-delay estimation with sample rate consideration," IET Signal Processing, vol. 10, no. 4, pp. 376­384, 2016. [23] C. M. Ionescu, R. Hodrea, and R. D. Keyser, "Variable time-delay estimation for anesthesia control during intensive care," IEEE Transactions on Biomedical Engineering, vol. 58, pp. 363­369, Feb 2011. [24] G. K. Rohde, F. Bucholtz, and J. M. Nichols, "Maximum empirical likelihood estimation of time delay in independently and identically distributed noise," IET Signal Processing, vol. 8, pp. 720­728, September 2014. [25] Y. Huang, J. Lin, and M. Giess, "High accuracy time delay measurements for band-pass signals," IEEE Transactions on Instrumentation and Measurement, vol. 62, pp. 2998­3005, Nov 2013. [26] S. Bjorkund, A Survey and Comparison of Time-Delay Estimation Methods in Linear Systems. PhD thesis, Linkopings universitet, Department of Electrical Engineering, Jun 2003.

54

[27] M. Davanipour, M. Zekri, and F. Sheikholeslam, "Fuzzy wavelet neural networks with hybrid algorithm in nonlinear system identification," in Computer Science and Automation Engineering (CSAE), 2011 IEEE International Conference on, vol. 1, pp. 153­156, June 2011. [28] P. M. Makila, "On optimal lti approximation of nonlinear systems," IEEE Transactions on Automatic Control, vol. 49, pp. 1178­1182, July 2004. [29] M. Salimifard and A. A. Safavi, "Nonlinear system identification based on a novel adaptive fuzzy wavelet neural network," in 2013 21st Iranian Conference on Electrical Engineering (ICEE), pp. 1­5, May 2013. [30] L. Ljung, "Approaches to identification of nonlinear systems," in Proceedings of the 29th Chinese Control Conference, pp. 1­5, July 2010. [31] A. A. Adeniran and S. E. Ferik, "Modeling and identification of nonlinear systems: A review of the multimodel approach­part 1," IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. PP, no. 99, pp. 1­11, 2016. [32] G. Pillonetto, F. Dinuzzo, T. Chen, G. D. Nicolao, and L. Ljung, "Kernel methods in system identification, machine learning and function estimation: A survey," Automatica, vol. 50, no. 3, pp. 657 ­ 682, 2014. [33] M. Barkat, Signal Detection and Estimation. Artech House, 2005. [34] A. O. Hero, J. A. Fessler, and M. Usman, "Exploring estimator bias-variance tradeoffs using the uniform cr bound," IEEE Transactions on Signal Processing, vol. 44, pp. 2026­2041, Aug 1996. [35] S. Beheshti and M. A. Dahleh, "Lti systems, additive noise, and order estimation," in Decision and Control, 2003. Proceedings. 42nd IEEE Conference on, vol. 6, pp. 6491­6496 Vol.6, Dec 2003.

55

[36] E. Gassiat and R. van Handel, "Consistent order estimation and minimal penalties," IEEE Transactions on Information Theory, vol. 59, pp. 1115­1128, Feb 2013. [37] S. Beheshti and M. A. Dahleh, "A new information-theoretic approach to signal denoising and best basis selection," IEEE Transactions on Signal Processing, vol. 53, pp. 3613­3624, Oct 2005. [38] K. S. Miller, "On the inverse of the sum of matrices," Mathematics Magazine, vol. 54, pp. 67­ 72, Mar. 1981. [39] N. Hasan, S. Khatoon, Ibraheem, Nizamuddin, and Y. Singh, "Automatic generation control problem in interconnected power systems," National Conference on Emerging Trends in Electrical, Instrumentation and Communication Engineering, vol. 3, no. 2, pp. 46­52, 2013. [40] M. Azzam, "Robust automatic generation control," Energy Conversion and Management, vol. 40, pp. 1413­1421, Dec 1998. [41] N. Hasan, Ibraheem, and S. Farooq, "Real time simulation of automatic generation control for interconnected power system," International Journal on Electrical Engineering and Informatics, vol. 4, pp. 40­51, Mar 2012. [42] A. Quazi, "An overview on the time delay estimate in active and passive systems for target localization," IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 29, pp. 527­533, Jun 1981. [43] G. L. Turin, "Introduction to spread-spectrum antimultipath techniques and their application to urban digital radio," Proceedings of the IEEE, vol. 68, pp. 328­353, March 1980. [44] Y. Lu, R. Fowler, W. Tian, and L. Thompson, "Enhancing echo cancellation via estimation of delay," IEEE Transactions on Signal Processing, vol. 53, pp. 4159­4168, Nov 2005.

56

[45] A. K. Nandi, "On the subsample time delay estimation of narrowband ultrasonic echoes," IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control, vol. 42, pp. 993­ 1001, Nov 1995. [46] J. Ianniello, "Time delay estimation via cross-correlation in the presence of large estimation errors," IEEE Transactions on Acoustics, Speech, and Signal Processing, vol. 30, pp. 998­ 1003, Dec 1982.

57

