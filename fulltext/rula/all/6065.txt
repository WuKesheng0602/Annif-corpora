ADAPTIVE REPRESENTATIONS FOR IMPROVING EVOLVABILITY, PARAMETER TUNING, AND PARALLELIZATION OF GENE EXPRESSION PROGRAMMING

by

Nigel P. A. Browne B. Sc. Ryerson University, 2005

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Science in the Program of Computer Science

Toronto, Canada, 2009

© Nigel P. A. Browne 2009

PRO~Cf

RYEROON t;ffiVimtTY UBftARV'

ii

Author's Declaration

I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

Signed:~

I

- - - - - - - - - - - - - - - -___ l

I

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

Signed:-i1-

-

iii

iv

ADAPTIVE REPRESENTATIONS FOR IMPROVING EVOLVABILITY, PARAMETER TUNING, AND PARALLELIZATION OF GENE EXPRESSION PROGRAMMING

Nigel P. A. Browne M. Sc. in Computer Science, 2009 Ryerson University, Toronto, Canada

Abstract
Gene Expression Programming (GEP) is a genetic algorithm that evolves linear chromosomes encoding nonlinear (tree-like) structures. In the original GEP algorithm, the genome size is problem specific and is determined through trial and error.

In this work, a novel method for adaptively tuning the genome size is presented. The approach
introduces new mutation, transposition and recolI)bination operators that enable a population of heterogeneously structured chromosomes, something the original GEP algorithm does not support. This permits crossbreeding between normally incompatible individuals, speciation within a population, increases the evolvability of the representations and enhances parallel GEP. To test our approach an assortment of problems were used, including symbolic regression, classification and parameter optimization. Our experimental results show that our approach provides a solution for the problem of self-adaptively tuning the genome size of GEP's representation.

v

.

vi

Acknowledgements

There are a number of individuals without whom this thesis would not have been possible and I would like to emphatically thank all of them for their assistance and input. First and foremost, I need to thank my thesis supervisor Marcus dos Santos, for being particularly effective at directing my efforts, shaping my ideas, wading through the verbiage that was the early draft of my thesis, and knowing when to use the carrot and when to use the stick. I'd like thank my friends and colleagues Dana Cotant and Greg Smith for their support throughout my master's degree. My good friends (you know who you are) deserve a huge "thank you" for periodically pulling me out of my research bubble, making me laugh and generally reminding me that the world still existed. Mom, Dad and my brother Drew, thanks for being my cheerleaders, occasionally feeding me, and listening to me ramble (incessantly) about my research.

Nigel P. A. Browne Ryerson University September 2009

vii

viii

Dedication

For Mom and Dad, thanks for the genes.

ix

x

Table of Contents
1 Introduction 1
II .. .. ..

1.1 Approach 1.2 Contribution . 1.3 Overview of Thesis

..

..

·. ·..

· ·. ·. · · .
..

Ii

..

..

·

·. ·

·. ·

·

·

·. · · . ·. .

2 3 4
5

2 Background and Related Work

.:.

2.1 Canonical GEP Algorithm · . . . 2.1.1 Chromosome encoding . ·. 2.1.2 Standard Genetic Operators 2.2 Evolvability ·. ·.·. 2.3 Crossbreeding and Speciation. 2.4 Distributed Evolution 2.5 Parameter Tuning and Self-Adaptation . .

·. ·.. · · · ·. ·. . ·· ·. ·. ·.· ·. · ·. ·. ·. · ·.. ·. ·. · ·.. · ·. ·. ·.
· ·

5 7 8
10 11

12 14 17
17

3 Methodology and Implementation

3.1 Proposed GEP Algorithm Enhancements . 3.1.1 Enhancements for Parameter Tuning and Evolvability . 3.1.2 Speciation and Crossbreeding . · . · .. ·.·. 3.2 Syrah Implementation . 3.2.1 Development and Runtime Envir~nments 3.2.2 Parallelization ·. 3.2.3 Population Initialization . · . Experimental Design 3.3 ·. 3.3.1 Symbolic Regression Experiments . · · .. .. .. .. 3.3.2 Classification Experiments . . 3.3.3 Parameter Optimization Experiments . .

·.

· .
~

··. · . · . . ·. · .· . . ·· ·. .. ·. · ·.·..·.·.·

·

· ·.·. ·..·. ·. · ..

·.

17 22
25 25

·· . · · · ·.. · · ·.

26 27 27 28 31 32 37 37 37 43
44

4 Results and Discussions 4.1 Symbolic Regression Results . .. .. .. .. 4.1.1 Discussion of Symbolic Regression Experiments .. .. .. .. .. .. .. .. .. · . .. .. .. .. 4.2 Classification Results 4.2.1 Discussion of Classification Experiments . 4.3 Parameter Optimization Results .. .. .. .. .. .. .. .. .. .. .. 4.3.1 Discussion of Parameter Optimization Experiments . .. . ... .. .. .. .. · . .. .. .. .. .. .. .. .. 4.4 General Discussion

·.

·

· . ·

.

·.. ·.· ·. ··. ·. ·. ·.·. .. .. .. · ·. ·.. ·..
·
"

·.

46 51 52
55

5 Conclusion and Future Work 5.1 Future Work · ·

·. ·..

.. .. .. .. ..

·.·.

· . ..

.. .. ..

57

xi

xii

List of Tables
3.1 3.2 3.3 4.1 4.2 4.3 Common Symbolic Regression Run Parameters . . . Classification Experiment Run Parameters . . . · . . Common Parameter Optimization Run Parameters. . Summary of symbolic regression experimental results · Summary of classification experimental results . . · . Summary of parameter optimization experimental results

29
32 33

37
44 ,46

xiii

xiv

List of Figures
2.1 Flowchart of the canonical Gene Expression Programming algorithm [1]. . . . 2.2 Chromosome with two genes, head size 3, tail size 4. . . . . . . . . . . . . .. 3.1 6
8

Flowchart of the proposed changes to the Gene Expression Programming algorithm. .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. 18 3.2 One-point recombination of two chromosomes. PI and l'2, containing 3 and 2 genes, respectively; hand t denote the head and tail portions of each gene, ) respectively. In Figure (a) the crossover point locates in the head of a gene. In Figure (b) the crossover point locates in the tail of a gene. . 24
4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 4.10 4.11 4.12 4.13 4.14 4.15 4.16 4.17 4.18 4.19 4.20 4.21

Symbolic regression experiment 1: chromosome sizes . . Symbolic regression experiment 2: chromosome sizes. · . . . . · . . · . . .. Symbolic regression experiment 3: chromosome sizes.. . . . . . . . . . . . Symbolic regression experiment 1: chromosome size in the population. . . .. Symbolic regression experiment 2: chromosome size in the population · · · .. Symbolic regression experiment 3: chromosome size in the population . . . .. Symbolic regression experiment 4: chromosome sizes. . . . . . . . . . . . .. Symbolic regression experiment 5: chromosome sizes. · · . . . . . . . · . .· Symbolic regression experiment 5: Target vs Model. . . . . · · . . . . · · .· Symbolic regression experiment 4: chromosome size in the population . LiveDescribe experiment: chromosome sizes . . . . . . . . . . . . . . . . . . LiveDescribe experiment: chromosome sJze in the population. Parameter optimization experiment 1: chromosome sizes Parameter optimization experiment 2: chromosome sizes Parameter optimization experiment 3: chromosome sizes . . . . . . Parameter optimization experiment 4: chromosome sizes . . . · . . Parameter optimization experiment 5: chromosome sizes . . . . . . . . . · Parameter optimization experiment 1: chromosome size in the population Parameter optimization experiment 2: chromosome size in the population Parameter optimization experiment 3: chromosome size in the popUlation Parameter optimization experiment 4: chromosome size in the population 4.22 Parameter optimization experiment 5: chromosome size in the population

38 38 39 39 40 40 41 41 42 42 44 45 46 47 47 48 48 49 49 50 50

51

xv

xvi

Chapter 1 Introduction
Evolutionary computation (EC) is a machine learning technique that uses processes often. inspired by biological mechanisms to obtain a solution to a given problem. Applying an EC algorithm to a problem begins by defining how potential solutions are represented, which is known as the problem representation. A problem representation is defined by the type of input data (the Terminal Set) used to generate a solution, the desired number and types of outputs and the operations (the Function Set) used to transform the inputs into the output values. An important step in applying an EC methodology to a particular problem is the specification of parameters that define the problem representation and control the algorithm. Finding appropriate parameter values that yield satisfactory results usually requires carefully developed heuristics or expert knowledge. In EC algorithms, the conc:pt of a popu!ation of candidate solutions, or individuals, is used to represent a pool of possible solutions to a particular problem.. The encodings, or genomes. used to represent a solution vary depending on the EC methodology. It can be as simple as binary code, or as complex as a fuJI fledged programming language. The Gene Expression Programming (GEP) algorithm [1], developed by Candida Ferreira, is an EC algorithm which uses separate encodings for the genotype and phenotype. This thesis introduces novel enhancements to the Gene Expression Programming (GEP) algorithm that enable flexible genome representations, endow self adaptive characteristics, increases the diversity within a population and enhances the parallelization of the algorithm. The following issues are particularly relevant to the work presented here: 1. Evolva~ility:. the structure of the problem representation does not vary during a run, as it is restricted to the initial values for the head domain length and number of genes. This constrains the algorithm to narrow bands of exploration and reduces its ability to produce

meaningful change or a paradigm shift within a population. 2. Crossbreeding and Speciation: in GEp, genetic operations and transformation are restricted to identically structured genomes, preventing different species, or disparately structured genomes, from evolving and competing within a population. 3. Distributed Evolution: parallelization is restricted by the inability for disparate populations to interact, slowing the exploration of the search space. 4. Parameter Thning and Self Adaptation: the GEP algorithm lacks a self-adaptation mechanism and thus requires additional time and resources to systematically evaluate different . control parameter sets and subjecting the algorithm to operator biases.

1.1 Approach
To address the evolvability of the problem representation, we developed two new operators to permit the structure of the GEP genome to be changed during a run. We call these new operators the Adaptive Chromosome Size (ACS) Mutation operator and the Head Insertion Sequence (IDS) Transposition operator. The problems of sp~iation and genome interactions between disparately structured in~ viduals was solved by replacing the canonical GEP recombination operators with modified versions that permit dissimilarly structured individuals to interact. From the beginning of our explorations we wanted to improve the performance of the GEP algorithm when distributed. We quickly realized that transferring individuals between sepa. I .

..

.

rate GEP populations was severely limited by the inability for structurally different individuals to recombine. This issue was eliminated by the introduction of our modified recombination operators. Finally, to enable parameter ·tuning in the GEP algorithm, we designed our IDS and ACS mutation operators to eliminate the two critical parameters of the GEP algorithm, the head size and the number of genes. Additionally, the HIS and ACS mutation operators were designed to

2

permit the algorithm to self-adaptively tune the optimal chromosome structure. Our proposed methodology was empirically evaluated using an assortment of problem classes and complexity levels. Symbolic regressions evaluated were kinematics proble~ns, a series of polynomial regressions, and the "Sunspot Problem". The classification problem tested was the LiveDescribe dataset from the The Center for Learning Technology at Ryerson Uni-

versity. Finally, the effectiveness of the proposed methodology for optimizing parameters was
evaluated using the De Jong test functions [2]. The effectiveness of the proposed changes were evaluated by comparing the performance of the enhanced GEP algorithm against the original GEP algorithm. Additionally, the symbolic regression results were compared to the adaptive distributed GEP algorithm developed by Park

-

et al.. [3]. The results obtained using an application developed during the course of this thesis,
known as Syrah, and the results were validated using the K-Fold method with 10 folds.

1.2 Contribution
The specific contributions of this work are:

1. Development of the Head Insertion Sequence (HIS) operator to self-adaptively tune the head size parameter in the GEP algorithm and to enable the structure of the individual to evolve during a run. 2. Creation of the Adaptive Chromosome Size (ACS) Mutation operator that self-adaptively tunes the number of genes of an individual in a GEP population. This further allows the genome structure to evolve. 3. Addition of new recombination operators to the GEP algorithm to enable structurally dissimilar genomes to interact. This also enables indi~iduals to be transfered between separate GEP populations ,without any genomic structural constraints. This feature is particularly important to parallel GEP systems, as it permits unrestricted migration."

3
.'

1.3 Overview of Thesis
The material following this introduction is organized as follows: Background material (Chapter 2), Materials and Methods (Chapter 3), presentation and discussion of our results (Chapter 4), and Conclusion and Future Work (Chapter 5). Chapter 2 reviews prior work in evolutionary computation, specifically the GEP algorithm, distributed EC and various methods for parameter tuning. Additionally, we discuss material relevant to the development of our testing methodology and the Syrah system. Chapter 3 introduces our new operators for the GEP algorithm. which solve the problems associated with the existing methods of parameter optimization in GEP. The. new operators . transform GEP populations from a collecticn of homogeneous individuals, with static sizes, to a dynamic population of heterogeneous individuals. This chapter also presents the Syrah
·
~7_'

system, which was developed to test and validate our hypothesis. Chapter 4 presents the results of our experiments, which show that our new GEP operators perform better than previously explored methods. The new operators were tested using a variety of problems, and the performance was compared to other GEP-based methods. Chapter 5 closes the thesis with the concluding remarks regarding the success of the new operators and a discussion of possible future work.

4

Chapter 2 Background and Related Work
This chapter presents the relevant existing research that pertains to the key issues addressed by this thesis, including: the canonical Gene Expression Programming algorithm, the evolvability of the problem representation, genome crossbreeding and speciation, distributed evolution, parameter tuning and self-adaptation.
;.

2.1

Canonical GEP Algorithm

The Gene Expression Programming (GEP) algorithm was first published by Candida Ferreira in
2001 [1]. Like other EC methodologies, GEP derives its inspiration from biological processes

and has been successfully applied to a variety of problems [4-9]. The outline of the canonical GEP algorithm is shown in Figure 2.1. A significant difference in GEP, compared to Genetic Programming (GP) [to] or Genetic Algorithms (GA) [11], is the separation of the phenotype and genotype. Many existing methodologies (such as GP and GAs), use a single representation for both the genotype and the phenotype. By separating the representation, the GEP algorithm is able to benefit from the speed of operating on a linear genotype and the flexibility offered by the tree-based phenotype. It also permits the physical representation to affect the genetic code of the individual. as is found in nature. In the GEP algorithm, each individual or candidate progran:t is referred to as a chromosome. Every chromosome in the population represents a syntactically correct program, because of the underlying nature of the chromosome's encoding and representation.

5

Create C/uomOsomes 01 Initial Population

New Cluomosomes 01 Nex1 a ....""'tion

Figure 2.1: Flowchart of the canonical Gene Expression Programming algorithm [1].
6

2.1.1

Chromosome encoding

In GEP the genome (or chromosome) consists of a linear, symbolic string of one or more genes, each gene coding for an expression tree (ET). A gene consists of two adjacent regions called the

head, containing symbols from both the function and terminal sets, and the tail, which encodes
symbols from the terminal set. The tail only contains leaf nodes of the encoded ET, while the head may contain both leaf and internal nodes. In canonic GEP, both the number of genes and the head size of a gene are input parameters for the algorithm. The tail size t, in GEP, is a function of the head size h, and is determined as follows:

t

= h(nmax-1)+ 1

(2.1)

where nmax denotes the maximum arity found in the function setl. In the case of mUltigenic chromosomes, all ETs are connected by their root node using a

linking function, which is a defined parameter. In the GEP system presented in this work we
used the addition operator as the linking function. Figure 2.2 shows sample chromosome and the respective tree it encodes. The linear genome 1S encoded using Karva notation [1 J and is translated into the expression tree by reading left to right and top to bottom. Using gene 1 in Figure 2.2 as an example, the first symbol (*) is used as the root node of the ET. Since the (*) operator has an arity of two, the next two symbols (a and I) are read from the linear genome and added as child nodes to the root of the ET. Next, since the (a) node is a terminal, it is a leaf node in the ET but the (I) node requires two child nodes (since it has an arity of two). The next two symbols are read from the linear genome (a and b) and added as child nodes to the (I) node. This completes the translation of the linear genome to the expression tree, since all of the leaf nodes consists of symbols from the terminal set. The two symbols remaining in the gene (a and a) are not used for the current translation, but could become active as a result of later changes to the genome. These regions that are not translated are call~ introns. Conversely, the region of the gene that is translated (designated by positions (4) is called the Open Read Frame. The
1Like

in genetic programming, the function set is also a parameter to the GEP algorithm.

7

linking function, used to join the genes during evaluation, is not encoded in the chromosome because it is specified in the algorithm's parameters.

Gene 1
0

Gene 2
5 6
~

1

2
pi",

3

4

0

1
')'(

2

3

4

5

6
..J

(* a / a b ... a a.. )
~

(i'+l \ ../

a b b a b)
d'

head

...

tail

head

...

tail

...

.....-- linking function ET encoded by gene 2

ETencoded by gene 1

0/' 0
2.1.2 Standard Genetic Operators

~

K * 0
®

Figure 2.2: Chromosome with two genes, head size 3, tail size 4.

The standard GEP algorithm implements several different classes of genetic operators, including: selection, mutation, inversion, transposition and recombination. Each operator promotes the exploration of the search space using different methods and have their own application rates. Most genetic operators in GEP are applied in a different manner'than they are' applied in other methodologies, such as Genetic Programming. When an operator is applied to the population, a subset of the population determined by the operator rate (probability of application) is selected. Each individual in this subset then has the operator applied to it. This contrasts to applying the rate individually to each genome, as in genetic programming. The exception to this is the mutation operator, which is applied to each chromosome in the population.

8

The standard GEP mutation operator is the main source of genetic variation in the algorithm. It can function anywhere within the chromosome, using rules depending on where the selected point is located. For example, if the mutation is to occur in the head of a gene, then the mutated value may be any element from the function or terminal sets. However, if the mutation occurs in the tail only terminals may be used. As a result, the modified chromosome will always be syntactically correct. As mentioned earlier, the mutation operator is applied to every chromosome in the population. Since every chromosome undergoes mutation, the mutation rate refers to the number of point mutations in the genome. The inversion operator is used to reverse the order of a section of a genome. Since parts of the genotype may not be translated into the phenotype, inversion allows non-coding regions to become active. There are three methods for mixing the sequence of symbols (or codons) within a chromosome when using the GEP algorithm: Insertion Sequence (IS) Transposition. Root Insertion Sequence (RIS) Transposition and Gene Transposition. This family of operators selects a sequence and relocates it within the chromosome. Th.e IS Transposition operator is permitted to select any sequence within the gene and insert it into any position except the root position of a gene. The RIS Transposition operator operates similarly to the IS Transposition operator, except it always inserts the selected sequence into the root position of the targeted gene. Since it is inserted into the root position, a sequence starting with a function is always selected. Finally, the Gene Transposition operator shuffles an entire gene within the chromosome. The final class of standard genetic operators in the Gene Expression Programming algorithm are the Recombination, or Crossover, operators. The GEP,algorithm supports three different recombination operators, each of which involves two chromosomes and creates two offspring. The One-Point recombination operator selects a single point along the chromosome pair and exchanges the genetic material after that point. The ,two point recombination operators selects two points within the chromosome and exchanges the codons between those points. Finally, the gene recombination operator swaps an entire gene between the two chromosomes.

9

2.2 Evolvability
Evolvability refers to the ability of a genome to change over time and to occasionally produce offspring that are more effective at a particular problem (and thus permit the algorithm to perform an effective search) [12,13]. For evolutionary computation, this becomes significant for representations, such as GEP. that separate the phenotype from the genotype. In the case of this thesis, we focus on the evolvability of the structure and encoding of the genotype. This is particularly important in the case of GEP, since the canonical algorithm uses a fixed genome structure and the structure controlled by two problem-specific parameters. Lopes and Weinert [14] proposed an enhanced GEP algorithm called EGIPSYS that varied the length of the head domain on a genome-level basis. The individuals, however. were composed of a fixed number of equal-length genes. This contrasts with the approach presented here, where each individual may have any number of genes and each gene may have a unique head length. Additionally, EGIPSYS did not implement the one-point recombination operator nor introduce operators to vary a chromosome's length. It also restricted the operation of the gene recombination operator to like-sized individuals. All of these issues are resolved in the method presented here. In an attempt to improve the evolvability of the individuals in GEP. Yue et al. [15] proposed a crossover strategy Valid Crossover Strategy which would crossover all individuals in a population and create the subsequent popUlation from the n-best valid chromosomes. This approach helped the evolution of the solution, but not the evolution of the genome structure itself. Several different strategies for improving the GEP algorithm were presented by Tang et al.
I

in [16]. A feature of interest that they developed was an adaptive mutation mechanism, 'which was essentially a fitness proportional mutation rate. On an individual basis, the mutation rate applied to a chromosome was inversely proportional to its fitness. '!hus, highly fit individuals would have a lower mutation rate applied to them, reducing the number of potentially disruptive changes to chromosome. Conversely, poorly fit individuals were more likely to have significant mutation performed on their chromosomes. The implementation of the Adaptive Chromosome
10

Size Mutation Operator introduced in this work uses the idea of a fitness proportional mutation rate to prefe!entially mutate the number of genes in poorly fit individuals. In this work ~e introduce new operators to improve the evolvability of GEP genomes. The new operators are the HIS transposition and ACS mutation operators, which allow the structure of a GEP genotype to change over time. The evolution of the genotype occurs in parallel to the exploration of the search space for a particular problem. but these two processes are fundamentally linked. These evolutionary processes are interconnected because changes in the genotype can permit the exploration of search space regions that may be inaccessible to other genome structures.

2.3

Crossbreeding and Speciation

The concept of crossbreeding and speciation embraced in this thesis is that of interactions between disparately structured, but fundamentally compatible, genomes. The idea of crossbreeding specifically refers to the ability for any individual, regardless of structure to reproduce and create viable offspring. The ability to crossbreed 'any individual permits a more genetically diverse population and enable unrestricted exploration of the search space by the algorithm. Speciation, on the other hand, can have several different interpretations. In particular, it can refer to the ability for "sub-populations" to exist within a single main population for the purpose of "niching" [17]. Speciation
an~

niching is used to promote diversity within a population,
whe~

prevent (or limit) convergence and to address multi-modal problems

different areas of

the solution space require different individuals [13]. Two methods for using speciation, or niching, are Crowding [2] and Function Sharing [18]. The EGIPSYS algorithm [14] permits different sized chromosomes within a population, which other systems, such as canonical GEP. AdaGep [19] and PGEP-O [3], do not support. All individuals in an EGIPSYS population. however, were required to have the same number of genes. This contrasts with our proposed methodology, which supports (and, in fact, encourages) populations consisting of individuals that have both differing head domain lengths and gene: 11

counts. Park et al. introduced a parallel system, PGEP-O [3], ~hich attempted to dynamically tune specific parameters of the GEP algorithm. In the work, the individuals were constrained by the genome restrictions of canonical GEP, that is, only identically structured individuals were able to interact and exist withing a single population or island. This methodology was limited because the transfer of individuals between islands, or migration, could only occur between islands with identical gene counts and head domain sizes. The methodology presented in this thesis eliminates these constraints by creating new operators that do not restrict the interaction of genomes with fundamentally different structures. The contributions presented in this thesis enable crossbreeding between disparately structured individuals in a GEP population, a feature unavailable in canonical GEP. This enables evolution of different species within a popUlation, and while specifically implementing niching is beyond the scope, of this work, it could be examined in the future.

2.4 Distributed Evolution
The intrinsic parallel nature of Evolutionary Computation (EC) can often be further exploited by distributing a given EC algorithm. Parallelization techniques can generally be classified by their granularity, defined as either fine grained or coarse grain~ models. Fine grained techniques commonly have low computational requirements, but higher communication needs and are well suited for multi-processor systems. Coarse gained models, on the other hand, tend to be computationally intensive but have lower communication requirements and are better
I

suited to discrete computational nodes. The Island Model is a coarse grained technique that was popularized by [20] and has been shown to be fault tolerant [21]. The distributed system implemented to validate our methodology uses the island model. The exchange of genetic material between islands, or demes, is referred to as migration. The structure of the connections between islands, or the topology, is bounded by the cases of isolated islands (no migration) and fully-connected islands (migration to all other demes) [22], 12 .

Our approach used a fully-connected coarse-grained model with random migration and to removed the restrictions placed on the migration mechanism by. canonical GEP's inability to support dissimilarly structured chromosomes in a single population. By permitting unrestrained migration, populations in a parallel setting are now able to freely exchange candidate solutions to enhance the solution quality and diversity.

2.5

Parameter Tuning and Self-Adaptation

Most Evolutionary Computation algorithms require a set of control parameters, which influence the process evolution to be configured based on the particular problem being explored. The process of setting these parameters often require complex heuristics, "rules of thumb" or specific knowledge from a domain expert. Thus. it is desirable to automatically tune the parameter values prior to executing the algorithm or to self-adaptively tune the parameters during the run. In problem solving and optimization, the impossibility theory of "No Free Lunch" [35] has been" postulated and roughly states that without a priori knowledge of a problem (to tailor the methodology to it) no single problem solving method is inherently better for all problem classes [36]. This has implications for any evolutionary algorithm and parameter tuning method. especially those that attempt to optimize the parameters prior to executing an evolutionary run and then use static values throughout the run [37]. Additionally, it has been shown [38] that optimal parameter values can vary throughout a single run. This implies that, while it may be impossible to determine optimal values for all problems and situations, it should be possible to' evolve values that are "good enough". Additionally. it implies that method~logies that are able to optimize their parameter values dynamically have an inherent advantage over those that do not. The PGEP-O system presented in [3] approached the issue of parameter tuning as a separate optimization problem that ran in parallel to the main evolutionary algorithm. This system was a parallel GEP implementation that used the island model to evolve solutions to the target
I

.

14

problem and a Genetic Algorithm (GA) running on a separate client to optimize the two GEP parameters. The head size and gene count parameters were optimized by using trial values on each GEP isla~~ and then reporting back to the GA parameter optimizer. This approach, while successful, suffered from several issues that are remedied by our proposed methodology. The PGEP-Q algorithm required additional resources, since the parameter optimization was a separate calculation. Additionally, the GA optimizer had to wait for an entire run to complete before it was able to execute a new generation, which is problematic for long running evolutions. ' The DM-GEP algorithm [33] introduced a dynamic mutation rate operator in an attempt to guide evolution. DM-GEP divided the execution of a run into three stages, the initial stage, the metaphase stage and the anaphase stage. Each stage was then assigned a specific mutation rate and the mutation rate used in each generation was progressively scaled, by a fixed amount, from one value to the next. In this manner, the number of generations executed in a run was directly related to the mutation rates. This approach did not, strictly speaking, tune the mutation parameter and was not self-adaptive, but did dynamically alter the rate and showed improvement over the standard GEP implementation. Bautu et al. introduced in [19] an algorithm, called AdaGEp, for automatically tuning the number of genes of a GEP representation. The approach involved add~ng to the genome a bit array that maps each bit to a gene in the chromosome. The bit in ea~h position of the array indicates if that gene would be included in the translation to an expression tree during the fitness evaluation. Specific genetic operators were designed to operate on this bit array, thus evolving an optimal mask. The AdaGEP algorithm was limited by the fact that the total number of genes in any chromosome could never change. Thus, there was little benefit to using that method versus using automatically defined functions, or homeotic genes, in GEP's jargon, to evolve the execution order of the genes. Additionally, the size of individuals in the algorithm's population could never change, so that even if fewer genes were required, the genetic operators would still be performed on the full chromosome. The work presented in [15] included a method to vary the mutation and crossover rates during a run, based on the Cloud Model [39]. This methodology improved the performance of 15

the GEP algorithm, but was only applied to like-structured genomes. Eiben et al. stated in their "Parameter Control in Evolutionary Algorithms" survey [37] that determining successful values for algorithm parameters in EC is a "grand challenge" problem. The approach to parameter tuning and self adaptation presented in this thesis was accomplished using multiple techniques which work together to self-adaptively tune GEP parameters. To tune the head domain length and number of genes, we developed the HIS Transposition and ACS mutation operators. In addition to these operators, we created new recombination operators which allowed structurally disparate (and normally incompatible) genomes to be able to crossbreed and create viable offspring, which permits individuals with different head domain length and gene count parameters to compete within a single population.

..<

16

Chapter 3 Methodology and Implementation
This chapter introduces the proposed enhancements to the GEP algorithm to address the issues identified in Chapter 1, to wit: the evolvability of the problem representation, genome speciation and crossbreeding, distributed evolution, and parameter tuning and self-adaptation in the canonical GEP algorithm. The chapter will introduce our proposed enhancemeI).ts, the details of the implementation of the framework used for evaluation, and the experiments used to validate our hypothesis.

3.1

Proposed GEP Algorithm Enhancements

To address the issues of evolvability, crossbreeding~ distributed evolution and parameter tuning found in canonical GEP, our proposed modifications to GEP include several new operators and . also modifications to the existing recombination operators. The new operators introduced in the following section offer solutions to the problems of evolvability and the tuning of two critical parameters in GEP. The modified recombination operators were developed to permit speciation within a GEP population and to enhance distributed GEP populations. The operators are shown, with heavy borders and a grey background, in the context of the GEP algorithm in Figure 3.1.

3.1.1

Enhancements for Parameter Thning and Evolvability

The original version of the GEP algorithm required that two critical parameters, the length of the head domain and the number of genes in the chromosome, be set to fixed values prior to the execution of a run. These parameters are generally domain and problem specific, which further exacerbates the problem of finding "good" values (not even particularly optimal ones) for the

17

.'

Figure 3.1: Flowchart of the proposed changes to the Gene Expression Programming algorithm. 18

parameters. By devel~ping new operators which pennit genome structure changes. we enabled the head domain length and number of genes to be implicitly tuned during a run. Our algorithm enhancements also pennit each gene in a chromosome to have a unique head domain length. This extra feature enables the length of the gene to vary, and thus. the length of the function encoded by that gene. In addition to parameter tuning, our approach improves the evolvability. or the ability of the structure of the genome to evolve, by removing the fixed length chromosome restrictions in canonical GEP and allowing the number of genes to vary during a run. Chromosome evolvability was specifically addressed by designing our new operators to increase the capacity of the genome for extracting and exploiting the underlying structure of the fitness function under consideration.

3.1.1.1 Adaptive Chromosome Size Mutation Operator
In Algorithm 1 we present the pseudo-code for the Adaptive Chromosome Size (ACS) mutation operator used in our enhanced GEP algorithm. The ACS operator mutates the number of genes

in a chromosome. potentially increasing or decreasing the total number of genes when it is
applied. The ACS operator is applied to the entire population during e<1:ch generation. The AcsGeneMutation{... ) method takes a chromosome (chr) as a parameter and mutates it according to the following procedure. Initially, it calculates the decayRate, which is used to decrease the operator's applica~on as the run progresses. In the decayRate calculation the

factor is a user defined value that scales the decayRate and is set to 0.2 for all experiments.
This scales the decayRate to zero for the final 20 percent of the run. Next, the algorithm calculates the probability of mutation muP. The probability of mutation is inversely proportional to the individual's fitness when compared to the best fitness in the current generation. If the muP is less than the user defined minimum mutation rate, minRate. then muP is set equal to minRate. The mutation rate. muP·. is then scaled by decayRate to arrive at the final muP value. The operator then generates a random probability using Rand-

Probability() and compares it to muP to determine if the AcsGeneMutation will be applied to

19

Algorithm 1: ACS Mutation Operator Pseudocode Data: Chromosome Result: Mutated chromosome begin 1* Calculate the decay rate scaleFactor = 0.2 decayRate = 1 - (gen + maxGen * scaleFactor) I maxGen

*1 *1
.~

1* Calculate the mutation rate, inverse to the fitness

muP = (1 - ehr.Ftn I bestFtn) *1 1* Adjust the mutation rate if it is below the minimum if muP less than minRate then I muP = minRate end *1 1* Apply the decay to the mutation rate muP = muP * decayRate *1 1* Determine if mutation will occur if RandProbability() less than or equal to muP then *1 1* Randomly decide to grow or shrink if DoCoinToss() then *1 1* Grow the chromosome by adding a new gene insertionPoint=GetRnd(O, ehr.NGenes) InsertGeneAt(insertionPoint) else 1* Shrink the chromosome by deleting a gene, but only if we *1 have at least two genes if chr.NGene greater than 1 then deletionGene = GetRnd(1, chr.NGenes) DeleteGeneAt(deletionGene) end end end end

, I

20

the chromosome. Next, the operator performs a coin toss using DoCoinTossO to determine if a gene should be added or removed. When a gene is added, the operator selects an insertion point, insertion!.'.oint, at a random position in the sequence of genes of the chromosome. It then calls the worker method,lnsertGeneAt(... }, to insert a randomly created gene at the insertion point. When a gene is removed, the operator first verifies that there is more than one gene (chr.NGenes) in the chromosome. It then randomly selects a gene in the chromosome using the GetRnd(... ) method and calls the DeleteGeneAt(... ) method to remove the gene from the chromosome. The mutation operator always uses a step size equal to one. Thus, it modifies a single gene in the chromosome during each application of the operator. Alternative step sizes were not investigated. but will be examined in future work.

3.1.1.2 HIS Transposition Operator

To dynamically tune the size of a gene. we introduced a new transposition operator called

head insertion sequence transposition, HIS transposition, for short. The transposable elements
(also called transposons) in this case are fragments of the genome, located in the head of a gene, that can be activated and jump to (possibly) another gene head in .the chromosome. '!\vo features make this operator different from the canonic transposition operators used in GEP, to wit: · the transposable element is ~ecessarily located in the head of a gene; and · during transposition. the transposon is cut from the place of origin (instead of copied. like in canonic transposition in GEP). thus shortening the length of the respective gene. and then inserted in the place of destination located necessarily in the head of (possibly) another gene, thus elongating the gene length at the target site. Specifically. the HIS transposition operator works as follows. Initially the operator randomly chooses the chromosome. the start and end sites of the transposon, and the the target site. As mentioned above, these start and end sites are located in the head of a gene. Moreover, 21

transposons contain at most three elements. Next, the operator cuts the transposon from the site of origin, making the necessary arrangements to maintain the structural integrity of the gene. That is, if the transposon locates in the middle of the head of a gene, then the left and right . remaining segments of the head are concatenated, thus forming the new gene head. Next, the operator inserts the transposon at the target site, thus elongating the head of the gene. Notice that the gene heads' at the place of origin and at the target site have now changed, the latter is now longer by say, k elements, and the former is k elements shorter. Finally, using Equation (2.1), the operator adjusts the respective new tail sizes of those genes. If the tail requires extra material, it is cut from the remaining genetic material in the source gene's tail.

3.1.2 Speciation and Crossbreeding
The notion of species is not present in canonic GEP, as all chromosomes have the same structure, i.e., all individuals in a population have the same gene head size, same gene tail size and the same number of genes. The possibility of different species within a single GEP population is highly desirable feature for the parallelization of the algorithm, particularly when using a migration mechanism in a distributed setting. By modifying the existing GEP recombination operators to handle genomes with different structures, our enhanced GEP algorithm now supports crossbreeding and speciation within both a single population and distributed islands.

3.1.2.1 Recombination Operators for Nonunifonn Chromosomes
To support different sized chromosomes created by ACS mutation and HIS transposition oper-

,

.,

ations, we created modified versions for the one point and two points recombination operators used in GEP. These operators also facilitate integrating individuals with differing genome struc-

.

tures (i.e., a differing number of genes and head domain lengths) into a target population during migration, when distributed. Recombination via these operators works as follows: initially the first positions for the head and tail sections of the two parent chromosomes are paired (see Figure 3.2). Then the crossover point (or points, in the case of two points recombination) is 22

randomly chosen from the overlapping sections of the chromosome. The crossover point 10cates either in the head of a gene or in the tail. If it falls in the head, then the genetic material is exchanged (the strands swapped) at the crossover point (see Figure 3.2(a». For this case, there is no need to adjust the structure (tail size) of the gene containing the crossover point. If it locates in the tail of a gene, then we use the following process to exchange the genetic material of the genes where the crossover point is located. First we exchange the genetic material at the point of crossover. Then, we verify the tail sizes of the resulting genes comply with the respective resulting head sizes. If the tail size of a recombined gene is s elements shorter than the allowed size, then we append to it s elements from the tail of the other parent gene, thus making the final tail size of the recombined gene compliant with its head size (notice the strand added to O} in Figure 3.2(b». On the other hand, if the tail size of the recombined gene is

s symbols longer than the allowed size, then we cut its s last symbols out (notice the strand
removed from 02 in Figure 3.2(b».

The rest of genetic material is exchanged as in normal crossover, with a caveat: for the case of GEP-RNC (GEP with real number constants [7]), if the crossover point locates in the tail of a gene, the genetic material in the domain of constants (Dc) is exchanged as normal and the length of the Dc domains are adjusted. If the crossover point falls in the Dc domain, then recombination proceeds via the same procedure used for the tails, as illustrated in Figure 3.2(b). The arrays containing the gene's real number constants are exchanged in their entirety [40].

Analogous to GEP, our recombination operators also produce two children from the parents. When the recombination point falls within the head region, one child having the same length

as one of the parents, and the other child having the same length as the other parent. However,
when the recombination point falls in the tail, the tail regions length of the children may need to be modified (using material from the parent), to satisfy Equation 2.1. 23

PI P2

01

02

-

[I] Q

UJ

-.,....,

!

~bOIS added from PI

[I] Q

UJoa~ . . .
· a :

~

t

·
: .:

,............,

;

~

,

"'-- symbols removed
(b)

Figure 3.2: One-point recombination of two chromosomes. PI and P2. containing 3 and 2 genes. respectively; h and t denote the head and tail portions of each gene. respectively. In Figure (a) the crossover point locates in the head of a gene. In Figure (b) the crossover point locates in the tail of a gene.

24

3.2

Syrah Implementation

In this study, a parallel capable GEP system called Syrah. which dynamically tuncs the number of genes and gene size was developed. To test this system, a suite of non-trivial symbolic regressions was used and the quality of the models was benchmarked against model. obtained via a canonic GEP system and competing methodologies.
Syrah's system requirements differ from GEP-RNC (OEP with real number con~tant' (7])

in regards to the genetic operators it uses, which are detailed in Sections 3.1.1.1, 3.1,1,2, and
3.1.2.1. In Syrah's implementation, tournament selection with elitism was used. Tournamem ~J.ec...

tion involves randomly selecting two individuals from the population. comparing their Ijtne~J values and then adding the more fit individual to the population used for the next ~atioo, When elitism is used, the best individual from each generation is carried OVet w the n.ext ~.. anon. Many GEP implementations use Roulette Wheel seJect.ion, but as loo8 u eliti$ID i~ u:sed, various selection methods will produce equally good resulU [1].
When the Syrah system is operating in parallel. it U~ a coat~ Uainc4 ~ (<< I~

Model [20]) to distribute the populations. Syrah UJeJ the pr~ ,~ opuaton to pm»Jt
dispara1e genome structures to be integrated into a Jiven poputamm durin~ a mi~9n e'¥~

3..2..1 Del'elopment and ltuntime EnvIronments
All ~ of the f~,h IYJtem Syrah wuc WfJtt.eIJ

mat U$fflJ tb.e ~o.1it ~
flaw ~e;an4

~ l'tDJon 3,5 and aeveJ0pe4 U$W, Mla'o§dt \'j.§wa 5w.ow 2fXjS..

~ waf ~JM'1C4 u§inJ Mi&ro.wft MJL Smtl ZOOj ~~ 00 Mi4~ ~
~XP Pm/e.f§/QIIIlI; lMd~ ~§ i1~ fJ,~ fbg MiI;f()wjl ~w~XP Rmfe.~$.~
~§Y~

3.2.2 Parallelization
Different methods and techniques exist for operating an Ee algorithm in parallel. Generally parallel techniques can be divided into two categories, fine grained and coarse grained [24]. Fine grained techniqu~s involve para1lelizing the evaluation of the test cases and usually have more intensive communication requirements. Alternatively. coarse grained techniques distribute populations and have lower communication requirements, but higher computational needs. Our experimental system uses a common coarse grained technique known as the Island Model [20J to distribute populations to discrete computational nodes. The network communication between nodes was implemented using the HTTPvI.I protocol over an SSL connection. The server node is designed to listen for client requests on port 443, the standard port used by SSL web servers. Additionally, the communication between the client and the server is always initiated by the client. This combination of techniques was selected so that the communication would be relatively secure and to facilitate communication between the client and server. when the client was located behind a firewall. This circumvented firewall issues in the original network used for testing. ..

3.2.2.1 The Island Model
The Island Model [20] is a coarse grained method for parallelizing an Ee algorithm that involves distributing a population (or subset of a population) to discrete computation nodes. Each
I

computational node. or client, is responsible for independently executing a full evolutionary run and only reports it's final results to the managing server node.
f

Each node also has the ability to exchange individuals with other islands in the topology. This exchange of genetic material is referred to as migration and helps maintain diversity amongst the islands. The Island Model implemented in Syrah is a fully-connected topology that supports random-random migrations, meaning that a migration event can (randomly) involve any node in the system. Details regarding migration can be found in [22-24,26,27,29,41]. Finally, based on [21], the nodes do not implement any special handling for detecting and

J

26

preventing network topology faults. When a client is unable to complete a run (i.e., because the host w~ restarted, the network failed, etc,), the client is simply starts a new run when it rejoins the Syrah topol~gy.

3.2.3 Population Initialization
With the use of our recombination operators, the population is able to support individuals with different chromosome sizes. To take advantage of this feature, the population is seeded with randomly sized chromosomes. Both the number of genes and the head domain length of each gene are varied during this phase. The number of genes in each individual is randomly selected from between 1 and 10. During the creation of the chromosome, each gene selects a random head domain length between 5 and 15. These values were empirically determined during ini· tial testing and were found to provide good genetic diversity. Additionally, we selected the random initialization method over a "ramped half and half" method [10] as a result of early experimentation. The elements of the head are selected from a weighted bag. If the function set is smaller than that of the terminals, then the probability of selecting a function is 1/2, otherwise they are equally weighted.

-

3.3 Experimental Design
An assortment of problems, of varying types and difficulty, were selected to evaluate the per· formance of our approach. The problems were selected from three areas to which Evolutionary Computation is commonly applied: 1. Symbolic regression, or the automatic synthesis of functions. 2. Classification, or generating boolean results (or labels) from a set of input values. 3. Parameter Optimization. or the automatic discovery of parameter values which produce a maximum andlor minimum for a given function.

27

Each experiment was perfonned using k-fold validation with 10 folds and 30 runs per fold. Each experiment consisted of two sets: a baseline set and an adaptive set. The baseline runs were executed using the standard GEP-RNC algorithm implemented as a part of the Syrah system with parameter tuning disabled. The adaptive runs were then executed in the same manner, but using the methodologies outlined previously. Each experiment was executed using the Syrah framework's parallel mode, which uses the island model to distribute the populations to separate computational nodes. The experiments used 32 islands that were executed on 16 dual-core Intel computers. running the Windows XP Professional operating system. The Syrah system supports migration between the islands, but to facilitate the statistical analysis of the results, these experiments were run without this feature.
,
~

The baseline experiments were perfonned repeatedly using the values presented in Tables
3.1,3.2 and 3.3. During the adaptive evolution runs, the number of genes and the size of the

hend domain were tuned using our new operators. The details of the initial chromosome lengths can be found in Section 3.2.3.

3.3.1 Symbolic Regression Experiments

nlC first three problems selected were the same problems used by H.H. Park et ai.
I

in [3],

These were selected so that the pedonnance of this methodology could be compared t~ an
e;tisting (parallel) GEP-b3sed self-adaptive approach. The fowth experiment was a regression

of a sa\\100th wa\-e. while the fifth experiment was a more difficult time series analysis problem.
'The common a.lgorithm configuration parameters are outlined in Table 3.1 and were shared

amongst all of the e.'<.perimenbl setups. The baseline experiments all produced poor results
for gene counts of 1 through 3, which required 900 (3 x 10. folds x 30 runs per fold) runs to
'!\~te.

28

Table 3.1: Common Symbolic Regression Run Parameters Selection Method Elitist Tournament Parameter Value Number of Generations 100 Population Size 50 Initial Head Size 5-15 Initial Number of Genes 1-10 One point recombination rate 0.5 Two point recombination rate 0.1 Gene recombination rate 0.1 Mutation rate 0.07 Minimum ACS Mutation Rate 0.05 IS transposition rate 0.1 RIS transposition rate 0.1 0.1 HIS transposition rate Gene transposition rate 0.1 +, ., * ,I Function set Linking function + 10 folds K-Fold Validation 31 Evolutionary Clients (Syrah)

3.3.1.1 Experiment 1
The first problem evaluated was a kinematics symbolic regression that modeled the movement of a vertically fired object. The kinematic equation for the position of the object at time t is defined by the following equation:

(3.1)

IT we use an initial velocity, Vo = 25m/s, an initial position of So

= 0, and assume the

acceleration is equal to earth's gravity. a = -9.8m/sZ, then we can simplify the equation as:

S(/)

-9.81% 1 =25t+--r=251-4.91

(3.2)

For this experiment, fifty data points were sampled from the interVal t = 0.1 to t =5 and
used as the test cases.

29

.'

3.3.1.2 Experiment 2
Our second experiment extended the first, using two independent variables instead of one. Modifying equation 3.1 with the same assumptions as in experiment one, but with an independent initial velocity, gives:

5(t) = vt -4.912

(3.3)

The test cases for this experiment were generated using Vo values of 20.25 and 30. The values of t were the same as in the first experiment.

3.3.1.3 Experiment 3
The third symbolic regression experiment used a fourth order polynomial that was used in [3] and similar to the ones used in [1,7].

y = -2.5x4 +4.&3 +3x2+2x+ 1

(3.4)

The algorithm attempted to evolve the function from 10 equally spaced samples taken from values of the Polynomial (3.4), in the interval x = [1,10].

3.3.1.4 Experiment 4: Sawtooth Wave
The fourth experiment was a regression of a sawtooth wave, which has been used as a benchmark in other works [42]. The function is defined by:

F(x) =

to

(}sin(iX») :n= 1, ... ,9

(3.5)

The dataset consisted of 250 equally spaced data points in the range x = [-8,8]. This range was selected instead of the 40 points in [-: 1, 1J used in [42] after discovering that the algorithm required a more challenging set of inputs.

30

3.3.1.5 Experiment 5: Wolfer Sunspot Time Series Prediction
The final experiment attempted to create a predictive model using 100 observations from the well known Wolfer Sunspot Series [43]. The data was formatted for time series analysis, using a delay time of I and an embedding dimension of 10. This dataset has also been used to evaluate other GEP systems, including [7] and [14].

3.3.2 Classification Experiments
Classification is a common and important task that evolutionary computation algorithms are applied to. The classification experiment performed in this work used a large. real world classification problem from the from the The Center for Learning Technology (CLT) at Ryerson

University.
The evaluation of the classification experiments was accomplished using the "Hits with Penalty" method, as described in [7]. Table 3.2 lists the algorithm configuration value,S that were used for the classification experiments.

3.3.2.1 The LiveDescribe Dataset
The LiveDescribe project [44] is a software application developed by the Center for Learn-

ing Technology (CLT) at Ryerson University to add video descriptions (for the deaf) to video
content. The project had originally used a manual process to select regions of dialog verses nondialog in video content, so that descriptive video captions could be programmatically added to the non-dialog sections. Since the process of selecting the non-dialog regions was a manual and user intensive process, the CLT modified their application using a human designed classifier system. This system was, on average. 70% effective. , The dataset 'consists of six real value inputs and a single boolean output per tuple. Part of what makes this dataset a challenge is it's size. The initial dataset consisted of approximately 90,000 tuples. The input variables are the audio metries RMS standard deviation, RMS average.

31

Table 3.2: Classification Experiment Run Parameters Selection Method Parameter Number of Generations Population Size Initial Head Size Initial Number of Genes One point recombination rate Two point recombination rate Gene recombination rate Mutation rate Minimum ACS Mutation Rate IS transposition rate RIS transposition rate HIS transposition rate Gene transposition rate Function set Linking function K-Fold Validation Evolutionary Clients (Syrah) Elitist Tournament Value

175 75 5-15 1-10 0.5
0.1

0.1
0.07 0.05

0.1 0.1 0.1
0.1

+. -. * .1. sqrt. exp, sin, cos, tan, fioor, ceiling, OR. AND, <, >. ~, 2!. =, != +
10 folds 31

a measure of audio entropy, zero crossing above to below, zero crossing left skew and a zero crossing low energy measurement. These inputs were sampled once for every 1 second of audio.

3.3.3 Parameter Optimization Experiments
The five parameter optimization test functions were selected from the the well known De Jong test functions [2]. These test functions were originally selected by De Jong to test the effectiveness of a given EC algorithm over a broad class of problems. While attempts have been made to
I

improve the test set, it remains the de facto standard for parameter optimization validation. The five functions are presented here in their original form. but were modified (where necessary) to change them all to maximization functions, which allows for simpler evaluation with the GEP algorithm. Table 3.3 lists the algorithm configuration values that were shared amongst all of the parameter optimization experiments. 32

Table 3.3: Common Parameter Optimization Run Parameters Selection Method Parameter Number of Generations Population Size Initial Head Size Initial Number of Genes One point recombination rate Two point recombination rate Gene recombination rate Mutation rate Minimum ACS Mutation Rate IS transposition rate RIS transposition rate HIS transposition rate Gene transposition rate Function set Linking function K-Fold Validation Evolutionary Clients (Syrah) Elitist Tournament Value 100 50 1-15 1-10 0.5 0.1 0.1 0.07 0.05 0.1 0.1 0.1 0.1 +, -, * ,I + 10 folds 31

~

3.3.3.1 De Jong Fl: Sphere Model
The first function in the De Jong test set is a three diritensional parabola that is convex, unimodal and continuous. The function has a maximum of 78.6 at (XI,X2,X3)
3

= (±5.12,±5.12,±5.12).

!(XI,X2,X3) =

Exl :-5.125 x 5 5.12
i=1

(3.6)

3.3.3.2 De Jong F2: Rosenbrock's Function
The second function in the De Jong test set was first proposed by Rosenbrock [45] and is commonly referenced in optimization literature. This function is non-convex, unimodal and continuous, with a maximum of 3905.93 at (XI,X2) = (-2.048, -2.048).

I(x) = 100 x (xt-X2)2+(1-Xl)2: -:-2.048 5~ 5 2.~8
33

(3.7)

3.3.3.3 De Jong F3: Step Function

The third De Jong test function is a five dimension step function that is discontinuous, nonconvex, unimodal and piece-wise constant. De Jong originally selected this function to test the ability for algorithms to handle discontinuities [2]. This function is restricted to -5.12 =:; x =:;

5.12 for testing. This function has a known maximum of 25 when the inputs are held at 5.12.
5

I(x)

= EXi: -5.12 =:; x =:; 5.12
i=1

(3.8)

3.3.3.4 De Jong F4: Quadratic Function with Noise

The fourth test function in the De Jong colh:~ction is a noisy, quadratic function that is continuous, unimodal. convex and has a high dimensionality. The function uses a Gaussian function to add noise. The function was limited to -1.28 =:; x =:; 1.28. This experiment used alternative val- ' ues for the number of generations and the population size than the other parameter optimization experiments. This experiment had 350 generations ~d 500 individuals in the popUlation. The maximum of this function is approximately 1248.2 and occurs when all inputs are equal to ±1.28.

f(x)

= Ei xx1 + Gauss (0, 1): -1.28 =:; x =:;1.28
;=1

30

(3.9)

3.3.3.5 De Jong F5: Shekel's Foxholes

This is a two dimension function that is continuous. non-quadratic and non-convex. with 25 local maximums. It was originally suggested by Shekel [46]. This version [47] of the function has maximum of approximately 499.002.

34

f(x,y) = 500
where

0.002+ Lj=o 1/ [1 +i + (x- a(i»6 + (y - b(i»6]

24

1

(3.10)

a(i) = 16 x (i mod 5 -2)
b( i) = 16 x

(3.11) (3.12)

(l~J -

2)

- 65.523 S x S 65.523

35

36

Chapter 4 Results and Discussions
'This chapter presents the results of the experiments outlined in Chapter 3 that were used to val· , idate our enhancements to the GEP algorithm and that address the issues identified in Chapter
1.

4.1 Symbolic Regression Results
Table 4.1 shows a summary of the experiment results, including the best individual's fitness and chromosome size t · The best fitness is expressed as a percentage of the number of fitness cases solved. The visualized results and perfonnance of the experiments are shown by Figures 4.1-4.10.

4.1.1 Discussion of Symbolic Regression Experiments .
There are two figures for each of the first four experiments perfonned. The first figure of each pair shows the minimum, maximum and average chromosome lengths in the population
1Note that the size of a chromosome (i.e., the length of the chromosome string) depends on its number of genes and the head size of each gene.

Exper. Number
11 21 31 42 52

Table 4.1: Summary of symlb0 rIe regressIOn ex penmental resu ts Comparison Ours Length Fitness Fitness Length 99.496% 266 99.984% 254 99.907 % 282 99.983% 87 96.187 % 470 99.735 % 155 99.966% 185 99.987 % 62 98.936% 186 99.179 % 55

1: Compared to PGEP-O 2: Compared to canonical distributed OEP

37

50000 500 450 400 350
;.l~
I

_ - - - - - - -Min Size- · - -, - - Max Size Avg . Size Best Fitness - - - - -

49950

~9900

(~))

i\

·ftl

h.,

49850
<1'1
<II

300
OJ N

OJ

.-E 49800 u49750

U)

250 200 150 100 50

rn OJ

CD

49700

Generations

Figure 4.1 : Symbolic regressio n experiment 1: chromosome sizes

150000 450
\'

400 350 300 250
ci)
N

Min . Size Max. Size Avg . Size Best Fitness

n "

149950

I

\

~.l~'

149900

I
OJ

~

149850

~

E

OJ

200 150 100 · 50 149700 100 149800

ill

en OJ

149750

10

20

30

40

60 50 Generations

70

80

90

Figure 4.2: Symbolic regression experiment 2: chromosome sizes

38

500 450 400 350 300
Min. Size Max. Size Avg . Size Best Fitness

10000

80110

1;
/~~
,\.t'o;

6000

4000
Ji
<lJ N

<JI <JI

250 200 150 100 50 1000

u::
<JI

5

<lJ

m

<lJ

Generations

Figure 4.3: Symbolic regression experiment 3: chromosome sizes

29

15

18

1l1li

Figure 4.4: Symbolic regression experiment I: chromosome size in the population

39

29

l'
59
45 40

19

35

38
2' 29 15 18

'It

188

Figure 4.5: Symbolic regression experiment 2: chromosome size in the population

29

15 35 38 19

25
29

l'
18

188

Figure 4.6: Symbolic regr ssion xperiment : chrom som size in the population

40

450 400

T- r -

'"
350 300

Min S I7 Max Size A V~ Size: 13 SI lIn as :

-.-

12fi!l!lO

')')n910

1250 0

12595 250
N

II>

en
200 150 100
50
,-.

-- .

27,,940

u..
~

P

Jj
12 ... 930
<·

-22597

n5910

20

30

40

50
Generation

60

70

775WO

130

90

100

Figure 4.7: Symbolic regression experiment 4: ch

0

~ .-----~----~----,_----,_--~,_----_r----_r----_,

t;4,

450

400

Igu

4.: Sy I1bolic egre il)1

41

160 140 120 100

Target -e-Model

a n

<f)

80 60 40 20 0 -20 I 0

e: :::,
(f)

<I,

':; ~
,>
.

, t
~

~

,

~

10

20

30

40
Time

50

60

70

80

90

figure 4.9: Symbolic regression experiment 5: Target vs Model

199

69 198
88 68 48 20 60

40

20

"0

1118

Figure 4. 10: Symbolic regression experiment 4: chromosome size in the population

42

for each generation. The other figures display a surface visualization of the distribution of the chromosome lengths in the population, with respect to the generation number in the run. For the final experiment, the surface plot was omitted because of the rapid convergence to a narrow range of chromosome lengths. Figure 4.9 compares the evolved model's performance to the target data. Since k-fold validation was used, every tenth data point in Figure 4.9 was previously unseen by the model. The figures show that while the algorithm was optimizing the chromosome length, it initially explored a wide search space, then focused on a band of neighboring chromosome sizes. A significant result was that the best solutions found using our new operators, evolved better individuals with smaller representations than the PGEP-O system presented in [3] and the canonical GEP algorithm. It is interesting to note that the best chromosomes evolved for the two most difficult problems were significantly smaller than those evolved by the PGEP-O. Specifically, during the second and third experiments, the best evolved individuals were approximately 30% to 33% of the size of the individuals evolved using the PGEP-O methodology. Similarly,

in experiments four and five, where our methodology was compared to a distributed canoncial
GEP algorithm (based on Syrah), our methodology produced results 33% and 30% the size of the alternative's results. The results of the experiments, as shown in Table 4.1, show that our new operators are significantly more efficient and produced better results for symbolic regression problems. This may have been because our populations were evolving smaller solutions and were able to explore the search space more effectively.

4.2

Classification Results

Table 4.2 shows the results of the classification experiments. These include the chromosome size and the best fitness found, expressed as a percentage of the number of fitness (or test) cases solved. The visualized results and performance of the experiments are shown by Figures 4.11-4.12. 43

Total Len. 247

Table 4 .2: Summary of classification experimental resul ts Ours Canonical GEP Genes Avg Gene Len . Fitness Total Len. Genes Gene Len. 8 30.9 81.08 % 770 10 77
950

Fitness 80.31 %

450

.----r----.----,----,----.----,----,--~~~--r-~I

400 350

Min. Size " Max Size <· · Avg Size - - .,.: Best Fitness - - . . -

940

930

250
rJi
N

IlJ

920 200 150 910

'" IlJ .s u::
III

1;;
IlJ

aJ

900

30

40

50
Generations

60

70

80

90

890 100

Figure 4.11: LiveDescribe experiment: chromosome sizes

4.2.1

Discussion of Classification Experiments

As stated in chapter 3, the full LiveDescribe data set consisted of approximately 90,000 entries, each with 6 real number variables and grouped into two classes. One of the challenges of this experimenl was the computational resources required to evolve candidate solutions. Both our methodology and canonical GEP evolved individuals with similar performance, with both systems evolving a classifier capable of successfully identifying 80%-81 % of the fitness cases. This is a substantial improvement over the original, human written classifier (developed by the CLT at Ryerson [44]), which was able to correctly classify approximately 70% of the fitnes s cases. Based on discussions with the CLT lab, it is believed that 85% may be the practical limit for identifying non-dialog sections of video using the current variable 44

30 25
#

35 30 25 20 15 10 5

20 15 10

8

0

Figure 4. 12: LiveDescribe experiment: chromosome size in the population

set. The CLT is currently working to modify their data aquisition software to colkct additional parameters. Examining the solutions evolved by our enhanced algorithm and canonical GEP, it is important to !lote that our methodology evolved a solution 32.1 % the size of the one evolved by the standard algorithm. Since the size of the candidate solution's genome has a direct impact on the evaluation of the fitness cases (and live data, once implemented in the real world), the reduction in representation size may improve the overall performance of the system, even after considering the additional computation requirements of our new operators . The small number of classes in this experiment may have been a possible limitation. With only two possible classes, the evolutionary process may not have been significantly challenged. However, it is felt that the number of test cases may have offset thi s. In the future, more complex classification problems should be investigated. What the summary of results do not show is the number of additional runs (and thus processing time) requir~d to evaluate different values for the head domain length and number of

45

genes for the canonical GEP algorithm that was used for comparison.

4.3 Parameter Optimization Results
Table 4.3 shows a summary of the results of parameter optimization experiments. The summary shows the maximum function value found, the average gene length (static for canonical GEP) and the total genome size. The visualized results and performance of the experiments are shown by Figures 4.13-4.22. Table 4.3: Summary of parameter optimization experimental results Ours Canonical GEP Total Len. Avg. Gene Len. Maximum Total Len. Gene Len. Maximum 105 78.30 35 231 78.51 77 10 5 3904.62 184 3902.40 92 25 5 25 385 25 77 426 14.2 1233.87 1125.61 780 26 22 11 94 499.002 : 499.002 47

Exper. Number 1 2 3 4 5

200r----r----r----r--~----~--~----r_--_r----r_--~

80

75 70

65
(I) (I)

II)

60

u..

,

tl <l)
/XI

55 50 45

o ~--~--~~~~--~---L--~~--~---L--~~~ 40 o 10 20 30 40 50 60 70 80 90 100
Generations

Figure 4.13: Parameter optimization experiment 1: chromosome sizes

46

4000

3500

70

3000

2500

III Q)

'"

u:
2000
ell

.E
Q)

1;;

1500 30 20 1000

10

20

30

40

50
Generations

60

70

80

90

500 100

Figure 4.14: Parameter optimization experiment 2: chromosome sizes

250

r----r----.----.----,----,--~~--~----~----r_--

,., .....
200

Min. Size -'j..~ ·.··. , 'Max: Size' ~'.-.c;.,..-' Avg. Size .,.".t..__ Best Fitness ,. - ··

__

26

24 22 20

150 18 16 100 14 12 50

j

i

u:

°OL----~10----~20----~3-0--~4-0--~5-0--~6~0--~7~0--~8LO----9LO--~10:
Generations

Figure 4.15: Parameter optimization experiment 3: chromosome sizes

47

iOOO
800 800

r-------.------,-------,--- ---~------.--M in -.S izre------,

1400

Max. Size Avg. Size
_ · .h

.,_8~.s.tfl~.·.-··

-., -

1200

1000 700 800
Ui
N
<II
<II

GJ

.s u:::
iii

GJ

600

co

<lJ

400

200

100 L-____- L______

~

_____ L_ _ _ _ _ _

~

_ _ _ __ L_ _ _ __ _ L __ _ _ _~.

o

50

100

150

200

250

300

0 350

Generations

Figure 4.16: Parameter optimization experiment 4: chromosome sizes

500
,''f.VJ.OH..

V
499
J,~

90
I

80 70

498

497 60
.~
<II <II

GJ

496 50

Cf)

.s u:::
en GJ
<D

GJ

.1\1
40 30

495

\
\
494

20

" n;

: \ :.J,l, !
.
'1.1"

,

r.U

l

«rHn rIUJ1HRl..T

493

10 [¥t ~

I~~ __~____L __ _~~_ _~_ _ _ __ L_ _ _ _L__ _~~_ _~_ _ _ __ L_ _ _ _~ 492
10 20 30 40 50 60 70 80 90 100

:I

o

Generations

Figure 4.17: Parameter optimization experiment 5: chromosome sizes

48

#

50 45 40 35 30 25 20 15 10

40 35 30 25 20 15 10 5
0

" 8

100

Figure 4.18: Parameter optimization experiment 1: chromosome size ;n the population

50
#

40 30 10
10

40 35 30 25 20
15 10 5 0

8
00

100

Figure 4.19: Parameter optimization experiment 2: chromosome size in the population

49

i uO
80 100 80 60 40 20 40 20 0 60

8

.:~50

100

Figure 4.20: Parameter optimization experiment 3: chromosume size in the population

70

60 90
50

»

BO
70 60 50 40 30
20

40

30
20

10

10

o
50

825

75
100

125 150 175 200
225

Generati on s

250 275 300

Size

325

350

Figure 4.21: Parameter optimization experiment 4: chromosome size in the population

50

30 25 ')0
p

50 '; 0 30
~O

20 15 10 5 0

10

8

100

Figure 4 -22: Parameter optimization experiment 5: chromosome size in the population

4.3.1

Discussion of Parameter Optimization Experiments

The results of the parameter optimization experiments show that both our methodology and canonical GEP are effective at evolving either optimal or near-optimal sclutions to the problems in the De long test suite. As seen in the previous series of experiments, our enhancements enabled the algorithm to consistently evolve solutions those evolved by canonical GEP. The solutions evolved by our enhanced algorithm in experiments two and three were remarkably smaller than those found by canonical GEP. Spec ifi cally, they were 5.4% and 5.5 7(1 the size of those found by standard GEP. Both methodol og ies had difficultly with the high-dimension problem found in parameter optimization experiment 4. However, our enhanced GEP algorithm evolved a slightly better result and had a representation size 54.6% the size of the one evolved by the standard algorithm. It is believed that the difficultly of this problem and the inability of the algorithm to locate the optimal parameter values contributed to the evolved size of the genome. Similarly, the 51
WhI Ch

were significantly smaller than

numerical results of experiment 1 were comparable, but the solutions evolved using the HIS operator and our other enhancements were 45.5% the size of standard GEP's solutions. The chromosome sizes evolved during final parameter optimization experiment were closer to what we had observed during the Symbolic Regression and Classification experiments, with our evolved solutions being approximately 23.4% the size of those evolved by canonical GEP. In this case, both methodologies successfully found the maximum value of Shekel's fox-holes. All of the parameter optimization experiments have shown that our enhancements retained GEP's problem solving ability while allowing it to evolve smaller genomes. While the De Jong functions have been reported [48] to not be an effective test set, they have been repeatedly shown to provide a good metric of the effectiveness of algorithms for a broad range of optimization problems. A possible limitation is that it is not currently possible to use the ACS mutation operator with our existing experimental setup. Since we have not used Automatically Defined Functions (ADFs) [1], we must use a fixed number of genes - one per parameter requiring optimization. While we were still able to obtain good results, we can only speculate that using ADFs and allowing the number of "normal" genes to evolve (as they do in the symbolic regression and classification experiments), would enhance the solutions of more difficult parameter optimization problems.

4.4

General Discussion

Reviewing the results of our experiments, we see that our enhancements to the GEP algorithm consistently produced smaller solutions (sometimes significantly so) than canonical GEP. Since the represent~tion size of a genome has a direct impact on the evaluation of the fitness cases, the reduction in representation size may improve the overall performance of the system, even after considering the additional computation requirements of our new operators. This was indirectly observed during the classification experiments while waiting for the two methodologies to complete their evolutionary runs. When our enhanced algorithm was running, it was notice52

ably faster than when the standard GEP algorithm was processing the same problem. The tuning of the number of genes and the head size of each gene was an implicit part of our GEP run and, thus, we did not require separate clients for optimization. This reduced the overall computational resources required to evolve solutions. For all of the parameter optimization experiments the ACS mutation operator was disabled and thus, we were unable to evaluate its potential effectiveness for this class of problems. The operator was disabled because of the evaluation method used. Since our GEP implementation did not use ADFs, it required one gene per parameter to optimize. It is possible that if we implemented automatically defined functions and used the ACS mutation operator to evolve the number of "normal" genes, we would see different results. The decision to randomly initialize the genes that were inserted during the ACS mutation phase appears successful. However, it would be interesting to investigate the use of gene cloning, or other methods, in the future. We observed that the insertion point in the ACS mutation operator for classification and symbolic regression problems was not important because we used a commutative linking function during testing. The insertion point, however, may have been significant because of the way the gene would mix within the population during recombination. Additionally, since the Gene Transposition operator was used, good genes could be reordered within the chromosome. Had we used a non-commutative linking function or homeotic (ADF) genes, the insertion location could have had a greater impact. Based on the results of our experiments, our new operators were able to successfully selfadaptively tune the two critical parameters of the GEP algorithm, the head domain length and the number of genes. While our new operators have additional computational costs associated with them, it is believed that the additional operator execution times are offset by the shorter time required to evaluate the fitness functions, because of the smaller representations it evolved. Our new recombination operators have also been empirically shown to permit crossbreeding and speciation within a single GEP population. Additionally, our operators have been shown to be effective in a distributed environment. However, additional research into the effects of our

53

3 ""

operators on migration is required.

54

Chapter 5 Conclusion and Fllture Work
This thesis presented novel enhancements to the Gene Expression Programming algorithm that enabled flexible genome representations, endowed self-adaptive characteristics, assisted with maintaining diversity within a population and enhanced the parallelization of the algorithm. In particular, the enhancements addressed issues of evolvability, crossbreeding and speciation, parameter tuning and parallelization in canonical GEP. Through a series of experiments that used an assortment of problem classes, including symbolic regression, classification and parameter optimization, we have shown that our proposed methodology produced better results and, generally, smaller genome representations than the canonical GEP algorithm and the PGEP-O system [3] (for symbolic regression). Specifically. the contributions presented in this work were:

1. Creation of a new transposition operator, the Head Insertion Sequence (HIS), which selfadaptively tunes the head domain length of a gene. 2. Development of a new mutation operator, the Adaptive Chromosome Size (ACS) mutation, which mutates the number of genes in an individual to tune the gene count parameter. 3. Addition of new GEP recombination operators to permit structurally dissimilar individuals to interact. This removed the structural constraints imposed when transferring an individual from one population to another and permitted both crossbreeding and speciation. Our enhancements to the GEP algorithm also simplified its use, by implicitly tuning the head domain length and number of genes throughout an evolutionary run. By removing the

55

need to set these two critical GEP parameters prior to executing a run, the level of "expert knowledge" required to use GEP is reduced and allows EC novices to use the algorithm more effectively. The simplification of the algorithm's configuration and the implicit parameter tuning of the two critical parameters are still subject to the concept of "No Free Lunch" [35]. The "No Free Lunch" theorem [35] states that without a priori knowledge of a problem, all potential solution methods are equal. While the values of the parameters evolved during a run may not be optimal for all problem types, they are frequently "good enough" and "No Free Lunch" is partially offset by the ease of using the new algorithm. This was seen during our experimental verification of the algorithm and when comparing our methodology to canonical GEP. To detenrune the GEP experimental baselines, several runs with different head domain length and number of gene parameter values were required, to obtain usable results. Comparatively, with our enhanced algorithm we only needed to start a run sequence and let the algorithm evolve the parameters. While our enhancements to the GEP algorithm have proven to be successful, they are not without costs and limitations. Since we have added extra operators to enable our meta-evolution of the parameters, we also have added additional computational overhead. In particular. the ACS mutation operator has significant overhead when it generates a new gene from random elements. The overhead associated with the new operators may be partially offset by the reduced size of the solution representations (as experienced during our trials), but further experimentation and analysis are required to confirm this. Another side effect of our self-adaptive method is that we have increased the search space available to the algorithm. This is both a benefit and a liability, since the algorithm can traverse the entire space defined by any combination of head domain length and number of genes. This allows the algorithm to find novel solutions, but also increases the number of potential solutions dramatically, possibly increasing the search time and allowing the algorithm to get stuck in at a non-optimal solution. When developing the enhancements to the GEP algorithm, the possibly of introducing bloat, or the excessive creation of introns to protect a genome's functionality, was a major concern.

56

By eliminating the fixed chromosome size (which was necessary to remedy the issues we saw with GEP), the potential for the genome representation and size to grow unchecked became a possibility, even with the parameter tuning inherent in the new operators. One possible reason for not observing bloat is because the HIS Transposition operator, which is responsible for tuning the head size, restructures the genome by adding sections from one domain to another instead of simply inserting or deleting material. This does not account for the effect of the ACS mutation operator, which mutates the number of genes in a chromosome. However, the selection pressure from the Tournament Selection with Elitism selection method may have provided resistance to unnecessary gene additions. It is possible that in more difficult problems (that require longer runs or larger datasets), we may begin to observe bloat and need to take steps to measure and constrain it. Related to the previous topic of bloat and introns, is the matter of genetic diversity within a population. OUf current research did not include any specific mechanisms to measure the diversity of individuals within a population (either in a single population or distributed multipopulation setting), but the genome length statistics, recorded during the experiments, can be used as a simple metric. Using the surface plots of the chromosome lengths (found in chapter 4) we can suppose that our methodology maintains a level of genetic diversity throughout a run. While the populations were initially very diverse and chaotic, as the runs progressed the outliers were reduced and a narrower band of chromosome sizes (and thus diversity) was maintained. Overall, our enhancements have been shown to be effective at addressing the issues of evolvability, crossbreeding and speciation, parameter tuning and parallelization in the canonical GEP algorithm.

5.1

Future Work

Though our enhancements have been effective, there is still work that can be done to further our understanding of them, their relationship and application to Evolutionary Computation in general, and the workings of the GEP algorithm itself.

57

A detailed study of the effects of our enhancements on the levels of genetic diversity in a population would aid in understanding the mechanisms that make the operators effective. Additionally, applying the "Nonsynonymous to Synonymous Substitution Ratio (Ka/Ks)" [49) to study the rate of evolution, in conjunction with a diversity study, could show where further improvements could be made in the GEP algorithm. Applying our enhancements to Automatically Defined Functions (ADFs) in GEP could potentially provide interesting results and bears further investigation. This could be particularly useful for difficult or complex parameter optimization problems, since, when using GEP-PO, the number of genes must always equal the number of parameters being optimized. Using ADFs would allow the number of normal genes to be adaptively tuned using the ACS mutation operator. Further research into the potential of unrestrained chromosome growth, or bloat, and selection pressure in our enhanced GEP algorithm would be interesting, as we did not observe significant bloat during our experiments. In evolutionary computation, any algorithm or representation that allows unrestrained growth and yet demonstrates resistance to bloat warrants further investigation. The impact of our operators on migration and the exchange of genetic material in a distributed setting requires further study. In particular, a thorough examination our system when running in a distributed, multi-island settings with different connection topologies and migration strategies would be useful for determining the optimal configuration (if possible). While the enhancements presented in this work enabled crossbreeding and the evolution of different species within a population, we did not specifically implement any niching methods. This could prove to be an interesting avenue of exploration in the future, as it could enhance the algorithm'~ performance with multi-modal problems. Finally, adapting our enhancements to neuroevolution, or the evolution of neural networks, using GEP (such as the GEP-nets algorithm [7)) has great potential. This is because our enhancements could permit size and structure changes to the evolved neural networks. allowing a more dynamic and complicated structure to be evolved.

58

Bibliography
[1] C. Ferreira, "Gene expression programming: A new adaptive algorithm for solving problems," Complex Systems, vol. 13, no. 2, pp. 87-129, 2001. [2] K. A. De Jong, "Analysis of the behavior of a class of genetic adaptive

systems," Ph.D. dissertation, University of Michigan, 1975. [Online]. Available: http://hdl.handle.netl2027.42/4507 [3] H.-H. Park, A. Grings, M. dos Santos, and A. Soares, "Parallel hybrid evolutionary computation: Automatic tuning of parameters for parallel gene expression programming,"

Appl Math Comput (New York), 2008.
[4] K. Zhang, S. Sun, and H. Si, "Prediction of retention times for a large set of pesticides based on improved gene expression programming," in GECCO '08: Proceedings of the

10th annual conference on Genetic and evolutionary computation. New York, NY, USA:
ACM, 2008, pp. 1725-1726. [5] Z. Xie, X. Li, B. Di Eugenio, P. C. Nelson, W. Xiao, and T. M. Tirpak, "Using gene expression programming to construct sentence ranking functions for text summarization," in COLING '04: Proceedings of the 20th international conference on Computational

Linguistics.
1381.

Morristown, NJ, USA: Association for Computational Linguistics, 2004, p.

[6] J. Venter and A. Hardy, "Generating plants with gene expression programming," in AFRI-

GRAPH '07: Proceedings of the 5th international conference on Computer graphics, virtual reality, visualisation and interaction in Africa.
pp. 159-167. [7] C. Ferreira, Gene Expression Programming - Mathematical Modeling by an Artificial New York, NY, USA: ACM, 2007,

Intelligence, 2nd ed.

Springer-Verlag, 2006. 59

[8] M. Ostaszewski, P. Bouvry, and F. Seredynski, "Multiobjective classification with mogep: an application in the network traffic domain," in GECCO '09: Proceedings of the 11th

Annual conference on Genetic and evolutionary computation.
ACM, 2009, pp. 635-642.

New York, NY, USA:

[9] J. Yin. L. Huo, L. Guo, and J. Hu, "Short-term load forecasting based on improved gene
expression programming," in Intelligent Control and Automation, 2008. WCICA 2008.

7th World Congress on, June 2008, pp. 5647-5650.

[10] 1. Koza, Genetic Programming: On the Programming of Computers by Means of Natural
Selection.
The MIT Press, 1992.

[11] D. E. Goldberg, Genetic Algorithms in Search. Optimization, and Machine Learning.
Addison-Wesley Professional, 1989.

[12] J. Reisinger, K. O. Stanley, and R. Miikkulainen, "Towards an empirical measure of evolvability," in GECCO '05: Proceedings of the 2005 workshops on Genetic and evolutionary

computation.

New York, NY, USA: ACM, 2005, pp. 257-264.

[13] K. O. Stanley, "Efficient evolution of neural networks through complexification," Ph.D. dissertation, The University of Texas at Austin, August 2004.

[14] W. R. W. Heitor S. Lopes, "Egipsys: An enhanced gene expression programming approach for symbolic regression problems," Int. J. Appl. Math. Comput. Sci, vol. 14, no. 3, pp. 375-384, 2004. [15] J. Yue, T. Chang-jie, Z. Hai-chun, L. Chuan, C. Yu, W. Jiang, and W. Dong-lei, "Adaptive gene expression programming algorithm based on cloud model," in BioMedical Engineer-

ing and Informatics. 2008. BME12008. International Conference on, vol. 1, May 2008,
pp. 226-230. [16] C. Tang, L. Duan, J. Peng, H. Zhang, and Y. Zong, "The strategies to improve performance of function mining by gene expression programming: Genetic modifying, overlapped 60

gene, backtracking and adaptive mutation." in Proceedings of the 17th Data Engineering
Workshop, 2006.

[17] O. M. Shir and T. Back,Algorithmic Bioprocesses. Springer Berlin Heidelberg, 2009, ch. Niching Methods: Speciation Theory Applied for Multi-modal Function Optimization, pp. 705-729. [Online]. Available: http://dx.doi.org/lO.1007/978-3-540-88869-735 [18] J. H. Holland, Adaptation in natural and artificial systems. an introductory analysis with
applications to biology, control and artificial intelligence. University of Michigan Press,

1975. [19] E. Bautu, A. Bautu, and H. Luchian, "Adagep - an adaptive gene expression programming algorithm," Symbolic and Numeric Algorithms for Scientific Computing, 2007. SYNASC.
International Symposium on, pp. 403-406, Sept. 2007.

[20] M. Gorges-Schleuter, "Explicit parallelism of genetic algorithms through population structures," Parallel Problem Solving from Nature, pp. 150-159, 1991. [Online]. Available: http://dx.doLorgll 0.10071BFb0029746 [21] 1. Hidalgo, F. De Vega, 1. Lanchares, and D. Lombrana, "Is the island model fault tolerant?" in 9th Annual Genetic and Evolutionary Computation Conference, GECCO 2007, London, 2007. [22] E. Cantu-Paz and D. Goldberg, "Efficient parallel genetic algorithms: Theory and practice," Comput. Methods Appl. Mech. Eng., vol. 186, no. 2-4, pp. 221-238, 2000. [23] J. Berntsson and M. Tang, "Dynamic optimization of migration topology in internet-based distributed genetic algorithms," in GECCO 2005 - Genetic and Evolutionary Computation
Conference, B. H.G., O. U.M., A. D., B. W., B. C., B. E.W., C.-P. E., D. D., D. K., and

et aI, Eds., Washington, D.C., 2005, pp. 1579-1580. [24] E. Cantu-Paz, Efficient and Accurate Parallel Genetic Algorithms. 61 Springer, 2000.

[25] E. Alba and 1. Troya, "Analyzing synchronous and asynchronous parallel distributed genetic algorithms," Future Gener Comput Syst, vol. 17, no. 4, pp. 451-465, 2001. [26] Z. Skolicki and K. De long, "The influence of migration sizes and intervals on island models," in Proceedings of the Genetic and Evolutionary Computation Conference, 2005. [27] Z. Skolicki and K. De long, "The importance of a two level perspective for island model design," in Proceedings of the IEEE Congress on Evolutionary Computation, 2008. [28] S.-K. Oh, C. T. Kim, and 1.-1. Lee, "Balancing the selection pressures and migration schemes in parallel genetic algorithms for planning multiple paths," in Robotics and Au-

tornation, 2001. Proceedings 2001 ICRA.IEEE International Conference on, vol. 4, 2001,
pp. 3314-3319 vol.4. [29] S.-C. Lin, I. Punch, W.E, and E. Goodman, "Coarse-grain parallel genetic algorithms: categorization and new approach," in Parallel and Distributed Processing, 1994. Pro-

ceedings. Sixth IEEE Symposium on, Oct 1994, pp. 28-37.
[30] E. Alba and l. Troya, "Influence of the migration policy in parallel distributed gas with structured and panmictic popUlations," ApplIntell, vol. 12, no. 3, pp. 163-181,2000. [31] Y. Lin, H. Peng, and J. Wei, "A niching gene expression programming algorithm based on parallel model," in Lecture Notes in Computer Science, vol. 4847 LNCS, Guangzhou, 2007, pp. 261-270. [32] J. Wu, C. Tang, T. Li, S. Qiao, Y. Jiang, and S. Ye, "Parallel multi-objective gene exf

pression programming based on area penalty," in International Conference on Computer

Science and Information Technology, 29 2008-Sept. 2 2008, pp. 264-268.
[33] Q. Liu, T. Li, C. Tang, Q. Liu, C. Li, and S. Qiao, "Multi-population parallel genetic algorithm for economic statistical information mining based on gene expression programming," in Natural Computation, 2007. ICNC 2007. Third International Conference on, vol. 3, Aug. 2007, pp. 461-465. 62

[34] X. Du, L. Ding, and L. Jia, "Asynchronous distributed parallel gene expression programming based on estimation of distribution algorithm," in Natural Computation, 200B.ICNC
'OB. Fourth International Conference on, vol. 1, Oct. 2008. pp. 433-437.

[35] D. Wolpert and W. Macready, "No free lunch theorems for optimization;' IEEE Trans
Evol Comput, vol. I, no. I, pp. 67-82,1997.

[36] Y. Ho and D. Pepyne, "Simple explanation of the no-free-Iunch theorem and its implications," J. Optim. Theory Appl., vol. 115, no. 3, pp. 549-570, 2002. [37] A. Eiben, Z. Michalewicz, M. Schoenauer, and J. Smith, "Parameter control in evolutionary algorithms," Stud. Comput.Intell., vol. 54, pp. 19-46,2007. [38] T. Bck, "Self-adaptation in genetic algorithms," in Proceedings of the First European
Conference on Artificial Life.

MIT Press, 1992, pp. 263-271.

[39] M. H.-j. LI De-yi and S. Xue-mei, "Membership clouds and membership cloud generators," Journal of Computer Research and Development, pp. 15-20., 1995. [40] C. Ferreira, "Questions and answers from personal correspondence," September 2009. [Online]. Available: http://www.gene-expression-programming.com!Q&A03 .asp [41] J. Branke, A. Kamper, and H. Schmeck, "Distribution of evolutionary algorithms in heterogeneous networks," Lecr. Notes Comput. Sci., vol. 3102, pp. 923-934, 2004. [42] R. McKay, H. X. Nguyen, J. R. Cheney, M. Kim, N. Mori, and T. H. Hoang, "Estimating the distribution and propagation of genetic programming building blocks through tree compression," in Proceedings ofGECCO 2009, Sigevo. [43] T. W. Anderson, The statistical analysis of time series. ACM,2009. Wiley New York" 1971.

[44] Livedescribe video description software. The Center for Learning Technology at Ryerson University. [Online]. Available: http://www.livedescribe.com! 63

[451 II. Rosenbrock. "An automatic method for finding the greatest or least value of a function."

Compo J., vol. 3, pp. 175-184 .· 1960.
[461 J. Shekel, "Test functions for multi modal search techniques," in Fifth Annual Princeton

Conference olllnfonllatioll Science and Systems., 1971.
[471 J. Alami, A. E. Imrani. and A. Bouroumi, "A muItipopulation cultural algorithm using fuzzy clustering," Applied Soft Computing, vol. 7, no. 2, pp. 506 - 519, 2007. [On1 ine 1. Available: http://www.sciencedirect.comlscience/articleIB6W86-4MJCI VF- 21 213c9b90ea39aab93a935d8151Id0614c2 [48] D. Whitley, K. Mathias, S. Rana, and 1. Dzubera. "Building better test functions," Proc.

Sixth ITttemational Conference Oil Genetic Algorithms, vol. -, pp. 239-246, 1995.
[49] T. Hu and W. Banzhaf, "Nonsynonymous to synonymous substitution ratio kalks: Measurement for rate of evolution in evolutionary computation," Lecture Notes in Computer

Science, pp. 448-457, 2008.

64

