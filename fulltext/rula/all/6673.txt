HUMAN VISUAL SYSTEM INSPIRED SALIENCY GUIDED EDGE PRESERVING TONE-MAPPING FOR HIGH DYNAMIC RANGE IMAGING

By Nipu Rani Barai Master of Science, Electrical and Electronic Engineering, 2013 Bachelor of Science, Electrical and Electronic Engineering, 2014 American International University-Bangladesh.

A Thesis Presented to Ryerson University in Partial Fulfillment of the Requirements for the Degree of Master of Applied Science in the program of Electrical and Computer Engineering

Toronto, Ontario, Canada, 2017 © (Nipu Rani Barai) 2017

Author's Declaration
I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my thesis may be made electronically available to the public.

ii

ABSTRACT
Human Visual System Inspired Saliency Guided Edge Preserving Tone-Mapping for High Dynamic Range Imaging Master of Applied Science, 2017 Nipu Rani Barai Electrical and Computer Engineering, Ryerson University

With the growing popularity of High Dynamic Range Imaging (HDRI), the necessity for advanced tone-mapping techniques has greatly increased. In this thesis, I propose a novel saliency guided edge-preserving tone-mapping method that uses saliency region information of an HDR image as input to a guided filter for base and detail image layer separation. Both high resolution and low resolution saliency maps were used for the performance evaluation of the proposed method. After detail layer enhancement and base layer compression with constant weights, a new edge preserved tone-mapped image was composed by adding the layers back together with saturation and exposure adjustments. The filter operation is faster due to the use of the guided filter, which has O(N) time operation with N number of pixels. Both objective and subjective quality assessment results demonstrated that the proposed method has higher edge and naturalness preserving capability, which is homologous to the Human Visual System (HVS), as compared to other state-of-the-art tone-mapping approaches.

iii

ACKNOWLEDGEMENTS
I would like to thank my supervisors Dr. Dimitrios Androutsos and Dr. Matthew Kyan for giving me the opportunity to pursue my graduate studies at the Department of Electrical and Computer Engineering at Ryerson University. I am greatly indebted to both of them for their continuous encouragement, support and guidance given during the course of my thesis research project. It is a great honour for me to work under their supervision. I thank my parents and sisters for their encouragement in pursuing my graduate studies. The consistent encouragement and support of my elder sister Gouri Barai and my brother-in-law Dr. Pulin Mondal throughout my study are greatly acknowledged. I also want to thank my colleagues, friends and everyone who helped me with their time and patience in the subjective study survey of my thesis. Finally, I thank God for giving me the strength to complete this work.

iv

"To me, photography is an art of observation. It's about finding something interesting in an ordinary place. I've found it has little to do with the things you see and everything to do with the way you see them." -- Elliott Erwitt

v

TABLE OF CONTENTS
Title Page Author's Declaration Page Abstract Acknowledgements Table of Contents List of Tables List of Figures Nomenclature 1 Introduction 1.1 1.2 1.3 Introduction Saliency in an Image and Application in HDR Tone-mapping Motivation and Objectives of the Thesis 1.3.1 Motivation 1.3.2 Objectives 1.4 Thesis Organization i ii iii iv vi ix x xiii 1 1 2 3 3 4 4 6 6 6 7 8 8 8 9 10 13 17

2 Supporting Methods 2.1 2.2 Introduction Human Visual System 2.2.1 Human Eye 2.2.2 Reflectivity and luminance 2.2.3 Psychophysics 2.3 2.4 Saliency Saliency Detection Methods used in the Proposed Method 2.4.1 Methods for Low­resolution Saliency Map 2.4.2 Methods for High­resolution Saliency Map 2.4.2.1 Wavelet Decomposition
vi

2.5

Tone-mapping 2.5.1 Tone-mapping using Bilateral Filtering 2.5.2 Photographic Tone-reproduction 2.5.3 Gradient based Tone-mapping 2.5.4 Display Adaptive Tone-mapping

18 20 21 22 24 24 28 28 30 34 35 35 36 39 41 43 43 43 43 45 48 52 52 55 59 59 63

2.6 2.7

Other Tone-mapping (TM) approaches Filters used in HDR Tone-mapping 2.7.1 Bilateral Filter 2.7.2 Guided Filter and Its Applications

2.8

Chapter Summary

3 Model Development 3.1 3.2 3.3 3.5 Introduction Method Description Tone Reproduction Algorithm Chapter Summary

4 Results and Analyses 4.1 4.2 Introduction Saliency Maps of HDR Images using Different Methods 4.2.1 Low - Resolution Maps of HDR Images 4.2.2 High - Resolution Maps of HDR Image 4.3 4.4 Proposed Tone-mapping Algorithm using Saliency Map as Guidance Objective Quality Assessment 4.4.1 Structural Similarity Index Matrix (SSIM) Results 4.4.2 Feature Similarity Index Matrix (FSIM) Results 4.4.3 Edge Strength Based Similarity Index Matrix (ESSIM) Results 4.5 Subjective Quality Assessment 4.5.1 Results for Images Viewed on Various Screens
vii

4.6

Chapter Summary

64 65 65 65 65 65 66 67 68 69

5 Conclusions and Recommendations 5.1 5.2 General Chapter-wise Summary 5.2.1 Chapter 2: Literature Review 5.2.2 Chapter 3: Method Development 5.2.3 Chapter 4: Results and Analyses 5.3 5.4 Contributions: Key Findings and Important Discovery Recommendations for Future Work

References

viii

LIST OF TABLES
4.1 4.2 4.3 4.4 4.5 4.6 4.7 The SSIM scores for the resultant images in Figure. 4.9 using 5 different saliency maps in the proposed tone-mapping algorithm. FSIM for the proposed and other three state-of-the-art tone-mapping methods for RIT MCSL database. FSIM for proposed and other three state of the art tone-mapping methods for EMPA 57 database. FSIM for the proposed and other three state-of-the-art tone-mapping methods for 58 Debevec's database. Percentage of highest FSIM scores for the tested images. Percentage of highest ESSIM scores for the tested images. The names of the methods for the images shown in Figure 4.12. 58 59 63 56 54

ix

LIST OF FIGURES
2.1 2.2 2.3 Raw images at three different exposures ((a), (b), and (c)) in Cannon CR2 Format, and 6 tone -mapped HDR image for regular display. Elements in human eye. though each bar in the Mach Bands is uniformly gray (actual), HVS enhances the luminance changes (perceived); (b) Simultaneous contrast effect showing that the perceived brightness depends on the contrast with the local background. 2.4 2.5 2.6 2.7 2.8 2.9 2.10 2.11 2.12 2.13 Itti's approach for saliency detection. saliency map obtained by CS saliency detection method. (a) Original image of flower, (b) the low-resolution saliency map obtained by SR saliency 12 detection method. The overview of the frequency tuned (FT) method. Here, I is the mean image, 14  (, ) is the Gaussian blur of the image and ( , ) is the saliency map. saliency map obtained by FT saliency detection method. (a) Original image of flower, (b) the high-resolution saliency map obtained by RCS 15 saliency detection method. (a) Original image of flower, (b) the high-resolution saliency map obtained by HDHVS 16 saliency detection method. Block diagram of the HDHVS algorithm. (further decomposed), vertical (LH1), horizontal (HL1), and diagonal (HH1) detail image. (a) An original HDR image of a hotel room (EXR format), and the resultant tone-mapped 19 HDR image using (b) Ashikmin's, (c)Drago's, (d) Durand's, (e) Reinhard's, (f) Tumblin's and (g) Mantiul's tone-mapping operators. 2.14 2.15 The steps for tone-mapping using Bilateral filtering. Mapping from scene zones to print zone. 21 22 17 Simple representation of wavelet decomposition in an image resulting in approximate 18 (a) An original image of a red flower and several blue flowers, (b) the high-resolution 14 10 (a) An original image of a red flower and several blue flowers, (b) the low-resolution 11 7 Difference between actual and perceived contrast: (a) Mach effect showing that even 9

x

2.16 2.17 2.18 2.19 2.20

(a) to (e) are five photographs with exposure increasing from (1/1000) to (1/4) of a 23 second, (f) Tone mapped image using the gradient based tone-mapping algorithm. Process flow diagram of the display adaptive tone-mapping method. Process flow diagram of the adaptive post processing contrast enhancement. (a) Input signal, (b) bilateral filtered output. filter. The signals from the left to right showing base and input (base on red and input on black) signal together, detail signal and enhanced detail signal. The bilateral filter introduced gradient reversal effect after enhancing. 24 27 29

1D illustration for detail enhancement: (a) using bilateral filter and (b) using guided 30

2.21

(a) A simple 2-D representation of the structure-transferring operation of the guided 32 filter. (b) Shows the guided filtering operation in details (3-D). Here, I is the guidance image, p is the input image and q is the filtered output. The output  = a + b and   . a and b are co-efficient of the linear transform and n is the noise.

2.22 3.1 4.1 4.2 4.3

Smoothing an image using both guided filter and bilateral filter. The bilateral filter 33 introduced gradient reversal and halo artifact. Flowchart showing the proposed SGTMO method. saliency maps obtained by using the SR method (middle) and the CS method (right). High resolution saliency gradient maps using: (a) HDHVS method, (b) FT method, and 46 (c) RCS method. The Original HDR images are shown in Figure 4.1 (a). An Original HDR image with a magnified section (shown in a), and saliency maps 47 obtained by three methods: (b) (b) HDHVS method, (c) FT method and (d) RCS method. The magnified sections of the saliency maps show the differences in details in the saliency maps obtained by three high resolution saliency detection methods. 35 Two original HDR images (left, top and bottom) and corresponding low resolution 44

4.4 4.5 4.6

The workflow of the proposed tone-mapping method showing the transformation of 49 an HDR image at different stages. (a) The detailed layer without using the saliency map as guidance in the guided filter 50 and (b) the detailed layer using the saliency map as guidance in the guided filter. Effects of different radius of window of mean filter in the guided filter. Radius, r = 0.2 51 was found to be producing the best result.

xi

4.7

Effects of saturation (sat) in the tone mapped images. Saturation parameter value of 52 0.5 was proven to be the best option with respect to maintaining the natural look of the image and preserving the edges.

4.8 4.9

Comparison of highest SSIM score percentages for five different saliency methods in 53 the proposed TM algorithm for all images of EMPA database. Tone-mapped images of five HRD images using five different saliency methods in the 54 proposed TM algorithm ((a) HDHVS, (b) FT, (c) RCS, (d) SR and (e) CS method, respectively).

4.10 4.11

20 images selected for subjective study using 5 different TMO's including the proposed 60 method. The method names were not mentioned to the viewers for unbiased results. Subjective study results showing average scores of 58 observers for the five methods. 64 Lower score represents better results as the viewer labeled the best image with 1 and worst with 5.

xii

NOMENCLATURE
HDRI LDR TM GF HVS HDHVS FT CS SR RCS WT SSIM FSIM ESSIM High Dynamic Range Imaging Low Dynamic Range Tone-Mapping Guided Filter Human Visual System High Definition Human Visual Saliency Detection Frequency Tuned Center-surround Spectral-residual Random center-surround Wavelet Transform Structural Similarity Index Matrix Feature Similarity Index Matrix Edge Strength Similarity Matrix

xiii

Chapter 1 INTRODUCTION
1.1 Introduction An image close to the real-world scene has always been a desired characteristic of photography from the very beginning of its invention. High contrast in illuminance in a scene makes the photography a challenge in reproduction of the scene into an image. Different exposure durations can produce images of a scene highlighting different features in each image. To address this challenge, during the earlier period of photography the idea of taking multiple images of a scene with different exposure time was introduced. In 1850, Gustave Le Gray, a French photographer, took two different exposed images of a scene to produce an equally illuminated seascape that showed both the sea and the sky in an image clearly [1]. This event is considered as the root idea of the modern-day's High Dynamic Range (HDR) Imaging, though the term HDR has been introduced very recently in advanced digital photography. The term dynamic range means how precisely the pixels in an image can mimic the real scene [2]. With higher dynamic range a pixel in an image has higher number of options for contrast value to represent a point in the scene. Consequently, the images that have high dynamic range for its pixels, are named as HDR images. Single exposed images captured by regular camera are limited to lower dynamic ranges as these cameras use a low dynamic range (LDR) image detector. This detector typically provides 256 levels of brightness data at each pixel that results in image with lower range [3]. An HDR image is generally formed by merging several single exposed LDR images of a same scene with different exposure in each case. Each LDR image contains information of the same scene under different fixed exposures. The combination of all the information of various LDR images results in an HDR image with a higher range of contrast. As a real scene can have wide range of brightness variations, an HDR image of that scene can provide higher range of variations and bringing it closer to the real scene dynamic range. With the advancement in digital photography in recent decades, High Dynamic Range Imaging (HDRI) has drawn significant research attention and become popular after the year 1990 [1].

1

Since an HDR image of a scene contains lots of information, the imaging requires a significant amount of data processing and implementation of various algorithms. The following steps summarize the entire process of HDR imaging: Step 1 - Acquisition of the HDR image: It is done using several LDR images of a same scene having different exposures, and an algorithm to combine the images into one image [4-7]. Step 2 - Compression of the HDR image: The process of compression is known as tone-mapping. This is the most critical step towards HDRI. Tone-mapping can make the image very similar to the real scene after compressing unnecessary data. Furthermore, it contains limited necessary information that allows it to be displayable in the regular display devices. This thesis focuses on developing a novel tone-mapping approach. Step 3 - Post processing of the image: This step results in noise or artifact removal. Various artifact removal methods have been developed to date by different researchers [8-14]. Depending on the applications or requirements Step 2 and Step 3 can be interchanged. The next section of this chapter (Section 1.2) presents a brief description of saliency usage in tone-mapping to provide the readers a background that leads to the motivation and objective of this thesis. Chapter 2 presents in details the subject matters that were used in the proposed method of this thesis. 1.2 Saliency in an Image and Its Application in HDR Tone-mapping

Salient regions in an image are the regions that draw human visual attention more. Saliency map exhibits the salient regions of an image. It is an arranged topographical map that represents the visual saliency of a scene. A topographically oriented map with salient locations is established by computing the position of the local maxima of this map by winner-take-all mechanism [15]. Low level saliency map is based on contrast, such as, color, orientation, size or motion, and depth. High level saliency map is based on context such as people. A saliency method can result in either high resolution or low resolution maps. Most of the saliency detection methods are limited to Lower Dynamic Range (LDR) images. Though the use of saliency in the HDRI is very limited, it can

2

be used for tone-mapping in HDRI in many ways to compress the HDR image keeping it visually attractive. Some of the techniques on using saliency in HDRI are briefly described below: · Mei et al. [16] developed a saliency modulated HDR tone-mapping technique. They introduced a saliency based operator for tone-mapping. The resultant images used subjective user input for comparison with several other method results. · · Patel et. al [17] provided a review on tone-mapping operators and how they can be used in HDR images. However, the review was missing elaborate explanation of the methods. Li et al. [18] proposed an approach of using saliency map for tone-mapping. They used a guided filter to decompose the HDR image, and compressed it using a saliency based weight. However, this study did not provide a detail discussion and analysis on the saliency map used in the method; and only mentioned about the histogram based approach to get the weight. Nevertheless, their study forms a basis for the proposed method in this thesis.

In this thesis, both high-resolution and low-resolution HDR saliency maps were studied for tonemapping purpose. This thesis presents the necessary discussion on different types of saliency maps, and analyses on how these can be modified and used for HDRI in a simpler manner. In addition, a guided filter was proposed to be used to separate a detail layer and a base layer from an HDR image so that the proposed algorithm would be free of complex iterative calculation due to O(N) time operation of the guided filter [19]. 1.3 Motivation and Objectives of the Thesis

1.3.1 Motivation In the areas of photography and imaging, from the very first pin hole camera to the hand-held cameras, and digital cameras to Digital Single Lens Reflex (DSLR) cameras it has been a prime objective of capturing a moment as real as possible. With the advancement in the areas of image detection sensor technology and computation, the HDR research has received significant research attention. However, at present we thrive for making the HDRI process flawless and more advanced. Simultaneously, we desire for making the procedures less complex. A study of the
3

current state of the HDRI indicates that we need a better tone-mapping process that will result visually more attractive tone-mapped images. The review on the use of saliency in tone-mapping shows that this area is not very enriched and there are opportunities for improvement, such as preserving the edges of salient regions keeping the natural look of the HDR image, and making the processes and computation simpler. These opportunities have motivated this thesis work on saliency in HDR tone-mapping. As HDRI is an active area of research, a significant amount of works has been conducted that need to be further progressed. These studies also provide the basis for this thesis. 1.3.2 Objectives The main objective of this thesis is to develop a new tone-mapping technique for HDR imaging using saliency region information of the original HDR radiance map to obtain visually attractive tone-mapped image with enhanced edge information. The specific objectives are to: a) Conduct a detailed literature survey on saliency detection methods and tone-mapping techniques of HDR imaging identifying the research gaps and the way of improving and modifying them for HDR images b) Develop an algorithm that uses information from saliency map for tone-mapping of HDR images, and enhances the edge information or details of salient objects and compresses the less variant area information c) Perform an objective quality assessment study giving priority to the edge strength and compare the results with the results of four other state-of-the-art methods, and d) Conduct a subjective quality assessment focusing on the HVS, and compare the results with the results of four other state-of-the-art methods. 1.4 Thesis Organization This thesis is comprised of five chapters. The contents of these chapters are briefly described below: 1) Introduction - The ideas that lead to this thesis are discussed in this chapter along with the objectives of the work.
4

2) Supporting Methods - This chapter discusses in details all the saliency detection methods, filters, and tone-mapping (TM) methods that were used in this thesis work. 3) Method Development - This chapter includes the proposed TM algorithm with the detail development. In addition, the modified saliency detection methods used in the proposed TM method are also included. 4) Results and Analyses - This chapter presents the step by step transformation of an HDR image to a tone-mapped image following the proposed algorithm. It also includes the objective and subjective quality assessment results and comparison with the results of four other state-of-the-art methods. Related discussions are presented and conclusions are drawn based on the results. 5) Conclusions and Recommendations - This chapter summarizes the key findings and observations of this research. In addition, it states the recommendations for future work.

5

Chapter 2 SUPPORTING METHODS
2.1 Introduction In the proposed tone-mapping method of this thesis, it has been proposed to use saliency region information to tone-map HDR image preserving the edge details. In this chapter, the related background information starting from the Human Visual System (HVS) to saliency detection and tone-mapping methods supporting the experiments along with existing other works on tonemapping are explained in details.
(a) (b) (c) (d)

Figure 2.1: Raw images at three different exposures ((a), (b), and (c)) in Cannon CR2 Format, and tone mapped HDR image for regular display.

2.2 Human Visual System The proposed method is an HVS inspired method as saliency has been used for the tone-mapping. Therefore, it is important to understand an HVS and its importance in imaging. The relationship between visual importance and visual saliency is strong [3, 20]. Salient areas of an image denote the areas that draw attention to the human eyes at first. Therefore, saliency is significantly related to HVS. In order to understand saliency and its application in tone-mapping for image processing, it is important to understand the HVS. Generally, there is a large difference between the image we display and the image we perceive. HVS can perform a number of image processing tasks in a very superior manner than we are presently able to perform with computers. In the area of image processing, the goal is to mimic how human brains can solve complex image

6

processing problems in a blink of eyes. The following paragraphs in this section (Section 2.2) present various concepts related to the actual image and the perception and function of HVS. 2.2.1 Human Eye HVS consists of two functional parts: the eye and the brain. The eye functions as the biological equivalent of a camera and the brain performs all of the complex image processing. When a light ray hits the eye, it passes through the cornea, and subsequently the aqueous humor, the iris, the lens, vitreous humor and the retina (Figure 2.2). The cornea acts like a lens and it can vary its shape to focus the image on to the retina. Two types of photoreceptors in the retina, the rods (120 million cells) and the cones (6 million cells), convert the light rays into electric signals. Under a dark state, only the rods are active. It is called night vision or scotopic. Under daylight or bright state, the cones are most active. It is called day vision or photopic. Under dimly light state, there exists an intermediate stage, where both rods and cones are active known as the mesopic vision. Three types of cones sensitive to different band of electromagnetic spectrum, distinguish the colors [21]. Rods are sensitive towards luminance information and acts logarithmically. Thus, intensity contains more information of a scene than color.

Figure 2.2: Elements in human eye. (adopted from Myers [21]). 7

2.2.2 Reflectivity and Luminance When a light ray of wavelength  and energy  () is emitted from a source, the light  reflected  (  ) = ()() (2.1)

from an object can be written as,

where, () is the reflectivity of that object. If an object reflects only lights with wavelength of about 650 nm, it is a "red" colored object. Similarly, other color objects reflect light of corresponding wavelengths. The luminance  of an object can be expressed using the following  = 0  () ()


equation (2.2):

(2.2)

detects light of certain wavelength. 2.2.3 Psychophysics

where, () is the luminous efficiency function of a HVS. It states how well a visual system

In visualization, the detection of a spot depends more on the difference in the luminance of a spot and its background than the luminance of the spot itself. The higher the background luminance, the higher the contrast needs to be before the difference can be detected. Weber's law [22] explains this phenomenon. In addition, the Mach effect and the simultaneous contrast effect influence the perceived brightness [22]. Figure 2.3 explains the above stated effects. 2.3 Saliency Saliency region of an image is the region that is outstanding or that grabs attention naturally when someone looks at it. For example, a red flower in a green garden will grab attention first when someone looks at it. A saliency map is an arranged topographical map that shows the visual saliency of the real scene [23]. This map is used as an input to convert selective attention. Saliency detection methods can be divided into two different categories: (1) bottom up approach and (2) top down approach.

8

(a)

(b)

Figure 2.3: Difference between actual and perceived contrast: (a) Mach effect showing that even though each bar in the Mach Bands is uniformly gray (actual), HVS enhances the luminance changes (perceived); (b) Simultaneous contrast effect showing that the perceived brightness depends on the contrast with the local background. (adopted from Yund et al. [24]).

In bottom up saliency, the regions that grab attention naturally are detected. Whereas, in topdown approach the specific regions are intentionally looked for. Biologically inspired method, frequency tuned method, multi-scale contrast, depth of field, spectral residual methods, global contrast based methods are several bottom up approaches [23, 25]. Context aware method is a top-down approach [26]. In the proposed study (this thesis) a bottom up saliency method was used as the target to preserve more of the regions that HVS finds attractive naturally. Therefore, more focus is given in describing the bottom up saliency detection methods that were applied in the proposed algorithm. 2.4 Saliency Detection Methods used in the Proposed Method Among the saliency detection methods applied, spectral-residual (SR) and center-surround (CS) methods provided low-resolution saliency maps, and frequency-tuned (FT), random centersurround (RCS), and high definition human visual saliency (HDHVS) methods provided highresolution maps. The algorithms of these methods for TM operation are described in this section. The methods were modified for HDR images; whereas, the original methods were proposed for LDR images.
9

2.4.1 Methods for Low­resolution Saliency Map Center-surround (CS) saliency detection method: Itti et al. [15] developed one of the prominent bottom up saliency based visual attention methods. It was a biologically inspired method, where multiple image-features on different scales were combined into a single saliency map. A dynamical neural network then selected attending locations in order of decreasing saliency. Figure 2.4 presents the process flow diagram of Itti's saliency detection method [15]. Figure 2.5 shows the saliency map of an image obtained by using the CS method. Various other saliency detection methods were developed by further modifying the CS method.

Input Image Linear filtering

Gaussian Pyramids Gabor pyramids for  = {0º, 45º, 90º, 135º} Colors R, G, B, Y 24 Feature maps

Color

Intensity Center-surround differences

Orientations

12 Feature maps

6 Feature maps

Across-scale combinations and normalization Conspicuity map Conspicuity map Linear combinations Saliency map
Figure 2.4: Itti's approach for saliency detection. (adopted from Itti et al. [15]). 10 Conspicuity map

(a)

(b)

Figure 2.5: (a) An original image of a red flower and several blue flowers, (b) the low-resolution saliency map obtained by CS saliency detection method.

The steps towards the saliency map of the method are: (1) linear filtering resulting in color, intensity, and orientation maps; (2) Center-surround operation and normalization resulting in feature maps (total 42); (3) across scale operation and combination of all feature maps for each feature resulting in 3 different conspicuity maps; and (4) normalization of the conspicuity maps combining to one saliency map. These steps are expressed in the following four equations (Equations 2.3-2.6):  ( , ) = |  ( )   ()| (2.3)

  (, ) = |( () -  ( ))  ( () -  ())| ( , , ) =  (, )   (, )

  ( , ) = |( () -  ( ))  ( () -  ())|

(2.4) (2.6) (2.5)

where, subscript H represents HDR image. I, C and O represents intensity, color, orientation. Subscript RG and BY represents the color opponency for red-green and blue-yellow, c represents the center, and s represents the surround (c and s are correlated as: c  {2, 3, 4}, s = c + d, and d  {3, 4}). The numbers in the {} represents the center and surround area.  denotes the interpolation to finer scale and point-to-point subtraction.

11

Spectral ­ residual (SR) saliency detection method: The SR method was one of the earliest approaches in detecting saliency [27]. The method extracted the salient features by separating the spectral residual from an image by using its log spectrum. It was not only effective on natural images but also artificial images such as psychological patterns. The process of this method was divided into two stages: a pre-attentive process and a complex attention process. The first process dealt with separating the features that pops up in an image, and the second process dealt with finding the salient map with the detected region of saliency. This method was less complex than other state-of-the-art methods as no prior knowledge was required in the process. Figure 2.6 shows the saliency map of the image (in Figure 2.5) obtained by using the SR method.

(a)

(b)

Figure 2.6: (a) Original image of flower, (b) the low-resolution saliency map obtained by SR saliency detection method.

The steps for this method are: (1) down-sampling the image; (2) smoothing of the amplitude spectrum using Gaussian filter; (3) obtaining difference between the filtered amplitude and the original amplitude resulting in residual; and (4) composing back to the saliency map using residual and phase. The process can be expressed using the following equations (Equations 2.7-2.11):

( ) =   ()
12

( ) = | [ ()]|

(2.7) (2.8)

where, A(f) is the amplitude spectrum, P(f) is the phase spectrum, L(f) is the log of the amplitude spectrum, and R(f) is the residual in Fourier domain. 2.4.2 Methods for Low­resolution Saliency Map Frequency ­ tuned (FT) saliency detection method: Achantay et al. [28] developed the frequency tuned (FT) saliency detection, which is a bottom-approach. In this process, the average image and the Gaussian blur were found separately and then subtracted from each other to form the saliency map (Figure 2.7). The method exhibited promising potential in salient object segmentation. Figure 2.8 shows the saliency map of some flowers obtained by using the FT method. The steps to find the saliency map in this process were as follows: a. Emphasize the largest salient objects b. Highlight these whole salient areas uniformly c. Form well defined boundaries of salient objects d. Obtain high frequencies arising from texture and noise e. Disregard the blocking artifacts f. Find the full-resolution saliency map output

 = ()   -1 [exp(( ) + ( ))]

 ( ) = ( ) - ( )  ( )

( ) = log( )

(2.9) (2.10) (2.11)

13

Gaussian blur

Image

Saliency map
µ  µ -  µ  µ

Image Average
( , ) = µ -  (, )

   (, ) =     Figure 2.7: The overview of the frequency tuned (FT) method [27]. Here, I is the mean image,  (, ) is the Gaussian blur of the image and ( , ) is the saliency map.

(a)

(b)

Figure 2.8: (a) An original image of a red flower and several blue flowers, (b) the high-resolution saliency map obtained by FT saliency detection method. 14

The saliency map preserves same resolution as the original image. The process can be expressed by the following equations (2.12-2.14): µ µ = µ  µ (2.12)

blurred version of the HDR image.   (, ) carries the fine texture details, noise and coding artifacts. Random Center ­ Surround (RCS) saliency detection method: This method is a bottom up saliency detection method and was proposed by Vikram et al. [29]. In this method, the contrast between random pixels in an image was captured. It was explained on the basis of the stimulus bias between two given stimuli (pixel intensity values) in an image, and had a minimal set of tunable parameters. In addition, it does not require any training bases or priors. Figure 2.9 shows the saliency map of an image obtained by using the RCS method.

where, µ is the arithmetic mean pixel value of the HDR image, and   (, ) is the Gaussian

 = µ -   (, ) 

    (, ) =     

(2.13) (2.14)

(a)

(b)

Figure 2.9: (a) Original image of flower, (b) the high-resolution saliency map obtained by RCS saliency detection method. 15

Equation 3.16 represents the resultant saliency map:   , 1 , 1 , 2 , 2,  =
| (1 ,1 )-  (2 ,2 )| (1 -2 )2 +(1 -2 )2

(2.15)

where, (1 , 1 ) and (2 , 2 ) are the co-ordinates of two distinct points in the image randomly selected between 0 and the dimensions (height x width). High Definition Human Visual Saliency (HDHVS) detection method: Saber et al. [30] proposed a high resolution biologically inspired salient region detection method. They applied centersurround method of Itti et al. [15] by using wavelet transform for lossless high resolution saliency maps. The identified features were kept intact in the method, keeping the resolution high. The wavelet approximation of the image was taken as center scale, and the original map as the surround scale. The center-surround function was implemented by downsizing the surround scale to the size of the center scale using bicubic interpolation, and performing absolute point by point subtraction. The output image resolution and size of the center-surround operation were not same as the input image. The wavelets played an important part in preserving the image resolution. The center surround difference was brought back to high resolution map using the vertical, horizontal and diagonal details from wavelet decomposition. Figure 2.10 shows the saliency map of an image obtained by using the HDHVS method, and Figure 2.11 presents the process flow diagram of the HDHVS method.

(a)

(b)

Figure 2.10: (a) Original image of flower, (b) the high-resolution saliency map obtained by HDHVS saliency detection method. 16

Input Image

Linear filtering

Grayscale Wavelet transform

Red Wavelet transform V V

Green Wavelet transform V V

e

A A

D D

H H

e

A A

D D

H H

e

A A

D D

H H

V V

Inverse wavelet transform Intensity feature map

Inverse wavelet transform Color feature map

Inverse wavelet transform Color feature map


Final Saliency Map Figure 2.11: Block diagram of the HDHVS algorithm.

2.4.2.1 Wavelet Decomposition To fulfill the need of a transformation that provides local frequency information, wavelet transform (WT) was introduced [30]. The basis functions of WT are called `wavelets', which are wave like particles. The difference in WT and Fourier transform is that Fourier breaks a signal to sine and cosine, whereas, WT breaks the signal to wavelets. These wavelets are shifted and scaled version of a mother wavelet, which is constructed according to the requirement. 2D WT are 1D WT performed along row and column. Discrete WT are transformed, where wavelets are discretely sampled [31]. Figure 2.12 shows simple wavelet decomposition to extract horizontal and vertical approximate, and detail image using 2D discrete wavelet transform (DWT).

17

LL2

HL2 HL1

LH2

HH2

LH1

HH1

Figure 2.12: Simple representation of wavelet decomposition in an image resulting in approximate (further decomposed), vertical (LH1), horizontal (HL1), and diagonal (HH1) detail image.

2.5 Tone-mapping Tone-mapping (TM) is the intensity compression technique of the HDR image to make it suitable for LDR displays [32-33]. The main limitation in TM is the difference between the intensity level of the environment and the display medium. The light intensity of the environment may be completely different from the intensity level reproduced by the display medium. The appearance of an image in a display mainly depends on the illumination and contrast range. However, as a scene may appear differently during different times of the day, compressing and changing contrast range to fit in the display device may not always be sufficient enough to reproduce the same visual appearance of that scene. An HDR image is capable of exhibiting the details of extremely dim and extremely bright regions, which may be lost at LDR image. HVS can deal with a large amount of variation in illumination (approximately 14 orders of magnitude). Whereas, the LDR image contains information of only 2 to 3 orders. On the other hand, a single HDR image contains a lot of information compared to single LDR image making it hard for displaying in LDR display devices. Therefore, HDR image is needed to be converted into the LDR displayable image with important information in favor of the HVS. This tonereproduction problem was first introduced to the computer graphics community in 1993 [3].
18

Since then development of TM algorithm to incorporate visual models has been an active area of research within computer graphics and digital imaging communities [9].

(a)

(b)

(c)

(d)

(e)

(f)

(g)

Figure 2.13: (a) An original HDR image of a hotel room (EXR format), and the resultant tone-mapped HDR image using (b) Ashikmin's, (c)Drago's, (d) Durand's, (e) Reinhard's, (f) Tumblin's and (g) Mantiul's tone-mapping operators.

19

To date various tone-mapping methods have been developed, such as Ashikmins's [34], Drago's [35], Fattal's [36], Reinhard's [37], Tumblin's [38], Durand's [39], and Mantiuk's [40]. These follow different approaches such as gradient based, edge aware, display adaptive, piecewise linear etc. [3, 41]. However, each has certain limitations. A new algorithm of tone-mapping, eliminating some of the existing limitations, is necessary for various applications in this area. Figure 2.13 shows the resultant tone-mapped images of an HDR image, that were obtained by using some of these TM methods.

2.5.1 Tone-mapping using Bilateral Filtering Durand et al. [39] developed one of the earlier and popular edge preserving tone-mapping method using bilateral filter. The goal of this method was to reduce the contrast of the image and preserving the details. They used an edge preserving bilateral filter for the compression. The filter was a non-linear filter, where the weight of each pixel was calculated using a Gaussian in the spatial domain multiplied by an influence function in the intensity domain that decreased the weight of the pixel with large intensity variations. The filter was proposed by Tomasi et al. [42]. The tone-mapping method did not require any prior parameter setting. The bilateral filtering included two-scaled decomposition of base layer and detail layer. The base layer was compressed using a user controllable base contrast. The weight was 5 for all the pictures in general for their experiment. Figure 2.14 shows the process involved in tone-mapping of an HDR image using bi lateral filter.

20

HDR Image

Intensity

Color

Bilateral Filtering

Large scale variation

Details

Reduce Contrast

Preserve Details

Color

Output Tone-mapped Image Figure 2.14: The steps for tone-mapping using Bilateral filtering

2.5.2 Photographic Tone-reproduction Reinhard et al. [37] developed a popular method for tone-mapping. They used zone system in their method. The scene luminance was divided into zones from pure black to pure white. Each zone was assigned a key value based on lightness and darkness. For example, a white painted
21

room was high key and a complete dark room was low key. First step of this algorithm was luminance mapping depending on its key values, and the second step was automatic dodging and burning. It brought up selected dark region, and brought down the selected lighter region to convey the details. Figure 2.15 presents the mapping from scene zones to print zones using this method.

Figure 2.15: Mapping from scene zones to print zone. (adopted from Reinhard et al. [37]).

2.5.3 Gradient based Tone-mapping Fattal et al. [36] proposed an edge preserving HDR compression method. In this method, the gradient field of the luminance image was manipulated. The algorithm was based on the observation that any strong change in the image resulted rise to large magnitude luminance gradients at some scale. Fine details corresponded to gradients of much smaller magnitude. The algorithm attenuated the large gradients without changing the direction. The fine details or less variant gradient information was unaltered. A reduced dynamic range image was constructed due to the attenuation of the gradient field. There were some limitations in this method. The resultant images looked visually unreal and burnt. This was because human visual system was not considered in any steps of this method. There was no user input for contrast correction or saturation parameter adjustment. Figure 2.16 shows images of a scene taken at various exposures and the tone-mapped image using gradient based method.

22

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2.16 2.15: (a) to (e) are five photographs with exposure increasing from (1/1000) to (1/4) of a second, (f) Tone-mapped image using the gradient based tone-mapping algorithm.

23

2.5.4 Display Adaptive Tone-mapping Mantiuk et al. [40] proposed a display adaptive tone-mapping method. This method was able to minimize visible contrast distortions for a range of output devices. They used HVS to predict the visibility distortions, based on which the operator weighted contrast distortions. This tonemapping technique could adjust image or video content for optimum contrast visibility, which was done by considering ambient illumination and display characteristics. The method was easily extendable for video sequence. The algorithm led to a unique, well defined solution, with no subjective parameters. The operator was used to tone-mapped images adaptively, for display's dynamic range, brightness and ambient illumination. Figure 2.17 presents the processes involved in adaptive tone-mapping method.
Viewing Conditions for Original Image Enhancement (optional) Human Visual System Model

Original Image

Tone-mapping Operator

Tone-mapping Parameters Human Visual System Model

Error Metric

Display Adaptive Image

Display Model

Viewing Conditions for Original Figure 2.17: Process flow diagram of the display adaptive tone-mapping method.

2.6 Other Tone-mapping (TM) Approaches In addition to the methods discussed in previous section (Section 2.5), many other tone-mapping methods have been proposed by various researchers, and some of those are explained in the following paragraphs:
24

1) Lee et al. [43] proposed a piecewise tone reproduction method for image processing in 2009. The developed algorithm relied on piecewise construction and a suitable tone reproduction function. The method followed the estimations of global luminance modification and local luminance adaption. The method applied chromatic adaption technique of color appearance model to facilitate the visual appearance of the color consistency of the displayed image. Therefore, the displayed image and the real scene could be kept similar. According to the authors, the algorithm provided good result with a simple and time efficient real-world structure. 2) Revathi et al. [44] proposed a design for artifact free HDR imaging, where the method included all the available exposures and patches consistent with the selected image. The images were generated by averaging the radiance estimations of all such regions. The camera calibration errors were compensated by removing the potential seams. 3) Yao et al. [45] proposed a method with simpler weighted frame averaging based on intensity mapping function (IMF) while reproducing the image in LDR. This method required shorter exposures, and it could reduce the noise level in the resultant converted LDR displayed image. However, this method was time consuming. 4) Mai et al. [46] proposed an optimized tone curve for backward compatible HDR imaging. It enabled the reconstruction of HDR sequence using inverse tone-mapping of an LDR version of the original HDR content. A numerical optimization problem was formulated to find the tone curve, which reduced the expected mean square error in the new HDR sequence. This algorithm included photographic, logarithmic and display adaptive TM operators. The study showed comparable quality with the existing TM algorithms at that time. 5) Kovesi [47] presented a phase preserving TM for non-photographic HDR images in 2012. Non-photographic images such as aeromagnetic images are very difficult to understand. This proposed method compressed the dynamic range of an image at the same time preserved the local features. Monogenic filters were used for extracting the phase and amplitude values from the images. The dynamic range was reduced using a range reduction function to the amplitude. Local phase information was preserved (which was
25

important for Human Visual System) while interpreting an image. The method was advantageous due to its applications in a wide range of scientific images, avoidance of image segmentation, ability to select the spatial frequencies using high pass filters, and controlling of the scale of analysis. 6) Lakhshmi et al. [48] reviewed several tone-mapping operators for TM process. In their discussion, color correction and hierarchical tone-mappings were explained for the enhancement of the image quality using the selected operators. 7) Narwaria et al. [49] implemented an adaptive contrast enhancement for post processing of tone-mapped HDR images, where the method overcame two major drawbacks of HDR imaging: (a) inability to reproduce all the contrast of HDR images to LDR displays, and (b) requirement of content specific parameter set by subjective testing. They enhanced the contrast adaptively depending on the loss of the HDR image and TM image. It was effective for the recovery of the damaged contrast. This method was unique because no human input was needed to enhance the contrast. This unique feature made it effective for real-time applications. Figure 1.2 shows the process diagram of this method. 8) Huang et al. [50] developed a real-time application method for TM. This method was based on per pixel exposure method. The method kept the camera response compressed, and varied the exposure per pixel. It obtained real-time performance. The method was not suitable as it included time consuming operation. 9) Thakur et al. [51] provided a fast and flexible TM algorithm. The contrast and visibility were controlled using a single parameter for tone reproduction curve (TRC). TRC was used to create a link between the image and the real scene. The method provided computational efficiency, simplicity as well as availability for enhancing LDR digital images.

26

LDR Tonemapping Loss of contrast (gradient) Chip limit Block based contrast enhancement algorithm

HDR HDR Image

NO

Greater than threshold?
YES

Determine naturalness

Final enhanced image
Figure 2.18. Process flow diagram of the adaptive post processing contrast enhancement. (adapted from Narwaria et al. [49]).

10) Herwig et al. [52] emphasised on single shot HDR image tone-mapping. The region based approach for pre-processing the image increased Signal to Noise ratio (SNR) and perceptual sharpness of the image afterwards. 11) Yaacoub et al. [53] proposed a method to combine the output of several operators to a single image. The process used two methods at a time to obtain the resultant image. The method was based on objective quality maps, and was not dependent on the dynamic range of input or output. In summary, this method was a fusion of three different types of distortions based on computation at each pixel position. A metric was used for quality measurement of the images.

27

Besides forward TM, inverse TM has also received research attention [54-56]. In inverse TM method the HDR information are determined from LDR image. Several inverse tone-mapping algorithms have been developed to find the HDR image from a single low dynamic range image. Kuo et al. [56] proposed an algorithm to inverse TM, which was called HDR image hallucination for inverse tone-mapping. It was used to reproduce the information that was lost during LDR image capturing. This method did not require human interaction. The performance was automatic using the luminance and texture decoupling process. The method was applicable to video inverse tone-mapping as well. 2.7 Filters used in HDR Tone-mapping One of the common tone-mapping techniques for HDR images is to separate the important information layer and base or less variant layer using a filter. These separated layers are further processed before combining to a tone-mapped image. The proposed TM algorithm is based on saliency detection using a guided filter. There are other similar filters that can be used for the targeted operation. However, there are certain advantage and disadvantages of each filters. This section explains some important filters used for tone-mapping purpose. For edge preserving bilateral filter was commonly used. However, guided filter was proposed later to reduce the limitations of the bilateral filter. 2.7.1 Bilateral Filter Bilateral filter is edge preserving smoothing filter [42]. The filter requires two parameters indicating size and contrast of the features to preserve. Each pixel is replaced by a weighted average of its corresponding neighbor. The filter averages the small and weak correlated differences between pixel values caused by noise. In the operation of this edge preserving filter a sharp boundary is assumed between dark and bright region. When the bilateral filter is centered, on a pixel on the bright side of the boundary, the similarity function assumes values close to one for pixels on the same side, and values close to zero on the dark side. The normalization term ensures that the weights for all the pixels add up to one. Therefore, the bright pixel at the center is replaced by the filter by an average of the bright pixels in its locality. It
28

essentially ignores the dark pixels. Conversely, when the filter is centered on a dark pixel, the bright pixels are ignored instead. As a result, good filtering behavior is achieved at the boundaries. Moreover, crisp edges are preserved at the same time. Figure 2.19 shows output of an input signal processed by the bilateral filtering.

(a)

(b)

Figure 2.19: (a) Input signal, (b) bilateral filtered output. (adopted from Tomasi et al. [42]).

Bilateral filter can deal with high dynamic ranges. In addition, the edge preserving property makes the bilateral filter applicable for edge preserving tone-mapping. Limitations of Bilateral filter in HDR tone-mapping: 1) The resultant filtered image using bilateral filter faces gradient reversal (as shown in Figure 2.20) and halo artifacts. Gradient reversal creates a dark line where there is a gradient change (at edge of the elements of the components in an image). Halo artifacts create a dreamy whitish effect at the edges.
2) The processing time for the tone-mapping is high due to O(N 2 ) time approximate

operation [18]. Thus, for high dynamic range image with high value of N and radius of the filter increased the operational time is increased significantly.

29

(a)

(b) Figure 2.20: 1D illustration for detail enhancement: (a) using bilateral filter and (b) using guided filter. The signals from the left to right showing base and input (base on red and input on black) signal together, detail signal and enhanced detail signal. The bilateral filter introduced gradient reversal effect after enhancing. (adopted from He et al. [19]).

2.7.2 Guided Filter and Its Applications Guided Filter is a structure transferring smoothing filter [19]. It requires two input images: a guidance image to guide the structure related information to the filtered output, and an input image that is required to be filtered. The filtered output is assumed to be a linear transform of the guidance image in a defined window. Maintaining the linear model, a solution is obtained minimizing the difference between the input and filtered output. A box shaped window with radius r is used to find the mean by a moving sum method. In this process the edges are well preserved as the pixel values are unchanged in a high variance region and averaged in a low variance region. The guided filter has advantages over other filters such as the bilateral filter [42] and the domain transform filter [57] on similar usages. This is because it has O(N) operational time approximate algorithm, which is independent of the window radius unlike the bilateral filter, which has O(N 2 ) based algorithm. Therefore, the operation with guided filter is much faster. In The operation of guided filter can be expressed using the following steps and set of equations. addition, the other filters do not have better structure transferring ability as the guided filter [19].

30

Inputs: Filtering image: , guidance image:  , radius: r, regularization:  Output:   is the mean filter known as box filter Output image,  Algorithm for the guided filter:  =   () (2.16) (2.17) (2.18) (2.19) (2.20) (2.21) (2.22) (2.23) (2.24) (2.25) (2.26)

 =  -  .   =  - .   =  ()  =  .  +   =   ()  =
 + 

 =  -  . 

 =  (. )

 =  ( .  )

 =  ()

In the above equations, `corr' denotes correlation and `var' denotes variance. The subscripts denote the relation between the mentioned images. Figure 2.21 shows the process flow of structure-transferring operation of the guided filter. Figure 2.22 compares the effects of the guided filter and bilateral filter operation on an image.

31

p

Guided Filter q

I

(a)

 =  -

(, )

min ( +  -  )2 +  2


Linear Regression

 =a  =  + 
(b)

 =  -  

a= ()+

( , )

Figure 2.21: (a) A simple 2-D representation of the structure-transferring operation of the guided filter. (b) Shows the guided filtering operation in details (3-D). Here, I is the guidance image, p is the input image and q is the filtered output. The output  = a + b and  -  . a and b are co-efficient of the linear transform and n is the noise.

32

Figure 2.22: Smoothing an image using both guided filter and bilateral filter. The bilateral filter introduced gradient reversal and halo artifact. (adopted from Tomasi et al. [42]).

Applications of Guided Filtering The guided filter has many applications due to its various properties: · Based on the value of the regularization parameter, the flat patch and high patch areas in an image are determined, and high patch or high variance areas are preserved. The edges are usually the high variance areas, and therefore, guided filter preserves the edges. In image processing, where edge preserving smoothing is required, the guided filter works well [19]. · · The guided filter can be applied in both gray and color images, providing flexibility in various areas of image processing. Gradient reversal artifact can be avoided as it is a gradient preserving filter (as shown in Figures 2.20 and 2.22). This filter can replace bilateral filters to remove the gradient reversal artifact.

33

·

This is a structure transferring filter. The structure of the guidance image can be transferred to the output image, providing its applicability in many image filtering applications [19].

·

It can be used for HDR imaging, to smooth the less variant area while preserving the details [16, 18, 19].

2.8 Chapter Summary In this chapter, a comprehensive literature survey on various saliency detection approaches and tone-mapping have been conducted. Various filters used in edge preserving for HDR tonemapping have been studied and comparisons have been made. The guided filter's working principle, advantages, and applications have been explained thoroughly. The guided filter was used for the detail layer separation in the proposed tone-mapping of this thesis. This chapter, therefore, provides the required knowledge for better understanding of the proposed saliency guided HDR tone-mapping method.

34

Chapter 3 METHOD DEVELOPMENT
3.1 Introduction This chapter focuses on the proposed HVS inspired Saliency Guided Edge Preserving ToneMapping (SGETM) method development and the necessary constraints of the related algorithm. The proposed tone-mapping method used saliency map and a guided filter for tone-reproduction process. The guided filter was used for tone-mapping because of its better edge preserving behavior than other similar filters. Figure 3.1 illustrates the flowchart of the proposed method, and the following sections describe the method in detail.
Input Image Log luminance of Input Image Saliency Map of Input HDR Image Guided Filtering (1) Edge Preserved Gradient map

Guided Filtering (2)

Base Layer Detail Layer Compressed Base layer Enhanced and Median Filtered Detail Layer

New Log Luminance Image Exponent of the luminance Image Resultant Tone-mapped Image Figure 3.1: Flowchart illustrating the proposed SGETM method. 35

3.2 Method Description Saliency detection methods can be divided into two categories: (1) the methods resulting lowresolution maps, and (2) the methods resulting high-resolution maps. In the proposed method in this work five different saliency detection methods resulting both low and high resolution maps were applied to identify the better method. For the low-resolution maps, Center-Surround (CS) method by Itti et al. [15] and Spectral Residual (SR) method by Hou et al. [27] were used; whereas, Frequency-Tuned (FT) method by Achanta et al. [28], Random Center-Surround (RCS) method by Vikram et al. [29] and High Definition Human Visual Saliency (HDHVS) method by Saber et al. [30] were used for high-resolution maps. In the proposed method, a Guided Filter (GF) was used for base layer and detail layer separation. A similar approach was first taken by Durand et al. [39]; however, using a bilateral filter for the separation. The limitations of the use of bilateral filter were gradient reversal artifact, lower edge preserving capability, and higher computational time. Recently, guided filter was proposed and used for tone-mapping [19], where the filter exhibited more edge preserving properties with less computational complexity. It also eliminated the gradient reversal artifacts. For these reasons, the guided filter was chosen for the proposed method. The guided filter requires two inputs: the input image and the guidance image. Both inputs can be same image or different images. The output filtered image is the linear transform of the guided image. In this process, a cost function (relationship showing the difference between guidance image and input image with respect to edge information) was developed with the input image and guidance image information [19], and the function was solved for the values of its co-efficient by minimizing the cost function. The filtered output preserved detail at edges and smoothened the less variant areas. The linear transform equation (Equation 3.1) and the cost function (Equation 3.2) were,  =   +  ,   
36

(3.1)
2

,   = (  +  - ,  +  2

(3.2)

image, p is the input image, q is the output image, and  is a small square window with radius r for performing local operation.

where,  is the regularization parameter, ,  are the linear co-efficient, I is the guidance

The guidance image provides information to guide the filtering. In the proposed method, saliency map of the original HDR image was used as a guidance image. The target was to transfer the structure of the saliency map to the output image while smoothing the less variant pixel areas. The GF preserved the pixel values of the high variance area (edges) with the intention of keeping the edge pixel values unchanged. On the other hand, low variance pixels were averaged by a box filter (squared averaging filter). A 1D Box filter algorithm can be shown as follows [19]:  =  =0    (3.3)

 = -1 + + - --1 where, O is the output Image, I is the input image, and r is the radius. When a saliency map is used to guide the image structure, the salient areas of the input image are preserved better and visually emphasized in the resultant filtered output image. The resultant image with more prominent edges provides more details in salient areas. In the proposed method, filtered result obtained by using the input image as a guide, was subtracted from filtered result obtained by using the saliency map as a guide. Here, the filtered output without saliency was further smoothened and compressed by a fixed weight, and considered as the base layer. The weight was selected as 0.6 in the proposed method. The separated detailed layer, on the other hand, was smoothened by a 2D median filter with 2x2 neighborhood and enhanced by a factor of 1.1. At the end, the enhanced detailed layer and compressed base layer were added to compose the resultant tone-mapped image.
37

,  = 1   do

The Structural Similarity Index Matric (SSIM) [58], was used to identify the most appropriate saliency detection method in the proposed method. The HDHVS method provided higher scores for the TM images than the four other saliency detection methods used. After identifying the best saliency method, two edge-aware assessments were completed to determine the edge strength and naturalness of the images. The Feature Similarity Index Matric (FSIM) uses phase congruency and gradient magnitude as features [59], where the edge information is given more importance in the quality assessment. In the proposed method, the resultant images were tested using FSIM. The results were compared with three other TM method results that were developed by Durand et al. [39], Fattal et al. [36] and Mantiuk et al. [40]. These methods were selected for comparison due to their similarity with the proposed method in different aspects. Durand et al. [39] separated the base and detail layers using bilateral filter. Fattal et al. [36] used gradients of the luminance and performed compression of base layers along with enhanced detailed layer. Mantiuk et al. [40] obtained similar looking results as several other tone-mapping methods using backward compatibility with less complex calculation. Another edge strength based quality assessment (ESSIM) [60] was performed to prove the better edge preserving tone-mapping of the proposed method. Three different types of datasets with various lightning condition were selected for testing the results of the proposed method. They were the EMPA database [61], the RIT MCSL database [62], and some images from Paul Debevec's database [63]. All three datasets are available online. The HDR images were found in RGBE radiance map (.hdr file extension), where the format was proposed by Ward et al. [64]. The RGBE format of the image uses 1 byte each for red, green, and blue channel data preservation and 1 additional byte to carry an exponent value. The exponent provides more accuracy in preserving dynamic range. The EMPA dataset had images of mostly outdoor scenes with high variation in lighting condition. The HDR images of that dataset provided details of the raw images used in obtaining the HDRI. The dataset is well balanced in terms of raw image exposure with not too many over-exposed
38

images or under-exposed images. The RIT MCSL dataset images have high color variations and the database has a mix of both over-exposed and under-exposed HDR images. The images contain more salient regions, hence, useful for this thesis work. Paul Debevec's database is one of the mostly used dataset for HDR images, and is used in different tone-mapping method development. A subjective study was conducted using 20 image sets, each set containing results of five tonemapping methods including the result of the proposed method. The subjective study was divided into two categories: (a) viewers assessed the resultant images on various platforms, and (b) viewers assessed the images on a fixed calibrated monitor and ranked. The viewers ranked the results of five methods of each original HDR image with 1 to 5 based on the naturalness with maximum preserved edge details. Rank 1 represents the highest quality and 5 represents the lowest quality among the tested methods. To avoid any biasness in the assessment of the resultant images the used methods' names were not reveled to the viewers. The detailed results are presented in Chapter 4. 3.3 Tone Reproduction Algorithm The algorithm of the proposed TM method is provided step-by-step in this section. This algorithm was based on HDHVS saliency map. The goals of this algorithm were simpler implement and lesser computation complexity. Due to the O(N) time operation of the guided filter, the method required less computation time. The operational time was independent of the radius value. Four versions of this algorithm were considered using different saliency information, where all the versions had same steps except step 2 with different saliency maps. Step 1: Input Calculation of the Log luminance of the input HDR image:  =  ( ) (3.4)

39

Step 2: Saliency Map Computation The saliency map was obtained by modifying the HDHVS method for the HDR radiance map. The map was resized to the log luminance image size. This was done so that the saliency map can be directly used in the guided filter. Step 3: Guided Filtering  = ( ) (3.5)

filtered output can be obtained using the following equations (Equations 3.6-3.8):  =  (). ( ) +  ()  =  ( () ­ .  ( ))

The Calculated LL and  in Steps 1 and 2 were used as the inputs of the guided filter. The (3.6)

 =

[( . )- ( ).( )]+

( .)-[( ).()]

(3.7) (3.8)

where,  is the guided filtered HDR image that is the linear transform of the guidance

saliency map, f() is the mean filtered component, and eps is the regularization parameter. Here, a and b were obtained from the cost function minimization following the method developed by the He et al [19]. A box filter was used for the mean calculation with window radius of r. The radius (r), of the window for the mean filter inside guided filter, was chosen as 2 for the eps value of 0.01. Step 4: Edge Separation and Base Layer Computation: The difference between the guided filtered output ( ) and the log luminance (LL), provided  =  -  (3.9)

the edge preserved detailed layer of the HDR image. The detail layer can be expressed as follows:

Base layer ( ) containing large scale variations was the filtered output, where both the input and guidance images were LL.  =  ()
40

(3.10)

Step 5: Determination of Resultant Image a. The compressed base layer (reduced by 60%) and the enhanced edge layer (enhanced by 10%) were added together to form new luminance (LLnew) of tone-mapped image (Equation 3.24). This combination of weights avoids introduction of artifacts. The Detailed layer was median-filtered to avoid halo artifact in the resultant image. This also gave the resultant image a visually natural appearance.  = 0.6.  + 1.1. ( ) (3.11)

b. The new luminance was composed back to color image (Equation 3.12). The saturation parameter was selected as 0.5 for an experiment. The exposure was dependent on the mean pixel value. The power equation for the exposure parameter (Equation 3.13) was best fitted for the exposure selection.  =  [( ))] (3.12) (3.13)

The resultant tone-mapped image from the proposed saliency detection method was compared with the resultant images from four other saliency detection methods, using the tone-map quality index based on structural similarity. Based on the structural similarity between the tonemapped image and original HDR image a score was assigned. For the structural similarity comparison, the EMPA dataset was used, where the raw images had similar exposures and camera response function. 3.4 Chapter Summary As presented in this chapter, the proposed thesis was divided into three major parts: (1) proposal of an algorithm using saliency for tone-mapping; (2) analysis and application of several major saliency detection methods; and (3) the quality assessments of the results. Three different objective quality assessments were used for the results: structural similarity index matric (SSIM), feature similarity index matric (FSIM), and edge strength based similarity index matrix (ESSIM).
41

 = (1.276       )-0.3535 - 0.1418

The features used in the matric were phase congruency and gradient magnitude. Both features greatly provoked by the edge information. A subjective quality assessment was conducted using total 58 viewers on various types of screens, and on a fixed calibrated screen. All the resultant images are shown in the results chapter (Chapter 4). All the methods discussed in this chapter were implemented using MATLAB2014b on Windows platform.

42

Chapter 4 RESULTS AND ANALYSES
4.1 Introduction This chapter presents the results obtained by the proposed method. The used datasets for testing were the EMPA database [61], the MCSL database [62], and Paul Debevec's dataset [63]. The EMPA database was a well-balanced database with 32 HDR radiance maps of mostly outdoor images with high lighting variations. The MCSL database had 62 images containing more salient regions including both outdoor and indoor scenes. The number of raw exposed images also varied for each image for that dataset. The Debevec's database included HDR images that were used in most of the popular HDR tone-mapping methods. In this study 13 images form this database were used. The HDR radiance maps, used to test the proposed method, were in RGBE format that was proposed by Ward et al. [64]. The chapter is divided into three main sections. The first section includes the resultant saliency maps using 5 different saliency detection methods. The second section explains states of the images in every step of the algorithm. The third section presents objective and subjective quality assessment results and analysis.

4.2 Saliency Maps of HDR Images in Different Methods 4.2.1 Low-Resolution Maps of HDR Images Center-surround (CS) and Spectral Residual (SR) Tone-mapping Approach for HDR Images: The CS and SR methods were modified for application in HDR images to obtain the saliency maps. These saliency maps were used in the proposed tone-mapping method. Figure 4.1 (a) shows two original HDR images, saved as JPEG format using the `imwrite' command in MATLAB 2014b. Figure 4.1(b) and Figure 4.1 (c) shows the resultant saliency maps for those HDR images obtained using the CS and SR method. The resultant saliency maps were low-resolution maps. Although the salient regions were successfully detected, the resultant maps were not showing clear edges of each identified salient regions. Figure 4.1 (b) and Figure 4.1 (c) show that the saliency maps of the HDR images identified the saliency regions (the white circled area and rectangular areas);
43

however, the details in these areas were not very clear and the map looked blurry. In the proposed TM method, these low-resolution maps did not provide better results than the results acquired by using the high-resolution maps.

(a) Original HDR Images

(b) Saliency Maps (CS Method)

(c) Saliency Maps (SR Method)

Figure 4.1: Two original HDR images (left, top and bottom) and corresponding low resolution saliency maps obtained by using the CS method (middle) and the SR method (right).

44

4.2.2 High Resolution Maps of HDR Image High Definition Human Visual Saliency (HDHVS) Detection Approach for HDR Images: The HDHVS method was modified for HDR image and used in the proposed TM approach. The resultant saliency maps were high-resolution maps as there were no down sampling of the image in the saliency detection method. The use of wavelets for CS operation, eliminated the low-resolution problem. The detected saliency regions carried more information because of the high-resolution. Figure 4.2 (a) shows the saliency maps obtained by using the HDHVS method. These saliency maps were used in the proposed TM method. The final tone-mapped images, obtained using the HDHVS saliency maps, were found to be better in the quality assessment and subjective quality assessment studies.

Frequency Tuned (FT) Saliency Detection for HDR Images: The frequency tune method was also modified for application in HDR images to obtain the saliency maps, which then were used in the proposed method. The output saliency map was high resolution map, and the detected saliency region showed more detail information than the low-resolution saliency maps. Figure 4.2 (b) shows the obtained saliency maps for HDR images using FT saliency detection method.

Random Center Surround (CS) Saliency Detection Method: Figure 4.2 (c) shows the saliency maps obtained by using the RCS method. The saliency maps obtained by using this method, were also high-resolution maps. The saliency map was not clear near the frame edges. The problems of the image blurring near the frame of the images were also observed while applying this method on LDR images as shown in Figure 2.9 in Chapter 2.

45

(a) Saliency Maps (HDHVS Method)

(b) Saliency Maps (FT Method)

(c) Saliency Maps (RCS Method)

Figure 4.2: High-resolution saliency gradient maps using: (a) HDHVS method, (b) FT method, and (c) RCS method. The Original HDR images are shown in Figure 4.1 (a).

46

(a)

(b)

(c)

(d)

Figure 4.3: An Original HDR image with a magnified section (shown in a), and saliency maps obtained by three methods: (b) (b) HDHVS method, (c) FT method and (d) RCS method. The magnified sections of the saliency maps show the differences in details in the saliency maps obtained by three high-resolution saliency detection methods.

47

In the proposed method, the high-resolution saliency maps produced better result because of the more detailed information in the saliency regions. A detail explanation of this observation is provided in Section 4.2.2. Figure 4.3 shows an original HRD image with a magnified section and saliency maps found using three different high-resolution methods. The magnified salient region clearly shows the differences in the details for three different methods. The magnified saliency maps indicate that the saliency map by HDHVS method (Figure 4.3 (b)) showed minor details in the window design. All three saliency maps were high-resolution maps. However, the details of the maps of FT and RCS methods (Figure 4.3 (c) and (d)) were not as good as the HDHVS output.

4.3 Proposed Tone-mapping Algorithm using Saliency Map as Guidance Figure 4.4 presents transformation of an input HDR image at different stages to the final tonemapped image following the proposed algorithm as described in Section 3.2 and Figure 3.1 The input was an HDR radiance map of RGBY format. All the operations were performed in the luminance channel. The detailed and base layer were separated by a saliency map guided filter. The final luminance image was adjusted with the user defined saturation and contrast parameter for better visual appearance. The weight of the parameters depended on the mean pixel value of the original HDR image. The power equation, formulated by the mean and corresponding exposure values of 31 images of the EMPA dataset, was used for determining the exposure values for all the test images. A weight of 0.5 was selected as the saturation parameter for all the test images. It was adjustable according to the requirement of the user.

One of the major step in the proposed tone-mapping method was to use saliency map as guidance to separate the detailed layer. That layer was added with the compressed base layer to preserve the edge of the image. Figure 4.5 shows differences between tone-mapped images with and without using saliency map as guidance image. The guided filter preserved the edges up to a certain level; however, saliency map as guidance preserved the edges of salient regions better. Figure 4.5 (a) shows the detailed layer separated using same image as guidance and input. Figure 4.5 (b) shows the detailed information of edges, which was obtained by using saliency map as
48

guidance in the TM method. The details were more enhanced than the one obtained without the use of saliency map as a guide image.

Input HDR Image

Luminance Image

Log of luminance Image

Guided Filter (1)
Saliency map of the Image

Guided Filter (2)

Saliency guided filtered output

Base layer

Detail layer

Tone mapped image

New luminance image

New log luminance image

Figure 4.4: The workflow of the proposed tone-mapping method showing the transformation of an HDR image at different stages.

49

(a)

(b)

Figure 4.5: (a) The detailed layer without using the saliency map as guidance in the guided filter, and (b) the detailed layer using the saliency map as guidance in the guided filter.

The radius of the window (r) of the mean filter and eps were selected as 2 and 0.01 for the experiment. With a fixed regularization, these selected values were the best selection to avoid halo artifact in the resultant image. Figure 4.6 provides the detailed layer for various radius of window. In Figure 4.6 (c), the detailed layer was sharper and richer than the other two (r = 2, and r = 5). However, it introduced halo artifacts. Use of this layer would introduce halo artifact and gradient reversal artifact in the resultant image. Thus, with increasing radius the details become more prominent; however, the halo artifact negatively affects the natural look of the image. The exposure parameter was selected based on a power equation obtained from the relationship between mean pixel value of 32 images of the EMPA dataset and user inputted exposure. It was observed that the mean pixel and exposure value were inversely related. The saturation value of 0.5 was the best selection for the proposed method avoiding halo artifact. This exposure equation and saturation parameter worked for other images as well. Figure 4.7 shows the effects
50

of increasing saturation value in the tone-mapped images. The higher saturation value had a tendency of reducing the naturalness of the image.

(a) r = 2

(b) r = 5

(c) r = 10 Figure 4.6: Effects of different radius of window of mean filter in the guided filter. Radius, r = 0.2 was found to be producing the best result. 51

(a) sat = 0.5

(b) sat = 0.8

(c) sat = 1

(d) sat = 2

Figure 4.7: Effects of saturation (sat) in the tone mapped images. Saturation parameter value of 0.5 was proven to be the best option with respect to maintaining the natural look of the image and preserving the edges.

4.4 Objective Quality Assessment 4.4.1 Structural Similarity Index Matrix (SSIM) Results Since the resultant tone-mapped images, using 5 different saliency maps, visually did not show major differences, a tone map quality index matrix (Structural Similarity Index Matrix or SSIM) was applied to identify the best among all the results. The goal was to identify the best edge preserved tone mapped output using saliency regions. As the guided filter is an edge preserving filter, it was guided with saliency map in such a way that the natural edges were preserved and more details were preserved on the saliency regions. The expected output was an edge preserved
52

visually attractive tone-mapped image. The results of the proposed method provided better scores in edge preserving matrices no matter which saliency map was used. Maintaining structural similarity was not the primary objective of the proposed method. Therefore, the results were tested with the SSIM to determine which method not only preserved the edges but also maintained more structural similarity to the original HDR image. In addition, SSIM was orignally developed for the assessment of tone-mapped HDR images. The other quality assessment methods (Feature similarity index and Edge strength similarity index matrices) used for testing the results (shown in Sections 4.4.2 and 4.4.3) were mostly for LDR image quality assessment. Figure 4.8 shows bar graph of the percentages of the highest SSIM scores for the resultant images using the proposed method with 5 different saliency maps as guidance for the filter. For the lowresolution saliency methods, SSIM scores were similar and lower. Therefore, it was not effective to use low-resolution saliency maps to guide the filter. According to the SSIM scores (Figure 4.8 and Table 4.1), the HDHVS had the higher percentage of highest scores; and therefore, proved to be the best option to guide the HDR image for tone-mapping.

Percentage of the Highest SSIM Score

Different saliency guided tone-mapping

Figure 4.8: Comparison of the percentage of highest SSIM scores for five different saliency methods in the proposed TM algorithm for all the images of EMPA database. 53

Table 4.1: The SSIM scores for the resultant images in Figure. 4.9 using 5 different saliency maps in the proposed tone-mapping algorithm. Images 1 2 3 4 5 HDHVS 0.7055 0.4583 0.8148 0.6124 0.8479 FT 0.6801 0.4585 0.7988 0.5838 0.8217 RCS 0.7042 0.4584 0.8130 0.6125 0.8455 SR/CS 0.7051 0.4593 0.8147 0.6124 0.8459

(a)

(b)

(c)

(d)

(e)

Figure 4.9: Tone-mapped images of five HRD images using five different saliency methods in the proposed TM algorithm ((a) HDHVS, (b) FT, (c) RCS, (d) SR and (e) CS method, respectively).

54

Figure. 4.9 shows the tone-mapped images using five different saliency maps in proposed algorithm. The differences are negligible visually, however, Table 4.1 shows the difference in the SSIM scores for all the images. 4.4.2 Feature Similarity Index Matrix (FSIM) Results The tone-mapped results were tested with the Feature Similarity Index Matrix (FSIM). Three other popular tone-mapping methods were also implemented and tested with FSIM. Implementation of other tone-mapping methods and testing were necessary, as an edge based assessment was needed for testing the edge strength of the tone-mapped images. The FSIM was originally developed by Zhang et al. [59] for LDR images, and modified further for tone-mapped images by Hossein et al. [65] recently. The features used for the matric were phase congruency and gradient magnitude. Both the features were edge dominated. The results were compared with Durand's TMO [39], Fattal's TMO [36] and Mantiuk's TMO [40]. Durand's method is an edge preserving method and is similar to the proposed method, except bilateral filter was used instead of guided filter. Fattal's TMO was gradient dominated, where detailed layer was added for booted edges. This method was expected to produce more FSIM score. The display adaptive TMO by Mantiuk [40] based on HVS. The proposed method is bottom up saliency dependent; and therefore, HVS was preferred in the proposed method. In addition, the contrast weight and saturation parameter were based on HVS. The bar graph in Figure 4.10 shows the percentage of the highest FSIM scores for the tested images using above mentioned 4 TM methods. Among 107 various HDR images, 57 provided higher scores for the proposed method. Fattal's method provided relatively high scores (~33%) for FSIM because it was a gradient based approach. Durand's method using bilateral filter provided low scores (~10%) due to less edge preserving capability. Mantiuk's method was mainly focused on HVS and did not use any edge preserving technique, thus, the scores were lower (5%) than other methods. Tables 4.2, 4.3, and 4.4 present the FSIM scores of 4 TM methods for images in three databases (RIT MCSL, EMPA, and Debevec's, respectively). Table 4.5 provides the percentage of highest FSIM scores for all the tested methods including the proposed method.

55

Table 4.2: FSIM for the proposed and other three state-of-the-art tone-mapping methods for RIT MCSL database. Image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 Proposed 0.7697 0.7011 0.6665 0.6829 0.6031 0.5542 0.4619 0.5981 0.5053 0.3410 0.6157 0.5762 0.7062 0.7009 0.5913 0.7243 0.5835 0.6781 0.7703 0.5640 0.5681 0.8310 0.6142 0.5767 0.6676 0.5120 0.5413 0.5535 0.6630 0.4966 0.6960 0.7189 0.7880 0.6156 0.6687 0.4186 0.6419 0.5359 0.7347 0.6455 0.5061 0.7065 Durand 0.7051 0.6253 0.5856 0.6596 0.5406 0.4617 0.4681 0.5773 0.4314 0.3586 0.6001 0.5368 0.6979 0.6880 0.5185 0.6998 0.5655 0.6246 0.7768 0.5416 0.5952 0.8292 0.3625 0.5569 0.5796 0.5244 0.4740 0.5453 0.6051 0.4863 0.5998 0.6838 0.7262 0.3815 0.6078 0.3814 0.6092 0.5275 0.6766 0.6766 0.3401 0.6291 56 Fattal 0.7312 0.6212 0.5850 0.6814 0.5218 0.4789 0.4938 0.6668 0.4393 0.4062 0.5565 0.6440 0.6873 0.6538 0.4995 0.6713 0.5420 0.6891 0.7574 0.6022 0.6866 0.8012 0.3596 0.4984 0.6540 0.5202 0.4581 0.5264 0.5931 0.4795 0.6317 0.6248 0.7314 0.4114 0.6339 0.3743 0.6352 0.5756 0.5905 0.5859 0.3284 0.6493 Mantiuk 0.7287 0.6943 0.6285 0.5611 0.6028 0.5431 0.4654 0.5929 0.4719 0.3439 0.6047 0.5231 0.6552 0.6003 0.5500 0.6993 0.5645 0.5258 0.7896 0.5415 0.5590 0.8297 0.4579 0.5590 0.5093 0.4475 0.5070 0.5371 0.6533 0.5214 0.6270 0.6656 0.6769 0.4114 0.6178 0.4128 0.6285 0.5311 0.6751 0.6154 0.3608 0.5871

Image 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62

Proposed 0.5901 0.7557 0.4202 0.4364 0.6474 0.5759 0.6280 0.5809 0.5697 0.7865 0.6159 0.5959 0.6095 0.5918 0.7312 0.5641 0.3725 0.5760 0.6502 0.7767

Durand 0.5642 0.6908 0.4285 0.3409 0.5798 0.5064 0.5323 0.4410 0.5789 0.7812 0.5410 0.6242 0.5613 0.5895 0.6936 0.5480 0.3541 0.5412 0.5609 0.6974

Fattal 0.5774 0.6222 0.4585 0.4066 0.5623 0.5417 0.5404 0.4367 0.7410 0.6682 0.5367 0.5755 0.6245 0.5351 0.7284 0.5434 0.3898 0.5979 0.5410 0.5410

Mantiuk 0.5530 0.7170 0.4417 0.3886 0.6189 0.5062 0.5428 0.5120 0.5624 0.7540 0.6030 0.5545 0.5452 0.5314 0.6335 0.5716 0.3644 0.5018 0.6345 0.7405

Table 4.3: FSIM for the proposed and other three state-of-the-art tone-mapping methods for EMPA database. Image 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Proposed 0.5133 0.5426 0.3682 0.7298 0.3807 0.5346 0.5318 0.2329 0.6046 0.5800 0.5324 0.2102 0.4049 0.6954 0.3323 0.4209 0.7936 Durand 0.5543 0.6075 0.3887 0.7105 0.4203 0.5600 0.5965 0.2383 0.6350 0.5629 0.5321 0.2415 0.4502 0.7322 0.3826 0.4410 0.8135 57 Fattal Mantiuk 0.5616 0.5727 0.3901 0.6737 0.4157 0.5081 0.5363 0.2574 0.6367 0.5644 0.5274 0.2328 0.4278 0.7037 0.3600 0.4493 0.7473

0.7862 0.7199 0.3893 0.7394 0.5433 0.7118 0.7549 0.2522 0.6398 0.5775 0.5200 0.2894 0.5775 0.7889 0.4330 0.4643 0.7945

Image 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32

Proposed 0.8108 0.7319 0.4448 0.6698 0.3883 0.5486 0.7912 0.4801 0.6972 0.3945 0.6609 0.6290 0.7342 0.6703 0.4888

Durand 0.8106 0.6685 0.4422 0.6471 0.3814 0.5352 0.8204 0.5400 0.6328 0.4753 0.6711 0.5820 0.6843 0.7026 0.5143

0.7933 0.7299 0.3508 0.6313 0.3347 0.4733 0.7998 0.6462 0.6183 0.5423 0.6793 0.5703 0.6368 0.7574 0.5622

Fattal

Mantiuk 0.7529 0.6393 0.3999 0.6391 0.3764 0.5193 0.7597 0.4345 0.7145 0.4365 0.6523 0.5753 0.6703 0.6394 0.4999

Table 4.4: FSIM for the proposed and other three state-of-the-art tone-mapping methods for Debevec's database. Image # 1 2 3 4 5 6 7 8 9 10 11 12 13 Proposed 0.4183 0.6729 0.5978 0.3546 0.2575 0.7196 0.3488 0.5509 0.5529 0.7162 0.3975 0.4496 0.6781 Durand 0.5661 0.6606 0.5806 0.5776 0.3601 0.7116 0.3666 0.5368 0.5508 0.6995 0.3733 0.6207 0.6461 Fattal 0.7601 0.5942 0.7942 0.8936 0.6062 0.7190 0.3541 0.5125 0.5349 0.7097 0.4943 0.6323 0.6733 Mantiuk 0.8801 0.5680 0.4959 0.4843 0.3487 0.7189 0.3383 0.5199 0.5517 0.6517 0.3588 0.5862 0.5918

Table 4.5. Percentage of highest FSIM scores for the tested images. Database EMPA RIT MCSL Debevec's Overall Proposed 35% 70% 47% 56% Durand 10% 5% 1% 6% Fattal 50% 20% 47% 33% Mantiuk 5% 5% 5% 5%

58

4.4.3 Edge Strength Based Similarity Index Matrix (ESSIM) Results For edge strength assessment, another quality assessment metric was tested using the Edge Strength based Similarity Index Matrix (ESSIM). It was proposed by Zhang et al. [60] for image quality assessment and was based on comparing the edge similarity between test image and the reference image. The reference was the original HDR image and the test image was the tonemapped image for each assessment. Proposed method provided excellent results in preserving edges for the tested method. Fattal's TMO and Mantiuk's TMO provided lower number of higher scores for all the tested images. Durand's method had the lowest edge preserving capability than the other three methods. This observation also proves that the guided filter has more edge preserving capability than the bilateral filter. Table 4.6 presents the percentage of the highest ESSIM score for all the tested images for 4 methods.
Table 4.6. Percentage of highest ESSIM scores for the tested images. Database EMPA RIT MCSL Debevec's Overall Proposed 97% 48% 97% 70% Methods Durand 1% 8% 1% 5% Fattal 1% 26% 1% 15% Mantiuk 1% 18% 1% 10%

4.5 Subjective Quality Assessment 20 images with variations of exposures and saliency regions were randomly selected for subjective quality assessment. Figure 4.10 presents the resultant tone-mapped images from the proposed method and 4 other state-of-the-art TM methods of the tested images. Among the 4 TM methods, three were same as the ones selected for objective quality assessments. The 5th method was Reinhard et al. [37] proposed TM method. It is a popular and widely used tonemapping method. The detailed description of this method is provided in Chapter 2 (Section 2.4.2). Two types of subjective tests were accomplished. One was testing on different screens or monitors, and the other was on a fixed calibrated screen. For the subjective quality assessment study, the method names were not mentioned to the viewers for unbiased results. Table 4.7 shows the names of the methods used for different images in Figure 4.10.
59

2

3

4

Figure 4.10: 20 images selected for subjective study using 5 different TMO's including the proposed method. The method names were not mentioned to the viewers for unbiased results.

60

Figure 4.10 (continue): 20 images selected for subjective study using 5 different TMO's including the proposed method. The method names were not mentioned to the viewers for unbiased results.

61

Figure 4.10 (continue): The 20 images selected for subjective study using 5 different TMO's including the proposed method. The method names were not mentioned to the viewers for unbiased results.

62

Table 4.7: The names of the methods for the images shown in Figure 4.12. Images for subjective study 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Method (a) Durand's Mantiuk's Proposed Reinhard's Fattal's Durand's Proposed Mantiuk's Fattal's Reinhard's Durand's Mantiuk's Proposed Reinhard's Fattal's Durand's Proposed Mantiuk's Fattal's Reinhard's Method (b) Proposed Fattal's Fattal's Manituk's Proposed Mantiuk's Fattal's Durand's Reinhard's Durand's Proposed Fattal's Fattal's Manituk's Proposed Mantiuk's Fattal's Durand's Reinhard's Durand's Method (c) Fattal's Proposed Durand's Durand's Mantiuk's Proposed Durand's Reinhard's Proposed Mantiuk's Fattal's Proposed Durand's Durand's Mantiuk's Proposed Durand's Reinhard's Proposed Mantiuk's Method (d) Reinhard's Durand's Mantiuk's Fattals's Durand's Reinhard's Mantiuk's Fattal's Durand's Fattal's Reinhard's Durand's Mantiuk's Fattals's Durand's Reinhard's Mantiuk's Fattal's Durand's Fattal's Method (e) Mantiuk's Reinhard's Reinhard's Proposed Reinhard's Fattal's Reinhard's Proposed Mantiuk's Proposed Mantiuk's Reinhard's Reinhard's Proposed Reinhard's Fattal's Reinhard's Proposed Mantiuk's Proposed

4.5.1 Results for Images Viewed on Various Screens 58 observers were asked to rank five tone-mapped images of each scene (total 20 scenes) from 1 to 5 based on the naturalness of the image with maximum details preserving capability. Rank 1 was for the best image and Rank 5 was for the worst image. The test was taken on different platforms and on a calibrated monitor. The monitor of an ASUS Republic of Gamers laptop was calibrated using the i1-Profiler by X-rite software with an X-rite calibrating tool. All the scores were averaged for each method. Figure 4.11 shows the average scores for the five methods including the proposed method. Comparing to the other, the proposed method was found to provide lower ranking for most of the scenes (average 2.7), indicating better naturalness and details preserving capability of the proposed method.

63

Proposed 4

Durand

Fattal

Mantiuk

Reinherd

3

Average Score

2

1

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Test images

Figure 4.11: Subjective study results showing average scores of 58 observers for the five methods. Lower score represents better results as the viewer labeled the best image with 1 and worst with 5.

4.6 Chapter Summary Key results and analyses of these observations are presented in this Chapter. The HDR saliency maps using both the modified low-resolution and high-resolution saliency detection methods are included. Transformation of an HDR image to tone-mapped image at different stages of the proposed method are shown as well. The effects of the radius of window and saturation values have been presented along with the explanation on selecting particular values for these parameters. The last part of this Chapter includes the quality assessment results using three different quality matrices based on structural similarity and edge strength. Two different subjective assessments' resulting scores are also summarized.

64

Chapter 5 CONCLUSIONS AND RECOMMENDATIONS
5.1 General This chapter presents chapter-wise summary of the Chapters 2, 3, and 4, key findings and contributions of this research work, and the recommendations for future work. 5.2 Chapter-wise Summary 5.2.1 Chapter 2: Literature Review a) A comprehensive literature survey on Human Visual System, saliency detection methods, and HDR image tone-mapping, were included. b) Various saliency detection methods and tone-mapping methods that were used in this thesis work were presented with detail explanation and comparison. c) Explanation of the workflow of various filters used in the proposed method along with their advantages and disadvantages were summarized. d) The procedures of the quality assessments used for testing the proposed method were explained. 5.2.2 Chapter 3: Method Development a) The flowchart showing the workflow of the proposed tone-mapping algorithm and the method were described in detail. In addition, the modifications made to existing saliency methods for application in HDR images were presented. b) Each step of the proposed saliency based tone-mapping algorithm using both high and low resolution saliency information was explained and demonstrated. The guided filter algorithm and how it was applied for tone-mapping was also explained.

65

5.2.3 Chapter 4: Results and Analysis a) The proposed tone-mapping algorithm was implemented on HDR images of three different datasets (RGBE format). Both high and low resolution saliency detection methods were modified for HDR images in a way to make it applicable in the proposed tone-mapping method. b) The differences between using high-resolution saliency maps and low-resolution saliency maps for tone-mapping were shown with resultant tone-mapped images. c) The transformation of raw HDR images to tone-mapped images, through various stages of the proposed tone-mapping method were presented. Separation of the detailed and base layers from the luminance image, was the major step in the tone-mapping algorithm. The difference between tone-mapped results with and without saliency map was shown. d) The effects of the change in radius of window of the guided filter were shown. In addition, the effects of change in saturation parameter in the proposed method were also included. These resulted the selection of suitable radius and saturation parameter in tone-mapping method for the dataset used. e) Three objective quality matrices were used to assess the quality of the resultant images. These were the structural similarity based, feature based and edge strength based matrices. The results of the proposed method were compared with the results of other state-of-the-art tone-mapping methods. The proposed method contributed to higher scores (i.e., better) for edge strength based methods. f) A subjective quality assessment results were collected for 20 image sets, each set having 5 different tone-mapped versions of an original HDR image. One version of the tonemapped images in a set was the resultant of the proposed method; whereas, the other four were results of four existing state-of-the-art tone-mapping methods. The results were ranked on the basis of naturalness with maximum details preserved. For the surveys, the images were viewed on various screens (i.e., various screens and platforms) and on one calibrated monitor, and ranked. g) The proposed method provided the best results among the tested five tone-mapping methods for the subjective quality assessment.
66

5.3 Contributions: Key Findings and Important Discovery This work contributes to the HDR tone-mapping image processing area. The specific contributions are: a) A new saliency guided edge preserving technique for HDR image tone-mapping was developed. This thesis provides the detailed explanation on how the saliency information can be used in HDR tone-mapping in a simpler manner. From the resultants of using lowresolution and high-resolution saliency map in the proposed algorithm, it was found that edges were preserved better with the high-resolution saliency map; and therefore, highresolution saliency map should be preferred as the guidance image. b) A novel exposure value selection equation was developed, and it worked well for the tested HDR images. The saturation value of 0.5 preserved the naturalness of the tested images while used in the proposed method. This value, however, can be changed if the naturalness is not the prime requirement for the viewers. c) The proposed saliency based tone-mapping method resulted high score percentage than three other state-of-the-art TM methods (Durand's, Fattal's and Mantiuk's TMO) while the resultant images were tested using three different objective quality matrices, which were structural similarity based, feature based and edge strength based matrices. d) In the subjective quality assessments, where the results were viewed in different screens and platforms, and on a single calibrated screen, the proposed saliency based tonemapping method provided better results as compared to four selected state-of-the-art TM methods (Durand's, Fattal's, Mantiuk's and Reinhard's TMO). The survey was completely unbiased and the results proved that the HVS consideration by using saliency was a success.

67

5.4 Recommendations for Future Work Some recommendations for the future work are listed below: 1. The method can be expanded to HDR rendering, HDR video, and in developing saliency inspired quality assessment method. 2. The saliency based tone-mapping approach can be optimized for application in cellular phones or mobile devices. HDR option has become a very common option in current cellular phones and devices, which take maximum of three different exposed images and merge to one using display adaptive tone-mapping. The current HDR image processing in cellular phones does not account for the salient regions. Therefore, the saliency based tone-mapping operation in cellular phones and mobile devices would increase the display quality of the HRD images. 3. The saturation parameter in the proposed method was a weight to provide the natural look for the images and this was selected based on trial and error with several datasets. However, for few HDR images the selected saturation parameter contributed to a blunt look. Therefore, a robust saturation parameter selection method can be developed and implemented with the proposed tone-mapping method. 4. The quality and comparative assessments of the proposed method were conducted using images from some existing datasets. A new database of HDR images can be established with newly created HDR images of a wide variation of scenes. The current work can be extended by using the newly created HDR datasets. Saliency can also be used to render the HDR images from different exposed raw images.

68

REFERENCES
[1] Gustave Le Gray: 1820 ­ 1884, Sylvia Aubenas, Getty Publications, 2002. [2] R. K. Chaurasiya, K. R. Ramakrishnan, "High Dynamic Range Imaging", International Conference on Communication Systems and Network Technologies, pp. 83-89, 2013. [3] E. Reinhard, G. Ward, S. Pattanaik, P. Debevec, "High Dynamic Range Imaging: Acquisition, Display and Image-Based Lighting", Morgan Kau_man, 2005. [4] P. E. Debevec, "Recovering High Dynamic Range Radiance Maps from Photographs", SIGGRAPH '97, pp. 1-10, 1997. [5] C. Cheng, O. C. Au, N. Cheung, C. Liu, K. Yip, "High Dynamic Range image capturing by Spatial Varying Exposed Color Filter Array with specific De Mosaicking Algorithm", IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, pp. 648 ­ 653, 2009 [6] D. C. H. Schleicher, B. G. Zagar, "High Dynamic Range Imaging by Varying Exposure Time, Gain and Aperture of a Video Camera", IEEE Instrumentation and Measurement Technology Conference (I2MTC), pp. 486 ­ 491, 2010. [7] Y. Piao, W. Xu, Y. Piao, "Method of Auto Multi-Exposure for High Dynamic Range Imaging", International Conference on Computer, Mechatronics, Control and Electronic Engineering (CMCE), vol.6, pp. 93 ­ 97, 2010. [8] J. Kaftan, "Wavelet Based Denoising by Correlation Analysis for High Dynamic Range Imaging", IEEE conf. on Image Processing, pp. 3857 ­ 3860, 2009. [9] J. Lee, "Tone-mapping Using Color Correction Function and Image Decomposition in High Dynamic Range Imaging", IEEE Trans. On Consumer Electronics, Vol. 56, pp. 2772-2780, 2010. [10] H. Kong, "Comparative Study Using SNR and Detail Loss CRITERIA "Jens N. Kaftan, André ´ Institute of Imaging and Computer Vision, RWTH Aachen University, 3149-3152, 2010. [11] Y. Heo, "Ghost-Free High Dynamic Range Imaging", proc. ACCV, pp. 486 ­ 500, 2010. [12] D. Lee, "Improved histogram based ghost removal in exposure fusion for high dynamic range images", Proceedings of the International Symposium on Consumer Electronics, ISCE, pp. 586 ­ 591, 2011. [13] Y. Moon, "A simple ghost-free exposure fusion for embedded HDR imaging", Digest of Technical Papers - IEEE International Conference on Consumer Electronics, pp. 9 -10, 2012. [14] J. Hu, "HDR Deghosting: How to Deal with Saturation?", 2013 IEEE Conference on Computer Vision and Pattern Recognition, pp. 1163 ­ 1170, 2013. 69

[15] L. Itti, "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis", Pattern Analysis and Machine Intelligence, Vol. 20, Issue. 11, PP 1254 ­ 1259, 1998. [16] Y. Mei, "Saliency modulated high dynamic range image tone-mapping", 2011 Sixth International Conference on Image and Graphics, pp. 22 ­ 27, 2011. [17] A. Patel, "LDR Image from HDR by Using Fast and Saliency Based Tone-Mapping Algorithm: A Review", IJSPR, pp. 85 ­ 90, 2015. [18] Z. Li, "Visual-Salience-based tone-mapping for high dynamic range imaging," IEEE Transactions on Industrial Electronics, Vol. 61, Issue. 12, PP. 7076-7082, 2014. [19] K. He, J. Sun, X. Tang, "Guided Image Filtering", IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.35, Issue: 6, pp. 1397 ­ 1409, 2013. [20] K. Sivakumar, CS 445, Lecture2, Washington State University. [21] R. L. Myers, "Human Visual System", Chapter 2 in Display Interfaces: Fundamentals and Standard, John Wiley & Sons, Ltd., 2003. [22] M. S. Landy, "Weber's Law and Fechner's Law" New York University, handouts for Course 0044. Website visited on December 28, 2016. Website: http://www.cns.nyu.edu/~msl/courses/0044/handouts/Weber.pdf [23] L. Zhang, W. Lin, "Selective Visual Attention, computation model and applications", Wiley, IEEE press, 2013. [24] E. W. Yund, J. C. Armingtor, "Color and brightness contrast effects", Vision Res., Vol. 15, PP. 917929, Pergamon Press, 1975. [25] C. Wing, H. Ngau, L. Ang, "Bottom-up visual saliency map using wavelet transform domain", Image (Rochester, N.Y.), 2010. [26] S. Gofeman, L. Zelnik-Manor, A. Tal, "Context-aware saliency detection", IEEE transactions on pattern analysis and machine intelligence, Vol 34, PP. 1915-26, 2012. [27] X. Hou, "Saliency detection: A spectral residual approach", Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Issue 800, PP. 1-8, 2007. [28] R. Achantay, "Frequency-tuned salient region detection", 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops, PP. 1597 ­ 1604, 2009. [29] T. N. Vikram, ""A random center surround bottom up visual attention model useful for salient region detection", IEEE workshop on Application of Computer Vision (WACV), pp. 166 ­ 173, 2011. [30] Y. Saber, "High Resolution Biologically Inspired Salient Region Detection", PP. 649 ­ 652, 2011. [31] W. Lawton, "Applications of wavelets to image coding", Sixth Multidimensional Signal Processing Workshop, 1989. 70

[32] E. Reinherd, "Parameter estimation for photographic tone reproduction", Journal of Graphics Tools, vol. 7, Issue 1, pp. 45 ­ 51, 2002. [33] J. Tumblin, "Tone reproduction for realistic images", IEEE Computer Graphics and Applications, vol. 13, pp. 42 ­ 48, 1993. [34] M. Ashikhmin, "A tone-mapping algorithm for high contrast images", Proc. Eurographics Workshop on Rendering, P. Debevec and S. Gibson Eds., pp. 1 ­ 11, 2002. [35] F. Drago, "Adaptive logarithmic mapping for displaying high contrast scenes", Computer Graphics Forum, vol. 22, Issue 3, pp. 419 ­ 426, 2003. [36] R. Fattal, "Gradient domain high dynamic range compression", 29th annual conference on Computer graphics and interactive techniques, pp. 249- 256, 2002. [37] E. Reinhard, "Parameter estimation for photographic tone reproduction", Journal of Graphics Tools, vol. 7, Issue 1, pp. 45 ­ 51, 2002. [38] J. Tumblin, "Tone reproduction for realistic images", IEEE Computer Graphics and Applications, vol. 13, pp. 42 ­ 48, 1993. [39] F. Durand, "Fast bilateral filtering for the display of high dynamic-range images", ACM Transactions on Graphics, vol. 21, Issue. 3, pp. 257 ­ 266, 2002. [40] R. Mantiuk, "Display Adaptive Tone-mapping", SIGGRAPH, Vol. 27, Issue 3, 2008. [41] L. Meylan, "Tone-mapping for High Dynamic Range Images", PhD thesis, EPFL, Vol. 3588, 70767082, 2006. [42] C. Tomasi, "Bilateral Filtering for Gray and Color Images", IEEE Int. Conf. on Computer Vision, 1998. [43] J. Lee, G. Jeon, J. Jeong, "Piecewise Tone Reproduction for High Dynamic Range Imaging", IEEE Transactions on Consumer Electronics, vol. 55, pp. 911 ­ 918, 2009. [44] R. Revathi, T. kavitha, "Generate an Artifact-free High Dynamic Range Imaging", IEEE International Conference on Signal and Image Processing, pp. 63-68, 2010. [45] W. Yao, Z. G. Li, S. Rahardja, "Intensity Mapping Function Based Weighted Frame Averaging for High Dynamic Range Imaging", 6th IEEE Conference on Industrial Electronics and Applications (ICIEA), pp. 1574 ­ 1577, 2011. [46] Z. Mai, H. Mansour, R. Mantiuk, P. Nasiopoulos, R. Ward, W. Heidrich, "Optimizing a Tone Curve for Backward-Compatible High Dynamic Range Image and Video Compression", IEEE Transactions on Image Processing, vol. 20, pp. 1558 ­ 1571, 2011. [47] P. Kovesi, "Phase Preserving Tone-mapping of Non-Photographic High Dynamic Range Images", IEEE International Conference on Digital Image Computing Techniques and Applications, pp. 1-8, 2012. 71

[48] S. V. Lakshmi, J. Janet, Sujatha, T. Bellarmine, "Analysis of Tone-mapping Operators on High Dynamic Range Images", Proceedings of IEEE Southeastcon, pp. 1-6, 2012. [49] M. Narwaria, M. P. Da Silva, P. Le Callet, R. Pepion, "Adaptive Contrast Adjustment for Postprocessing of Tone Mapped High Dynamic Range Images", IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1103 ­ 1106, 2013. [50] J. Huang, V. Rampersad, S. Mann, "High Dynamic Range Tone-mapping Based On Per-Pixel Exposure Mapping", IEEE International Symposium on Technology and Society, pp. 98 ­ 106, 2013. [51] S. K. Thakur, M. Sivasubramanian, N. Krishnan, M. Karthikeyan, N. Vishwanath, "Fast Tonemapping for High Dynamic Range Images", IEEE International Conference on Computational Intelligence and Computer Research, pp. 1-4, 2013. [52] J. Herwig, M. Sobczyk, J. Pauli, "Tone-mapping for single-shot HDR imaging", International Conference on Computer Vision Theory and Applications, 2014. [53] C. Yaacoub, C. Yaghi, C. Bou-Rizk, "Fusion Of Tone-Mapped High Dynamic Range Images Based On Objective Range-Independent Quality Maps", IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 1195 ­ 1199, 2014. [54] Z. Wei, C. Weu, Z. Li, "Local Inverse Tone-mapping for scalable High Dynamic Range Image coding", IEEE Trans. On Circuits and Systems for video Technology, Issue. 99, PP. 1 ­ 1, 2016. [55] W. Fan, G. Valenzise, F. Benterle, "Forensic detection of inverse tone-mapping in HDR images" IEEE Conf. on Image Processing, PP. 1-6, 166 ­ 170, 2016. [56] P. Kuo, C. Tang, S. Chien, "Content-adaptive inverse tone-mapping", Visual Communications and Imag Processing, PP. 1-6, 2012. [57] E. S. L. Gastal and M. M. Oliveira, "Domain Transform foe edge-aware image and video processing", ACM Trans. Graphics, vol. 30, pp. 1-12, 2011. [58] K. Ma, H. Yeganeh, K. Zeng, Z. Wang, "High Dynamic Range Image Tone-mapping by Optimizing Tone Mapped Image Quality Index", IEEE International Conference on Multimedia and Expo (ICME), pp. 1-6, 2014. [59] L. Zhang, "FSIM: A Feature Similarity Index for Image Quality Assessment", IEEE Transactions on Image Processing, Vol. 20, PP. 2378 ­ 2386, 2011. [60] X. Zhang, "Edge Strength Similarity for Image Quality Assessment", IEEE Signal Processing Letters, Vol. 20, PP. 319 ­ 322, 2013. [61] EMPA Media Technology, HDR database, 2011-2013. Website visited on Oct 31st, 2016. Website: http://www.empamedia.ethz.ch/hdrdatabase/. [62] RIT MCSL High Dynamic Range Image database. Website visited on Oct 31st, 2016. Website: http://www.cis.rit.edu/research/mcsl2/icam/hdr/rit_hdr/ 72

[63] P. E. Debevec, Senior Staff Engineer, Google VR, Adjunct Research Professor, USC computer science, Website visited on Oct 31st, 2016. Website: http://www.pauldebevec.com/ [64] G. Ward, "A visibility matching tone reproduction operator for high dynamic range scenes", IEEE Transactions on Visualization and Computer Graphics, vol. 3, Issue: 4, pp. 291 ­ 306, 1997. [65] Z. N. Hossein, "FSITM: A Feature Similarity Index for Tone mapped images", IEEE Signal Processing Letters, Vol: 22, PP. 1026 ­ 1029, 2015.

73


