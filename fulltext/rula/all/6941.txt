Rearrangement Algorithm in Risk Aggregation by Alex Thomas B.Sc. (Honours), University of Toronto, 2014 A thesis presented to Ryerson University in partial fulfilment of the requirements for the degree of Master of Science in the program of Applied Mathematics

Toronto, Ontario, Canada, 2017

©

Alex Thomas, 2017

DECLARATION I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis, including any required final revisions, as accepted by my examiners.

I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my thesis may be made electronically available to the public.

ii

ABSTRACT Rearrangement Algorithm in Risk Aggregation Alex Thomas, Master of Science, Applied Mathematics, 2017, Ryerson University Sometimes there's no closed-form analytical solutions for the risk measure of aggregate losses representing, say, a company's losses in each country or city it operates in, a portfolio of losses subdivided by investment, or claims made by clients to an insurance company. Assuming there's enough data to assign a distribution to those losses, we examine the Rearrangement Algorithm's ability to numerically compute the Expected Shortfall and Exponential Premium Principle/Entropic Risk Measure of aggregate losses. A more efficient discretization scheme is introduced and the algorithm is extended to the Entropic Risk Measure which turns out to have a smaller uncertainty spread than the Expected Shortfall at least for the cases that we examined.

iii

ACKNOWLEDGMENTS I'd like to express my effusive gratitude to all the members of staff in Ryerson's Mathematics department ­ administrators, professors, and support ­ for their conviviality and cordiality throughout my two years here, all the lecturers I had during my graduate course studies for their superlative pedagogy, and my supervisor, Dr. Foivos Xanthos, for his ubiquitous support and encouragement in writing my thesis.

iv

TABLE OF CONTENTS

Declaration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ii iii iv

List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x x 3 3 4 7 10 10 13 15 22 22 29 29

List of Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Risk Measures 1.1 1.2 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Coherent and Convex Risk Measures . . . . . . . . . . . . . . . Value-at-Risk and Expected Shortfall . . . . . . . . . . . . . . . Entropic Risk measure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 Risk Aggregation 2.1 2.2 2.3

Convex Order . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Aggregate Losses . . . . . . . . . . . . . . . . . . . . . . . . . . . Analytical Solutions for the Homogeneous case . . . . . . . . .

3 Rearrangement Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 3.1 3.2 Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Numerical Results . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 Homogeneous Risk Aggregation . . . . . . . . . . . . . .

v

3.3 3.4 3.5

Uncertainty Spread for the Expected Shortfall . . . . . . . . . Non-Homogeneous Cases . . . . . . . . . . . . . . . . . . . . . . Project . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

35 38 40 47 47 59

Appendix

A MATLAB Code Bibliography

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

vi

LIST OF TABLES

3.1

Sharp lower bounds on the ES for the sum of d = 3 random variables all being Exp( = 2). . . . . . . . . . . . . . . . . . . 30

3.2

Sharp lower bounds on the ES for the sum of d = 3 random variables all being Exp( = 4). . . . . . . . . . . . . . . . . . . 30

3.3

Sharp lower bounds on the ES for the sum of d = 3 random variables all being Pareto( = 2). . . . . . . . . . . . . . . . . . 31

3.4

Sharp lower bounds on the ES for the sum of d = 3 random variables all being Pareto( = 4). . . . . . . . . . . . . . . . . . 31

3.5

Sharp lower bounds on the ES for the sum of d = 56 random variables all being Pareto( = 2). We can see that 'SIM' scheme provides a much closer approximation than the 'PUC' scheme in all cases. Here RE stands for relative error. . . . . . 32

3.6

Sharp lower bounds on the ES for the sum of d = 4 random variables all being N (0, 1). . . . . . . . . . . . . . . . . . . . . . 32

3.7

Sharp lower bounds on the Entropic Risk Measure for the sum of d = 3 random variables all being Exp(). . . . . . . . . . . . 33

3.8

Sharp lower bounds on the Entropic Risk Measure for the sum of d = 4 random variables all being Exp(). . . . . . . . . . . . 33

3.9

Sharp lower bounds on the Entropic Risk Measure for the sum of d = 5 random variables all being Exp(). . . . . . . . . . . . 34

3.10 Sharp lower bounds on the EN for the sum of d = 4 random variables all being N (0, 1). . . . . . . . . . . . . . . . . . . . . . 34

vii

3.11 ES dependence range for the sum of d = 7 random variables having distributions L1  P areto(5), L2  P areto(7), L3  Exp(2), L4  Exp(4), L5  N (1, 3), L6  N (1, 4), L7  N (2, 5) when  = 0.99. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.12 EN and ES dependence range for the sum of d = 5 random variables having distributions L1  Exp(3), L2  Exp(5), L3  Exp(7), L4  Exp(8), L5  Exp(9) when  = 0.99. . . . . . . . 39 39

viii

LIST OF FIGURES

3.1

'PUC' discretization (left) versus 'SIM' discretization (right) empirical distribution approximations of a Pareto(2) CDF for n=8. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

3.2

'PUC' discretization (left) versus 'SIM' discretization (right) empirical distribution approximations of a Pareto(2) CDF for n=24. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

3.3

Uncertainty spread of the Expected Shortfall for 3 losses all Exponential(2) distributed as  is varied. . . . . . . . . . . . . 36

3.4

Uncertainty spread of the Expected Shortfall for 3 losses all Pareto(2) distributed as  is varied. . . . . . . . . . . . . . . . 37

3.5

Uncertainty spread and Gaussian of the Expected Shortfall for the 5 stocks using the 'SIM' discretization. ES 0.99 (L+ ) is in blue, Gaussian is in green, and ES0.99 (L+ ) is in red. . . . . . . 41

3.6

Uncertainty spread of the Entropic Risk Measure for the 5 stocks using the 'SIM' discretization. ent (L+ ) is in blue, 42 Gaussian is in green, and ent (L+ ) is in red. . . . . . . . . . . .

3.7

Amalgamation of both uncertainty spreads and the Gaussians for visual comparison all using the 'SIM' discretization. Expected Shortfall related loss metrics are in red and Entropic Risk Measure related loss metrics are in blue. . . . . . . . . . . 43 44 45

3.8 3.9

Adjusted closing price of each stock for each day. . . . . . . . Plot of the sum of all losses for each day. . . . . . . . . . . . .

ix

3.10 Plot of the uncertainty spreads for both risk measures. Entropic in blue and ES in red. . . . . . . . . . . . . . . . . . . . . 46

x

Introduction Often in practice we wish to calculate the risk measure (L+ ) of an aggregate sum of losses, L+ = L1 + ... + Ld , representing, say, a company's losses subdivided by geography or portfolio losses subdivided by different investments. By using historical data from each loss, Li , one can assign a distribution Fi to each Li . Then the class of aggregate losses is described as follows. A(F1 , ..., Fd ) = {L+ = L1 + ... + Ld Li  Fi } Given only this information, it's not possible to calculate (L+ ) as we are uncertain about the dependence between the Li 's. The following are the extreme values of (L+ ): (L+ ) = inf {(L+ ) L+  A(F1 , ..., Fd )}

(L+ ) = sup{(L+ ) L+  A(F1 , ..., Fd )} The interval [(L+ ), (L+ )] is called the uncertainty spread of . So when we are uncertain about the dependence of L i s one would like to use a risk measure  that has the smallest possible uncertainty spread. It turns out that the calculation of (L+ ), (L+ ) is a deep mathematical problem and analytical solutions are known only for some special cases. The Rearrangement Algorithm is a probabilistic numerical method that estimates these values. This method has been extensively used to calculate the uncertainty spread of the Value at Risk and the Expected Shortfall for various scenarios (see e.g. [1, 7, 5, 2]). 1

The aim of this thesis is to give modified versions of the Rearrangement Algorithm that can be used for the calculation of ES  (L+ ) and ent (L+ ), where ent is the Entropic Risk Measure. In Chapter 1, we give the definition and the main properties of ES and ent . In Chapter 2, we give analytical solutions for the upper bounds, ES  (L+ ) and ent (L+ ), and for the lower bounds in some special cases. In chapter 3, we present the Rearrangement Algorithm and numerical results for different choices of Fi . From our results it follows that the uncertainty spread of ent is smaller than ES0.99 at least for the particular cases we analysed and that the new discretization scheme we introduced here for the calculation of ES  (L+ ) is much more efficient than the one introduced in [5] when we work with heavy tailed distributions, large , and a large number of losses. In chapter 4, we outline our main MATLAB codes.

2

Chapter 1

RISK MEASURES

1.1

Coherent and Convex Risk Measures

In this section we will present an axiomatic theory of risk measures. The premise of this approach is to identify the essential properties that a reliable risk measure should possess. For the following we will fix a linear subspace M of the space L0 (, F ) of all random variables on (, F ). The space M is our model of all the possible portfolio losses L in the market. We assume here that M contains constants, which represent portfolios with predictable profits (e.g. backing capital). The risk measure  is defined as a map   M  R. Axiom I(Monotonicity): For L1 , L2  M such that L1  L2 (i.e. L1 ( )  L2 ( ) for each   ), we have (L1 )  (L2 )). From an economic point of view this axiom is obvious: positions that lead to higher losses in every state of the world require more risk capital. Axiom II(Translation invariance): For all L  M and l  R we have that (L + l) = (L) + l. The translation invariance axiom states that by adding or subtracting a deterministic quantity l to a position leading to the loss L, we alter our capital requirement by exactly that amount. Axiom III(Subadditivity): For all L1 , L2  M we have (L1 + L2 )  (L1 ) + (L2 ) 3

Subadditivity reflects the idea that risk can be reduced by diversification, a time-honoured principle in finance and economics. Axiom IV(Positive homogeneity): For all L  M and   0 we have (L) = (L) Positive homogeneity is the requirement that equality should hold in Axiom III if there is no diversification between losses in the portfolio (e.g. (L + L) = 2(L)). Axiom V(Convexity): For all L1 , L2  M and   (0, 1) we have (L1 + (1 - )L2 )  (L1 ) + (1 - )(L2 ) Convexity can be regarded as a relaxation of assumptions III and IV. Definition 1.1. A risk measure   M  (-, ] is called coherent if it satisfies Axioms I-IV and convex if it satisfies Axioms I,II and V. 1.2 Value-at-Risk and Expected Shortfall

Two of the most widely used risk measures by financial institutions include Value-at-Risk and its average over some confidence level  called the Expected Shortfall. It is well-known that the Expected Shortfall is a coherent risk measure and Value-at-Risk fails axioms III and V. To set up our framework, consider the portfolio loss L at the end of some fixed time horizon t. Definition 1.2. Given some confidence level   (0, 1), the VaR of a portfolio at the confidence level  is given by the smallest number l such that the probability that the loss L exceeds l is no larger than 1 - . Mathematically,

4

VaR (L) = inf {l  R P (L > l)  1 - } = F -1 () Proposition 1.3. Suppose that L  N (µ,  2 ) then VaR (L) = µ +  -1 () Proof. Let F be the cdf of L, we will show that F (µ +  -1 ()) = . Indeed, P (L  µ +  -1 ()) = P ( L-µ  -1 ()) = (-1 ()) =  

In particular for N (0, 1) the VaR0.95 = 1.645, this means that there is 95% chance that we will lose at most this amount.

Definition 1.4. Let L be a loss distribution with E ( L ) < . The expected shortfall at confidence level   (0, 1) is defined as ES (L) = 1 1-
1 

VaRu (L)du

In the case where L follows a continuous distribution, the Expected Shortfall can be calculated by the following formula ES (L) = E (L L  VaR (L)) 5

Proposition 1.5. Suppose that L  N (µ,  2 ). Then ES (L) = µ +  (-1 ()) , 1-

where  is the density function of the standard normal distribution. ~= Proof. Let L
L-µ  ,

~  N (0, 1) and by Proposition 1.3 and the above then L (-1 ()) 1-

conditional expectation formula we have that ~) = ES (L 1 1-
 -1 ()

l(l)dl =

1 - (l) 1-

 -1 ()

=

~ + µ) and since ES is a coherent risk Now we have that ES (L) = ES ( L measure by axiom II we get that ~) + µ = µ +  ES (L) = ES (L (-1 ()) 1-

We recall here that a random vector L = (L1 , ..., Ld ) is comonotonic, whenever there exists a random variable X and increasing functions fi such that Li = fi (X ). It turns out that both Value at Risk and Expected Shortfall are additive on comonotonic vectors. This is an important observation that will be used later. Theorem 1.6. ([4]) Let   (0, 1) and L = (L1 , ..., Ld ) be a comonotonic random vector. Then VaR (L1 + ... + Ld ) = VaR (L1 ) + ... + VaR (Ld ) Theorem 1.7. Let   (0, 1) and L = (L1 , ..., Ld ) be a comonotonic random vector. Then ES (L1 + ... + Ld ) = ES (L1 ) + ... + ES (Ld ) 6

Proof. By applying the prior theorem we get that ES (L1 + ... + Ld ) = 1 ( 1-
1 

1 1-
1 

1 

VaRu (L1 + ... + Ld )du =

VaRu (L1 )du + ... +

VaRu (Ld )du) = ES (L1 ) + ... + ES (Ld )

To estimate VaR(L), ES (L) for a loss L with unknown distribution we will use a data set {~ l1  ...  ~ lN } with large N drawn from L and use the following estimators. More details on the derivation of these formulas can be found in [4]. VaR = ~ lj , where j = N (1 - ) + 1 1 ES = N (1 -  ) 1.3 Entropic Risk measure
N (1-)

~ li
i=1

Also known as the Exponential Premium Principle, this risk measure is used in the insurance industry to calculate premiums. Definition 1.8. (Entropic Risk Measure) Given the exponential utility function given by u(x) = 1 - exp(-x) the loss function is defined as l(x) = -u(-x) = -(1 - exp(x)). Assume moreover that M contains random variables L with E(exp(L)) < +. The acceptance set is defined to be the following set A = {L  M E (l(L))  l(0)} = {L  M E(exp(L))  1} 7

The derived risk measure ent is called the Entropic Risk Measure or the Exponential Premium Principle. The value of ent (L) corresponds to the minimum capital required to make our position acceptable. ent (L) = inf{m  R E(exp(L - m))  1} = inf {m  R E(exp(L))  exp(m)} = log (E(exp(L))) Proposition 1.9. Suppose that L  N (µ,  2 ) then 1 ent (L) = µ +  2 2 Proof. L  N (µ,  2 )  exp(L)  LogN ormal(µ,  2 )  1 1  E(exp(L)) = exp(µ +  2 )  log (E(exp(L))) = µ +  2 2 2 .

Theorem 1.10. The Entropic Risk Measure is convex, but not coherent. Proof. To show that it's convex we have to show that it satisfies axioms I, II, and V. I: Pick any L1 , L2  M such that L1  L2 . Since the exponential, expectation, and natural logarithms are all monotonically increasing we have that  exp(L1 )  exp(L2 )  E(exp(L1 ))  E(exp(L2 ))  log (E(exp(L1 )))  log (E(exp(L2 ))) 8

II: Pick any L  M and l  R. Then ent (L + l) = log (E(exp(L + l))) = log (E(exp(L))exp(l)) = log (E(exp(L))) + l = ent (L) + l

V: Show that for any L1 , L2  M and   (0, 1), ent (L1 + (1 - )L2 )  ent (L1 ) + (1 - )ent (L2 ). By definition ent (L1 + (1 - )L2 ) = min{m  R E(exp(L1 + (1 - )L2 - m))  1}  ent (L1 ) + (1 - )ent (L2 ) Indeed, note that E(exp(L1 + (1 - )L2 - ent (L1 ) - (1 - )ent (L2 ))) = E(exp((L1 - ent (L1 )) + (1 - )(L2 - ent (L2 )))) Since the exponential is a convex function and the expectation is additive then,  E(exp(L1 - ent (L1 ))) + (1 - )E(exp(L2 - ent (L2 )))   + (1 - ) = 1 Where the last inequality follows by definition of the Entropic Risk Measure. The Entropic Risk Measure fails axiom IV preventing it from being co1 ~ = 3L  N (0, 9 ) we have that ) and L herent. For instance, if L  N (0, 2 2

exp(L) follows a lognormal distribution and thus by the previous proposi1 tion 3(L) = 3 log(E (exp(L))) = 3(0 + 4 ) = 0.75. On the other hand we have

~ ) = log(E (exp(L ~ )) = 0 + 9 = 2.25  3(L). that (L 4

9

Chapter 2

RISK AGGREGATION

2.1

Convex Order

Definition 2.1. Let X and Y be two random variables with finite mean. X is smaller than Y in convex order, X CX Y, if for every convex function , E[(X )]  E[(Y )] whenever they are well-defined. Definition 2.2. Given a set of losses Li  Fi , the class A(F1 , ..., Fd ) = {L+ = L1 + ... + Ld Li  Fi for all i = 1, ..., d} is called the class of aggregate losses. Remark 2.3. If X CX Y , then E(X ) = E(Y ) and E(X 2 )  E(Y 2 ). The inequality is achieved by choosing  to be x2 in the above definition and the equality is achieved by choosing  to be x and -x. Indeed, by choosing ~(x) = -x, we have (x) = x, we have that E(X )  E(Y ) and by choosing  that E(-X )  E(-Y )  -E(X )  -E(Y )  E(X )  E(Y ). Proposition 2.4. (Levy and Kroll, p.553-574, 1978 [3]) X CX Y if and only if ES (X )  ES (Y ) and E(X ) = E(Y ) for all   (0, 1). Given the set of aggregate sums, A(F1 , ..., Fd ) = { 10
d i=1

Li Li  Fi },

we wish to find max{A(F1 , ..., Fd )} and min{A(F1 , ..., Fd )} with respect to CX .
-1 -1 Proposition 2.5. (p.96 [1]) max{A(F1 , ..., Fd )} = F1 (U )+...+Fd (U ) where

U  Unif(0, 1).
d -1 Proof. Since Fi-1 (U )  Fi for each i, d i=1 Fi (U )  A(F1 , ..., Fd ). Let i=1 Li  d -1 A(F1 , ..., Fd ). We will show that d i=1 Li CX i=1 Fi (U ). Indeed, by the

sub-additivity of ES we have that ES (
d i= 1

Li ) 

d i=1

ES (Li ) =

d i= 1

ES (Fi-1 (U )) = ES (

d i= 1

Fi-1 (U )),

where the last equality follows by the additivity of ES on the comonotonic
-1 -1 vector (F1 (U ), ..., Fd (U )) (see Theorem 1.7).

Proposition 2.6. (Ruschendorf, 1983 [6])

-1 -1 min{A(F1 , F2 )} = F1 (U ) + F 2 (1 - U )

The following example shows that if d > 2, min{A(F1 , F2 )} may not exist. Example 2.7. (Example 3.1 [1]) Let F1 be a discrete distribution on {0, 3, 8} with equal probability, F2 be a discrete distribution on {0, 6, 16} with equal probability, and F3 be a discrete distribution on {0, 7, 13} with equal probability. In our example, the sample space is divided into three disjoint subsets
1 . Let i  Ai , i = 1,2,3. We verify two A1 , A2 , A3 with equal probability 3

scenarios:

11

(a) First, consider the following dependence structure:

   L1 (1 ) L2 (1 ) L3 (1 ) 3       L ( ) L ( ) L ( ) = 0   1 2 2 2 3 2        L1 (3 ) L2 (3 ) L3 (3 ) 8    It is easy to verify that the distribution of Li is E[(L1 + L2 + L3 - 19)+ ] = 0; (b) Consider another dependence structure:

16

 0   6 13    0 7  Fi , i = 1,2,3. The dis-

tribution of L1 + L2 + L3 is on {19, 19, 15} with equal probability. Thus,

    L1 (1 ) L2 (1 ) L3 (1 ) 0 16 0          L ( ) L ( ) L ( ) = 3 0 13    1 2 2 2 3 2          L1 (3 ) L2 (3 ) L3 (3 ) 8 6 7      It is easy to verify that the distribution of Li is Fi , i = 1,2,3. The distribution of L1 + L2 + L3 is on {16, 16, 21} with equal probability. Thus, E[(16 - (L1 + L2 + L3 ))+ ] = 0. Note that both g (x) = (x - 19)+ and g (x) = (16 - x)+ are convex functions. Hence, if there exists a convex ordering minimal element S in A(F1 , F2 , F3 ), it must satisfy E[(S - 19)+ ] = 0 and E[(16 - S )+ ] = 0. However, we can see that when L1 = 8, no matter what values L2 and L3 take, S will be either > 19 or < 16. That means that E[(S - 19)+ ] = 0 and E[(16 - S )+ ] = 0 cannot be satisfied simultaneously by the same S  A(F1 , F2 , F3 ). This shows that the minimal element with respect to convex order does not exist. Proposition 2.8. E(d i=1 Li ) CX L for all L  A(F1 , ..., Fd ). 12

Proof. This follows by Jensen's Inequality: (E(L))  E((L)) for any convex funtion . Indeed, let L = d i=1 Li , Li  Fi and  a convex function, then we have that E((E(
d i=1

Li ))) = (E(

d i= 1

Li ))  E((

d i= 1

Li )).

d Therefore E(d i=1 Li ) CX i=1 Li since  is arbitrary.

2.2

Aggregate Losses

As a practical real-world problem, let's say that we wish to forecast the aggregate sum of a company's potential losses for d store locations in different cities or a portfolio of d stocks assuming that we have enough data to assign a distribution to each loss represented by Li . Knowing each marginal distribution does not allow us to know the joint distribution of their aggregate sum, L+ , with certainty as there's an infinitude of ways that the losses could interact with one another based on their dependencies meaning that we cannot compute (L+ ), where L+  A. So, we consider the set of possible joint distributions given each marginal distribution, A(F1 , ..., Fd ) or the class of aggregate losses, and we calculate its maximum value, (L+ ), the most that we could lose, and its minimum value, (L+ ), the least that we could lose. Analytical solutions always exist for the former value, but not the latter value. Of course, there are a plethora of possible risk measures we could use, but convex ones like the Expected Shortfall and Entropic Risk Measure work quite well here. Definition 2.9. Let  be a risk measure, then 13

(i) (L+ ) = inf {(L+ ) L+  A(F1 , ..., Fd )} is the least that we could lose. (ii) (L+ ) = sup{(L+ ) L+  A(F1 , ..., Fd )} is the most that we could lose. (iii) The interval [(L+ ), (L+ )] is called the uncertainty spread of . Moreover, risk and insurance experts are always looking for the 'best' measure of risk. Here, we'll consider the risk measure with the smallest uncertainty spread as the 'best'. That is, the measure with the smallest distance between the most and least that we could lose on an aggregate portfolio is the 'best' risk measure. The following example illustrates the role of dependence of risk factors in risk measurement. Example 2.10. Suppose that the aggregate loss of our portfolio is L+ = L1 +L2 and it is estimated that the risk factor changes L1 , L2 follow N (0, 1) and N (0, 4) respectively. With this information alone, we cannot calculate the VaR of L+ , we also need to determine the dependence of L1 and L2 . As the following calculations show our estimation for VaR change dramatically when we assume different dependence structures. (a) L1 , L2 are independent. Then L1 + L2 follows N (0, 5), therefore VaR0.99 (L+ ) =  5  -1 (0.99) = 5.2019

(b) L = (L1 , L2 ) is a comonotonic vector.

VaR0.99 (L+ ) = VaR0.99 (L1 ) + VaR0.99 (L2 ) = -1 (0.99) + 2  -1 (0.99) = = 6.9790 14

(c) Take L1 = Z, L2 = -2Z , then L+ = -Z and we have that

VaR0.99 (L+ ) = VaR0.99 (-Z ) = -1 (0.99) = 2.3263      0   1 -1      2 ). Then we have that L+  N (0, 4) (d) L = (L1 , L2 )  N2 (  ,     1   0   -2 4      and thus VaR0.99 (L+ ) = 2  -1 (0.99) = 4.6527. Dependence VaR0.99 (L+ ) 2.3 (a) 5.20 (b) 6.98 (c) 2.33 (d) 4.65

Analytical Solutions for the Homogeneous case

In this section we will calculate the analytical solutions for the bounds, ES  (L+ ), ES  (L+ ), ent (L+ ), ent (L+ ), of the class A(F, ..., F ), where F is a distribution function. This is the sod

called homogeneous risk aggregation problem. The results will be used later on in the Numerical Results section of Chapter 3 to compare our outputted solutions with. In the general case of non-homogeneous distributions (i.e. Fi  Fj ) the problem of finding analytical solutions for ES  (L+ ), ent (L+ ) turns out to be extremely difficult. In the next chapter we will present numerical solutions via the Rearrangement Algorithm for some special cases. For ES  (L+ ), ent (L+ ) the calculations can be carried out by applying Proposition 2.5. In the table below we calculate the values for different choices of F .

15

F

ES  (L+ )

ent (L+ )

Exp()

d 1 -

1  -  log (1 - u)du

1

log (0 ((1 - u)-  )du)  1 log (0 exp(d 2 2 erf -1 (2u - 1) + d  µ)du)

1

d

N (µ,  2 )

d 1-

1  (

 2 2 erf -1 (2u - 1) + µ)du

Pareto()

d 1-

1 1 - 1)du  ( (1-u) 

1

-

where erf -1 denotes the inverse of the error function given by erf (x) =
2  2 0 exp(-t )dt which requires computational software to compute. x

Theorem 2.11. ([4] See Prop 8.34 on p.307) ES  (L+ ) = where  =
1- d

1 

 0

(d - 1)F -1 ((d - 1)t) + F -1 (1 - t)dt

and Li  Fi for all i. (i) If F is the cdf of Exp(), then we have that 1 
 0

Corollary 2.12.

ES  (L+ ) =

-

1 (d - 1) log (1 - (d - 1)t) - log (t)dt  

(ii) If F is the cdf of Pareto() then we have that 1 
 0

ES  (L+ ) =

(d - 1)(

1 (1 - (d - 1)t)
1 

- 1) +

1 t
1

- 1dt

16

Proof. (i) Using the previous theorem and the inverse CDF of the exponential distribution we get that ES  (L+ ) = 1  1 = 
 0  0

(d - 1)F -1 ((d - 1)t) + F -1 (1 - t)dt - 1 (d - 1) log (1 - (d - 1)t) - log (t)dt  

(2.1) (2.2)

(ii) Using the previous theorem and the inverse CDF of the one-parameter variant of the Pareto distribution, namely F (x) = 1 - (1 + x)- for x > 0, we get that

ES  (L+ ) =

1  1 = 

 0  0

(d - 1)F -1 ((d - 1)t) + F -1 (1 - t)dt (d - 1)( 1 (1 - (d - 1)t)
1 

(2.3) (2.4)

- 1) +

1 t
1

- 1dt

Theorem 2.13. ([1] See section 3.3 on p.97) If F is defined on R+ , then we have that

U Ta = H ( )1U [0,da] + D(a)1U (da,1] CX L+ for each L+  A(F, ..., F ), d
d 1 ] such that H(x) is non-increasing on where U  U nif (0, 1), and a  [0, d

[0,a], and limxa- H (x)  D(a) where 17

H (x) = (d - 1)F -1 ((d - 1)x) + F -1 (1 - x)
(y ) D(a) = d (d-1)a F1-da dy 1-a
-1

In most practical cases, Ta as defined above turns out to be an element of A(F, ..., F ) and thus Ta = min{A(F, ..., F )}. For more details on this see
d d

[1]. Proposition 2.14. If F is the cdf of Exponential() and Ta is as in the previous theorem, then ent (Ta ) = log (
da 0

(1 -

(d - 1) -(d-1) u -1 u)  ( )  du d d

-d(1-(d-1)a) da d +(1 - da)exp( )a (1-da) (1 - (d - 1)a) (1-da) ) 

Proof. Recall that ent (Ta ) = log (E(exp(Ta ))).

U (d - 1) U H ( ) = (d - 1)F -1 ( U ) + F -1 ( 1 - ) d d d -1 (d - 1) 1 U = (d - 1)log (1 - U ) - log (1 - (1 - ))  d  d (d - 1) - (d-1) U -1 U )  + log ( )  = log (1 - d d

(2.5) (2.6) (2.7)

18

D ( a) = d

F -1 ( y ) dy (2.8) (d-1)a 1 - da 1-a -1 d log (1 - y )dy (2.9) = 1 - da (d-1)a  d y 1 -a = [ + (1 - y )log (1 - y )]1 (2.10) (d-1)a 1 - da   1 - a alog (a) (d - 1)a 1 d [ + - - (1 - (d - 1)a)log (1 - (d - 1)a)] = 1 - da     (2.11)
1-a

=

-d(1-(d-1)a) da d + log (a) (1-da) + log (1 - (d - 1)a) (1-da) 

(2.12)

ent (Ta ) = log (E((1 -

d1U (da,1] (d - 1) -(d-1) 1U [0,da] U -1U [0,da] U  ) ( )  exp( d d  (2.13) ×a (1-da) 1U (da,1] (1 - (d - 1)a)
da -d(1-(d-1)a) (1-da)

1U (da,1]

))

(2.14) Let A = [0, da] andB = (da, 1] then A  B = [0, 1] and A  B = .

= log (

1 0

(1-

1B -d(1-(d-1)a)1B (d - 1)u -(d-1)1A u -1A d1B da )  ( )  exp( )a (1-da) (1-(d-1)a) (1-da) du) d d 

= log ( +
1

da 0

(1 -

(d - 1) -(d-1) u -1 u)  ( )  )du d d

-d(1-(d-1)a) da d exp( )a (1-da) (1 - (d - 1)a) (1-da) du)  da da (d - 1) -(d-1) u -1 = log ( (1 - u)  ( )  du d d 0 -d(1-(d-1)a) d (1da +(1 - da)exp( )a -da) (1 - (d - 1)a) (1-da) ) 

19

1 Recall that a  [0, d ] such that H (x) is non-increasing on [0,a], and

limxa- H (x)  D(a)() In order for a to satisfy ():

xa

lim- (d - 1)F -1 ((d - 1)x) + F -1 (1 - x) 

d 1 - da

1-a (d-1)a 1-a

F -1 (y )dy

xa

lim-

-(d - 1) log (x) d log (1 - (d - 1)x) -    1 - da

1 - log (1 - y )dy (d-1)a 

The arguments of the natural logarithms are always positive since 0  a 
1 d,

however, choosing a = 0 yields log (0) for the Entropic Risk Measure which
1 n

diverges so we could just ignore a = 0 as a solution. Indeed, 0 < a  -a 
-1 n

0>

 0 > -(n - 1)a 

-(n-1) n

1  1 > 1 - (n - 1)a  1 - 1 + n =

1 n

> 0. So we

could just plug in x = a on the left-hand side. -(d - 1) 1 d da log (1 - (d - 1)a) - log (a)  + log (a)    (1 - da) - d(1 - (d - 1)a) log (1 - (d - 1)a) (1 - da)

(-(1 - da)(d - 1) + d(1 - (d - 1)a)) (-(1 - da) - da) log (1-(d-1)a)+ log (a)  d 1 - da 1 - da 1 - (d - 1)  exp(d - d2 a) a Ostensibly, a =
1 d

may seem like a good choice, however, since 1 - da occurs
1 d

in the denominator in the above equations, a =

is in fact a restriction. For

some fixed d, we must use computational software that can solve inequalities 20

1 in order to find some a  (0, d ) and then plug it into the following equation

to obtain the analytical solutions: ent (Ta ) = log (
da 0

(1 -

(d - 1) -(d-1) u -1 u)  ( )  du d d

-d(1-(d-1)a) da d +(1 - da)exp( )a (1-da) (1 - (d - 1)a) (1-da) ) 

It is worth mentioning here that in that our numerical findings (see Tables 7-9 in the following chapter) show that ent (Ta ) agrees with ent (L+ ). Proposition 2.15. If d is even and F = , then ent (L+ ) = ES  (L+ ) = 0 Proof. Note that in this case we have that 0 = Z + (-Z ) + Z + (-Z ) + ...  A(, ..., ) and thus by Proposition 2.8 we get that 0 is the minimum of A(, ..., ) with respect to convex order.

21

Chapter 3

REARRANGEMENT ALGORITHM

3.1

Description

The Rearrangement Algorithm (RA for short) is a probabilistic algorithm used to approximate (L+ ) and (L+ ). In this chapter we will use it to find the lower bound of the Expected Shortfall, ES  and Entropic Risk Measure, ent . Given a class of distributions Fi , i = 1, ..., d, the algorithm searches for minimal elements in A(F1 , ..., Fd ) with respect to convex order. As we will illustrate in Example 3.5 when A(F1 , ..., Fd ) has no minimum element, the algorithm fails to converge to (L+ ). The convergence of this algorithm is still an open problem. Nonetheless, in situations where the losses follow non-homogeneous distributions and analytical solutions cannot be found, the RA is of significant use for estimation purposes. Please see https://sites. google.com/site/rearrangementalgorithm/ for more information. The following example gives a simple illustration of the algorithm. Example 3.1. Suppose that we're dealing with the variance risk measure, d = 2 and F1 = F2 = U {1, 2, 3, 4} (i.e. the discrete uniform distribution on {1, 2, 3, 4}). The following matrix describes the dependence of two random variables L1 and L2 that follow U {1, 2, 3, 4}. The first and second column represent the possible L1 , L2 values respectively and the third column represents the possible values of the aggregate sum.

22

L1 , L2  Discrete Uniform{1, 2, 3, 4}   1 1 2     2 2 4       3 3 6       4 4 8   (a) First, randomly permute the first two columns. This is where the probabilistic aspect of the algorithm comes from. And, as we can see, their row sums change.  2   1    4    3  Definition 3.2. Two vectors x = sitely ordered if and only if (xj - xk )(yj - yk )  0 for all i = 1,...,n. (b) Making L1 and L2 oppositely ordered to one another equilibrates ~1 and L ~2 respectively. the spread of their aggregate or sum. Call them L   2 3  5     1 4 5       4 1 5       3 2 5   23  3   3 4    2 6    4 7  (x1 ,...,xn ) and y = (y1 ,...,yn ) are oppo1

(c) Calculate the variance of what you started off with and the variance after applying the Rearrangement Algorithm. ~1 + L ~2 ) = 0 V (L1 + L2 ) = 5 and V (L ~1 + L ~2 ) meaning that we've minimized the V (L1 + L2 ) is greater than V (L ~1 + L ~2 ) = 0 is indeed the variance of what we started with. The value V (L value V (L+ ) that we were looking for. The first step of the RA is to discretize the given distribution F . This is done by considering an empirical distribution function of the following form Fn (x) = 1 n 1[F -1 (si ),+)] (x), n i=1

where s1 < ... < sn are sample point in [0, 1]. In our numerical results, we will use the following discretizations schemes a) si = b) si =
i -1 n ,i

= 1, ..., n. This is the discretization used in [5] which we will call = 1, ..., n. This is a different discretization we propose here. In

'PUC' in our code.
i+0.7 n+1 , i

our code we call this 'SIM'. We then define the dependence matrix X as follows xi,j = Fj-1 (si ) where 1  i  n and 1  j  d

-1 -1  F1 (s1 )  Fd (s1 )     [Xi,j ] =         -1 -1 F1 (sn )  Fd (sn )

24

Figure 3.1: 'PUC' discretization (left) versus 'SIM' discretization (right) empirical distribution approximations of a Pareto(2) CDF for n=8.

Figure 3.2: 'PUC' discretization (left) versus 'SIM' discretization (right) empirical distribution approximations of a Pareto(2) CDF for n=24.

25

The vector that corresponds to the row sum of the d columns is denoted by (+X ). The RA algorithm is then described by the following steps (1) Each column of the matrix X is randomly permuted. (2) Iteratively rearrange the jth column of the matrix X so that it becomes oppositely ordered to the row sum of everything but the jth column. A new dependence matrix Y is found.   -1  -1   Fk (s1 )    F (s1 )   kj   j      - 1  F -1 (s )   Fk (s2 )    j 2      kj                 -1   - 1 Fj (sn )   ( s ) F n    k   kj (3) Repeat step (2) until ((+Y )) - ((+X )) < , where threshold. Items (1),(3) are introduced to decrease the number of loops needed to reach (L+ ). Item (2) is the essence of the RA. In the following we demonstrate why making the vectors in a matrix oppositely ordered to one another reduces the convex order of the row sum. Let a  Rn , then we denote a = (a[n] , ..., a[2] , a[1] ) which is the vector a with its elements in ascending order and a = (a[1] , ..., a[n] ) which is the vector a with its elements in descending order. We also introduce the following order
j n n a  b if and only if j i=1 a[i]  i=1 b[i] for all 1  j  n and i=1 ai = i=1 bi .

> 0 is a fixed

26

Proposition 3.3. (Day, 1972)

a + b   a + b Proof. Let S = a + b , r = a + b. For simplicity, we assume that a = a Case 1 (n = 2): Since a = a, we have that a1  a2 . If b1  b2 , then b = b so s = r. If b1 < b2 , then s = (a1 + b2 , a2 + b1 ) and r = (a1 + b1 , a2 + b2 ). Let s1 = a1 + b2 , s2 = a2 + b1 , r1 = a1 + b1 , r2 = a2 + b2 . Note that s1 + s2 = r1 + r2 .

r[1] = a2 + b2  max{a2 + b1 , b2 + a1 } = s[1]

For the general case, if b1  b2  ...  bn then s = r. Suppose that there exists some 1  j < k  n such that bj < bk . Then put s i = ri for i  j,k.
  s j = aj + bk and sk = ak + bj . By case 1, we have that s  r .

(aj + bk , ak + bj )  (aj + bj , ak + bk ) If s = s we're done, otherwise repeat the previous step for r = s . Corollary 3.4. For any L1 , L2 discrete uniformly distributed random vari~ 2 CX L1 + L2 where L ~ 2 is a rearrangement of L2 ables we have that L1 + L made oppositely ordered to L1 . Proof. By Day, we have that s = a + b  a + b = r for any a,b  Rn .

27

~ 2  L + L CX L1 + L2 L1 + L 2 1 ~ 2) = ES (L1 + L
n(1-) n(1-) 1 1 s[ i]  r[i] = ES (L1 + L2 ) n(1 - ) i=1 n(1 - ) i=1

Below we give an example where A(F1 , ..., Fd ) has no minimum element and the RA fails to converge to ES 0.99 (L+ ). Example 3.5. Let's say we're using the Rearrangement Algorithm to find the ES 0.99 (L+ ) of the following matrix used in Example 2.1.8.   3 16 0       X = 0 6 13      8 0 7    After finding the Expected Shortfall measure of all (3!)3 different column permutations of our matrix and taking the smallest one, we find that the 'true value' is 19. Now let's apply the RA to this matrix 100 times, average the values, and perform a hypothesis test to determine if the average produced by the RA is close enough to the true value using a two-sided t-test with unknown mean and variance.     H0  average of 100 values = 19      HA  average of 100 values  19 T=
x- µ 0
s  n

=

22.82-19
2 .8898  100

= 13.2189

p-value = 2P(t99  13.2189)  0 28

Very strong evidence against the H0 causing us to reject it in favour of the HA at any level of significance. In particular, the RA fails to find the true smallest Expected Shortfall for this particular case. 3.2 Numerical Results

In this section we present our numerical results from the application of the Rearrangement Algorithm to several risk aggregation problems. For our numerical computation we used n = 100, 000 and = 0.0001. Each value taking MATLAB about 15 seconds to compute when d = 4 and about 300 seconds when d = 56 using a personal computer with a 3.30 GHz processor and about 6.00 GB of RAM. The definite integrals that appeared in section 2.3 were solved via Wolfram Integrator. 3.2.1 Homogeneous Risk Aggregation

For a small number of homogeneously distributed losses, both the 'PUC' and 'SIM' discretizations work well in calculating the ES  , however, it seems that the 'SIM' discretization is more accurate for values of  very close to 1 (see Tables 3.1-3.4). Moreover, for large d the new scheme appears to be more efficient for heavy-tailed distributions like the Pareto distribution (see Table 3.5). For homogeneously distributed losses, both discretization schemes work well in calculating the ent (see Tables 3.7-3.9).

29

Table 3.1: Sharp lower bounds on the ES for the sum of d = 3 random variables all being Exp( = 2). =2  = 0.5  = 0.6  = 0.7  = 0.8  = 0.9  = 0.99  = 0.999 ES  ( P U C  ) 1.6113 1.6666 1.7590 1.9234 2.2338 3.3495 4.4633 ES  ( SIM  ) 1.6115 1.6669 1.7594 1.9240 2.2348 3.3573 4.5167 Analytical 1.5850 1.6545 1.7587 1.9239 2.2347 3.3552 4.5036

Table 3.2: Sharp lower bounds on the ES for the sum of d = 3 random variables all being Exp( = 4). =4  = 0.5  = 0.6  = 0.7  = 0.8  = 0.9  = 0.99  = 0.999 ES  ( P U C  ) 0.8056 0.8334 0.8796 0.9617 1.1169 1.6748 2.2317 ES  ( SIM  ) 0.8058 0.8336 0.8798 0.9620 1.1174 1.6786 2.2583 Analytical 0.7925 1.6545 0.8794 0.9620 1.1172 1.6776 2.2518

30

Table 3.3: Sharp lower bounds on the ES for the sum of d = 3 random variables all being Pareto( = 2). =2  = 0.5  = 0.6  = 0.7  = 0.8  = 0.9  = 0.99  = 0.999 ES  ( P U C  ) 4.0736 4.5975 5.3900 6.7484 9.8508 32.2849 95.5076 ES  ( SIM  ) 4.1015 4.6323 5.4364 6.8178 9.9893 33.6447 108.3204 Analytical 4.1010 4.6320 5.4360 6.8175 9.9889 33.6444 108.5449

Table 3.4: Sharp lower bounds on the ES for the sum of d = 3 random variables all being Pareto( = 4). =4  = 0.5  = 0.6  = 0.7  = 0.8  = 0.9  = 0.99  = 0.999 ES  ( P U C  ) 1.1874 1.2810 1.4244 1.6573 2.1336 4.5136 8.5448 ES  ( SIM  ) 1.1884 1.2822 1.4261 1.6598 2.1386 4.5595 8.9359 Analytical 1.1845 1.2819 1.4258 1.6593 2.1376 4.5507 8.8679

31

Table 3.5: Sharp lower bounds on the ES for the sum of d = 56 random variables all being Pareto( = 2). We can see that 'SIM' scheme provides a much closer approximation than the 'PUC' scheme in all cases. Here RE stands for relative error. =2  = 0.99  = 0.995  = 0.999 ES  ( P U C  ) ES  ( SIM  ) 125.0195 164.8556 274.4890 148.1578 208.7450 444.3673 Analytical 148.8020 210.7278 472.3000 RE('PUC') 15.98% 21.77% 41.88% RE('SIM') 0.42% 0.94% 5.91%

Table 3.6: Sharp lower bounds on the ES for the sum of d = 4 random variables all being N (0, 1). Risk Measure Expected Shortfall 'PUC' -4.21 × 10-4 'SIM' 3.2596 × 10-4 Analytical 0

32

Table 3.7: Sharp lower bounds on the Entropic Risk Measure for the sum of d = 3 random variables all being Exp(). d=3 =2 =3 =4 =5 =6 =7 =8 ent ( P U C  ) 1.5760 1.0273 0.7640 0.6085 0.5057 0.4327 0.3781 ent ( SIM  ) 1.5789 1.0279 0.7642 0.6086 0.5058 0.4327 0.3781 Analytical 1.5817 1.0290 0.7649 0.6091 0.5061 0.4330 0.3783

Table 3.8: Sharp lower bounds on the Entropic Risk Measure for the sum of d = 4 random variables all being Exp(). d=4 =2 =3 =4 =5 =6 =7 =8 ent ( P U C  ) 2.0355 1.3459 1.0063 0.8038 0.6692 0.5733 0.5014 ent ( SIM  ) 2.0380 1.3464 1.0066 0.8040 0.6694 0.5734 0.5015 Analytical 2.0794 1.3649 1.0169 0.8105 0.6739 0.5767 0.5040

33

Table 3.9: Sharp lower bounds on the Entropic Risk Measure for the sum of d = 5 random variables all being Exp(). d=5 =2 =3 =4 =5 =6 =7 =8 ent ( P U C  ) 2.5153 1.6721 1.2527 1.0017 0.8344 0.7151 0.6256 ent ( SIM  ) 2.5173 1.6726 1.2530 1.0018 0.8346 0.7152 0.6257 Analytical 2.6939 1.7484 1.2947 1.0281 0.8526 0.7283 0.6357

Table 3.10: Sharp lower bounds on the EN for the sum of d = 4 random variables all being N (0, 1). Risk Measure Entropic 'PUC' -5.0611 × 10-4 'SIM' 2.7918 × 10-4 Analytical 0

34

3.3

Uncertainty Spread for the Expected Shortfall

Here we consider plotting the difference between ES  (L+ ) and ES  (L+ ) as we vary  from 0.01 to 0.99 for the Exponential and Pareto distributions. The former is calculated analytically and the latter is calculated via the Rearrangement Algorithm. It's worth noting that for Exp() the uncertainty spread increases as  increases to 1. Please see the next couple of pages for their plots.

35

Figure 3.3: Uncertainty spread of the Expected Shortfall for 3 losses all Exponential(2) distributed as  is varied.

36

Figure 3.4: Uncertainty spread of the Expected Shortfall for 3 losses all Pareto(2) distributed as  is varied.

37

3.4

Non-Homogeneous Cases

Now let's suppose that each loss follows a different distribution with different parameters. The analytical solutions for the lower bounds of the aggregate losses are not known so we depend solely on the Rearrangement Algorithm. From our results, it follows that the Entropic Risk Measure has a smaller uncertainty spread than the Expected Shortfall for non-homogeneously distributed Exponential random variables (see Table 3.12). Please see the next page for these next tables.

38

Table 3.11: ES dependence range for the sum of d = 7 random variables having distributions L1  P areto(5), L2  P areto(7), L3  Exp(2), L4  Exp(4), L5  N (1, 3), L6  N (1, 4), L7  N (2, 5) when  = 0.99. d=7  = 0.9  = 0.95  = 0.99 ES 0.99 ( P U C  ) 5.1654 5.1659 5.1659 ES 0.99 ( SIM  ) 5.1670 5.1675 5.1675 ES 0.99 18.5531 21.3728 27.5025

Table 3.12: EN and ES dependence range for the sum of d = 5 random variables having distributions L1  Exp(3), L2  Exp(5), L3  Exp(7), L4  Exp(8), L5  Exp(9) when  = 0.99. ent ( P U C  ) 0.9241 ent ( SIM  ) 0.9244 ent 2.3955 ES 0.99 ( P U C  ) ES 0.99 ( SIM  ) 1.8782 1.8812 ES 0.99 5.1136

39

3.5

Project

Suppose we have a portfolio of 5 non-dividend stocks belonging Yahoo Incorporated, Jacobs Engineering, Adobe Systems Incorporated, E*TRADE Financial Corporation, and Mohawk Industries Incorporated. We view here the total loss L+ of the portfolio as the sum of the losses Li from each individual stock i 1 . Our assumption is that each Li follows a normal distribution, this is a typical assumption in risk measurement that is employed when we use the variance covariance method to estimate the risk of a portfolio. The parameters of the distributions will be estimated by taking the average of the difference between the opening prices and the closing prices on each day over the course of 1 year. The variance is calculated similarly. We then shift that window of size 1 year over day by day for 3 years from about 250 business days after August 04, 2012 to 1000 business days after that date, and calculate each of the aforementioned loss metrics. Our task is to calculate ES 0.99 (L+ ) and ent (L+ ) at each day and compare their uncertainty spread. We'll also calculate ES0.99 (L+ ) and ent (L+ ) by assuming Gaussian dependence among Li . In this case, it is know that L+ follows a normal distribution, where the mean is the sum of the means and the variance is calculated from the estimated covariance matrix. Generally, it seems that the Entropic Risk Measure has a smaller uncertainty spread than the Expected Shortfall for these stocks when  = 0.99 making it a better measure of risk (See Figure 3.10). Also, we can see that both of their lower bounds seem to converge towards the same value.
1

We choose this rather non-standard approach to view the calculation of the risk of the

portfolio loss as a risk aggregation problem

40

Figure 3.5: Uncertainty spread and Gaussian of the Expected Shortfall for the 5 stocks using the 'SIM' discretization. ES 0.99 (L+ ) is in blue, Gaussian is in green, and ES 0.99 (L+ ) is in red.

41

Figure 3.6: Uncertainty spread of the Entropic Risk Measure for the 5 stocks using the 'SIM' discretization. ent (L+ ) is in blue, Gaussian is in green, and ent (L+ ) is in red.

42

Figure 3.7: Amalgamation of both uncertainty spreads and the Gaussians for visual comparison all using the 'SIM' discretization. Expected Shortfall related loss metrics are in red and Entropic Risk Measure related loss metrics are in blue.

43

Figure 3.8: Adjusted closing price of each stock for each day.

44

Figure 3.9: Plot of the sum of all losses for each day.

45

Figure 3.10: Plot of the uncertainty spreads for both risk measures. Entropic in blue and ES in red.

46

Appendix A

MATLAB CODE

Here we present the main MATLAB functions used in this thesis. RearrangementAlgorithm.m is the main function that calculates the lower bound of both the Expected Shortfall and the Entropic Risk Measure. It requires specifying the risk measure, n, > 0, the homogeneous distributions and their parameters, the number of losses, the discretization scheme, and  for the Expected Shortfall. The other two functions serve as auxiliary functions aiding the main function in its computation. For the non-homogeneous cases, the 'starting' matrix in RearrangementAlgorithm.m was manually modified, but everything else remained the same.
1

f u n c t i o n RearrangementAlgorithm = RearrangementAlgorithm ( measure , d i s t r i b u t i o n , parameter1 , parameter2 , d i s c r e t i z a t i o n , n , d , e p s i l o n , alpha )

2

%t a k e s a s i n p u t t h e r i s k measure , the

3

%p r o b i l i t y d i s t r i b u t i o n used , the

4

%d i s c r e t i z a t i o n scheme , n , t h e number o f

5

%l o s s e s d , e p s i l o n , and a l p h a i n the case

6 7 8

%o f ES h = []; for i = 1:n;

47

9 10 11 12

h ( i ) = rand ( 1 ) ; end ;

i f measure == 'ES ' S h o r t f a l l measure , i t i h a t = f l o o r ( a l p h a *n ) ;

%i f you u s e t h e Expected

13 14 15 16

%g o e s through t h i s c l a u s e

i f d i s t r i b u t i o n == 'PAR ' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

17

for j = 1:d; distribution

%f o r t h e P areto

18 19

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( ( i - 1 ) /n ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

20 21

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( ( i +0.7) / ( n+1) ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

22 23

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( i +0.99995) / ( n+1) ) ) ^ ( 1 . / parameter1 ) - 1 ;

24 25

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = (1/(1 -(h( i ) ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

26 27 28 29 30

end end ; end ; e l s e i f d i s t r i b u t i o n == 'EXP ' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

48

31

for j = 1:d; distribution

%f o r t h e e x p o n e n t i a l

32 33

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g ( 1 - ( ( i - 1 ) /n ) ) ;

34 35

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g ( 1 - ( ( i +0.7) / ( n+1) ) ) ;

36 37

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g (1 - ( i +0.99995) / ( n+1) ) ;

38 39

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g (1 - ( h ( i ) ));

40 41 42 43 44

end end ; end ; e l s e i f d i s t r i b u t i o n == 'NOR' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

45

for j = 1:d; distributions

%f o r t h e s t a n d a r d normal

46 47

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i - 1 ) /n - 1)+parameter1 ; %d i f f e r e n t matrix f o r each d i s c r e t i z a t i o n scheme

48 49

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i +0.7) / ( n+1) - 1)+parameter1 ;

49

50 51

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i +0.99995) / ( n+1) - 1)+parameter1 ;

52 53

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * h ( i ) - 1)+parameter1 ;

54 55 56 57 58 59 60 61

end end ; end ; end new = z e r o s ( s i z e ( s t a r t i n g ) ) ; old = s t a r t i n g ;

for c = 1:d ; t h e columns

%randomly permute

62 63 64 65

s t a r t i n g ( randperm ( n ) , c ) = s t a r t i n g ( : , c ) ; end

w h i l e A l t e r n a t i v e D i s c r e t e E S ( old , a l p h a ) - A l t e r n a t i v e D i s c r e t e E S ( new , a l p h a ) >= e p s i l o n

66 67 68

for j = 1: size ( starting ,2) u n t i l the

%keep g o i n g through t h e RA

69

old = s t a r t i n g ; within the

%ES o f t h e next matrix i s

70

%t h r e s h o l d o f t h e ES o f t h e p r e v i o u s one

71 72

x = 1; for i = 1: size ( starting ,1)

50

73 74

C( x ) = sum ( s t a r t i n g ( i , : ) ) - sum ( s t a r t i n g ( i , j ) ) ; x = x + 1; j t h column %f o r each column make t h e

75

end sum o f t h e

%o p p o s i t e l y o r d e r e d t o t h e

76 77 78 79 80 81 82 83 84 85

%l e f t o v e r e l e m e n t s D = h o r z c a t ( s t a r t i n g ( : , j ) ,C' ) ;

[ ~ , i x ]= s o r t (D( : , 2 ) ) ; i n v e r s e=z e r o s ( s i z e ( i x ) ) ; i n v e r s e ( i x ) = numel ( i x ) : - 1 : 1 ; E = s o r t (D( : , 1 ) ) ; D( : , 1 )=E( i n v e r s e ) ;

s t a r t i n g ( : , j ) = D( : , 1 ) ; o r d e r e d column

%put t h e new o p p o s i t e l y

86 87 88

new = s t a r t i n g ; s t a r t i n g = new ;

%v e c t o r back i n t o t h e matrix

i f A l t e r n a t i v e D i s c r e t e E S ( old , a l p h a ) - A l t e r n a t i v e D i s c r e t e E S ( new , a l p h a ) < e p s i l o n

89 90

break end the d i f f e r e n c e %check t o s e e i f t h e ES o f

91

end the old

%between t h e new matrix and

92

end threshold ; i f it ' s

%matrix i s w i t h i n t h e

93

%not , r e p e a t t h e w h i l e loop , otherwise

94

RearrangementAlgorithm = A l t e r n a t i v e D i s c r e t e E S ( new , a l p h a ) ;

51

%output t h e v a l u e
95 96 97

e l s e i f measure == 'EN ' , it

%i f you u s e t h e E n t r o p i c measure

98 99 100 101

%g o e s through t h i s c l a u s e

i f d i s t r i b u t i o n == 'PAR ' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

102

for j = 1:d; distribution

%f o r t h e P areto

103 104

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( ( i - 1 ) /n ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

105 106

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( ( i +0.7) / ( n+1) ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

107 108

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = ( 1 / ( 1 - ( i +0.99995) / ( n+1) ) ) ^ ( 1 . / parameter1 ) - 1 ;

109 110

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = (1/(1 -(h( i ) ) ) ) ^ ( 1 . / parameter1 ) - 1 ;

111 112 113 114 115

end end ; end ; e l s e i f d i s t r i b u t i o n == 'EXP ' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

52

116

for j = 1:d; distribution

%f o r t h e e x p o n e n t i a l

117 118

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g ( 1 - ( ( i - 1 ) /n ) ) ;

119 120

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g (1 - ( i +0.7) / ( n+1) ) ;

121 122

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g (1 - ( i +0.99995) / ( n+1) ) ;

123 124

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = ( - 1 . / parameter1 ) * l o g (1 - h ( i ) ) ;

125 126 127 128 129

end end ; end ; e l s e i f d i s t r i b u t i o n == 'NOR' for i = 1:n; matrix " s t a r t i n g " %c r e a t e t h e p e r m u t a t i o n

130

for j = 1:d; distributions

%f o r t h e s t a n d a r d normal

131 132

i f d i s c r e t i z a t i o n == 'PUC ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i - 1 ) /n - 1)+parameter1 ; %d i f f e r e n t matrix f o r each d i s c r e t i z a t i o n scheme

133 134

e l s e i f d i s c r e t i z a t i o n == 'SIM ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i +0.7) / ( n+1) - 1)+parameter1 ;

53

135 136

e l s e i f d i s c r e t i z a t i o n == 'OTH ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * ( i +0.99995) / ( n+1) - 1)+parameter1 ;

137 138

e l s e i f d i s c r e t i z a t i o n == 'RAN ' s t a r t i n g ( i , j ) = s q r t ( parameter2 ) * s q r t ( 2 ) * e r f i n v ( 2 * h ( i ) - 1)+parameter1 ;

139 140 141 142 143 144 145 146 147

end end ; end ; end

new = z e r o s ( s i z e ( s t a r t i n g ) ) ; old = s t a r t i n g ;

for c = 1:d ; t h e columns

%randomly permute

148 149 150 151 152 153

s t a r t i n g ( randperm ( n ) , c ) = s t a r t i n g ( : , c ) ; end

w h i l e abs ( LNofEXPofE ( o l d ) - LNofEXPofE ( new ) ) >= e p s i l o n

for j = 1: size ( starting ,2) RA u n t i l t h e

%keep g o i n g through t h e

154

old = s t a r t i n g ; i s within the

%EN o f t h e next matrix

155

%t h r e s h o l d o f t h e EN o f t h e p r e v i o u s one

156 157 158

x = 1; for i = 1: size ( starting ,1) C( x ) = sum ( s t a r t i n g ( i , : ) ) - sum ( s t a r t i n g ( i , j ) ) ;

54

159

x = x + 1; t h e j t h column

%f o r each column make

160

end t h e sum o f t h e

%o p p o s i t e l y o r d e r e d t o

161 162 163 164 165 166 167 168 169 170

%l e f t o v e r e l e m e n t s D = h o r z c a t ( s t a r t i n g ( : , j ) ,C' ) ;

[ ~ , i x ]= s o r t (D( : , 2 ) ) ; i n v e r s e=z e r o s ( s i z e ( i x ) ) ; i n v e r s e ( i x ) = numel ( i x ) : - 1 : 1 ; E = s o r t (D( : , 1 ) ) ; D( : , 1 )=E( i n v e r s e ) ;

s t a r t i n g ( : , j ) = D( : , 1 ) ; o r d e r e d column

%put t h e new o p p o s i t e l y

171 172 173 174

new = s t a r t i n g ; s t a r t i n g = new ; i f abs ( LNofEXPofE ( o l d ) - LNofEXPofE ( new ) ) < e p s i l o n break of the d i f f e r e n c e %check t o s e e i f t h e ES

175

end and t h e o l d

%between t h e new matrix

176

end threshold ; i f it ' s

%matrix i s w i t h i n t h e

177

end loop , o t h e r w i s e

%not , r e p e a t t h e w h i l e

178 179 180 181

%output t h e v a l u e RearrangementAlgorithm = LNofEXPofE ( new ) ;

end

55

182 183

end

1 2 3

f u n c t i o n A l t e r n a t i v e D i s c r e t e E S = A l t e r n a t i v e D i s c r e t e E S (A, a l p h a )

x = 1; a s i g n i f i c a n c e l e v e l , alpha

%t a k e s a s i n p u t a matrix , A, and

4 5 6 7 8

m = s i z e (A, 1 ) ;

f o r y = 1 : s i z e (A, 1 ) C( x ) = sum (A( y , 1 : s i z e (A, 2 ) ) ) ; column sums %f o r each row , f i n d t h e

9 10 11

x = x + 1; end C = s o r t (C, ' d e s c e n d ' ) ; s m a l l e s t and put i n a v e c t o r %s o r t from l a r g e s t t o

12 13 14 15 16 17 18 19 20 21 22 23

Z = 0; i f f l o o r (m* (1 - a l p h a ) ) ~= 0 ; f o r i = 1 : f l o o r (m* (1 - a l p h a ) ) ; Z = Z + C( i ) ; end

%c o n d i t i o n s o f t h e ES

A l t e r n a t i v e D i s c r e t e E S = Z/((1 - a l p h a ) *m) ; else ; Z = C( 1 ) ; AlternativeDiscreteES = Z;

end

1

f u n c t i o n LNofEXPofE = LNofEXPofE (A) %i n p u t a matrix , A

56

2 3 4 5

format l o n g ; x = 1;

m = s i z e (A, 1 ) ; Entropic function

% m i s e q u a l t o t h e n you c h o s e i n t h e

6 7

start = 1; the case

%we always s t a r t t h e summation from 1 i n

8 9 10

%o f t h e E n t r o p i c r i s k measure f o r y = 1 : s i z e (A, 1 ) C( x ) = sum (A( y , 1 : s i z e (A, 2 ) ) ) ; columns o f A %add t h e v a l u e s o f t h e

11

x = x + 1; them i n a

%f o r each row and s t o r e

12 13 14 15 16

end

%v e c t o r c a l l e d C

C;

Z = 0; values in C;

%add up t h e e x p o n e n t i a l o f t h e

17

f o r i = s t a r t : s i z e (A, 1 ) ' re taking

%t h e r e ' s no need t o s o r t i t s i n c e we

18

Z = Z+exp (C( i ) ) ; commutative

%a l l o f C' s v a l u e s and a d d i t i o n i s

19 20 21

end

LNofEXPofE = l o g ( ( Z/m) ) ; v a l u e s by t h e

%d i v i d e t h a t sum o f e x p o n e n t i a l

22

%number o f rows o f A and t a k e t h e l o g then

57

23 24 25

%output

end

58

REFERENCES

[1] Carole Bernard, Xiao Jiang, Ruodu Wang. Risk aggregation with dependence uncertainty. Insurance: Mathematics and Economics, 2014. [2] Embrechts, P., Puccetti, G., R¨ uschendorf, L.: Model uncertainty and VaR aggregation. Journal of Banking and Finance 37(8), 2750-2764, 2013. [3] Levy, H., Kroll, Y. Ordering uncertain options with borrowing and lending J. Finance, p.553-574, 1978. [4] Alexander J. McNeil, Rudiger Frey, and Paul Embrechts. Quantitative Risk Management: Concepts, Techniques, and Tools. Princeton University Press, 2005. [5] Giovanni Puccetti. Sharp bounds on the expected shortfall for a sum of dependent random variables. Statistics and Probability Letters, 2013. [6] Ruschendorf, L. Solution of a statistical optimization problem by rearrangement methods Metrika 30, p.55-61, 1983 [7] Ruodu Wang, Liang Peng, and Jingping Yang. Bounds for the Sum of Dependent Risks and Worst Value-at-Risk with Monotone Marginal Densities, Finance and Stochastics April 2013, Volume 17, Issue 2, pp 395­417.

59


