PERFORMANCE ANALYSIS OF MULTISPECTRAL LIDAR IN LAND COVER CLASSIFICATION

by

Khakan Zulfiquar Bachelor of Engineering, Ryerson University, 2011

A MRP presented to Ryerson University

in partial fulfillment of the requirements for the degree of Master of Engineering in the program of Civil Engineering

Toronto, Ontario, Canada, 2017 © Khakan Zulfiquar, 2017

AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A MRP I hereby declare that I am the sole author of this MRP. This is a true copy of the MRP, including any required final revisions. I authorize Ryerson University to lend this MRP to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this MRP by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my MRP may be made electronically available to the public.

ii

ABSTRACT PERFORMANCE ANALYSIS OF MULTISPECTRAL LIDAR IN LAND COVER CLASSIFICATION Master of Engineering, 2017 Khakan Zulfiquar Civil Engineering Ryerson University

The Optech Titan is the world's first multispectral airborne Light Detection and Ranging (LIDAR) sensor, a revolutionary sensor that includes three active imaging channels of different wavelengths for day or night mapping of complex environments. Multispectral imagery and monochromatic LIDAR have long existed as independent technologies and both systems have developed workflows to perform land cover classification. This project was undertaken to analyze the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification. By processing selective parameters through the multispectral image land cover classification process, we can determine the accuracy performance of individual channels and attributes in land cover classification. The outcome of this process will measure the effectiveness of combining LIDAR attributes with multispectral imagery for land cover classification. The test site was a 600m x 600m residential neighbourhood in Oshawa, Ontario captured at point-spacing of 0.5 meter.

Multispectral imagery had an overall accuracy result of 77%. The most accurate land cover classification result from our testing was 77.5%. This was produced as a special index scenario by using the three intensities along with the nDSM. It is apparent from the results that the intensity-attribute provides the most useful information in land cover classification. The highest monochromatic LIDAR accuracy result of 70% came from Channel 2 (NIR - 1024 mm). Channel 2's accuracy is only 7% lower than multispectral imagery result. Channel 1 and 3 had less-favorable results at 59.5% and 58% respectively. Individual land cover classification tests on Z-attribute and N-attribute produced unfavorable results of 37% and 47.5% respectively.

Keywords: multispectral, LIDAR, land cover classification, Optech Titan, nDSM, point-to-raster, IDW, and Kriging. iii

TABLE OF CONTENTS
AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A MRP ABSTRACT 1. INTRODUCTION 1.1. 1.2. 1.3. 1.4. 1.5. 2. 3. Optech Titan Multispectral LIDAR System Multispectral Imagery and Land Cover Classification LIDAR and Attributes Raster Images and Interpolators Problem Statement ii iii 1 1 2 3 5 6 7 10 11 11 12 14 14 15 16 17 17 18 20 20 21 22 24 38

LITERATURE REVIEW METHODOLOGY 3.1. 3.2. 3.3. Technical Background Step- By- Step Procedure Execution

4.

RESULTS 4.1. 4.2. 4.3. Inverse Distance Weighting (IDW) Kriging Spectral Indices

5.

ANALYSIS 5.1. 5.2. 5.3. 5.4. 5.5. Accuracy Assessment LIDAR Attributes Spectral Indices Interpolators Testing Site

6.

CONCLUSIONS

APPENDIX A ­ EXECUTION WALKTHROUGH REFERENCES

iv

1. INTRODUCTION
1.1. Optech Titan Multispectral LIDAR System
"The Optech Titan is the world's first multispectral airborne Light Detection and Ranging (LIDAR) sensor, a revolutionary sensor that includes three active imaging channels of different wavelengths for day or night mapping of complex environments." (Teledyne Optech, 2017). This high precision environmental mapping tool is the first of its kind to capture data in three different wavelengths referred to as channels. There are two key advantages of the sensor. First, by combining three independent channels, operators can produce high resolution false-colored Red-Green-Blue (RGB) images. Second, by comparing variations in intensity of various surface targets, operators can conduct finer material differentiation to aid in land cover classification. As seen in Figure 1, materials such as vegetation, water and soil reflect or absorb different wavelengths of light in different ways; vegetation strongly reflects near-infrared light but absorbs visible green light, whereas soil responds significantly differently to the same wavelengths (Teledyne Optech, 2017). By utilizing these natural reflective properties of Earth's surfaces, we can enhance the ability to conduct material differentiation leading to better land cover classification.

Figure 1. Spectral reflectance signatures f or Water, Vegetation, and Soil with Optech Titan's standard channels (courtesy of Teledyne Optech, 2017).

The Optech Titan's three channels capture data using three active beams with independent wavelengths of 532 nm, 1064 nm and 1550 nm. The latter two wavelengths are outside of the visible RGB range mainly to leverage the intensity variation of Earth's surfaces and are the reason for false-colored images. Additional specifications of the Optech Titan can 1

be seen in Table 1. Optech Titan is at the forefront of revolutionizing applications to vegetation mapping, shallow-water bathymetry, dense topography, and 3D land cover classification. This project took a deep dive into the implementation of multispectral LIDAR in land cover classification.

Table 1. Optech Titan Laser and Camera Specifications (courtesy of Teledyne Optech, 2017).

1.2.

Multispectral Imagery and Land Cover Classification

Although Optech Titan is the world's first multispectral airborne Light Detection and Ranging (LIDAR) sensor, airborne multispectral imagery and monochromatic LIDAR have long existed as independent systems. Multispectral image land cover classification relies on the reflectance from earth's surfaces, such as vegetation or water, to differentiate between materials in order to determine land cover. Remote sensing satellite sensors such as Landsat, IKONOS, and SPOT are common sources of multispectral imagery. Image classification refers to the task of extracting information classes from a multiband raster image. Depending on the interaction between the analyst and the computer during classification, there are two common 2

types of classifications: supervised and unsupervised (ArcMap Help, 2013). This project only examined supervised classification. In this process, the operator selects pixels that represent patterns or land cover features that can recognized, or that can be identified with help from other sources, such as aerial photos, ground truth data, or maps. Knowledge of the data, and of the classes desired, is required before classification. By identifying patterns, the operator can instruct the computer system to identify pixels with similar characteristics. If the classification is accurate, the resulting classes represent the categories within the data that operator originally identified (PCI Geomatics, 2015). An example of image classification for a multiband image into a thematic image is shown in Figure 2. Land cover refers to the surface cover on the ground, whether vegetation, urban infrastructure, water, bare soil or other. Identifying, delineating and mapping land cover is important for global monitoring studies, resource management, and planning activities.

Figure 2. Example of test-site's multispectral image (C2-I,C3-I,C1-I = RGB) being classified into 5 information classes; Vegetation (green), Water (blue), Buildings (yellow), Roads (red), and Ground (pink).

1.3.

LIDAR and Attributes

Light Detection and Ranging (LIDAR) is a remote-sensing technique that uses laser light to densely sample the surface of the earth, producing highly accurate x, y, z measurements. The point data is post-processed after the LIDAR data collection survey into highly accurate georeferenced x, y ,z coordinates by analyzing the laser time range, laser scan 3

angle, GPS position, and INS information (ArcMap Help, 2013). Additional information is stored along with every x, y, and z positional value. The following LIDAR point attributes are automatically generated for each laser pulse recorded: intensity, return number, number of returns, GPS time, scan angle, and scan direction. In addition to these LIDAR point attributes, information regarding point classification values, points that are at the edge of the flight line, and RGB values can be stored as well. The latter attributes require manual input or generation and are subject to frequent change depending on the operator's application. This project will utilize the core LIDAR attributes of x, y, z, intensity, and number of returns to differentiate land cover for classification.

Figure 3. Typical LIDAR data collection survey being conducted and how the emitted laser pulse would produce multiple returns as it interacts with Earth's surfaces (courtesy of ArcMap Help, 2013).

The positional data of x and y are essential to ensuring that a point in an image or on Earth gets referenced correctly. The intensity data is the key factor in LIDAR land cover mapping. The intensity data produced from LIDAR survey is similar to reflectance data referenced in Section 1.2 describing how reflectance is used in supervised land cover classification. The other two main attributes of LIDAR that hold any significant information in differentiating land cover are `elevation' (Z) and `# of returns' (N). The data contained within the Z-attribute holds all the elevation information for the scene. This information is critical in producing digital surface models (DSM) and digital elevation models (DEM). This is useful because different land covers tend to have different heights (e.g. low = ground and high = tree/ 4

building) and therefore can be used to assist in land cover differentiation. Figure 3 shows a typical LIDAR data collection survey being conducted and how the emitted laser pulse would produce multiple returns as it interacts with Earth's surfaces. The N-attribute is a LIDAR exclusive attribute that records the number of splits by the emitted laser pulse as it travels and interacts with surfaces. One emitted laser pulse can return to the LIDAR sensor as one or many returns. The first returned laser pulse is the most significant return and will be associated with the highest feature in the landscape (e.g. a treetop or the top of a building). The first return can also represent the ground, in which case only one return will be detected by the LIDAR system (ArcMap Help, 2017). Likewise, the last return will almost always be from the ground. These inherent properties of LIDAR can be used to assist in differentiating land cover.

1.4.

Raster Images and Interpolators

Traditional Light Detection and Ranging (LIDAR) data is stored as point clouds, which are different than standard aerial imagery format. Regardless of the format extension, typical aerial imagery is stored as a raster format - e.g. .IMG, .PNG, .JPEG, and etc. Typically any raster-image representations of LIDAR data will have gone through an interpolation that converts the point-data into cell-data. Two mainstream point-to-raster interpolators are Inverse Distance Weighting (IDW) and Kriging. IDW is widely used for its fast computation, sound theory, and favorable results while Kriging is a highly regarded interpolator that is computationally heavy but produces highly accurate results. The main use of interpolators is for producing DSMs and DEMs. The most commonly produced visual representation of LIDAR data is an `intensity image'. Intensity images are the product of only x, y, and intensity attributes from LIDAR data while all information about other attributes will not be used. This is an ingrained restriction when using raster type data. Traditional LIDAR systems were only able to produce monochromatic images from LIDAR intensity data whereas Titan Optech can produce multispectral images due to its three different channels. Figure 4 shows the test-site's LIDAR data converted into monochromatic images for each channel and a combined false-color-image using IDW interpolator. It is evident visually that each channel provides different information about the same area which when combined provides more valuable information.

5

Figure 4a. C1: 532 nm

Figure 4b. C2: 1084 nm

Figure 4c. C3: 1550 nm

Figure 4d. False-color-image (C2,C3,C1 = RGB)

Figure 4. Test-site's LIDAR data converted into intensity images using IDW for each channel and a combined false-color-image. The test site was a 600m x 600m residential neighbourhood in Oshawa, Ontario captured at point-spacing of 0.5 meter.

1.5.

Problem Statement

This project was undertaken to analyze the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification. By processing selective 6

parameters through the multispectral image land cover classification process, we can gauge the accuracy performance of individual channels and attributes in land cover classification. The outcome of this process will measure the effectiveness of combining LIDAR attributes with multispectral imagery for land cover classification.

2. LITERATURE REVIEW
Research into the subject matter yielded a wide range of studies conducted on multispectral imagery and LIDAR separately for land cover classification, but comparatively fewer studies discussed the combined results of multispectral LIDAR. This is because the Optech Titan is a new system that has only been field-operational in recent years while multispectral imagery and monochromatic LIDAR have long existed as independent technologies and both systems have developed workflows to perform land cover classification. Multispectral image land cover classification relies on the reflectance from earth's surfaces, such as vegetation or water, to differentiate between materials in order to determine land cover while LIDAR land cover classification relies on a geometric calculation of `return number', `number of returns' (N) and `elevation' (Z) to determine ground, buildings, and vegetation. Further investigation into the subject matter proved using LIDAR's attributes with multispectral land cover classification process to be advantageous as highlighted by our references who used normalized-DSM (nDSM) as an added parameter (aka band) to increase the overall accuracy by up to 10%; M. Sitar (2015), Morsy et al. (2017), Miller et al. (2016), and Huang et al. (2011) were able to significantly increase their classification results by utilizing the elevation attribute. This signifies that LIDAR's Z-attribute (elevation), and possibly other attributes, hold valuable information for land cover classification.

Furthermore, a common trend in the references was to use spectral indices to aid and improve the classification results. Spectral indices are simple band ratio used to enhance spectral properties of reflective surfaces on Earth. Spectral indices were developed to highlight the spectral properties of vegetation at different stages of growth and senescence. Recent years have seen the development of new spectral indices for applications other than vegetation health - e.g. indices for burned area assessment and fire severity.

The references used the generic multispectral imagery classification process to perform land cover classification along with an additional step: interpolation. As mentioned in Section 7

1.4, the standard format of LIDAR data is point-clouds. These point-clouds must be interpolated into rasters in order to use them in the multispectral imagery classification process. A summary of the reference's land cover classification accuracy results are summed up in Table 1.

ARTICLE TITLE

AUTHOR

YEAR

# OF CLASS 3

OVERALL ACCURACY 91%

NOTES
Multispectral Multispectral + nDSM Multispectral + nDSM Test was performed on 5 different targets, rather than land cover Average of multiple studies conducted over 2 years

Towards Automatic SingleSensor Mapping by Ahokas et al. Multispectral Airborne Laser Scanning Testing Of Land Cover Classification From Bakula et al. Multispectral Airborne Laser Scanning Data Multispectral Lidar Point Cloud Classification: A Twostep Approach

2016

93.5% 2016 6 90%

Chen et al.

2017

5

81%

Capability Assessment And Performance Metrics For The FernandezTitan Multispectral Mapping Diaz et al. Lidar

2016

5

90%

82.5%

Multispectral

84%

Multispectral + spectral indices Multispectral + spectral indices + nDSM Multispectral + spectral indices + nDSM + Z Multispectral + spectral indices + Z Multispectral + spectral indices + nDSM + I

Fusion Of High Resolution Aerial Multispectral And Lidar Data: Land Cover In The Context Of Urban Mosquito Habitat.

89.2% Hartfield et al. 2011 8 80.9%

71.1%

83.5%

8

Information Fusion Of Aerial Images And Lidar Data In Urban Areas: Vectorstacking, Re-classification And Post-processing Approaches Application Of Image Classification Techniques To Multispectral Lidar Point Cloud Data Multispectral Lidar Data For Land Cover Classification Of Urban Areas Airborne Multispectral Lidar Data For Land-cover Classification And Land/Water Mapping Using Different Spectral Indexes

82.5% Huang et al. 2011 5 95%

Multispectral

Multispectral + nDSM

Miller et al.

2016

unk.

+10% 77%

Multispectral + Z+N

Multispectral Multispectral + nDSM site I - aided by spectral indices site II - aided by spectral indices aided by DSM as added band aided by DSM as added band

Morsy et al.

2017

4 89% 3 96% 83-92% 69-78% 78%

Morsy et al.

2016 3 2015 2015 6 6

Beyond 3d - Multispectral Optech Titan Opens New Sitar, M. Applications For Lidar New, Flexible Applications with the Multi-Spectral Titan Swirski et al. Airborne Lidar Evaluating The Potential Of Multispectral Airborne Lidar Wichmann et For Topographic Mapping al. And Land Cover Classification 3d Land Cover Classification Xiaoliang et Based On Multispectral Lidar al. Point Clouds

2015

5

99%

Geometrical Classification

2016

9

91%

aided by spectral indices and filtering

Table 1. Summary of Reference's Overall Classification Accuracy, # of Classes, Year, and Reference Title.

Accuracy assessment is an important part of any land cover classification project. It compares the classified image to another data source that is considered to be accurate or ground truth data (ArcMap Help, 2013). The highest classification accuracy of multispectral LIDAR was 95% achieved by Huang et al. (2011) who also tied Morsy et al. (2017) for the largest increase in classification accuracy, ~12%, by using LIDAR's Z-attribute. M. Sitar (2015) and Miller et al. (2016) were able to increase their results by ~9% when using LIDAR attributes with multispectral imagery but Ahokas et al. (2016) was only able to increase their result by 2.5%. Ahokas et al. (2016) were performing a much more difficult classification by distinguishing three different vegetation in a scene and therefore only had a minor improvement in 9

classification accuracy between multispectral imagery and multispectral LIDAR. Even though Wichmann et al. (2015) and Morsy et al. (2016) have higher classification accuracies at 99% and 96% respectively, their results were omitted because one of them used geometrical classification rather than multispectral image classification and the other did not utilize LIDAR's attributes - Z or N. The reason for omitting results not using LIDAR attributes is because the Optech Titan can simulate and isolate the multispectral imagery result by selecting only the intensities from the three different channels. The test-site data was classified using geometrical classification via LAStools into 3 classes - ground, building, and vegetation - but had uncertain results. The classified data could not be exported into a raster for further testing and the pointon-point accuracy checks had unconfirmed results. Although Hartfield's et al. (2011) paper does not mention Optech Titan and/ or multispectral LIDAR, their concept for testing multispectral imagery and LIDAR attributes together closely resembles the scope proposed by this project to analyze the performance of Optech Titan in land cover classification. They identified five parameters to be used in conjunction with each other to gauge the performance of multispectral imagery and LIDAR: multispectral imagery, spectral indices, nDSM, Z-attribute, and monochromatic intensity. A series of land cover classifications were done with various combinations of the parameters mentioned above to see how individual parameters will increase or decrease the result. Summary of Hartfield's et al. (2011) results are available in Table 2. Their multispectral image was classified at 82.5% accuracy. The addition of spectral indices and nDSM positively increased the accuracy results by up to ~7% together while the Z-attribute and the monochromatic intensity decreased the accuracy. The lowest accuracy of 71% was achieved by a combination involving multispectral imagery + spectral indices + Z, where it can be derived that the Z-attribute effectively lowered the accuracy by 13%. The average accuracy of Optech Titan's sensor from our references is 85%.

3. METHODOLOGY
In order to gauge the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification, three key steps were identified based on the lessons learned from our references: Interpolation, Supervised Classification, and Accuracy Assessment. Sample Optech Titan data was put through a series of trials to determine best practices for the steps mentioned above. ArcMap was used to perform the point-to-raster 10

interpolations. ArcMap was chosen to interpolate because of its robust performance and its exclusive Empirical Bayesian Kriging interpolator that automatically adjusts settings to the data being processed. Two different interpolators were used on the data: IDW and Kriging. IDW is widely used for its fast computation, sound theory, and favorable results while Kriging is a highly regarded interpolator that is computationally heavy but produces highly accurate results. The performance of these two interpolators were consequently tested as a result of the overall analysis performed. The next step is supervised classification.

3.1.

Technical Background

Prior to determining the best practices for supervised classification, the parameters being used in the classification process should be clearly outlined. The Optech Titan has three active imaging channels and each channel has the following attributes: x, y, z, intensity, return number, number of returns, GPS time, scan angle, and scan direction. Based on our research and sample trials, it was determined that only intensity (I), number of returns (N) and elevation (Z) would be used in the classification process. Three parameters from three different channels equals to a total of nine parameters; C1 - I / N / Z, C2 - I/ N/ Z, and C3 - I / N / Z. These parameters can be used in combinations with each other to simulate the following systems: monochromatic LIDAR (individual channels), multispectral imagery (intensities only), and multispectral LIDAR. By analyzing the land cover classifications of the systems mentioned above, we can gauge the performance effects of these systems in comparison to each other. Additionally, spectral indices and nDSM are derivatives of the parameters mentioned above and have shown to be valuable in the land cover classification process. Spectral indices are simple band ratio used to enhance spectral properties of reflective surfaces on Earth while nDSM is the product of DEM subtracted from DSM. PCI Geomatics - Focus (software) was chosen to perform supervised classification because of its test­retest reliability. PCI Geomatics - Focus provided the optimal interface to add or remove parameters (aka bands) during supervised classification. The same program was used to perform accuracy assessment as well.

3.2.

Step- By- Step Procedure

This project was undertaken to analyze the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification. By processing selective parameters through the multispectral image land cover classification process, we can gauge the accuracy performance of individual channels and attributes in land cover classification. The 11

outcome of this process will measure the effectiveness of combining LIDAR attributes with multispectral imagery for land cover classification. Through combining the lessons learned from the references and operator experience using LIDAR data, a standardized workflow was produced to impartially compare land cover classification results of monochromatic LIDAR, multispectral imagery, Optech Titan sensor, and spectral indices. The steps within the process and their standard description is as follows:

1. Collect LIDAR data;  Collect LIDAR data using Optech Titan in three different wavelengths - C1, C2, C3; 2. Interpolate LIDAR attributes into raster;  Interpolate individual LIDAR attributes (I - N - Z) for each channel using IDW and Kriging; 3. Compile rasters;  Compile C1/ C2/ C3 - IDW - I/ N/ Z rasters;  Compile C1/ C2/ C3 - Kriging - I/ N/ Z rasters; 4. Perform supervised classification on various combination of rasters;  Perform supervised classification on individual channels;  Perform supervised classification on intensities;  Perform supervised classification on elevation;  Perform supervised classification on number of returns;  Perform supervised classification on intensities + elevation;  Perform supervised classification on intensities + number of returns;  Perform supervised classification on intensities + elevation + number of returns;  Perform supervised classification using all parameters;  Perform supervised classification on combinations of spectral indices; 5. Execute accuracy assessment; and  Isolate monochromatic LIDAR results;  Isolate multispectral results;  Isolate Optech Titan (multispectral + LIDAR) results;  Isolate spectral indices and special cases; 6. Compare results.  Gauge Optech Titan's performance;  Compare to traditional multispectral;  Compare to traditional LIDAR; and  Compare to references.

3.3.

Execution

In this section, the execution of the workflow (shown in Figure 5) used to gauge land cover classification accuracy of monochromatic LIDAR results vs. multispectral imagery vs. Optech Titan vs. spectral indices will be explained. Step-by-step visual walkthrough of the workflow being executed is available in Appendix A.

12

Figure 5. Workflow to impartially compare classification results of monochromatic LIDAR, multispectral imagery, Optech Titan sensor, and Spectral Indices.

STEP STEP 1: Collect LIDAR data

TOOLS / SOFTWARE Optech Titan Sensor

EXPLANATION
     Sample Optech Titan LIDAR data was provided by the manufacturer The sample data was for a residential neighbourhood in Oshawa, Ontario; The footprint of the scene was 600m x 600m; The point spacing for the data was 0.5m; There were three separate files - one for each channel on the Optech Titan sensor; The point clouds must be converted into rasters because this is the format required by standard multispectral image classification methods; ArcMap was used to apply IDW and Kriging interpolators to the point cloud data from Step 1; Each attribute of interest - intensity, elevation, and # of returns - were interpolated individually using IDW for each channel; 9 files were produced; Each attribute of interest - intensity, elevation, and # of returns - were interpolated individually using Kriging for each channel; 9 files were produced; The 9 files from IDW interpolations were stacked together for future testing; The 9 files from Kriging interpolations were stacked together for future testing; Supervised classification was carried out in PCI Geomatics - Focus; Training areas were manually collected on false color image of the test-site (C2-I, C3-I, C1-I = RGB); The training areas were clustered into 4 classes Vegetation, Ground, Roads, and Building;;

STEP 2: Interpolate LIDAR attributes into raster

ArcMap 10.4.1 for Desktop to execute commands.

          

STEP 3: Compile rasters STEP 4: Perform supervised classification on various

PCI Geomatics Focus PCI Geomatics Focus

13

combination of rasters

    

A signature file was created for the combo C2-I, C3-I, C1-I; Supervised classification using maximum-likelihood was performed; A signature file was created for the combo C1-I, C1-N, C1-Z using the same training areas from the previous execution; Supervised classification using maximum-likelihood was performed; The two steps above were repeated until all desired combinations of channels and attributes were achieved. EASI Modelling tool in PCI Geomatics - Focus was used to create spectral indices for testing; All spectral indices were produced from IDW rasters; A signature file was created for the spectral indices combos using the same training areas from the previous executions; Supervised classification using maximum-likelihood was performed; 200 point checks were carried out in PCI Geomatics - Focus for every classification combo from Step 4; The 200 points were randomly distributed; The same 200 points distribution were used in each accuracy assessment; and Results were compiled.

   

STEP 5: Execute accuracy assessment

PCI Geomatics FOCUS

   

4. RESULTS
4.1.
Band C1

Inverse Distance Weighting (IDW)
IDW
Stack 1 Stack 2 Stack 3 Stack 4 Stack 5 Stack 6 Stack 7 Stack 8 Stack 9 Stack 10

Attribute

C2

C3

I N Z I N Z I N Z

X X X X X X X X X 58 0.43

X X X X X X X X 47.5 0.25 X 37 0.19 77 0.69

X

X

X

X X X

X X X

X X X X

Overall Accuracy % Kappa Coefficient

59.5 0.45

70 0.59

74.5 0.66

71.5 0.61

75 0.66

X X X X X X X X X 71 0.61

Table 2. Accuracy assessment results for land cover classification using IDW interpolator.



Stacks 1 to 3: monochromatic LIDAR  Monochromatic LIDAR is when only one channel actively collects data; 14

   

These stacks represent and simulate results for monochromatic LIDAR; The highest accuracy of 70% was achieved by C2/ Stack 2; The lowest accuracy of 58% was obtained by C3/ Stack 3;

Stacks 4 to 5: LIDAR attributes  These stacks represent and isolate results for LIDAR attributes - elevation (Z) and # of returns (N);  N-attribute achieved better accuracy at 47.5% than Z-attribute; Stack 6: multispectral imagery  This stack represents and simulates result for multispectral imagery;  This combination produced the most accurate result at 77% compared to all other combinations; Stacks 7 to 9: Optech Titan sensor  This stack represents and isolates results for Optech Titan sensor's exclusive combinations;  These combinations are exclusive to Optech Titan because monochromatic LIDAR has only one channel and multispectral imagery do not have Z-attribute and N-attribute;  It should be noted that these stacks produced lower accuracy results than Stack 6 even though the same intensities data are used along with additional attributes information;  Stack 9 produced the highest accuracy at 75% by utilizing all-intensities, C2-Z, and C2-N; Stack 10: All parameters  This stack represents the result for land cover classification using all parameters produced using IDW interpolator; and  The resultant accuracy for the stack was 71%.







4.2.
Band C1 I N Z I N Z I N Z

Kriging
KRIGING
Stack 1 Stack 2 Stack 3 Stack 4 Stack 5 Stack 6 Stack 7 Stack 8 Stack 9 Stack 10

Attribute

X X X X X X X X X 59 0.44

X X X X X X X X 49 0.27 X 36.5 0.19 76 0.67

X

X

X

C2

X X X

X X X

X X X X

C3

Overall Accuracy % Kappa Coefficient

61 0.47

73.5 0.64

75.5 0.67

73.5 0.64

76 0.68

X X X X X X X X X 71 0.61

Table 3. Accuracy assessment results for land cover classification using Kriging interpolator.



The overall accuracy results of using Kriging interpolation compared to IDW interpolation are indistinguishable; 15



All aspects of the Kriging results - monochromatic LIDAR, LIDAR attributes, multispectral imagery, and Optech Titan exclusive combos - behave as they did for IDW interpolation; and The highest accuracy of 76% was produced using only the multispectral intensities, similar to IDW but the latter had an accuracy of 77%.



4.3.

Spectral Indices
SPECTRAL INDICES
Stack 1 Stack 2 Stack 3 Stack 4 Stack 5 Stack 6 Stack 7 Stack 8 Stack 9

Spectral Index nDSM C1 C1-C2/C1+C2 C1-C3/C1+C3 C2 C2-C1/C2+C1 C2-C3/C2+C3 C3 C3-C1/C3+C1 C3-C2/C3-C2
Overall Accuracy % Kappa Coefficient

X X X X X X

X

X

X

X

X X

X

X X X X X

X

X

X X

X

X

X

X

X X 71 0.61

X

77 0.69

77 0.69

77.5 0.67

76.5 0.68

74.5 0.66

72 0.62

77.5 0.70

77.5 0.70

Table 4. Accuracy assessment results for land cover classification using spectral indices.



Stack 1: baseline accuracy  This stack represents the most favorable result from our land cover classification achieved by using only intensities, aka multispectral imagery result; Stacks 2 to 7: Spectral Indices  These stacks represent and isolate results for spectral indices being used;  Generic pseudo indices were created by comparing band ratios of the three channels with each other;  The highest accuracy of 77.5% was achieved by Stack 3;  This result is slightly better than the baseline accuracy but the result also had slightly lower kappa coefficient;  The lowest accuracy of 71% was obtained by Stack 7; Stack 8: baseline + nDSM  This stack represents the most favorable result from our land cover classification achieved by using only intensities, aka multispectral imagery result, along with nDSM as mentioned by references;  This combination produced a result of 77.5%, a 0.5% increase over the baseline accuracy along with 0.01 increase in kappa coefficient; Stack 9: Stack 3 + nDSM  Stack 3 represents the most favorable result from spectral indices combined with nDSM; and 16









This combination produced a result of 77.5%, same as Stack 3's result but with 0.03 increase in kappa coefficient.

5. ANALYSIS
5.1. Accuracy Assessment
The intent of the study was to analyze the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification. The most accurate land cover classification result from our testing was 77.5% with a 0.70 kappa coefficient. This was produced as a special index scenario by using the three intensities along with the nDSM (Table 4 - Stack 8). The least accurate land cover classification result was 37% with a 0.19 kappa coefficient. This was produced by using only the Z-attribute (Table 2 - Stack 5). The subsequent sections will further analyze LIDAR attributes and spectral indices results while this section will concentrate on monochromatic LIDAR, multispectral imagery, and multispectral LIDAR results.

Multispectral imagery has an overall accuracy result of 77% with a 0.69 kappa coefficient. This result is comparable to our references - M. Sitar (2015) and Morsy et al. (2017) - who had similar accuracy results when using the multispectral portion of the Optech Titan sensor in land cover classification. Their results were 69% and 77% respectively. The result was achieved by using only the intensities from the three LIDAR channels and will be referred to as the baseline accuracy for remainder of the analysis sections. The reason for assigning multispectral imagery the `baseline' title is because the land cover classification process utilized in this project is built specifically for multispectral images. Additionally, multispectral imagery represents the middle ground between monochromatic LIDAR and multispectral LIDAR.

The highest monochromatic LIDAR accuracy result of 70% with a 0.59 kappa coefficient came from Channel 2 (NIR - 1024 mm). Channel 2's accuracy is only 7% lower than baseline accuracy. There are two distinct reasons why Channel 2 achieved the highest accuracy result amongst other channels; the test-site has over 50% vegetation land cover and material distinction at NIR. Vegetation is highly susceptible to NIR wavelengths and therefore can be easily distinguished from other land covers. Channel 1 and 3 had less-favorable results at 59.5% and 58% respectively. The highest accuracy produced by multispectral LIDAR (Optech Titan's exclusive combinations) was 75% with a 0.66 kappa coefficient. This result was achieved by combining all 17

intensities with C2-Z-attribute and C2-N-attribute (Table 2 - Stack 9). The output is less favorable when compared to the multispectral imagery (using only intensities), which resulted in an accuracy of 77%. When adding only the N-attribute to the intensities in the classification process, the result drops down to 74.5%. Likewise, when adding only the Z-attribute to the intensities in the classification process, the result decreases to 71.5%. The N-attribute is 3% more accurate than the Z-attribute, however both attributes decrease the overall accuracy of the results when compared to the multispectral imagery result. Interestingly, when the Z-attribute and N-attribute are combined together with intensities, the result is 75%. To confirm this trend of adding additional parameters to increase the accuracy, an exploratory analysis was conducted using all nine attribute files (Table 2 - Stack 10) to see if additional dimensions of data would increase the overall accuracy result as observed in our earlier trials. The resultant overall accuracy was 71% when using all nine attributes. A possible cause for the deterioration in accuracy with additional data is due to over-parameterization. This is when same or similar data is used in an analysis and results in bias classification. It is apparent from the results that the intensity-attribute provides the most useful information in land cover classification. Other LIDAR attributes, elevation and # of returns, contribute very little or negative information to the land cover classification process and because these attributes were repeated in the overparameterization scenario, the resultant accuracy is lower than multispectral imagery and optimal multispectral LIDAR results.

5.2.

LIDAR Attributes

Individual land cover classification tests on Z-attribute and N-attribute produced unfavorable results of 37% and 47.5% respectively. It is not surprising that the accuracy results are low since the multispectral image classification methods rely on intensity as the decision variable. The intensity data for the test-site from C2 has a range from 1 to 4085. The elevation data (Z) and # of returns (N) from C2 for the test-site have a range of 73 to 126 and 1 to 4 respectively. Visual representation of Z-attribute and N-attribute images from C2 are shown in Figure 6 below. These rasters may seem informative but a quick comparison of these images with respective intensity image shows exactly how much more information is stored within the intensity-attribute compared to elevation and # of returns attributes. This reduced range makes it more difficult for materials to be distinguished in images. For example, with a range of 1 to 4 for C2's N-attribute, theoretically only four different types of land cover can be distinguished at most whereas the intensity raster can distinguish up to 4085 different types. However, during testing the N-attribute produced better results than Z-attribute despite having shorter range of 18

data; e.g. 4 for N vs. 53 for Z. This strange trend has continued from our earlier tests. If attributes are not likely to increase classification results, perhaps attribute enhancement as used by our reference is the alternative solution to increasing accuracy.

Figure 6a. C2 - N raster. Range: 1-4

Figure 6b. C2 - Z raster. Range: 73-126

Figure 6c. C2- intensity raster. Range: 1-4085

Figure 6d. False-color-image (C2,C3,C1 = RGB)

19

5.3.

Spectral Indices

Spectral indices are simple band ratio used to enhance spectral properties of reflective surface on Earth. Multiple classification scenarios were ran with generic band ratios to detect if any spectral index would significantly contribute to increase the accuracy of land cover classification. The highest overall accuracy of 77.5% was produced by combining C2-I, C3-I, and a band ratio involving C1 and C3. Although the result is better than our baseline accuracy of 77%, the kappa coefficient is slightly lower. Another significant spectral index used during testing was the normalized-DSM (nDSM). This index is calculated by subtracting DSM from DEM. The inclusion of nDSM along with intensities used to perform classification produced the most favorable result of the project at 77.5% and kappa coefficient of 0.7, which is a 0.5% increase in accuracy and 0.01 increase in kappa coefficient from baseline. The nDSM is a byproduct of the elevation-attribute. The same elevation-attribute that decreased accuracy and kappa coefficient results in our earlier tests now yields better results. This result makes it plausible to assume other LIDAR attributes, elevation and # of returns, may be able to contribute information to the land cover classification process if used properly. The general consensus from our references was that the overall accuracy should increase by up to ~10% when nDSM is used as an additional parameter, however our project's results confirm that nDSM had only a 0.5% increase in land classification accuracy.

5.4.

Interpolators

Within our testing to determine advantages of multispectral LIDAR in land cover classification, a shallow dive was taken to test performances of the two most prominent point-toraster interpolation methods; inverse distance weighting and Kriging. The overall accuracy results of using Kriging interpolation seem slightly better all-around compared to IDW interpolation. Kriging has a maximum accuracy result of 76% while IDW has a maximum accuracy result of 77%. Both of these results were produced using only the intensities from the channels. The biggest difference between the two interpolators comes during the preprocessing of the data as it is being converted to raster. IDW averaged ~1 minute per file to complete the conversion while Kriging took a healthy ~11 minutes per file. The slight improvement in results are not worth the processing time needed to perform Kriging, especially in land cover classification where minor variations in range of values are negligible.

20

Figure 7a. Test - site's multispectral image being classified into 4 information classes; Vegetation (green), Buildings (yellow), Roads (red), and Ground (pink).

Figure 7b. Test - site's multispectral image being classified into 5 information classes; Vegetation (green), Water (blue), Buildings (yellow), Roads (red), and Ground (pink).

5.5.

Testing Site

During the execution of the workflow steps described in Figure 5, it was observed that the input scene greatly affects the land cover classification result. Ideally, a test-site would have evenly distributed land cover to aid in the classification process. If a test-site is predominately covered by vegetation then the classification process becomes biased and will more likely categorize pixels to the vegetation class over others. The sizable source of error contributed by the testing scene came during the supervised classification step. Figure 7a shows the test-site's classified image along with the four classes it was categorized into. When using the fifth water class as seen in Figure 7b, approximately 50% of the buildings were incorrectly classified. As water is only ~3% of the test site's scene composition, the decision was made to move forward with four classes for the entirety of the project. By omitting the water class from the classification process, a more favourable outcome was produced.

21

6. CONCLUSIONS
The intent of the study was to analyze the performance of Optech Titan's three active imaging channels and LIDAR attributes in land cover classification. Multispectral imagery had an overall accuracy result of 77%. This result is comparable to our references - M. Sitar (2015) and Morsy et al. (2017) - who had similar accuracy results of 69% and 77% respectively when using the multispectral portion of the Optech Titan sensor in land cover classification. The most accurate land cover classification result from our testing was 77.5%, which was produced as a special index scenario by using the three intensities along with the nDSM. Although the consensus amongst our references was that nDSM would increase the classification results by up to ~10%, our testing only resulted in a 0.5% increase. It is apparent from the results that the intensity-attribute provides the most useful information in land cover classification.

The highest monochromatic LIDAR accuracy result of 70% came from Channel 2 (NIR 1024 mm). Channel 2's accuracy is only 7% lower than multispectral imagery result. There are two distinct reasons why Channel 2 achieved the highest accuracy result amongst other channels; the test-site has over 50% vegetation land cover and material distinction at NIR. Vegetation is highly susceptible to NIR wavelengths and therefore can be easily distinguished from other land covers. Channel 1 and 3 had less-favorable results at 59.5% and 58% respectively.

Individual land cover classification tests on Z-attribute and N-attribute produced unfavorable results of 37% and 47.5% respectively. Other combinations using these exclusive LIDAR attributes with intensities resulted in disappointment. It is not surprising that Z-attribute and N-attribute contribute very little to multispectral imagery classification process since those methods rely on intensity values as the decision variable. In addition to testing spectral indices, a quick comparison of raster interpolators was carried out as well.

IDW has a maximum accuracy result of 77% while Kriging has a maximum accuracy result of 76% even though Kriging has slightly better accuracy results all-around for stacks tested. Both of these results were produced using only the intensities from the channels. The biggest difference between the two interpolators comes during the pre-processing of the data where Kriging took 10x more time to process. The slight improvement in results are not worth

22

the processing time needed to perform Kriging, especially in land cover classification where minor variations in range of values are negligible. Future work on this topic would revolve around creating spectral indices using LIDAR's exclusive elevation and # of returns attributes. Individually these attributes contribute very little to the multispectral image classification process but as observed with addition of nDSM to multispectral imagery, this attribute can be exploited to increase accuracy results. These attributes are best used with mathematical formulas as seen with LAStools to isolate bare-earth, trees, and buildings. Additional testing into creating spectral indices with mathematical formulas based around Z-attribute and N-attribute will provide further insight into performance of multispectral LIDAR in land cover classification.

23

APPENDIX A ­ EXECUTION WALKTHROUGH

Workflow to impartially compare classification results of monochromatic LIDAR, multispectral imagery, Optech Titan sensor, and Spectral Indices.

Test-site's LIDAR survey data collected in three different channels - C1, C2, and C3.

24

LIDAR data being converted into text files using LAStools.

LIDAR data in text-format loaded into ArcMap.

25

IDW interpolator used on LIDAR data to produce raster for X, Y, elevation. (Z value field = 3)

IDW interpolator used on LIDAR data again to produce raster for X, Y, intensity. (Z value field = 4)

26

IDW interpolator used on LIDAR data to produce raster for X, Y, # of returns. (Z value field = 5)

Kriging interpolator used on LIDAR data to produce rasters for intensity, # of returns, and elevation. 27

Results of IDW raster interpolations for C1 - intensity, # of returns, and elevation.

Results of IDW raster interpolations for C2 - intensity, # of returns, and elevation.

Results of IDW raster interpolations for C3 - intensity, # of returns, and elevation.

28

Results of Kriging raster interpolations for C1 - intensity, # of returns, and elevation.

Results of Kriging raster interpolations for C2 - intensity, # of returns, and elevation.

Results of Kriging raster interpolations for C3 - intensity, # of returns, and elevation.

29

Generic workflow of LULC classification. (Courtesy of ArcMap Help, 2013)

IDW rasters for the test-site are loaded into PCI Geomatics - Focus. The screen capture above is the false color image representation using C2-I, C3-I, C1-I = RGB. 30

The first classification testing was performed only on the intensity rasters.

Training areas for 4 distinct land covers were created.

31

Result of training areas and application of maximum likelihood classification.

Result of supervised classification.

32

Initiating accuracy assessment of classified image.

Overview of 200 point check distribution.

33

Accuracy assessment in progress.

Sample Report Listing and Error Matrix were created for each accuracy assessment performed.

34

Accuracy statistics were also created for each accuracy assessment.

Example of adding or changing raster(s) prior to other combination classification processing.

35

The new raster combination is put through the classification process using the same training areas and accuracy assessment point check to ensure standardized results.

Accuracy Statistics for the new combination is recorded and then another combination is trialed.

36

After the combinations have been classified, the results are compiled for comparison. The same process was applied to Kriging rasters as well.

37

REFERENCES
Ahokas, E., Hyyppä, J., Yu, X., Liang, X., Matikainen, L., Karila, K., & Holopainen, M. (2016). Towards Automatic Single-Sensor Mapping By Multispectral Airborne Laser Scanning. Isprs-International Archives Of The Photogrammetry, Remote Sensing And Spatial Information Sciences, 155-162. Bakula, K., Kupidura, P., & Jelowicki, L. (2016). Testing Of Land Cover Classification From Multispectral Airborne Laser Scanning Data. International Archives Of The Photogrammetry, Remote Sensing & Spatial Information Sciences, 41. Chen, B., Shi, S., Gong, W., Zhang, Q., Yang, J., Du, L., & Song, S. (2017). Multispectral Lidar Point Cloud Classification: A Two-Step Approach. Remote Sensing, 9(4), 373. Fernandez-Diaz, J. C., Carter, W. E., Glennie, C., Shrestha, R. L., Pan, Z., Ekhtari, N., & Sartori, M. (2016). Capability Assessment And Performance Metrics For The Titan Multispectral Mapping Lidar. Remote Sensing, 8(11), 936. Hartfield, K. A., Landau, K. I., & Van Leeuwen, W. J. (2011). Fusion Of High Resolution Aerial Multispectral And Lidar Data: Land Cover In The Context Of Urban Mosquito Habitat. Remote Sensing, 3(11), 2364-2383. Karila, K., Matikainen, L., Puttonen, E., & Hyyppä, J. (2017). Feasibility Of Multispectral Airborne Laser Scanning Data For Road Mapping. Ieee Geoscience And Remote Sensing Letters, 14(3), 294-298. Huang, X., Zhang, L., & Gong, W. (2011). Information Fusion Of Aerial Images And Lidar Data In Urban Areas: Vector-Stacking, Re-Classification And Post-Processing Approaches. International Journal Of Remote Sensing, 32(1), 69-84 Miller, C. I., Thomas, J. J., Kim, A. M., Metcalf, J. P., & Olsen, R. C. (2016, May). Application Of Image Classification Techniques To Multispectral Lidar Point Cloud Data. In Spie Defense+ Security (Pp. 98320x-98320x). International Society For Optics And Photonics. Morsy, S., Shaker, A., & El-Rabbany, A. (2017). Multispectral Lidar Data For Land Cover Classification Of Urban Areas. Sensors, 17(5), 958. Morsy, S., Shaker, A., El-Rabbany, A., & Larocque, P. E. (2016). Airborne Multispectral Lidar Data For Land-Cover Classification And Land/Water Mapping Using Different Spectral Indexes. Isprs Ann. Photogrammetry. Remote Sens. Spat. Inf. Sci, 3(3), 217-224.

38

Sitar, M. (2015). Beyond 3d Multispectral Optech Titan Opens New Applications For Lidar. Lidar News - Multispectral Mapping, 5(1), 10-15. Swirski, A., Larocque, D. P., Shaker, A., & Smith, B. (2015, December). New, Flexible Applications With The Multi-Spectral Titan Airborne Lidar. In Agu Fall Meeting Abstracts. Optech Titan Multispectral Lidar System. (2017). Optech Titan High Precision Environmental Mapping Specifications. Toronto, Canada. Retrieved From Http://Www.Teledyneoptech.Com/ Wichmann, V., Bremer, M., Lindenberger, J., Rutzinger, M., Georges, C., & Petrini-Monteferri, F. (2015). Evaluating The Potential Of Multispectral Airborne Lidar For Topographic Mapping And Land Cover Classification. Isprs Annals Of The Photogrammetry, Remote Sensing And Spatial Information Sciences, 1, 113-119. Xiaoliang, Z., Guihua, Z., Jonathan, L., Yuanxi, Y., & Yong, F. (2016). 3d Land Cover Classification Based On Multispectral Lidar Point Clouds. International Archives Of The Photogrammetry, Remote Sensing & Spatial Information Sciences, 41. Training Manuals: ArcMap Help. (2013). What is a LAS dataset? ArcGIS--Help | Desktop.arcgis.com. doi:http://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/what-is-a-lasdataset-.htm PCI Geomatics, Inc. (2015). Geomatica II - Course Guide Version 0.2. doi:http://www.pcigeomatics.com/pdf/TrainingGuide-Geomatica-2.pdf

39


