MORPHOLOGICALLY CONSTRAINED ADAPTIVE SIGNAL DECOMPOSITIONS IN STUDYING VENTRICULAR ARRHYTHMIAS by Krishnanand Balasundaram B.Sc., Ryerson University, Toronto, Canada, 2008 M.A.Sc., Ryerson University, Toronto, Canada, 2012 A dissertation presented to Ryerson University
in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the program of Electrical and Computer Engineering Toronto, Ontario, Canada, 2018 Â©Krishnanand Balasundaram, 2018

AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A DISSERTATION I hereby declare that I am the sole author of this dissertation. This is a true copy of the dissertation, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this dissertation to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my dissertation may be made electronically available to the public.

ii

MORPHOLOGICALLY CONSTRAINED ADAPTIVE SIGNAL DECOMPOSITIONS IN STUDYING VENTRICULAR ARRHYTHMIAS Doctor of Philosophy, 2018, Krishnanand Balasundaram, Electrical and Computer Engineering, Ryerson University

Abstract

Ventricular fibrillation (VF) is one of the major causes for sudden cardiac deaths (SCD). The duration from the onset of VF to SCD is a few minutes, making it difficult to study VF. This dissertation proposes methods to extract meaningful information from VF electrograms and formulate associations to underlying structural and physiological properties of the cardiac tissue and clinical events of interest during VF. This was achieved by analyzing clues in the electrograms during VF to infer the underlying anatomical and physiological properties of the cardiac tissue and certain clinical events of interest, which is otherwise not easily available. The proposed methods will be of great assistance for the diagnosis and treatment planning of cardiac arrhythmias. The proposed adaptive time-frequency (TF) signal decomposition was separated into two categories based on two purposes: (1) Time-specific event detection and (2) Time-averaged VA characterization. For the time-specific event detection (in this work rotor detection), electrogram signal features related to the rotor event were identified with an adaptive TF decomposition and a modified criterion function. Using the proposed features and a linear discriminant analysis based classifier with leave-one-out cross validation, overall classification accuracies of 80.77% and 79.41% were achieved in detecting rotor events and separating them from similar but non-rotor events. In the time-averaged ventricular arrhythmia characterization, previously established signal features were used to associate electrogram clues to the structural and physiological characteristics of the cardiac tissue. Using label-consistent K-means singular value decomposition dictionary learning process, dictionaries of TF basis functions were generated to capture specific electric structures iii

and physiological characteristics of the underlying cardiac tissue. The association of these characteristics with the extracted electrogram clues were validated using a cross-validation technique. The cross-validated results ranged from 65.58% to 81.80% for the 7 characteristics used in this study. Further to this, to build a decision-support system with non-linear separable capabilities that could automate and infer the heart events and/or characteristics from the identified electrogram signal structures, neural network models were generated. The cross-validated accuracies ranged from 66.99% to 85.90% for each of the developed models for the decision-support system.

iv

Acknowledgments
I would like to acknowledge my supervisor Dr. K. Umapathy for his guidance and motivation. I also thankfully acknowledge Mr. S. Masse and Dr. K. Nanthakumar from Toronto General Hospital for access to the intracardiac electrogram database used in this dissertation. I also acknowledge Dr. K. Nair for providing the clinical information on the retrospective isolated heart database. I would like to acknowledge the members of my lab for all of their assistance in any relevant work on the intracardiac electrogram database. Finally, I would like to acknowledge Dr. E. Vigmond on helping with the Luo-Rudy model. I would also like to thank my dissertation exam committee for their valuable feedback.

v

Dedication
I lovingly dedicate this dissertation to my parents and my brother. They served as an inspiration for my hard work and focus throughout my graduate studies. This dissertation is a testament to their loving support and guidance.

vi

Table of Contents
Author's Declaration Abstract Acknowledgments Dedication List of Figures List of Tables Acronyms Symbols 1 Introduction 1.1 Cardiovascular System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.1.1 1.2 Heart Electrophysiology . . . . . . . . . . . . . . . . . . . . . . . . . . . ii iii v vi xi xiv xix xxiii 1 2 2 8 9

Current Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2.1 Anatomical, Pathological and Physiological Characteristics . . . . . . . . .

1.3

Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 1.3.1 1.3.2 Objective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 Proposed Approaches and Contributions . . . . . . . . . . . . . . . . . . . 13

1.4

Dissertation Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 vii

2

Background 2.1 2.2

17

Time-Frequency Signal Decomposition . . . . . . . . . . . . . . . . . . . . . . . 17 Adaptive Time-Frequency Signal Decomposition . . . . . . . . . . . . . . . . . . 20 2.2.1 2.2.2 2.2.3 Wavelet Based Signal Decomposition . . . . . . . . . . . . . . . . . . . . 20 Matching Pursuit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 Dictionary Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

2.3 2.4 2.5 3

Pattern Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 Decision-Support System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Background Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 40

Time-Specific Event Detection 3.1 3.2

Time-Specific Event Background . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.2.1 3.2.2 3.2.3 Retrospective Arrhythmia Database . . . . . . . . . . . . . . . . . . . . . 45 In-Vivo Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 Luo-Rudy Synthetic Database . . . . . . . . . . . . . . . . . . . . . . . . 49

3.3 3.4 3.5

Rotor Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 Envelope Amplitude Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 Matching Pursuit Signal Decomposition . . . . . . . . . . . . . . . . . . . . . . . 57 3.5.1 3.5.2 3.5.3 3.5.4 Dictionary Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Modified Criterion Function . . . . . . . . . . . . . . . . . . . . . . . . . 59 EAV MP and Rotor Event . . . . . . . . . . . . . . . . . . . . . . . . . . 65 Feature Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

3.6

Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 3.6.1 3.6.2 3.6.3 EAV Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 EAV MP Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

3.7

Chapter 3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90

viii

4

Time-Averaged Ventricular Arrhythmia Characteristics 4.1 4.2 4.3 4.4

91

Time-Averaged Characteristics Background . . . . . . . . . . . . . . . . . . . . . 91 Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 Correlation of Time-Averaged Characteristics with APP . . . . . . . . . . . . . . . 96 LCKSVD Dictionary Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 4.4.1 4.4.2 LCKSVD Dictionary Learning Process . . . . . . . . . . . . . . . . . . . 102 LCKSVD Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108

4.5 5

Chapter 4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 135

Decision-Support System 5.1 5.2

Decision-Support System For the Diagnosis of Ventricular Arrhythmias . . . . . . 135 Time-Specific Event Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 5.2.1 5.2.2 Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 Cross-Validated Results and Discussion . . . . . . . . . . . . . . . . . . . 143

5.3

Time-Averaged General Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147 5.3.1 5.3.2 Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 Cross-Validated Results and Discussion . . . . . . . . . . . . . . . . . . . 149

5.4 6

Chapter 5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 163

Conclusions and Future Works 6.1

Summary of Results and Impact . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 6.1.1 Potential Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166

6.2

Direction for Future Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167 169 172

A Appendix A: EAV MP Decomposition Proof B Appendix B: Weights and Bias for the Decision-Support System

B.1 Weights and Bias for Time-Specific Event Model . . . . . . . . . . . . . . . . . . 172 B.1.1 B.1.2 Stage 1: PS vs. Non-PS Model . . . . . . . . . . . . . . . . . . . . . . . . 173 Stage 2: Rotor vs. Non-Rotor Model . . . . . . . . . . . . . . . . . . . . . 174 ix

B.2 Weights and Bias for Time-Averaged Model . . . . . . . . . . . . . . . . . . . . . 175 B.2.1 B.2.2 B.2.3 B.2.4 B.2.5 B.2.6 B.2.7 Bibliography Time-Averaged General Model: Cardiomyopathy . . . . . . . . . . . . . . 176 Time-Averaged General Model: DCM MAP . . . . . . . . . . . . . . . . 177 Time-Averaged General Model: DCM ARI . . . . . . . . . . . . . . . . . 178 Time-Averaged General Model: ICM MAP . . . . . . . . . . . . . . . . . 179 Time-Averaged General Model: ICM ARI . . . . . . . . . . . . . . . . . . 180 Time-Averaged General Model: ICM Vol . . . . . . . . . . . . . . . . . . 181 Time-Averaged General Model: ICM DVDT . . . . . . . . . . . . . . . . 182 184

x

List of Figures
1.1 1.2 1.3 1.4 1.5 2.1 2.2 2.3 2.4 2.5 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 Intercalated Discs in the Muscle Fiber . . . . . . . . . . . . . . . . . . . . . . . . Electrical Conduction pathways of the heart . . . . . . . . . . . . . . . . . . . . . Normal Sinus Rhythm (ECG) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Typical Ventricular Arrhythmia Electrograms . . . . . . . . . . . . . . . . . . . . 3 4 5 6

Dissertation Block Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Heisenberg Uncertainty in the Fourier Transform [1] . . . . . . . . . . . . . . . . 19 Sample Wavelet Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Heisenberg Uncertainty in the Wavelet Transform [1] . . . . . . . . . . . . . . . . 22 Sample MP Decomposition of an Arrhythmia Signal . . . . . . . . . . . . . . . . 27 Example Neural Network Model Diagram . . . . . . . . . . . . . . . . . . . . . . 38 Contributions for Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 Unipolar Electrogram Patterns Â©[2013] IEEE . . . . . . . . . . . . . . . . . . . . 43 Bipolar Electrogram Patterns [2] . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Electrode Array . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 Sample Phase Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 Sample Electrograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 Sample Electrogram Illustrating the Envelope and Carrier Components . . . . . . . 55 Signal Decomposition Between the Two Types of MP for a Sample Signal After 100 Iterations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

3.9

Synthetic Amplitude Modulated Signals . . . . . . . . . . . . . . . . . . . . . . . 63

3.10 Residual Component of the Synthetic Signal With 0.9 MI . . . . . . . . . . . . . . 64 xi

3.11 Teager-Kaiser Energy over 100 iterations for each Synthetic signal . . . . . . . . . 65 3.12 Scale-Frequency Map of EAV MP vs ORG MP for Rotor PS . . . . . . . . . . . . 66 3.13 Original Signal, Approximated and Residual Component of an Electrogram with EAV MP After 100 Iterations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 3.14 Corresponding Phase Maps for the Sample Electrogram in Figure 3.13 . . . . . . . 69 3.15 Original Signal, Approximated and Residual Component of a Simulated Electrogram with EAV MP After 100 Iterations . . . . . . . . . . . . . . . . . . . . . . . 71 3.16 Corresponding Phase Maps for the Sample Simulated Electrogram in Figure 3.15 . 72 3.17 Residual Component of the Simulated Electrogram and the Corresponding Instantaneous Frequency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 3.18 Residual Component and Corresponding IF with Identified Time Samples . . . . . 76 3.19 Approximated FD Feature Boxplot for the Rotor-PS, Non-Rotor PS and Non-PS Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 3.20 EAV Approximated RMS Feature Boxplot for the Rotor PS and Non-Rotor PS Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 3.21 Two Stage Classification for the Time-Specific Event . . . . . . . . . . . . . . . . 80 3.22 Average MI Between the Rotor PS and Non-PS events for RDB . . . . . . . . . . 81 3.23 Average MI Between the Rotor PS and Non-PS events for LRDB . . . . . . . . . . 82 3.24 Average MI Between the Rotor PS and Non-Rotor PS events for RDB . . . . . . . 82 3.25 Approximated FD Feature Boxplot for IVDB . . . . . . . . . . . . . . . . . . . . 86 3.26 EAV Approximated RMS Feature Boxplot for IVDB . . . . . . . . . . . . . . . . 87 4.1 4.2 4.3 4.4 4.5 4.6 4.7 Contributions for Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 Unipolar Electrogram Patterns Â©[2013] IEEE . . . . . . . . . . . . . . . . . . . . 94 LCKSVD Process to Arrive at a Trained Dictionary . . . . . . . . . . . . . . . . . 103 Average Accuracies for different  and  for the Cardiomyopathy LCKSVD . . . . 110 Average Accuracies for Different Iterations for the Cardiomyopathy LCKSVD . . . 111 Sample Weighted Average Sparse Code for DCM vs ICM . . . . . . . . . . . . . . 112 Scale-Frequency Map for DCM versus ICM . . . . . . . . . . . . . . . . . . . . . 115 xii

4.8 4.9

Scale-Frequency Map for Normal versus Abnormal DCM MAP . . . . . . . . . . 118 Scale-Frequency Map for Normal versus Abnormal DCM ARI . . . . . . . . . . . 121

4.10 Scale-Frequency Map for Normal versus Abnormal ICM MAP . . . . . . . . . . . 124 4.11 Scale-Frequency Map for Normal versus Abnormal ICM ARI . . . . . . . . . . . 127 4.12 Scale-Frequency Map for ICM Healthy versus Scar Electrograms . . . . . . . . . . 130 4.13 Scale-Frequency Map for ICM Normal versus Abnormal DVDT . . . . . . . . . . 133 5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 Contributions for Chapter 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 Decision-Support System Diagram . . . . . . . . . . . . . . . . . . . . . . . . . . 138 Diagram for the Time-Specific Event Model . . . . . . . . . . . . . . . . . . . . . 140 Diagram for the Time-Averaged General Model . . . . . . . . . . . . . . . . . . . 140 Distribution of the Standard Deviation of the Max Voltage for the Rotor Event . . . 141 Standard DSS Neural Network Architecture . . . . . . . . . . . . . . . . . . . . . 144 Distribution of the Second Hidden Layer for the Time-Specific Event Model . . . . 148 Distribution of the Second Hidden Layer for the Time-Averaged General Model . . 161

xiii

List of Tables
3.1 3.2 3.3 3.4 3.5 3.6 3.7 Average ER for each dictionary type . . . . . . . . . . . . . . . . . . . . . . . . . 58 Confusion Matrix - Average MI for RDB: Rotor PS Versus Non-PS Event . . . . . 81 Confusion Matrix - Average MI for LRDB: PS Event Versus Non-PS Event . . . . 83 Confusion Matrix - Stage 1 Percentage: PS Versus Non-PS Event . . . . . . . . . . 84 Confusion Matrix - Stage 2 Percentage: Rotor PS Versus Non-Rotor PS Event . . . 84 Confusion Matrix - Stage 1 Entropy Percentage: PS Versus Non-PS Event . . . . . 85 Confusion Matrix - Stage 2 Entropy Percentage: Rotor PS Versus Non-Rotor PS Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 4.1 4.2 4.3 4.4 4.5 4.6 APP Characteristic Range for Normal and Abnormal . . . . . . . . . . . . . . . . 97 Feature P-Value and Classification versus APP Characteristic . . . . . . . . . . . . 99 Feature P-Value and Classification versus APP Characteristic for DCM Hearts . . . 100 Feature P-Value and Classification versus APP Characteristic for ICM Hearts . . . 100 Cardiomyopathy LCKSVD Dictionary Learning Parameter Values . . . . . . . . . 111 Classification of Cardiomyopathy Hearts Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 4.7 4.8 DCM MAP LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . . 117 Classification of Normal and Abnormal DCM MAP Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119 4.9 DCM ARI LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . . 120

4.10 Classification of Normal and Abnormal DCM ARI Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122

xiv

4.11 ICM MAP LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . . 123 4.12 Classification of Normal and Abnormal ICM MAP Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 4.13 ICM ARI LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . . . 126 4.14 Classification of Normal and Abnormal ICM ARI Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 4.15 ICM Vol LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . . . 129 4.16 Classification of Healthy and Scar for ICM Episodes Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131 4.17 ICM DVDT LCKSVD Dictionary Learning Parameter Values . . . . . . . . . . . 132 4.18 Classification of normal and abnormal DVDT for ICM Episodes Using the Finalized LCKSVD Trained Dictionary . . . . . . . . . . . . . . . . . . . . . . . . . . 132 5.1 5.2 5.3 Confusion Matrix - Stage 1 Percentage: PS Versus Non-PS Event . . . . . . . . . . 144 Confusion Matrix - Stage 2 Percentage: Rotor PS Versus Non-Rotor PS Event . . . 145 Confusion Matrix - Stage 1 Percentage: Simulated Electrogram PS Versus Non-PS Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 5.4 5.5 5.6 5.7 5.8 5.9 Confusion Matrix - Stage 2 Percentage: Rotor-PS Versus Non-Rotor PS Event . . . 146 Confusion Matrix - Time-Averaged General Model-Cardiomyopathy Percentage . . 150 Confusion Matrix - Time-Averaged General Model-DCM MAP Percentage . . . . 152 Confusion Matrix - Time-Averaged General Model-DCM ARI Percentage . . . . . 154 Confusion Matrix - Time-Averaged General Model-ICM MAP Percentage . . . . . 155 Confusion Matrix - Time-Averaged General Model-ICM ARI Percentage . . . . . 157

5.10 Confusion Matrix - Time-Averaged General Model-ICM Vol Percentage . . . . . . 158 5.11 Confusion Matrix - Time-Averaged General Model-ICM DVDT Percentage . . . . 160

xv

Acronyms
aMI - Approximated Modulation Index

ANOVA - Analysis of Variance

APD - Action-Potential Duration

APP - Anatomical, Pathological and Physiological

ARI - Activation Recovery Interval

aRMS - Approximated Root-Mean-Square

A-V - Atrio-Ventricular

BPM - Beats-Per-Minute

DCM - Dilated Cardiomyopathy

DF - Dominant Frequency

DSS - Decision-Support-System

DVDT - Time Derivative of the Voltage Signal

EAV - Envelope Amplitude Variation

xvi

EAV MP - Envelope Amplitude Variation Based Matching Pursuit

ECG - Electrocardiogram

ER - Energy Ratio

FD - Frequency Deviation

FRDB - Faber-Rudy Database

ICD - Implantable Cardioverter Defibrillator

ICM - Ischemic Cardiomyopathy

IDFT - Inverse Discrete Fourier Transform

IF - Instantaneous Frequency

IVDB - In-Vivo Database

KSVD - K-Means Singular Value Decomposition

LCKSVD - Label-Consistent K-Means Singular Value Decomposition

LDA - Linear Discriminant Analysis

LOO - Leave-One-Out

xvii

LRDB - Luo-Rudy Database

MAP - Monophasic Action Potential

MI - Modulation Index

MP - Matching Pursuits

OMP - Orthogonal Matching Pursuits

ORG MP - Original Matching Pursuits

PS - Phase-Singularity

RDB - Retrospective Database

S-A - Sino-Atrial

SCD - Sudden Cardiac Death

STD - Standard Deviation

TF - Time-Frequency

VA - Ventricular Arrhythmia

VF - Ventricular Fibrillation

xviii

VT - Ventricular Tachycardia

xix

Symbols
 - Control of the Contribution of the Sparse Component

 - Control of the Contribution of the Class Label Component

 - Orthogonal Matching Pursuit Coefficient Multiplication Factor

 - Singular Value Matrix

 - Matching Pursuit Iteration

 - Orthogonal Component for the Newest Atoms

 - Set of the Translation (m), Scaling (s) and Frequency Modulation ( ) Parameters

 - Observations

 - Neural Network Learning Rate

 - Weights of the Classifier

 - Phase of Analytic Signal

 - Wavelet Function

 - Orthogonal Matching Pursuit Atom Expansion Coefficient

xx

 - Atom Iteration from 1 to 

 - Frequency Modulation of an Atom

 - Dictionary

A - Signal Amplitude

aF D - Approximated Frequency Deviation

aM I - Approximated Modulation Index

b - Atom Expansion Coefficient

C - Matching Pursuit Criterion Function

cl - Classes

[CL] - Class Labels

d - Number of Input Parameters

e - Error Term

EAV - Envelope Amplitude Measure

ER - Energy Ratio

xxi

f - Signal

F - Fourier Transform of Signal f

g - Atom (Mathematical Function)

h - Hidden Layer Neurons

hf - Short Time Fourier Transform Window Function

J () - Criterion Function for the Classifier

l - Frequency

m - Time Shift (Translation)

M - Magnitude of Analytic Signal

M F - Neural Network Modulation Function

M I - Modulation Index

N - Total Signal Length

n - Time Sample

q - Neural Network Training Iterations

xxii

[Q] - Discriminative Sparse Codes

R - Residual Observations

Rf - Residual

s - Scale Parameter

Sf - Short Time Fourier Transform

sgn - Signum Function

SS - Sum of Squares

StatF - F-Statistic

T - Treatment Observations

[T M ] - Transformation Matrix

t - Target Output Parameter

U - U Eigenvector

us - Step Function

V - V Eigenvector

xxiii

[W ] - Classifier Matrix

W f - Wavelet Transform

x - Neural Network Input Parameter

y - Analytic Signal of Signal f

z - Neural Network Output Parameter

xxiv

Chapter 1 Introduction

O

NE of the important systems in the human body is the circulatory system. This system transports blood throughout the body, which is essential for all the vital organs and systems.

Through the transport of blood, cells within these organs and systems exchange oxygen, carbon dioxide and other essential nutrients. If this exchange is absent for a long duration, the cells begin to deteriorate and eventually die. The heart is the primary component of the circulatory system responsible for blood transport. Heart acts as an versatile electromechanical pump, providing the pressure required to circulate the blood to the remainder of the body. Rhythmic electrical stimulus from the sino-atrial node of the heart coupled with the biochemical processes, generate and propagate action potentials over the myocardium resulting in a coordinated and rhythmic contraction and expansion of the heart. Due to various patho-physiological reasons, when the electrical activity of the heart becomes arrhythmic, it leads to cardiac arrhythmias. Depending on the anatomical origin of these arrhythmias, they are broadly classified as atrial arrhythmia and ventricular arrhythmia (VA). Of these arrhythmias, VA (specifically ventricular fibrillation [VF]) is one of the leading causes of cardiac arrest and sudden cardiac death (SCD) [3]. Cardiac arrest is believed to cause between 300,000 to 400,000 deaths on an annual basis in the United States alone [4]. During a VA episode, the electrical activations of the ventricles of the heart become abnormal, thereby resulting in uncoordinated and ineffective ventricle contractions causing reduced or no blood output from the heart. Research into VA has led to a few prevailing theories on the onset and genesis of the arrhythmia;

1

however, there is yet to be a definitive theory that can fully explain this phenomenon. A major obstacle in studying VA (specifically VF) is its lethality and short observation time window as SCD occurs within minutes of the onset of VF. This makes it practically impossible to study VA in a living subject to detect events of clinical interest or perform active interventions to extract and associate the underlying patho-physiological characteristics of the cardiac substrate in the genesis of VAs. In current practice, often these patho-physiological relations are deduced using special research setups to study the heart as an isolated organ (i.e. not part of a living subject) and postmortem analysis. If using engineering methods we could infer: (i) specific events of clinical interest during VA and (ii) dynamic/static characteristics of the underlying cardiac substrate of VAs using their manifestation on multi-channel electrogram morphologies, this would be a significant step towards studying VAs. As a positive step in this direction, this dissertation presents adaptive signal decomposition methods in extracting spatio-temporal information from multi-channel electrograms that could provide inference on relevant events of clinical interest and patho-physiological characteristics of cardiac substrate during VAs.

1.1

Cardiovascular System

This section begins by discussing the general functionality of the heart during normal sinus rhythm and during a VA episode. The cardiac substrate characteristics relevant for ventricular arrhythmias will be explored in the later part of this section.

1.1.1 Heart Electrophysiology
Normal Sinus Rhythm It is important to understand the normal electrophysiology of the heart prior to further discussing VA. This section will briefly summarize heart's electrophysiology from the "Textbook of Medical Physiology" [5]. The interested reader may refer to Chapter 3 for more detailed information. The muscle structure of the heart is composed of atrial muscle fibers, ventricle muscle fibers and the specialized excitation and conductive muscles. The specialized excitation and conductive 2

Intercalated discs allows the heart to propagate a single electric impulse through the muscle strands in order to provide a simultaneous contraction.

Figure 1.1: Intercalated Discs in the Muscle Fiber muscles are limited in their ability to contract as regular muscle fibers; however, they serve a significant purpose in propagating an electric impulse through the heart. The atria and ventricle muscle fibers are responsible for creating the pressure to transport blood through to the rest of the body. The muscle fibers of the atria and ventricle are made of muscle fibers that are interconnected through intercalated discs, which are different from other types of muscle fibers found within the human body. The intercalated discs (illustrated in Figure 1.1) allow for the electric impulse to propagate between the strands. This helps create a simultaneous contraction of the muscles, creating the aforementioned pressure required. The heart is made up of four chambers: the two atrias that act as a primer by forcing blood into the ventricles, and the two ventricles that create pressure to transport blood to the rest of the body. The electrical system of the heart is presented in Figure 1.2. The initiation of the electric impulse responsible for contracting the heart begins at the sino-atrial (or sinus) node (S-A node). This activation propagates through the internodal pathways in the atria to the atrioventricular node (AV node). As the impulse propagates to the A-V node, the atria contracts, pushing the accumulated blood into the ventricles. Upon reaching the A-V node, the impulse is slightly delayed through the 3

Figure 1.2: Electrical Conduction pathways of the heart A-V bundle before progressing further into the left and right bundle branch. The delay allows for simultaneous contraction of ventricle muscle fibers as well as for the atria to pump blood into the ventricles. Finally, the impulse propagates through the ventricles. Once a cell within the muscle fiber has been activated by the electric impulse, it will contract for a brief period of time (known as depolarization) before eventually relaxing (known as repolarization). This rhythmic activation of the electric impulse is autonomous and can also be initiated in other regions of the conduction pathway other than the S-A node. A typical normal sinus rhythm observed as electrical activity on the surface of the body is illustrated in Figure 1.3 and is referred to as the electrocardiogram (ECG). It begins with the P wave, which is representative of the electrical impulse traveling from the sino-atrial node to the atrioventricular node, causing the atria to contract. The QRS complex captures the depolarization 4

Figure 1.3: Normal Sinus Rhythm (ECG) of the ventricles and the T wave is caused by the repolarization of the ventricles. This process makes up one heart beat, with an average resting heart rate of 72 beats per minute (bpm) [5]. The electrical activity can also be directly recorded on the outer surface of the heart, which is referred to as an epicardium electrogram, or from within the ventricles (or atria) of the heart, which is referred to as an endocardium electrogram. In general in the context of cardiac electrophysiology, ECGs refer to electrical activity measured on the surface of the body and electrograms refer to electrical activity on the surface of the heart. Ventricular Arrhythmias During a VA episode, abnormal electrical activations dictate the contractions (or lack there/of) in the ventricles of the heart. The two prominent types of ventricular arrhythmias are ventricular tachycardia (VT) and VF. VT is a condition that causes the ventricles to beat (contract and expand) 5

Sample VT Signal
0.04

0.03

0.02

Amplitude (arbitrary units)

0.01

0

-0.01

-0.02

-0.03

-0.04

0

1

2

3

4

5

6

7

8

9

10

Time (s)

(a) VT Electrogram
Sample VF Signal
0.06

0.04

Amplitude (arbitrary units)

0.02

0

-0.02

-0.04

-0.06

0

1

2

3

4

5

6

7

8

9

10

Time (s)

(b) VF Electrogram

Figure 1.4: Typical Ventricular Arrhythmia Electrograms abnormally fast (i.e. heart rate around 150 bpm [5]). VF, on the other hand, is characterized by a heart rate which exceeds that of VT and is a lethal condition because there is no coordinated contraction of the ventricles. This can lead to sudden cardiac death if not treated within minutes of its onset. VA remains a field of intensive research due to their persistently high fatality rate, despite nearly over a century of research. A sample electrogram of the two prominent types of VA is provided in Figure 1.4. It should be noted that VT (Figure 1.4a) is classified as an abnormally fast rhythmic beating of the ventricles, which does not include the increase in heart rate during physical exercise. Rather, this increase in heart rate is related to physiological conditions or factors. An increase in body temperature, stimulation of the heart's nerves from the central nervous system and toxic conditions are some examples of factors found to cause VT [5]. The blood volume output of the heart during VT is limited as the increase in heart rate (and non-PQRST sequence) does not allow sufficient time for the ventricles to fill completely with blood, subsequently diminishing the blood pressure. Some common side effects of VT include shortness of breath, dizziness, and even fainting. VT was also

6

observed to be polymorphic in nature [6], where disorders change the nature of the contractions and electrogram signal structure observed during the VT episode. The far more lethal of the arrhythmias is VF. During VF (Figure 1.4b), the electrical activation of the heart is non-rhythmic, leading to non-uniform contraction of the ventricles. Without a coordinated contraction, the heart produces little to no cardiac output, thus almost no blood flow. If there is no blood flow through the cardiovascular system, none of the organs (including the heart) receive nutrients or oxygen. Within a few minutes, the cells within the organs begin to die off, leading to sudden cardiac death if left untreated. Some of the known factors that cause VF include ischemia of the heart muscles, ischemia of the heart's conduction system, abnormalities in the conduction pathways, and electric shocks. It is also possible for someone suffering from a VT episode to develop a VF episode. Due to the reduction of blood flow during VT, the heart muscles will begin to degrade, causing uncoordinated conduction of the electrical impulse or uncoordinated contractions due to the muscle degradation. Even with the current understanding of VA, there is still a lot of uncertainty on the mechanisms that initiate and drive VF. Depending on the type of arrhythmia affecting someone, the short and long-term treatment options are different. When considering a patient suffering from VT, one of the immediate treatment option is to provide electrical pacing to slow the heart rate back to normal sinus rhythm, while for someone who is afflicted with VF, the standard immediate treatment option is to provide a defibrillation shock in an attempt to reset the heart's electrical conduction system [7]. As long term treatment options of the arrhythmias, for patients that are prone to recurring VT, the following are administered: anti-arrhythmic medications, ablation therapy, and placement of an implantable cardioverter defibrillator (ICD). The ICDs are also a long-term option for VF, and usually ICDs are equipped with intelligence to choose between defibrillation shock therapy or pacing depending on the type of arrhythmia [8]. Existing research has shown that a better understanding of the underlying characteristics (either one or a combination of anatomical, pathological and physiological characteristics) affecting the heart could lead to improved treatment of the arrhythmia [9Â­11].

7

1.2

Current Research

Specific to the subject of this dissertation, there are several characteristics of the heart that are known to influence the initiation and maintenance of the VA episode. The interaction of the electrical activations between the healthy and scar tissue can influence the arrhythmic episode [12]. The type of disease affecting the scar tissue [13, 14] is also an example of the characteristic that is associated with the genesis of VA. The study of specific characteristics of the action potential has been shown to play an important factor in influencing the therapy choice [15Â­17]. The heart's wall motion velocity as well as the ejection fraction are two measures that determine the capability of the ventricles of the heart [18, 19]. However, these characteristics cannot be accessed without intervention, and hence difficult to use in treatment planning. There have been a few studies that attempted to infer the underlying characteristics of the heart based on features extracted from the electrograms. The analysis of the electrogram characteristics (particularly frequency) were observed to have a correlation with the diameter of the left ventricle [20], but there was no observed relation to the mass of the heart. The conduction velocity and amplitude were used as determining factors for reducing the recurrence of future VT episodes [21]. The study of delayed potentials causing fractionation in the electrograms were observed to have a relation for patients with hypertrophic cardiomyopathy [22]. An electrogram signal structure known as the double potential was also previously identified as having a correlation to the vicinity of a conduction block in the myocardium of the heart [23]. The regional differences in the dominant frequencies of the heart were also observed to reflect the characteristics of the heart [24]. Research has also revealed there to be specific or averaged characteristics of the electrogram without any knowledge on the heart's characteristics. For example, the occurrence of amplitude variations observed on the electrograms were used as a determinant in whether a defibrillating shock would be successful in resuscitating the heart from an arrhythmic episode [25]. Features that characterize the electrograms (such as the amplitude spectrum area) were observed to be a marker that predict successful shock outcome [26], but have been only marginally successful in understanding the etiology of the heart [27]. The analysis of the normal electrical activations in a bipolar electrogram demonstrated that these activations to could be used to determine the organi8

zational aspect of the arrhythmia [28]. Further research on the organization of the arrhythmia had observed that regions of the heart that had a variation in its local dominant frequency were more susceptible to the forming of rotors [29]. These rotors are believed to be centres where the ventricular arrhythmia originates [30Â­33]. Rotors are of special clinical interests as detecting them and tracking them could lead to termination of VA through ablation [2, 34]. A conference proceeding by our group revealed that there exists different distributions of a few repeating electrogram signal patterns during an arrhythmic episode [35]. Based on the above discussed existing literature there seems to be evidence that the electrogram signal structures during VA may have associations with specific events of clinical interest and different characteristics of VA, which could be stemming from different patho-physiological combinations occurring in the underlying cardiac substrate. As discussed earlier, although there are works that have associated patho-physiological characteristics with VA [12Â­14], often this is done postmortem or using special isolated organ setups. If the information on the underlying cardiac substrate is made available during VA for a live subject without interventions, it would positively impact the treatment options. Multi-channel electrical activity of the heart is relatively easier to acquire (such as ECG from the body surface, electrograms from the walls of the heart using ICDs, or using forward-inverse solutions). Therefore, if we can infer specific events of clinical interest and the underlying characteristics of the cardiac substrate using electrograms, it will be an invaluable clinical tool, as simply the availability of this information can inspire new treatment options and optimize existing treatment options.

1.2.1 Anatomical, Pathological and Physiological Characteristics
The myocardium along with the components of the electrical conduction system of the heart all play a part in the genesis and maintenance of VA. There are evidences in the literature that both dynamic and static characteristics of the underlying cardiac substrate does influence VA [12, 23, 24, 31]. Although there are numerous static and dynamic characteristics of cardiac tissue that could influence VA, for the purpose of this dissertation we will restrict them to static: anatomical and pathological information of the cardiac tissue and dynamic: physiological information of

9

the cardiac tissue. Here, pathological information can be grouped both in static and dynamic characteristics depending on the temporal observation period and progression of the pathology. These anatomical, pathological, and physiological characteristics of the heart will be abbreviated as the APP characteristics for the remainder of the dissertation. As explained previously, despite their significance in influencing the VA episode, it is difficult to obtain the APP characteristics of a heart in a non-invasive manner. This research, conducted in collaboration with Toronto General Hospital, provided us with access to a special retrospective multi-channel electrogram arrhythmia database using isolated heart experiments that had also recorded the APP characteristics (obtained during experiments, from health records, and postmortem analysis). Therefore, this retrospective data can be used to associate the signal morphologies in the multi-channel electrograms with specific APP characteristics. The APP characteristics that were recorded and will be used in this dissertation are presented below. Anatomical - Scar Tissue Scar tissue refers to diseased or dead muscle tissue of the heart and is considered a static (i.e. does not change) characteristic of the cardiac substrate. Usually the spatial distribution of the scarhealthy regions are obtained postmortem (accurate) or using invasive catheter procedures (approximated by sampling bipolar voltages on few locations). The ability to identify this type myocardial region is important in diagnosing patients that are prone to ventricular arrhythmias. Existing research [12, 36, 37] has shown that the border regions between healthy and scar tissue could be targeted for ablation therapy in order to better control or prevent the re-occurrence of ventricular arrhythmia. There are also studies that have shown rotors (i.e. events of interest during VA) tend to anchor around the scar healthy border zones [9,38]. Researchers have tried to use medical imaging (positron emission tomography and computed tomography [39], MRI [40], and ultrasound [41]) to identify possible scar sites, but these are time consuming and may not be readily available. If the spatial extent of the regional scar regions can be inferred from the multi-channel electrogram morphologies in a non-invasive manner, this could assists the clinician to devise patient specific treatment plans. Especially for ICDs and catheter procedures, this information will be vital in

10

planning shock/ablation therapy, which involves shocking/burning regions of the heart in order to prevent these regions from triggering future arrhythmic episodes. Pathological - Cardiomyopathy Cardiomyopathy describes the underlying disease affecting the heart muscle, which may be related to the anatomical and physiological abnormalities in the heart. This characteristic in this dissertation is treated as static for a given VA episode or heart since the data used in this dissertation is from isolated hearts. There are two common types of cardiomyopathies: ischemic cardiomyopathy (ICM) and dilated cardiomyopathy (DCM). For someone suffering from ICM, typically the heart muscles become damaged or deceased because of a lack of blood flow to the muscle itself. This can occur if there is myocyte loss (leading to loss of blood flow deeper into the tissue), coronary artery disease, hypertension or artery occlusion [13, 42]. The lack of blood flow will eventually either deteriorate or completely kill the muscle tissue. Therefore, the healthy regions of the heart (i.e. the parts with adequate blood supply) will grow in muscle mass to compensate for the dead muscle tissues. These dead regions can impede the action potential propagation and therefore may cause future VA episodes. During DCM, the heart muscle becomes diseased and dies out. The death of the muscles in this case is not due to a lack of blood flow. The dilation of the heart can be caused by several factors such as electrolyte imbalance, ion-channel disruption, apoptosis (due to genetics) and alcohol, among others [14, 43]. The enlargement of the heart in a patient suffering from DCM is due to the disease affecting the heart muscle within the scar region. Similar to ICM, the healthy regions will become larger as well to compensate for the decreased output. It is often difficult to determine the type of cardiomyopathy affecting the patient, and sometimes genetic testing [44] and/or myocardial biopsy (muscle sample) [45] are required. The type of cardiomyopathy affecting the patient is of special interest as it can help clinicians narrow down the unique therapy for each type. VF initiated in ICM hearts are believed to be a result of the healthy and scar boundary electrical interactions, which results in a targeted treatment solution [46, 47]. The are many underlying etiologies affecting DCM hearts, leading to many other possible therapy

11

options [46, 48]. The characteristics of the disease may be inferred by studying the electrical activations since the activations are a reflection of the myocardium muscle health. Physiological Functional aspects of the cardiac tissue are captured by physiological measurements. Few of the well known measures that play a role in the arrhythmia are derived from the action potential, as this is the primary impulse that initiates the muscle contraction. The action potential characteristics can be dynamic (i.e. constantly changing) over the course of a VA episode. Action potential duration and the activation recovery time [10] are two well known measures. The action potential duration refers to the time width of the action potential that depolarizes the heart muscle. The activation recovery time refers to the time taken from when the cell begins depolarizing to the time when the cell finishes repolarizing. It was observed that the therapy selected by a clinician could be better optimized based on these characteristics [15, 16]. Another measure used to characterize the action potential is the slope of the action potential itself (referred to as DVDT). This is used to determine whether the cell has the ability to properly depolarize [17], which influences the contraction strength. The standard slope may be used to determine the healthiness of a particular cell or tissue. These characteristics of the action potential are usually difficult to measure from the natural action potential generated by the heart. Therefore, typically a pacing impulse is initiated to record the cell's action potential in response to this pacing impulse. The above mentioned characteristics is then recorded from the resulting action potential. Similar to the previous anatomical and pathological characteristics, it is difficult to obtain these measures from a live subject, since the pacing impulse cannot be applied directly to the heart. Therefore, it is imperative and would be valuable if we could infer the influence of these measures on the electrograms.

1.3

Motivation

The VA (specifically VF) is a major cause of SCDs annually in North America. Based on the existing literature, the influence of the APP characteristics on VA is evident. Likewise, literature also has shown there are spatio-temporal events (rotors) during VA that could provide valuable 12

information in terminating VAs. However, the lethal nature of VA and the practical infeasibility in obtaining APP characteristics in a non-invasive manner are obstacles in studying VA. Given that literature has shown that there exists relationships between the electrograms and APP characteristics (and in turn could influence specific events) [20, 22], this dissertation will develop adaptive signal decomposition methods to extract information from multi-channel electrograms that could be used to infer specific events and the APP characteristics during VAs. The outcome of this research will be a positive step in coding the inaccessible (in live subjects) spatio-temporal events during VA and APP characteristics in terms of multi-channel electrogram features. The association of the APP characteristics with the electrogram morphologies could help improve the accessibility of obtaining the underlying characteristics of the heart, which may inspire new directions in treatment option that would eventually reduce the number of fatalities as a result of SCD.

1.3.1 Objective
The objective of this dissertation is to develop adaptive signal decomposition and dictionary learning approaches for: (i) time-specific event detection during VAs and (ii) quantifying time-averaged VA characteristics driven by APP characteristics. The outcomes of these approaches will be used as inputs to a decision-support system (DSS) that will automate and assist clinicians in inferring the VA events and/or APP characteristics. In achieving the objective, the following section elaborates on the proposed approaches and contributions of this dissertation.

1.3.2 Proposed Approaches and Contributions
The contribution by the time-specific event detection aims to develop an adaptive time-frequency (TF) decomposition for capturing specific electrogram signal structures associated with certain VA events. These events, such as rotors [31] and double potentials [23], are a manifestation of the mechanisms that may be responsible for the genesis and maintenance of VA. The novelty of this approach would be to identify signal structures, as they relate to the occurrence of a VA event, and provide the clinical community the ability to track these events using only the electrogram record-

13

ing, which may be otherwise difficult to ascertain. This contribution could be accomplished by customizing a criterion function used in adaptive decomposition to specifically target electrogram signal structures of interest. The contribution from the time-averaged VA characteristics aims to identify averaged electrogram signal structures as they relate to the APP characteristics of the heart. The APP characteristics have been previously observed to influence the electrical activations of the heart [21, 22, 24]. The TF dictionary learning process (driven by the APP characteristics) will be valuable in identifying time-averaged electrogram signal structures. The discussion on the APP characteristics in Section 1.2.1 had revealed that it is difficult to know the specific characteristic of the heart, despite their clinical significance. The novelty of this contribution will be identifying possible electrogram signal structures that are associated with the underlying APP characteristics. The signal structures and features that were associated with time-specific event detection and quantifying the time-averaged VA characteristic will then be used as inputs to a DSS that will automate and assist clinicians in inferring the events and APP characteristics. This could potentially provide clinicians with valuable feedback (which is otherwise difficult to obtain) to plan effective treatment options (such as anti-arrhythmic medication, ablation therapy or the placement of an ICD) [7]. The novelty of such a DSS is to provide a tool to the clinical community that automates and assists with inferring the specific events or APP characteristics. The contributions of this dissertation can be summarized as follows: Â· Development of novel signal decomposition criterion function to automate extraction of electrogram signal structures driven by time-specific events during VAs. Â· Using dictionary learning approaches to identify and associate relevant electrogram signal structures driven by particular APP characteristics of the VA. Â· Development of a DSS that incorporates the identified electrogram signal structures to automate and assist clinicians in the diagnosis and treatment of VA. The block diagram for the purpose of achieving the objectives set forth in this dissertation is provided in Figure 1.5. The diagram begins with two branches: (i) time-specific event detection 14

d^  Z

 d& ZZZ

 Z ^ ^ Z^Z ^ E EZ  DZ

Z

h /

 WW >

d& Z > DZ  WW 

 Z 

d  s 

This dissertation will analyze (i) time-specific event detection and (ii) time-averaged VA characteristics. The specifics of each block will be further discussed through the dissertation.

Figure 1.5: Dissertation Block Diagram and (ii) time-averaged VA characteristics. The first two blocks of the top branch is the adaptive TF decomposition approach that will be used to identify electrogram signal structures of interest for the time-specific events. The first two blocks of the bottom branch are the TF dictionary learning process, that is governed by the APP characteristics, used to identify time-averaged electrogram signal structures of interest. The last two blocks are the DSS that was developed to automate the process of inferring VA events and/or APP characteristics. This diagram will be discussed in more detail over the course of this dissertation.

1.4

Dissertation Outline

The chapters in this dissertation will be outlined as follows:

15

Â· Chapter 2: This chapter discusses the background of signal processing concepts and will also educate the reader on the fundamentals of the adaptive signal decomposition approach. Simple statistical analysis and the linear classifier will be discussed for the purpose of feature validation. Finally, the fundamentals of the DSS will be presented. Â· Chapter 3: This chapter will present the proposed method that is significant for identifying electrogram signal structures of interest in time-specific events. The identified subspace and its relation to the signal structure will be further explored. Feature extraction will also be presented such that they may be used to help generate a DSS associating electrogram signal structures with the event of interest. The results of these findings will also be discussed. Â· Chapter 4: This chapter will present the time-averaged characteristics in ventricular arrhythmia. The correlation of the time-averaged characteristics with the APP characteristics will also be discussed. The dictionary learning method will be used to identify electrogram signal structures of interest that is driven by the underlying APP characteristics. The results of this method will also be presented in this chapter. Â· Chapter 5: This chapter will discuss the DSS (neural-network-based) that is developed to automate and assist clinicians in inferring the VA events/APP characteristics and signal structures extracted from the electrogram. The results of this DSS will be discussed. The DSS will serve as a foundation that can be used by the clinical community. Â· Chapter 6: This chapter will summarize the dissertation with conclusions and potential applications of the proposed work will also be identified. The possible directions for future work will also be discussed.

16

Chapter 2 Background

C

HAPTER 2 will begin by introducing the fundamental signal analysis concepts that are relevant for adaptive signal decomposition approach, which is used in this dissertation for the

analysis of VA electrograms. While there are many different signal processing tools that exist over either the time, frequency or time-frequency domains, this chapter will only discuss the necessity of the time-frequency signal decomposition. Tools that are used for feature validation will also be discussed in this chapter. The basic concept that was used in generating a DSS that approximates the association between the APP characteristics to the identified electrogram signal structures will be explored.

2.1

Time-Frequency Signal Decomposition

The TF signal decomposition takes advantage of the joint time and frequency properties of the signal to aid in analyzing the time-varying frequency components. This is of particular importance when decomposing signals that has time-varying frequency components. The VF electrogram can be considered to be of this type of signal, therefore requiring a TF decomposition approach to better understand its underlying signal structure. The TF decomposition was used for enhancing and localizing the time and frequency characteristics of the signal as well as for visualization on the TF plane. There are several techniques by which to perform TF decomposition with. One of the first TF decomposition tools was the short time Fourier transform. The discrete generic equation for the 17

short time Fourier transform is given by Equation 2.1 [1].
N -1 n=0
-i2ln N

Sf (l, m) =

f (n)hf (n - m)e

(2.1)

In the above Equation 2.1, the window hf (n - m) (with discrete time shifts m) is applied to the discrete signal f (n) (with discrete time index n) to determine the energy (Sf (l, m)) at frequency l and time instance m. The squared modulus of the short time Fourier transform Sf is called the spectrogram represented by |Sf (l, m)|2 [1]. Another aspect of the windowed Fourier transform is that the user can determine what specific type of windowing (hf ) to use (e.g. Hanning, Butterworth, etc.). The concept of this method is to compute the Fourier transform on a windowed segment of the signal. The spectral components within the window is computed to determine its frequency distribution. The window is then shifted to encompass a different portion of the signal. The spectral distribution is then captured for this new segment of the signal. This process is repeated until the window has been shifted through the entire signal. The time-varying frequency components can be observed through the spectral components produced by each window component. The TF distribution is produced from the resulting spectral distributions from each of the windows. The short time Fourier transform has been used in several applications of electrogram analysis. The prediction of heart rate and heart rate variability was accomplished by varying the window function in the short time Fourier transform [49]. The organization of the arrhythmia was also determined by studying the frequency distribution of the short time Fourier transform [50]. It has also been used to identify regions of conduction blocks in the heart by identifying the double potential electrogram signal structure [23]. While this method is one way to observe the time-varying frequency components, there is an inherent limitation with the short time Fourier transform. The assumption is that within the window being analyzed, the signal has limited time-varying frequency components. While this may be the case for VT, the VF electrogram does not follow such an assertion. To put this in perspective, the traditional Fourier transform has an infinite window (a window that spans the full duration of the signal). This provides the highest resolution for the signal's frequency content, but 18

The Heisenberg uncertainty illustrated in this figure shows the interdependency between the time-localization and frequency resolution. The window length does not vary when analyzing different frequency ranges.

Figure 2.1: Heisenberg Uncertainty in the Fourier Transform [1] it is impossible to determine the exact time instance when a particular frequency occurs. Thus, for the purpose of localizing the TF energy, the window must be made smaller to determine the exact time of the frequency content. However, as the window is made smaller, the frequency resolution becomes poorer, as it is difficult to distinguish individual low frequencies. This phenomena is known as Heisenberg's uncertainty principle and is illustrated in Figure 2.1 [1]. From this figure, it can be observed resolution of the frequency spectrum and the localization in the time domain are interdependent. Therefore, short time Fourier transform suffers from this frequency resolution versus time localization. If it were possible to adaptively vary the window size as per the frequency of interest, then there would still be another limitation set on Fourier based decomposition. The basis function used in the Fourier transform (e
-i2ln N

) spans the entire window length, which has an unlimited support. When

19

considering a single frequency within the signal, the basis function with this particular frequency will be used to determine the energy within the span of the window length, which means the Fourier transform will provide the average energy captured by that particular frequency within that portion of the window. When considering a non-stationary signal (such as VF), where the spectral content varies with time, the analysis falls short, requiring us to consider a decomposition with more freedom on the basis functions themselves. The choice on the basis function will also aid in targeting specific signal structures in the arrhythmic episode.

2.2

Adaptive Time-Frequency Signal Decomposition

To overcome some of the limitations (varying window length and basis functions) that were discussed for the short time Fourier transform, this section will explore some of the well established tools that are useful for adaptive signal decomposition. These tools include the wavelet transform, matching pursuit algorithm and label consistent k-mean singular value decomposition dictionary learning.

2.2.1 Wavelet Based Signal Decomposition
One particular TF decomposition that can better address some of the limitations discussed previously is the wavelet transform. Similar to the short time Fourier transform, the objective of the wavelet transform is to capture the frequency components of the signal over time. However, wavelet analysis uses basis functions (wavelets) with a specific TF localization. Furthermore, the ability to vary the basis function (time and frequency support) to specific type of structures makes wavelet better suited for adaptive signal decomposition. The generalized equation for the discrete implementation of the continuous wavelet transform is given by Equation 2.2 [51]. 1 W f (s, m) =  s
N n=1

f ( n)   (

n-m ) s

(2.2)

The signal (f (n)) is multiplied with a wavelet function ( ) with a particular scale parameter (s) and a particular translation parameter (m) to produce the wavelet coefficients W f (s, m). An example of a complex wavelet function is illustrated in Figure 2.2. The scaling parameter s in 20

Complex Morlet wavelet cmor1-1
0.6 0.4 0.2 0 -0.2 -0.4 -0.6 -0.8 -8 -6 -4 -2 0 Real part 2 4 6 8

0.6 0.4 0.2 0 -0.2 -0.4 -0.6 -0.8 -8 -6 -4 -2 0 Imaginary part 2 4 6 8

Figure 2.2: Sample Wavelet Function a wavelet basis function shrinks or expands the wavelet function, which is analogous to altering the frequency of the function. The translation parameter m centers the wavelet function around a particular time segment of the signal. Therefore, the coefficient W f is representative of the correlation between the wavelet function (with a particular scale s and translation m) to the signal f . Based on this transform, it is possible to analyze the TF (or time-scale) energy for signals that are not necessarily stationary and that have time varying frequency components. The wavelet transform has several advantages over the short time Fourier transform for the application of adaptively decomposing the electrograms. The first advantage is the ability to better localize the TF components of the electrograms, which will provide a more accurate description of the signal itself. Furthermore, the wavelet transform uses an adaptive window length that is dependent on the scale s. Recall that the short time Fourier transform uses a basis function that is comprised of sinusoidal signals (i.e. e
-i2ln N

). This limits the ability to localize the TF energy

within the window of analysis due to its unlimited time support. The wavelet basis functions are typically limited in their time support, which means they are centered around m and decay towards the edge of the window. Consider the Heisenberg uncertainty for wavelets illustrated in Figure 2.3. For large-scale wavelet functions (i.e. low frequency components), the window is large, thus

21

The Heisenberg uncertainty illustrated in this figure shows the varying window length when analyzing different frequency ranges.

Figure 2.3: Heisenberg Uncertainty in the Wavelet Transform [1] allowing for better analysis of low frequency components of the signal. Additionally, for lowscale wavelet functions (i.e. high frequency components), the window is much smaller, allowing for better localization of the high frequency components of the signal. Another advantage of the wavelet transform over the short-time Fourier transform is the flexibility in selecting the basis function. The basis function itself can be varied to any type of function that is governed based on certain properties [1]. These basis functions may be selected to better conform to either the general structure of the signal, or specific sets of signal structures. The wavelet transform has been used widely for different applications in studying VA. A few examples of these applications include using the wavelet transform to determine the optimal time to defibrillate [52Â­54], distinguishing VF waveforms from non-VF waveforms [52], using the scale band energy to detect the cardio pulmonary resuscitation waveform and the atria activity in the ECG during VF [55, 56] and to classify the type of arrhythmia [57, 58]. The ability to capture 22

specific recurring signal structures from the ventricular arrhythmia episode was also previously presented [35], which indicates that there may be various events of interest in characterizing ventricular arrhythmias (specifically VF). This method had used scale-band energy ratios to manually identify signal structures within the electrogram signal. While manual detection did highlight a difference in distribution that may be indicative of events in the arrhythmia, it would be difficult to fully represent the signal with a manual detection method based on a set of fixed parameters for these events. Therefore, an adaptive signal decomposition approach that can automatically decompose the electrogram into a set of signal structures would be invaluable for the purpose of identifying and associating electrogram signal structures with the APP characteristics.

2.2.2 Matching Pursuit
Adaptive signal decomposition methods are widely used to target specific signal structures of interest. The matching pursuits algorithm (MP) is an example of adaptive signal decomposition when decomposing a signal with a specific TF dictionary  , because it can iteratively decompose the signal based on the atoms in the dictionary [59]. A TF dictionary is made up with a set of mathematical functions (i.e. known function and parameters) that satisfy a set of properties (and is referred to as atoms). The set of atoms used in such a representation should span the Hilbert space of the signal. This means that the dictionary should be capable of representing the structure of the signal being analyzed by selecting a variations of atoms that can match all of the signal properties (such as amplitude, frequency, phase, and structure). This concept is analogous to writing a report with a given literature dictionary. If the vocabulary is limited, then the report might not convey the full details of the subject. However, if the dictionary has a large vocabulary base (with a large volume of unique and/or redundant words), then the report may be more accurately written to provide precise details. The MP algorithm is a greedy algorithm because the atoms are selected iteratively based on a set criterion function. This also makes MP with a TF dictionary flexible, as it allows for the targeting of specific signal structures. The dictionary  is comprised of atoms (specific waves that are used for the decomposition) that can either be orthogonal to one another or redundant over

23

the Hilbert Space. The end result of MP is to form a linear expansion of waves that provides an approximation of the signal. An atom g (n) in a dictionary may be defined as given by Equation 2.3. 1 n - m in )e g  ( n) =  g ( s s

(2.3)

Similar to the wavelet transform, the terms s and m represent the scale and translation parameter respectively. The term  is the frequency modulation for the atom g . The term  is considered as a set of the translation (m), scaling (s) and frequency modulation ( ) parameter for the atom at a specific iteration. Furthermore,  also contains the parameters specific to the atom at the given iteration (i.e. the window length and type). The dictionary  has a limited number of such atoms g that was used to decompose the signal. It is important to note that the MP itself is simply an iterative decomposition algorithm. The adaptive decomposition stems from the TF atoms used in the dictionary  to decompose the signal. The MP algorithm itself maintains an energy conservation that will guarantee convergence of the vectors after a sufficiently large number of iterations  [59]. The MP algorithm can serve as an adaptive TF decomposition to highlight specific signal structures within the signal by iteratively selecting atoms based on a specific criterion function. A signal f (n) is represented as a linear expansion of atoms from the dictionary, and can be observed in Equation 2.4.
+ =0

f ( n) =

b  g   ( n)

(2.4)

For a given number of iterations (), a TF wavelet atom g (n) is selected with specific parameters  . The term b is the expansion coefficient for an atom g (n) at the given iteration . In this equation, the signal f (n) is represented by a combination of atoms with varying expansion coefficients. The expansion coefficient is based on the criterion function used to select an atom at a given iteration. In the original implementation of MP, the criterion function selects an atom based by maximizing its projection onto the signal (provided in Equation 2.5).

b =< f, g >= 24

 f ( n) g  ( n)

(2.5)

 The product between the complex conjugate of an atom (g (n)) and the signal (f (n)) forms

the inner product b at the first iteration. After the first iteration, the signal can be represented by Equation 2.6.

f = b0 g0 + Rf

(2.6)

This equation illustrates that the signal is represented by the atom g0 with an expansion coefficient b0 and a residual component Rf . The residual component is the signal that is not captured by the atom g0 . If we were to expand this to large number of iterations (and assuming that the dictionary  spans the complete Hilbert space of the signal f(n)), then the residual component will become zero, which will give us the linear expansion in Equation 2.4. There are two criteria that must be met in order to be able to completely represent a signal. First, the dictionary must encompass the full Hilbert Space of the signal (i.e. there are a sufficient atoms to capture all the signal structure variations). Second, the number of iterations used must be sufficiently large (usually infinite) in order to capture all the signal structures present in the signal. If these condition are not met, then Equation 2.4 becomes an approximation of the original signal f (n). In this case, the signal f (n) will contain an approximated component after a set number of iterations and a residual component. Suppose that after a finite number of iterations (), the residual may be calculated as given by Equation 2.7. R f =< R f, g > g + R+1 f

(2.7)

Equation 2.7 states that the residual component at iteration  is decomposed by maximizing the projection of an atom on the residual, therefore creating an expansion of an atom at that specific iteration (g ) and a new residual component (R+1 f ). If the number of iterations is not sufficient to represent the signal or the dictionary is not complete, then the signal f (n) will contain an approximated component and a residual component (given by Equation 2.8). b g (n) + R+1 f (n)

f (n) =



(2.8)

25

The approximated component of signal f (n) consists of the summation of the atoms with its respective expansion coefficients (
 b g (n)).

The residual component (R+1 f (n)) is the part of

the signal f (n) that is not represented by the atoms. As previously stated, the original MP has a criterion function that minimizes the norm of the residual ||Rf || (or maximizing the projection of the atom on to the signal or its residual). The criterion function C can be defined as given by Equation 2.9.

C = argmax[< R f, g >] = argmax[b ]

(2.9)

This iterative process will continuously select the atom g that maximizes its projection on to the residual R f at a given iteration. This MP algorithm uses a TF dictionary to represent a signal, and will be referred to as the original MP (ORG MP) decomposition in this dissertation. The complexity for the ORG MP is O(N 2 log (N )) [60]. An example of the original MP decomposition (using a Gabor dictionary) of an arrhythmia signal over 100 iterations is illustrated in Figure 2.4. The purpose of Figure 2.4 is to explain how the MP decomposition can be visualized. From this figure, the top panel (Figure 2.4a) illustrates the original arrhythmia signal that is to be decomposed. The middle panel (Figure 2.4b) is a plot of all the atoms over the 100 iterations. This plot shows each atom's (represented by the boxes) time (location along the x-axis), frequency (location along the y-axis), scale (based on the length and width of a particular box) and coefficient (colour of the box). The longer boxes represents the atoms with a larger scale. The colour ranging from dark red to dark blue represents the strength of the coefficient of each atom ranging from strong to weak, respectively. This type of diagram is useful when observing how specific signal structures of the arrhythmia are represented by the atoms of the dictionary. The bottom panel (Figure 2.4c) represents the scale-frequency amplitude map [61, 62]. This map categorizes the atoms into bins of scale and frequency bands and then averaging the coefficients within that particular band. This type of representation is useful when observing the generic structures of the signals between different sets. In terms of capturing specific signal structures from a signal, MP provides an advantage in terms of its flexibility to approximate structures of interest. This advantage comes from the it26

Sample Arrhythmia Signal
0.06

0.04

Amplitude (Arbitrary Units)

0.02

0

-0.02

-0.04

-0.06

0

2

4

6

8

10

Time (s)

(a) Original electrogram
Matching Pursuit Book
12

10

8

Frequency (Hz)

6

4

2

0

0

2

4

6

8

10

Time (s)

(b) The MP decomposition book plot illustrates each of the atom's scale (rectangle x-axis length), frequency (Y-axis value) and coefficient (color) that was selected over the 100 iterations.
Matching Pursuit Scale-Frequency Map
0.5

128

0.45 0.4

256

0.35 0.3

Scales

512

0.25 0.2

1024

0.15 0.1

2048 0 2 4 6 Frequency (Hz) 8 10 12

0.05 0

(c) The scale-frequency map categorizes the atoms into scale and frequency bands. The color represents the average coefficient for the given scale-frequency band.

Figure 2.4: Sample MP Decomposition of an Arrhythmia Signal 27

erative approximation of the signal based on the TF dictionary. This approximation may also be constrained in order to analyze specific signal structures. In the analysis of EEG signal structures, MP was used to identify transients from the EEG [63]. The MP algorithm was also used in capturing the ventricle and atrial activations from the normal ECG [64]. The original MP is based on maximizing the projection of an atom onto the signal. However, if there are specific signal structures that are of interest, then having the ability to alter either the dictionary, the range of parameters ( ) and/or the criterion function C will be invaluable in identifying signal structures that may be hidden within the electrogram during an arrhythmic episode, as well as associating such signal structures to the underlying APP characteristics. Orthogonal Matching Pursuit The orthogonal matching pursuit (OMP) is a decomposition algorithm that is similar to the original MP. The objective is to represent a signal with the elements (atoms) of the dictionary  . The main difference between the OMP and MP is with respect to the coefficients and the residual at any given iteration. Considering the original MP decomposition given by Equation 2.8, the coefficient b+1 is selected by determining the maximum projection of an atom g+1 onto the residual R+1 f (n). The MP decomposition becomes suboptimal in terms of selecting the atom because there is no guarantee that the residual R+1 f (n) spans the remaining Hilbert space not captured by the atoms from the first iteration up until  [65]. On the other hand, the OMP converges to the projection spanned by the dictionary's Hilbert space faster than MP. Consider the OMP decomposition given by Equation 2.10.  g (n) + R+1 f (n)

f ( n) =



(2.10)

The term  refers to the sparse code at any given iteration . The overall decomposition looks nearly identical to the decomposition by the original MP (Equation 2.8). However, the projection for the atom at  + 1 onto the residual is what is different. The projection of the residual onto all the atoms up to  (i.e. g1 to g and denoted as g1: ) is zero (as illustrated in Equation 2.11).

28

< R+1 f, g1: >= 0

(2.11)

If this constraint is considered, then all the atoms selected from iteration 1 to  will no longer have a projection onto the residual, thereby limiting the Hilbert space to the remaining atoms that were not selected from the dictionary to represent the signal. This means that the maximum number of iterations in the OMP decomposition is limited to the number of elements in the dictionary  . In order to guarantee that the residual is orthogonal to the atoms selected until  (g1: ), the projection at any given iteration must update all previous sparse code coefficients (1 to  ). In order to update the sparse code coefficients, it is necessary to determine the Hilbert space spanned by the atoms until . The auxiliary representation for the atom at  + 1 (g+1 ) can be redefined as a component that is dependent on the previous atoms (g1: ) and an orthogonal component (given by Equation 2.12) [65].
  =1

g+1 =

  g   + 

(2.12)

From this equation, the atom g+1 consists of the component captured by the previously selected atoms and their coefficients (i.e.
   =1  g )

and the orthogonal component ( ) that is not

captured by any of the previous atoms. It should be noted that for an orthogonal dictionary, only the  component will exist. The next step is to update all the sparse codes . This update is defined by Equation 2.13 and Equation 2.14.
+1   =    -   

(2.13)

where, = 1...
+1  +1 = 

(2.14)

+1 Equation 2.13 states that the updated sparse codes coefficient (denoted as   ) is the differ-

ence between the previous sparse codes coefficient (denoted as   ) and the previous sparse codes
+1 multiplied by a  factor (denoted as    ). The sparse code for the newest iteration (+1 from

Equation 2.14) is the  factor. The  factor is defined by Equation 2.15. 29

=

< R f, g+1 > <  , g+1 >

(2.15)

The  factor is the ratio between the inner product of the residual signal and the atom g+1 and the inner product between the  component and the atom g+1 . The updated sparse codes and atoms will be orthogonal to the residual produced at  + 1. The application of OMP for this dissertation is producing the sparse codes using the trained dictionaries. The complexity for OMP is O(N 2.5 ) [66]. The following section will discuss the dictionary learning algorithm.

2.2.3 Dictionary Learning
The signal decomposition using MP relies on selecting a dictionary  that can accurately approximate the signal. Traditionally, the selection of such a dictionary would rely on understanding the Hilbert space spanned by the signal structure and then appropriately using a dictionary that is made up of atoms also spanning this same Hilbert space. When considering a signal such as VF, however, the underlying signal structure that should be targeted may not be fully understood. Therefore, it is not clear which part of the Hilbert space is significant for a given event or APP characteristic in the VA electrogram. Dictionary learning is a valuable tool for such instances and could be used to assist in identifying electrogram signal structures of interest in the arrhythmia episode. The concept of dictionary learning relies on training the atoms of the dictionary to conform to a set of signal structures that best represent a set of training signals. There are several methods that can be used for dictionary learning, such as maximum likelihood [67], method of optimal directions [68], maximum a-posteriori probability [69], and unions of orthonormal bases [70], but the main focus of dictionary learning that will be discussed is the K-means singular value decomposition (KSVD) method [71]. This is because the KSVD dictionary learning is considered a more generalized method for training a dictionary. To better understand the K-SVD algorithm, assume that a given set of training signals (that can be denoted as [f ]) can be represented with a dictionary  (which consists of a set of r atoms and is denoted as [g ] to describe the KSVD process) and a coefficient matrix [b] (as given by Equation 2.16).

30

[f ] =

[g ] Ã [b] + [e]

(2.16)

The term [e] is the error term that is not represented by the coefficient matrix [b] and the dictionary [g ] for the given set of training signals [f ]. Given a dictionary  , the objective is to minimize the error term (similar to the MP algorithm minimizing the residual for a single signal). The initial coefficient matrix [b] is determined by computing the MP for each of the training signals. Once the coefficients are fixed for a given dictionary, the KSVD algorithm proceeds to update the dictionary atom g r one at a time. This is accomplished by setting all the remaining columns of the [b] and [e] matrices to zero with the exception of the rth atom (these matrices will be denoted as [b]r and [e]r ). The singular value decomposition is then applied on the error matrix for the rth atom such that the atom could be updated. This is given in Equation 2.17.

[e]r = U  V T

(2.17)

The singular value decomposition of a matrix (in this case the error matrix) produces two unitary eigenvectors U and V and a singular value matrix . These eigenvectors are representative of the error matrix. The atom [g ]r and the coefficient matrix [b]r are updated based on the first component of the U unitary matrix and the first component of the V unitary matrix, respectively. This process is then repeated one at a time until each atom in the dictionary has been updated. This iterative update of the atom and coefficient is why this algorithm is referred to as K-SVD due to the similarities by which K-means is used to update the mean of cluster of data points [71]. Once all of the atoms have been updated, the original MP decomposition is performed on the training signals again to update the error matrix. This process can then be repeated for as many iterations as needed. The objective function for the KSVD algorithm is defined as minimizing the error between the training signals and the trained dictionary (as provided by Equation 2.18). The complexity for the KSVD dictionary training is O(N 3 ) [66]. However, the training is completed once, at which point the OMP is used with the trained dictionary.

< [b],  >= arg min||[f ] -  [b]||
[b],

(2.18)

31

The KSVD dictionary learning method is mainly focused on fully approximating the training signals and not on creating a discriminative dictionary. By providing supervised information (labels) and a classification error to the objective function, a dictionary can be trained not only to approximate the training signals, but also to provide the ability to discriminate between subsets in the training samples. The label-consistent-KSVD (LCKSVD) introduces two additional terms to introduce the discriminative component to the objective function (as provided in Equation 2.19) [72].

< [b], [T M ], [W ],  > = arg

[b],[T M ],[W ],

min

||[f ] -  [b]||2 2

2 + ||[Q] - [T M ][b]||2 2 +  ||[CL] - [W ][b]||2

(2.19)

[T M ][b]||2 2 ). The matrix [Q] are the discriminative sparse codes for the training signals, the matrix [T M ] is the transformation matrix that will linearly transform the coefficients [b] to the most discriminative sparse feature space and the term  represents the contribution of the sparse component to the objective function. The classification error component ( ||[CL] - [W ][b]||2 2 ) is introduced as the second newly added term to Equation 2.19. The matrix [CL] is the class labels for the training signals, the matrix [W ] is the classifier parameters and the term  controls the contribution of the classification error component to the objective function. Depending on whether approximation, sparsity or discrimination of the training signals is a priority in the trained dictionary, the  and  values should be set. In order to update the terms < [b], [T M ], [W ],  >, a K-SVD algorithm is applied on the criterion function given in Equation 2.19. The updated terms are obtained iteratively. The dictionary  is initialized by any starting dictionary (Gabor dictionary for this dissertation). The [T M ] transformation matrix as well as the [W ] classifier parameter matrix are initialized using a ridge regression model [72]. The coefficient matrix [b] is initialized by decomposing the training signals with the starting dictionary. The LCKSVD dictionary learning algorithm is a valuable tool in trying to identify components of significance (based on the trained atoms) that may relate to signal structures found in the arrhythmia episode. 32

The first newly added term introduced by Equation 2.19 is the sparse code component (||[Q] -

2.3

Pattern Classification

There are two common types of methods in assessing a feature (or set of features). In order to determine its ability to discriminate a data set, the statistical significance tests and/or a classification system can be used. This section will introduce the methods that will be used to test features that will be introduced in subsequent chapters. The objective of hypothesis testing is to use simple statistics to determine if a feature belongs to the same class or is part of separate classes [73]. A null hypothesis (the observations belong to one single class) is tested based on the statistical analysis. The null hypothesis is rejected only if the probability value is below a certain threshold. For the purpose of this dissertation, the probability value threshold was set as 0.01 (denoted by P < 0.01 throughout this dissertation), which is a commonly accepted value [73]. A simple example of a statistical significance test is the T-test that analyzes the means of each class to determine if the observation belongs to the same distribution or not. The analysis of variance (ANOVA) is another type of statistical significance test that is more commonly used to determine if a feature is significant. Specifically, the ANOVA method is used to determine whether the difference in the means of the groups is greater than the expected variation of the data and is not actually being caused by the variations themselves [73]. By considering the variation of the data, the ANOVA can provide a more robust method for determining if the given feature could be considered for representing the data. The ANOVA will produce an F-statistic (denoted as StatF ) based on the significance of the distribution. The equation for the ANOVA method is given by Equations 2.20 and 2.21 [74]. SST /DoFT SSR /DoFR (( -  Â¯ )2 )

StatF =

(2.20)

SS =

(2.21)

The term SS refers to the sum of squares, which is the square sum of the observations () subtracted by the mean of the observations ( Â¯ ). The term SST refers to the sum of squares produced 33

by the treatment deviations, which is the observations subtracted by the total mean of all the observations. The term SSR is the sum of squares produced by the residual deviation, which is the mean of each class subtracted by the total mean of all observations. The DoF term refers to the degrees of freedom for the observations in the treatment deviation and the residual deviation. This refers to the number of elements in each deviation table that can be arbitrarily assigned. For example, if a data set consisted of 4 classes and 8 observations in each class, then the degree of freedom with respect to the treatment deviation (DoFT ) is 23 and the degree of freedom with respect to the residual deviation (DoFR ) is 3. The DoFT is 23 because there are a total of 24 observations with a fixed total mean, and it is only possible to vary 23 of the observations while having the same total mean. Similarly, the DoFR is 3 because there are 4 class means and only 3 can be varied in order to still produce the fixed total mean. From the ANOVA analysis in Equation 2.20, the F-statistic is produced, which can then be used to create a probability value P . Note that the probability value simply states if the observations are significant or not and does not reveal which set of observations (i.e. which class) are contributing to the significance. Therefore, the ANOVA tests is a good tool in determining the strength of the observations, obtained from features, in segregating one or more classes. The statistical significance test assesses how viable a feature is for the purpose of separating multiple groups. Considering the ANOVA test, the combination of the mean and variation of the observations for each group were used to determine the strength of the feature. However, these tests do not provide insight into how successful the feature performs on classifying the data into a class. Therefore, a classification system must be used to quantify how accurate the feature is in classifying the data. There are several types of classification systems that can be used to quantify the accuracy, but only the linear discriminant analysis (LDA) will be discussed. The LDA creates linear boundaries in the feature space to classify the data. If a feature does not have a strong ability to discriminate the classes, then the LDA will produce poor accuracies. Thus, this ensures that the features are discriminative. The Fisher's LDA [75] is a supervised machine learning algorithm, which means that the data has to be pre-classified in order to train the classifier. If a linear classifier were to have cl classes,

34

then the number of linear discriminant functions to separate the classes would be cl-1. The combination of discriminant functions will create regions in the feature space, where a particular region would represent a given class. The objective of the linear classifier is to create a projection of the observations () of the feature space into a particular class using a set of weights . This projection is defined as given by Equation 2.22.

Class = []T Ã

(2.22)

The training of the classifier will determine the weight matrix ([]) that will be used to project the observations () to a particular class. The criterion function J () for the training the weights for a LDA is defined by Equation 2.23. |[]T SSR []| |[]T SST []|

J (w ) =

(2.23)

Based on the distribution of the observation and the class mean (SSR ) versus the distribution of the class mean and the total mean (SST ), the weights will be updated. The objective is to maximize the criterion function, which means selecting the weights to maximize the variations between group means while limiting the variation of the feature space for each of the classes. In order to train the classifier, pre-classified training samples is given to the classifier to establish the linear discriminant boundaries (by training the weights) such that the testing data can be classified. Classification systems often require a large number of samples to train the classifier, which is often difficult when considering biomedical databases. If the database size is limited, it is difficult to generalize the classifier [75]. Cross validation can be performed on the data set in order to better test the feature space for small data sets and arrive at a more generalized performance of the classifier. The extreme form of cross validation method is the Leave-One Out (LOO). In the LOO method, the classifier is trained with all the observations except one. The trained classifier is then tested with the remaining one observation and a classification is given for that observation. This process is repeated by leaving out each observation one by one and training with the remaining observations to create a classification for each observation. Finally, a classification accuracy can be determined by identifying how many observations were correctly classified when compared to 35

the total number of observations. Furthermore, the accuracy for each class can also be found by determining how many observations within each class were correctly classified when compared to the total number of observations for the specific class. The LOO method is important in determining the classification accuracy produced by the feature space that will be introduced in subsequent chapters.

2.4

Decision-Support System

The objective of developing a DSS in this dissertation is to automate and assist clinicians in the diagnosis of VA. In particular, the adaptive signal decomposition and dictionary learning approaches will be used to capture electrogram signal structures as they relate to specific events and APP characteristics. This means that the signal structures already have a relation with the event and structures, and the DSS becomes a tool that can automate and assist clinicians in inferring the events/APP characteristics. The brain of the DSS can be created by many types of machine learning models. Some examples related to cardiology include decision tree, k-nearest neighbor and support vector machine based DSS [76, 77]. Neural networks are preferred over these other types of models because of its ability to support a linear or non-linear model for the DSS [76]. Furthermore, the use of a neural network based DSS is supported by an established relation between the signal structures and the events/APP characteristics, allowing for a type of explainable artificial intelligence. Neural networks resemble a biological system [78, 79], where the inputs to the system are associated to the outputs of the system through multiple hidden layers, each with a finite set of neurons. These hidden layers consists of neurons and weights that quantify the relationship between adjacent layers. In combination, the relationship between the input and output layers could be established. Consider that, if there are d input parameters (denoted as x), then the input layer will have d neurons. Similarly, there would be cl neurons in the output layer for cl output parameters (denoted as z ). The simplest form of the neural network is a three-layer system with one input layer, one output layer and one hidden layer. A generic equation for the three layer neural network is given in Equation 2.24 [75]. 36

h

d

zi3 = M Fi3 ((
i2 =1

i3 i2 M Fi2 ((
i1 =1

i2 i1 xi1 ) + i2 0 )) + i3 0 )

(2.24)

For this equation, zi3 is the output parameter with a modeling function M Fi3 . The term i3 refers to the neurons (zi3 ) or functions (M Fi3 ) in the third layer. There also exists a modeling function M Fi2 as a result of the hidden layer (i2 ). These modeling function describes what the relationship is between the two layers. The are a total of h hidden neurons. The two weight functions i3 i2 and i2 i1 represent the weights between the hidden and output layer (i3 i2 ) and between the input and hidden layer (i2 i1 ) respectively. The i3 0 and i2 0 are the bias values for the respective layers. The overall relationship between the input parameters x and the output parameters z are a result of the modeling functions as well as the final weights. To determine the input parameter's influence on a particular output zk , the weights along that neural path will have to be explained. The training of the weights is based on the minimization of a criterion function J () that occurs iteratively for a set of input and output parameters. For neural networks, this criterion function J () compares the systems current output zk to the target outputs tk . The goal of the criterion function is to minimize the squared error between the target outputs and the trained outputs. The minimization of the square error provides the neural network with a smoother error surface, which provides better control at arriving to the global minimum error for the weights [75]. This criterion function is given in Equation 2.25. 1 J () = 2
cl

k=1

( tk - zk ) 2

(2.25)

The trained outputs after a given iteration is dependent on the trained weights . The backpropagation learning rule for the weights  is based on a gradient descent [75]. To determine the step size by which the weights  increments at each iteration (), the derivative of the criterion function J () with respect to the weights  is taken and multiplied by a learning rate  . The updated weights at iteration q + 1 is calculated by adding the step size weight () with the weight at iteration q . The step-size weight and the updated weight is given by Equations 2.26 and 2.27 respectively.

37



Â¨



Â©

D&

Â¥ Â£Â¤ 

D&

Â¥ Â£Â§ 

  




D&

  Â£Â¤ 

D&

Â¥ Â£Â¦ 

  






Â¡



Â¢

Figure 2.5: Example Neural Network Model Diagram

 = -

J 

(2.26)

(q + 1) = (q ) + 

(2.27)

Figure 2.5 is an example of a three-layer neural network. This general form of the neural network can be used to associate the identified signal structures (the input parameters to the neural network) with the APP characteristics (the output parameters to the neural network). These models may serve as micro-models to characterize the VA episode, and the specific models will be discussed in subsequent chapters.

2.5

Background Summary

This chapter presented the relevant signal processing tools used in this dissertation. It began by introducing the fundamentals of TF decomposition and discussing the short-time Fourier transform. The fundamentals of the wavelet transform and its significance to TF decomposition were also explained. For the specific purpose of identifying signal structures from the electrogram, the matching pursuits algorithm was introduced. The orthogonal matching pursuits as well as the 38

LCKSVD dictionary learning was also introduced in an extension to the matching pursuits algorithm. The ANOVA statistical significance test and the LDA classification with LOO for testing a feature strength were presented. Finally, the neural network system for a DSS was discussed for its ability to create dynamic relationships between input and output parameters, such as signal structures and the event/APP characteristics. These methods will be discussed in detail in the subsequent chapters.

39

Chapter 3 Time-Specific Event Detection

T

HE electrical activations of a VF episode was believed to be random with no known mechanistic behaviours. Modern research into VF, however, has discovered the manifestation of

time-specific events [30Â­32] that may govern the initiation and maintenance of VF. This chapter will discuss some of these time-specific events. Next, the relevant database that is used for this study will be discussed in detail. The adaptive signal decomposition used to associate electrogram signal structures with relevant time-specific events will then be introduced. The results and discussion for the proposed approach will be presented for this chapter followed by a brief summary. The general block diagram for this chapter is illustrated in Figure 3.1

3.1

Time-Specific Event Background

During a VA episode, abnormal electrical activations of the ventricles of the heart causes a reduction and/or cessation of normal ventricular activity. While VT can have a highly rhythmic electrical impulse governing its activations, VF typically has more chaotic electric impulses. However, despite the differences between VT and VF or the fundamental APP differences from patient to patient, there are some events of clinical interest during VA episodes that are reflected in the electrogram morphology. One example of a time-specific event is known as the "double potential", which has been observed to occur near regions of conduction blocks [23]. These conduction blocks primarily occur when an electrical impulse wave is propagating through the myocardium and is impeded or blocked by a region of dead or scar tissue, therefore signifying a relation to an 40

d^  Z

 d& ZZZ

 Z ^ ^ Z^Z ^ E EZ  DZ

Z

h /

 WW >

d& Z > DZ  WW 

 Z 

d  s 

This chapter will discuss the time-specific event detection. In particular, the adaptive signal decomposition approach to identify discriminant electrogram signal structures and the relation of these structures to timespecific events will be discussed.

Figure 3.1: Contributions for Chapter 3

41

APP characteristic. Another event that was previously observed was a signal-amplitude variation from low to high was used in determining the defibrillation outcome [25]. The region with a high electrogram amplitude was found to result in a higher chance of success for a defibrillation shock than a region of low electrogram amplitude. There are also examples of electrogram signatures (refer to Figures 3.2 and 3.3) that were previously identified [2, 35] and some have relationships with events in the arrhythmia. The electrogram signature in Figure 3.2a is an example of the "double potential" that is known to occur around conduction blocks. When analyzing the distributions of the unipolar electrogram signatures from Figure 3.2 (unipolar electrograms will be further discussed in Section 3.2.1), sets of distributions for different patients were observed [35], which indicates that there may be some similarities that can be observed in different patients suffering from VA. The bipolar electrogram signatures from Figure 3.3 [2] (bipolar electrograms will be further discussed in Section 4.2) also demonstrate that there exists certain sets of activations known to exist in VA. Furthermore, the continuous activity, multiple component, and wide complex signatures were observed to occur around the vicinity of a rotor event [2]. The occurrence of the alternating activation was also observed to be a precursor to an arrhythmic episode [80]. Another spatio-temporal event observed during VA episodes is known as a rotor. Rotors are, as per rotor theory, organized, rotating, and migrating spatio-temporal centres of electrical activity, which are believed to be the drivers of VF [30Â­32]. Rotor theory is one hypothesis on the initiation and maintenance of ventricular arrhythmia, specifically VF, and has continued to garner further study [81]. The rationale for such a hypothesis is attributed to the idea that the circulating wavefront constantly reactivates its own partially refracted cells left in the wake of the wavefront. Existing literature has also reported that it may be possible to modulate the rotors (through antiarrhythmic drugs or ablation [34, 81]) to prevent future arrhythmic episodes. Furthermore, the occurrence of rotors were found to be around the boundary regions between scar and healthy tissues [9], thereby having a correlation with APP characteristics of the heart. Given the significance of the rotor event, it is important to the clinical community to be able to track this event during a VA episode. Current methods in tracking rotors need spatio-temporal electrical information over the

42

0.25 0.25 0.2 0.2 0.15 0.15

Amplitude

0.1

Amplitude
0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2

0.1 0.05 0 -0.05 -0.1 -0.15 -0.2

0.05

0

-0.05

-0.1

-0.15

-0.2

-0.25

-0.25

Time (s)
(a) Local Pattern 1

0.2

0.4

0.6

0.8

Time (s)

1

1.2

1.4

1.6

1.8

2

(b) Local Pattern 2

0.4 0.5 0.4 0.2 0.3 0.2 0.1 0 -0.1 -0.2 -0.3 -0.4 -0.5 -0.5

0.3

Amplitude

0.1

0

-0.1

-0.2

-0.3

-0.4

-0.6

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

Amplitude

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

5.5

6

Time (s)
(c) Local Pattern 3

Time (s)
(d) Global Pattern

Figure 3.2: Unipolar Electrogram Patterns Â©[2013] IEEE

43

EZ
1000 ms

d

Z

500 ms

500 ms


500 ms 500 ms

t

/
1000 ms

D
500 ms

Normal Activation, AT: Alternans, CA: Continuous activity, WC: Wide complex, I:Intermittent, MC: Multiple components, R: Rapid

Figure 3.3: Bipolar Electrogram Patterns [2]

44

surface of the heart, for which the resolution required is of concern [82, 83]. Furthermore, the axis of rotors have also been observed to pass through the myocardium transmurally [84, 85], which requires a more involved acquisition system to capture these events. The ability to identify such an event using only the electrogram is important for the clinical community. Identifying electrogram characteristics in the vicinity of a rotor can assist electrophysiologists in possibly modulating rotors in hopes of terminating a fundamental mechanism that is believed to initiate and maintain VA episodes. Hence, this chapter will focus on identifying electrogram signal structures as it relates to the rotor event.

3.2

Database

This section discusses the databases that will be used for the identification of electrogram signal structures as they relate to the time-specific rotor event. There were three types of database used for the identification of signal structures: the retrospective arrhythmia database, the in-vivo arrhythmia database, and the synthetic arrhythmia database.

3.2.1 Retrospective Arrhythmia Database
One way to study VA (particularly VF) is by analyzing explanted human hearts. As previously stated in Chapter 1, a person suffering from VF can only survive for a few minutes before it leads to SCD. Therefore, the short time frame makes it difficult and unethical to study VF on a live patient. While studies that have used animal hearts to better understand VF exists [86Â­88], these may not directly relate to humans due to the differences in the physiology of the heart. Thus, this study uses explanted human hearts to study VF and its relation to the APP characteristics. In order to analyze the electrical activations of an explanted heart, the heart was kept alive using a special Langendorff setup. Informed consent was obtained from each patient and the REB ethics was approved by the University Health Network, Toronto, Canada. The hearts being analyzed were kept alive for a few hours after being explanted, at which time the electrical activations were recorded using a specialized system [31]. The experiments and collection of the electrograms were performed by Mr. S. Masse, Dr. K. Umapathy, Dr. T. Farid, Dr. K. Nair, Dr. K. Nanthakumar and clinical team 45

from Toronto General Hospital. Additional histological information for each heart was collected by Dr. K. Nair. The retrospective arrhythmia database consisted of 8 individual human hearts and a total of 13 arrhythmic episodes. In order to record the electrical activations of the heart, an electrode array of 112 electrodes were attached to the outer surface of the heart. The shape of the electrode array was in shape of a dome that would be placed on the outer surface of the heart (Figure 3.4a). This dome consisted of 14 sets of electrodes, with each set having 8 electrodes. The electrode array can be observed in Figure 3.4b. In this dissertation, only de-identified electrograms were used for the study. The multichannel electrodes record the electrical signals produced by the heart during the induced arrhythmia episode. The system recorded the electrograms at a specific sampling rate depending on the type of electrogram recording. Once the electrograms were sampled, the signals were processed through a hardware bandpass filter (between 0.5 to 200 Hz) before being stored. The retrospective database consisted of the electrical activations during the arrhythmic episode as well as the APP characteristic. To record some of the APP characteristics (such as the scar tissue and the action-potential characteristics), a pacing system recorded from the bipolar electrograms was used (discussed further in Section 4.2). The recording of the arrhythmia episode was done on the unipolar system for this dissertation. The rotor event is a spatio-temporal phenomena, for which the unipolar electrogram may be better suited in identifying unique signal structures because it is an average of the activations around the electrode location. The unipolar electrogram records the electrical activation by placing one electrode on the surface of the heart and the reference electrode away from the ventricles but on the heart [31]. This records the far-field effect on the surrounding tissue, as opposed to the local activation recorded by the bipolar electrograms (discussed in Section 4.2). Once the pacing study is complete, the heart is resuscitated, such that it creates its own impulse. The heart is then forced into an arrhythmia. The electrical activations during the arrhythmia episode were sampled at 1000 samples/S and stored for a specific episode. The electrograms were down-sampled to 250 samples/S in order to reduce the number of samples for the analysis. These signals were also filtered further to limit the frequency range to the dominant range for ventricular arrhythmias. A Gaussian windowed FIR bandpass filter

46

>Z Z ^

  ZZ

D   Z ^  ^Z

Z 

(a) This figure represents how the electrode array is placed on the outer surface of the heart. The explanted heart is kept alive in a special Lagendroff system, which allows for the electrode array to be placed on the outer surface of the heart.

2000 ms

0 13 12
0 .1

1 2

0 .2

0 .3

0 .4

0 .5

0 .6

0 .7

11

0 .8

3

10

4

9 8 7 6

5

(b) This figure represents the electrode array that is attached to the surface of the heart. Each point represents an electrode from which the electrical activation is recorded from. The X and Y axes represent the spatial location of the myocardium.

Figure 3.4: Electrode Array 47

was used to to retain the 1 to 10 Hz frequency range from the electrogram [89] and filter out the remaining frequency ranges. The retrospective arrhythmia database consisted of 7 individual human hearts. There were a total of 13 unique arrhythmia episodes in which the rotor event was identified (identification of the rotor event was performed by our collaborators at Toronto General Hospital). From each episode, 2 electrodes in the vicinity of a rotor, 2 electrodes in the vicinity of a phase singularity (discussed further in Section 3.3), and 4 electrodes that were not in the vicinity of a phase singularity were selected. The electrograms extracted were a 10 S window of the total arrhythmia episode. Even though there were 112 electrodes used to record the electrical activations of the heart, only 8 electrodes per arrhythmia episode were selected because the number of rotors per case were limited. Therefore, a total of 104 electrograms (8 electrograms from each of the 13 episodes) were used for this analysis. This recorded arrhythmia episodes were used to identify the rotor events and identify any relating electrogram signal structures. This database will be referred to as RDB in this dissertation.

3.2.2 In-Vivo Database
There were two clinical patients who were undergoing intraoperative VT mapping, but had accidentally developed VF. During the VT mapping procedure, a similar electrode array to the RDB was attached to the outer surface of the heart and inside the left ventricles. This unintentional VF episodes that were recorded were also used to study the time-specific events. Though only two clinical cases exist, they represent the most ideal cases in order to study VF because the hearts are in a live clinical case. Also due to the limited availability, both the available surfaces (the inner left ventricle and outer heart surfaces) were used for one of the patients. Only the inner left ventricle recordings were available for the other patient. The acquisition system was similar to the one used for the RDB [31]. The average length of the VF recordings were 2.75 S. Similar to the RDB, 2 electrodes in the vicinity of a rotor, 2 electrodes in the vicinity of a phase singularity, and 4 electrodes that were not in the vicinity of a phase singularity were selected from each episode. Since there were 3 unique episodes, a total of 24 electrograms (8 electrograms from each of the

48

3 episodes) was used. This database was used to validate the adaptive decomposition approach presented in this chapter. This database will be referred to as IVDB for this dissertation.

3.2.3 Luo-Rudy Synthetic Database
The synthetic arrhythmia database was created synthetically generate a rotor event in a simulated cardiac tissue sample and determine whether the electrogram signal structures introduced in subsequent sections were valid. The synthetic arrhythmia database was generated using the Luo-Rudy 1 model [90Â­92]. The Luo-Rudy 1 model characterizes the transmembrane current based on the cell membrane's capacitance per unit area and the cell's transmembrane voltage. This model simulates the inward and outward current flow that occurs during an action potential. The voltage generated by the simulated cardiac tissue is used for the analysis. This database was provided by a third party collaborator (Dr. Edward Vigmond) to analyze the rotor events. For the model, a 36cm2 (6 Ã 6cm2 ) cardiac tissue area was simulated for different organization levels of the arrhythmia. From the area of simulated electrical activations, electrograms were computed on a 10 Ã 10 array. The electrograms were filtered between 1 to 10 Hz. This database was used primarily for the validation of the observed signal structures that were identified by the adaptive decomposition method that is discussed in the next section. The Luo-Rudy 1 model that was used to synthetically generate electrograms were not associated to the APP characteristics of the heart because this information was unavailable for the simulated cardiac tissue. Therefore, this synthetic arrhythmia will serve only as a means to validate the time-specific event and its associated signal structures (discussed in Section 3.5.3). This database will be referred to as LRDB.

3.3

Rotor Event

In order to observe the occurrence of these spatio-temporal rotor events, a phase map has to be generated, as it can provide an easier method by which to observe these points of circulating wavefronts. The phase is an important and fundamental parameter of a signal. Given a signal f , it is possible to calculate the instantaneous phase by analyzing the analytical form (y ) of the signal (f ). In order to calculate the analytical signal y , the Hilbert transform was used. Considering the 49

signal f (n) with the Fourier transform F (l), the analytical signal y (n) can be obtained by Equation 3.1 [93].

y (n) = IDFT(2us(l)F (l)) = IDFT((1 + sgn(l))F (l)) (3.1) = IDFT(F (l)) + IDFT(sgn(l)F (l)) = f (n) + jH (f (n)) Equation 3.1 states that the analytical signal y (n) is the inverse discrete Fourier transform (IDFT) of two times the Fourier step function (us(l)) multiplied by the Fourier transform (F (l)) of signal f (n). The unit step function is defined in Equation 3.2 [94]. The term sgn(l) is the signum function and is defined by Equation 3.3 [95]. The term H (f (n)) is the Hilbert transform of signal f (n). Once the analytical form y (n) was obtained, the instantaneous phase ((n)) was calculated using Equation 3.4.    0, l < 0 us(l) = 1, l > 0  1 , l =0 2    - 1, l < 0 sgn(l) = 1, l >0   0, l =0

(3.2)

(3.3)

(n) = arctan(

H (f (n)) ) f ( n)

(3.4)

Based on the previous steps used to calculate the instantaneous phase , it is possible to construct a phase map using the 112 recorded electrograms throughout the surface of the heart. However, in order to locate the precise location of such rotors, the spatial resolution has to be higher than that provided by the 112 electrodes. Therefore, a simple linear interpolation was performed on the electrical activations over the surface of the heart using the 112 electrodes [96]. Figure 3.5 is an example of a phase map.

50

Phase Map Frame: 2.2S
2pi

pi

0

(a) Phase map at time instance 1. The X and Y axes are spatial locations along the heart (refer to Figure 3.4)
Phase Map Frame: 2.3S
2pi

pi

0

(b) Phase map at time instance 2. The X and Y axes are spatial locations along the heart (refer to Figure 3.4)

Figure 3.5: Sample Phase Maps

51

From this figure, there are two example of phase singularity locations (circled in white). The colour in the phase map represents the phase at the particular time instance, while blue represents a phase of 0 and red represents a phase of 2 . A phase singularity is defined as a point around which the phase changes from 0 to 2 to complete one cycle [31, 96]. During a phase singularity, the electric waves are rotating around the centre point, which is referred to as the phase singularity. A rotor is defined as a phase singularity that completes at least two electric wave rotation cycles around the centre point. The example provided in Figure 3.5 is a phase map frozen in time at different time instances. In the first time instance (Figure 3.5a), there are two rotors identified occurring on the surface of the heart. The second time instance (Figure 3.5b) illustrates that the rotors had migrated to different locations over the heart. The manifestation of these spatio-temporal events are important in understanding the initiation and maintenance of VA (particularly VF). One of the fundamental limitations of generating phase maps is that it requires multiple electrodes [82, 83]. It is difficult to attach an electrode array to capture the simultaneous activation across the heart for a patient suffering from VA. Current ablation therapies attach a limited number of electrodes to monitor the electrical activations over a small region of the heart with very limited spatial resolution. Therefore, the detection of this event will depend on identifying electrogram characteristics that are in the vicinity of a rotor.

3.4

Envelope Amplitude Variation

In order to detect the occurrence of the rotor event, the electrograms in the vicinity would have to be closely observed. The generation of the phase maps allowed the cardiologists and clinicians at Toronto General Hospital to localize the occurrence of these rotor events on the explanted hearts (previously explained in Section 3.2.1). From these localized regions, it was observed that a repeating signal pattern that represented a form of amplitude modulation existed. Figure 3.6 are examples of electrograms, one in the vicinity of a rotor (Figure 3.6a) and one away from the rotor (Figure 3.6b). The occurrence of the amplitude modulation structure is observable in the electrograms near the vicinity of a rotor (Figure 3.6a) than the electrogram away from the rotor (Figure 3.6b). Based 52

Example of Rotor PS Electrogram
0.1 0.08 0.06

Normalized Amplitude

0.04 0.02 0 -0.02 -0.04 -0.06 -0.08 -0.1 0 2 4 6 8 10

Time (s)

(a) Rotor PS Electrogram

Example of Non-PS Electrogram
0.1 0.08 0.06

Normalized Amplitude

0.04 0.02 0 -0.02 -0.04 -0.06 -0.08 -0.1 0 2 4 6 8 10

Time (s)

(b) Non-PS Electrogram

Figure 3.6: Sample Electrograms

53

on this observation, an article submitted by our group [2] reported that it is possible to extract a electrogram feature that could capture the above-mentioned amplitude variation. In the article, an approximated modulation index feature was proposed for this purpose. Since the electrogram does not contain identical signal properties of a truly amplitude modulated signal (a signal with a fixed carrier and modulation frequency), only an approximate modulation index could be determined. In wireless communication, the modulation index (MI) is calculated from a generic modulated signal fM (refer to Equation 3.5) using Equation 3.6 [97].

fM (n) = AC sin(C (n)) + AE sin(E (n))(sin(C (n))) AE AC

(3.5)

MI =

(3.6)

The term AE refers to the envelope amplitude in an amplitude modulated signal and the term AC refers to the carrier amplitude. For the general modulated signal in Equation 3.5, the C and E are the carrier and envelope phases respectively, which is a function of time. It should also be noted that the envelope amplitude AE should be less than the carrier amplitude AC (i.e. Ve < Vc ) for traditional amplitude-modulated signals in wireless communication, so as to avoid distortion of the signal being modulated. The envelope and carrier components for a sample electrogram is illustrated in Figure 3.7. Since the arrhythmia electrogram has no defined properties of the amplitude modulated signal, the modulation index was approximated from the electrogram signal and its corresponding envelope. In order to approximate the envelope signal of the electrogram (f (n)), the analytic form of the signal (y (n)) was required. Similar to the process used for constructing the phase maps, the Hilbert transform (given by Equation 3.1) was used to obtain the analytic signal of the electrogram. However, instead of calculating the instantaneous phase (refer to Equation 3.4), the magnitude of the analytic signal (My (n)) was obtained given by Equation 3.7.

My ( n ) = | y ( n ) | =

f (n)2 + H (f (n))2

(3.7)

The magnitude signal (My (n)) captures the envelope amplitude variation (EAV) of the electrogram over time. Once both the magnitude signal (treated as the approximated envelope signal) and 54

Sample Electrogram with Envelope and Carrier Components
0.1

0.08

Envelope
0.06

0.04
Normalized Amplitude

0.02

0

-0.02

-0.04

-0.06

Carrier

-0.08

-0.1

0

1

2

3

4

5

6

7

8

9

10

Time (s)

Figure 3.7: Sample Electrogram Illustrating the Envelope and Carrier Components

55

the original electrogram signal were obtained, the approximated modulation index for each peak (pk ) in the magnitude signal was calculated. The approximate modulation index at a given peak (aM Ipk ) is the peak-peak amplitude of the magnitude signal at the given peak (AMy ,pk ) divided by the peak-peak amplitude of the electrogram signal at the given peak (Af,pk ). Once the approximate modulation index was calculated, an average was taken for all the peaks (P K ) to arrive at a single feature value for each of the electrograms. The approximate modulation index as well as its average is given by Equations 3.8 and 3.9, respectively. AMy ,pk Af,pk
PK

aM Ipk = Â¯I= 1 aM PK

(3.8)

aM Ipk
pk=1

(3.9)

The objective of such a feature was to quantify the observation made visually from Figure Â¯ I is a feature 3.6. Considering the generic modulated signal fM (refer to Equation 3.5), the aM that measures the amplitude-modulated component (i.e. AE sin(E (n))(sin(C (n)))). The results published in the Circulation Electrophysiology article [2] demonstrated that electrograms in Â¯ I ) than those the vicinity of the rotor had a higher average approximated modulation index (aM electrograms not in the vicinity of a rotor. An overall accuracy of 85% was reported between the rotor event electrograms and non-PS event electrograms (electrograms that are not near any phase singularity events). The overall accuracy for the LRDB was reported as 73%. This finding will be further expanded on in the results section (Section 3.6). There are a few advantages to such a feature, including that that it relies on the electrogram's signal structure, is related to the electrogram's vicinity to a rotor, and does not require a large degree of spatial resolution. Existing literature has also highlighted that dominant frequency maps [9, 29, 32] as well as entropy [98Â­100] may also be useful in localizing rotors, but face a similar limitation with phase maps, which require spatial resolution. One common limitation with dominant frequency maps as well as the approximated modulation index feature identified above is that the complexity of the electrical activations during VF also creates phase singularities that are not rotors (i.e. do not satisfy the two rotation requirements). These regions with phase singularities 56

also demonstrate similar dominant frequency relation and/or the approximated modulation index feature characteristics with the regions that have rotors, and will be discussed further in the results section Section 3.6). Decomposing the EAV structure (with a matching pursuit-based adaptive signal decomposition) may provide further insight into the rotor events and automate the detection process. The automated selection of atoms from a TF dictionary can be guided by a customized criterion function based on the EAV. This will allow for a formulation of the electrogram signal structure that would segregate the electrogram into two components: the EAV component and the residual component. The EAV and the residual components could then be further analyzed to possibly identify the rotor events.

3.5

Matching Pursuit Signal Decomposition

The electrical activations occurring during VF are often regarded as multi-component and chaotic with a high degree of complex signal structures. As previously described in Section 2.2.2, the ability of MP to decompose a signal relies on the Hilbert space that the dictionary spans as well as the criterion function. This section will review the dictionary used for the decomposition. Then, the rotor specific signal decomposition and the identified structures will be introduced.

3.5.1 Dictionary Selection
It is possible to use a number of different types of atoms to make up the dictionaries. Some examples of the more common matching pursuit basis atoms are the Gabor, Chirp and Dirac atoms [59, 60, 101]. While it is possible to create a dictionary that consists of all these various atoms to form an over-complete Hilbert space, there are two issues that should be considered. The first is that atoms of a particular dictionary type (i.e. dictionary of Gabor atoms) may overlap the same Hilbert space as an atom from another dictionary type (i.e. atoms from the Chirp dictionary). This makes extracting specific signal structures more challenging because a small variation observed in the signal structure could potentially be characterized by a set of different atoms. Another issue that arises is the computational complexity. By increasing the number of atoms in the dictionary, 57

the MP algorithm will have to check even more atoms per iteration to determine each atom's projection onto the signal/residual at that iteration. Thus, selecting the dictionary that is suitable for the arrhythmia signal structures is important for this dissertation. In order to determine suitability of the dictionary for the arrhythmia signal structures, sample dictionaries were created for the Gabor, Chirp and Dirac atoms. The scaling parameters for the Gabor atoms were selected as 128, 256, 512, 1024, and 2048, as these represented likely timesupport structures to be observed in the arrhythmia signal based on its sampling frequency (250 Hz). The scaling parameter of 128 would create atoms that are a little larger than one half of a second (precisely
128 250

S). Considering the dominant frequency range of VF being between 2 to

6 Hz [102], a scale that is half a second is sufficient to represent the signal structures for this frequency range. Therefore, the scaling parameter creates atoms that are approximately 0.5, 1, 2, 4 and 8 seconds, which can be used to represent local and generic signal structures in the electrogram. Once the dictionaries were generated, a sample of 100 electrogram signals were decomposed by each dictionary individually for 100 iterations. The number of iterations was set to 100 to benchmark the performance for each of the dictionaries and compare them to one another. The implementation of the MP algorithm was done using the Matching Pursuit Tool Kit [103] with a MATLAB interface. Once all the signals were decomposed by each dictionary type, the original energy and the residual energy were obtained. From these energies, an energy ratio (ER) was obtained using Equation 3.10. The ER was then averaged for all 100 signals for each dictionary type. This is presented in Table 3.1. f2 ) (R100 f )2

ER = 10  log10 (

(3.10)

Table 3.1: Average ER for each dictionary type Gabor 16.034 Chirp 16.047 Dirac 1.015

ER (dB)

From the results, it can be observed that in 100 iterations, the Gabor and Chirp dictionaries are quite effective in capturing the signal structures of the arrhythmia sample signals, with the Chirp 58

dictionary being better. However, upon closely analyzing the atoms used by the Chirp dictionary to decompose the arrhythmia signals, it was observed that over 80% of the atoms did not have an associated Chirp rate, effectively making these atoms a type of Gabor atom. Therefore, the dictionary that is used through this dissertation will be the Gabor dictionary, which has been previously established for the MP decomposition of ECG signals [64, 104]. Another advantage of using the Gabor dictionary is it provides optimal TF localization [105, 106], which is particularly important for identifying electrogram signal structures that are related to time-specific events.

3.5.2 Modified Criterion Function
The standard MP decomposition has a criterion function that maximizes the projection of the atoms in the dictionary onto the signal (refer to Equation 2.9) in order to represent the different structures of the signal. Since VF has a high degree of signal complexity, the ability to focus the adaptive MP decomposition to target specific signal structures is imperative for associating the signal structure with the rotor event. The approximated modulation index has revealed that amplitude variations exists in the envelope of the signal, which was also observed to be correlated with the occurrence of the rotor event [2]. Since the signal structure of interest for the rotor event is already known, the MP can be modified to capture only this signal structure. Therefore, the LCKSVD will not be used for this analysis because the LCKSVD is better suited when the electrogram signal structure is unknown. If the objective is to emphasize the EAV structure through the MP signal decomposition, then either the criterion function can be modified or specific atoms that span only the Hilbert space of these variations must be used in the dictionary. The complexity of the electrical activations makes it difficult to directly identify the atoms of the Hilbert space, and a customized criterion function is therefore required. There exists current methods to adaptively decompose a signal for its amplitude variations [107], but these methods are for deterministic (or quasi-harmonic) type signals. As VF may not be deterministic, the criterion function must be specifically tailored for the EAV structure identify and analyze the Hilbert space. In order to target the EAV structure, the analytic form of the electrogram as well as the magni-

59

tude of the analytic signal were used (refer to Equations 3.1 and 3.7). The envelope (My (n)) of the electrogram (f (n)) can be used to create a criterion function. Since the objective of this criterion function is to capture the EAV structure, the envelope must be minimized through each iteration in order for the approximated component of MP to retain the EAV structure. This can be thought of as the envelope signal component in an amplitude-modulated signal. The criterion function will also need to preserve the carrier signal component of an amplitude-modulated signal. Therefore, the following EAV measure was developed (given by Equation 3.11).
n ( My ( n )

EAVf =

The EAV measure (EAVf ) is the energy of the mean-adjusted envelope signal (denoted by
n ( My ( n )

Â¯ y )2 -M Â¯2 n ( f ( n) - f )

(3.11)

Â¯ y )2 ) divided by the energy of the mean-adjusted electrogram signal (denoted by -M Â¯ 2 ). The terms M Â¯ are the mean values for the envelope signal and the electroÂ¯ y and f

n ( f ( n) - f )

gram signal, respectively. Therefore, the numerator term corresponds to the energy in the envelope signal, whereas the denominator corresponds to the total signal energy, which creates a ratio between the envelope component to the original signal. One way to retain only the EAV structure in the approximated component of the MP algorithm would be to minimize the EAV measure through each iteration of MP. Based on this, the atom g that is selected on the th iteration is the atom that minimizes the EAV measure onto its residue R+1 f . The modified criterion function C  is defined by Equation 3.12 and has been presented in a recent article [108].

C  = argmin[EAVR+1 f ]

(3.12)

One requirement for such a criterion function is that the EAV measure is not zero (EAVR+1 f > 0). This is analogous to the residual energy not being zero in order to perform the original MP decomposition. If the EAV measure is zero, then the decomposition will stop. With the EAV-based criterion function, the residual Rf does not necessarily need to approach zero as the iterations approach infinity, which is the case in the original MP algorithm; the residual Rf could also approach a sinusoid with frequency variations, but no amplitude varying components, for which the proof is provided in Appendix A. To illustrate this, consider an electrogram that is decomposed 60

by the original criterion function (denoted as ORG MP) in Figure 3.8a and the EAV-based criterion function (denoted as EAV MP) in Figure 3.8b. For each type of MP decomposition (Figure 3.8a and Figure 3.8b), the top panel of the figure is the original electrogram signal, the middle panel is the approximated component after 100 iterations, and the bottom panel is the residual component after 100 iterations. As is expected in the case of the original MP, the residual component (bottom panel of Figure 3.8a) is approaching zero (or possibly signal structures that cannot be approximated by the atoms of the dictionary). This is because the criterion function is to select the atom that maximizes its projection onto the residual, therefore approximating all signal structures until the residual is zero. The approximated component (middle panel of Figure 3.8a) also visually shows a close approximation to the original signal (top panel of Figure 3.8a). This is in contrast to the decomposition by the EAV MP. The residual component (bottom panel of Figure 3.8b) does not approach zero, but instead appears to be approaching a sinusoid that will have no amplitude variations as the iteration approaches infinity. The approximated component (middle panel of Figure 3.8b) also appear to visually capture the amplitude variations in the original electrogram (top panel of Figure 3.8b). In order to verify the observations that were made visually from Figure 3.8, the EAV MP could be validated using synthetic sinusoids. Synthetic sinusoids are appropriate for validating the above mentioned concepts because it removes the variability that exists in VA electrograms. The standard notation for a modulated signal was given by Equation 3.5. Three synthetic signals with two frequency components and varying degrees of amplitude modulations were generated (modulation index of 0.9, 0.5 and 0.1). The phase component () were constant with time. Figure 3.9 illustrates the three different amplitude-modulated signals that were generated for this part of the analysis. These signals were then decomposed using the EAV MP. An example of this decomposition can be observed in Figure 3.10, where the residual component of the synthetic sinusoid with a modulation index of 0.9 is displayed after 10 and 100 iterations in Figures 3.10a and 3.10b, respectively. It can be observed that the residual component approaches a sinusoid with no amplitude variation as the number of iterations increase. In order to quantify the decrease in amplitude variations over the number of iterations, a tech-

61

Normalized Amplitude

Example of Rotor Vicinity Electrogram
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Time (s)
Normalized Amplitude

Approximated Component of Original Electrogram with ORG MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Time (s)
Normalized Amplitude

Residual Component of Original Electrogram with ORG MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Time (s)

(a) Original signal, approximated and residual component created as a result of decomposing the signal with ORG MP
Example of Rotor Vicinity Electrogram
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Normalized Amplitude

Time (s)
Normalized Amplitude

Approximated Component of Original Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Time (s)
Normalized Amplitude

Residual Component of Original Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Time (s)

(b) Original signal, approximated and residual component created as a result of decomposing the signal with EAV MP

Figure 3.8: Signal Decomposition Between the Two Types of MP for a Sample Signal After 100 Iterations

62

Synthetic Signal with 0.9 MI
0.1 0.08 0.06 0.04

Amplitude

0.02 0 -0.02 -0.04 -0.06 -0.08 -0.1 0 2 4 6 8 10

Time (s)

(a) Synthetic Signal with 0.9 MI
Synthetic Signal with 0.5 MI
0.1 0.08 0.06 0.04

Amplitude

0.02 0 -0.02 -0.04 -0.06 -0.08 -0.1 0 2 4 6 8 10

Time (s)

(b) Synthetic Signal with 0.5 MI
Synthetic Signal with 0.1 MI
0.1 0.08 0.06 0.04

Amplitude

0.02 0 -0.02 -0.04 -0.06 -0.08 -0.1 0 2 4 6 8 10

Time (s)

(c) Synthetic Signal with 0.1 MI

Figure 3.9: Synthetic Amplitude Modulated Signals

63

Residual after 10 Iterations
0.04 0.03 0.02

Amplitude

0.01 0 -0.01 -0.02 -0.03 -0.04

0

2

4

6

8

10

Time (s)
(a) Residual Component after 10 Iterations

Residual after 100 Iterations
0.04 0.03 0.02

Amplitude

0.01 0 -0.01 -0.02 -0.03 -0.04

0

2

4

6

8

10

Time (s)
(b) Residual Component after 100 Iterations

Figure 3.10: Residual Component of the Synthetic Signal With 0.9 MI

64

Teager-Kaiser Energy for Synthetic Signals Over MI Matching Pursuits Iterations
0.8

0.7

Synth Sig 0.9 Synth Sig 0.5 Synth Sig 0.1

Teager-Kaiser Energy

0.6

0.5

0.4

0.3

0.2

0.1

0

0

10

20

30

40

50

60

70

80

90

100

Iterations

The Teager-Kaiser energy approximates the energy of the envelope. This figure illustrates this energy for the synthetic sinusoids as it is being decomposed by the EAV MP at each iteration.

Figure 3.11: Teager-Kaiser Energy over 100 iterations for each Synthetic signal nique known as Teager-Kaiser energy operator [109] can be used to estimate the energy of the envelope at each iteration of the EAV-based decomposition. Figure 3.11 illustrates the Teager-Kaiser energy at different iterations of the EAV-based MP algorithm for the three synthetic sinusoid examples. From the figure, we can observe that there is a decrease in the Teager-Kaiser energy over the iterations, which implies that the atoms selected per iteration does capture the amplitude variations. It was also observed that the synthetic sinusoid with 0.9 modulation index had the largest reduction in the Teager-Kaiser energy. Therefore, the EAV-based MP could be a valuable tool in identifying and targeting the amplitude variations of the envelope, which can be used to better understand the rotor events.

3.5.3 EAV MP and Rotor Event
While the relation of the EAV with the rotor event was already discussed, the signal subspace captured by this decomposition will help in better understanding the electrogram signal structure. From the EAV MP, the amplitude variations that were captured are represented by a specific set of atoms. From these atoms, it is possible to make a scale-frequency map. Figure 3.12 was constructed by averaging the atom coefficients of the electrograms for the rotor PS event and comparing to those same electrograms decomposed by the ORG MP. 65

EAV MP - Rotor PS - Scale-Frequency-Amplitude Map
128
Scales

256 512 1024 2048 0 2 4 6 8 10 12

0.1 0.05 0

Frequency (Hz) ORG MP - Rotor PS - Scale-Frequency-Amplitude Map
128
Scales

0.15 0.1 0.05 0

256 512 1024 2048 0 2 4 6 8 10 12

Frequency (Hz) Diff - Scale-Frequency-Amplitude Map
0.15
128
Scales

256 512 1024 2048 0 2 4 6 8 10 12

0.1 0.05 0

Frequency (Hz)

The scale-frequency maps were created for the electrograms belonging to the Rotor PS class using the EAV MP and the ORG MP. The bottom panel illustrates the difference in the scale-frequency maps between the two types of MP.

Figure 3.12: Scale-Frequency Map of EAV MP vs ORG MP for Rotor PS

66

This figure illustrates that the subspace captured by the varying MP are different from one another. The subspace for the ORG MP (top panel of Figure 3.12) is concentrated around the 4 Hz frequency but spans a larger scale range (512, 1024, 2048). Conversely, the EAV MP (middle panel of Figure 3.12) subspace has a relatively stronger focus on the lower scale (128). This is indicative of the amplitude variations expected in ventricular arrhythmias (specifically VF). VF is known to have high-frequency chaotic signal structures, which may be why EAV MP was more focused on the low-scale atoms for capturing the time-specific EAV structure. In contrast, the ORG MP uses atoms with larger scales to better approximate the complete electrogram signal structure using a limited number of atoms. The bottom panel of Figure 3.12 shows the difference between the two scale-frequency maps. It illustrates the observations made previously between the EAV MP and ORG MP (e.g. EAV MP having more atoms captured by the lower scales). A significant focus of this section has been discussing the EAV and its ability to identify electrograms that are in the vicinity of a rotor. However, one of the shortcomings of the EAV alone (as well as the aMI feature, dominant frequency maps, and entropy) is that it had difficulty distinguishing locations with stable rotors from other locations (such as locations with phase singularities that were not rotors and locations with amplitude and frequency variations caused by other sources). To address this issue, rather than analyzing only the amplitude variations extracted by the EAV MP, the residual component can also be analyzed. The decomposition provided by the EAV MP on a sample electrogram is illustrated in Figure 3.13 and is similar to that of Figure 3.8b, only with a different sample electrogram. As previously noted, the top panel is the original electrogram, the middle panel is the approximated component that captures the EAV, and the bottom panel is the residual component once the amplitude variations have been extracted. It is possible to observe that a type of frequency deviation (FD) exists in the residual component. Two instances of this FD example can be observed in the bottom panel of Figure 3.13. The first instance occurs at a time of 2.8 seconds and the second instance occurs at a time of 5.2 seconds. While the existence of the FD structure is of interest, its correlation with the phase maps used to identify phase singularities and rotor locations is more interesting. Figure 3.14 is the corresponding phase map for the heart that was used for this specific example.

67

Normalized Amplitude

Original Electrogram in the Vicinity of a Rotor
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Normalized Amplitude

Time (s) Approximated Component of Original Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 10

Normalized Amplitude

Time (s) Residual Component of Original Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 Time: 5.2 s Time: 2.8 s

6

7

8

9

10

Time (s)

A sample electrogram in the vicinity of a rotor was decomposed with the EAV MP. The residual component (bottom panel) has an observable frequency deviation that correlates with the time of the rotor occurrence in Figure 3.14.

Figure 3.13: Original Signal, Approximated and Residual Component of an Electrogram with EAV MP After 100 Iterations

68

Phase Map Time Frame: 2.8 s
2pi

pi

0

(a) Phase Map at Time Instance of 2.8 S. The X and Y axes are spatial locations along the heart (refer to Figure 3.4)
Phase Map Time Frame: 5.2 s
2pi

pi

0

(b) Phase Map at Time Instance of 5.2 S. The X and Y axes are spatial locations along the heart (refer to Figure 3.4)

Figure 3.14: Corresponding Phase Maps for the Sample Electrogram in Figure 3.13

69

This figure provides the phase maps at the time instance of 2.8 seconds (Figure 3.14a) and 5.2 seconds (Figure 3.14b). In both figures, the electrode location for the electrogram in Figure 3.13 is denoted by a white circle, which illustrates its spatial location on the ventricles of the heart. When considering the residual component (bottom panel of Figure 3.13) and the phase maps (Figure 3.14), it is possible to observe that the occurrence of a phase singularity around the electrode location is corresponding to both the time instances (2.8 s and 5.2 s) presented in the residual component. In order to validate the above-mentioned signal structure, the simulated electrogram database was used. A simulated electrogram in the vicinity of a rotor was extracted from the simulation and decomposed using the EAV MP. Figure 3.15 presents the simulated electrogram (top panel), approximated component (middle panel) and residual component (bottom panel). From the residual component of the simulated electrogram (bottom panel of Figure 3.15), a FD type structure that is consistent with the electrograms obtained from the hearts of the RDB can be observed. Two instances of the FD occurrence are also highlighted in the residual component (bottom panel of Figure 3.15) of the simulated electrogram, for which the corresponding phase maps can be found in Figure 3.16 for each time instance (Figure 3.16a for time 1.7 s and Figure 3.16b for time 8.0 s). As with the RDB electrogram, the phase map for the simulated electrograms also indicates a correlation with the occurrence of a phase singularity around the electrode location and the time instances (1.7 s and 8.0 s) highlighted in the residual component. Next, the FD structure that exists in the simulated electrogram (as well as the RDB electrogram) and its association with the phase singularity will be quantified. Since the goal is to capture the frequency deviation in a frequency-modulated type signal, the straightforward approach would be to obtain the instantaneous frequency (IF) from the residual component. The IF can be easily determined from the phase (defined again in Equation 3.13 and 3.14). Given that the phase of the residual component is Rf , the IF can be calculated as given by Equation 3.15 [110].

y (n) = f (n) + jH (f (n))

(3.13)

70

Normalized Amplitude

Simulated Electrogram in the Vicinity of a Rotor
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9

Normalized Amplitude

Time (s) Approximated Component of Simulated Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9

Normalized Amplitude

Time (s) Residual Component of Simulated Electrogram with EAV MP
0.1 0.05 0 -0.05 -0.1 0 1 2 3 4 5 6 7 8 9 Time: 1.7 s Time: 8.0 s

Time (s)

A sample simulated electrogram in the vicinity of a rotor was decomposed with the EAV MP. The residual component (bottom panel) also has an observable frequency deviation that correlates with the time of the rotor occurrence in Figure 3.16.

Figure 3.15: Original Signal, Approximated and Residual Component of a Simulated Electrogram with EAV MP After 100 Iterations

71

Phase Map Time Frame: 1.7 S
2pi

pi

0

(a) Phase Map at Time Instance of 1.7 s
Phase Map Time Frame: 8 S
2pi

pi

0

(b) Phase Map at Time Instance of 8.0 s

Figure 3.16: Corresponding Phase Maps for the Sample Simulated Electrogram in Figure 3.15

72

(n) = arctan(

H (f (n)) ) f ( n)

(3.14)

IFRf (n) =

dRf (n) dn

(3.15)

Equation 3.15 states that the derivative of the instantaneous phase  will equal the IF. An example of the IF for the simulated electrogram's residual component (bottom panel of Figure 3.15) is provided in Figure 3.17. From this figure, it is possible to observe a change in the IF as the phase singularity is in the vicinity of the electrode location. Based on the EAV and the IF of the residual component, it is possible to detect the rotor event using only signal structures within the electrogram.

3.5.4 Feature Extraction
Given the EAV MP decomposition structures identified for the rotor event, the RDB was used to identify non-rotor phase singularity and rotor locations. The rotor locations were previously identified by clinical experts from Toronto General Hospital. The non-rotor phase singularity event locations were also identified to help validate whether the combination of the EAV and FD structures were unique for the rotor event. For both the rotor and non-rotor phase singularity locations, the time at which the phase singularity events had occurred were also recorded, since the EAV and FD structures were correlated to the time of the event. Electrogram locations and times were also recorded for non-phase singularity event locations in order to validate the structural significance for the specific event. The time and locations for the non-phase singularity events were selected randomly and to specifically not have a phase singularity occurring around the location or at the selected time. Given the EAV MP decomposition structures identified for the rotor event, the RDB was used to identify non-rotor phase singularity and rotor locations. The rotor locations were previously identified by clinical experts from Toronto General Hospital. The non-rotor phase singularity event locations were also identified to help validate whether the combination of the EAV and FD structures were unique for the rotor event. For both the rotor and non-rotor phase singularity locations, the time at which the phase singularity events had occurred were also recorded, since the 73

Residual Component of Simulated Electrogram with EAV MP
0.1
Normalized Amplitude

0.05

Time: 1.7 s

Time: 8.0 s

0

-0.05

-0.1

0

1

2

3

4

5

6

7

8

9

Time (s) Instantaneous Frequency of the Simulated Electrogram Residual Component
0.5
Normalized Frequency

0.4 0.3 Time: 1.7 s 0.2 0.1 0 Time: 8.0 s

0

1

2

3

4

5

6

7

8

9

Time (s)

Figure 3.17: Residual Component of the Simulated Electrogram and the Corresponding Instantaneous Frequency

74

EAV and FD structures were correlated to the time of the event. Electrogram locations and times were also recorded for non-phase singularity event locations in order to validate the structural significance for the specific event. The time and locations for the non-phase singularity events were selected randomly and to specifically not have a phase singularity occurring around the location or at the selected time. The FD structure was analyzed for the different types of electrograms. As previously observed in Figure 3.17, there is a noticeable change in the IF as the phase singularity is in the vicinity of the electrogram. In order to quantify this phenomenon, the difference between the IF before and after the phase singularity was used. The time sample before (nIF,Bef ore ) and the time sample after (nIF,Af ter ) the event were extracted by taking the derivative of the IF signal. After taking the derivative, the zero crossing points before and after (corresponding to the IF local minima/maxima) the phase singularity event would indicate the desired time samples. These time samples are illustrated in the bottom panel of Figure 3.18. The approximated FD (aF D) feature is defined by Equation 3.16. This equation states that the aF D feature is the absolute difference between the IF at time sample nIF,Bef ore and nIF,Af ter . The distribution of this feature for the three sets of electrodes is given in Figure 3.19.

aF D = |IFRf (nIF,Bef ore ) - IFRf (nIF,Af ter )|

(3.16)

From the distribution of this feature in Figure 3.19, it is possible make a few observations. The first observations is that both the phase singularity cases (denoted as rotor PS and non-rotor PS) show a difference from the electrodes not in the vicinity of a phase singularity (denoted as non-PS) and this was statistically significant (P < 0.01). This indicates that the electrode and the time of the phase singularity (represented by both rotor and non-rotor PS) creates greater change in the IF feature than those electrodes that do not have a phase singularity (non-PS). It is also interesting to note that the rotor phase singularity cases (rotor PS) and the non-rotor phase singularity cases (non-rotor PS) have a similar distribution with respect to the IF feature. This suggests that the change in the instantaneous frequency (observed as a FD) is a phenomenon of phase singularities in general and not specific to rotors themselves. 75

Residual Component of Simulated Electrogram with EAV MP
0.1
Normalized Amplitude

0.05

0

-0.05

-0.1

0

1

2

3

4

5

6

7

8

9

Time (s) Instantaneous Frequency of the Simulated Electrogram Residual Component
0.5
Normalized Frequency

0.4 0.3 0.2 0.1 0

n

IF,Before

nIF,After

0

1

2

3

4

5

6

7

8

9

Time (s)

Figure 3.18: Residual Component and Corresponding IF with Identified Time Samples

76

IF Absolute Difference

0.2

0.15
Normalized Frequency

0.1

0.05

0

Rotor PS

Non-Rotor PS Groups

Non-PS

Figure 3.19: Approximated FD Feature Boxplot for the Rotor-PS, Non-Rotor PS and Non-PS Classes

77

Considering phase singularities, in terms of the time-domain signals around the centre point, this phenomena occurs when electric waves circulate around this centre point [31]. Therefore, a phase singularity consists of signals with a progressive phase change around a point [31, 96]. However, this would mean that the signal at the exact centre point of the phase singularity would theoretically be zero [96]. Recall the primary difference between a rotor and a non-rotor PS point is the number of electric wave rotations around the point. A phase singularity is considered a rotor if the electric waves around the phase singularity completes a minimum of two rotations, as stated earlier in this section. This may be reflected by the EAV structure (specifically the signal energy) captured in the approximated component of the EAV MP decomposition. Therefore, analyzing the EAV around the occurrence of the FD may be useful. This EAV feature can be obtained from the approximated component (
 b  g   ( n) )

of the EAV MP and over the duration of the IF change

(nIF,Bef ore and nIF,Af ter ). The feature that is used is an approximate root mean square (aRMS) of this component over the duration of the IF change is given by Equation 3.17.
n=nIF,Af ter n=nIF,Bef ore (  b g (n)) 2

EAVaRM S =

nIF,Af ter - nIF,Bef ore + 1

(3.17)

Equation 3.17 is the root mean squared sum of the approximated component over the time of the event (between nIF,Bef ore and nIF,Af ter ), and is measured as energy per unit time sample. Based on this feature, the distribution between the rotor and non-rotor PS is provided in Figure 3.20. From the EAV aRMS distribution between the groups, we observe that the feature was lower for the rotor PS when compared to the non-rotor PS (P < 0.01). Given the more stable number of rotations for rotors PS (or abrupt rotations for non-rotor PS), it is possible that this is reflected by the EAV structure and the aRMS feature. Recall, from the generic modulated signal from Equation 3.5 (provided again in Equation 3.18), the two signal structures (and subsequent features) correspond to specific components of the generic modulated signal fM . The residual IF structure (and the aF D feature) relates to the FD component (C (n)), refer to Appendix A, and can be described as a measure of the FD created as a result of the rotor event. The EAV structure (and the EAVaRM S feature) is related to the amplitude modulation component (AC ) + AE sin(E (n)) (refer to Appendix A) of the signal fM . 78

EAV Approximated RMS

0.022

0.02

0.018

0.016
RMS (Normalized)

0.014

0.012

0.01

0.008

0.006

0.004

0.002

Rotor PS Groups

Non-Rotor PS

Figure 3.20: EAV Approximated RMS Feature Boxplot for the Rotor PS and Non-Rotor PS Classes

79

ZZZ W^ ^  W^ EZZZZ W^ Z ^ 

EZW^ EZW^ Z

Figure 3.21: Two Stage Classification for the Time-Specific Event The combination of these features describe different aspects of the electrogram, and will be used for discussing the final results.

fM (n) = AC sin(C (n)) + AE sin(E (n))(sin(C (n)))

(3.18)

3.6

Results and Discussion

Â¯ I feature The results for this chapter will be discussed in this section. The initial result with the aM is presented first. Then, the results for the EAV-based MP is provided, followed by a discussion of the analysis. The RDB can be segregated by a two stage classification system. The first stage was between PS and non-PS electrograms and the second stage was between rotor and non-rotor PS electrograms. This is illustrated in Figure 3.21.

3.6.1 EAV Results
Â¯ I ), this For the analysis performed on the average approximated modulation index feature (aM feature was determined for each of the rotor PS and non-PS electrograms. There are 2 rotor PS and 2 non-Rotor PS electrograms from each episode, giving a total of 52 electrograms for this analysis. 80

Average Modulation Index for Rotor PS versus Non-PS event

0.45

0.4

0.35

Modulation Index

0.3

0.25

0.2

0.15

Rotor PS

Non-PS

Figure 3.22: Average MI Between the Rotor PS and Non-PS events for RDB Â¯ I feature for the RDB (described Figure 3.22 and Figure 3.23 illustrates the distribution of the aM in Section 3.2.1) and the LRDB (described in Section 3.2.3), respectively. These results show that the amplitude variations in the envelope is a discriminative signal structure (P < 0.01) for the rotor events when compared to the non-PS events. The classification table for this feature is given by Tables 3.2 and 3.3 for the RDB and LRDB, respectively. Table 3.2: Confusion Matrix - Average MI for RDB: Rotor PS Versus Non-PS Event Rotor PS Event 19 3 73.08 11.54 Non-PS Event 7 23 26.92 88.46 Total 26 26 100 100

Rotor PS Event Non-PS Event Rotor PS Event (%) Non-PS Event (%)

The overall accuracy achieved for the RDB and LRDB were 80.77% and 72.50%, respectively. Â¯ I feature illustrates its strength in identifying rotor PS events from non-PS events. When The aM analyzing this feature for the rotor PS events and the non-rotor PS events, similarities in its distriÂ¯ I feature for the rotor PS bution can be observed. Figure 3.24 provides the distribution of the aM and non-rotor PS electrograms, which illustrates the limitation of this feature.

81

Average Modulation Index for Simulated Electrodes
0.45

0.4

0.35

Modulation Index

0.3

0.25

0.2

0.15

0.1

0.05

Rotor PS

Non-PS

Figure 3.23: Average MI Between the Rotor PS and Non-PS events for LRDB

Average Modulation Index for Rotor PS versus Non-Rotor PS event

0.45

0.4

Modulation Index

0.35

0.3

0.25

0.2

Rotor PS

Non-Rotor PS

Figure 3.24: Average MI Between the Rotor PS and Non-Rotor PS events for RDB

82

Table 3.3: Confusion Matrix - Average MI for LRDB: PS Event Versus Non-PS Event Rotor PS Event 14 5 70.00 25.00 Non-PS Event 6 15 30.00 75.00 Total 20 20 100 100

Rotor PS Event Non-PS Event Rotor PS Event (%) Non-PS Event (%)

The EAV analysis revealed that the rotor event could be associated with electrogram signal structures that occur during an arrhythmia episode. Furthermore, this analysis demonstrated that the time-specific rotor event could be tracked without the need for high-resolution mapping of Â¯ I analyzed the the electrical activations of the heart. The average modulation index feature aM envelope variations of the electrogram, which had been strong for classifying the rotor PS events from the non-PS events, but could not be used to classify the rotor PS events from the non-rotor PS events. This led to the MP decomposition constrained by the EAV through the use of a modified criterion function.

3.6.2 EAV MP Results
The results for the EAV-based MP decomposition was limited to the RDB and IVDB. The LRDB was used to produce a rotor PS event, but it did not have non-rotor PS events, and thus could not be used for this result. Based on the observations made from the EAV MP decomposition (Sections 3.5.3 and 3.5.4), a simple two-stage classification (refer to Figure 3.21) was performed to determine the classification accuracies of the aF D and EAVaRM S feature. A total of 104 electrograms were used for the results. The first stage classifies PS events and non-PS events. Table 3.4 presents the results of the first stage of the classification. The feature used for the first stage of the classification was the aF D feature from Equation 3.16. The results from Table 3.4 give an overall classification accuracy of 80.77%. The sensitivity and specificity were 65.38% and 96.15%, respectively. These results have a high specificity, thereby able to better identify electrograms that are not in the vicinity of a phase singularity. On the other hand, the ability to identify electrograms around a phase singularity with this feature is 65.38%,

83

Table 3.4: Confusion Matrix - Stage 1 Percentage: PS Versus Non-PS Event PS Event 34 2 65.38 3.85 Non-PS Event 18 50 34.62 96.15 Total 52 52 100 100

PS Event Non-PS Event PS Event (%) Non-PS Event (%)

which highlights that around two-thirds of the phase singularity points exhibit a shift in the IF. This indicates that the residual component generated by the EAV-based MP creates uniquely identifiable signal structure to detect phase singularity points. While it may be possible to improve the accuracy of Stage 1, such as through the use of existing features (including aMI, DF, and entropy), the objective was to illustrate that the FD structure can be used to associate an electrogram to the vicinity of a phase singularity. From the correctly classified phase singularity cases in Stage 1, a Stage 2 classification ( Table 3.5) was also performed using the EAVaRM S feature. Table 3.5: Confusion Matrix - Stage 2 Percentage: Rotor PS Versus Non-Rotor PS Event Rotor PS 14 4 82.35 23.53 Non-Rotor PS 3 13 17.65 76.47 Total 17 17 100 100

Rotor PS Non-Rotor PS Rotor PS (%) Non-Rotor PS (%)

The overall classification accuracy obtained from Stage 2 was 79.41%. The classification between the two groups can be observed as being more balanced (sensitivity of 82.35% and specificity of 76.47% for non-rotor events) when compared to the first stage. The strong classification accuracy provided by this feature (EAVaRM S ) reflects that the EAV structure can be used to distinguish between these phase singularity types. The EAV MP results was also compared with entropy. The entropy was another feature that was observed for its ability to identify rotor locations using minimal electrodes [100]. This feature was used to classify the RDB. Tables 3.6 and 3.7 presents the results for stage 1 and stage 2 using the entropy feature. The accuracies obtained by this feature illustrates the strength and balanced results obtained by the approximated RMS of the EAV struc84

ture, which is better suited in distinguishing the Rotor PS events when compared to the existing entropy method. Table 3.6: Confusion Matrix - Stage 1 Entropy Percentage: PS Versus Non-PS Event PS 23 23 44.23 44.23 Non-PS 29 29 55.77 55.77 Total 52 52 100 100

PS Non-PS PS (%) Non-PS (%)

Table 3.7: Confusion Matrix - Stage 2 Entropy Percentage: Rotor PS Versus Non-Rotor PS Event Rotor PS 11 9 64.71 52.94 Non-Rotor PS 6 8 35.29 47.06 Total 17 17 100 100

Rotor PS Non-Rotor PS Rotor PS (%) Non-Rotor PS (%)

Lastly, the IVDB cases were also decomposed using the EAV MP. The electrical recordings gathered from the IVDB cases are extremely valuable despite the limited episodes that were available. These cases were recorded during intraoperative surgery, which provided a unique insight to the electrogram signal structures and their relation to the rotor events. It allows for analysis of the hearts electrical activations in a live clinical case. The above features (aF D and EAVaRM S ) from the respective residual and EAV structures were extracted for the select electrogram locations. With 3 arrhythmia episodes, a total of 12 electrograms were used. The distribution for the IVDB cases is given by Figures 3.25 and 3.26. The distribution of the approximated FD feature appears consistent with the results obtained through the RDB. The PS electrograms (rotor and non-rotor PS) have a higher approximated FD feature value when compared to the non-PS electrograms (Figure 3.25). The distribution in the approximated RMS for the EAV does not show a similar distribution observed in RDB. It should be noted that two of the three episodes originated from the inner wall of the left ventricle, while all of the episodes in the RDB were from the outer surface of the heart. This will be further discussed 85

IF Absolute Difference - InVivo
0.25

0.2

Normalized Frequency

0.15

0.1

0.05

Rotor PS

Non-Rotor PS Groups

Non-PS

Figure 3.25: Approximated FD Feature Boxplot for IVDB

86

EAV Approximated RMS - InVivo
0.026

0.024

0.022

0.02
RMS (Normalized)

0.018

0.016

0.014

0.012

0.01

0.008

0.006

Rotor PS Groups

Non-Rotor PS

Figure 3.26: EAV Approximated RMS Feature Boxplot for IVDB

87

in the following section.

3.6.3 Discussion
The analysis and results presented in this chapter had introduced the rotor event that is believed to be the manifestation of a mechanism that initiate and maintain arrhythmic episodes. The analysis also revealed the existence of electrogram signal structures that are related to the occurrence of such an event. While the electrogram signal structure may be visually used by the clinical community to assess a patient, the observations made on the EAV structure (from the approximated component) and the FD (from the residual component) can be quantified by the features discussed above to assist in automated analysis of the electrograms. Furthermore, the electrogram signal structure can be extracted with a minimal number of electrodes, making it more feasible to detect and track the rotor event in a clinical setup for better treatment planning. In particular, the tracking of the rotor event on the precise location on the myocardium can enable clinicians to provided targeted therapy. As discussed earlier in this section, other features have been previously established to help identify rotors. These include features such as the dominant frequency [9, 29, 32] and entropy [98Â­100] because they do not need as high of a resolution as phase maps; however still requiring multiple electrograms. Furthermore, these features are also known to highlight other non-rotor regions (either non-rotor PS or non-PS events) as having a similar feature distribution as regions with rotors, which may be attributed to phase singularities that do not meet the criteria of being Â¯ I ) feature [2] was also initially a rotor (i.e. non-rotor PS). The average approximated MI (aM proposed as a feature in hopes to limit the number of electrograms required to determine the rotor location. However, this feature was unable to distinguish rotors from non-rotor phase singularity events. The decomposition of the electrogram to highlight the EAV structure using the EAV-based MP was motivated by the initial results obtained by the average approximated MI and it's limitations. This decomposition revealed that the electrogram signal structure could be decomposed into components that correlate with the known rotor-electrophysiological event during an arrhythmic episode. The tandem of the approximated and residual components, produced as a result of the

88

EAV MP decomposition, provides insight to the rotor event, which could be useful in the clinical setting. Specifically, the residual IF revealed the possibility of segregating the PS from non-PS events. Analysis on the misclassified PS samples had indicated that the FD feature has a similar distribution to the non-PS events, and visually the MI component was less prominent in those misclassified samples. This could be attributed to inherent natural overlap in the database and possible far-field effects that may influence the rotor's effect on the electrodes. The EAV structure was analyzed to determine which phase singularity electrograms had a rotor event. The results from the EAV MP analysis was also observed to outperform the results of entropy. While the approximated FD distribution remained consistent between the RDB and IVDB, the distribution of the approximated RMS of the EAV structure was different for the clinical cases, which could be due to the fact that two of the episodes were recorded from the inner wall of the ventricle. It has been previously observed that the electrical activations from the inner wall was dissimilar from the outer surface [111], which could explain the discrepancy observed in the EAV structure of the rotor and non-rotor PS electrograms. These signal structures revealed by the EAV MP decomposition cannot be easily observed directly from the electrogram, and the decomposition can therefore be useful in the clinical setting by providing the clinician a tool to better diagnose the arrhythmia episode. One of the limitations of the EAV MP decomposition is the computational complexity required. The complexity of such a system (MP based system) was O(N 2 log(N )) [60]. The complexity of the overall system is the MP algorithm (O(N 2 log(N ))) plus the complexity in calculating the residual's IF through the Hilbert transform (O(N log(N ))) [112]. However, the identification of these signal structures and its relationship to the rotor event can inspire offline analysis of the arrhythmic episode. Furthermore, the advent of fast digital signal processors will eventually make the current analysis near real-time realizable. Currently, people who are prone to recurring arrhythmic episodes will have an ICD installed in order to monitor and treat future episodes [8]. The electrograms recorded by this device can later be analyzed by clinicians to determine probable regions where the rotor may have existed during the episode. The EAV decomposition can also be used for patients who are in the intensive care unit of the hospital to better understand the arrhythmic episode (such as the possible locations of the phase

89

singularities). The identification of the signal structures revealed by the EAV MP decomposition can also lead to better strategies in treating future episodes (such as better localization of possible ablation sites). This finding forms the basis of decomposing the electrogram signal structures influenced by time-specific events in the arrhythmia.

3.7

Chapter 3 Summary

This chapter introduced and discussed some of the time-specific event signal structures that may be found in the electrogram during an arrhythmic episode. Specifically, the rotor event was explained in more detail because it is believed to be a manifestation of one of the underlying mechanisms that initiate and maintain the arrhythmia episode. An envelope amplitude variation is reflected in the electrogram when a rotor was in the vicinity. This section also introduced a unique criterion function aimed at capturing this amplitude variation using the matching pursuits algorithm. This decomposition led to identifying two unique components, the approximated component (identifying the approximated RMS of the EAV structure) and the residual component (identifying the approximated FD structure), which correlated with the occurrence of the rotor, thereby providing the ability to detect a rotor from the electrogram alone. This analysis on the electrogram signal structure is associated with the time-specific rotor event (along with APP characteristics known to be in the vicinity of the rotor), and can be used to drive a DSS in order to assist clinicians in diagnosing VA for the time-specific rotor event.

90

Chapter 4 Time-Averaged Ventricular Arrhythmia Characteristics

T

HE study of general characteristics of the VA episode has been an area of focus for some time. The features identified in literature describe some time-averaged characteristic of the

arrhythmia for specific applications, including classifying the type of arrhythmia or even predicting shock success based on feature distribution. The signal decomposition in the previous chapter identified structures that was related to events that occurred at a specific time during the arrhythmic episode. In this chapter, some of the time-averaged characteristics that influences the VA episode will be discussed. Then, the specific database and the extraction of the APP characteristics for the analysis is provided. The relationship of the time-averaged characteristics with the underlying APP of the heart will be presented. The dictionary learning is then discussed to assist in identifying discriminatory signal structures as they pertain to the APP characteristics. Finally, the results and discussion for the dictionary learning are provided, before the chapter concludes with a brief summary. The general block diagram for this chapter is illustrated in Figure 4.1.

4.1

Time-Averaged Characteristics Background

While ventricular arrhythmia episodes are known to have one or many events that occur at a given time instant, as discussed in Chapter 3, there are still some unknown phenomena that initiate and sustain the arrhythmia. This can sometimes be observed by analyzing characteristics of the ventricular arrhythmia episode. During the occurrence of a ventricular arrhythmia episode (particularly 91

d^  Z

 d& ZZZ

 Z ^ ^ Z^Z ^ E EZ  DZ

Z

h /

 WW >

d& Z > DZ  WW 

 Z 

d  s 

This chapter will discuss the time-averaged VA characteristics. In particular, the TF dictionary learning approach that is motivated by the APP characteristics to identify discriminant dictionary elements will be discussed.

Figure 4.1: Contributions for Chapter 3

92

VF), signal characteristics can change over the course of the episode. While the underlying cause may not be fully understood, these time-averaged signal structures in the arrhythmia episode may be associated with a set of APP characteristics. Time-average characteristics describe a specific or set of properties that extends over a time segment of the VA episode, and thus represent the average characteristics of the VA electrogram. One such example of a time-averaged characteristic of the VA episode is frequency, which may be time-varying in the case of VA electrograms. There have been many time-averaged characteristics or features that have been extracted to analyze an arrhythmic episode in existing literature. Each feature describes some general characteristic of the electrogram signal structure. Time-domain-based characteristics (such as a complexity measure, threshold-crossing interval and auto-correlation) have been used for the purpose of classifying the arrhythmia as VT or VF [52, 113]. The frequency domain was also previously used in applications involving the prediction of the success of a defibrillation shock. Specifically, features such as the dominant frequency, median frequency, spectral flatness and bandwidth have been used for the purpose of predicting the shock success [89, 114]. Spectral coherence is another frequency domain feature that was used to analyze how organized the arrhythmia is [115], where VT is highly organized and VF is highly disorganized. Our group also previously quantified the dynamic range of the organization of the ventricular arrhythmia episode using features extracted from a waveletbased singular value decomposition [58, 116]. Another characteristic of the arrhythmic episode is the occurrence of electrogram patterns during an episode. Electrogram patterns previously identified through my Master's dissertation [116] (refer to Figure 4.2) revealed that arrhythmic episodes from different patients had similarities in their distribution [35]. In this study, the occurrence of the electrogram patterns over the entirety of the episode were examined in terms of the energy retained by these patterns. This study also revealed that similar distributions among the individual's VF episodes had existed, where some groups of patients had a similar type of distribution in the electrogram patterns. While the above-mentioned features are a small fraction of what exists in literature, they all demonstrate that there may be some features of the arrhythmic episode that can be associated with the APP characteristics. The association of the signal structures with the APP characteristics can help clinicians to better strategize the available therapy options.

93

0.25 0.25 0.2 0.2 0.15 0.15

Amplitude

0.1

Amplitude
0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2

0.1 0.05 0 -0.05 -0.1 -0.15 -0.2

0.05

0

-0.05

-0.1

-0.15

-0.2

-0.25

-0.25

Time (s)
(a) Local Pattern 1

0.2

0.4

0.6

0.8

Time (s)

1

1.2

1.4

1.6

1.8

2

(b) Local Pattern 2

0.4 0.5 0.4 0.2 0.3 0.2 0.1 0 -0.1 -0.2 -0.3 -0.4 -0.5 -0.5

0.3

Amplitude

0.1

0

-0.1

-0.2

-0.3

-0.4

-0.6

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

2

Amplitude

0.5

1

1.5

2

2.5

3

3.5

4

4.5

5

5.5

6

Time (s)
(c) Local Pattern 3

Time (s)
(d) Global Pattern

Figure 4.2: Unipolar Electrogram Patterns Â©[2013] IEEE

94

4.2

Database

This section will expand on the retrospective arrhythmia database that was introduced in Section 3.2.1. The unipolar recordings that were used to capture the electrical activations during the arrhythmic episode was used to analyze the time-averaged characteristics. The retrospective arrhythmia database consisted of 7 individual human hearts. While 13 arrhythmic episodes existed, only 11 of the episodes were used in this analysis. The 2 episodes that were removed for this analysis were special cases where the perfusion was stopped (i.e. no synthetic blood flow), and including these would introduce an added variability for the time-averaged characteristics. Thus, a total of 11 episodes with a maximum of 112 electrograms per episode were used for this analysis. In order to determine some of the APP characteristics, a pacing system had to be used. The pacing system produces an impulse on one part of the myocardium, which will then propagate throughout the heart. The action potential produced by the myocardium is in response to this paced impulse, which is recorded and used to determine the APP characteristics. The paced impulse and resulting action potential was recorded from a unipolar and bipolar electrode. The unipolar electrode was described previously in Section 3.2.1. Briefly, the unipolar electrode records the electrical activation on the tissue with respect to a reference electrode that is not on the ventricles. The hardware sampling frequency for the unipolar electrograms was 1000 samples/S. In contrast, the bipolar electrogram requires two closely placed electrodes to measure the potential. The potential is determined by subtracting the electrical activation recorded from one electrode from the other. The hardware sampling frequency for the bipolar electrograms was 2000 samples/S. This unipolar and bipolar recording of the pacing signals were then used to determine some of the APP characteristics The bipolar electrogram was used for extracting the max voltage, which is then used to determine if the tissue was healthy or diseased (scar) [21]. The activation recovery interval (ARI) was derived by measuring the duration from the end of the action-potential to the beginning of the repolarization wave in the unipolar electrogram [10]. The approximation of the monophasic action potential (MAP) duration is a characteristic that is a measure of the action-potential duration (APD) [117, 118]. In particular, it was observed that 90% of the MAP is closely correlated with 95

the APD. It was also observed that regression models correlated the ARI recorded from the unipolar electrogram with the MAP duration [119, 120]. The approximation of the MAP duration was derived from the ARI using a regression model and will be referred to as MAP for the remainder of this dissertation. The DVDT was determined by first obtaining the derivative of the unipolar pacing electrogram and then recording the maximum negative slope [121]. After the pacing system was used to record the unipolar and bipolar tracings, the heart was bought to normal sinus rhythm and then forced into an arrhythmia for the analysis. At the completion of the arrhythmia tests, the heart was then sent to the histology lab where the pathological characteristics were obtained, thus labeling the type of cardiomyopathy for the heart. These characteristics were recorded once for each heart, and therefore, a heart with multiple arrhythmia episodes will have the same APP characteristics. The unipolar electrical recordings during the arrhythmia episode along with the corresponding APP characteristics were used for the objective of identifying signal structures from the electrograms and associating them with the APP characteristics. The APP characteristics for each electrode location were divided into clinically established categories. The MAP and ARI intervals were classified as normal or abnormal depending on the value, with a normal value between 193 mS and 277 mS [122]. The max voltage was classified as normal, if the value is greater than 0.5 mV, or abnormal [123]. As the more clinical term for normal is healthy and for abnormal is scar, those terms will be used for this chapter. The DVDT was also classified as normal, if the negative slope was less than -0.25 mV/mS, or abnormal [17]. Table 4.1 summarizes the normal and abnormal range for each APP characteristic. Additionally, the type of cardiomyopathy for each heart (i.e. all electrogram locations for that heart) was also used as a category. The categories serve as the ground truth for the analysis. This database will continue to be referred to as the RDB.

4.3

Correlation of Time-Averaged Characteristics with APP

Identifying general signal structures from the arrhythmic episode relies on using some of the timeaveraged characteristics as the starting basis. These characteristics describe an underlying signal structure of the electrograms. Some of these characteristics or signal features were significant for 96

Table 4.1: APP Characteristic Range for Normal and Abnormal APP MAP ARI Max Voltage DVDT Normal 193mS  MAP  277mS 193mS  ARI  277mS  0.5mV (Healthy)  -0.25mV/mS Abnormal MAP < 193mS or MAP > 277mS ARI < 193mS or ARI > 277mS < 0.5 mV (Scar) > -0.25mV/mS

such applications as determining the organization of the arrhythmia [58, 115, 116] and predicting the shock success [89, 114]. These features, as well as the previously observed distribution of electrogram patterns in different patients [35], are an indication that the APP characteristics may influence electrical activations, and by extension the time-averaged characteristics, which is the foundation for this analysis. In order to illustrate this, some of the features discussed in this chapter will be used. It should be noted that the features discussed here are representative of features used in existing literature [35, 58, 89, 114Â­116], but are used to describe the process by which to identify general signal structures as they relate to the APP characteristics. A list of the features and a brief description is given as follows: Â· Dominant Frequency: The DF has been a widely used signal feature for many application in analyzing ventricular arrhythmias. Some of the applications include predicting shock success, classifying the degree of organization within the VF arrhythmia class, and using dominant frequency maps to predict rotor locations [29, 89]. The DF describes the most dominant frequency structure in the arrhythmia signal. Â· Local Pattern Energy: The occurrence of the local patterns and the amount of the signal energy represented by these local patterns were previously observed to vary from patient to patient [35], which may be correlated with varying APP characteristics. The local patterns are presented in Figure 4.2a, Figure 4.2b and Figure 4.2c and defined as Local Pattern 1, Local Pattern 2 and Local Pattern 3 respectively. Â· Arrhythmia Organization Level: The organized and disorganized structures of an arrhyth97

mic episode is significant in aiding ICDs and clinicians to determine the short- and long-term therapy options. The features from a wavelet-based singular value decomposition [58, 116] were used to determine the organization level observed in an electrogram and was used to classify the electrogram as either VT or VF. Â· EAV Energy: In the previous chapter, the EAV aRMS energy was significant in identifying whether the electrogram was in the vicinity of a rotor event or not. The total amount of amplitude variations in the electrogram could be used to describe the generic EAV structure (represented by the approximated component). Therefore, the total energy captured by the EAV structure (as a ratio to the original electrogram energy) was used. Â· Residual Instantaneous Frequency Standard Deviation: Also in the previous chapter, the deviation in the IF from the residual component was important in identifying electrograms with a phase singularity. The IF standard deviation (STD) describes the underlying deviations in the IF of the residual component after the EAV-based MP decomposition. The aforementioned features were extracted for each electrogram and were used in conjunction with the APP characteristics for the electrode location. This makes it possible to determine if a specific set of signal structures (via features) may be associated with an APP characteristic. To achieve this association, the features that were extracted for the electrograms can be tested against the APP characteristics for the same electrograms. The testing in this case is a combination of the ANOVA significance test and the LDA-LOO classification. This helps identify which type of APP characteristics display an association with the signal features, and warrant further adaptive decomposition analysis. The previously established APP categories (normal/abnormal for the MAP, ARI, max voltage and DVDT as well as the cardiomyopathy type) from Table 4.1 were used to asses the feature significance and classification accuracy. In order to determine if the feature is significant for a particular APP characteristic, the p-value should be significant (P < 0.01) as well as have an overall LDA-LOO classification accuracy greater than 60%. While the probability threshold for a feature to be statistically significant has been previously established [73], the classification accuracy 98

threshold was selected conservatively to establish if a relation exists between the APP characteristic and the feature in classifying the database. This denotes that the signal features may be representative of a particular APP characteristic, and thus this threshold to determine the feature significance was used. Extracting the feature and APP characteristic from the available electrograms (maximum of 112) from each of the 11 episodes, the ANOVA significance test and the LDA-LOO classification were performed. The results presented in Table 4.2 are the ANOVA pvalue and the LDA-LOO classification accuracy for the features that were identified as significant for the APP characteristics across all 11 episodes. For instance, the first two rows are the local pattern 1 ANOVA p-value and the overall classification respectively for each APP category. Table 4.2: Feature P-Value and Classification versus APP Characteristic MAP < 0.01 51.50% < 0.01 58.00% ARI 0.02 50.69% < 0.01 56.78% Max Voltage < 0.01 57.92% < 0.01 53.53% DVDT < 0.01 73.51% < 0.01 76.03% Cardiomyopathy < 0.01 54.34% < 0.01 64.82%

Local Pattern 3 (P-Value) Local Pattern 3 (%) Arrhythmia Organization (P) Arrhythmia Organization (%)

The first significant association is the energy captured by local pattern 3 and arrhythmia organization with the DVDT category and the second significant association is the arrhythmia organization with the type of cardiomyopathy. The association between the arrhythmia organization and the type of cardiomyopathy is of special interest because it has been established that the characteristics and the management for each type of cardiomyopathy differ from one another [124]. Existing research has described ICM as having an area of fibrotic tissue caused by previous myocardial infraction [46]. Therefore, future VF episodes may be a result of interaction between the healthy tissue and the scar fibrotic tissue [47]. When contrasting this to DCM hearts, there are many possible etiologies [46] that often require multiple simultaneous parameters [48] in order to provide risk stratification. It will be worthwhile to observe the signal features and their association to the individual cardiomyopathy cases. In order to accomplish this, the RDB was separated based on the type of cardiomyopathy for each heart. Once the database was segregated, the ANOVA p-value and clas99

sification for each feature was determined for the remaining APP characteristics for the DCM and ICM cases. Of the total 11 arrhythmic episodes, there were 5 arrhythmic episodes from DCM hearts and 6 arrhythmic episodes from ICM hearts. The results presented in Tables 4.3 and 4.4 are the ANOVA p-value and the LDA-LOO classification accuracy for the feature that was significant for a particular APP characteristic for DCM and ICM hearts, respectively. Table 4.3: Feature P-Value and Classification versus APP Characteristic for DCM Hearts MAP < 0.01 61.96% ARI < 0.01 62.68% Max Voltage 0.01 53.21% DVDT 0.26 68.57%

Residual IF STD (P) Residual IF STD (%)

Table 4.4: Feature P-Value and Classification versus APP Characteristic for ICM Hearts MAP < 0.01 60.66% < 0.01 56.48% < 0.01 57.08% < 0.01 62.59% ARI < 0.01 61.70% 0.50 49.48% 0.01 50.97% < 0.01 61.70% Max Voltage < 0.01 61.55% < 0.01 55.44% < 0.01 62.00% < 0.01 59.80% DVDT < 0.01 33.23% < 0.01 63.64% < 0.01 72.58% 0.05 72.28%

Local Pattern 1 (P) Local Pattern 1 (%) Local Pattern 2 (P) Local Pattern 2 (%) Local Pattern 3 (P) Local Pattern 3 (%) Arrhythmia Organization (P) Arrhythmia Organization (%)

From Table 4.3, the residual IF STD feature appears to provide the only significance, which is for distinguishing the MAP normal and abnormal categories and the ARI normal and abnormal for the DCM cases. In contrast, there appears to be multiple features (Table 4.4) that are significant in segregating the four different types of APP characteristic for the ICM cases. For instance, the MAP category for the ICM cases has a significance with the energy captured by Local Pattern 1 and the arrhythmia organization. The stark contrast in the signal features and their significance could be a result of the underlying the type of cardiomyopathy. These differences may also possibly explain the variations in the significance of the signal features observed from DCM to ICM hearts (Table 4.3 vs. Table 4.4).

100

Based on this difference observed between DCM and ICM hearts, it may be possible to create trained dictionaries for each of the APP categories that were significant for the analyzed signal features. The creation of a trained dictionary to help segregate the type of cardiomyopathy is important because of the known physiological differences between the two cardiomyopathies [124]. For the DCM cases, the MAP and ARI had a significance with the residual IF STD. Therefore, the DCM MAP and DCM ARI categories will be considered for dictionary learning. As previously stated, all the APP categories for the ICM cases were significant for a combination of signal features. Hence, the following list of APP characteristics will be used for dictionary learning. Â· Cardiomyopathy Â· DCM MAP Â· DCM ARI Â· ICM MAP Â· ICM ARI Â· ICM Max Voltage Â· ICM DVDT The above mentioned relation identifies that it is possible to associate time-averaged characteristics of the electrogram with the APP characteristics. However, the exact signal structure that is representative of a particular APP characteristic may not be directly associated with the feature, but only a partial representation of the underlying structure. Therefore, the objective of using dictionary learning is two fold: the first is the identification of discriminative signal structures motivated by the APP characteristics, and the second is using the trained dictionary to label electrograms in order to be able to infer the APP characteristic.

101

4.4

LCKSVD Dictionary Learning

The LCKSVD method outlined in Section 2.2.3 described an objective function used to create a trained dictionary. The objective function from Equation 2.19 (provided below as Equation 4.1) consisted of three main components that influence the dictionary learning process. To recap, the first component was to select atoms that better approximates the training signals; the second component was to select atoms that sparsely represent the training signals; and the third component was to select atoms to represent the class labels assigned to the training signals. The influence of the sparse component and the class-label component on the objective function can be controlled through the use of the  and  parameters, respectively. The process by which to select the parameters to arrive at a trained dictionary will be discussed next.

< [b], [T M ], [W ],  > = arg

[b],[T M ],[W ],

min

||[f ] -  [b]||2 2

2 + ||[Q] - [T M ][b]||2 2 +  ||[CL] - [W ][b]||2

(4.1)

4.4.1 LCKSVD Dictionary Learning Process
There are many parameters that can be varied for the LCKSVD dictionary learning. These parameters determine how the objective function will perform the dictionary training. The selection of the dictionary learning parameters, such as the ,  , number of training iterations, and identification of the significant trained dictionary elements will be discussed in a LCKSVD dictionary learning process that consists of 7 steps. Figure 4.3 illustrates the process that was applied for the four identified APP characteristics in order to arrive at a uniquely trained dictionary. This flowchart will be referred to for the subsequent results. Process 1: Electrogram Labeling Based on APP The objective of the LCKSVD dictionary learning is to arrive at trained dictionary elements that are driven by the APP characteristics. Therefore, the first step in the process is to segregate the database based on the APP category that is being analyzed. For instance, when considering the LCCKSVD for the cardiomyopathy, the electrograms from the database were labeled as DCM or 102

><^s Z > WZ

WZ  Z >  Z WW 

WZ  ><^s Z sZ  ZZ Z   

WZ  K ^Z Z   

K    ><^s W

WZ  ><^s Z sZ  s /Z

WZ  K ^Z Z /Z

K /Z ><^s W

WZ  ^Z Z ^ d Z 

WZ  & d Z

& ><^s d Z   WW 

Figure 4.3: LCKSVD Process to Arrive at a Trained Dictionary

103

ICM depending on which type of heart the electrogram originated from. This labeling served as the ground truth that was then used to create the trained dictionary. Process 2: LCKSVD Cross-Validation with all Combinations of  and  The ability to choose any combination of the  and  values provide a great deal of flexibility in training a dictionary such that the atoms are selected based on one or multiple components. In order to create a trained dictionary for which the objective is to segregate a particular APP category, it may be straightforward to think that the  value should selected to provided the largest component so that more emphasis on the class-label component for the LCKSVD objective function. However, it is also important that the trained dictionary represents the underlying signal structure and sparsely represent the electrogram. Therefore, various combinations of the  and  values must be analyzed, with the overall classification as the determining factor for finalizing the value of  and  . In order to provide a robust analysis of the LCKSVD objective function, a wide range for the  and  value must be considered. In the LCKSVD objective function from Equation 4.1, the approximation component always has a weight of 1 to the objective function. For instance, if  is much larger than 1 and  is equal to 1, then a greater emphasis will be placed on selecting atoms that can sparsely represent the training signals. If both  and  are equal and much larger than 1, then there is more emphasis on the sparsity and label components of the objective function. Also, if the  and  values are equal and much smaller than 1, more emphasis is placed on the approximation component of the LCKSVD objective function. Therefore, in order to create a robust range of the  and  values, the values must range from much greater than one to much smaller than one. For selecting a value much larger than 1, 1000 was selected, since it will allow the LCKSVD to place a much larger emphasis on the sparse or class-label components of its criterion function. Similarly, the minimum  and  values were selected as emphasis on the approximation component. The values in between 1000 and
1 1000 1 1000

to place more were selected

based on a log scale to have a dynamic range for the  and  values. Based on this, the following range for  and  was selected. For the given range of  and  values, there are 121 combinations

104

(11 Ã 11) of LCKSVD objective functions that will be analyzed in order to train the dictionaries.
1 1 , 5, Â· : 1000, 100, 10, 5, 2, 1, 2 1 1 Â·  : 1000, 100, 10, 5, 2, 1, 2 , 5, 1 , 1 , 1 10 100 1000 1 , 1 , 1 10 100 1000

The starting point for all the dictionaries will be the Gabor dictionary that is frequency and scale limited. The limitation on the starting Gabor dictionary is required by LCKSVD because the number of atoms in the dictionary has an upper bound [71]. The upper bound is determined based on the group with a smaller number of training signals. The number of atoms in the dictionary cannot exceed half the number of training signals available. The number of iterations used by the LCKSVD was set to 50 to test all the  and  combinations. Based on this initial dictionary, the training of the LCKSVD with the different  and  combinations could be completed. Process 3: Optimal  and  Selection In order to create a robustly trained dictionary, the dictionary will be cross-validated to ensure its ability to capture signal structures that exist within the electrogram. It is possible to crossvalidate the trained dictionary by training the dictionary with a set of electrograms and then testing it against another set of electrograms. However, care should be taken in selecting the training and testing database. Each arrhythmia episode is unique, even if they originate from the same heart. Therefore, in order to create the most robustly trained dictionary, the LCKSVD was trained with all arrhythmia episodes except one. The remaining episode can then be tested to determine if the trained dictionary atoms can sparsely represent the electrograms in the episode and still correctly determine its class labels. This method was repeated with each episode being left out of the training and then used to test the trained dictionary. For instance, there are 11 episodes that are available for the purpose of studying the electrogram signal structure in order to determine the type of cardiomyopathy. The dictionary is trained with 10 episodes and then tested with the last remaining episode. This process is repeated for a total of 11 times, with each episode being the testing episode once. It is possible to obtain the accuracy of a given training episode based on the trained dictionary. To accomplish this, the trained dictionary  is used to decompose the testing signals by the OMP. 105

The resulting sparse coefficients () with the classifier parameters [W ] from the LCKSVD can be used to classify the electrograms with respect to the labels. The approximated label is determined from the product of the sparse coefficients  and the classifier parameters [W ] to produce the sparse code product (defined as [W ] ). Recall that the sparse codes  are the coefficients as a result of the OMP decomposition (refer to Section 2.2.2) and the classifier parameters [W ] are the LCKSVD dictionary weights that were trained for each class. The classifier parameter [W ] has multiple entries, for which each of the entries will determine the strength of the respective label (i.e. first set of classifier parameters multiplied with the sparse codes will determine the label value for category 1) to a specific dictionary element. After this product, the category with the maximum value is assigned as the label. Once the labels are approximated for all the electrograms, the labels that are correctly approximated when compared to the ground truth can be used to define the accuracy of the trained dictionary. The accuracy for a given  and  is the averaged accuracy obtained from each of the crossvalidated accuracy. The cross-validation of the episodes were done for all combinations of  and  . The averaged accuracy was used to determine which  and  should be selected for the final trained dictionary. The  and  value that produced the best average accuracy of the testing episodes was used for the optimal values. Process 4: LCKSVD Cross-Validation with Varying Iterations Another flexibility given to the LCKSVD objective function is the number of iterations used to train the dictionary. As previously discussed in Section 2.2.3, the objective function iteratively updates the atoms in the dictionary and the coefficients. For instance, suppose that the  and  values were much smaller than one, thereby placing more emphasis on the approximation component of the LCKSVD objective function. If the LCKSVD is trained for a greater number of iterations, it is expected that the error between training signals and dictionary elements (trained atoms) will be smaller as the iterations increase. While this is preferable for fully approximating the training signals, the objective of identifying significant underlying signal structures may not require full approximation to capture all the subtle discriminative signal structures in the electrograms. There-

106

fore, a range of iterations for the LCKSVD will also have to be tested to determine the optimal number of iterations that can be used to classify the specific APP characteristic. The iterations were varied between 25, 50, 100, 250 and 1000 for this process. Process 5: Optimal Iteration Selection Given that the  and  values were selected in the third process, the iterations were varied to perform the LCKSVD training for this  and  value. The LCKSVD was performed for each of the iterations and for each of the testing episode individually. Similar to Process 3, the optimal number of iterations was selected based on the maximum average accuracy obtained from the accuracies for each cross-validated episode. Process 6: Selection of Significant Trained Dictionary Elements Using cross-validation of the database, the LCKSVD will produce an individual trained dictionary for each of the arrhythmia episode that was tested. For instance, if there were 11 episodes, then there will be 11 trained dictionaries that will be produced. However, rather than selecting all of the dictionary elements from each of these trained dictionaries, only the most significant elements from each trained dictionary were selected. In order to determine which element were to be selected, the sparse coefficients from the OMP for all the training signals per trained dictionary were considered. Since the dictionary was created based on the training signals, the training signals and not the testing signals were used to select the most significant elements. Simply, the sparse code  produced for each trained dictionary was averaged across all the training signals for a given category and then multiplied by the classifier parameters [W ] for that category to produce a weighted average sparse code ( Â¯[W ] ). Ideally, if a training signal was exactly the same as an element, then the sparse code for that element of the dictionary would be 1. If all the training signals of a particular category also share this element, then the weight assigned to this element would be relatively greater (normalized to a maximum of one). Therefore, a threshold can be set on the weighted average sparse code. The threshold was selected as 1% of the maximum possible product because if the weighted average sparse code is below 1%, then the contribution by this element may be attributed to noise and 107

not a relevant electrogram signal structure for the APP characteristic. Any elements that satisfy having a product greater than this 1% threshold were then compared with the average sparse code product for the other category. The dictionary element is only considered as significant for the first category when it is above the 1% threshold, and the difference between the products for each category is also greater than 1%. The second condition is set to ensure that the signal structure is more discriminative for a particular category and it is not a signal structure that may be common to both categories of training signals. This process is repeated for the second category. The significant dictionary elements along with the corresponding classifier parameters are retained per cross-validated episode. Process 7: Final Trained Dictionary Given that there is a trained dictionary for each episode, the significant dictionary elements from each of the trained dictionaries were combined o arrive at the final trained dictionary (F inal ). The classifier parameter [W ] for each of the significant dictionary elements was also retained. Therefore, the final trained dictionary (denoted as F inal ) and the final classifier parameter (denoted as [W ]F inal ) are used for the final LCKSVD trained dictionary.

4.4.2 LCKSVD Results
The signal features that were previously discussed in this chapter helped to motivate the dictionary learning for specific APP characteristics. The results were presented based on these specific APP characteristics. The complexity of the dictionary learning was O(N 3 ) [66], but this is a one time occurrence. Therefore, the complexity for the process that uses the trained dictionary relies on the OMP complexity, which is O(N 2.5 ) [66]. This makes the method useful in offline analysis of patient's suffering from VA, with a possibility of near real-time analysis due to the advent of more powerful digital signal processors. Cardiomyopathy In order to create a dictionary that is trained specifically to determine the type of cardiomyopathy the electrogram belongs to, the complete RDB was segregated to hearts that were DCM and hearts 108

that were ICM. Thus, all the electrograms from a given heart (even if there were multiple episodes from the same heart) were labeled as either DCM or ICM. There were a total of 11 arrhythmia episodes, of which, 5 arrhythmic episodes were from DCM hearts and 6 arrhythmic episodes were from ICM hearts. Therefore, all the electrograms recorded from a single episode were either labeled as belonging to the DCM or ICM category. This refers to the first process in Section 4.4.1 and Figure 4.3 for the cardiomyopathy LCKSVD training. The second and third process in the LCKSVD training of the dictionary (Section 4.4.1 and Figure 4.3) was testing and selecting the optimal  and  combination for the database that was previously labeled based on the type of cardiomyopathy. The LCKSVD training was first performed on 10 episodes and tested with the 11th episode. For each of the cross-validation set, the dictionary was trained with a single  and  combination and the accuracy for the testing episode was determined. This testing process was repeated for all of the  and  combinations. This was again repeated for each of the episodes being a testing episode, and the accuracies were a matrix with 11 Ã 121 entries. Finally, the accuracies were averaged over all of the episodes, and the optimal  and  value was selected. Figure 4.4 illustrates the average accuracies from the cross-validated episodes for a fixed iteration of 50. From the illustration in Figure 4.4, the X axis has the 11 possible  values and the Y axis has the 11 possible  values. In total, there are 121 possible combinations presented in this figure. The colours represent the accuracies ranging from 40% to 75%. The maximum average accuracy was obtained for an  and  combination of 2 and 5 respectively. Next, the  and  were fixed and the number of iterations used by LCKSVD were varied to arrive at an optimal number of training iterations, which corresponds to the fourth and fifth process in the LCKSVD dictionary learning (Section 4.4.1 and Figure 4.3). The iterations used were 25, 50, 100, 250 and 1000 to determine which iteration was the most optimal for the LCKSVD training. Similar to the  and  tests, the accuracy for each episode was obtained for a given training iteration. Once the accuracies for each episode and iteration was obtained, a matrix with 11 Ã 5 entries corresponding to the accuracies was used to obtain an average accuracy for the iterations. Figure 4.5 illustrates the average accuracies for the cross-validated episodes for a fixed  and  value of 2 and 5, respectively. From the results in Figure 4.5, the maximum average accuracy was

109

Average Accuracy for Different Alpha and Beta Values
75

1/1000 1/100 1/10
65 70

1/5

Beta Parameters

1/2 1 2 5

60

55

50

10 100 1000 1000 100 10 5 2 1 1/2 1/5 1/10 1/100 1/1000
40 45

Alpha Parameters

Figure 4.4: Average Accuracies for different  and  for the Cardiomyopathy LCKSVD

110

Cardiomyopathy LCKSVD Dictionary Learning with Varying Iterations and Fixed Alpha (2) and Beta (5)
75

70

65

Classification Accuracy (%)

60

55

50

45

40

25

50

100

250

1000

Iterations

Figure 4.5: Average Accuracies for Different Iterations for the Cardiomyopathy LCKSVD obtained with an iteration of 50. Therefore, the LCKSVD training parameters were set as  being 2,  being 5, and the number of iterations for training being 50 (listed in Table 4.5). Table 4.5: Cardiomyopathy LCKSVD Dictionary Learning Parameter Values  Value 2  Value 5 Iterations 50

Parameter Value

Based on the above LCKSVD parameters, the maximum average cross-validated result was 53.11%. However, this accuracy was achieved using the individually trained dictionary elements for each cross-validated episode. The next step was to create a single, trained dictionary from a combination of the individually trained dictionaries, corresponding to the sixth and seventh process 111

Average Weighted Sparse Code For DCM vs ICM

10 9 8 7
DCM ICM

Percentage (%)

6 5 4 3 2 1 0 0 10 20 30 40 50 Trained Dictionary Elements 60 70 80

The red and green colors show the weighted average sparse codes that were generated by LCKSVD and OMP for the DCM and ICM training signals, respectively.

Figure 4.6: Sample Weighted Average Sparse Code for DCM vs ICM of the LCKSVD training dictionary (Section 4.4.1 and Figure 4.3). For a given cross-validation episode, the sparse code CM was obtained by decomposing the training signals with the trained dictionary elements. The sparse codes DCM belonging to the electrograms from the DCM category were averaged and multiplied by the classifier parameters [W ]DCM that belonged to the DCM category. A similar process was done for the electrograms from the ICM category. From Figure 4.6, it is possible to observe the weighted-average sparse codes for the DCM and ICM categories for one of the test episodes. The red and green bars in Figure 4.6 are the weighted-average sparse codes for the DCM and ICM categories, respectively, for each of the trained dictionary elements (80 dictionary elements for Figure 4.6). This weighted-average sparse code is an example produced from one of the crossvalidated episode. From this figure, we can observe several elements that are significant for the DCM and ICM categories. First, there are some elements from the trained dictionary that have a

112

higher weighted average sparse code for DCM (red bar) than the ICM (green bar). For instance, dictionary element 11 is an example of a significant component for the DCM category, since the red bar (value around 6%) is larger than the ICM category's green bar (value around 0%). Similarly, some of the elements from the trained dictionary have a higher weighted average sparse code for ICM (green bar) than the DCM (red bar). An example of this is observed in element 45, where the weighted average sparse code higher for the ICM category (value around 5%) than the DCM category (value of 0%). For a dictionary element that contributes to both categories (e.g. element 23), the element will belong to the category for which it has a larger weighted average sparse code. Based on this distribution, significant elements for the DCM and ICM category for this given cross-validated episode were selected from the trained dictionary. This process was then repeated to select significant elements from each of the remaining trained dictionaries. The final trained dictionary (denoted as F inal,CM ) is a combination of all the significant elements for the cardiomyopathy LCKSVD cross-validation. In order to better understand the differences in the signal structure between the DCM and ICM hearts as a result of the trained dictionary elements, a scale-frequency map was constructed. To create a scale-frequency map, the standard parameters of the atom (e.g. scale, frequency, etc.) must be known. However, LCKSVD trains a standard dictionary with known parameters for each atom into elements that may not have standard parameters, such as a fixed frequency or scale. Therefore, to create such a scale-frequency map, each element was decomposed using a standard Gabor dictionary with known parameters. The resulting coefficients, scales, and frequencies were then used to represent the structure for each element. This was used to create the scale-frequency maps for the elements belonging to the DCM hearts and similarly for all the coefficients belonging to the ICM hearts. Figure 4.7 consists of three panels of scale-frequency maps. The top panel is the resulting scale-frequency map for elements from the DCM hearts and the middle panel is the scale-frequency map for elements from the ICM hearts. The bottom panel, which illustrates the difference between the two scale-frequency map, highlights the differences between the two. The most notable differences occur around 2.5 to 3.5 Hz and for the scale of 2048. Another notable difference occurs around 4 to 4.5 Hz for the scale of 2048. This indicates that subtle frequency

113

components that spans a large part of the electrograms, due to the scale size, may be important in segregating DCM and ICM electrograms. With the finalized dictionary (F inal,CM ), each episode was decomposed using OMP, and then labeled. From the OMP decomposition using F inal,CM , their resulting sparse codes F inal,CM along with the finalized classifier parameters [W ]F inal,CM were used to label each electrogram as DCM or ICM. Given that each episode was either DCM or ICM, all electrograms belonging to that episode were either DCM or ICM. The accuracy can be determined based on whether the electrogram was correctly labeled. Table 4.6 provides classification accuracies for each of the episode as well an overall classification accuracy. The average accuracy highlights that 81.80% (standard deviation of 7.89%) of the electrograms could be correctly classified based on only the sparse code and the classifier parameters. Looking more closely into the cardiomyopathy categories, we can make additional observations. For example, the accuracies for the DCM cases seem to have less variation (ranging from 74% to 90%) than the ICM cases (ranging from 68% to 89%), which is surprising considering that DCM was expected to have more variations. This may indicate that the trained elements were more discriminative for the DCM electrograms than the ICM electrograms, or that the signal structures within the ICM cases differ from one another, making it more difficult for the final trained dictionary to focus on a particular electrogram signal structure. The variation in the cross-validated accuracies also seems to vary from the feature analysis in Tables 4.3 and 4.4. The expectation was that the DCM hearts would have many possible etiologies [46], in turn exhibiting a wide range of electrogram signal structures. This was observed from the P-values and classification accuracies for the DCM cases from Table 4.3, where most of the signal features did not show any significance for the APP characteristics. It is possible that the signal structure identified by the scale-frequency map for the DCM cases were similar from heart to heart, whereas that may not have been the case for the ICM hearts. Another possibility for the large variation in the ICM hearts could have been that the underlying APP characteristics, such as the approximate of the MAP, ARI, scar tissue and DVDT, could have been wide ranging. The LCKSVD was trained to look for common signal structures across all of the ICM hearts, which would make it more difficult. The  and  values (5 and 2, respectively) also placed more emphasis

114

DCM - Scale-Frequency-Amplitude Map 128 256 512 1024 2048 0 2 6 8 10 Frequency (Hz) ICM - Scale-Frequency-Amplitude Map 4 12

Scales

0.2 0.1 0

128 256 512 1024 2048 0 2 6 8 10 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 12

Scales

0.2 0.1 0

128 256 512 1024 2048 0 2 4 6 Frequency (Hz) 8 10 12

Scales

0.2 0.1 0

The scale-frequency map was created for the trained dictionary elements for the DCM (top panel) and ICM (middle panel) training signals. The bottom panel illustrates the difference in the scale-frequency maps.

Figure 4.7: Scale-Frequency Map for DCM versus ICM

115

Table 4.6: Classification of Cardiomyopathy Hearts Using the Finalized LCKSVD Trained Dictionary Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode 6 Episode 7 Episode 8 Episode 9 Episode 10 Episode 11 Episode Average Episode Standard Deviation Accuracy (%) 73.21 89.29 84.82 74.11 90.18 87.50 89.29 68.75 84.82 84.82 72.97 81.80 7.89 Cardiomyopathy ICM DCM DCM DCM DCM DCM ICM ICM ICM ICM ICM N/A N/A

on creating more sparse elements, thus possibly making it more difficult if the ICM electrograms if it does not have a common signal structure. DCM MAP Another APP characteristic that was identified as significant was the normal and abnormal MAP in the DCM cases. The APD (related to the MAP duration) was shown to be an important characteristic in optimizing therapy options [15, 16]. While the ICM MAP cases also showed significance based on the signal features, the signal features themselves were different from one another. The DCM MAP had only the residual IF STD signal feature, as significant from Table 4.3. Contrasting this with the ICM MAP cases, the residual IF STD signal feature was not significant. Therefore, the dictionary learning was applied to the DCM MAP cases and ICM MAP cases individually. As previously mentioned in the LCKSVD training process (Section 4.4.1 and Figure 4.3), the first process was identifying the DCM episodes and label the DCM electrograms based on the approximate of the MAP characteristic as either normal (DCM M N) or abnormal (DCM M A). There were 5 DCM arrhythmia episodes for the RDB. The LCKSVD training was conducted on 4 of the

116

episodes and tested with the 5th episode (similar to the LCKSVD for cardiomyopathy). Following the second to fifth processes that were the outlined, the LCKSVD training parameters were set as 5 for , 100 for  , and 50 for the number of iterations for training (also given in Table 4.7). A maximum average cross-validated result of 64.64% was achieved with these parameters. The sixth and seventh process for the LCKSVD dictionary learning involves combining the significant elements from each of the trained dictionary to arrive at a final trained dictionary (denoted as F inal,DCM M ). This was accomplished with the averaged sparse code for the training signals  Â¯DCM M as well as the classifier parameters [W ]DCM M . Table 4.7: DCM MAP LCKSVD Dictionary Learning Parameter Values  Value 5  Value 100 Iterations 50

Parameter Value

To visualize the signal structures captured by the finalized trained dictionaries, the scalefrequency maps were constructed for the normal DCM MAP elements and the abnormal DCM MAP elements. The Gabor dictionary with known atom parameters was used to decompose the elements. The three panels of Figure 4.8 are the resulting scale-frequency maps for elements from the normal DCM MAP electrograms (top panel), abnormal DCM MAP electrograms (middle panel), and difference between the two scale-frequency maps (bottom panel). There exists multiple scale-frequency structures that are different for the normal DCM MAP and abnormal DCM MAP scale-frequency maps. The scale of 512 between 1 to 1.5 Hz is an example of a scale-frequency structure that exists in the abnormal DCM MAP cases when compared to the normal DCM MAP cases. The other observable difference is at scale 2048 between 2.5 to 3.5 Hz as well as between 4.5 to 5.5 Hz. For this scale-frequency structure, it is possible to observe that this scale-frequency structure exists in the normal DCM MAP and is not as significant in the abnormal DCM MAP. The finalized dictionary (F inal,DCM M ) was then used to decompose and label the electrograms. The finalized sparse codes F inal,DCM M and the finalized classifier parameters [W ]F inal,DCM M were used to label the electrogram as normal or abnormal DCM MAP. The accuracy was then determined by comparing the predicted label against the actual label for the electrogram. Table

117

DCM MAP Normal - Scale-Frequency-Amplitude Map 128
Scales

256 512 1024 2048 0 6 8 10 Frequency (Hz) DCM MAP Abnormal - Scale-Frequency-Amplitude Map 2 4 12

0.2 0.15 0.1 0.05 0

128
Scales

256 512 1024 2048 0 2 6 8 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 10 12

0.2 0.15 0.1 0.05 0

128
Scales

256 512 1024 2048 0 2 4 6 Frequency (Hz) 8 10 12

0.2 0.15 0.1 0.05 0

The scale-frequency map was created for the trained dictionary elements for the normal (top panel) and abnormal (middle panel) DCM MAP training signals. The bottom panel illustrates the difference in the scale-frequency maps.

Figure 4.8: Scale-Frequency Map for Normal versus Abnormal DCM MAP

118

4.8 provides the classification accuracies for each of the episode as well an overall classification accuracy. The average accuracy over all of the episodes was 71.43%, with a standard deviation of 11.85%. This accuracy illustrates that the finalized trained dictionary elements may be able to capture all of the variations between the DCM MAP normal and abnormal electrograms. The variations between the episodes indicate that signal structures may not necessarily be consistent from episode to episode. Table 4.8: Classification of Normal and Abnormal DCM MAP Using the Finalized LCKSVD Trained Dictionary DCM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode Average Episode Standard Deviation Accuracy (%) 63.61 69.64 58.03 85.71 82.14 71.43 11.85

Based on the initial signal feature analysis from Table 4.3, only the residual IF STD signal feature was significant for highlighting the DCM MAP. This illustrates that the DCM electrogram signal structure may be more complex when compared to the ICM electrograms (which had many significant signal features). The  and  values (5 and 100, respectively) place a much larger emphasis on the classification error component of the LCKSVD objective function. The electrogram signal structures that are meant to segregate the assigned labels is targeted by the LCKSVD, which further indicates the complexity of the DCM MAP electrograms. The structures that were identified by the dictionary elements placed more emphasis on discrimination, which could possibly explain the distribution of the accuracies (since emphasis was not placed on sparsity or representation). The results indicate that it may be possible to infer the DCM MAP based on the trained dictionary.

119

DCM ARI The ARI for the DCM cases were also observed to have a significant correlation with the timeaveraged characteristics, specifically with the residual IF STD. Therefore, the ARI cases will also be analyzed by LCKSVD. The ARI was also another characteristic that could be used to optimize existing therapy options [15, 16]. The LCKSVD training process (Section 4.4.1 and Figure 4.3) was used to create a trained dictionary for DCM ARI. The electrograms of the DCM episodes were labeled as normal (DCM A N) or abnormal (DCM A A) depending on the ARI value. Since there were DCM arrhythmia episodes in the RDB, there were 5 LCKSVD dictionaries that were created. From the second to fifth processes, the LCKSVD training parameters were selected as 100 for , 1000 for  , and 50 for the number of iterations for training (Table 4.9). The maximum average cross-validated result obtained with this set of LCKSVD parameters was 62.86%. The sixth and seventh processes were used to combine significant elements from each of the trained dictionaries. The average sparse code for the training signals  Â¯DCM A and the classifier parameters [W ]DCM A were used to create the final dictionary (denoted as F inal,DCM M ). Table 4.9: DCM ARI LCKSVD Dictionary Learning Parameter Values  Value 100  Value 1000 Iterations 50

Parameter Value

The scale-frequency map was constructed for the normal and abnormal DCM ARI elements in order to visualize the signal structures captured by this final dictionary. The three panels of Figure 4.9 are the scale-frequency maps for elements from the normal DCM ARI electrograms (top panel), elements from the abnormal DCM ARI electrograms (middle panel), and difference between the two scale-frequency maps (bottom panel). The scale-frequency maps reveal that the scale-frequency structures at the 2048 scale between 3 and 3.5 Hz as well as 4.5 and 5.5 Hz have the largest difference. In particular, the abnormal ARI for DCM cases have stronger time-varying frequency structures (above discussed scale-frequency ranges) that does not exist in the normal DCM ARI cases. The finalized dictionary (F inal,DCM A ) was then used to decompose and label the electrograms. 120

DCM ARI Normal - Scale-Frequency-Amplitude Map 128
Scales

256 512 1024 2048 0 2 6 8 10 Frequency (Hz) DCM ARI Abnormal - Scale-Frequency-Amplitude Map 4 12

0.2 0.15 0.1 0.05 0

128
Scales

256 512 1024 2048 0 2 6 8 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 10 12

0.2 0.15 0.1 0.05 0

128
Scales

256 512 1024 2048 0 2 4 6 Frequency (Hz) 8 10 12

0.2 0.15 0.1 0.05 0

The scale-frequency map was created for the trained dictionary elements for the normal (top panel) and abnormal (middle panel) DCM ARI training signals. The bottom panel illustrates the difference in the scalefrequency maps.

Figure 4.9: Scale-Frequency Map for Normal versus Abnormal DCM ARI

121

The accuracy was determined label for each electrogram was compared with the predicted label, which was produced using the finalized sparse codes F inal,DCM A and the finalized classifier parameters [W ]F inal,DCM A . Table 4.10 provides the classification accuracies for each of the episode as well an overall average classification accuracy. The overall average accuracy of 75.18% (standard deviation of 13.40%) is an indication that the finalized trained dictionary is able to identify structures that can be used to indicate normal from abnormal DCM ARI. Table 4.10: Classification of Normal and Abnormal DCM ARI Using the Finalized LCKSVD Trained Dictionary DCM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode Average Episode Standard Deviation Accuracy (%) 53.57 71.43 81.25 87.50 82.14 75.18 13.40

This ARI for DCM cases was also correlated with the residual IF STD. The combination of the  and  values (100 and 1000, respectively) used shows that an increased emphasis was placed on identifying structures that were better suited for labeling the electrogram. The variation in the accuracies was similar to what was observed in the MAP analysis, which further supports the complexity that was observed in literature for DCM hearts. Based on this analysis, the DCM ARI could be inferred by the LCKSVD trained dictionaries. ICM MAP The ICM MAP characteristic was a significant APP characteristic that was supported by two signal features. From the results provided in Table 4.4, these signal features were the local pattern 1 and arrhythmia organization. The first process in the LCKSVD dictionary learning (Section 4.4.1 and Figure 4.3) was labeling the electrograms. There were 6 ICM arrhythmia episodes from the RDB. Similar to the DCM MAP LCKSVD, the ICM electrograms were labeled as normal (ICM MAP N) or abnormal (ICM MAP A) depending on the approximate of the MAP value for the 122

electrode. The second to fifth processes were used to determine the optimal LCKSVD dictionary learning parameters. The LCKSVD training parameters was 1 for , 100 for  , and 50 for the number of iterations for training (listed in Table 4.11). The maximum average cross-validated result that was obtained for the given LCKSVD parameters was 58.06%. Next, the individually trained dictionaries were used to create a single trained dictionary through the used of the sparse codes ICM M and the classifier parameters [W ]ICM M (outlined by the sixth and seventh processes for the LCKSVD dictionary learning). After the significant dictionary elements were identified for each of the trained dictionaries, the elements were combined to create a final trained dictionary (F inal,ICM M ). Table 4.11: ICM MAP LCKSVD Dictionary Learning Parameter Values  Value 1  Value 100 Iterations 50

Parameter Value

The scale-frequency maps for the normal and abnormal ICM MAP were also generated by decomposing the trained dictionary elements for each group with a Gabor dictionary with fixed parameters. Figure 4.10 illustrates the scale-frequency map for the elements from the normal ICM MAP electrograms (top panel), the elements from the abnormal ICM MAP electrograms (middle panel) and difference between the two scale-frequency maps (bottom panel). The largest difference is observed at scale 2048 between 4.5 and 5 Hz. The abnormal ICM MAP electrograms appears to have more emphasis placed on this scale-frequency structure than the normal ICM MAP. From the finalized dictionary (F inal,ICM M ), the sparse codes for the signals were determined. The finalized classifier parameters [W ]F inal,ICM M were used with the sparse codes F inal,ICM M to label each electrogram as normal or abnormal. By comparing the predicted labels to the actual labels, the accuracy could be determined. Table 4.12 contains the classification accuracies for all 6 episodes as well as the average accuracy. The average accuracy over the episodes was 70.49%. The standard deviation for the episodes was 2.26%. The classification accuracy highlights that the ICM MAP trained dictionaries can be used for identifying signal structures to segregate the normal and abnormal ICM MAP electrograms. When considering the variation of the results, the

123

ICM MAP Normal - Scale-Frequency-Amplitude Map 128
Scales

256 512 1024 2048 0 2 6 8 10 Frequency (Hz) ICM MAP Abnormal - Scale-Frequency-Amplitude Map 4 12

0.2 0.1 0

128
Scales

256 512 1024 2048 0 2 6 8 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 10 12

0.2 0.1 0

128
Scales

256 512 1024 2048 0 2 4 6 Frequency (Hz) 8 10 12

0.2 0.1 0

The scale-frequency map was created for the trained dictionary elements for the normal (top panel) and abnormal (middle panel) ICM MAP training signals. The bottom panel illustrates the difference in the scalefrequency maps.

Figure 4.10: Scale-Frequency Map for Normal versus Abnormal ICM MAP

124

ICM cases had a smaller degree of variation in the classification accuracy. This may indicate that the ICM arrhythmia episodes have a lower degree of signal structure variation (identified by the trained dictionaries) from episode to episode. Table 4.12: Classification of Normal and Abnormal ICM MAP Using the Finalized LCKSVD Trained Dictionary ICM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode 6 Episode Average Episode Standard Deviation Accuracy (%) 73.21 69.64 73.21 67.86 68.75 70.27 70.49 2.26

There were multiple signal features that displayed significance for the ICM MAP from Table 4.4. These signal features were the energy capture from local pattern 1 and the arrhythmia organization. The  and  value (1 and 100, respectively) places an increased emphasis on the classification error component of the dictionary learning process. Therefore, the dictionary elements were trained to be able to better discriminate between the normal and abnormal ICM MAP electrograms. These results are indicative that the trained dictionary elements could be used to infer the ICM MAP. ICM ARI The ICM ARI characteristic was also a significant APP characteristic that was correlated with two signal features (energy captured by local pattern 1 and arrhythmia organization from Table 4.4). The significant correlation with the local pattern and arrhythmia organization may indicate that there a specific time-frequency structures that influence the ARI in ICM cases. The LCKSVD dictionary learning processes (Section 4.4.1 and Figure 4.3) were used to create the finalized trained dictionary for the ICM ARI (F inal,ICM A ). Based on the first process, the 6 ICM arrhythmia episodes from the RDB were labeled as normal (ICM ARI N) or abnormal (ICM ARI 125

A) based on the ARI value or the electrode. The second to fifth processes had selected the optimal LCKSVD dictionary learning parameters, with  as 10,  as 0.5, and the number of iterations as 50 (given in Table 4.13). The maximum average cross-validated accuracy was 55.28% for the LCKSVD parameters. The sparse codes ICM A and the classifier parameters [W ]ICM A were used for each trained dictionary to identify the significant elements and crate the finalized trained dictionary (F inal,ICM A ). Table 4.13: ICM ARI LCKSVD Dictionary Learning Parameter Values  Value 10  Value 0.5 Iterations 50

Parameter Value

The finalized dictionary elements for the normal and abnormal ICM ARI were used to generate the scale-frequency maps in Figure 4.11. The top panel of this figure represents the scale-frequency map for the normal ICM ARI electrograms, the middle panel represents the scale-frequency map for the abnormal ICM ARI electrograms and the bottom panel is the difference between the two scale-frequency maps. The observable difference between the scale-frequency maps occurs at scales 512 and 2048 between 3.5 and 4 Hz. The ARI normal electrograms from the ICM cases has more representation of this scale-frequency structure than the abnormal ICM ARI electrograms. The sparse codes F inal,ICM A for the signals were determined using the finalized dictionary (F inal,ICM A ). Next, the label for each electrogram was determined by the finalized classifier parameters [W ]F inal,ICM A and the sparse codes F inal,ICM A . These predicted labels were compared to the actual labels so that the accuracy could be determined. The classification accuracies for the 6 episodes and the average accuracy is presented in Table 4.14. An average accuracy of 67.51% (with a standard deviation of 7.04%) was achieved. The strength of the classification accuracy indicates the trained dictionary elements identified discriminatory structures within the ICM ARI electrograms that could infer this APP characteristics. The distribution of the accuracies is consistent with the ICM MAP results. The ICM ARI cases had two time-averaged characteristics (energy captured by local pattern 1 and arrhythmia organization) from Table 4.4 that were significant. The classification accuracy was

126

ICM ARI Normal - Scale-Frequency-Amplitude Map
0.25

128
0.2

256
Scales

0.15

512
0.1

1024
0.05

2048 0 2 6 8 Frequency (Hz) ICM ARI Abnormal - Scale-Frequency-Amplitude Map 4 10 12
0

0.25

128
0.2

256
Scales

0.15

512
0.1

1024
0.05

2048 0 2 6 8 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 10 12
0

0.25

128
0.2

256
Scales

0.15

512
0.1

1024
0.05

2048 0 2 4 6 Frequency (Hz) 8 10 12
0

The scale-frequency map was created for the trained dictionary elements for the normal (top panel) and abnormal (middle panel) ICM ARI training signals. The bottom panel illustrates the difference in the scalefrequency maps.

Figure 4.11: Scale-Frequency Map for Normal versus Abnormal ICM ARI

127

Table 4.14: Classification of Normal and Abnormal ICM ARI Using the Finalized LCKSVD Trained Dictionary ICM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode 6 Episode Average Episode Standard Deviation Accuracy (%) 74.11 67.86 66.96 73.21 54.46 68.47 67.51 7.04

achieved using an  and  value of 10 and 0.5, respectively. This placed a greater emphasis on identifying structures that are sparse for each category. The strength of the classification accuracy indicates that it may be possible to infer the label of the ICM ARI electrograms using the finalized trained dictionary. ICM Max Voltage The ICM max voltage was another significant APP characteristic that will be analyzed by LCKSVD. Two of the signal features from Table 4.4 were significant (these signal features being the energy captured by local pattern 1 and local pattern 3). Furthermore, it is known that the area of scar and healthy tissue for ICM hearts is important for the initiation of future arrhythmia episodes [47], which makes it important to create trained dictionary elements to infer these regions. Following the seven processes for the LCKSVD dictionary learning (Section 4.4.1 and Figure 4.3), the first process was segregating the database. There were 6 ICM arrhythmia episodes originating from 3 hearts. Each electrogram from the episodes were labeled as healthy (ICM Vol H) or scar (ICM Vol S) depending on the max voltage value. The second to fifth processes were used to arrive at optimal LCKSVD dictionary learning parameters (provided in Table 4.15). The final ICM Vol LCKSVD parameters are 5 for , 0.2 for  and 50 for the number of training iterations. From the LCKSVD parameter testing, the maximum average accuracy was 65.58%. The final trained dictionary (denoted as F inal,ICM V ) was then obtained following the sixth and seventh processes 128

for the LCKSVD dictionary learning. Table 4.15: ICM Vol LCKSVD Dictionary Learning Parameter Values  Value 5  Value 0.2 Iterations 50

Parameter Value

After finalizing the dictionary elements for the ICM healthy and scar electrograms, the scalefrequency maps were generated. The final trained dictionary was decomposed with the Gabor dictionary to identify scale and frequencies of significance. The scale-frequency maps in Figure 4.12 represent the ICM healthy (top panel), ICM scar (middle panel) and the difference between the scale-frequency maps. The largest difference appeared to occur at scale 2048 and between 4 and 4.5 Hz and between 5 and 5.5 Hz. Considering that the scale is 2048, there is an underlying scale-frequency structure that can differentiate between the ICM healthy and scar electrograms. To obtain the accuracy from the finalized dictionary (F inal,ICM V ), the sparse codes for all the ICM electrograms were determined. Using the finalized sparse codes F inal,ICM V and the finalized classifier parameters [W ]F inal,ICM V , the labels for the electrograms were predicted. The accuracy was calculated based on whether the predicted label was correct or not. The classification accuracies for the 6 episodes are given in Table 4.16 along with the average accuracy. The average accuracy and standard deviation were 70.19% and 6.22%, respectively, for the ICM healthy versus scar electrograms. The variation for the ICM cases is similar to what was observed for the ICM MAP and the ICM ARI LCKSVD. These results still indicate that there is a possibility of predicting whether an electrogram comes from a healthy or scar region. When compared to the other LCKSVD analysis of the APP characteristics, the signal features were more local (local patterns) to the electrograms. The significant features were the energy captured by local pattern 1 and local pattern 3 (from Table 4.4). The signal structures captured by the LCKSVD analysis appeared to be more generic frequency structure, which is dissimilar from what was observed from the significant signal features. The ability to identify healthy and scar regions is important because the scar boundary region for ICM hearts are believed to cause future arrhythmic episodes [47]. The  and  value (5 and 0.2, respectively) focus the dictionary learning 129

ICM Healthy Tissue - Scale-Frequency-Amplitude Map 128 256 512 1024 2048 0 6 8 10 Frequency (Hz) ICM Scar Tissue - Scale-Frequency-Amplitude Map 2 4 12
Scales

0.2 0.1 0

128 256 512 1024 2048 0 2 6 8 10 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 12

Scales

0.2 0.1 0

128 256 512 1024 2048 0 2 4 6 8 Frequency (Hz) 10 12

Scales

0.2 0.1 0

The scale-frequency map was created for the trained dictionary elements for the healthy (top panel) and scar (middle panel) ICM training signals. The bottom panel illustrates the difference in the scale-frequency maps.

Figure 4.12: Scale-Frequency Map for ICM Healthy versus Scar Electrograms

130

Table 4.16: Classification of Healthy and Scar for ICM Episodes Using the Finalized LCKSVD Trained Dictionary ICM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode 6 Episode Average Episode Standard Deviation Accuracy (%) 66.96 78.57 72.32 60.71 74.11 68.47 70.19 6.22

on sparse atoms. Despite having a relatively higher sparsity factor, the dictionary elements were discriminative and had revealed that it is possible to infer the healthy and scar regions in an ICM heart. ICM DVDT The last of the APP characteristics that will be analyzed by LCKSVD is the ICM DVDT. There were two signal features that were significant for the ICM DVDT cases. These features were the energy captured by local pattern 2, and local pattern 3 (Table 4.4). The analysis of the DVDT had revealed that it is related to the contraction strength of the particular region around which it was recorded from [17], which is important in identifying regions where the depolarization is normal in order to better understanding of the heart's characteristics. The first step of the LCKSVD dictionary learning process (Section 4.4.1 and Figure 4.3) was identifying regions of normal and abnormal DVDT. From the 6 ICM episodes, the electrograms were either labeled as normal (ICM DVDT N) or abnormal (ICM DVDT A). The second to fifth steps of the process were used to obtain the LCKSVD dictionary learning parameters that provided the most optimal cross-validated accuracies. These values were  of 5,  of 0.2, and the number of training iterations of 50 (listed in Table 4.17). These LCKSVD parameters resulted in a cross-validation accuracy of 55.93%. The sixth and seventh steps of the process were used to produce a finalized trained dictionary (denoted as F inal,ICM DV DT ). 131

Table 4.17: ICM DVDT LCKSVD Dictionary Learning Parameter Values  Value 5  Value 0.2 Iterations 50

Parameter Value

The scale-frequency maps (normal ICM DVDT in the top panel, abnormal ICM DVDT in the middle panel and the difference between the scale-frequency maps in the bottom panel) were then generated for the normal and abnormal ICM DVDT and is illustrated in Figure 4.13. The scalefrequency structures that exhibited the largest difference were at scale 1024 between 2.5 to 3 Hz and 4.5 to 5 Hz as well at scale 2048 between 3.5 to 4 Hz. The normal ICM DVDT electrograms displayed a strong occurrence of this scale-frequency structure than the abnormal ICM DVDT electrograms. Next, the accuracy was created obtained by decomposing the signals using the finalized trained dictionary (F inal,ICM V ) and multiplying the resulting sparse codes F inal,ICM DV DT with the finalized classifier parameters [W ]F inal,ICM DV DT . This produced a predicted label for each electrogram that could be compared with the actual label for each electrogram to produce an accuracy. Table 4.18 lists the accuracies for each episode as well as the average accuracy for the ICM episodes. The average accuracy across all the ICM episodes (73.77% with a standard deviation of 16.52%) is an indication of the strength of the trained dictionary elements. The variation in the accuracies is also larger when compared to the other ICM APP categories. Table 4.18: Classification of normal and abnormal DVDT for ICM Episodes Using the Finalized LCKSVD Trained Dictionary ICM Episodes Episode 1 Episode 2 Episode 3 Episode 4 Episode 5 Episode 6 Episode Average Episode Standard Deviation Accuracy (%) 62.50 87.50 91.96 77.68 47.32 75.62 73.77 16.52

132

ICM DVDT Normal - Scale-Frequency-Amplitude Map 128
Scales

256 512 1024 2048 0 6 8 10 Frequency (Hz) ICM DVDT Abnormal - Scale-Frequency-Amplitude Map 2 4 12

0.2 0.1 0

128
Scales

256 512 1024 2048 0 2 6 8 Frequency (Hz) Diff - Scale-Frequency-Amplitude Map 4 10 12

0.2 0.1 0

128
Scales

256 512 1024 2048 0 2 4 6 Frequency (Hz) 8 10 12

0.2 0.1 0

The scale-frequency map was created for the trained dictionary elements for the normal (top panel) and abnormal (middle panel) ICM DVDT training signals. The bottom panel illustrates the difference in the scale-frequency maps.

Figure 4.13: Scale-Frequency Map for ICM Normal versus Abnormal DVDT

133

The energy captures by local pattern 2 and 3 were observed as significant (from Table 4.4) for ICM DVDT. The  value of 5 and  value of 0.2 indicates a slightly higher emphasis on the sparsity, which may indicate the structures were more unique for the normal and abnormal ICM DVDT categories. This may also possibly explain the variation observed in the accuracies across the episodes. This result also indicates that the dictionary elements could be used to possibly infer the DVDT characteristics for ICM hearts.

4.5

Chapter 4 Summary

This chapter had introduced and discussed some of the time-averaged characteristics that may be found in an electrogram during an arrhythmic episode. A small variety of signal features that describe time-averaged characteristics of the electrogram were used to identify the particular APP characteristics that may have a correlation with the electrogram. Based on the observed correlation, the LCKSVD dictionary learning (driven by the APP characteristics) was used to identify discriminatory signal structures, which may be used to infer what category an electrogram belongs to. These signal structures (trained elements) serve as the foundation to create a DSS, which will automate the process of identifying the APP characteristics of the heart from the electrograms, which can in turn assist clinicians in the diagnosis and treatment of VA.

134

Chapter 5 Decision-Support System

T

HE focus of Chapter 3 and Chapter 4 involved the decomposition of the electrogram to identify signal structures that were of significance for the arrhythmia episode. Subsequently, the

objective of this chapter is to develop a DSS to automate and assist clinicians in diagnosing VA. From Chapter 1, the discussion of the APP characteristics explained that it is difficult to obtain this information from live patients, and the identification of the previously identified signal structures can assist clinicians (through the DSS) and allow to infer the specific event/APP characteristics. Thus, this chapter will use the signal features and the signal structures from the adaptive signal decomposition (refer to Chapter 3 and 4) to create a DSS, as illustrated by Figure 5.1. The user input will pick the specific model to be used by the DSS depending on the event or APP characteristic that is to be targeted by the clinician.

5.1

Decision-Support System For the Diagnosis of Ventricular Arrhythmias

The adaptive signal decomposition and dictionary learning approaches from Chapter 3 and Chapter 4, respectively, had already established a relationship between the signal structures and the events/APP characteristics. The EAV and residual IF structures from the electrograms were identified and a relationship with the rotor event was established in Chapter 3. The discriminatory signal structures was identified by the LCKSVD dictionary learning for specific APP characteristics in Chapter 4. Therefore, after establishing a relationship between the signal structures and 135

d^  Z

 d& ZZZ

 Z ^ ^ Z^Z ^ E EZ  DZ

Z

h /

 WW >

d& Z > DZ  WW 

 Z 

d  s 

This chapter will discuss the DSS that was used to automate and assist clinicians in diagnosing VA.

Figure 5.1: Contributions for Chapter 5

136

VA events/APP characteristics, it is possible to devise a DSS to help clinicians in the diagnosis of VA by inferring these events/APP characteristics using the electrogram. As stated previously in Section 2.4 of Chapter 2, neural networks models can provide the DSS with a linear or non-linear model to support the decision making [76]. Neural network model based DSS have also been used in the field of cardiology for the purpose of studying heart diseases [76, 77]. Therefore, it is possible to create a DSS that is an explainable artificial intelligence model, which could be used directly by the clinical community to infer the events/APP characteristics. Figure 5.2 illustrates the basic diagram for the DSS that will be used in this chapter. The input of a DSS will be the electrogram and specific user input on which event or APP characteristic to target. The DSS itself is made up with a combination of neural network models that is used to infer the event/APP characteristic at the output. The architecture of the neural network model has a high degree of flexibility. The input layer of the neural network will take in the input parameters in order to label the unknown electrogram sample. The output layer will then assign a label based on the weights that transgress from the input layer through to the hidden layers, to the output layer. The number of hidden layers determine the complexity of the generic equation (refer to Equation 2.24) of the network. Though the number of neurons in the hidden layer is flexible, there are limitations that should be considered. For example, if the number of neurons in the hidden layer are few, then the network will be over-generalized, and therefore make it difficult to capture the variations in the training data [125]. On the other hand, if there are too many neurons in the hidden layer, then the network will memorize the training data. As per literature, the upper bound on the number of neurons in a hidden layer was observed to be two times the number of neurons in the input layer [125]. However, this does not guarantee an optimized network. For the neural network models presented in this chapter, the modeling function for each layer was defined as the sigmoid function for the input layer and a linear function for all remaining layers. The sigmoid function is used at the input layer in order to try and capture any non-linearity in the distribution of the input parameters. If this is captured in the input layer, then the remaining hidden layers and neurons should be able to model the parameters with a linear modeling function.

137

/ Z^Z ^ E EZ  ^

K

Z

 Z

& ><^s W

h /

  

WW >

Figure 5.2: Decision-Support System Diagram

138

The network architecture created for this chapter was varied for the time-specific event models and the time-averaged general models. Therefore, the specific architecture for each model is given in the respective sections. Next, the architecture parameters for each neural network are presented. Each model describes the input parameter's association with the output APP characteristic. The cross-validation result to test the networks will also be presented individually. The models are as follows: Â· Time-Specific Event Model Â· Time-Averaged General Model A diagram for the time-specific event model is illustrated in Figure 5.3. The model consists of two stages, the first stage will identify if the electrogram is in the vicinity of a PS and the second stage will determine if the PS electrogram is in the vicinity of a rotor. This will be further discussed in the time-specific event model section. Figure 5.4 illustrates the diagram for the time-averaged general model. This model also consisted of two stages. The first stage was used to determine from what type of heart (DCM or ICM) the electrogram originated from. The DCM electrogram was then further decomposed to identify either normal and abnormal MAP or normal and abnormal ARI. The ICM electrograms were also labeled into four subcategories. The first subcategory labeled the electrogram a normal or abnormal MAP, the second subcategory labeled toe electrogram as normal or abnormal ARI, the third subcategory labeled the electrogram as originating from a healthy or scar region of the ICM heart, and the fourth subcategory labeled the electrogram normal or abnormal DVDT. The results for each of the models will be presented next.

5.2

Time-Specific Event Model

The event discussed in Chapter 3 looked at events that occurred during the arrhythmic episode. Specifically, the rotor event was analyzed to determine whether the electrogram signal structure could be used to identify these events. Before proceeding into the discussion of the model, the rotor events relationship with the APP characteristics will be briefly explained. As stated previously in Chapter 3, the rotor event is believed to be a manifestation of mechanisms that initiate 139

ZZZ W^   DZ ^  W^ EZZZZ W^ Z   DZ ^ 

EZW^ EZW^ Z

Figure 5.3: Diagram for the Time-Specific Event Model

' DZD D W

D

' DZD D W

Z

' DZ ZZ ^ 

' DZ/D D W /D

' DZ/D Z/

' DZ/D sK>

' DZ/D sd

Figure 5.4: Diagram for the Time-Averaged General Model

140

Adjacent Voltage Standard Deviation
2

1.8

1.6

1.4

1.2

mV

1

0.8

0.6

0.4

0.2

0

Rotor PS

Non-Rotor PS Groups

Non-PS

Figure 5.5: Distribution of the Standard Deviation of the Max Voltage for the Rotor Event and maintain VA [81]. Furthermore, they have been observed to occur in the boundary around healthy and scar regions [9], meaning that there will be an expected variation in the max voltage characteristic. In order to visualize this, the electrogram locations previously identified in the time-specific event analysis (refer to Chapter 3) was used. For each of the electrode locations previously identified, the max voltage characteristic for this electrode location and for the adjacent electrodes were recorded. The standard deviation for a particular location could be determined to observe the distribution. Figure 5.5 illustrates the distribution of the standard deviation for electrode locations in the vicinity of a rotor PS, electrode locations in the vicinity of a non-rotor PS and non-PS electrode locations. As previously described in literature, a larger deviation in the max voltage in the electrode locations adjacent to a rotor PS exists when compared to the other cases (P < 0.01). Analyzing the other APP characteristics for their mean and standard deviation did not reveal any other significant characteristics. This section will present the database used to train and validate the time-specific model, followed by discussing the specifics of the architecture and the cross-validated results.

141

5.2.1 Database
There were two databases specifically used for the time-specific event model. These databases are the retrospective database and the Faber-Rudy synthetic database. Retrospective Database The retrospective database consists of the same electrograms that was used for the time-specific event signal decomposition in Chapter 3. For the time-specific model, the unipolar recordings were used to label the electrogram as rotor PS, non-rotor PS or non-PS events. A total of 104 electrograms (8 electrograms from each of the 13 episodes) were used for the time-specific model. This database is referred to as RDB. Faber-Rudy Synthetic Database The Faber-Rudy synthetic database was explicitly created for two purposes: to generate a simulated rotor and to capture the simulated APP characteristics. The arrhythmia episodes were generated using the Faber-Rudy model [92], which is similar to the Luo-Rudy model used in Chapter 3. This model also simulates the inward and outward current flow using the transmembrane model. The additional model equation to the Faber-Rudy model is the ion model. The ion model characterizes the change in the ion concentration within the tissue. The model consisted of a tissue that was 6 Ã 4cm2 . The characteristics of the tissue were selected such that different regions of the tissue had simulated characteristics of a lower max voltage to represent the scar tissue. The pacing simulation was created by only using a single impulse to measure the simulated APP characteristics. The arrhythmia episode was then initiated on the same tissue. One electrogram was recorded near the location of the rotor event and one electrogram was recorded away from the rotor event for each arrhythmia episode. There were a total of 5 arrhythmia episodes that were generated, providing a total of 10 electrograms (5 in the vicinity of a rotor event and 5 that were away from the PS). The simulated electrogram was generated at 1000 samples/S and then down-sampled to 250 samples/S. Finally, the electrograms were filtered between 1 and 10 Hz. The simulated electrograms and APP characteristics were used to validate

142

the time-specific event model and the association of the electrogram signal structures from the time-specific event signal decomposition with the event/APP characteristics. This database will be referred to as FRDB.

5.2.2 Cross-Validated Results and Discussion
The time-specific event model architecture consisted of 4 layers (illustrated in Figure 5.6). The input layer consisted of neurons for each of the input parameters for the network. The output layer had 1 neuron to label the electrogram (e.g. PS versus Non-PS or rotor PS versus non-rotor PS). The first hidden layer was selected based on the upper bound [125] to allow the greatest flexibility in approximating the function that relates the input to the eventual output space. Thus, the first hidden layer had double the neurons as the input layer. The second hidden layer had as many neurons as there were unique labels. The weights were randomly initialized for the training of the networks. The validation of the neural networks required a testing data set. Due to the limited number of electrograms for the time-specific event model, cross-validation was carried out based on a single electrogram set. A random rotor PS electrogram, non-rotor PS electrogram and two of the non-PS electrograms were chosen to validate the network model created from all the other electrograms. This process was repeated until all electrograms were used once to validate the network. The EAV structure along with the frequency deviation structure from the EAV-based MP decomposition had revealed that these were significant in identifying the rotor events. The IF of the residual was observed to be able to identify electrograms in the vicinity of a PS, while the approximated RMS of the EAV structure was used to determine if the electrogram was near a rotor or non-rotor PS. Therefore, the input parameters for the time-specific event model are as follows: Â· Approximated FD (aF D) from Equation 3.16 Â· Approximated RMS of the EAV Structure (EAVaRM S ) from Equation 3.17 The signal features for the time-specific event-based signal decomposition classified the data in two stages; therefore, two network models were created for each stage. The first stage was used to label the electrogram as PS or non-PS. The number of input neurons was set as 1 because 143

,>







  
/ >   Z

  

,>



& , >    Z

^Z , >  Z

K >  Z



  



,>



  
,>


Figure 5.6: Standard DSS Neural Network Architecture only the approximated FD feature (aF D) was needed for stage 1 of the time-specific model. The number of neurons for the first hidden layer was set to 2 (twice the number of input neurons) and the number of neurons in the second hidden layer was set to 2 because there is 2 unique labels (either PS or non-PS). The labels created for the output layer was 1 for PS electrograms and 2 for non-PS electrograms. Based on the cross-validation, it was possible to evaluate the average accuracy. Table 5.1 presents the average cross-validated results from stage 1. Table 5.1: Confusion Matrix - Stage 1 Percentage: PS Versus Non-PS Event PS 71.15% 9.62% Non-PS 28.85% 90.38% Total 100% 100%

PS Non-PS

This table illustrates that the network can be readily used to determine whether an electrogram can be labeled as a PS or non-PS electrogram with an overall accuracy of 80.77%. The overall accuracy was determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it across all the cross validation sets. The results for the nonPS electrograms had a better classification accuracy (90.38%) when compared to the classification accuracy for PS electrograms (71.15%). The stage 2 was generated in order to determine if the 144

correctly identified PS electrogram from stage 1 was a rotor or non-rotor PS event. A similar network architecture to stage 1 was used for stage 2. However, the input parameter was changed to the approximated RMS of the EAV. Table 5.2 shows the validation results from stage 2. Table 5.2: Confusion Matrix - Stage 2 Percentage: Rotor PS Versus Non-Rotor PS Event Rotor PS 83.33% 26.32% Non-Rotor PS 16.67% 73.68% Total 100% 100%

Rotor PS Non-Rotor PS

The cross-validated labeling from stage 2 also indicates the strength of the model to predict the electrogram as rotor or non-rotor with an overall accuracy of 76.09%. The second hidden layer distributions for stage 1 and stage 2 is illustrated in Figure 5.7. The values produced from neuron 1 of the second hidden layer is given by the x-axis while the values produced from neuron 2 of the second hidden layer is given by the y-axis. This figure provides an illustration on how the input parameters were mapped to the output layer in order to label the electrograms. It is observable that there is a linearly separable boundary for both models, which was also observed from the results presented in Chapter 3. The computer-simulated electrogram model generated by the FRDB was also used to test the two stages by simulating a rotor on a sample tissue. An electrogram around the vicinity of a rotor and one away from the rotor was extracted for each of the simulated arrhythmia episodes. The max voltage characteristic was also recorded for both locations as well as the surrounding regions around the electrogram. From the recorded max voltages, the standard deviation of the max voltage for each of the electrograms were determined. The average of the standard deviation for the electrograms in the vicinity of the rotor was 2.75mV and the average of the standard deviation for the electrograms away from the rotor was around 0.29mV. These simulated values are comparable to the distribution from Figure 5.5. Next, the electrograms were decomposed using the EAV-based MP to capture the EAV and residual components. Then, for the electrogram in the vicinity of a rotor, the approximated FD and the EAV-approximated RMS feature around the time occurrence of the rotor were recorded. These two features were also recorded for an arbitrary time sample for the electrogram away from PS. The features of the electrograms were tested using both stages to 145

label the electrograms. Table 5.3: Confusion Matrix - Stage 1 Percentage: Simulated Electrogram PS Versus Non-PS Event PS 100% 0% Non-PS 0% 100% Total 100% 100%

PS Non-PS

Table 5.4: Confusion Matrix - Stage 2 Percentage: Rotor-PS Versus Non-Rotor PS Event Rotor PS 60.00% Non-Rotor PS 40.00% Total 100%

Rotor PS

From stage 1, the electrograms in the vicinity of a rotor were labeled correctly as a PS electrogram and the electrograms that were away from the rotor were labeled correctly as a non-PS electrogram. The classification from stage 1 (Table 5.3) was therefore 100% with the approximated FD feature as the input to the model. The electrograms in the vicinity of a rotor was then used to validate the stage 2 with the approximated RMS of the EAV structure. The label assigned from stage 2 was the rotor event label. The electrograms from the simulated arrhythmia episode were labeled with an accuracy of 60% (Table 5.4), which is an indication of the strength of the input parameters to the models. It should be noted that the analysis of the electrograms in a two-stage model could also have been accomplished with a single model. However, testing the database with the single model made it difficult to validate the rotor event because of the approximated RMS of the EAV structure. While it was observed that the approximated RMS value was lower for rotor PS than the non-rotor PS events, it had a large variations for the non-PS electrogram cases. This variation added more parameters to the input space in a single combined model, and the model was therefore segregated into two stages. The model provided in Appendix B shows the function and the weights and bias values that relates the input parameter with the label of the event. The number of input parameters was also increased by including the signal features that were discussed for the general signal decomposition (local pattern energies, DF and arrhythmia organization). The cross-validation results 146

from a single model and a two-stage model performed poorly when compared to the approximated FD and approximated RMS of the EAV structure alone. Finally, the two-stage model was validated with simulated electrograms generated from the FRDB. These electrograms were correctly labeled in stage 1, while having some difficulty in being labeled in stage 2. The simulated electrograms also had a similar distribution with respect to the max voltage APP characteristic. The label output created for the rotor event can then be associated with the max voltage distribution expected for the rotor events, which can provide clinical insight by locating the important scar/healthy boundary region. The two stage time-specific event model is useful in clinical practice, as clinicians could infer when an electrogram is in the vicinity of a rotor event and what the expected distribution of the max voltage should be.

5.3

Time-Averaged General Model

The time-averaged general models were developed to automate the time-averaged signal characteristics and the LCKSVD trained dictionary elements such that it may be used to infer the APP characteristics. The time-averaged general model was also broken into two stages. The first stage was used to label the electrogram as DCM or ICM. The second stage then determined the subcategory of either the DCM electrogram (normal/abnormal MAP, and normal/abnormal ARI) or the ICM electrogram (normal/abnormal MAP, normal/abnormal ARI, healthy/scar, and normal/abnormal DVDT). The cross-validation for the time-averaged general models were done differently when compared to the time-specific event models. For the time-averaged general models, 95% of the total dataset was first used to train the network. This network was then tested with the remaining with the 5% data points. This process was repeated until all the observations were used once as testing data. This was done because of the relatively larger data size for the time-averaged general models when compared to the time-specific event models. The following subsections will discuss the database followed by the cross-validated results and discussion for each time-averaged DSS.

147

Hidden Layer 2 Distribution For One Sample Cross Validation Set
1.6

Hidden Layer 2: Neuron 2 Model Values

1.4

PS Non-PS

1.2

1

0.8

0.6

0.4

0.2 -0.32

-0.3

-0.28

-0.26

-0.24

-0.22

-0.2

-0.18

-0.16

-0.14

Hidden Layer 2: Neuron 1 Model Values

(a) Stage 1 Distribution
Hidden Layer 2 Distribution For One Sample Cross Validation Set
-0.8

Hidden Layer 2: Neuron 2 Model Values

-0.805 -0.81 -0.815 -0.82 -0.825 -0.83 -0.835 -0.84 -0.845 2.09

Rotor PS Non-Rotor PS

2.1

2.11

2.12

2.13

2.14

2.15

2.16

Hidden Layer 2: Neuron 1 Model Values

(b) Stage 2 Distribution

Figure 5.7: Distribution of the Second Hidden Layer for the Time-Specific Event Model

148

5.3.1 Database
The database that was used to create the time-averaged general models was the RDB (described in Section 4.2). A total of 11 episodes with a possible 112 electrograms per episode were used to generate the DSS. Similar to the analysis carried out in Chapter 4, the APP characteristics for each electrogram were also used to label the electrograms.

5.3.2 Cross-Validated Results and Discussion
The results for each of the time-averaged general models will be discussed in this section. Time-Averaged General Model - Cardiomyopathy The time-averaged general model for the cardiomyopathy was created to map the input space for the electrograms with the cardiomyopathy type. The significant signal features and the LCKSVD output parameters (the product of the [W ]F inal,CM classifier parameter and the OMP sparse code F inal,CM ) were selected for the purpose of labeling the electrogram as DCM or ICM. From the significance test conducted in the general signal decomposition in Chapter 3 (refer to Table 4.2 of Chapter 4), the significant signal feature was the arrhythmia organization. The trained final dictionary F inal,CM was used to produce the sparse codes F inal,CM for all the electrograms, and along with the final classifier parameters [W ]F inal,CM , the second (F inal,CM DCM ), and third (F inal,CM ICM ) input parameter can be created. Recall that the sparse code product with the classifier parameter (F inal,CM ) is used to define the sparse code product for the DCM dictionary elements (F inal,CM DCM ) and the sparse code product for the ICM dictionary elements (F inal,CM ICM ). Therefore, the input space consisted of three parameters, as follows: Â· Arrhythmia organization Â· Sparse code product for DCM Â· Sparse code product for ICM With the input parameters set, the neural network architecture was established (architecutre illustrated in Figure 5.6). The general model consists of 4 layers, 1 input layer, 1 output layer 149
[W ] [W ] [W ] [W ] [W ] [W ]

and 2 hidden layers. The input layer had 3 neurons, the first hidden layer had 6 neurons, the second hidden layer had 2 neurons and the output layer had 1 neuron. The labeling provided for the output layer was 1 for DCM electrograms and 2 for ICM electrograms. The total number of available electrograms from the 11 episodes was separated into training observations (95%) and testing observations (5%). The model was tested and then this process was repeated until the entire data set was used as a testing data set. The average of the cross-validated results is provided in Table 5.5. Table 5.5: Confusion Matrix - Time-Averaged General Model-Cardiomyopathy Percentage DCM 82.07% 18.93% ICM 18.06% 89.12% Total 100% 100%

DCM ICM

As evident from Table 5.5, the input parameters have a strong relation with the type of cardiomyopathy. The classification accuracy is also fairly balanced between the two groups, indicating the strength of the input parameters. The overall accuracy was determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it across all the cross validation sets. The average overall cross-validation accuracy achieved was 85.90% with a standard deviation of 5.43% for the cross-validation sets. The sensitivity was 82.07% and the specificity was 89.12%. The second hidden layer space could also be visualized from the network parameters. Since the neural network consists of 4 layers, the first 3 layers were used to map the input space to the function space, for which a label is given in the output layer. The output at the last hidden layer reveals how the input parameters were mapped to the label. Figure 5.8a illustrates the network space for one of the cross-validated data sets. In this figure, the x-axis shows the values produced from neuron 1 of the second hidden layer while the y-axis shows the values produced from neuron 2 of the second hidden layer. The network space for the second hidden layer appears to be linearly distributed for the DCM and ICM electrograms. This distribution does not necessarily mean that the input space is linearly related to this network space. The distribution of the DCM electrograms appear to be grouped towards the right half of this network space when compared to the ICM electrograms. The weight and bias parameters for the general 150

cardiomyopathy model can be found in Appendix B. This distribution does indicate, however, that the model can use the arrhythmia organization and LCKSVD parameters to appropriately label the type of cardiomyopathy based on the electrogram. The results indicate that the model provides a strong DSS to assist clinicians in determining the type of cardiomyopathy. Considering the results achieved by the LCKSVD trained dictionary (81.80% from Table 4.6 of Chapter 4) and the arrhythmia organization signal feature (64.82% from Table 4.2 of Chapter 4), the benefit of the model (based on the neural network) is evident. The combination of the input parameters and the non-linear relationship created a strong association between the input and output space; adding the other non-significant signal features to the input parameters only changed the overall results slightly, with a maximum increase of 2%. The model generated to label the electrogram as DCM or ICM allows the prediction of the type of cardiomyopathy based on only the electrograms of the arrhythmic episode. As previously discussed in Chapter 4, the difference between DCM and ICM hearts is important, given that the therapy options vary for the two cardiomyopathies [46Â­48]. The time-averaged general model developed for the cardiomyopathy was also used for the subsequent models, where only the correctly identified electrograms were used for the validation of the subsequent time-averaged general models. Time-Averaged General Model - DCM MAP The next time-averaged general model was developed to label the DCM electrograms as normal or abnormal MAP. This required that the electrogram was already labeled as DCM from the general model for the cardiomyopathy. The signal feature that was identified from the general decomposition in Chapter 4 (refer to Table 4.3) was the standard deviation of the residual IF. This parameter, along with the LCKSVD parameters (the product of the sparse code F inal,DCM M and the classifier parameters [W ]F inal,DCM M ) for each category serves as the input of the model and is provided below. Â· Residual IF STD Â· Sparse code product for DCM MAP N 151

Â· Sparse code product for DCM MAP A The input parameters were used to train and cross-validate the 4 layer network. There were 3 neurons in the input layer, 6 neurons in the first hidden layer, 2 neurons in the second hidden layer and 1 neuron in the output layer. The labeling provided for the output layer was 1 for normal DCM MAP electrograms and 2 for abnormal DCM MAP electrograms. There were 5 DCM episodes for this analysis. The cross-validation sets had used 5% of the electrograms to test the trained model. Table 5.6 presents the average cross-validated results for the general model for the DCM MAP cases. Table 5.6: Confusion Matrix - Time-Averaged General Model-DCM MAP Percentage DCM MAP N 87.68% 47.95% DCM MAP A 12.32% 52.05% Total 100% 100%

DCM MAP N DCM MAP A

The distribution of the results from Table 5.6 indicates that the input space has a strong relationship with the normal DCM MAP electrograms, but a relatively weak relationship with the normal DCM MAP electrograms. The overall accuracy was determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it across all the cross validation sets. An overall accuracy of 79.98% was achieved in the cross-validation, with a sensitivity and specificity of 87.68% and 52.05%, respectively. The standard deviation for the set of cross validation was 7.38%. The distribution for the second hidden layer space, provided in Figure 5.8b, is shown for one of the cross-validated data sets. The x-axis and y-axis represent the neuron values for the second hidden layer. The distribution for this space appears to be linear. The distribution of the normal and abnormal DCM MAP electrograms is poor, which is reflected in the low cross-validation accuracy for the DCM Normal MAP electrograms. The network parameters (weight and bias) for the general DCM M model is presented in Appendix B. The results presented for the general DCM MAP model implies that the signal feature and the LCKSVD parameters were better suited to identifying normal DCM MAP electrograms. This result could be a result of the discrepancy in the number of electrograms available for normal and 152

abnormal DCM MAP. Of the 560 electrograms from the DCM hearts, only 121 electrograms were from abnormal DCM MAP. This meant that there were almost twice as many electrograms for the normal DCM MAP electrograms, placing more emphasis for both the LCKSVD and the neural network model for this category. The general model for the DCM MAP electrograms were also varied to include additional signal features, but did not improve the balance of the classification accuracies or the overall classification accuracy. This analysis indicates that the time-averaged DCM MAP model could be used to infer the label, particularly normal MAP in DCM hearts. Time-Averaged General Model - DCM ARI The dictionary learning was also applied on the normal and abnormal ARI for DCM electrograms because of the significance with the standard deviation of the residual IF signal feature (Table 4.3). Using the DCM electrograms that were correctly labeled by the time-averaged model for the cardiomyopathy, the model was generated for the DCM ARI. The DCM ARI model used the residual IF STD and the LCKSVD parameters (the product of the sparse code F inal,DCM A and the classifier parameters [W ]F inal,DCM A ) for each category as the model inputs. Â· Residual IF STD Â· Sparse code product for DCM ARI N Â· Sparse code product for DCM ARI A The neural network was a 4 layer network, with 3 neurons in the input layer, 6 neurons in the first hidden layer, 2 neurons in the second hidden layer and 1 neuron in the output layer. A label of 1 was assigned for the normal DCM ARI electrograms and a label of 2 was assigned for the abnormal DCM ARI electrograms. There were a total of 5 DCM episodes used to train the model. The average results of the cross-validation is given in Table 5.7. The overall accuracy produced as a result of averaging the cross-validation result was 78.19% (standard deviation of 8.02%). The sensitivity for this result was 86.43%, while the specificity was 52.00%. The overall accuracy for each cross-validation set was calculated by dividing the correctly labeled testing samples by the total number of testing samples. The results are indicative 153

Table 5.7: Confusion Matrix - Time-Averaged General Model-DCM ARI Percentage DCM ARI N 86.43% 48.00% DCM ARI A 13.57% 52.00% Total 100% 100%

DCM ARI N DCM ARI A

that the normal DCM ARI can be inferred more accurately by the model. Figure 5.8c illustrates the distribution of the second hidden layer space for one of the cross-validated sets. The x-axis and y-axis represent the neuron values for the second hidden layer. The distribution appears to have a linear representation. The network parameters (weight and bias) for the general DCM A model is presented in Appendix B. These results imply that it maybe possible to infer the DCM ARI characteristics from the LCKSVD parameters. Similar to the DCM MAP cases, the discrepancy of the number of normal and abnormal DCM ARI electrograms may have played a factor in training the models. This can be observed in the classification accuracy difference between the normal and abnormal DCM ARI categories, with the normal DCM ARI category performing well. The general model for DCM ARI revealed that the trained elements can be provided to a model to automate and assist clinicians in inferring the normal ARI regions in DCM hearts. Time-Averaged General Model - ICM MAP Similar to the DCM MAP electrograms, a time-averaged general model was generated for the ICM MAP electrograms that would label the correctly assigned ICM electrograms from the timeaveraged general cardiomyopathy model as normal or abnormal MAP. The input parameters consisted of multiple signal features as well as the LCKSVD output parameters. The signal features that were observed to be significant (Table 4.4) were the energy captured by local pattern 1 and the arrhythmia organization. These signal features along with the LCKSVD output parameters F inal,ICM M AP , formed the input space that consisted of 4 parameters, and are given below. Â· Local pattern 1 Â· Arrhythmia Organization 154
[W ]

Â· Sparse code product for ICM MAP N Â· Sparse code product for ICM MAP A The input layer consisted of 4 neurons for each of the input parameters, the first hidden layer had 8 neurons, the second hidden layer had 2 neurons and the output layer had 1 neuron. The labeling provided for the output layer was 1 for normal ICM MAP electrograms and 2 for abnormal ICM MAP electrograms. A total of 6 arrhythmic episodes existed for this model. The average cross-validated accuracies (given in Table 5.8) were obtained by averaging the results from each of the cross-validation sets. Table 5.8: Confusion Matrix - Time-Averaged General Model-ICM MAP Percentage ICM MAP N 90.02% 47.47% ICM MAP A 9.98% 52.53% Total 100% 100%

ICM MAP N ICM MAP A

The overall accuracy was determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it across all the cross validation sets. The results from Table 5.8 had an overall classification accuracy of 75.06% (sensitivity of 90.02%, specificity of 52.53%, and standard deviation of 7.92%), which shows a strong ability to infer the normal ICM MAP. The accuracy for the normal ICM MAP was stronger when compared to the abnormal ICM MAP, and the distribution of the second hidden layer for one of the cross-validated sets is given in Figure 5.8d also illustrates this. The axis represent the values for the two neurons in the second hidden layer. This distribution appears to be linearly separable based on the second hidden layer. Furthermore, the distribution indicates that more of the abnormal ICM MAP is distributed along the upper right quadrant of this space while the abnormal ICM MAP is distributed along the lower half quadrant. The weight and bias network parameters for this model are provided in Appendix B. The electrogram signal structures appear to be better suited for identifying the normal ICM MAP electrograms. This observation was also similar to the DCM MAP case. The normal MAP for the ICM hearts appear to have a more discriminative electrogram signal structure than that of 155

the DCM hearts, as evident from the discrepancies in the normal MAP accuracies between ICM (Table 5.8) and DCM (Table 5.6). Though the results indicate that the signal structures are better suited for labeling the normal MAP electrograms, the ICM hearts also had an imbalance in the number of electrograms for each category, with normal ICM MAP having almost twice as many electrograms than the abnormal ICM MAP. The addition of the 4 remaining signal features did not significantly improve the model (increase of 2%). The overall accuracy does suggest that the model could be important for identifying regions of the heart with normal and abnormal MAP values in ICM cases (with better accuracy for normal MAP), which could help clinicians to better optimize existing therapy option [15, 16]. Time-Averaged General Model - ICM ARI The ICM ARI was another characteristic for which LCKSVD dictionaries were created to reveal its hidden structures that may be used to represent the normal and abnormal ARI. From the analysis of the signal features (Table 4.4), the energy captured local pattern 1, and arrhythmia organization were observed as significant for ICM ARI. The LCKSVD parameters (F inal,ICM ARI ) and the signal features were used for the input space and is provided below. Â· Local pattern 1 Â· Arrhythmia organization Â· Sparse code product for ICM ARI N Â· Sparse code product for ICM ARI A A 4 layer neural network was generated for this model. The input layer had 4 neurons, the first hidden layer had 8 neurons, the second hidden layer had 2 neurons, and the output layer had 1 neuron. The normal ICM ARI was given a label of 1 and the abnormal ICM ARI was given a label of 2. The 6 ICM episodes were used to train the model. Table 5.9 presents the average results for the cross-validated accuracies. The overall accuracy for each cross-validation set was determined based on dividing the correctly labeled testing electrograms by the total number of testing electrograms. An average overall 156
[W ]

Table 5.9: Confusion Matrix - Time-Averaged General Model-ICM ARI Percentage ICM ARI N 74.77% 46.98% ICM ARI A 26.23% 53.02% Total 100% 100%

ICM ARI N ICM ARI A

classification accuracy of 66.99% (with sensitivity and specificity of 74.77% and 53.02%, respectively) was achieved using the ICM ARI model. The standard deviation across the cross-validation sets was 8.29%. The model had a relatively better accuracy for the normal ICM ARI (similar to ICM MAP). The second hidden layer distribution can be observed in Figure 5.8e. The axis for this figure represents the two neurons in this layer. The distribution of the normal and abnormal appear to be clustered but linearly separable. The weight and bias network parameters for this model are provided in Appendix B. The model used for ICM ARI shows a stronger ability to infer the normal ARI. This could be a result of the structures identified by the trained dictionary, where the structure was better captured for the normal ICM ARI. Similar to the ICM MAP, DCM MAP, and DCM ARI cases, the discrepancy between the number of electrograms for the normal and abnormal ARI could have influenced the accuracies that were presented. This model serves as an automated tool that clinicians may use to better infer the ICM ARI characteristics, and in particular the normal ARI region within ICM hearts. Time-Averaged General Model - ICM Vol The time-averaged general model that was developed was for the ICM max voltage was done on the electrograms that were correctly labeled as ICM from the time-averaged general cardiomyopathy model were used in the validation set. The energy captured by local pattern 1 and local pattern 3 (refer to Table 4.4 of Chapter 3) were observed to be the significant signal features. The LCKSVD output parameters F inal,ICM V ol served as additional input parameters for the model. The input space consisted of the following input parameters: Â· Local pattern 1 157
[W ]

Â· Local pattern 3 Â· Sparse code product for ICM healthy Â· Sparse code product for ICM scar The neural network had 4 total layers. The first input layer had 4 neurons, the first hidden layer had 8 neurons, the second hidden layer had 2 neurons and the final output layer had 1 neuron. Similar to the general model for the ICM MAP, a total of 539 electrograms from 6 arrhythmic episodes were used, with approximately 512 (95%) electrograms used to train the model and approximately 27 (5%) electrograms used per cross-validation set. The average accuracies produced from the cross-validated accuracies are given in Table 5.10. Table 5.10: Confusion Matrix - Time-Averaged General Model-ICM Vol Percentage ICM Healthy 70.03% 20.88% ICM Scar 29.97% 79.12% Total 100% 100%

ICM Healthy ICM Scar

The average overall accuracy for this table was 74.41% and a standard deviation of 8.65%. The sensitivity and specificity were 70.03% and 79.12%, respectively. The overall accuracy was determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it across all the cross validation sets. These results demonstrate a good relationship between the input and output space, with the relationship being stronger for the healthy regions of the ICM hearts than the scar regions. Figure 5.8f illustrates the distribution in the second hidden layer space for one of the cross-validated sets. The neuron values for the second hidden layer is represented by the X and Y axes. The distribution of this hidden layer appears linear, with the healthy ICM electrograms being tightly clustered with the scar ICM electrograms. The distribution of the healthy ICM electrograms is more towards the lower right of the network space when compared to the scar ICM electrograms. The weight and bias parameters for the general ICM V model can be found in Appendix B. The signal structures that were targeted for the healthy and scar regions of ICM hearts were more discriminant for electrograms origination from the healthy regions of the ICM hearts. The 158

addition of the remaining signal features to the input space of the model did not change the overall accuracy. The number of training electrograms were more balanced for this model when compared to the ICM MAP and ICM ARI cases. The healthy/scar boundary region was established as a potential cause for future arrhythmic episodes in ICM hearts [47]. A model that can infer the health of the tissue using only the electrogram can provide clinicians with more insight of the signal structure of the heart, which can then be used to devise a more suitable strategies in treating patients with ICM. Time-Averaged General Model - ICM DVDT The last of the time-averaged general model was for the ICM DVDT. The correctly labeled ICM electrograms was used to validate the model generated for the ICM DVDT. There were several signal features (Table 4.4) that were significant for the ICM DVDT. These signal features included the energies captured by local pattern 2, and local pattern 3. The combination of these features and the LCKSVD parameters (F inal,ICM DV DT ) were used for the input space of the model. The variables provided to the input space is also listed below. Â· Local pattern 2 Â· Local pattern 3 Â· Sparse code product for normal ICM DVDT Â· Sparse code product for abnormal ICM DVDT The number of neurons for the 4 layers of the neural network were 4 for the input layer, 8 for the first hidden layer, 2 for the second hidden layer, and 1 for the output layer. A total of 6 ICM episodes were used to train the model. The average accuracies for the cross-validation sets are listed in Table 5.11. The average overall accuracy (determined by dividing the correctly classified testing samples by the total number of testing samples and then averaging it) was 85.78% (with a standard deviation of 5.63%). A sensitivity and specificity of 51.87% and 93.01%, respectively, were achieved. The 159
[W ]

Table 5.11: Confusion Matrix - Time-Averaged General Model-ICM DVDT Percentage ICM DVDT N 51.87% 6.99% ICM DVDT A 48.13% 93.01% Total 100% 100%

ICM DVDT N ICM DVDT A

accuracy indicates that the combination of features and LCKSVD parameters was better suited to infer the abnormal ICM DVDT electrograms. The distribution in the second hidden layer space for an example cross-validation set also illustrates this (Figure 5.8g), where the normal ICM DVDT is clustered around the abnormal ICM DVDT. The X and Y axis represent the values for the two neurons in the second hidden layer. The weight and bias parameters for the general ICM DVDT model can be found in Appendix B. This result illustrates that the structures for the abnormal ICM DVDT may have been more discriminatory when compared to the structures for the normal ICM DVDT. There also existed a discrepancy between the number of electrograms that were used for the normal and abnormal ICM DVDT. There were almost 6 times as many abnormal electrograms, which could possibly explain the accuracies observed. The DVDT was a measure on the ability of the tissue to contract [17], and thus being able to infer abnormal ICM DVDT can allow clinicians to identify regions that have an abnormal contraction.

5.4

Chapter 5 Summary

In this chapter, a DSS was introduced to create a decision function that will assist clinicians in using the identified signal structures (previously described from Chapter 3 and 4) that were associated with specific event and/or APP characteristic labels and automating the process by which to infer these events/APP characteristic labels. Time-specific event models were developed for the rotor event that associated the EAV and residual IF structures with the variations observed in the max voltage around the vicinity of a rotor. The time-specific event model was broken into two stages: the approximated FD feature was used in stage 1 to label the electrograms as PS or non-PS and the approximated EAV RMS was used in stage 2 to label the electrograms as rotor and non-rotor

160

Hidden Layer 2 Distribution
1.6 3

Hidden Layer 2 Distribution

Hidden Layer 2: Neuron 2 Model Values

1.4 1.2 1 0.8 0.6 0.4 0.2 0 -0.2 -0.4 -0.3 -0.25 -0.2 -0.15 -0.1 -0.05 0

Hidden Layer 2: Neuron 2 Model Values

DCM ICM

DCM N DCM A
2.5

2

1.5

1

0.5

0.05

0 -1.6

-1.4

-1.2

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

Hidden Layer 2: Neuron 1 Model Values

Hidden Layer 2: Neuron 1 Model Values

(a) General CM Model Distribution
Hidden Layer 2 Distribution
1.2

(b) General DCM M Model Distribution
Hidden Layer 2 Distribution
0.5

Hidden Layer 2: Neuron 2 Model Values

1

Hidden Layer 2: Neuron 2 Model Values

DCM A N DCM A A

0

ICM M N ICM M A

0.8

-0.5

0.6

-1

0.4

-1.5

0.2

-2

0

-2.5

-0.2 -2.5

-2

-1.5

-1

-0.5

0

0.5

-3 -2.2

-2

-1.8

-1.6

-1.4

-1.2

-1

-0.8

-0.6

-0.4

Hidden Layer 2: Neuron 1 Model Values

Hidden Layer 2: Neuron 1 Model Values

(c) General DCM A Model Distribution
Hidden Layer 2 Distribution
0.4

(d) General ICM M Model Distribution
Hidden Layer 2 Distribution
0.5

Hidden Layer 2: Neuron 2 Model Values

0.3 0.2 0.1 0 -0.1 -0.2 -0.3 -0.4 -0.5

Hidden Layer 2: Neuron 2 Model Values

ICM A N ICM A A

0.4

ICM V H ICM V S

0.3

0.2

0.1

0

-0.1

0

0.5

1

1.5

2

2.5

-0.2 -1.2

-1

-0.8

-0.6

-0.4

-0.2

0

0.2

0.4

Hidden Layer 2: Neuron 1 Model Values

Hidden Layer 2: Neuron 1 Model Values

(e) General ICM A Model Distribution
-0.4

(f) General ICM V Model Distribution
ICM DVDT N ICM DVDT A

Hidden Layer 2 Distribution

Hidden Layer 2: Neuron 2 Model Values

-0.6

-0.8

-1

-1.2

-1.4

-1.6

-1.8 0.1

0.15

0.2

0.25

0.3

Hidden Layer 2: Neuron 1 Model Values

(g) General ICM DVDT Model Distribution

Figure 5.8: Distribution of the Second Hidden Layer for the Time-Averaged General Model

161

PS. Seven time-averaged general models were developed to relate the general arrhythmia LCKSVD parameters and time-averaged characteristics with the APP characteristics of the heart. The general model was broken into two stages: stage 1 consisted of labeling the electrogram as belonging to a DCM or ICM heart, and stage 2 used the labeled electrogram to identify further APP characteristics for each type of cardiomyopathy. These models crated a DSS to automate and assist clinicians in inferring the VA event/APP characteristic, which could be valuable in a clinical setup.

162

Chapter 6 Conclusions and Future Works

V

ENTRICULAR arrhythmias is one of the leading causes of death. There are approximately 300,000 to 400,000 sudden cardiac deaths on an annual basis in the United States alone [4].

These arrhythmias, and in particular VF, has traditionally been regarded as chaotic in nature, but recent evidence suggests the existence of mechanisms and events that might initiate and sustain the arrhythmias [30Â­33]. The methodologies outlined in this dissertation focused on identifying underlying signal structures in the VA episode, such that the events and characteristics of the heart could be inferred and clinical therapy could be better strategized. The adaptive signal decomposition of the arrhythmia electrogram aimed at identifying signal structures that were related to a time-specific event (rotor) as well as signal structures that can describe time-averaged VA characteristics of the heart. These signal structures were used as inputs into a DSS that could infer the VA event and APP characteristics in order to assist clinicians. The proposed approaches were well suited in achieving the objective set out for this dissertation.

6.1

Summary of Results and Impact

The contributions for the dissertation are two-fold. The first contribution was the use of adaptive signal decomposition to identify signal structures unique to the arrhythmic episode. This contribution can be further separated into the time-specific events and the time-averaged VA characteristics. For the time-specific events, a modified criterion function was used to extract the EAV structure that was observed in electrograms in the vicinity of a rotor. In the process of segregating the EAV struc163

ture (through the approximated component) from the electrogram, it was observed that the residual component also consisted of a deviation in its frequency component around the occurrence of a PS. The combination of these signal structures were used to classify the 104 electrograms originating from 13 arrhythmia episodes. The electrograms were classified as rotor PS events, non-rotor PS events and non-PS electrograms. A two-stage LDA classifier was used to classify the data set using the LOO method. The first stage of the classification had an overall accuracy of 80.77% for classifying the PS electrograms from the non-PS electrograms using the residual IF feature. The second stage of the classification had an overall accuracy of 79.41% for classifying the rotor PS from the non-rotor PS electrograms using the approximated RMS of the EAV structure. These results are significant in that they demonstrate an electrogram structural relationship with a phenomenon that is believed to be a manifestation of mechanisms that initiate and sustain VA. The time-averaged VA characteristics identified some common signal features that are of significance to the APP characteristics of the heart. Given that some APP characteristics showed a relationship with these signal features, the LCKSVD dictionary learning algorithm was used to train dictionaries that would specifically capture signal structures of interest from the electrograms to represent the APP characteristics. For this analysis, a maximum of 11 arrhythmia episodes were used to train the dictionary for specific electrogram signal structures driven by the APP characteristics. The scale-frequency maps were used to identify the space represented by the possible discriminant signal structures. The LCKSVD was used to determine signal structures that targeted the type of cardiomyopathy, normal versus abnormal approximate of the MAP in DCM hearts, normal versus abnormal ARI in DCM hearts, normal versus abnormal approximate of the MAP in ICM hearts, normal versus abnormal ARI in ICM hearts, healthy versus scar regions in ICM hearts and normal versus abnormal DVDT in ICM hearts. The trained dictionary cross-validated results were 81.80%, 71.43%, 75.18%, 70.49%, 67.51%, 70.19%, and 73.77%, respectively. The outcome of the dictionary learning indicate that there exists signal structures within the arrhythmic electrogram that could be used to infer the APP characteristics of the heart, which will provide clinicians with valuable insight and feedback on the VA. Another important contribution of this dissertation is the development of a DSS that can be

164

used to automate the analysis of the electrograms and assist clinicians in diagnosing VA. The DSS consisted of a combination of time-specific events models and time-averaged general models. The time-specific event-based model used the approximated RMS of the EAV structure as well as the approximate FD of the residual IF to label the electrograms. This was separated into two stages: The first stage labeled the electrogram as PS or non-PS using the residual IF and a neural network and the second stage labeled the PS electrograms as rotor PS or non-rotor PS events. The cross-validated accuracy for stage 1 was 80.77% and the cross-validated accuracy for stage 2 was 76.09%. Additionally, 5 computer-simulated rotor models were also generated and tested on the time-specific event-based model. An electrogram in the vicinity of a rotor and one electrogram away from the rotor were extracted from each simulation. The EAV and residual structures were obtained using the EAV MP decomposition to highlight the approximated RMS of the EAV and the approximated FD features for the simulated electrograms. The simulated electrograms were labeled correctly (100%) by the Stage 1 time-specific event model. The rotor simulated electrograms had an average accuracy of 60% in the Stage 2 time-specific event model. The APP characteristics of the rotor simulation also resembled what was observed for the rotor event in the retrospective database. The two-stage time-specific event model successfully crated a DSS that used the electrogram signal structure to label the rotor event. The objective of the time-averaged general model was to provide the clinician with a DSS to infer the APP characteristics based on the signal features and discriminatory dictionary elements. The specific APP characteristic were the type of cardiomyopathy, normal versus abnormal approximate of the MAP in DCM hearts, normal versus abnormal ARI in DCM hearts, normal versus abnormal approximate of the MAP in ICM hearts, normal versus abnormal ARI in ICM hearts, healthy versus scar regions in ICM hearts and normal versus abnormal DVDT in ICM hearts. The time-averaged general model was also separated into two stages. The first stage used the arrhythmia organization signal feature with the LSCKSVD output parameter for the cardiomyopathy to label the electrograms as either DCM or ICM. The cross validated accuracy for stage 1 was 85.90%. The second stage of the time-averaged general DSS then further sub-classified the DCM and ICM electrograms. In the time-averaged general models for DCM MAP, the cross validated accuracies

165

for the normal versus abnormal approximate of the MAP in DCM hearts and the normal versus abnormal ARI in DCM hearts were 79.98%, and 78.19%, respectively. The time-averaged general model for ICM consisted of a stage 2 model for ICM MAP, ICM ARI, ICM max voltage, and ICM DVDT. The cross validated accuracies were 75.06%, 66.99%, 74.41%, and 85.78%, respectively. The strength of the stage 1 and stage 2 accuracies in the time-averaged general model indicate that it is possible for the DSS to use the underlying electrogram signal structures to infer the label of the APP characteristics.

6.1.1 Potential Applications
The following are few of the potential applications that can stem from this dissertation. Retrospective Time-Specific Event Analysis of the Arrhythmia Episode The electrogram signal structure presented for the rotor event detection provides a unique approach to track the rotor event with the electrogram. This is unique because identifying the electrogram signal structure does not require multiple electrogram recordings. Therefore, one of the applications can be the retrospective analysis of electrograms for patients who suffer from a VA episode. The electrogram may be recorded when the patient is recovering in the ICU or can be obtained by the ICD. The ICD is placed inside a patient who suffer from reoccurring arrhythmia episodes. The electrograms that are recorded by the ICD during a VA episode can be analyzed by the clinician to determine if the rotor event was present at any of the electrode locations. The electrode locations could also be better strategized for the ICD to record suspected regions that may have a rotor event (e.g. suspected healthy/scar boundary locations). These recorded sited can then be used for future ablation strategies. Retrospective Time-Averaged Characteristic Analysis of the Arrhythmia Episode The identified time-averaged characteristics as well as the LCKSVD trained dictionaries had revealed that it is possible to infer the APP characteristics from the electrogram. By being able to infer the APP characteristics without post-morterm analysis, clinicians can determine or adjust existing therapy options that have already been established for specific sets of APP characteristics. 166

Furthermore, the effectiveness of a therapy option could be analyzed by monitoring the progression of the APP characteristic from abnormal to normal. The ability to infer the APP characteristic from the electrogram can also allow for better regional therapeutic solutions to specifically target abnormal characteristics. Modeling Synthetic Electrograms Based on APP Characteristics Another potential future application would be generating synthetic (computer simulated) models that relate the APP characteristic with the electrogram signal structure. The idea is to provide the clinician with the ability to input a set of APP characteristics that affects the tissue sample, and a combination of electrogram signal structures will be produced to form the electrical activations of the tissue. This can be thought of a reverse model that produces the likely electrogram signal structures based on known APP characteristics. The model can help clinicians to further study the ventricular arrhythmia and help inspire newer treatment options. Another benefit of such a model would be in training future generation of cardiologists.

6.2

Direction for Future Works

The adaptive signal decomposition methods used to extract signal structures focused on a significant event (i.e. rotor). However, there are other events known to occur during an arrhythmia episode, such as a conduction block creating a double potential in the electrogram. With a database that includes more representative VA events, other events could potentially be targeted for adaptive decomposition to better characterize the signal structure. Furthermore, it may also be possible to further analyze the approximated and residual components of the EAV MP decomposition to determine if the may be used to represent other events. Other APP characteristics could also be incorporated to determine if an electrogram structural relationship with the APP characteristic exists. Another potential future work that could stem from this dissertation is extrapolating the identified signal structures in the electrogram to the surface electrocardiogram. The existence of a model (known as the forward problem in cardiac electrophysiology [126]) relates the electrogram activation on the surface of the heart to the non-invasive electrical activations of the electrocardiogram. 167

Therefore, projecting the electrogram signal structures to the electrocardiograms will be another possible direction that will be of benefit to the clinical community. The adaptive signal decomposition and LCKSVD dictionary learning had revealed that a relationship between the electrogram signal structure and the events/APP characteristics exists, which was the objective set out for this dissertation. The DSS was developed to automate the ability to infer the events/APP characteristics so that it could be used to assist clinicians in diagnosing VA. It is our hope that the identification of electrogram signal structures can provide further insight into understanding ventricular arrhythmias, which may in turn help identify more electrogram signal structures that can then be used to expand the the DSS. The ideal end goal of this work is to be able to fully characterize the events and APP characteristics of the heart with signal structures from the electrogram in the hope of easily diagnosing VA and limiting the number of sudden cardiac deaths, for which this dissertation has created the foundation.

168

Appendix A Appendix A: EAV MP Decomposition Proof

T

HE EAV based MP decomposition discussed in Section 3.5.2 had presented the decomposition that extracted the amplitude variations, with the residual being a sinusoid with no

varying amplitude components. The proof of this will be given in this chapter of the appendix. Consider the general sinusoidal modulated signal (provided again in Equation A.1).

fM (n) = AC sin(C (n)) + (AE sin(E (n)))(sin(C (n)))

(A.1)

The term AE refers to the envelope amplitude in an amplitude modulated signal and the term AC refers to the carrier amplitude. For the general modulated signal in Equation 3.5, the C and E are the carrier and envelope phases respectively, which is a function of time. Before proceeding into the proof, Equation A.1 can be expanded using the trigonometric identity given in Equation A.2 [97].

2sin(1 )sin(2 ) = cos(1 - 2 ) - cos(1 + 2 ) Therefore, Equation A.1 can be rewritten as Equation A.3.

(A.2)

fM (n) = AC sin(C (n)) +

AE AE cos(C (n) - E (n)) - cos(C (n) + E (n)) 2 2

(A.3)

The next step is to determine the magnitude (My (n)) of the analytic signal (yfM (n)). Recall the Hilbert transform can be used to determine the complex component for any real signal. The 169

Hilbert transform for a sinusoid is a 90 deg shift in phase [127]. Therefore the complex component for Equation A.3 can be given by Equation A.4.

H (fM (n)) = -AC cos(C (n)) +

AE AE sin(C (n) - E (n)) - sin(C (n) + E (n)) (A.4) 2 2

Combining the Equations A.3 and A.4 creates the analytic signal (yfM (n)) given by Equation A.5. yfM (n) = fM (n) + iH (f (n)) = AC sin(C (n)) - iAC cos(C (n)) (A.5) AE AE cos(C (n) - E (n)) + i sin(C (n) - E (n)) + 2 2 AE AE - cos(C (n) + E (n)) - i sin(C (n) + E (n)) 2 2 Equation A.5 was rearranged to keep the real and complex terms together in each line of the equation. Next, using the trigonometric identities in Equation A.2 and A.6, it is possible to simplify the second and third lines of Equation A.5 to give Equation A.7.

2cos(1 )sin(2 ) = sin(1 + 2 ) - sin(1 - 2 ) yfM (n) = AC sin(C (n)) - iAC cos(C (n)) + AE sin(C (n))sin(E (n)) - iAE cos(C (n))sin(E (n))

(A.6)

(A.7)

The next step is to factor out the common components from the first and second line in Equation A.7. This will produce the formulation given by Equation A.8.

yfM (n) = [AC + AE sin(E (n))]Ã[sin(C (n)) - icos(C (n))]

(A.8)

From this equation it is possible to note that there are two components (each denoted by its own set of square brackets). It is easy to show that the first square bracket is the envelope amplitude variation by converting the second component complex number to polar form. Consider the following equation (Equation A.9) to convert the sine and cosine complex number into an exponential. 170

sin() - icos() =

e i - e - i e i + e - i -i 2i 2 e - i e i e - i e i +i -i -i = -i 2 2 2 2 i = -ie

(A.9)

Therefore, we can rewrite Equation A.8 into a polar form given by Equation A.10.

yfM (n) = [AC + AE sin(E (n))]Ã[-ieC (n) ]

(A.10)

The first component in the polar form of a signal is the magnitude of the analytical signal, while the second component refers to the phase of the analytical signal. The EAV decomposition uses a criterion function that selects an atom at a given iteration that will minimize the magnitude of the analytical signal. Therefore, as the iteration  approaches infinity, the residual produced as a result of the EAV based MP decomposition will have the form given by Equation A.11.

Rinf fM (n) = [sin(C (n)) - icos(C (n))] = [-ieC (n) ]

(A.11)

This proof shows that a synthetically generated amplitude modulated sinusoid could be segregated into the amplitude and frequency modulation component. Though this process is straight forward when considering the amplitude modulated sinusoid, this can be extended to electrograms during VF. For the cases of electrograms during VF, as the iteration  approaches infinity using the EAV MP, the residual's frequency could be time-varying with the envelope variation approaching zero.

171

Appendix B Appendix B: Weights and Bias for the Decision-Support System

T

HE DSS comprised of multiple four layer neural networks. The number of neurons for the input and first hidden layer were varied for each DSS. The second hidden layer and the

output layer had 2 and 1 neurons respectively. Based on this network architecture, the general model can be written by Equation B.1. The first hidden layer modeling function was the sigmoid function (given by Equation B.2) [128].

2

h

d

z=

(M Fi3 ((
i3 =1 i2 =1

i3 i2 M Fi2 ((
i1 =1

i2 i1 xi1 ) + i1 0 )) + i2 0 ) + i3 0 )

(B.1)

M F i2 =

1 1 + e -x

(B.2)

Given these models, the final bias and weights from the cross validated cases was determined. Since there was be a single set of weights for each of the neural network models, the weights and bias values were averaged and presented for each of the model.

B.1 Weights and Bias for Time-Specific Event Model
The time-specific model presented in Chapter 5 was broken into two stages. The first stage had modeled the residual IF feature in order to label the electrogram as PS or non-PS electrogram.

172

The second stage of the model was used to label the PS electrograms as rotor or non-rotor using the approximated RMS on the EAV structure. These models with their corresponding weights are presented in this section.

B.1.1 Stage 1: PS vs. Non-PS Model
The DSS used for this stage was a neural network with 1 neuron in the input layer, 2 neurons in the first hidden layer, 2 neurons in the second hidden layer and 1 output neuron. The number of weights between the input and first hidden layer was 2, with 2 bias values for each of the hidden layer neurons. The average weight and bias between the input and first hidden layer is presented in Table B.1. The rows represent the neurons for the first hidden layer (referred to as HL1) while the columns represent the neuron for the input layer as well as the bias values. Table B.1: Stage 1 Average Weight and Bias Between Input and First Hidden Layer Weight Residual IF Feature -60.96 -22.28 Bias 1.91 0.06

HL1 Neuron 1 HL1 Neuron 2

The average weight and bias between the first (HL1) and second (HL2) hidden layers is given in Table B.2. The rows represents the neurons for the second hidden layer and the columns are the average weights for the first hidden layer and bias for the second hidden layer. There were a total of 4 (2Ã2) weights and 2 bias values. Table B.2: Stage 1 Average Weight and Bias Between First and Second Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 -0.24 -0.37 -0.02 0.63 Bias 0.15 -0.34

HL2 Neuron 1 HL2 Neuron 2

Lastly, the average weight and bias between the second hidden layer (HL2) and the output layer is provided by Table B.3. The row represents the output layer neuron and the columns are the 173

average weight for the second hidden layer neurons and the bias for the output layer. There were a total of 2 weights and 1 bias value. Table B.3: Stage 1 Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 -0.81 -0.40 Bias 0.56

Output Neuron

Considering that the input was only a single feature, the weights and bias simply highlight the non-linear relationship between the feature and the label. The large weight factors prior to the first hidden layer may be indicative that there is a degree of non-linearity in the feature space for PS versus non-PS electrograms, which the large weight values amplify prior to entering the sigmoid function in the first hidden layer. This could also be visually observed from the boxplot in Figure 3.19. The feature distribution is more widely spread for the PS electrogram cases when compared to the non-PS electrograms.

B.1.2 Stage 2: Rotor vs. Non-Rotor Model
The second stage consisted of labeling the PS electrograms as rotor or non-rotor. The model was a neural network with 1 neuron in the input layer, 2 neurons in the first hidden layer, 2 neurons in the second hidden layer and 1 output neuron. Table B.4 presents the weights and bias values between the input layer and the first hidden layer (HL1). The input feature used for this model was the approximated EAV RMS. Table B.4: Stage 2 Average Weight and Bias Between Input and First Hidden Layer Weight Approximated EAV RMS -0.30 -0.19 Bias -0.03 -0.05

HL1 Neuron 1 HL1 Neuron 2

Next, Table B.5 provides the average weight and bias between the first (HL1) and second (HL2) hidden layers as well as the bias values for the second hidden layer. 174

Table B.5: Stage 2 Average Weight and Bias Between First and Second Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 -0.49 -0.13 0.08 0.35 Bias -0.01 -0.01

HL2 Neuron 1 HL2 Neuron 2

Lastly, the values provided by Table B.6 are the average weight and bias between the second hidden layer (HL2) and the output layer. Table B.6: Stage 2 Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 0.08 0.07 Bias 0.72

Output Neuron

Considering that the input was only a single feature, the weights and bias simply highlight the non-linear relationship between the feature and the label. The relatively lower weights (compared to stage 1) may be indicative that the feature is more linear, for which the lower weights will restrict the range on the sigmoid function. The linearity of the feature can be observed in the boxplot from Figure 3.20.

B.2 Weights and Bias for Time-Averaged Model
The time-averaged models from chapter 5 were used to label the electrograms based on the type of cardiomyopathy and then another subcategory depending on the type of cardiomyopathy. The subcategory for the DCM electrograms were DCM MAP normal or abnormal and DCM ARI normal or abnormal, while the subcategories for the ICM hearts were ICM MAP normal or abnormal, ICM ARI normal or abnormal, ICM healthy or Scar, and ICM DVDT normal or abnormal. The following subsections will present the average weights and bias values from the cross validated models.

175

B.2.1 Time-Averaged General Model: Cardiomyopathy
The model architecture was 3 neurons for the input layer, 6 neurons for the first hidden layer, 2 neurons for the second hidden layer and 1 neuron for the output layer. The weights and bias values in Table B.7 are for the parameters between input layer and the first hidden layer (HL1). The input features were the arrhythmia organization (AO), the sparse code product for DCM (F inal,CM DCM ), and the sparse code product for ICM (F inal,CM ICM ). Table B.7: Cardiomyopathy Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 AO -5.70 -3.47 0.90 1.16 -3.25 1.03
[W ] F inal,CM DCM [W ] F inal,CM ICM [W ] [W ]

Bias 0.71 -4.02 -4.06 -0.01 -10.07 16.63 -1.51 10.34 5.85 3.04 5.18 -4.14

-6.90 -2.86 0.25 -2.82 16.13 11.73

Next, the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer is given in Table B.8. Table B.8: Cardiomyopathy Model Average Weight and Bias Between First and Second Hidden Layer Weight HL1 N3 HL1 N4 -0.54 0.45 0.16 -1.53 Bias HL1 N5 -0.36 0.15 HL1 N6 -0.35 -0.05 -0.29 0.27

HL2 Neuron 1 HL2 Neuron 2

HL1 N1 -0.31 1.51

HL1 N2 0.64 -0.08

The values for the average weight and bias between the second hidden layer (HL2) and the output layer are provided in Table B.9.

176

Table B.9: Cardiomyopathy Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 0.96 1.26 Bias 0.58

Output Neuron

B.2.2 Time-Averaged General Model: DCM MAP
The number of neurons for the 4 layer network was 3, 6, 2, and 1 respectively. The weights and bias values between the input layer and the first hidden layer (HL1) is given by Table B.10. The input features were the Residual IF STD, the sparse code product for DCM MAP normal (F inal,DCM M N ), and the sparse code product for DCM MAP abnormal (F inal,DCM M A ). Table B.10: DCM MAP Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 Residual IF STD 291.03 194.57 53.99 50.24 55.75 -30.96
[W ] F inal,DCM M N [W ] F inal,DCM M A [W ] [W ]

Bias 44.18 18.01 9.65 -21.86 24.14 16.89 -10.49 5.16 -14.06 57.23 -26.50 -19.70

-32.72 -24.61 8.05 -21.68 15.25 4.49

Table B.11 provides the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Table B.11: DCM MAP Model Average Weight and Bias Between First and Second Hidden Layer Weight HL1 N3 HL1 N4 -1.80 3.01 0.04 1.18 Bias HL1 N5 -1.53 0.82 HL1 N6 -0.70 -1.90 1.47 0.49

HL2 Neuron 1 HL2 Neuron 2

HL1 N1 3.64 2.43

HL1 N2 -3.04 -3.07

The average weight and bias between the second hidden layer (HL2) and the output layer is given by Table B.12. 177

Table B.12: DCM MAP Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 10.22 -4.29 Bias 0.31

Output Neuron

B.2.3 Time-Averaged General Model: DCM ARI
The 4 layers of the network had 3, 6, 2, and 1 neurons respectively. The weights and bias values between the input layer and the first hidden layer (HL1) is given by Table B.13. The input features were the Residual IF STD, the sparse code product for DCM ARI normal (F inal,DCM AN ), and the sparse code product for DCM MAP abnormal (F inal,DCM AA ). Table B.13: DCM ARI Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 Residual IF STD 14.55 9.73 2.70 2.51 2.79 -1.55
[W ] F inal,DCM AN [W ] F inal,DCM AA [W ] [W ]

Bias 2.21 0.90 0.48 -1.09 1.21 0.84 5.37 -0.23 -0.25 27.29 26.61 -0.70

-1.64 -1.23 0.40 -1.08 0.76 0.22

Table B.14 provides the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Table B.14: DCM ARI Model Average Weight and Bias Between First and Second Hidden Layer Weight HL1 N3 HL1 N4 -0.09 0.15 0.00 0.06 Bias HL1 N5 -0.08 0.04 HL1 N6 -0.03 -0.10 -0.33 1.75

HL2 Neuron 1 HL2 Neuron 2

HL1 N1 0.18 0.12

HL1 N2 -0.15 -0.15

The average weight and bias between the second hidden layer (HL2) and the output layer is given by Table B.15. 178

Table B.15: DCM ARI Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 0.51 -0.21 Bias 0.40

Output Neuron

B.2.4 Time-Averaged General Model: ICM MAP
The time-averaged ICM MAP model had 5, 10, 2, and 1 respectively for the 4 layer network. Table B.16 presents the weights and bias values between the input and first hidden layer. The input features were the DF, energy captured by local pattern 2 (LP2), arrhythmia organization (AO), the sparse code product for ICM MAP normal (F inal,ICM M N ), and the sparse code product for ICM MAP abnormal (F inal,ICM M A ). Table B.16: ICM MAP Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 HL1 Neuron 7 HL1 Neuron 8 LP2 3.81 3.77 -23.99 24.18 8.00 9.21 3.93 10.85 AO -1.02 -0.26 0.02 0.97 2.44 -0.29 -1.37 1.55
[W ] F inal,ICM M N [W ] F inal,ICM M A [W ] [W ]

Bias 3.51 8.41 -2.45 -1.82 0.65 -8.21 -0.48 5.57 -9.52 -2.79 4.91 -0.88 -0.57 3.86 -19.38 -5.71

-0.14 -8.56 2.24 -7.42 -6.13 -3.64 -2.27 3.57

Table B.17 presents the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Table B.17: ICM MAP Model Average Weight and Bias Between First and Second Hidden Layer
HL1 N1 1.41 -0.22 HL1 N2 -0.73 0.24 HL1 N3 -0.64 -0.11 Weight HL1 N4 HL1 N5 -0.48 -0.99 0.18 2.30 Bias HL1 N6 1.26 -0.92 HL1 N7 -0.69 0.66 HL1 N8 0.45 0.39 0.30 -1.51

HL2 N1 HL2 N2

179

Table B.18 presents the average weight and bias between the second hidden layer (HL2) and the output layer. Table B.18: ICM MAP Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 -0.81 -5.87 Bias 0.62

Output Neuron

B.2.5 Time-Averaged General Model: ICM ARI
The time-averaged ICM ARI model had 5, 10, 2, and 1 respectively for the 4 layer network. The weights and bias values between the input and first hidden layer are presented in Table B.19. The input features were the DF, energy captured by local pattern 2 (LP2), arrhythmia organization (AO), the sparse code product for ICM ARI normal (F inal,ICM M N ), and the sparse code product for ICM MAP abnormal (F inal,ICM AA ). Table B.19: ICM ARI Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 HL1 Neuron 7 HL1 Neuron 8 LP2 7.37 0.39 32.82 -15.93 -35.31 -12.38 51.83 12.76 AO -0.60 1.76 -1.50 0.33 -2.69 -0.63 0.75 -0.77
[W ] F inal,ICM AN [W ] F inal,ICM AA [W ] [W ]

Bias 1.07 -5.40 1.50 -4.29 -9.21 0.40 6.28 11.71 -0.40 2.25 -7.07 -4.88 14.86 6.14 -17.75 -14.57

2.05 5.42 -10.82 -1.05 0.12 1.16 2.44 -1.49

Table B.20 presents the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Table B.21 presents the average weight and bias between the second hidden layer (HL2) and the output layer. 180

Table B.20: ICM ARI Model Average Weight and Bias Between First and Second Hidden Layer
HL1 N1 0.48 Â­0.23 HL1 N2 0.32 0.09 HL1 N3 -0.63 1.61 Weight HL1 N4 HL1 N5 1.04 -1.63 -0.41 0.41 Bias HL1 N6 0.13 0.62 HL1 N7 0.65 0.74 HL1 N8 -0.55 -1.64 0.08 -0.47

HL2 N1 HL2 N2

Table B.21: ICM ARI Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 1.56 0.12 Bias 0.21

Output Neuron

B.2.6 Time-Averaged General Model: ICM Vol
The 4 layer network for the time-averaged ICM Vol model had 4, 8, 2, and 1 neurons for each layer respectively. The weights and bias values between the input and first hidden layer is given in Table B.22. The input features were the energy capture by local pattern 1 (LP1), energy captured by local pattern 3 (LP3), the sparse code product for ICM Healthy (F inal,ICM V H ), and the sparse code product for ICM Scar (F inal,ICM V S ). Table B.22: ICM Vol Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 HL1 Neuron 7 HL1 Neuron 8 LP1 0.92 -5.66 -11.63 -11.80 -1.88 36.58 -0.58 3.71 LP3 30.79 0.70 -12.77 3.66 4.77 12.29 20.53 12.74 F inal,ICM V H -21.07 0.07 1.74 8.00 -1.55 1.11 14.84 -0.79 F inal,ICM V S -13.29 39.99 13.40 3.85 -10.91 -14.41 4.45 -2.60 Bias 10.30 -2.26 10.88 4.82 -1.41 -13.19 -21.73 -1.75

Table B.23 provides the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Lastly, Table B.24 presents the average weight and bias between the second hidden layer (HL2) 181

Table B.23: ICM Vol Model Average Weight and Bias Between First and Second Hidden Layer
Weight HL1 N4 HL1 N5 1.42 -2.00 1.22 0.03 Bias HL1 N6 -1.60 -2.36 HL1 N7 2.79 4.90 HL1 N8 0.65 -0.07 -2.07 -1.59

HL2 N1 HL2 N2

HL1 N1 -0.50 -2.19

HL1 N2 -0.19 0.67

HL1 N3 2.81 0.61

and the output layer. Table B.24: ICM Vol Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 -0.80 1.20 Bias 0.24

Output Neuron

B.2.7 Time-Averaged General Model: ICM DVDT
The time-averaged ICM DVDT model had 4, 8, 2, and 1 neurons respectively for each layer of the network. The weights and bias values between the input and first hidden layer is given in Table B.25. The input features were the energy capture by local pattern 1 (LP1), energy captured by local pattern 3 (LP3), the sparse code product for ICM DVDT (F inal,ICM DV DT N ), and the sparse code product for ICM DVDT abnormal (F inal,ICM DV DT A ). Table B.25: ICM DVDT Model Average Weight and Bias Between Input and First Hidden Layer Weight HL1 Neuron 1 HL1 Neuron 2 HL1 Neuron 3 HL1 Neuron 4 HL1 Neuron 5 HL1 Neuron 6 HL1 Neuron 7 HL1 Neuron 8 LP2 -127.86 -17.23 -11.84 -1.48 -42.68 -1.53 15.52 16.41 LP3 -27.45 19.77 10.80 -0.59 -53.10 6.15 -0.61 11.59 F inal,ICM DV DT N 15.85 -2.79 56.94 7.96 -49.42 -2.87 1.71 -29.89 F inal,ICM DV DT A -25.47 17.86 -19.55 -2.14 27.22 0.41 0.89 8.46 Bias -13.52 5.07 -25.71 -3.19 17.83 -0.60 1.84 5.89

182

Table B.26 provides the average weight and bias between the first (HL1) and second (HL2) hidden layers and the bias values for the second hidden layer. Table B.26: ICM DVDT Model Average Weight and Bias Between First and Second Hidden Layer
Weight HL1 N4 HL1 N5 -0.34 -1.58 0.96 -1.70 Bias HL1 N6 1.67 -0.56 HL1 N7 -4.16 2.28 HL1 N8 1.84 2.86 -0.35 -3.03

HL2 N1 HL2 N2

HL1 N1 -0.62 0.59

HL1 N2 2.03 0.84

HL1 N3 0.77 0.37

Lastly, Table B.27 presents the average weight and bias between the second hidden layer (HL2) and the output layer. Table B.27: ICM DVDT Model Average Weight and Bias Between Second Hidden and Output Hidden Layer Weight HL2 Neuron 1 HL2 Neuron 2 8.74 -7.29 Bias 0.63

Output Neuron

183

Bibliography
[1] S. Mallat. A wavelet tour of signal processing. 2009. [2] K. Balasundaram, K. Umapathy, J. Jeyaratnam, A. Niri, S. MassÂ´ e, T. Farid, K. Nair, J. Asta, R.J. Cusimano, E. Vigmond, and K. Nanthakumar. Tracking rotors with minimal electrodes: Modulation index based strategy. Circulation: Arrhythmia and Electrophysiology, pages CIRCEPÂ­114, 2015. [3] H.V. Huikuri, A. Castellanos, and R.J. Myerburg. Sudden death due to cardiac arrhythmias. New England Journal of Medicine, 345(20):1473Â­1482, 2001. [4] R. Virmani, A. P. Burke, and A. Farb. Sudden cardiac death. Cardiovascular pathology, 10(5):211Â­218, 2001. [5] A.C. Guyton and J.E. Hall. Textbook of Medical Physiology. Saunders Elsevier, Philadelphia, PA, 2011. [6] H. Swan, K. Piippo, M. Viitasalo, P. HeikkilÂ¨ a, T. Paavonen, K. Kainulainen, J. Kere, P. Keto, K. Kontula, and L. Toivonen. Arrhythmic disorder mapped to chromosome causes malignant polymorphic ventricular tachycardia in structurally normal hearts. Journal of the American College of Cardiology, 34(7):2035Â­2042, 1999. [7] B.L. Wilkoff, V. Kuhlkamp, K. Volosin, K. Ellenbogen, B. Waldecker, S. Kacet, J.M. Gillberg, and C.M. DeSouza. Critical analysis of dual-chamber implantable cardioverterdefibrillator arrhythmia detection: results and technical considerations. 103(3):381, 2001. 184 Circulation,

[8] M.S. Wathen, P.J. DeGroot, M.O. Sweeney, A.J. Stark, M.F. Otterness, W.O. Adkisson, R.C. Canby, K. Khalighi, C. Machado, D.S. Rubenstein, and K.J. Volosin. Prospective randomized multicenter trial of empirical antitachycardia pacing versus shocks for spontaneous rapid ventricular tachycardia in patients with implantable cardioverter-defibrillators pacing fast ventricular tachycardia reduces shock therapies (painfree rx ii) trial results. Circulation, 110(17):2591Â­2596, 2004. [9] J. Jeyaratnam, K. Umapathy, S. Masse, K. Nair, T. Farid, S. Krishnan, and K. Nanthakumar. Relating spatial heterogeneities to rotor formation in studying human ventricular fibrillation. In Engineering in Medicine and Biology Society, EMBC, 2011 Annual International Conference of the IEEE, pages 231Â­234. IEEE, 2011. [10] R. Coronel, J.M.T. de Bakker, F.J.G. Wilms-Schopman, T. Opthof, A.C. Linnenbank, C.N. Belterman, and M.J. Janse. Monophasic action potentials and activation recovery intervals as measures of ventricular action potential duration: experimental evidence to resolve some controversies. Heart Rhythm, 3(9):1043Â­1050, 2006. [11] C.J. McLeod, W.K. Shen, R.F. Rea, P.A. Friedman, D.L. Hayes, A. Wokhlu, T.L. Webster, H.J. Wiste, D.O. Hodge, D.J. Bradley, and S.C. Hammil. Differential outcome of cardiac resynchronization therapy in ischemic cardiomyopathy and idiopathic dilated cardiomyopathy. Heart Rhythm, 8(3):377Â­382, 2011. [12] P. JaÂ¨ is, P. Maury, P. Khairy, F. Sacher, I. Nault, Y. Komatsu, M. Hocini, A. Forclaz, A.S. Jadidi, R. Weerasooryia, and A. Shah. Elimination of local abnormal ventricular activities: a new end point for substrate modification in patients with scar-related ventricular tachycardia. Circulation, 2012. [13] S. Boudina and E.D. Abel. Diabetic cardiomyopathy, causes and effects. Reviews in Endocrine and Metabolic Disorders, 11(1):31Â­39, 2010. [14] J.L. Jefferies and J.A. Towbin. Dilated cardiomyopathy. The Lancet, 375(9716):752Â­762, 2010. 185

[15] G. Stix, M. Borggrefe, C. Wolpert, G. Hindricks, H. Kottkamp, D. BÂ¨ ocker, T. Wichter, Y. Mika, S. Ben-Haim, D. Burkhoff, and M. Wolzt. Chronic electrical stimulation during the absolute refractory period of the myocardium improves severe heart failure. European heart journal, 25(8):650Â­655, 2004. [16] M.L. Koller, M.L. Riccio, and R.F. Gilmour Jr. Dynamic restitution of action potential duration during electrical alternans and ventricular fibrillation. American Journal of PhysiologyHeart and Circulatory Physiology, 275(5):H1635Â­H1642, 1998. [17] H. Qin, M.W. Kay, N. Chattipakorn, D.T. Redden, R.E. Ideker, and J.M. Rogers. Effects of heart isolation, voltage-sensitive dye, and electromechanical uncoupling agents on ventricular fibrillation. American Journal of Physiology-Heart and Circulatory Physiology, 284(5):H1818Â­H1826, 2003. [18] A.E. Buxton, K.L. Lee, G.E. Hafley, D.G. Wyse, J.D. Fisher, M.H. Lehmann, L.A. Pires, M.R. Gold, D.L. Packer, M.E. Josephson, and E.N. Prystowsky. Relation of ejection fraction and inducible ventricular tachycardia to mode of death in patients with coronary artery disease an analysis of patients enrolled in the multicenter unsustained tachycardia trial. Circulation, 106(19):2466Â­2472, 2002. [19] J.P. Bourke, T. Hawkins, P. Keavey, M. Tynan, S. Jamieson, R. Behulova, and S.S. Furniss. Evolution of ventricular function during permanent pacing from either right ventricular apex or outflow tract following av-junctional ablation for atrial fibrillation. Europace, 4(3):219Â­ 228, 2002. [20] J.L. Bonnes, J. Thannhauser, J. Nas, S.W. Westra, R.M.G. Jansen, G. Meinsma, M.J. de Boer, J.L.R.M. Smeets, W. Keuper, and M.A. Brouwer. Ventricular fibrillation waveform characteristics of the surface ecg: Impact of the left ventricular diameter and mass. Resuscitation, 115:82Â­89, 2017. [21] A. Arenal, S. del Castillo, E. Gonzalez-Torrecilla, F. Atienza, M. Ortiz, J. Jimenez, A. Puchol, J. GarcÂ´ ia, and J. Almendral. Tachycardia-related channel in the scar tissue in patients 186

with sustained monomorphic ventricular tachycardias. Circulation, 110(17):2568Â­2574, 2004. [22] R.C. Saumarez, M. Pytkowski, M. Sterlinski, J.P. Bourke, J.R. Clague, S.M. Cobbe, D.T. Connelly, M.J. Griffith, P.P. McKeown, K. McLeod, and J.M. Morgan. Paced ventricular electrogram fractionation predicts sudden cardiac death in hypertrophic cardiomyopathy. European heart journal, 29(13):1653Â­1661, 2008. [23] F.G. Evans, J.M. Rogers, W.M. Smith, and R.E. Ideker. Automatic detection of conduction block based on time-frequency analysis of unipolar electrograms. Biomedical Engineering, IEEE Transactions on, 46(9):1090Â­1097, 1999. [24] K. Umapathy, S. Masse, E. Sevaptsidis, J. Asta, H. Ross, N. Thavandiran, K. Nair, T. Farid, R. Cusimano, J. Rogers, et al. Regional frequency variation during human ventricular fibrillation. Medical engineering & physics, 31(8):964Â­970, 2009. [25] W. Hsu, Y. Lin, J.E. Heil, J. Jones, and D.J. Lang. Effect of shock timing on defibrillation success. Pacing and clinical electrophysiology, 20(1):153Â­157, 1997. [26] P. Schoene, J. Coult, L. Murphy, C. Fahrenbruch, J. Blackwood, P. Kudenchuk, L. Sherman, and T. Rea. Course of quantitative ventricular fibrillation waveform measure and outcome following out-of-hospital cardiac arrest. Heart Rhythm, 11(2):230Â­236, 2014. [27] D. Hidano, J. Coult, J. Blackwood, C. Fahrenbruch, H. Kwok, P. Kudenchuk, and T. Rea. Ventricular fibrillation waveform measures and the etiology of cardiac arrest. Resuscitation, 109:71Â­75, 2016. [28] E.F. Treo, D.O. Cervantes, and E.J. Ciaccio. Automated detection and mapping of electrical activation when electrogram morphology is complex. Biomedical Signal Processing and Control, 8(1):41Â­49, 2013. [29] E.J. Ciaccio, J. Coromilas, A.L. Wit, and H. Garan. Onset dynamics of ventricular tachyarrhythmias as measured by dominant frequency. Heart Rhythm, 8(4):615Â­623, 2010. 187

[30] K.H. Ten Tusscher, A. Mourad, MP Nash, R.H. Clayton, C.P. Bradley, D.J. Paterson, R. Hren, M. Hayward, A.V. Panfilov, and P. Taggart. Organization of ventricular fibrillation in the human heart: experiments and models. Experimental physiology, 94(5):553, 2009. [31] S. MassÂ´ e, E. Downar, V. Chauhan, E. Sevaptsidis, and K. Nanthakumar. Ventricular fibrillation in myopathic human hearts: mechanistic insights from in vivo global endocardial and epicardial mapping. American Journal of Physiology-Heart and Circulatory Physiology, 292(6):H2589Â­H2597, 2007. [32] F.H. Samie, O. Berenfeld, J. Anumonwo, S.F. Mironov, S. Udassi, J. Beaumont, S. Taffet, A.M. Pertsov, and J. Jalife. Rectification of the background potassium current: a determinant of rotor dynamics in ventricular fibrillation. Circulation research, 89(12):1216, 2001. [33] S.P. Thomas, A. Thiagalingam, E. Wallace, P. Kovoor, and D.L. Ross. Organization of myocardial activation during ventricular fibrillation after myocardial infarction. Circulation, 112(2):157Â­163, 2005. [34] S.M. Narayan, D.E. Krummen, K. Shivkumar, P. Clopton, W.J. Rappel, and J.M. Miller. Treatment of atrial fibrillation by the ablation of localized sources. Journal of the American College of Cardiology, 60(7), 2012. [35] K. Balasundaram, S. Masse, K. Nair, and K. Umapathy. Automated signal pattern detection in ecg during human ventricular arrhythmias. In Engineering in Medicine and Biology Society (EMBC), 2013 35th Annual International Conference of the IEEE, pages 1029Â­ 1032. IEEE, 2013. [36] A. Verma, N.F. Marrouche, R.A. Schweikert, W. Saliba, O. Wazni, J. Cummings, A. AbdulKarim, M. Bhargava, J.D. Burkhardt, F. Kilicaslan, and D.O. Martin. Relationship between successful ablation sites and the scar border zone defined by substrate mapping for ventricular tachycardia post-myocardial infarction. Journal of cardiovascular electrophysiology, 16(5):465Â­471, 2005. 188

[37] M. Kao-Wing, S. Yen Ho, P. Kojodjojo, N.S. Peters, D. Davies, and P. Kanagaratnam. Radiofrequency ablation of infarct scar-related ventricular tachycardia: Correlation of electroanatomical data with post-mortem histology. Journal of cardiovascular electrophysiology, 18(12):1330Â­1333, 2007. [38] K. Umapathy, S. Masse, K. Nair, T. Farid, E. Sevaptsidis, J. Asta, H. Ross, R.J. Cusimano, S. Krishnan, and K. Nanthakumar. The relationship of rotors to scar border zones and dominant frequency domains in human ventricular fibrillation, 2010. [39] J. Tian, M.F. Smith, P. Chinnadurai, V. Dilsizian, A. Turgeman, A. Abbo, K. Gajera, C. Xu, D. Plotnick, R. Peters, and M. Saba. Clinical application of pet/ct fusion imaging for threedimensional myocardial scar and left ventricular anatomy during ventricular tachycardia ablation. Journal of Cardiovascular Electrophysiology, 20(6):597Â­604, 2009. [40] T. Dickfeld, J. Tian, G. Ahmad, A. Jimenez, A. Turgeman, R. Kuk, M. Peters, A. Saliaris, M. Saba, S. Shorofsky, and J. Jeudy. Mri-guided ventricular tachycardia ablation integration of late gadolinium-enhanced 3d scar in patients with implantable cardioverter-defibrillators. Circulation: Arrhythmia and Electrophysiology, 4(2):172Â­184, 2011. [41] G. Baroldi, R. Bigi, and L. Cortigiani. Ultrasound imaging versus morphopathology in cardiovascular diseases. myocardial cell damage. Cardiovascular Ultrasound, 3(1):32, 2005. [42] C.A. Beltrami, N. Finato, M. Rocco, G.A. Feruglio, C. Puricelli, E. Cigola, F. Quaini, E.H. Sonnenblick, G. Olivetti, and P. Anversa. Structural basis of end-stage failure in ischemic cardiomyopathy in humans. Circulation, 89:151Â­151, 1994. [43] P.M. Kang and S. Izumo. Apoptosis and heart failure a critical review of the literature. Circulation Research, 86(11):1107Â­1113, 2000. [44] J.M. Bos, J.A. Towbin, and M.J. Ackerman. Diagnostic, prognostic, and therapeutic implications of genetic testing for hypertrophic cardiomyopathy. Journal of the American College of Cardiology, 54(3):201Â­211, 2009. 189

[45] B.J. Maron, J.A. Towbin, G. Thiene, C. Antzelevitch, D. Corrado, D. Arnett, A.J. Moss, C.E. Seidman, and J.B. Young. Contemporary definitions and classification of the cardiomyopathies. Circulation, 113(14):1807Â­1816, 2006. [46] J.T. Jacobson, S. Iwai, and W. Aronow. Management of ventricular arrhythmias in structural heart disease. Postgraduate medicine, 127(5):549Â­559, 2015. [47] N.F. Marrouche, A. Verma, O. Wazni, R. Schweikert, D.O. Martin, W. Saliba, F. Kilicaslan, J. Cummings, J.D. Burkhardt, M. Bhargava, and D. Bash. Mode of initiation and ablation of ventricular fibrillation storms in patients with ischemic cardiomyopathy. Journal of the American College of Cardiology, 43(9):1715Â­1720, 2004. [48] J.J. Goldberger, H. Suba cius, T. Patel, R. Cunnane, and A.H. Kadish. Sudden cardiac death risk stratification in patients with nonischemic dilated cardiomyopathy. Journal of the American College of Cardiology, 63(18):1879Â­1889, 2014. [49] M.G. Tsipouras and D.I. Fotiadis. Automatic arrhythmia detection based on time and timeÂ­frequency analysis of heart rate variability. Computer methods and programs in biomedicine, 74(2):95Â­108, 2004. [50] B.R. Choi, W. Nho, T. Liu, and G. Salama. Life span of ventricular fibrillation frequencies. Circulation research, 91(4):339Â­345, 2002. [51] L. Angrisani, P. Daponte, M. D'apuzzo, and A. Testa. A measurement method based on the wavelet transform for power quality analysis. Power Delivery, IEEE Transactions on, 13(4):990Â­998, 1998. [52] A. Amann, R. Tratnig, and K. Unterkofler. Reliability of old and new ventricular fibrillation detection algorithms for automated external defibrillators. BioMedical Engineering OnLine, 4(60), 2005. [53] F. H. Foomany, K. Umapathy, S. Krishnan, S. Masse, T. Farid, K. Nair, P. Dorian, and K. Nanthakumar. Wavelet-based Markers of Ventricular Fibrillation in Optimizing Human 190

Cardiac Resuscitation. In Conference proceedings:IEEE Engineering in Medicine and Biology Society, pages 2001Â­2004, 2010. [54] K. Umapathy, S. Krishnan, S. Masse, X. Hu, P. Dorian, and K. Nanthakumar. Optimizing cardiac resuscitation outcomes using wavelet analysis. In International Conference of the IEEE Engineering in Medicine and Biology Society, volume 1, pages 6761 Â­ 6764, 2009. [55] J.N. Watson, P.S. Addison, G.R. Clegg, M. Holzer, F. Sterz, and C.E. Robertson. A novel wavelet transform based analysis reveals hidden structure in ventricular fibrillation. Resuscitation, 43(2):121Â­127, 2000. [56] P.S. Addison, J.N. Watson, G.R. Clegg, P.A. Steen, and C.E. Robertson. Finding coordinated atrial activity during ventricular fibrillation using wavelet decomposition. Engineering in Medicine and Biology Magazine, IEEE, 21(1):58Â­65, 2002. [57] H.H. Namarvar and A.V. Shahidi. Cardiac arrhythmias predictive detection methods with wavelet-svd analysis and support vector machines. In Engineering in Medicine and Biology Society, 2004. IEMBS'04. 26th Annual International Conference of the IEEE, volume 1, pages 365Â­368. IEEE, 2004. [58] K. Balasundaram, S. Masse, K. Nair, and K. Umapathy. A classification scheme for ventricular arrhythmias using wavelets analysis. Medical and Biological Engineering and Computing, 51(1-2):153Â­164, 2013. [59] S.G. Mallat and Z. Zhang. Matching pursuits with time-frequency dictionaries. Signal Processing, IEEE Transactions on, 41(12):3397Â­3415, 1993. [60] R. Gribonval. Fast matching pursuit with a multiscale dictionary of gaussian chirps. IEEE Transactions on signal Processing, 49(5):994Â­1001, 2001. [61] K. Umapathy and S. Krishnan. Time-width versus frequency band mapping of energy distributions. Signal Processing, IEEE Transactions on, 55(3):978Â­989, 2007.

191

[62] J.C. Wang, C.H. Lin, B.W. Chen, and M.K. Tsai. Gabor-based nonuniform scale-frequency map for environmental sound classification in home automation. Automation Science and Engineering, IEEE Transactions on, 11(2):607Â­613, 2014. [63] P.J. Durka and K.J. Blinowska. Analysis of eeg transients by means of matching pursuit. Annals of biomedical engineering, 23(5):608Â­611, 1995. [64] O. D. Escoda, L. Granai, M. Lemay, J M. Hernandez, P. Vandergheynst, and J-M Vesin. Ventricular and atrial activity estimation through sparse ecg signal decompositions. In Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on, volume 2, pages IIÂ­II. IEEE, 2006. [65] Y.C. Pati, R. Rezaiifar, and P.S. Krishnaprasad. Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In Signals, Systems and Computers, 1993. 1993 Conference Record of The Twenty-Seventh Asilomar Conference on, pages 40Â­44. IEEE, 1993. [66] R. Rubinstein, M. Zibulevsky, and M. Elad. Efficient implementation of the k-svd algorithm using batch orthogonal matching pursuit. Cs Technion, 40(8):1Â­15, 2008. [67] M.S. Lewicki and T.J. Sejnowski. Learning overcomplete representations. Neural computation, 12(2):337Â­365, 2000. [68] K. Engan, S.O. Aase, and J.H. HusÃ¸y. Multi-frame compression: Theory and design. Signal Processing, 80(10):2121Â­2140, 2000. [69] K. Kreutz-Delgado, J.F. Murray, B.D. Rao, K. Engan, T.W. Lee, and T.J. Sejnowski. Dictionary learning algorithms for sparse representation. Neural computation, 15(2):349Â­396, 2003. [70] S. Lesage, R. Gribonval, F. Bimbot, and L. Benaroya. Learning unions of orthonormal bases with thresholded singular value decomposition. In Acoustics, Speech, and Signal

192

Processing, 2005. Proceedings.(ICASSP'05). IEEE International Conference on, volume 5, pages vÂ­293. IEEE, 2005. [71] M. Aharon, M. Elad, and A. Bruckstein. K -svd: An algorithm for designing overcomplete dictionaries for sparse representation. Signal Processing, IEEE Transactions on, 54(11):4311Â­4322, 2006. [72] Zhuolin Jiang, Zhe Lin, and Larry S Davis. Learning a discriminative dictionary for sparse coding via label consistent k-svd. In Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on, pages 1697Â­1704. IEEE, 2011. [73] G.E.P. Box, J.S. Hunter, and W.G. Hunter. Statistics for experimenters: design, innovation, and discovery, volume 2. Wiley-Interscience New York, 2005. [74] A. Cuevas, M. Febrero, and R. Fraiman. An anova test for functional data. Computational statistics & data analysis, 47(1):111Â­122, 2004. [75] R.O. Duda, P.E. Hart, and D.G. Stork. Pattern classification. 2nd edn wiley. New York, page 632, 2001. [76] O. W. Samuel, G.M. Asogbon, A.K. Sangaiah, P. Fang, and G. Li. An integrated decision support system based on ann and fuzzy ahp for heart failure risk prediction. Expert Systems with Applications, 68:163Â­172, 2017. [77] H. Yan, Y. Jiang, J. Zheng, C. Peng, and Q. Li. A multilayer perceptron-based medical decision support system for heart disease diagnosis. Expert Systems with Applications, 30(2):272Â­281, 2006. [78] I. AsiltÂ¨ urk and M. C Â¸ unkas Â¸. Modeling and prediction of surface roughness in turning operations using artificial neural network and multiple regression method. Expert Systems with Applications, 38(5):5826Â­5832, 2011. [79] H. Goh, J.H. Lim, and C. Quek. Fuzzy associative conjuncted maps network. Neural Networks, IEEE Transactions on, 20(8):1302Â­1319, 2009. 193

[80] B.D. Nearing and R.L. Verrier. Modified moving average analysis of t-wave alternans to predict ventricular fibrillation with high accuracy. Journal of Applied Physiology, 92(2):541Â­ 549, 2002. [81] S.V. Pandit and J. Jalife. Rotors and the dynamics of cardiac fibrillation. Circulation research, 112(5):849Â­862, 2013. [82] O. Berenfeld and H. Oral. The quest for rotors in atrial fibrillation: different nets catch different fishes. Heart rhythm: the official journal of the Heart Rhythm Society, 9(9):1440, 2012. [83] W.J. Rappel and S.M. Narayan. Theoretical considerations for mapping activation in

human cardiac fibrillation. Chaos: An Interdisciplinary Journal of Nonlinear Science, 23(2):023113, 2013. [84] K. Nair, K. Umapathy, T. Farid, S. Masse, E. Mueller, R.V. Sivanandan, K. Poku, V. Rao, V. Nair, J. Butany, and R.E. Ideker. Intramural activation during early human ventricular fibrillation. Circulation: Arrhythmia and Electrophysiology, 4(5):692Â­703, 2011. [85] J. Jalife. The tornadoes of sudden cardiac arrest, 2018. [86] W.B. Hood, J. Joison, R. Kumar, I. Katayama, R.S. Neiman, and J.C. Norman. Experimental myocardial infarction. i. production of left ventricular failure by gradual coronary occlusion in intact conscious dogs. Cardiovascular research, 4(1):73Â­83, 2017. [87] D. Linz, K. Wirth, C. Ukena, F. Mahfoud, J. PÂ¨ oss, B. Linz, M. BÂ¨ ohm, and H.R. Neuberger. Renal denervation suppresses ventricular arrhythmias during acute ventricular ischemia in pigs. Heart Rhythm, 10(10):1525Â­1530, 2013. [88] Y.C. Hsieh, J.C. Lin, C.Y. Hung, C.H. Li, S.F. Lin, H.I. Yeh, J.L. Huang, C.P. Lo, K.l Haugan, B.D. Larsen, and T.J. Wu. Gap junction modifier rotigaptide decreases the susceptibility to ventricular arrhythmia by enhancing conduction velocity and suppressing dis-

194

cordant alternans during therapeutic hypothermia in isolated rabbit hearts. Heart Rhythm, 13(1):251Â­261, 2016. [89] T. EftestÃ¸l, K. Sunde, S.O. Aase, J.H. HusÃ¸y, and P.A. Steen. Predicting outcome of defibrillation by spectral characterization and nonparametric classification of ventricular fibrillation in patients with out-of-hospital cardiac arrest. Circulation, 102(13):1523Â­1529, 2000. [90] E.J. Vigmond, M. Hughes, G. Plank, and L.J. Leon. Computational tools for modeling electrical activity in cardiac tissue. Journal of electrocardiology, 36:69Â­74, 2003. [91] D. Noble and Y. Rudy. Models of cardiac ventricular action potentials: iterative interaction between experiment and simulation. Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 359(1783):1127Â­1142, 2001. [92] R.H. Clayton and A.V. Panfilov. A guide to modelling cardiac electrical activity in anatomically detailed ventricles. Progress in biophysics and molecular biology, 96(1):19Â­43, 2008. [93] R. Bracewell. The Fourier Transform and Its Applications. McGraw Hill, 2000. [94] B. Gold, A.V. Oppenheim, and .M. Rader. Theory and implementation of the discrete hilbert transform. In Presented at the Symposium on Computer Processing in Communications, volume 235, 1969. [95] K. Kohlmann. Corner detection in natural images based on the 2-d hilbert transform. Signal Processing, 48(3):225Â­234, 1996. [96] K. Umapathy, K. Nair, S. Masse, S. Krishnan, J. Rogers, M.P. Nash, and K. Nanthakumar. Phase mapping of cardiac fibrillation. Circulation: Arrhythmia and Electrophysiology, 3(1):105Â­114, 2010. [97] L. Frenzel. Principles of electronic communication systems. McGraw-Hill, Inc., 2007. [98] M. Mas` e, L. Faes, R. Antolini, M. Scaglione, and F. Ravelli. Quantification of synchronization during atrial fibrillation by shannon entropy: validation in patients and computer model of atrial arrhythmias. Physiological measurement, 26(6):911, 2005. 195

[99] J. Lee, D. McManus, and K. Chon. Atrial fibrillation detection using time-varying coherence function and shannon entropy. In Engineering in Medicine and Biology Society, EMBC, 2011 Annual International Conference of the IEEE, pages 4685Â­4688. IEEE, 2011. [100] A.N. Ganesan, P. Kuklik, D.H. Lau, A.G. Brooks, M. Baumert, W.W. Lim, S. Thanigaimani, S. Nayyar, . Mahajan, J.M. Kalman, and K.C. Roberts-Thomas. Bipolar electrogram shannon entropy at sites of rotational activation: implications for ablation of atrial fibrillation. Circulation: Arrhythmia and Electrophysiology, pages CIRCEPÂ­112, 2012. [101] S.S. Chen, D.L. Donoho, and M.A. Saunders. Atomic decomposition by basis pursuit. SIAM review, 43(1):129Â­159, 2001. [102] A. Neurauter, T. EftestÃ¸l, J. Kramer-Johansen, B.S. Abella, K.l Sunde, V. Wenzel, K.H. Lindner, J. EilevstjÃ¸nn, H. Myklebust, P.A. Steen, and H.U. Strohmenger. Prediction of countershock success using single features from multiple ventricular fibrillation frequency bands and feature combinations using neural networks. Resuscitation, 73(2):253Â­263, 2007. [103] S. Krstulovic and R. Gribonval. MPTK: Matching Pursuit made tractable. In Proc. Int. Conf. Acoust. Speech Signal Process. (ICASSP'06), volume 3, pages IIIÂ­496 Â­ IIIÂ­499, Toulouse, France, May 2006. [104] B. MailhÂ´ e, R. Gribonval, F. Bimbot, M. Lemay, P. Vandergheynst, and J.M. Vesin. Dictionary learning for the sparse modelling of atrial fibrillation in ecg signals. In Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on, pages 465Â­468. IEEE, 2009. [105] K. Umapathy, S. Krishnan, V. Parsa, and D.G. Jamieson. Discrimination of pathological voices using a time-frequency approach. Biomedical Engineering, IEEE Transactions on, 52(3):421Â­430, 2005. [106] L. Cohen. Time-frequency distributions-a review. Proceedings of the IEEE, 77(7):941Â­981, 1989. 196

[107] Y. Pantazis, O. Rosec, and Y. Stylianou. Adaptive amÂ­fm signal decomposition with application to speech analysis. IEEE Transactions on Audio, Speech, and Language Processing, 19(2):290Â­300, 2011. [108] K. Balasundaram, S. Masse, T. Farid, K. Nair, J. Asta, R.J. Cusimano, E. Vigmond, K. Nanthakumar, and K. Umapathy. Morphologically constrained signal subspace characterization of electrograms during ventricular fibrillation. Biomedical Signal Processing and Control, 38:379Â­387, 2017. [109] P. Maragos, J.F. Kaiser, and T.F. Quatieri. On separating amplitude from frequency modulations using energy operators. In Acoustics, Speech, and Signal Processing, 1992. ICASSP92., 1992 IEEE International Conference on, volume 2, pages 1Â­4. IEEE, 1992. [110] N.E. Huang, Z. Wu, S.R. Long, K.C. Arnold, X. Chen, and K. Blank. On instantaneous frequency. Advances in adaptive data analysis, 1(02):177Â­229, 2009. [111] R.J. Selvaraj, P. Picton, K. Nanthakumar, S. Mak, and V.S. Chauhan. Endocardial and epicardial repolarization alternans in human cardiomyopathy. Journal of the American College of Cardiology, 49(3):338Â­346, 2007. [112] S.G. Mallat. A wavelet tour of signal processing. Academic Pr, 1999. [113] I. Jekova. Comparison of five algorithms for the detection of ventricular fibrillation from the surface ECG. Physiological measurement, 21:429, 2000. [114] H.U. Strohmenger, K.H. Lindner, and C.G. Brown. Analysis of the ventricular fibrillation ecg signal amplitude and frequency parameters as predictors of countershock success in humans. Chest, 111(3):584Â­589, 1997. [115] K.M. Ropella, J.M. Baerman, AV Sahakian, and S. Swiryn. Differentiation of ventricular tachyarrhythmias. Circulation, 82(6):2035Â­2043, 1990. [116] K. Balasundaram. Analysis of electrocardiograms during human ventricular arrhythmias for optimizing treatment options. Ryerson University, 2012. 197

[117] D. Western, B. Hanson, and P. Taggart. Measurement bias in activation-recovery intervals from unipolar electrograms. American Journal of Physiology-Heart and Circulatory Physiology, 308(4):H331Â­H338, 2014. Â´ and A. Vinet. Estimating atrial action potential [118] E.J. Vigmond, V. Tsoi, Y. Yin, P. PagE, duration from electrograms. IEEE Transactions on Biomedical Engineering, 56(5):1546Â­ 1555, 2009. [119] A.M. Yue, J.R. Paisey, S. Robinson, T.R. Betts, P.R. Roberts, and J.M. Morgan. Determination of human ventricular repolarization by noncontact mapping: validation with monophasic action potential recordings. Circulation, 110(11):1343Â­1350, 2004. [120] C.W. Haws and R.L. Lux. Correlation between in vivo transmembrane action potential durations and activation-recovery intervals from electrograms. effects of interventions that alter repolarization time. Circulation, 81(1):281Â­288, 1990. [121] N. Jackson, S. MassÂ´ e, N. Zamiri, M.A. Azam, P.F.H. Lai, M. Kusha, J. Asta, K. Quadros, B. King, P. Backx, and R.E. Ideker. Mechanisms of long-duration ventricular fibrillation in human hearts and experimental validation in canine purkinje fibers. JACC: Clinical Electrophysiology, 1(3):187Â­197, 2015. [122] C. Ramanathan, P. Jia, R. Ghanem, K. Ryu, and Y. Rudy. Activation and repolarization of the normal human heart under complete physiological conditions. Proceedings of the National Academy of Sciences, 103(16):6309Â­6314, 2006. [123] K. Umapathy, S. Masse, E. Sevaptsidis, J. Asta, S. Krishnan, and K. Nanthakumar. Spatiotemporal frequency analysis of ventricular fibrillation in explanted human hearts. Biomedical Engineering, IEEE Transactions on, 56(2):328Â­335, 2009. [124] B.A. Bart, L.K. Shaw, C.B. McCants, D.F. Fortin, K.L. Lee, R.M. Califf, and C.M. OConnor. Clinical determinants of mortality in patients with angiographically diagnosed ischemic or nonischemic cardiomyopathy. Journal of the American College of Cardiology, 30(4):1002Â­1008, 1997. 198

[125] M.Y. Rafiq, G. Bugmann, and D.J. Easterbrook. Neural network design for engineering applications. Computers & Structures, 79(17):1541Â­1552, 2001. [126] G.T. Lines, M.L. Buist, P. Grottum, A.J. Pullan, J. Sundnes, and A. Tveito. Mathematical models and numerical methods for the forward problem in cardiac electrophysiology. Computing and Visualization in Science, 5(4):215Â­239, 2003. [127] R. Cabot. A note on the application of the hilbert transform to time delay estimation. IEEE Transactions on Acoustics, Speech, and Signal Processing, 29(3):607Â­609, 1981. [128] X. Yin, J. Goudriaan, E.A. Lantinga, J. Vos, and H.J. Spiertz. A flexible sigmoid function of determinate growth. Annals of botany, 91(3):361Â­371, 2003.

199


