   

Intuitive Interaction in a Mixed Reality System  
Shital Desaia*, Alethea Blacklerb, Vesna Popovicc  
a

Queensland University of Technology, Brisbane, Australia  Queensland University of Technology, Brisbane, Australia  c Queensland University of Technology, Brisbane, Australia  *Corresponding author email:  sh.desai@qut.edu.au 
b

Abstract:  Tangible  physical  systems  are  more  intuitive  than  Intangible  virtual  Systems.   Mixed  reality  systems  are  considered  as  an  alternative  to  virtual  systems,  bringing  advantages  of  tangible  systems  into  an  interaction.  However,  past  research  has  mainly  focussed  on  technical  aspects  of  incorporating  pervasiveness  and  immersiveness  in  the  virtual  systems.  This  paper  reports  on  an  empirical  study  of  intuitive  Interaction  in  a  Mixed  Reality  game  system  for  children  and  the  design  aspects  that  could  facilitate  intuitive  Interaction  in  such  systems.  A  related  samples  Friedman's  test  showed  that  the  Mixed  Reality  game  system  demonstrated  more  intuitive  interactions  than  nonintuitive  Interactions.  A  linear  regression  analysis  further  established  that  the  variation  in  intuitive  Interaction  in  the  Mixed  Reality  system  could  be  statistically  significantly  explained  primarily  by  physical  affordances  offered  by  the  Mixed  Reality  system  and  to  a  lesser  extent  by  the  perceived  affordances  in  the  system.  Design  guidelines  to  develop  intuitive  Mixed  Reality  systems  are  discussed.  These  guidelines  should  allow  designers  to  exploit  the  wonders  of  advances  in  technology  and  at  the  same  time  allow  users  to  directly  interact  with  the  physical  real  world.  This  will  allow  users  to  access  maximal  physical  affordances,  which  are  primary  contributors  to  intuitive  interaction  in  Tangible  and  Mixed Reality systems.  Keywords: Intuitive Interaction; Mixed Reality Systems; Tangibles; Child Computer  Interaction 

1. Introduction  
Developments in hardware technologies have driven impressive technological innovations  that let mobile and embedded devices connect to the Web. There is a growing need of  people to be able to benefit from these technological innovations and at the same time be  able to interact with the real world through tangible systems.  

 

 
This work is licensed under a Creative Commons AttributionNonCommercial 4.0  International License.

1 

Shital Desai, Alethea Blackler, Vesna Popovic

Children start interacting with tangibles very early in their childhood. Tangibles help children  develop their sensory capabilities and put them in control of their learning process, enabling  them to learn through personal investigation and exploration (Montessori, 2013). But  children are also familiar with modern technology due to increasing everyday use of  technology for learning at schools (Walden, 2015) and to play games (Danby et al., 2015).  Children are expected to use their past experience and knowledge to play in the virtual  space and physical and tangible properties of the real world in the physical space of the  Mixed Reality system. Tangibles are more intuitive than the intangible virtual elements  (Desai et al., 2015). The coupling between the virtual and physical domains could pose  challenges in traversing the boundary between the two domains in Mixed Reality system.  The question then arises how designers ensure that mixed reality systems still maintain the  intuitiveness of tangible systems.   This research study is an empirical investigation into intuitive interaction in a Mixed Reality  game system and design aspects that could facilitate intuitive interaction in a Mixed Reality  system. 

2. Background 
A Mixed reality system is a user interface where tangible physical elements and intangible  virtual elements coexist in the same environment. Milgram and Kishino (1994) defined  Mixed Reality as being anywhere between the real and virtual environments on the Real Virtual (RV) continuum. The RV continuum can be adapted to discuss Mixed Reality systems  in terms of tangibility and physicality of the system and the source of prior knowledge in  interaction with the system (Figure 1).  At the extreme left end of the continuum (shown in Figure 1) lie tangible systems  representing physical real world associated with interaction using embodied knowledge of  the world, also known as sensorimotor knowledge (Blackler et al., 2010; Desai et al., 2015).  The intangible systems on the other hand lie at the extreme right end of the continuum  representing virtual systems, associated with interaction using experiential knowledge  (Desai et al., 2015).   Over the years, designers saw the need to develop systems that allow users to take  advantage of the technological innovations but at the same time directly interact with the  physical world. The real physical world is either augmented with virtual objects as in  Augmented Reality (Azuma et al., 2001) or the virtual world is augmented with real physical  objects as in Augmented Virtuality (Regenbrecht et al., 2004). The entire paradigm extending  from the tangible to intangible systems is referred to as Mixed Reality Systems.   

2 

Intuitive Interaction in a Mixed Reality System 

  

 Figure 1 Continuum of Tangible and Intangible Systems (adapted from Milgram and Kishino (1994)) 

Mixed Reality systems have found their applications in gaming (Crowle et al., 2014), patient  rehabilitation (Vogiatzaki et al., 2013), visualization of data (Marks et al., 2014), collaborative  coordination in time critical situations (Fischer et al., 2014) and in Education (Gardner and  Elliott, 2014). Efforts to develop Mixed Reality systems for children are more prevalent in  Education and to some extent in gaming, than in any other field. In one of the first examples  of attempts to encourage social interactions in a game, Brederode et al., (2005) developed  pOwerball to bring together children with and without learning disabilities to play a game.  The game consists of tangible objects that are manipulated on a tabletop to control graphic  virtual elements on the tabletop.   Lindgren and JohnsonGlenberg (2013) studied Mixed Reality systems to facilitate embodied  and immersive learning in children and developed Meteor, an interactive system that allows  children to use their body movements to learn about how objects move in space.   Mixed physical virtual environments in a system could affect the intuitiveness of the  tangible physical environment and thus the Mixed Reality system as a whole. Desai et al.  (2015) made an empirical comparison of tangibles and intangibles for intuitive interaction in  children and concluded that tangibles are more intuitive than intangibles. They discussed the  intuitive interaction in tangibles being the result of children using their sensorimotor  knowledge to interact with the tangible system. Intuitive interaction in tangibles is less  complex and the encoding and retrieval of associated sensorimotor knowledge is fast. On  the other hand, we found that intuitive interaction in Intangibles relies primarily on  perceived affordances, derived from prior experience with similar products and features.  Intuitive interaction in intangibles is highly complex and the encoding and retrieval of  associated experiential knowledge is slow.   Mixed reality systems can pose challenges for children as they are interacting with two  interfaces which require knowledge from two different domains. The tendency in the past  has been to look at Mixed Reality systems through the lens of pervasiveness (Fischer et al.,  2014; Gardner and Elliott, 2014; Ricci et al., 2015). Thus the focus has been more on the  technical aspects rather than human centred aspects of design. Attempts have been made  to create immersive environments in virtual environments such as in Capture the Flag social  gaming environment (Cheok et al., 2006) and Holodeck, a Virtual Reality system for  visualisation of scientific data (Marks et al., 2014), instead of maintaining the natural  immersive and intuitive capabilities of the physical environment. These systems are mostly  based on visual perception using visual systems such as Head Mounted Displays (HMD) and 

3

Shital Desai, Alethea Blackler, Vesna Popovic

Cave Automatic Virtual Environment (CAVE) which could have some impact on the  immersiveness and intuitiveness of the Mixed Reality systems.  There is no research that looks into intuitive interaction of Mixed Reality systems and  aspects that could facilitate intuitive interaction. This is important because in an attempt to  allow children to exploit the wonders of technological innovations, designers may end up  developing systems that are nonintuitive. This brings with it problems associated with non intuitive systems such as difficulty in learning which can easily lead to disengagement from  the product.   This research study has thus investigated intuitive interaction in a Mixed Reality game  system with children. Intuitive interaction in tangible physical systems is a result of children  using their sensorimotor knowledge and physical affordances offered by the system and  intuitive interaction in Intangibles relies primarily on perceived affordances. This study thus  studied physical affordances and perceived affordances as design aspects that could  contribute to intuitive interaction in Mixed Reality systems. 

3. Methodology 
An observational study was carried out within People and Systems Lab (PASLab) at  Queensland University of Technology (QUT), Brisbane, Australia. Children participated in the  study during school holidays. They were asked to bring along a friend or a sibling to play  with. The children and their parents were known to the researchers through personal  contacts and through their participation in a previous research study.   42 children in the age groups of 5 to 12 years participated in the study. Twentyone pairs of  children were observed playing with a Mixed Reality game system from Tangible Play called  Osmo (Figure 2). Osmo allows physical play with a virtual system (IPad). It comes with a  reflector and a stand that is attached to an Ipad and four games that can be downloaded as  apps from iTunes. The app used for the study is called `Newton'. Newton works with any  objects or drawings that are placed in front of the screen and manipulated to guide falling  balls onto targets (Figure 2). The game involves manipulating objects and drawings placed in  front of the screen to guide free falling balls onto various targets on the screen. The physical  interaction in the game is entirely with the objects in real space and in the context of  achieving the goal of directing balls onto the targets. The display screen is used for  generating feedback from the manipulation, in relation to the targets on the screen.  

4 

Intuitive Interaction in a Mixed Reality System 

 

Figure 2 Osmo setup and Newton app. 

Children were instructed how to play with the game system and told that they have to work  together as a team. The entire game play was video and audio recorded for analysis. Two  digital video cameras were used to record the activity (Figure 3). One camera was placed in  front of the children and the other on the side to capture the interaction and facial  expressions during the playtime.  

Figure 3 Children playing Osmo. The view of the tablet screen (on the left) and the view of children  manipulating objects and drawing in the physical space (on the right) 

4. Analysis 
Audiovideo recordings of the game play were coded using Noldus Observer XT 12 to analyse  the interaction with the game system. The interaction with the game system was  categorised into two main behaviours: Explore and Perform. Explore refers to a behaviour  where children were figuring out ways to guide the balls onto the target. They manipulated  objects and drawings in front of the tablet, exploring different angles and layouts to guide  the balls onto the target. Once they had found the right alignment and layout, they made 

5

Shital Desai, Alethea Blackler, Vesna Popovic

few adjustments to their angular positions to guide the balls onto the target. This behaviour  was coded as Perform.   Explore and Perform behaviours were coded for Type of interaction: intuitive, nonintuitive  and partiallyintuitive and Type of affordance: physical and perceived affordance for each  child. Figure 4 shows a part of the coding in Noldus Observer XT 12. 

 

Figure 4 Part of a coding of the game play in Noldus Observer XT 12  

Coding Heuristics 
Intuitive interaction involves utilising knowledge gained through other experience(s), is fast  (Salk, 1983), and generally nonconscious (Bastick, 2003). The coding heuristics employed to  code for intuitive interaction are derivations of methods developed by Blackler et al. (2010).  Nonconscious reasoning ­ Intuitive interaction does not involve conscious reasoning   (Bastick, 2003) but  involves actions and decisions which cannot be explained or verbalised  (Blackler et al., 2010). Children were considered to be reasoning nonconsciously when they  could not explain how they guided the balls onto the targets. One of the participants said, 
"It is easy, don't you understand this?" 

Another participant who chose to draw instead of using objects, said while playing, 
"I like to draw, drawing is easy. Do you know I got an award at the assembly for art?" 

Although the participant did explain why he chose to draw, the explanation did not match  his actions in the game. Such behaviour was also coded as intuitive interaction.  Degree of Certainty ­ Intuition is associated with high degrees of certainty, confidence and  expectation with respect to correct use of a feature (Bastick, 2003; Hammond, 1993;  Woolhouse and Bayne, 2000). When participants were certain and confident about their  strategy to guide the balls onto the target, in contrast to trying out various options, the  behaviour was coded as intuitive interaction. One participant, while playing the game, said  to the other child, 
"I know. I know. I got this." 

6 

Intuitive Interaction in a Mixed Reality System 

The above statement not only shows that the participant was certain and confident of her  decision but also was reasoning unconsciously because she did not verbalise the actual  method that she is going to follow.   Nonintuitive behaviour is associated with conscious reasoning, uncertainty, lack of  confidence and unclear expectations with respect to the interaction with the system (ref).  While playing one of the levels in the game where four fans have to be spun all at the same  time by guiding balls onto the fans, one of the participants said,  
"Alright, we need to think about this logically".  

Some children did not understand the visual cues in the app on the screen such as a  teleporter; they patted their hand on their forehead indicating confusion and said, 
"What does this mean?" 

When interactions showed signs of intuitive as well as nonintuitive interaction, they were  coded as partiallyintuitive. For example, a child noticed that the balls were escaping  towards the left of the screen instead of being guided towards the target. He picked up a  straw and puts it on the left so that balls do not escape anymore. He told the other child, 
"Hang on. I have got this! Let's put this [here] so that balls don't run away" 

The child clearly verbalised his behaviour (nonintuitive interaction) but was certain and  confident about his decision (intuitive interaction).  Physical and perceived affordances were coded as per the following heuristics:  Physical affordance  Objects have spatial and material properties such as colour, texture,  composition, size and shape (Hornecker, 2007). The properties of the objects offer a  potential use to the user  (Maier and Fadel, 2009). People perceive their interaction with  these objects by discriminating their properties (Gibson, 1979) and using their sensorimotor  knowledge that is derived early in childhood.  Children used spatial orientation of objects and drawings relative to the balls and targets on  the screen to decide on the optimum angular position to guide the balls onto the targets.   Children aligned pencils and straws at horizontally when the targets were aligned  horizontally. When the targets were not aligned horizontally, the objects were aligned at an  angle with each other.  The properties of the objects do not mean anything in itself, but in  relation with other objects in the physical space and elements in the virtual space, children  were able to derive appropriate sensorimotor knowledge to align the objects to guide the  balls onto the targets (Stoffregen and Mantel, 2015).  Hornecker (2007)  refers to this  relationship as spatial relationship. When children used this spatial relationship to guide the  balls onto the targets, the interactions were coded as physical affordance.  Perceived affordance ­ Perceived affordance is based on past experience and prior  knowledge (Blackler et al., 2010; Norman, 2004).  People look for clues in the interface to  apply their previous knowledge (Dotov et al., 2012). These clues could be incidental/natural,  for example weight of a bag, or deliberate, for example a scrollbar in a web explorer. The 

7

Shital Desai, Alethea Blackler, Vesna Popovic

weight of the bag provides a natural clue whether it will be easily carried by the user,  without even weighing the bag. In absence of natural clues (physical affordance), children  resort to deliberate clues. The scrollbar not only tells users that they can navigate through  the web page by sliding the scrollbar but also tells them how much they have read and how  much is still left to read. The scrollbar acts like a virtual book mark to the web page. Children  perceive such clues using their past experience and knowledge.   The Mixed Reality game system offered familiarity and a set of common metaphors to  leverage users' familiarity in interaction. Children used their experience in everyday life and  their knowledge about features of tangible objects such as mass, elasticity, rigidity, mobility,  etc. One of the children explained his technique of trying to hit the balls with a straw: 
"...This is like tennis..." 

Some children referred to the simulation of balls hitting a bowl on the screen resulting in a  ball emerging from another bowl as a teleporter. One child explained that he had read about  it in the book, `Charlie and the Chocolate Factory'. Interactions where children used their  past experience and knowledge to play with the Mixed Reality game system were coded as  perceived affordance.   The audio and video data was coded with caution; every observation was checked twice and  at times thrice. All coding was done by one researcher and to avoid observer bias, data were  coded twice with a break of 15 days in between each coding. Reliability analysis was carried  out in Observer XT 12 to determine if there was an agreement between the two sessions of  coding carried out by the researcher. Cohen's kappa () is a measure of agreement between  two sets of coding. Cohen's kappa () statistic can range from 1 to +1 and was found to be  0.92. Based on the guidelines from Altman, (1990), a kappa () of 0.92 represents a strong  strength of agreement between two sessions of coding. Furthermore, since p = .00, kappa  () coefficient is statistically significantly different from zero.   

5. Results 
The coded data were exported from Observer and then analysed quantitatively using SPSS  statistics tool. The objective was to generate reliable generalisable populationbased results  that are suited to establishing causeandeffect relationships. Future exploratory and  investigative qualitative research will specifically look into these relationships.  

5.1 Intuitive Interaction in Mixed Reality Game System 
The first part of the analysis was to investigate intuitive interaction in the Mixed Reality  game System. The boxplot shown in Figure 3 compares the numbers of intuitive, non intuitive and partiallyintuitive interactions in the Mixed Reality system.  

8 

Intuitive Interaction in a Mixed Reality System 

 

Figure 3 Number of intuitive interactions, nonintuitive interactions and partiallyintuitive interactions  in a Mixed Reality System 

The Mixed Reality game system demonstrated highest number of intuitive interactions  followed by nonintuitive interactions. Partiallyintuitive interactions were the least  demonstrated.  A related Samples Friedman test was run to determine if there were any statistically  significant differences between numbers of intuitive, nonintuitive interactions and partially intuitive interactions in children playing with the Mixed Reality game system. The Friedman  test works by ranking each score of the dependent variables (numbers of intuitive, non intuitive and partiallyintuitive interactions), according to its value, with the smallest rank  assigned to the smallest value. The ranks obtained for each of the dependent variables are  averaged separately.   The mean ranks obtained for each of the dependent variables and a histogram of rank values  of numbers of intuitive interactions, nonintuitive interactions and partiallyintuitive  interactions is presented in Figure 4. If the shape of the rank distributions is similar, which is  the null hypothesis of the Friedman test, the mean rank will be the same for all three types  of interactions. However, intuitive interaction has higher mean rank than nonintuitive and  partiallyintuitive interaction. It is this difference in mean rank that is tested by Friedman  test for statistical significance.    

9

Shital Desai, Alethea Blackler, Vesna Popovic

 
Figure 4 Rank distributions of number of intuitive, nonintuitive and Partially intuitive interactions in  Mixed Reality game system. 

The rank distributions of numbers of intuitive interactions, nonintuitive interactions and  partiallyintuitive interactions were not similar, indicating statistically significant difference  2 in the type of interactions,  (2) = 53.006, p <0.05.  

5.2 Affordances in the Mixed Reality game system 
The intuitive interaction in the Mixed Reality System was further analysed by studying the  affordances offered by the game system to facilitate intuitive interaction. A Multiple  regression was run to explain how much of the variation in intuitive interaction in the Mixed  Reality system can be explained by physical affordances and perceived affordances in the  Mixed Reality system. Regression analysis investigates relationships between variables. In  contrast to methods such as the Friedman test which indicate if a significant difference exists  between the variables, regression analysis determines if physical affordance and perceived  affordance influenced intuitive interaction.   Physical and perceived affordances statistically significantly explained 82.5% of variability in  intuitive interaction in the Mixed Reality system, F(2,39) = 95.195, p<0.05. This suggests that  the regression model is a good fit of the data. Comparing the relative contributions of  physical and perceived affordance to the intuitive interaction of the system (Figure 5), it was  found that physical affordance explained 71.9% of the variability in the intuitive interaction  as compared to Perceived affordance contributing to 28.2% of the variability.  

 

Figure 5 Relative contributions of physical and perceived affordance to the intuitive interaction of the  system. 

10 

Intuitive Interaction in a Mixed Reality System 

6. Discussion 
The results have shown that the Mixed Reality game system demonstrated statistically  significantly higher numbers of intuitive interactions as compared to nonintuitive and  partially intuitive interactions. Further study into the role of physical affordances and  perceived affordances in the intuitive interaction of the Mixed Reality game system also  revealed that physical affordances offered by the elements of the game system are the  prime contributors of intuitive interaction with the Mixed Reality system.  One of the advantages of direct interaction with objects is that the coupling between cause  and effect is quickly observed and its spatial position in space quickly changed if required  (Rogers et al., 2002). Children were given an option to either draw or use objects to guide  the balls onto the targets on the tablet screen. Some children chose to draw while others  preferred to use objects. Some children preferred to draw, but slowly moved on to using  objects. This could be because drawing involved erasing number of times before the right  alignment was reached. On the other hand, objects required a quick change (cause) in  angular position when the balls were missing the target (effect).   Children were able to play intuitively because of the physical affordance offered by the  spatial properties of the objects that could be easily manipulated to obtain the correct  angular position to achieve the goal of guiding balls onto the target. Children picked long  elongated objects such as pencils and straw and drew straight lines to guide the balls onto  the targets. Children picked short cardboard strips or an eraser where small deflections were  required. While playing levels with multiple targets, children aligned the objects at an angle  when the targets were at an angle while they kept the objects horizontal when the targets  were placed horizontally.   Perceived affordance also contributed to the intuitive interaction in the Mixed Reality game  system. Some children used their past experience and previous knowledge to interpret the  meaning of the elements and cues in the app.  The spherical virtual objects were intuitively  recognised by children as targets. When coloured targets were introduced in the game in  one of the levels, children were quick to match the coloured balls onto the same coloured  targets. Some children drew tunnels around the target and the gun that released the balls.   It is necessary to look at the contributors of nonintuitive interactions in the game system  along with the contributors of the intuitive interaction as it allows designers to come up with  design guidelines to develop future intuitive Mixed Reality Systems. Some of the virtual  elements in the app either went unnoticed or the children were unable to interpret the  meaning of the virtual elements contributing to nonintuitive interactions. Spinning a fan by  guiding balls onto it, a teleporter in the form of paired bowls and an accelerator in the form  of a flashing arrow could not be reasoned and understood by the children. The meaning of  the virtual objects had to be either explained to the children or they consciously tried to  reason it out. 

11

Shital Desai, Alethea Blackler, Vesna Popovic

The other cause of nonintuitive interaction was the coupling between the tangible physical  and intangible virtual space. They used their previous experience interacting with tablets  and virtual systems. Some children started playing the game by swiping on the tablet trying  to guide the balls onto the target before realising that the game is controlled through  manipulations in the physical space. Children often could not determine the boundaries in  the physical space in relation to the virtual space. Some children were unable to understand  the disappearance of objects from the virtual space when they moved the objects outside  the field of view of the camera, resulting in nonintuitive interactions. Some children used  objects in midair to strike the balls onto the target, as one child said, "I know this game, I  have played this on Xbox". The objects, being too close to the camera, were outside the field  of view of the camera and thus these manipulations were not detected in the virtual space.  Similar boundary crossings were observed in the horizontal plane, on the left and right of the  tablet screen.  However, once Children had figured out the boundary limits of the physical space in relation  to the virtual space, they were able to continue playing the game intuitively. One child drew  lines on the paper to indicate the boundary limits for moving the objects in the physical  space and others were able to able to move the objects back within the limits without  prompts. The interpretation of the virtual objects in the virtual space and the coupling  between the physical and virtual spaces were the main contributors of nonintuitive  interaction in Mixed Reality systems. However, the intuitive interactions in the game system  were higher than the nonintuitive interactions, highlighting the importance of physical  manipulation of objects in real time and real space in facilitating intuitive interaction in  Mixed Reality Systems.  

6.1 

Implications in Design 

The mixed reality game system, Osmo consists of a tangible physical space that allows direct  interaction and manipulation with physical objects and an intangible virtual space with  virtual elements. Intuitive interaction in the Mixed Reality Systems was predominantly due  to physical affordances offered by the spatial orientation of the physical objects in the  physical space in relation to the virtual elements in the virtual space.   nonintuitive interaction in the mixed reality game system is predominantly due to the  virtual elements, the meanings of which were not understood by the children and the  challenges posed by the coupling between the physical and virtual spaces. Children spent  some time learning about the virtual elements and the boundary issues before they started  playing intuitively.  Although the Mixed Reality game system demonstrated nonintuitive interactions due to  above mentioned issues, there were higher numbers of intuitive interactions than non intuitive interactions in the game system primarily due to the physical affordances offered  by the direct interaction and manipulation of the objects in the physical space. This is in line  with Blackler's (2008) continuum of intuitive interaction, according to which the simplest 

12 

Intuitive Interaction in a Mixed Reality System 

form of intuitive interaction is through physical affordance which is derived from  sensorimotor knowledge. Encoding and retrieval of sensorimotor knowledge is fast and it is  acquired very early in childhood. Population stereotypes (such as clockwise to increase or  red for stop) is the second most accessible form of intuitive use followed by perceived  affordances. The higher end of the continuum contributes to high complexity in design for  intuitive use (Blackler, 2008) and requires maximum encoding and retrieval time.   Desai et al. (2015) compared intuitive interaction in a tangible physical system to that in an  equivalent intangible virtual system using continuum of intuitive interaction. They found  that intuitive interaction in physical systems is derived from sensorimotor knowledge,  physical affordances offered by spatial and material features naturally inherent in the  tangibles and from experiential knowledge acquired from prior experience with the physical  properties of similar and other physical systems. Intuitive interaction in virtual systems relies  heavily on perceived affordances, derived from prior experience with similar products and  features. Intuitive interaction in virtual systems is also governed by population stereotypes  associated with the technology such as tablets and touch screens are associated with  swiping left, right, up and down on the screen.  Based on the discussion above on factors contributing to intuitive and nonintuitive  interaction in the MixedReality game system, the following design guidelines could help to  insure intuitive interaction in Mixed Reality Systems:  1. Use of physical affordances ­ Intuitive interaction in tangible and Mixed Reality  systems is primarily due to physical affordances. Facilitating user inputs to the  system through direct interaction and manipulation of physical elements in the  physical space allows users to take advantage of the physical affordances offered by  the elements in the system. The virtual system provides feedback on the  manipulation and interaction in the physical space.   2. Use of perceived affordances  The virtual elements in the virtual space should be  designed keeping the past experience and prior knowledge of the users in mind. The  act of spinning a virtual fan is not known to children, so cues in the form of a  simulation of balls falling on a fan resulting in its spin could speed up the learning  process.  3. Dimensions of interaction  If the virtual space is in twodimensions, such as the  tablet screen in Osmo, limiting the interactions and manipulations in the physical  space in twodimensions, such as moving objects in the horizontal plane, help users  to traverse the coupling between physical and virtual space.   4. Size of interaction spaces  The size of the physical space and the virtual space in a  Mixed Reality System are usually not the same. This could result in physical  manipulations and interactions in the physical space going out of the limits of the  virtual space. The boundaries in the physical space in relation to the virtual space  should be specified. For example, simple lines in the physical space outlining the  boundaries in the field of view of the camera could reduce the time taken to learn 

13

Shital Desai, Alethea Blackler, Vesna Popovic

about the boundaries.  Alternatively, a feedback from the system to move back  within the boundary limits could help train people to determine the boundaries.  These guidelines are some ways in which Mixed Reality systems could be designed for  intuitive interaction and probably also for immersive interaction.  

7. Conclusions and Future Research 
Prior research has shown that tangibles are more intuitive than intangible systems. Mixed  reality systems incorporate both tangibles and intangibles in one system. A question then  arises on the intuitiveness of Mixed Reality Systems. This study has carried out an empirical  investigation on intuitive interaction in a Mixed Reality game system and the aspects that  facilitate intuitive interaction.  Intuitive interaction in Mixed Reality systems is primarily derived from sensorimotor  knowledge and physical affordances offered by the tangibles and from prior experience with  the physical properties of similar and other tangibles. The coupling between the physical and  virtual space and children unable to reason with the virtual elements in the virtual space  were identified as contributors to nonintuitive interaction in the system.   Some design guidelines to develop intuitive Mixed Reality systems were discussed. Further  research into different configurations of Mixed Reality systems, such as body interactions  and gesturebased interactions, is required to further build on the guidelines. This study is  important as it investigates Mixed Reality systems from the perspective of a human centred  design approach rather than from the perspective of looking at technical aspects of  incorporating immersiveness and pervasiveness in a virtual space.     
Acknowledgements: We thank all parents and children for their support and  participation in this research study.  

8. 5. References 
Azuma, R., Baillot, Y., Behringer, R., Feiner, S., Julier, S., MacIntyre, B., 2001. Recent advances in  augmented reality. IEEE Comput. Graph. Appl. 21, 34­47. doi:10.1109/38.963459  Bastick, T., 2003. Intuition: Evaluating the construct and its impact on creative thinking. Stoneman &  Lang.  Blackler, A., 2008. Intuitive interaction with complex artefacts: empiricallybased research. VDM  Verlag, Saarbrücken, Germany.  Blackler, A., Popovic, V., Mahar, D., 2010. Investigating users' intuitive interaction with complex  artefacts. Appl. Ergon. 41, 72­92. doi:10.1016/j.apergo.2009.04.010  Brederode, B., Markopoulos, P., Gielen, M., Vermeeren, A., de Ridder, H., 2005. pOwerball: the  design of a novel mixedreality game for children with mixed abilities. Interact. Des. Child. 32­39.  doi:10.1145/1109540.1109545  Cheok, A.D., Sreekumar, A., Lei, C., Thang, L.N., 2006. Capture the flag: Mixedreality social gaming  with smart phones. IEEE Pervasive Comput. 5, 62­69. doi:10.1109/MPRV.2006.25 

14 

Intuitive Interaction in a Mixed Reality System 

Crowle, S., Boniface, M., Poussard, B., Asteriadis, S., 2014. A design and evaluation framework for a  teleimmersive mixed reality platform. Lect. Notes Comput. Sci. (including Subser. Lect. Notes  Artif. Intell. Lect. Notes Bioinformatics) 8853, 151­158. doi:10.1007/9783319139692_12  Danby, S., Davidson, C., Theobald, M., Houen, S., Thorpe, K., 2015. Playing with Technology: Young  Children Making Sense of Technology as Part of Their Everyday Social Worlds. Multidiscip.  Perspect. Play From Birth to Beyond.  Desai, S., Blackler, A., Popovic, V., 2015. Intuitive use of tangibles, in: IASDR.  Dotov, D.G., Nie, L., De Wit, M.M., 2012. Understanding affordances: history and contemporary.  choices 33, 269­298.  Fischer, J.E., Jiang, W., Kerne, A., Greenhalgh, C., Ramchurn, S.D., Reece, S., Pantidi, N., Rodden, T.,  2014. Supporting Team Coordination on the Ground: Requirements from a Mixed Reality Game.  COOP 2014  Proc. 11th Int. Conf. Des. Coop. Syst. 49­67. doi:10.1007/9783319064987_4  Gardner, M., Elliott, J.B., 2014. The Immersive Education Laboratory: understanding affordances ,  structuring experiences , and creating constructivist, collaborative processes , in mixedreality  smart environments. Trans. Futur. Intell. Educ. Environ. 1, 1­13.  Gibson, J.J., 1979. The Theory of Affordances in the Ecological Approach to Visual Perceptual.  Hammond, K.R., 1993. Naturalistic decision making from a Brunswikian viewpoint: Its past, present,  future. Decis. Mak. action Model. methods 205­227.  Hornecker, E., 2007. Physical affordances considered harmful!?, in: Second International Workshop  on Physicality. p. 15.  Lindgren, R., JohnsonGlenberg, M., 2013. Emboldened by Embodiment Six Precepts for Research on  Embodied Learning and Mixed Reality. Educ. Res. 42, 445­452. doi:10.31020013189X13511661  Maier, J.R.A., Fadel, G.M., 2009. Affordance based design: a relational theory for design. Res. Eng.  Des. 20, 13­27.  Marks, S., Estevez, J.E., Connor, A.M., 2014. Towards the Holodeck: Fully Immersive Virtual Reality  Visualisation of Scientific and Engineering Data. Proc. 29th Int. Conf. Image Vis. Comput. New Zeal.   IVCNZ '14 42­47. doi:10.1145/2683405.2683424  Milgram, P., Kishino, F., 1994. A taxonomy of mixed reality visual displays. IEICE Trans. Inf. Syst. 77,  1321­1329.  Montessori, M., 2013. The montessori method. Transaction Publishers.  Norman, D.A., 2004. Emotional design: Why we love (or hate) everyday things. New York.  Regenbrecht, H., Lum, T., Kohler, P., Ott, C., Wagner, M., Wilke, W., Mueller, E., 2004. Using  Augmented Virtuality for Remote Collaboration. Presence Teleoperators Virtual Environ. 13, 338­ 354. doi:10.1162/1054746041422334  Ricci, A., Piunti, M., Tummolini, L., Castelfranchi, C., 2015. The mirror world: Preparing for mixed reality living. IEEE Pervasive Comput. 14, 60­63. doi:10.1109/MPRV.2015.44  Rogers, Y., Scaife, M., Gabrielli, S., Smith, H., Harris, E., 2002. A Conceptual Framework for Mixed  Reality Environments: Designing Novel Learning Activities for Young Children. Presence  Teleoperators Virtual Environ. 11, 677­686. doi:10.1162/105474602321050776  Salk, J., 1983. Anatomy of reality. Columbia University Press New York.  Stoffregen, T.A., Mantel, B., 2015. Exploratory movement and affordances in design. Artif. Intell. Eng.  Des. Anal. Manuf. 29, 257­265. doi:10.1017/S0890060415000190  Vogiatzaki, E., Gravezas, Y., Solutions, I.S.A.T., 2013. Rehabilitation System for Stroke Patients using  MixedReality and Immersive User Interfaces.  Walden, R., 2015. Schools for the Future. Springer. 

15

Shital Desai, Alethea Blackler, Vesna Popovic

Woolhouse, L.S., Bayne, R., 2000. Personality and the use of intuition: individual differences in  strategy and performance on an implicit learning task. Eur. J. Pers. 14, 157­169.  doi:10.1002/(SICI)10990984(200003/04)14:2<157::AIDPER366>3.0.CO;2L    About the Authors:  Shital  Desai  (M.S)  is  a  PhD  student  Discipline  in  Industrial  Design  at  QUT, Brisbane, Australia. She is currently working on her thesis which  looks at developing a framework for designing products that facilitate  Embodied  Intuitive  Interaction  in  children.  She  is  a  recipient  of  research  bursary  from  Design  Research  Society  (UK).  (sh.desai@qut.edu.au)  Alethea  Blackler  (PhD)  is  an  Associate  Professor  and  Head  of  Discipline  in  Industrial  Design  at  QUT,  Brisbane,  Australia.  Her  principle  area  of  research  interest  is  intuitive  interaction,  in  which  she  is  one  of  the  world  leaders.  She  pioneered  the  first  empirical  work in this field. (a.blackler@qut.edu.au)  Vesna  Popovic  (PhD)  is  a  Professor  in  Industrial  Design  at  Queensland  University  of  Technology,  Brisbane,  Australia.  Her  research  focus  is  within  experience,  expertise  and  intuitive  interaction. Vesna is a Fellow of the Design Research Society (UK) and  Design Institute of Australia. (v.popovic@qut.edu.au). 

16 


