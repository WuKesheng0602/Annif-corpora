Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

COMBINING HIERARCHICAL TASK ANALYSIS AND USAGE SCENARIOS TO HELP EMBED HUMAN FACTORS IN DESIGN
Filippo A. Salustri and W. Patrick Neumann
Department of Mechanical and Industrial Engineering, Ryerson University salustri@ryerson.ca, pneumann@ryerson.ca

Abstract ­ The introductory design course in
Mechanical and Industrial Engineering at Ryerson University combines Human Factors (HF) and Design. Due to its unique character, we have developed custom courseware. In recent years the instructors have noticed four specific shortcomings in students' abilities to incorporate HF into their designs. We are developing new courseware that focuses on embedding HF considerations into the requirements specification stage. The courseware incorporates a novel combination of Hierarchical Task Analysis (a well-known method) with Usage Scenarios (a method of Salustri's invention, based on the work of Stone and Wood). We further alter the courseware in several other ways to minimize the amount of documentation that students need to provide, while still capturing their decision-making process well enough to allow appropriate assessments. A plan for implementing and assessing the proposed work is also presented. Keywords: engineering design, human factors, hierarchical task analysis, courseware, user experience

developing the tool, the problems it is intended to address, the overall structure of the tool, our plans to introduce it to students, and how we expect to assess it.

2. BACKGROUND
Since its inception in 2009, the authors have team-taught MEC325 - Introduction to Engineering Design to second year Mechanical and Industrial Engineering undergraduate students at Ryerson University. The goal of the course was experimental in that to the best of our knowledge, no one had tried to provide an integrated introduction to both Human Factors and Design in one course. We could not find any previous substantive efforts to develop and offer such a course. We thus took the approach of beginning with entirely separate elements and then, year by year, integrating the material as we discovered good points of overlap, complementarity, and harmony. This particular paper reports on one point of this ongoing effort: to make HF concerns ubiquitous in requirements development. The key process elements pertinent to this paper involve: · Identifying and documenting a reference design; that is, an existing product that embodies a "typical" or "conventional solution" for a design brief. Analysing and documenting how users might reasonably interact with the reference design in conventional situations, for the sake of identifying flaws in the reference design and thus motivating new designs.

1. INTRODUCTION
The authors' work is grounded in the fact that human factors (HF) are rarely included at the early stages of product design engineering [2,3,6,8]. Besides working with industry to embed HF in practice, we are also investigating how to embed HF systematically and explicitly in design for mechanical engineering undergraduate students, so that they may help raise HF issues in practice (something rarely done today) once they enter the workforce To this end, we are developing tools for team-based design projects that drive students to address HF explicitly. In particular, we seek to embed methodological concern about users into designing through the use of personas and situated use cases. This paper introduces one such tool, HTA+US, that combines Hierarchical Task Analysis (HTA) [1,10] and flowchart-like Usage Scenario (US) diagrams. The following sections describe the course for which we are
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

·

Our goals in requiring this kind of analysis are to make students demonstrate the ability to (a) reason out the human factor consequences of designs upon users, and (b) to clearly specify undesirable conditions that students will "design out" of their own solutions. As such, this analysis feeds requirements specification: the requirements ought to specify designs that will not exhibit ­ or at least reasonably manage ­ the undesirable conditions. Originally, Salustri based his US diagrams of product usage on Stone's and Wood's flowchart-like function chain diagrams [11]. However, instead of representing

­ 1 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

the most fundamental functions of a product, Salustri used a higher-level approach that included only functions and transformations that were visible to a product's cosystems and users. Additionally, a US could have special branches at any step, where each branch represented an "error" that could happen during execution of that step. Identifying errors is a key purpose of a US, and students are expected to (try to) eliminate those errors from their subsequent design work. Furthermore, USs did not originally mention users at all, and described usage steps in a strictly functional way; e.g., one did not "push a button", which specifies a specific form, but rather "activate the system". We treated references to specific embodiments (such as buttons) to be errors on the part of students. We believed it was relatively easy to correct these mistakes by telling students to ask themselves "why?" whenever they specified a usage step that contained an embodiment (e.g., "Why does the user push the button?"). However, we discovered in grading final design reports, very few students did this. In 2014, Neumann suggested introducing personas into USs. A persona [9] is a hypothetical user archetype standing for a group of actual users and documented as a specific individual complete with name, age, abilities and disabilities, social context, and any other characteristics pertinent to the design brief. In this way, a US with personas comes to model a specific situated use case (SUC) of a product. We hoped that adding personas could help students think about the impact of human factors by making them have to visualize and document how different users can interact with a design in different ways. We revised our courseware to expect students to develop multiple personas for each major user group across the product life-cycle (users, co-users, manufacturers, installers, endof-life disassemblers, maintenance and repair people, etc.) and to produce USs combining one or more personas into particular situations. The branches denoting errors at a given step could now be specified with respect to the (dis)abilities and states of the named persona(s). We hoped this would help ground students' work more firmly and ubiquitously in HF. There was one immediate problem. For instance, in the context of designing an elevator, given the combinations of only four user personas and a situation of "taking the elevator to the office", one could devel op as many as 15 USs. Since this leads to a combinatorial explosion of USs as the number of personas and situations grows, and since we are heavily time-constrained in MEC325, we instructed students to develop only a few USs that were "representative" of all the possibilities they imagined. Over the subsequent two years, we noticed that students often encountered difficulties building the necessary USs, regardless of the effort that the instructors and teaching assistants put into providing guidance:
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

1.

2.

3.

4.

In an effort to secure the highest possible grade, teams would develop so many USs that it became impossible for them to account for all the design implications in subsequent stages of designing (e.g., in concept design). Many USs were very similar ­ and therefore quite repetitive ­ because only the SUC component would change, not the overall operation that the US describes. Students had trouble identifying an appropriate level of detail for each US. For instance, in a lifeboat design project, students would often have a single step named "passengers enter the lifeboat" and completely neglect the intricacy and importance of the implied sub-steps. Due to the number of USs, students would often miss design conflicts arising from inconsistencies between different USs. Students would spend too much time generating "attractive" US diagrams and not enough thinking about their content.

These difficulties led to designs with relatively weak human factors. In 2017, Neumann suggested incorporating aspects of HTA, because the hierarchical nature of HTA would presumably help students organize their USs as well as present a visual representation of the level of detail of a collection of USs. An HTA diagram appears roughly as a tree structure. The top-most node is the single, overarching goal/task (e.g., "make a smoothie with the blender"); the next level down shows, in order, the major tasks needed to achieve the overarching goal/task; the third level contains the steps needed to achieve each of the tasks at the second level; and so on. A sample partial HTA from [6] is shown in Figure 1. One notes three key differences between USs and generic HTA diagrams: · · · USs contain no hierarchical information. HTA diagrams contain no persona-specific information and, therefore, no information about the types of interaction errors that may occur. Levels of an HTA diagram consist strictly of sequential steps, and only HTA "plans" include conditional branches, whereas conditional branches can occur anywhere in a US.

There is a need to combine these two types of diagrams. The authors' goals were (a) to develop a graphical representation that would combine features of USs and HTA, such that (b) the four types of student difficulties noted above were addressed.

­ 2 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

Figure 1: A sample HTA diagram from [6].

7.

3. A NEW APPROACH
The overall layout of the design process as presented in MEC325 is available online at this link1; the steps relevant to the work in this paper are summarized below: 1. 2. based on a given design brief, establish personas that represent the types of users each team is targeting; establish a reference design against which all candidate designs will be assessed, and which represents a "typical" existing pr oduct used by the personas; develop a hierarchy of use tasks, represented with the usual graph structure of conventional HTA; develop US diagrams for each of the "lowest level" tasks in the HTA; develop a series of SUCs that reference specific personas, and that form a representative set of situations in which the reference design would likely be used; identify representative interaction errors (described below) to document the shortcomings of the reference design; and

"verify" the USs, SUCs, and interaction errors by comparing them to the design brief and to each other for consistency and breadth of scope.

In addition to incorporating HTA into our process, we will be making four other changes, which we describe below, all intended to address the four problems identified in Section 2. Examples are provided in Section 4. Separating SUCs from USs. To address the complexity of USs as they currently exist, which students seem to find overwhelming, treatment of specific interactions between a product and its users will be separated from the "ideal" process of product usage. That is, a US will describe how a product ought to be used, and SUCs will describe specific instances of personas using the product in specific contexts. In this way, we expect students to produce fewer US diagrams and correspondingly have more time to focus on producing the highest quality USs possible. This will also provide instructors with an extra "checkpoint" to review student work and provide constructive feedback before students invest time and effort in studying how the design will be used, misused, and abused by users. We note here that USs are similar (but not identical to) entities called "plans" in the language of HTA. Assuming three basic stages of any HTA. In the past, students often had difficulty starting the process of generating USs. To provide further initial guidance to students, we will instruct them to begin always with the assumption that any US+HTA analysis will include three

3. 4. 5.

6.

1

This material will be in flux throughout Spring and Summer 2018 as the material is changed per the outline in this paper. It will be stable by September 2018.
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

­ 3 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

"top level" stages: set-up (or initialization), use, and take-

down (or

Figure 2: Sample HTA fragment for the authors' approach and elevator example.

finalization). The authors have found that these three stages seem to apply to every possible task description, regardless of product or lifecycle stage, and so should provide a simple, universal rule to help students kick off construction of their HTA. New documentation for SUCs. Our students seem to have little experience visualizing information in nontextual forms (e.g., such as with concept maps). Since addressing this shortcoming is not part of our curriculum, we are developing some chart-based alternatives. A SUC will consist of a descriptive title, a list of the personas involved, and a brief description of the relevant contextual factors. We expect several SUCs to be developed by each student team for each US. This will minimize the amount of repetition of diagrams that students seem to have difficulty construction yet capture all the relevant information. New Interaction Error Charts. Since many interaction errors can occur on the application of one SUC to one US, a separate Interaction Error Chart (IEC) will be introduced to further help minimize redundancy and repetition of information. An IEC will include a reference to a US and a SUC, and information describing the nature of the interaction error, the human factors involved, the

design features involved, and the expected reactions of the personas. The IEC is a key aspect of our approach and is specifically intended to lead students to focus on the shortcomings of the reference design (rather than the more conventional "shortcomings of the user"). By (a) isolating this aspect of the analysis from the analysis of the design itself and (b) positioning this aspect after a more "objective" description of the reference design, we hope to make more evident the essential nature of the "human in the system" and that a design that is not usable enough is not usable at all. IECs must specifically address four areas of human factors covered in MEC325 ­ perception, cognition, motor abilities, and psychosocial aspects ­ and must highlight the ways in which a functional product can nonetheless be unusable by users. This should also help students understand the difference between functionality and usability (another problem we have in the past). We again note here that students are expected to perform this analysis with respect to their reference designs. This is done to help keep the students grounded in the concrete and to emphasize that every product ­ even ones that they may have chosen as reference designs for their popularity and superior reviews ­ are imperfect when viewed through the lens of human needs. It also gives them the

CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

­ 4 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

means to quantify as much as possible the specific shortcomings they identify.

4. EXAMPLES
In this section we present fragments of the kinds of diagrams and charts we will implement. The example is based on a sample problem that the authors often use in lecture, that of designing a building elevator. The reference design used is the existing elevator in Eric Palin Hall at Ryerson University, which houses the authors' department offices. The elevator is a conventional one for a four-storey building, with illuminated call buttons, and a floor indicator above the doors. This elevator is peculiar in that it makes noises when in motion that are audible from outside the elevator. (It hums when the elevator car is going up, and hisses when the car is going down.) This elevator is used in our courseware because most students are well-acquainted with it. The examples below are highly abbreviated due to formatting restrictions.

student project. While traceability is essential for professional diligence (and thus a characteristic we wish students to embody in their design projects), it also helps graders and Teaching Assistants follow students' logic. Notice also that the phrasing used in USs is functional (referring to "requests" rather than "pushing buttons", "granting access" rather than "doors opening", etc.). This is done to encourage students to think functionally rather than structurally, which in turn will help them expand the range of new potential design concepts later in the process. US diagrams are "reused" during systems and concept design, so maintaining a functional perspective will help students avoid fixation on existing solutions.

4.1. Sample HTA diagram
The HTA diagram captures the major tasks that a product will perform through interaction with users. Figure 2 shows a fragment of an HTA diagram for our example. The layout and formatting of the diagram helps communicate important aspects of the hierarchy and the nature of the relationships between its elements. It is more structured than a conventional HTA diagram (e.g., Figure 1). The top level identifies the overall product system being described. The 2nd, 3rd and 5th levels exhibit the three-part structure of initialization, use, and finalization, per Section 3. These levels consist of boxes connected by horizontal arrows to denote the sequential nature of the tasks they describe; task numbering emphasizes their sequential nature. The 4th level shows alternative subtask groups for a single task at the 3rd level; vertical arrows and the different numbering scheme emphasize this. We expect students to decompose HTA diagrams to a fairly detailed level; to facilitate this within the constraints of MEC325, we carefully select design briefs that we expect average students can "solve".

Figure 3: Sample US fragment for the elevator design.

4.2. Sample Usage Scenario diagram
A US diagram models the fine-grained actions users may take to complete a task and the responses the product system is expected to provide. Figure 3 shows a fragment of the US diagram for task 2.2a.2 in the elevator design HTA (Figure 2). We borrow extensively from conventional flowcharting notation. Each step in a US is numbered as an extension of the HTA task on which it is based; this is to help maintain consistent traceability of requirements throughout a
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

Also notice the phrasing of the branch: "delay too long." As we intend USs to be used, a branch does not signify an error of the product but only a possible unexpected behaviour that may conflict with users' needs. In this case, the elevator car might be delayed due to a malfunction, but also perhaps due to an interaction with other users ­ e.g., a child pressing all the floor buttons ­ in which case the elevator is operating as designed but with undesirable consequences.

4.3. Sample Situated Use Case
A SUC represents the application of a context and personas to a particular US. This tool is intended to have students focus on how specific other people may use,

­ 5 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

abuse, or misuse a product. Interactions with products are always situated; that is, they occur in an environment that includes various physical and non-physical (e.g., economic) factors as well as various users. Any change to that situation can result in significant performance differences for a single product. The goal of developing SUCs is to document and detail various possible situations that a new design with which a new design will have to contend and, hopefully, exceed the performance of existing products as exemplified by the reference design. SUCs are documented with simple charts. This means that the same SUCs developed to study the reference design (and thus lead to requirements) will also be used later in the design process to evaluate new designs that students will develop. A sample SUC for our elevator system example is given below. SUC 1: Aisha & Lars go to work PERSONAS: Aisha, Lars. CONTEXT: On a typical work day, Aisha and Lars arrive roughly at the same time to take the elevator from the ground floor to the fourth floor where they both work. They are casual acquaintances. Lars is on time for his work obligations, but only just. Aisha is carrying a heavy bag of student exams that he had brought home to grade. SUCs are identified by a simple numbering scheme and a short descriptive title, to facilitate referencing specific SUCs in subsequent text in design reports. The context describes the environmental conditions that pertain. Only those aspects are included that the designers believe will relate directly to interactions between the personas and the reference design. For instance, in the example above, whether Lars is wearing a business suit or shorts and a t-shirt is irrelevant. SUCs are documented separately from USs and IECs (described below) because a single SUC can apply to many USs and IECs. In this way, we hope to minimize the amount of repeated text in student work, and thus the opportunity for inconsistencies to arise in their reporting and designs.

RELEVANT HUMAN FACTORS: Perception: the elevator's noise is additional (unintended) feedback about its direction of travel; the floor indicator can tell them if the elevator is coming. Cognition: Can users distinguish cognitively between the sounds the elevator makes? How did they come to know the distinction? Can they deduce the direction of travel from the floor indicator? Motor ability: Aisha feels discomfort in her neck, shoulders, arms, and hands from carrying the heavy bag. Psychosocial: Lars is worried about being late for his first meeting. RELEVANT FEATURES: Location of elevator interface, brightness & size of call button light, location of floor indicator; ambient noise (that may mask elevator's noise). RESPONSE: Lars takes the stairs. Aisha hears the elevator moving and does not want to carry the exams up four flights of stairs, so remains in hope that it's only the feedback light that is broken and that transport will arrive. Aisha does not know Lars well enough to be comfortable asking him to help carry the exams up the stairs. We note that IECs are intended only to describe interaction errors, not to address them in any way. This is because research has shown that synthetic and analytic cognitive tasks are best not done in rapid alternation [4,7]. In our approach, requirements engineering (of which this work is part) is a purely analytic task that must precede the creative/synthetic parts of designing (e.g., ideation and concept design).

5. IMPLEMENTATION PLANS
The material presented in this paper will be implemented over the summer of 2018 for deployment in the fall offering of MEC325. Changes include: Reworking existing courseware. We have a complete set of custom courseware, developed by the authors over almost 3 decades, for this course. Existing courseware web pages still have personas embedded in the original US diagrams. Identifying SUCs and IECs is not covered. The page for USs must be entirely rewritten. All related examples must be redone. Furthermore, all courseware must be scanned for references to personas and USs; those references must be checked for consistency with the new material and revised accordingly. Developing new courseware. New material and examples must be developed for HTA, SUCs, and IECs. The material must be integrated into the rest of courseware. This includes updating the template document for the students' final design reports, which lays out formatting and section headings for all major elements of the project work.

4.4. Sample Interaction Error Chart
An IEC is a simple two-column chart that models a single undesired event occurring during an interaction between users and a product in a given SUC. Due to formatting restrictions, we present a sample Chart here as a list with headings. These Charts are only meaningful in a context including appropriately defined personas, a SUC, and a US. US STEP: 2.2a.2.1 User requests to go up. SUC: 1: Aisha & Lars go to work. ERROR: Elevator fails to provide feedback confirming request to go up.
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

­ 6 of 7 ­

Proc. 2018 Canadian Engineering Education Association (CEEA-ACEG18) Conf.

6. CONCLUSIONS
Updating rubrics. Rubrics used to grade milestones and final project reports are made available to students. These rubrics are rather detailed with regards to both quality and quantity of work. They are both beneficial to TAs who help grade student submissions, and helpful for instructors defending grading practices at Appeals Panels. The rubric for Milestone 1, which covers the development of requirements, will have to be updated significantly in light of the changes described in Section 3. Updating studio instructions for TAs. Due to the large size of MEC325 and various budgetary and resource constraints on our program, it is impossible to acquire TAs with consistent levels of skills in both design and human factors. As a result, we have various notes and documents to assist TAs when running studios and grading student work. The pertinent notes and documents will have to be updated to reflect all the changes noted above. Since we have soft copies of student design reports spanning several years, we can use those as a baseline and review the impact of the new courseware described in this paper. To assess the new courseware, the authors will review final reports of Fall 2018 student teams during Winter and Summer 2019, comparing them to previous years' reports. Evaluation of the impact of curriculum changes is something that our Department has done very little of in the past; to do this well will require particular effort to find and absorb existing best practices. We will depend heavily on the expertise available through Ryerson's Learning and Teaching Office. Our primary focus will be on two key exploratory qualitative measures: (a) the extent, if any, to which requirements address human factors better in the 2018 reports than in those of previous years, and (b) the extent, if any, to which ultimate designs account for the human factor issues identified in requirements. Although we are still developing the details of our assessment methods, we expect to conduct a text analysis of student reports and code the results by finding key terms used by students that connect HF to requirements. If we find increased use of those terms in the Fall 2018 design reports, we will consider our efforts successful. As for how HF is reflected in final designs, we expect to compare final submitted designs from Fall 2018 to designs of previous years. If the ideas proposed in this paper are successful, then we should see a significant increase in quality of designs with respect to HF. Since we typically have over 50 teams per year, we may not be able to analyze all available reports for multiple years. We will attempt to secure funding to hire a research assistant to help with the analyses; however, we may have to select a random sample of reports rather than perform an exhaustive review.
CEEA18; Paper 081 University of British Columbia; June 3 ­ 6, 2018

In recent years, we have noticed specific deficiencies in how students incorporate human factors into engineering design at the introductory level. We have developed a new approach, incorporating Hierarchical Task Analysis with Usage Scenarios, intended to address four specific shortcomings pertaining to requirements specification. We have broken the courseware into more manageable components to help students focus on specific goals at each stage of the design process. We will be implementing the changes for Fall 2018 and will conduct a subsequent analysis to determine the extent to which our efforts will encourage students to consider the "human in the system" when they perform engineering design work.

Acknowledgements
The authors would like to that the Teaching Assistants and students of past years of MEC325, who have provided valuable feedback about the course and thereby helping us to improve it.

References
[1] J. Annett, "Hierarchical task analysis," in Handbook of Cognitive Task Design pp. 17­35, 2003. [2] O. Broberg, "Integrating Ergonomics into Engineering: Empirical Evidence and Implications for Ergonomists," Human Factors and Ergonomics in Manufacturing, vol 17, pp. 353-366, 2007. [3] J. Dul and W.P. Neumann, "Ergonomics Contributions to Company Strategies," Applied Ergonomics vol 40, pp. 745-752, 2009. [4] J.S. Gero and T. McNeill, "An approach to the analysis of design protocols," Design Studies, vol. 19, pp. 21-61, 1998. [5] E.H. Grosse, C.H. Glock, and W.P. Neumann "Human Factors in Order Picking: A Content Analysis of the Literature," International Journal of Production Research, vol 55, pp. 1260-1276, 2017. [6] D. Lockton, D. Harrison, and N.A. Stanton, "The Design with Intent Method: a design tool for influencing user behaviour," Applied Ergonomics, vol. 41, pp. 382­92, 2010. [7] T. McNeill, J.S. Gero and J. Warren, "Understanding Conceptual Electronic Design Using Protocol Analysis," Research in Engineering Design, vol. 10, num. 3, pp.129-140, 1998. [8] C. Perrow, "The Organizational Context of Human Factors Engineering," Administrative Science Quarterly, vol. 28, pp. 521-541, 1983. [9] J. Pruitt, and J. Grudin, "Personas: Practice and Theory," ACM Proc. 2003 Conference on Designing for User Experiences (New York, NY, USA), 15 pp., 2003. [10] A. Shepherd, Hierarchical Task Analysis. London: Taylor & Francis, 2001. [11] R.B. Stone, and K.L. Wood, "Development of a Functional Basis for Design," J Mech Des, vol. 122, pp. 359­370, 1999.

­ 7 of 7 ­

