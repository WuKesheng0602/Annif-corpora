EXPLORING INTERACTIVE TECHNOLOGY IN EDUCATION THROUGH THE USE OF 3D LENTICULAR PROJECTION AND VOLUMETRIC DISPLAYS by MICHAEL CARTER-ARLT Bachelor of Technology, Ryerson University, 2015

A Major Research Project presented to Ryerson University in partial fulfilment of the requirements for the degree of Master of Digital Media in the program of Digital Media

Toronto, Ontario, Canada, 2018 Â©Michael Carter-Arlt, 2018

AUTHOR'S DECLARATION FOR ELECTRONIC SUBMISSION OF A MRP

I hereby declare that I am the sole author of this MRP. This is a true copy of the MRP, including any required final revisions. I authorize Ryerson University to lend this MRP to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this MRP by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my MRP may be made electronically available to the public.

ii

ABSTRACT

EXPLORING INTERACTIVE TECHNOLOGY IN EDUCATION THROUGH THE USE OF 3D LENTICULAR PROJECTION AND VOLUMETRIC DISPLAYS

MICHAEL CARTER-ARLT Master of Digital Media Ryerson University, 2018

This project explores some of the ways interactive technology has been used in education to increase student engagement, and suggests how novel rendering and interaction technologies can be used in learning environments to increase student engagement. With the utilization of the Unity game engine, Near Field Communication using an Arduino, and Vuforia image recognition software, a 3D platform was created for a technology called the Looking Glass, which adapts 3D models to appear as 3D holograms. The idea behind the platform was to suggest ways in which technology can be used to create more engaging content in an educational setting, in order to combat the constant struggle many students have with diverting their attention away from their distracting smartphones. In the end, the goal is to suggest that in battle against distractions in a classroom, engaging content prevails over technology confiscation.

iii

ACKNOWLEDGEMENTS I would like to thank Canadian author J.B. MacKinnon for lending his voice for the narration of my project. I would like to thank Matt Marshall for being an outstanding teacher in the Unity game engine and C# coding language. I would like to thank Dr. Richard Lachman for supervising my research and lending valuable advice that has greatly helped with the development of my project. Finally, I would like to thank the CEO of The Looking Glass Factory Shawn Frayne for allowing me to use the technology he has been developing with his company for the completion of my project. This project would not have been possible without him.

iv

TABLE OF CONTENTS AUTHOR'S DECLARATION..............................................................................ii ABSTRACT...................................................................................................iii ACKNOWLEDGEMENTS.................................................................................iv TABLE OF CONTENTS....................................................................................v LIST OF FIGURES.........................................................................................vii

INTRODUCTION.............................................................................................1 REVIEW OF LITERATURE..................................................................................2 RESEARCH MOTIVATIONS...............................................................................6 APPLICATION AESTHETICS..............................................................................8 CONCEPT OF TIMELINE....................................................................................9 EXPLANATION OF TECHNOLOGY....................................................................10 A. HOLOPLAYER ONE...........................................................................10 B. LOOKING GLASS.............................................................................10

PART A: APPLICATION DESIGN.........................................................................11 A. APPLICATION VERSION 1: VUFORIA IMAGE RECOGNITION..................12 B. VUFORIA USER INTERACTION..........................................................13 C. APPLICATION VERSION 2: ARDUINO RFID READER..............................14 D. ARDUINO USER INTERACTION/ GAME DESIGN...................................16

v

PART B: USER OBSERVATIONS.........................................................................17 A. HOLOPLAYER ONE USER OBSERVATIONS............................................17 B. LOOKING GLASS USER OBSERVATIONS..............................................19

PART C: CONCLUSION...................................................................................21

PART D: THE FUTURE....................................................................................24

APPENDICES................................................................................................25 A. VUFORIA IMAGE RECOGNITION CARDS.................................................25 B. DESCRIPTIONS OF MODELS..................................................................26 C. INTERVIEW WITH SHAWN FRAYNE.........................................................26 D. USER OBSERVATIONS 1..........................................................................27 E. USER OBSERVATIONS 2.........................................................................28 F. EVOLUTION OF RFID READER................................................................29 G. RFID READER LASER FILE.....................................................................30 H. RFID READER CODE FOR ARDUINO 1.......................................................31

REFERENCES...............................................................................................34

vi

LIST OF FIGURES FIGURE 1: Models displayed on the Looking Glass.......................................................9 FIGURE 2: RFID Reader Schematic.......................................................................15 FIGURE 3: Initial concept using the Holoplayer One...................................................17 FIGURE 4: Final application using the Looking Glass.................................................20

vii

INTRODUCTION As technology becomes more and more advanced, so does its ability to become increasingly distracting. Mobile technology has now eliminated the boredom of solitude, or as Tristan Harris, a former product manager at Google, puts it, it is technology companies that have made this trade for humans, designing platforms, games, and apps to keep them hooked (The Economist, 2017). In his book The Distracted Mind, Dr. Adam Gazzaley states that a notification on your phone can lead to an interruption in performing tasks, which becomes a distraction from that task, and ultimately lead to failure of completing the task altogether (Gazzaley et. al., 2016). This behaviour becomes a problem when it directly hinders one's ability to regularly perform or complete tasks on a daily basis (Gazzaley et. al., 2016). In a classroom setting for example, frequent interruptions can lead to distractions from class content, directly impacting a student's ability to learn (Calderwood et. al., 2014).

A study conducted by Stanford University in 2014 revealed that students switch to entertainment on their devices in order to combat the boredom of doing schoolwork (Yeykelis et. al., 2014). Additionally, although teachers continuously seek novel instructional approaches to teaching, it is largely agreed that today's schools face major problems around student motivation and engagement (Lee et. al., 2011). It is clear how technology can pose as a distraction from the completion of tasks, however, to simply ban the use of devices in an educational environment is almost unheard of, and even ill-advised by many experts (CBC, 2017). One study in 2014 found that even if a cellphone is placed away from an individual within the same room, it contributes to heightened levels of anxiety from not being able to use it (Cheever et. al., 2014). We must then ask the question; in the era of continuous interaction using mobile technology, how are we able to keep students engaged in educational content when their minds are constantly distracted? 1

REVIEW OF LITERATURE Decades of research by Dr. Larry Rosen, who specializes in the psychology of technology, along with research groups around the world, have shown that one of the major factors that contributes to a distracted mind is the emergence of modern technology (Gazzaley et. al., 2016). Through text messages and social media notifications, distractions are prevalent in almost every form of modern technology, which lead to interruptions in our everyday lives, which then hinder our ability to perform tasks and ultimately affect goal setting in negative ways (Gazzaley et. al., 2016). Indeed, as technological advances propel us forward to create new discoveries each day, so does its ability to limit our cognitive functions through the means of distraction each day (Gazzaley et. al., 2016).

In 2017, CBC reported that 88% of 4,000 participants used their cellphones while in class (CBC, 2017). This is not strictly a North American phenomenon. Researchers at the Holon Institute of Technology in Israel found that 9 in 10 college students use their laptops for non-academic reasons while in class (Hammer et. al., 2010). Gazzaley and Rosen (2016) also found decades of research around the world agree linking distraction to the emergence of modern technology. In addition with this, Dr. Rosen argues cogently that educators must adapt their teaching strategies to meet the learning needs of this generation (Withrow, 2012). Studies conducted by the neuroscientist Adam Gazzaley have also found that 4 in 10 young adults between 18 and 34 check their phones immediately after receiving a notification (Gazzaley et. al., 2016). This ties back into how distractions can lead to interruptions which eventually lead to the detriment of a task. Statistics by the Neilson Company in 2010 revealed that American teen's text 3,339 times a month, which translates to texting more than 6 times per hour they are awake (Neilson, 2010). 2

Furthermore, a 15-minute study conducted in 2013 found that in a pool of both elementary and college students, it was reported that the students averaged about 9 minutes of total study time, with the other 6 minutes being self-interruptions from mobile devices (Rosen et. al., 2013).

In order to understand all alternatives on how to combat the issues surrounding motivation however, one must outline how the uses of technology can have positive effects on user engagement as well. Many studies have shown how the use of technology can lead to increased levels of student engagement, such as the use of clickers in education (BrckaLorenz et. al., 2010), and through gamification using the mobile app "Kahoot" (Fotaris et. al., 2016). Additionally, research conducted in 2013 by the University of California further explored the incorporation of technology in education through the creation of the video game NeuroRacer (Abbott, 2013). The study revealed that the video game improved multitasking performance of older adults on the game to the level of 20 year olds, which remained at this heightened level six months later without them playing again (Abbott, 2013). These studies concluded that despite the detriments of using technology in a classroom, modern technology can lead to beneficial results if used correctly, and even reinforce a need for more platforms to be created for educational purposes in the future.

An infographic from the New Jersey Institute of Technology reported last year that the AR device market is expected to reach $660 million this year, with several mobile apps being created in education to allow students to engage in interactive books about space and human anatomy (Cortez, 2017). Additionally, it has been noted that using AR for educational purposes can appeal to students at a personal level, promoting both engagement and motivation (Sharples et. al.,

3

2013). Supporting this statement, a study conducted in 2011 showed that positive aspects of AR in education include ease of use by young children, flexibility across age groups and subject domains, ease of use in reference to installation/mobility of hardware, and more specifically in relation to this project, the immersive nature of 3D AR visualisations to enhance engagement amongst students (Luckin et. al., 2011).

In addition to how AR can enhance formal education, the University of Nebraska Medical Center recently began construction on a $118.9 million virtual and augmented reality center to transform healthcare education (Cortez, 2017). The need for 3D content in classrooms has also been demonstrated as early as 2010, when the utilization of stereoscopic 3D technology in an elementary school lead to instant engagement from students, and proved to be more than just a way for grabbing the student's attention (Gordon, 2010). Further supporting this, the use of 3D stereoscopic glasses in a biology class enhanced content in relation to learning about the human heart, allowing students to see a heart as if it was floating in front of them (Monahan, 2010). It was noted however, that the biggest obstacle in making this technology more accessible to students was the cost of the 3D glasses themselves (Monahan, 2010). This hurdle is non-existent with volumetric displays, as it does not require the need for any wearable peripherals (Looking Glass, 2018).

Although volumetric displays have been around since 1912, development for this technology has a history of being isolated (Blundell et. al., 2000), ultimately making it accessible to only a few specific fields (Osmanis et. al., 2016). Volumetric displays and 3D lenticular projection in education could not only contribute to the commercialization of this technology, but potentially

4

influence the creation of other similar platforms in addition to the ways it can be used to enhance education. One such example can be referenced as far back as 2002, when the Magic Book, created by Mark Billinghurst, incorporated the use of Augmented Reality to create an interactive storybook (Billinghurst, 2002). When showcased at SIGGRAPH 2000, the attention it received got thousands of people interested in creating applications using the same type of technology for industrial applications (Shelton, 2002). In addition, the Magic Book was also a major inspiration for the creation of an AR astronomy application that was used in a study for an undergraduate geography class in 2002 (Shelton et. al., 2002).

Learning styles have also yielded positive results in relation to enhanced learning through the use of the widely adopted VARK (Visual, Auditory, Reading/Writing, and Kinesthetic) model to determine an individual's preferred form of learning (Stojanova et. al., 2017). These modes of learning are particularly important for students to learn the curriculum of a class, due to the fact that not every student can learn the teaching material in the same way (Stojanova et. al., 2017). The use of single learning models as opposed to multi-modal learning models is also an important factor that influences a student's ability to learn. A study conducted in 2014, found that out of a sample size of 141 medical students, 41.8% preferred a singular learning style, whereas 58.2% preferred multiple learning styles (Peyman et. al., 2014). Similarly, a study conducted in 2007 found that 36.1% preferred single modal styles and that 63.9% preferred multi-modal styles in a sample size of 155 students (Baykan et. al., 2007). These studies emphasize the need to deliver class content that does not focus on a single learning style, and further support the need to create content that focuses on multiple learning styles.

5

In summary, it is clear how the use of technology can both negatively and positively impact a learning environment, but the key is to find the right balance, or the best of both worlds. It would seem that the underlying problem is not with how we combat cellphone use in classrooms, but how we can make content in classrooms more engaging to combat distractions. Reinforcing this theory, a study commissioned by Steljes in conjunction with the survey company Censuswide showed that of all the teachers surveyed, 97% of primary and secondary school educators said they agreed that interactive technology in the classroom delivers an improved learning experience (Oakman, 2016). In addition, dozens of studies have shown that playing action video games can enhance cognitive control due to their nature of engagement (Gazzaley 195 et. al., 2016). Essentially, the idea behind this research is to create a platform that can effectively be used in an educational environment to enhance education to achieve greater engagement in classroom content.

RESEARCH MOTIVATIONS This project was heavily inspired by the illusion of the Pepper's Ghost Pyramid to create the appearance of holograms. The Pepper's Ghost Pyramid creates the illusion of what appears to be a translucent ghost through the reflection of an image off of a pane of clear glass (Costa, 2016). This is achieved by the use of a bright display or screen that projects an image onto the glass, creating a very convincing picture in low lit environments. The concept of the Pepper's Ghost illusion was first described by John Pepper in 1860. Renewed interest in this illusion resulted in modern companies using IR cameras to track user inputs and create interactive small-scale displays in the form of a glass pyramid (Costa, 2016). During the early development stage of this project, a concept was conceived that focused on the idea of using a video projector instead of a 6

display in order to create a larger illusion with a smaller overall footprint. This pyramid would then be augmented with a leap motion controller to create user interactions via hand gestures.

After conducting extensive research however, I concluded that it was simply not possible to create something that was different from what has already been done with a Pepper's Ghost Pyramid. Additionally, many versions of what I had planned on creating had already existed in some form or another, leading me to believe it was not worth pursuing. Through additional research I discovered the Holoplayer One, which took an entirely new approach to creating a hologram. The Holoplayer One was developed by The Looking Glass Factory in New York City, and creates a stereoscopic image that can be seen from up to 32 viewing angles without the need of any additional headgear or wearable peripheral (Looking Glass Factory, 2017). This device was originally used for the first iteration of my project, but was later swapped for the Looking Glass for image quality and accessibility purposes.

Conceptually, this project was partially inspired by the book The Once and Future World by J.B. Mackinnon. In his book, MacKinnon details how the impact of humans has changed the landscape of many environments, driving many species on our planet to extinction. He also states that as each new generation is born, we tend to forget about the past and accept the world we are born into as the norm. As a result, many people tend to lack an understanding of how things have changed, and goes on to say that we need find the proper ways of educating people to help combat the constant alteration of the natural environment (MacKinnon, 2013). This theme contributed to what subjects were chosen for my application as well, which create a brief timeline that dates back millions of years ago.

7

APPLICATION AESTHETICS The scenes that were created for each model represent a small fragment of their natural surrounding environment. In addition, each scene was designed to complement each model, but not add so much as to take away from the model itself. Lighting was a major consideration for each scene, and specific lighting was used for each scene respectively that use their own colour hues and lighting angles to achieve the best possible viewing experience. Perspective in relation to the environment was also incredibly important for each model to remain accurate, but the models also had to be scaled accurately in comparison to other models in order to remain realistic. Finally, animations for each model were specifically chosen to be more subtle in order to accommodate computers with less graphical computing power. In this sense, movement stuttering for animated models would be greatly reduced on a larger number of computers, making the application accessible to a larger number of people.

Each scene was designed to have some elements that were universal amongst all models, as well as unique elements that were independent to each model. The common element that was shared between models was the circular base for each scene that is shown in Figure 1. Unique elements included the surrounding environment (Tropical, Snowy, Forest, Desert), as well as which assets were used for each scene. A common asset that can be seen amongst all models was the use of one rock asset, and the number of rocks present in each scene represent the number of scenes respectively (1, 2, 3, and 4). Careful consideration was also used to determine the placement of each asset, with some assets purposely obstructing parts of particular models in order to take advantage of the lenticular technology from the Looking Glass. As a result of this, the user would be required to change their viewing angle in order to see all of the model that is being displayed. 8

Figure 1: Each model displayed on the Looking Glass CONCEPT OF TIMELINE The Gingko Tree was chosen to represent how even after millions of years of evolution, it has remained virtually unchanged, despite its surrounding environments (McMurray et. al., 2016). This is in contrast with the Woolly Mammoth, which is believed to have gone extinct as the result of overhunting by humans 10,000 years ago (National Geographic, 2011). The Deinonychus on the other hand, was chosen because it went extinct naturally, but also coexisted with the Gingko Tree. In addition, the Deinonychus is commonly misrepresented as a Velociraptor due to the "Jurassic Park" films, and is actually considered to be the most influential dinosaur to have been discovered (Strauss, 2017). Finally, the White Rhinoceros represents an endangered species caused by over hunting as well, and sheds light on how critically endangered the Northern White Rhinoceros is (2 females left in the world) (Karimi, 2018). 9

EXPLANATION OF TECHNOLOGY HOLPLAYER ONE The Holoplayer One is an interactive light-field device that utilizes 3D lenticular projection to display 3D content in a way that appears as if it is a floating hologram. It uses a lenticular overlay on top of a 2K (2048Ã1080p) screen, which splits the image into 32 different viewing angles (Frayne, 2018). This allows users to see around objects depending on the angle they are viewing on the device at. In addition, using a beam splitter that is the reflected off a piece of glass, an auto-stereoscopic image is created, which appears as if 3D content is floating space in front of the glass on the device (Frayne, 2018). Finally, a capacitive touch home button is present on the device, along with four buttons which allow for physical user interaction, as well as a Real-Sense camera on the top that tracks finger inputs for gestured interactions.

LOOKING GLASS The Looking Glass is a volumetric display that functions in a very similar way to the Holoplayer One. Instead of creating floating images however, the Looking Glass uses a volumetric display that displays 3D content in a large block of acrylic (Frayne, 2018). Essentially, it suspends millions of points of light in a physical three-dimensional space at specific locations to create a stereoscopic image with 45 viewing angles (Gartenberg, 2018). In addition, the Looking Glass is able to display content in 60 frames per second (Torres, 2018). Much like the Holoplayer One, content is viewed and created in the same way, however the image that is projected into the Looking Glass is far sharper than that of the Holoplayer due to the fact that it forgoes the essence of creating a floating hologram, and instead appears as if the content is in a glass box. 10

PART A: APPLICATION DESIGN Programs Used: Graphic Design Adobe Illustrator CC Adobe Photoshop CC Adobe InDesign CC 3D Modeling Unity Game Engine Autodesk Maya 2018 Tinkercad Coding Arduino Editor Visual Studio 2017 AR + Audio Editing Vuforia Camtasia Studio 9

The application I designed focuses on the 4 learning-styles of the VARK model (Visual, Audio, Reading/Writing, and Kinesthetic) (Prithishkumar et. al., 2014). This approach was chosen because learning styles have become a popular form of educating individual students and it has also been noted that it is necessary to determine what is most likely to trigger each student's concentration, how to maintain it, and how to respond to his or her natural processing style to produce long-term memory and retention (Pashler et. al., 2009). The application I created incorporates each element of the VARK model by allowing the user to view 3D models, read descriptions about the models, listen to narration about the model, and allow them to change viewing angles to learn more about the subject. Background audio is also audible for each model, and allow the user to get a sense of the surrounding environment that model belongs to. The Gingko Tree for example, has a city background noises associated with its model due to the fact that Gingko Trees can survive in virtually any environment (CBS, 2009).

Using the Unity Game Engine, I created four scenes that correspond to each model, which have their own elements to represent unique environments. These scenes were created using a combination of game objects within Unity and models from the Unity Asset Store, along with

11

various materials and textures from the Unity Asset Store. The Gingko Tree was created entirely in Autodesk Maya, with the textures of the leaves created in Adobe Photoshop. In addition, the narration for each model was voiced by J.B. Mackinnon, the author of the book The Once and Future World. All interactions for each model were programmed using Microsoft Visual Studio, and are executed using the C# coding language. The interactions that exist for each model are handled by a C# script that allows the user to execute them by pressing either 1, 2, or 3 on a computer keyboard. These will be mapped to physical buttons on the Looking Glass once that version is released later in 2018. The interactions for each model are as follows: Keyboard Button 1 = Description Toggle (Either On or Off) Keyboard Button 2 = Rotation Toggle (Start and Stop) Keyboard Button 3 = Play Audio Narration (Start and Stop)

APPLICATION VERSION 1: VUFORIA IMAGE RECOGNITION The first version of my application allows the user to present printed cards of each subject to a webcam, which are recognized by a webcam and projected in the Looking Glass. This is handled by the Vuforia image recognition software, which is an Augmented Reality software that identifies images or objects to trigger events or scenes within the Unity game engine (Vuforia, 2018). Through Vuforia, four images were selected for a webcam to identify, which each trigger their own unique scenes. When an image target has been identified by the camera, it triggers a specific scene that corresponds to what had been identified. Furthermore, if an image is not recognized by the camera, or if an image is presented that does not exist in the database, no additional actions will occur. 12

The image identifiers for each model were all created using Adobe Illustrator, Photoshop, and InDesign. Special consideration was given to the image identifiers that include size accommodation, image contrast to background, as well as User Experience (UX) Design considerations in relation to interaction design. Put simply, interaction design is the design of the interaction between users and products (Siang, 2018). In this version of my application, this particular element consisted of the placement of a blue square at the bottom left of each card to indicate where the user should place their finger when holding the card to the camera. This was designed primarily to reduce the chances of image obstruction.

VUFORIA USER INTERACTION Users were given four cards to present to a webcam that is constantly searching for image targets. Once a target is identified, a scene within unity would spawn that corresponds to what was recognized on the card. Image targets could be partially obstructed and still trigger scene spawning, however, heavily obstructed images would yield no result. Once the scene is loaded, users are able to read descriptions of the subject, change viewing angles, and toggle on and off voice narration about that subject by pressing either 1, 2, or 3 on the computer keyboard. Users also have the ability to change the model they are currently viewing at any given time by holding a different card to the camera. In addition, users would not be able to reload the same scene that was currently being viewed if they held up the same image target. Finally, by turning the card over to the back, a common artwork on all cards will be recognized, which would unload whichever scene is present in the application at that time.

13

APPLICATION VERSION 2: ARDUINO RFID READER Near Field Communication was also incorporated into the application to provide a faster response rate when scenes were loaded in my application. RFID (Radio Frequency Identification) tags were chosen specifically due to the fact that they are relatively small and can be identified through various materials (Kaur et. al., 2011). In this case, the RFID could be placed within 3D printed artifacts made of plastic, and identified by an RFID reading platform. The idea behind this iteration of my application was to explore various ways users could interact with the Looking Glass in order to enhance the learning experience of the platform. The RFID recognition was achieved by creating an RFID reader using an Adafruit PN532 breakout board and two Arduino Uno's. Other necessary components also include the use of five 10k resistors and a 4050 level shifter chip. Four push buttons were also added to the reader for testing purposes, but do not actually contribute to the functionality of the device.

In order to reflect elements of good UX Design, a photocell sensor was added to the device in order to detect the presence of light. Currently, the RFID reader that I created is capable of reading RFID tags when presented with them, but not capable of detecting when they are absent. As a result of this, when an RFID tag is read by the RFID reader, it loads the corresponding scene, but does not unload that scene once the tag was removed. The photocell sensor was considered as a UX Design component because it allows the Arduino to unload an active scene once it detects a specific amount of light. In this case, an artifact placed on the RFID reader would obstruct the photocell sensor, only allowing a partial amount of light to come through. Once the artifact is removed, all extraneous light is present to indicate that there is no object on the platform, which then unloads the scene. 14

As seen in Figure 2, Arduino 1 acts as the actual RFID reader, and the other Arduino acts at the Unity communicator. Two programs run on each Arduino separately, where Arduino 1 is solely responsible for identifying RFID tags, which then sends a signal to the second Arduino that reads an input of either 1 or 0 (HIGH or LOW) for each of the four pins connected. Each RFID tag has its own unique identifier, meaning a specific event will occur only when that particular ID is identified. Arduino 2 looks for a digital read of HIGH on pins 2, 3, 4, and 5, which is sent from Arduino 1 once a tag has been recognized. This interaction allows Arduino 2 to activate models in Unity by turning them on or off depending on which pin is reading HIGH or LOW. Each model is assigned its own unique pin as well, allowing them to be toggled on and off separately.

Figure 2: RFID Reader Schematic 15

ARDUINO USER INTERACTION/ GAME DESIGN In this version, RFID tags will be embedded into 3D printed artifacts that were unique to each model in their own way. The artifacts will be chosen to not be easily identifiable in regards to what model they belong to, in order to challenge the ability of the user to associate that artifact to what subject it belongs to. Gamification greatly influenced this iteration of my project, and will help enhance the overall experience of interacting with the Looking Glass. Using gamification concepts was a major consideration for the design of this version because gamification has the potential to improve learning if it is well designed and used correctly (Dicheva et. al., 2014). This will be done by the placement of four images on a table, with the four artifacts scattered in a small sandbox. The challenge is to find and retrieve the artifacts from the sandbox, and pair the artifacts with the images of each model prior to learning about them.

In order to receive clarification on which artifact belonged to a visual, the user would place the artifact on the RFID reader, where the RFID tag inside that artifact would be recognized, which would activate the associated model in turn. The retrieval of the artifacts from a sandbox was inspired by an Archaeology Dig Site. This idea was also influenced by many other examples of sandbox style archeology digs in a classroom, which create an interactive way to learn about the past through kinesthetic learning (Brown, 2018). This type of interactive learning has also been shown to have created higher levels of engagement amongst students, both on the elementary and university level (Chisholm et. al., 2007). Furthermore, the sandbox was not only chosen as a method of increasing user-engagement, but also chosen to coincide with kinesthetic learners of the VARK model (Roell, 2017).

16

PART B: USER OBSERVATIONS

HOLOPLAYER ONE USER OBSERVATIONS In the early phases of my project, I had the opportunity receive informal feedback on the Holoplayer One with a group of students, educators, and industry professionals in digital storytelling at a project showcase event at Ryerson University. The number of participants varied throughout a two-hour period, but peaked at over 50 attendees. Participants of the event were observed in terms of how they interacted with the Holoplayer One in order to understand the effectiveness of the technology, and whether it proved to be engaging enough for participants to inquire further about it. This version of my application served as a prototype of the initial concept and depicted one static model with no form of interaction, which can be seen in Figure 3. The event helped establish whether there was actually potential for this technology to be used for educational purposes.

Figure 3: Initial concept using the Holoplayer One 17

Overall, the Holoplayer One was generally well received with many people notably interested in how the device worked. Many participants inquired about the technology and were particularly interested in how the lenticular properties of the device allowed you to see around certain objects, which cannot be done using any form of display currently available. In addition, images projected on the Holoplayer One appear as if they are floating in mid-air, which seemed to pique the interest of quite a few participants. However, although the feedback of the Holoplayer was generally positive, some particular complaints were noted as well. This feedback is summarized in the chart below, along with comments in relation to them.

CONCERNS Depending on where you are standing, it can be hard to see the image on the device

COMMENTS Unfortunately, one of the downfalls with this technology is it has a very narrow field for viewing content. This proved to be a serious problem when showing content on the device to a group of more than 5 people. Although the technology is still quite new, it is hard to say how this problem will be addressed in future iterations of the device, considering the limitations of the technology itself.

One person suggested It is hard to say how this technology will be adopted in the future, and that it would be hard to use the device for purposes unrelated to just novelty Images on the Holoplayer One appear as if they are "blurry" or "out of focus" whether developers will use the technology for purposes other than simply displaying 3D content as holograms. The application that was showcased however was in its most basic form, so this comment was understandable considering the lack of interactions that were available to users. This was unanimously the most common complaint amongst users during the event. In order to achieve the appearance of a hologram, image quality is sacrificed on the Holoplayer One for what appears to the user as a floating image. With this being said, it is difficult to say whether or not this issue can be corrected due to that fact that it is intentional to achieve this effect. 18

LOOKING GLASS USER OBSERVATIONS During the final stages of development for the Vuforia version of my application, I had the opportunity to conduct further user testing during another showcase event for industry professionals, educators, and professors of Ryerson University. The event attracted many visitors with over 100 people present during its three-hour duration. Among the attendees was the President of the University, the Director of eLearning at Ryerson, as well as the Dean of Graduate Studies. In addition, numerous educators from various institutions were present at the showcase as well, making the feedback of this event critical to the future development of my project. In relation to the feedback received during the first demonstration of my application, the response to this version was almost surreal, and only positive feedback was received over the course of the entire event.

In terms of user interactions, participants were observed in regard to how they interacted with the device by holding image targets to the camera on my computer in order to spawn each corresponding scene. Each scene loaded in under 5 seconds, however, it was noted that the Gingko Tree consistently loaded at a slower rate than any other scene. This is presumably because the Gingko Tree model uses numerous copies of one texture for the leaves, which causes a minor lag when loading. Unfortunately, the delayed reaction time lead to some confusion as to whether the camera had successfully recognized the image target. The scene was later optimized to increase loading speed based off this observation.

One notable observation that was made during testing was some users referring others to visit my demonstration area in order to see my application. It was transparent how interest for this 19

technology could extend beyond that of a classroom setting based off the number of referrals I had received during the event. Additionally, another interesting observation that was made during the event was participants using their smartphones to take pictures and videos of the application to post on social media websites. The use of social media to promote educational content is almost a surreal prospect. This observation leads to the assumption that depending on how engaging educational content is, it could possibly be discovered by other people or rediscovered by the same people through social media platforms. In addition, this observation in particular reinforced how the use of new technologies can greatly enhance user engagement in educational content. Furthermore, participants expressed interest in how the technology could be used in museums, which spawned the idea of using RFID artifacts for the last version of my application. The final version of the application can be seen in Figure 4.

Figure 4: Final application using the Looking Glass 20

PART C: CONCLUSION

Although there is no single definition for user-engagement, multiple definitions of user engagement point to the common theme that focus on the ability of the system or application to "catch and captivate user interest," or to draw in and stimulate one's interest (Lalmas et. al., 2015). Based off this description, it is clear from observations made during the Looking Glass demonstration specifically that user-engagement has been achieved for the application I have developed. It is clear that there is a need for this technology to create engaging content has been reinforced by the responses received by high-level educators from Ryerson University. In addition, this technology has the potential to extend past the boundaries of education and could be used for various or purposes for the sake of enhancing digital content.

In terms of the Holoplayer One however, the mixed response toward the device, specifically due to its drawbacks in image quality, eludes that it would not be well suited for purposes other than displaying models. The blurriness of images that are displayed on the device also raise concerns on accessibility issues for people who may already be visually impaired. Furthermore, although text is legible on the device, the large font size required to read text comfortably do not allow for long descriptions to be displayed, and instead only allow for headlines and large bullet points to be displayed. Although the technology is still emerging, the requirements to achieve the appearance of a floating image seem too restrictive to theorize an adverse improvement of image quality will be achieved in the near future. Furthermore, the application that was demonstrated was also too simple to draw definitive conclusions, requiring more user testing with a more sophisticated application to formulate a concrete analysis.

21

The Looking Glass, although only well received during the showcase event, also has some notable drawbacks based on personal observations. One particular drawback that was noted during user testing was the fact that the device has limitations in displaying content for a larger audience of people. Although showing content to a small group of people (4-6) did not yield negative results, a larger crowd of people (10) did present issues, with some participants not able to fully see the content being displayed on the device. This could create problems in an educational environment if multiple people want to view content simultaneously on a single device. This issue however, is primarily due to the small footprint of the Looking Glass, which is approximately 8.5 inches wide. A larger model would be favourable to make the device more accessible to a larger group of people and should be used in these situations if available in the future.

Another notable drawback of the Looking Glass was lighting conditions. Although the Looking Glass can visibly display content in any lighting, it was observed that content became somewhat washed out by light that directly cast onto the front of the device. This was a result of the glare created by the light from the reflective surface of the Looking Glass. In order to dissipate the interference of glare, it was concluded that light should be placed above or behind the device, but not in front of it. Alternatively, ambient lighting should be reduced in the environment where the device is located. Low lighting is notably best to display content, however, if light is present, only partial, indirect light should be used. A good example of these conditions can be seen in Figure 4. This limitation could potentially be a deterring factor in using the device depending on the surrounding environment, however, it could theoretically be corrected with the use of a matte film on the front of the device.

22

The extent to which this technology could potentially enhance education is still unknown. Indeed, based off user observation, it is clear this technology does enhance content, and has proven to make educational experiences more engaging for a variety of people. However, concrete tests need to be conducted that measure the degree to which education can be enhanced by testing a user's ability to retain knowledge using the Looking Glass technology. This should be done by conducting tests that challenge the user's knowledge of a topic after using the device. Furthermore, a comparison would need to be illustrated that contrasts how retained knowledge of the participants who use the Looking Glass vary from participants who were taught the same information in the more traditional lecturing format of reading/writing.

Finally, considering this application attempts to combat the issue of distracting devices in a classroom, this technology would require more in depth user testing in an actual classroom setting environment. This should also be coupled with the idea of using this technology to test a student's intrinsic motivation to continually use the device to learn more about other subjects in order to gauge stimulation of that content and whether it is continually engaging. Intrinsic motivation is essential for effective learning and there is increasing recognition of the importance of affective and emotional aspects of usability of digital platforms (Sandars et. al., 2010). Furthermore, testing would also need to be conducted on students ranging from high school to undergraduate, in order to fully construct an accurate picture pertaining to the effects of this technology at various levels of education.

23

PART D: THE FUTURE

In order to determine the effectiveness of this technology in all areas of education, additional educational institutions need to be contacted in order to gain a greater understanding of its capabilities. This includes how it could be used for a range subjects in various learning environments. Furthermore, the future of this technology's role in education would ideally begin by assessing how effectively it can integrate within museums before making its way into a classroom setting. I am currently in touch with the Ontario Science Centre, and the application I created will most likely be previewed during an event in 2019 for their 50th anniversary. Additionally, the Royal Ontario Museum will also be contacted in the near future in hopes that the Looking Glass can be used in a similar context to what had been demonstrated in my project.

One aspect that is hard to determine is the longevity of this technology if it ever were to be embraced by educational institutions. The technology utilized for my project has shown to be both interesting and engaging, but then again, it is a new technology, and not something we have seen for years. Many forms of technology in some form or another may have been considered interesting and engaging at some point in time, only to be forgotten once the technology becomes dated. Capacitive touch screens were once considered revolutionary, but is now a technology we barely even think about. Indeed, from what is known about novelty and technology, it is hard to tell whether or not the engagement of users came from the content on the device, or the device itself. This being said, I believe that this technology will continue to evolve and remain engaging so long as creators continue to think of new ways to create interactive content for it. In other words, the longevity for this technology will be solely dependent on the innovators of the future.

24

APPENDICIES A. Vuforia Image Recognition Cards FRONT ARTWORK

BACK ARTWORK

25

B. Description for models in Vuforia and Arduino Looking Glass Applications

C. First meeting with Shawn Frayne, CEO of The Looking Glass Factory Â­ March 5, 2018

26

D. Transmedia Showcase (Ryerson University) Â­ User Observations 1 Â­ April 18, 2018

From left: Michael Ti Dismatsek, Michael Carter, Jennie Cross, and Joel McConvey

27

E. Collaboratory Showcase (Ryerson University) Â­ User Observations 2 Â­ May 23, 2018

Conversation with the President of Ryerson University, Mohamed Lachemi

28

F. Evolution of the RFID Reader

29

G. RFID Reader Case Laser File

30

H. RFID Reader Code for Arduino 1 #include <Wire.h> #include <SPI.h> #include <Adafruit_PN532.h> #include<Uduino.h> #define PN532_SCK (9) #define PN532_MOSI (10) #define PN532_SS (11) #define PN532_MISO (12) Adafruit_PN532 nfc(PN532_SCK, PN532_MISO, PN532_MOSI, PN532_SS); int thirdEye = A4; int thirdEyeValue; void setup(void) { Serial.begin(115200); nfc.begin(); nfc.SAMConfig(); pinMode(2, OUTPUT); pinMode(3, OUTPUT); pinMode(4, OUTPUT); pinMode(5, OUTPUT); pinMode(thirdEye, INPUT); } uint8_t card1[] = uint8_t card2[] = uint8_t card3[] = uint8_t card4[] = uint8_t card5[] = void loop() { thirdEyeValue = analogRead(thirdEye); boolean success; uint8_t uid[] = { 0, 0, 0, 0, 0, 0, 0 }; uint8_t uidLength; 31 { 0xF5, 0x95, 0x8A, 0xFF }; { 0xE5, 0xC5, 0x7A, 0xFF }; { 0x05, 0x8B, 0x8B, 0xFF }; { 0x05, 0xA2, 0x7E, 0xFF }; { 0xE7, 0xBC, 0xED, 0x64 };

unsigned long readID = 0; success = nfc.readPassiveTargetID(PN532_MIFARE_ISO14443A, &uid[0], &uidLength); if (success) { if(uid[0] == card1[0] && uid[1] == card1[1] && uid[2] == card1[2] && uid[3] == card1[3]) { digitalWrite(2, HIGH); digitalWrite(3, LOW); digitalWrite(4, LOW); digitalWrite(5, LOW); }

if(uid[0] == card2[0] && uid[1] == card2[1] && uid[2] == card2[2] && uid[3] == card2[3]) { digitalWrite(2, LOW); digitalWrite(3, HIGH); digitalWrite(4, LOW); digitalWrite(5, LOW); } if(uid[0] == card3[0] && uid[1] == card3[1] && uid[2] == card3[2] && uid[3] == card3[3]) { digitalWrite(2, LOW); digitalWrite(3, LOW); digitalWrite(4, HIGH); digitalWrite(5, LOW); } if(uid[0] == card4[0] && uid[1] == card4[1] && uid[2] == card4[2] && uid[3] == card4[3]) { digitalWrite(2, LOW); digitalWrite(3, LOW); digitalWrite(4, LOW); digitalWrite(5, HIGH); } if(uid[0] == card5[0] && uid[1] == card5[1] && uid[2] == card5[2] && uid[3] == card5[3]) { digitalWrite(2, LOW); digitalWrite(3, LOW); digitalWrite(4, LOW); 32

digitalWrite(5, LOW); } else { } } if (thirdEyeValue>300) { digitalWrite(2, LOW); digitalWrite(3, LOW); digitalWrite(4, LOW); digitalWrite(5, LOW); }

33

REFERENCES Abbott, A. (2013, September 4). Gaming improves multitasking skills. International weekly journal of science. News. Nature. Retrieved from: https://www.nature.com/news/gamingimproves-multitasking-skills-1.13674 Baykan, Z. Nacar, M. (2007, June 1). Learning styles of first-year medical students attending Erciyes University in Kayseri, Turkey. Journals. Advances in Physiology Education. American Physiological Society. Vol. 31. No. 2. Retrieved from: https://www.physiology.org/doi/10.1152/advan.00043.2006 Billinghurst, M. (2002). HITLAB. Mark Billinghurst Papers. Retrieved From: http://www.hitl.washington.edu/people/person.php?name=grof Blundell B. G. Schwarz, A. J. (2000). Volumetric Three-Dimensional Display Systems. John Wiley & Sons Inc. New York. BrckaLorenz, A. Garver, A. K. (2010). Interactive Technology and Effective Educational Practices. Indiana University. 47406-7512. Retrieved From: http://cpr.indiana.edu/uploads/AIR2010%20Interactive%20Tech%20FINAL.pdf Brown, S. (2018). Shoebox Dig. Simulated Digs. Lesson Plans. AIA Education Department. The Archer School for Girls. Retrieved from: https://www.archaeological.org/pdfs/education/digs/Digs_shoebox.pdf Calderwood, C. Ackerman, P. L. Conkiln, E. (2014, January 30). What else do college students "do" while studying? An investigation of multitasking. Computers & Education. Vol. 75. Retrieved From: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/pdf/03601315/v75icomplete/19_wedcswsaiom.xml CBC. (2017, May 16). School cellphone ban ill-advised, expert says. British Columbia. CBC News. Retrieved from: http://www.cbc.ca/news/canada/british-columbia/schoolcellphone-ban-ill-advised-expert-says-1.4118154 CBS. (2009, October 5). Smell Has Some Cities Ripping Out Ginkgo Trees. CBS News. Retrieved from: https://www.cbsnews.com/news/smell-has-some-cities-ripping-outginkgo-trees/ Cheever, N. A. Rosen, L. D. Carrier, L. M. Chavez, A. (2014, June 6). Out of sight is not out of mind: The impact of restricting wireless mobile device use on anxiety levels among low, moderate and high users. Computers in Human Behavior. No. 37. Retrieved from: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/pdf/07475632/v37icomplete/290_oosinoalmahu.xml

34

Chisholm, A. G. Leone, M. P. Bentley, B. T. (2007, September). Archaeology in the classroom: using a dig box to understand the past. Social Education. National Council for the Social Studies. 71.5. Retrieved from: http://go.galegroup.com.ezproxy.lib.ryerson.ca/ps/i.do?p=AONE&u=rpu_main&id=GAL E%7CA169457329&v=2.1&it=r&sid=summon Cortez, M. B. (2017, October 16). Augmented Reality in the Classroom: Transforming Education Through Technology. Software. EdTech. Retrieved from: https://edtechmagazine.com/k12/article/2017/10/how-will-ar-transform-educationinfographic Costa, B. (2016, January 11). Explaining the Pepper's Ghost Illusion with Ray Optics. Cosmol Blog. Cosmol. Retrieved from: https://www.comsol.com/blogs/explaining-the-peppersghost-illusion-with-ray-optics/ Dicheva, D. Dichev, C. Agre, G. Angelova, G. (2014, November 22). Gamification in Education: A Systematic Mapping Study. Educational Technology & Society, 18 (3), 75Â­88. Retrieved from: https://search-proquestcom.ezproxy.lib.ryerson.ca/docview/1707773428?pq-origsite=summon Fotaris, P. Mastoras, T. Leinfellner, R. Rosunally, Y. (2016). Climbing Up the Leaderboard: An Empirical Study of Applying Gamification Techniques to a Computer Programming Class. The Electronic Journal of E-Learning. Volume 4. Issue 2. ISSN 1479-4403. Retrieved From: https://search-proquestcom.ezproxy.lib.ryerson.ca/docview/1804471664?pq-origsite=summon Frayne, S. (2018, March 5). Personal Interview. Frayne, S. (2018, May 25). Personal Interview. Gartenberg, C. (2018, July 24). Put holograms in your home with The Looking Glass display. The future is getting closer. Circuit Breaker. Retrieved from: https://www.theverge.com/circuitbreaker/2018/7/24/17607136/the-looking-glassholographic-display-hologram-3d-image-kickstarter Gazzaley, A. and Rosen, L. D. (2016). The Distracted Mind. Ancient Brains in a High-Tech World. MIT Press. Gordon, D. (2010, October 1). Wow! 3D Content Awakens the Classroom. 3D Content. The Journal. Retrieved from: https://thejournal.com/Articles/2010/10/01/Wow-3D-ContentAwakens-the-Classroom.aspx?Page=1 Hammer, R. Ronen, M. Sharon, A. Lankry, T. Huberman, Y. and Zamtsov, V. (2010). Mobile Culture in College Lectures: Instructors' and Students' Perspectives. Interdisciplinary Journal of E-Learning and Learning Objects. Holon Institute of Technology. Volume 6. Retrieved from: http://www.ijello.org/Volume6/IJELLOv6p293-304Hammer709.pdf 35

Karimi, F. (2018, March 21). The world's last male northern white rhino is dead. Now what? Inside Africa. CNN. Retrieved from: https://www.cnn.com/2018/03/20/africa/kenya-northern-white-rhino-dies-whatsnext/index.html Kaur, M. Sandhu, M. Mohan, N. Sandhu, P. S. (2011, February). RFID Technology Principles, Advantages, Limitations & Its Applications. International Journal of Computer and Electrical Engineering, Vol.3, No.1. Retrieved from: http://www.ijcee.org/papers/306E794.pdf Lalmas, M. O'Brien, H. Yom-Tov, E. (2015). Measuring User Engagement. Morgan & Claypool Publishers series. DOI 10.2200/S00605ED1V01Y201410ICR038. Retrieved from: https://www-morganclaypoolcom.ezproxy.lib.ryerson.ca/doi/pdf/10.2200/S00210ED1V01Y200910HCI005 Lee, J. J. Hammer, J. (2011). Gamification in Education: What, How, Why Bother? Academic Exchange Quarterly, 15(2). Retrieved from: https://wwwcs.uwstout.edu/soe/profdev/resources/upload/Lee-Hammer-AEQ-2011.pdf Looking Glass Factory. (2017). The Looking Glass Factory. Retrieved From: https://lookingglassfactory.com/ Luckin, R. Fraser, D. S. (2011). Limitless or pointless? An evaluation of augmented reality technology in the school and home. Technology Enhanced Learning. Vol. 3. No. 5. Retrieved from: https://www-inderscienceonlinecom.ezproxy.lib.ryerson.ca/doi/pdf/10.1504/IJTEL.2011.042102 Mackinnon, J. B. (2013). The Once and Future World. Random House Canada. McMurray, M. Quimby, T. (2016, October 10). Why Do We Keep Planting Stinky Ginkgos? Science. Slate. Retrieved from: http://www.slate.com/articles/health_and_science/science/2016/10/why_we_still_plant_s melly_ginkgo_trees.html Monahan, J. (2010, November 30). Lessons in 3D promise students entry into new worlds. Classroom Innovation. The Guardian. Retrieved from: https://www.theguardian.com/classroom-innovation/3d-lessons-in-schools National Geographic. (2011, March 26). Woolly Mammoth Fact File. History. News. National Geographic. Retrieved from: http://www.nationalgeographic.com.au/history/woollymammoth-fact-file.aspx Neilson. (2010, October 14). U.S. Teen Mobile Report Calling Yesterday, Texting Today, Using Apps Tomorrow. Digital. Newswire. The Neilson Company. Retrieved from: http://www.nielsen.com/us/en/insights/news/2010/u-s-teen-mobile-report-callingyesterday-texting-today-using-apps-tomorrow.html 36

Oakman, H. (2016, January 13). Interactive tech in the classroom; it's all about engagement. Stories. Education Technology. Retrieved from: https://edtechnology.co.uk/Article/interactive-tech-in-the-classroom-its-all-aboutengagement Osmanis, K. Osmanis, I. (2016, April). Real-Time Volumetric 3D Imaging Technology. BioPhotonics. Photonics Media. Retrieved from: https://www.photonics.com/Articles/RealTime_Volumetric_3D_Imaging_Technology/a58372 Pashler, H. McDaniel, M. Rohrer, D. Bjork, R. (2009). Learning Styles. Concepts and Evidence. Psychological Science in the Public Interest. Association for Psychological Science. Vol. 9. No. 3. Retrieved from: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/pdf/15291006/v09i0003/105_lscae.xml Peyman, H. Sadeghifar, J. Khajavikhan, J. Yasemi, M. Rasool, M. Yaghoubi, Y. M. Nahal, M. M. H. Karim, H. (2014, August 20).Using VARK Approach for Assessing Preferred Learning Styles of First Year Medical Sciences Students: A Survey from Iran. Journal of Clinical & Diagnostic Research. US National Library of Medicine. National Institutes of Health. PMC. Retrieved from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4190729/#b15 Prithishkumar, I. Michael, S. (2014, April). Understanding your student: Using the VARK model. Journal of Postgraduate Medicine. Vol. 60. Issue 2. Retrieved From: https://search-proquest-com.ezproxy.lib.ryerson.ca/docview/1529147648?pqorigsite=summon Roell, K. (2017, November 22). The Kinesthetic Learning Style. Kinesthetic Learning Traits. For Students & Parents. Resources. ThoughtCo. Retrieved from: https://www.thoughtco.com/the-kinesthetic-learning-style-3212046 Rosen, L. D. Carrier, L. M. and Cheever, N. A. (2013, January 24). Facebook and Texting Made Me Do It: Media-Induced Task-Switching While Studying. Computers in Human Behavior. No. 3. Retrieved from: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/details/07475632/v29i0003/948_fatmmdimtws.xml Sandars, J. Lafferty, N. (2010). Twelve Tips on usability testing to develop effective e-learning in medical education. Twelve Tips. Medical Teacher. 32: 956Â­960. Retrieved from: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/pdf/0142159x/v32i0012/956_ttouttdeeime.xml Sharples, M. Specht, M. (2013, December). Augmented Reality and Mobile Learning: The State of the Art. International Journal Of Mobile And Blended Learning. Vol. 5. No. 4. Retrieved from: http://oro.open.ac.uk/38386/8/__userdata_documents4_ctb44_Desktop_FitzGerald%20pa per-IJMBL%205%284%29.pdf

37

Shelton, B. E. (2002, December). Augmented Reality and Education Current Projects and the Potential for Classroom Learning. New Horizons for Learning. Vol. 9. No. 4. Retrieved From: https://s3.amazonaws.com/academia.edu.documents/4810749/sheltonnh_aug_real.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1525202 028&Signature=dbyk0mheff3X%2FUpFBFksHc32r9U%3D&response-contentdisposition=inline%3B%20filename%3DAugmented_Reality_and_Education.pdf Shelton, B. E. Hedley, N. R. (2002, September 29). Using Augmented Reality for Teaching Earth-Sun Relationships to Undergraduate Geography Students. IEEE Catalog Number: 02EX632 ISBN: 0-7803-7680-3. Retrieved From: https://depts.washington.edu/pettt/papers/shelton-hedley-art02.pdf Siang, T. (2018, June). What is Interaction Design? Interaction Design Foundation. Retrieved from: https://www.interaction-design.org/literature/article/what-is-interaction-design Stojanova, A. Stojkovikj, N. Kocaleva, M. Zlatanovska, B. Martinovska-Bande, C. (2017, April 28). Application of VARK learning model on "Data structures and algorithms" course. IEEE Global Engineering Education Conference. Conferences. IEEE Xplore. Retrieved from: https://ieeexplore-ieee-org.ezproxy.lib.ryerson.ca/document/7942909/ Strauss, B. (2017, November 8). 10 Facts About Deinonychus, the Terrible Claw. Science, Tech, Math. Animals and Nature. ThoughtCo. Retrieved from: https://www.thoughtco.com/deinonychus-the-terrible-claw-1093783 The Economist. (2017, February 9). Smartphones are strongly addictive. Driven to Distraction. Special Report. The Economist. Retrieved from: https://www.economist.com/news/special-report/21716462-price-constant-entertainmenttap-smartphones-are-strongly-addictive Torres, J. C. (2018, July 26). Looking Glass promises a holographic display with no headsets. Slash Gear. Retrieved from: https://www.slashgear.com/looking-glass-promises-aholographic-display-with-no-headsets-26539083/ Vuforia. (2018). Vuforia News. Developer Portal. Vuforia. Retrieved from: https://developer.vuforia.com/home-page Withrow, L. R. (2012). Reviews. Rewired: Understanding the iGeneration and the Way they Learn. Blackwell Publishing Ltd. Retrieved from: https://journals-scholarsportalinfo.ezproxy.lib.ryerson.ca/pdf/13684868/v15i0003/288_rutiattlbldr.xml Yeykelis, L. Cummings, J. J. Reeves, B. (2014, January 7). Multitasking on a Single Device: Arousal and the Frequency, Anticipation, and Prediction of Switching Between Media Content on a Computer. Journal of Communication. Wiley Online Library. Retrieved from: https://onlinelibrary-wiley-com.ezproxy.lib.ryerson.ca/doi/full/10.1111/jcom.12070

38


