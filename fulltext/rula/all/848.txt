Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2003

Hardware software partitioning using directed acyclic data dependence graph with precedence
Matthew Jin
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Electrical and Computer Engineering Commons Recommended Citation
Jin, Matthew, "Hardware software partitioning using directed acyclic data dependence graph with precedence" (2003). Theses and dissertations. Paper 203.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

Hardware Software Partitioning Using Directed Acyclic Data Dependence Graph with Precedence

By

,Matthew Jin
BASc. University of Toronto 2001

A thesis presented to Ryerson University in partial fulfillment to the requirements for the degree of Master of Applied Science in the Program of Electrical and Computer Engineering.

Toronto, Ontario, Canada, 2003-09-10 Copyright Matthew Jin, 2003

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

UMI Number: EC52888

INFORMATION TO USERS

The quality of this reproduction is dependent upon the quality of the copy submitted. Broken or indistinct print, colored or poor quality illustrations and photographs, print bleed-through, substandard margins, and improper alignment can adversely affect reproduction. In the unlikely event that the author did not send a complete manuscript and there are missing pages, these will be noted. Also, if unauthorized copyright material had to be removed, a note will indicate the deletion.

®

UMI
UMI Microform EC52888 Copyright 2008 by ProQuest LLC. All rights reserved. This microform edition is protected against unauthorized copying under Title 17, United States Code. ProQuest LLC 789 E. Eisenhower Parkway PO Box 1346 Ann Arbor, MI 48106-1346

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Instructions on Borrowers
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

iii

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Abstract .
In this thesis, we present a system partitioning technique that employs C/C++ as input specification language for hardware/software co-design. The proposed

algorithm is able to explore a number of partitioning solutions as compared to other partitioning research. This benefit is obtained by processing data dependency and

precedence dependency simultaneously in a new representation called Directed Acyclic Data .dependency Graph with Precedence (DADGP). DADGP is an extension of

Directed Acyclic Graph (DAG) structure frequently used in the past for partitioning.

The DADGP based partitioning algorithm minimizes communication overhead, overall system execution time as well as system cost in terms of hardware area. The

algorithm analyzes the DADGP and tries to expose parallelism between processing elements and repeated tasks. The benefits of exposing parallelism with minimum However,

inter PE communication overhead are shown in the experimental results.

such benefits come with increase in cost due to additional hardware units and their interconnections. DADGP-based partitioning technique is also employed to implement Overall, the proposed system

block matching and SOBEL edge detection techniques.

partitioning algorithm is fast and powerful enough to handle complicated and large system designs.

iv

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Acknowledgements

I would like to acknowledge and give many thanks to Professor G. N. Khan for his patience and support. Without him I could not have accomplished this work.

His constant guidance and professionalism has been the driving force of my research. I would also like to acknowledge the financial support from the NSERC research discovery grant awarded to my supervisor, and Canadian Microelectronic Corporation (CMC) for providing Rapid Prototyping Platfonn as well as co-design tools.

My special thanks to the professors and the department for their feedback and participation before and during my thesis defense. I am also grateful to the School of

Graduate Studies and the Department of Electrical and Computer Engineering of Ryerson University for their support financially and academically.

I would also like to thank my family and friends who have supported and encouraged me. Especially to my parents who have been always there for me to give

courage and motivation during my times of doubt.

Finally, my deepest thanks to my girlfriend Christina for her encouragement, patience and understanding. support and love. I could not have been where I am today without her

.

v

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Contents
1
Introduction
1.1 1.2 1.3 1.4
Overview Motivation Original Contributions Thesis Organization

1 1
7 7
9
11 11

2

Hardware software co-design
2.1" 2.2 2.3
System specifications Validation and co-simulation Synthesis

14 18 23 23 24 33 34 34 36

3

System Partitioning Overview
3.1 3.2 3.3
Introduction Survey Summary

4

DADGP HW/SW co-design methodology
4.1 4.2
Sy~tem

specifications

DADGP graph repre~entation

4.2.1

Formal definition

36 4.3
Hardware-software partitioning algorithm

38

4.3.1
39

Profiling

4.3.2 4.3.3

Mapping and Scheduling Mapping and Scheduling of DADGP

41 43

vi

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

~

4.3.4

Complexity of algorithm

46 48 49 53 55
64

5

Experimental results
5.1 5.2 5.3 5.4 5.5
GDL scheduling technique Simulated annealing based partitioning Software simulation Rapid prototyping platform Rapid prototyping platform design flow

67 67 68 69 70 71

5.5.1 5.5.2 5.5.3 5.5.4 5.5.5 5.5.6
72

Design specification Algorithmic design and analysis System architecture design (partitioning) Hardware HDL coding Functiqnal simulation Synthesis

5.5.7 5.5.8 5.5.9
5.6

Place and route Applicaiion software HWISW integration

72 72 73 74 74 78 80
81

Block matching implementation

5.6.1 5.6.2 5.6.3 5.6.4 5.6.5
5.7

Introduction to Block Matching Specification Software simulation Overall architecture Simulation vs. actual implementation

84 85

SOBEL edge detection implementation

vii

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I ,
i

5.7.1 5.7.2 5.7.3 5.7.4

Introduction to SOBEL edge detection Specification Software simulation Simulation vs. actual implementation

85
88

89 93 94 94 95

6

Conclusions and future work
6.1 6.2
Summary and conclusion Future work

References Appendix A: Appendix B: Block Matching Implementation Code SOBEL Edge Detection Implementation Code

97

1 ·
I

I I !

viii

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

List of Figures
1.1 3.1 4.1a 4.lb 4.1c 4.2 5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 5.10 5.11 5.12
5.13

Hardware-software co-design methodology

Mms algorithm flow chart
Data table Specification of block matching algorithm Initial DADGP DADGP design flow Example of DAG and its node execution time table GDL algorithm flow chart Basic simulated annealing algorithm DADGP without precedence GDL scheduled results Initial all software DADGP solution DADGP result Randomly generated graph (9 nodes) Performance gain Simulated time Hardware area cost Hardware cost-performance ratio RPP (source CMC website) RPP design flow Block matching

-

4 27 35 35 35 39 49 53 55 56 57 57 58 59 61 62 63
64~

65 68 76

5.14 5.15

ix

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

5.16 5.17 5.18 5.19 5.20 5.21 5.22 5.23 5.24 5.25 5.26

Search window and correlation window Initial block matching solution with library info Simulated perfonnance improvement curve (block matching) Overall system implementation 32 bit parallel multiplier 32 bit carry save adder SOBEL masks SOBEL example Initial SOBEL solution with library info Simulated perfonnance improvement curve (SOBEL) SOBEL DADGP solution set

77 80 81 82 83 83 86 87 89 90 92 4

4

x

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

List of Tables and Equations
5.1 5.2 5.3 5.4 5.5
Software simulated comparison experiment result Execution time comparison result (block matching) Hardware area comparison result (block matching) Execution time comparison result (SOBEL) Hardware area comparison result (SOBEL)

60 84 85 93 93

4.1 4.2 4.3 5.1 5.2 5.3 5.4

Sum of absolute differences equation Longest delay time equation Longest delay path equation Dissimilarity equation MSE matching criterion Magnitude of gradient Approximate equation

35 42 42 77 78 86 86

xi

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Chapter 1 Introduction

1.1 Overview
There are many embedded systems surrounding us that we do not even realize their presence. Video game units, DVD players, televisions, microwaves, scanners, Using

I I

I

cellular phones, and many more contain some sort of embedded processor(s).

embedded computers in devices that previously relied on analog circuitry such as digital cameras, camcorders, Internet radios, and telephones provide revolutionary performance and functionality that any analog design improvement can not achieve. Most of the

embedded computer systems are designed for just one particular application, and it generally provides cost effective solution by employing specialized architecture rather than using a general purpose computing system.

Until now the embedded system design has taken brute force approach. Hardware and software were designed separately where correctness and comparability of the two domains were left to integrati?n stage.
If problems arise during the

integration stage, the design cycle spin begins and it results in a frequent struggle to

1

1

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

make a sub optimal architecture. even terminated.

Sometimes even the overall project is delayed or

Designing of embedded systems today requires working with several million gates of logic and millions of lines of software code.
In order to efficiently design

these systems. it is desirable to move to higher levels of abstraction for system design automation. Furthermore. rapid improvements in microprocessors performance are What use to be the

changing the balance between embedded software and hardware.

efficient and cost effective hardware solution can now be transferred into software. due to high performance microprocessors.
In this environment. it is necessary to adapt the
microprocesso~s

system design tools that encompass these fast with them.

rather than to compete

The current hardware/software design methodologies do not effectively handle the massive software-hardware integration necessary [1]. Waiting until a system

implementation before understanding the hardware-software interactions is no longer an option.
)
)')

To meet the current market demand. designers now need to produce more The previous approach of

complex computing architecture in a shorter period of time.
Ii c¥

..
",

~'f

l
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

i

~

2

independent hardware and software development methodology is not acceptable. Hardware software tradeoff must be analyzed early in the system design to reduce the iterative design cycle.

The main question is "how can we design with several hundred million transistors effectively and quickly?" Hardware software co-design is said to provide Hardware software co-design

the answer for designing such large systems [2, 3, 4, 5].

is a wide area of research consisting of specification, simulation and estimation, validation, synthesis, and other components. Hardware software co-design concept Many EDA vendors

has been proposed, and being researched for a number of years.

and researchers have employed dedicated efforts to develop viable hardware software co-design methodologies and tools, yet no standards has been adapted to streamline and coordinate their design efforts.

The main objective of hardware software co-design are to shorten the development cycle, minimize bugs, manage cost, and to produce competitive embedded computing systems that meet today's requir:,ements. design methodology for hardware/software co-design. Figure 1.1 shows a generalized Most of the past and recent

3

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

research and development has been built around this model.

Hardware/software co-

design problem is broken into three major components given below.

· System specification design for describing the system level behavior.

· ·

Hardware/software co-simulation and analysis (validation). Rapid hardware software integration by co-synthesis.

Specification Initial Architecture Partitioning System constraints

System Integration

Figure 1; 1: Hardware-Software Co-design Methodology Specification design for describing the systein level behavior is a aifficult and challenging problem as it needs high level of abstraction as well as fine details to reduce ambiguities during co-synthesis.
It is very Important to capture the system
· f

:l

specification correctly early in the design cycle. conducted to
cre~te

Many research projects have been

It

a unified co-design environment by proposing a system

4

J
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

specification language [6, 7].

The idea is to capture the specification with more

details by augmenting the HDL (Hardware Descriptive Language) and other programming languages like C to describe the entire system. SystemC are the main examples of such languages. MSC, SOL, PMSC and

Design specification language concept has lead to co-synthesis that involves automation of hardware and software architecture synthesis. The function of co-

synthesis is to take a system specification language as input and generate competitive hardware and software architecture. A number of co-synthesis systems are under

research, where PICO [8] (program in chipout), C<>rsair [9], Polis [1] are examples of some of these systems. Hardware/software partitioning is a sub problem of co-synthesis, which is also very difficult due to many conflicting factors affecting the outcome of partitioning decision. Generally speaking, hardware and software are interchangeable in terms of their functionality. To correctly partition the system, expertise of both hardware and software design communities must communicate with the help of diverse tools that can evaluate the trade offs of using hardware or software.

5

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

In this thesis, complete hardware software co-design methodology is proposed including: specification, analysis, partitioning and scheduling (co-synthesis) leading to final system implementation is presented by using a Rapid Prototyping Platform. The

proposed methodology includes system-partitioning technique with a system specification based on C/C++. The proposed technique also processes data and

precedence dependency simultaneously by employing a new structure, Directed Acyclic Data dependency Graph with Precedence (DADGP) that is an extension of Directed Acyclic Graph (DAG). The DADGP based partitioning technique minimizes the Furthermore, the The

communication overhead as weU as overall system execution time.

partitioning algorithm minimizes the system cost in terms of hardware area.

partitioning algorithm presented in this thesis analyzes the DADGP and tries to expose · parallelism between tasks and repeated tasks. The benefits of exposing parallelism

and considering inter processing element (PE) communication overhead are also explained in this thesis. However, these benefits come with an increase in price due to The proposed

additional hardware modules and their inter-connection structure.

partitioning algorithm is powerful enough to handle complex designs, and is easily extendable for future requirements as explained in the future work section. The partitioning technique provides promising system partitioning solution as compared to

6

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

previous methods in terms of efficiency of the over all system design.

However,

before we get to the proposed methodology, it is important to overview each components of hardware software Co-design process and their advancements until today.

1.2 Motivation

The current hardware software design flow has hard time meeting today's market demand. The separate design of hardware and software results in an error
In order

prone integration that leads to a design cycle spins delaying the final product

to design these hardware and software systems more efficiently, a proper partitioned hardware software module must be decided before implementation. Currently there

are no commercially available tools to help designers with the partitioning of complex hardware software embedded systems.

1.3 Original Contributions

This thesis proposes a new design methodology for designing hardware and software systems for embedded and System on Chip (SoC) application.
In particularly,

7

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

lI
I
i
~

,
I

computationally intensive embedded systems which require multiple hardware and software are considered. A full hardware software co-design methodology is

T.

presented with implementation results, which shows the validity of the new DADGP partitioning algorithm. The publication of the proposed research can be found in [10].

The Major contributions for the thesi's are summarized as follows: s Ir !r
~d

·
~

Development of software profiling tool for ARM? processor running under a Rapid Prototyping System has been developed

·

Design of software interaction representation graph called . a new hardware , Directed Acyclic Data dependence Graph with Precedence (DADGP)

re
!x

· Development of new DADGP partitioning

algori~

that includes iterative

mapping and scheduling method has been implemented · In-depth comparative analyses of DADGP algorithm with other system partitioning methods.

md
rrly,

8

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

t
1.4 Thesis Organization

This thesis consists of six chapters and it is organized as follows:
In chapter I, we provide a brief overview of current issues of embedded system design

j
,
I

and their solutions (hardware software co-design).

In chapter two, a more detailed

design of hardware software co-design methodology is presented.

The chapter will

i
~

t

help readers to understand the basic idea behind the notion of designing hardware software systems.

I
This chapter also serves to present introductory

I

Chapter 3 will survey previous works related to hardware software partitioning. Partitioning research presented in this chapter is implemented and compared to DADGP partitioning algorithm in later chapter.

knowledge for readers who are interested in different partitioning algorithms.

Chapter 4 describes the newly proposed DADGP based hardware software codesign methodology in .depth from specifications to partitioning. discusses the proposed system
specification~,

This chapter

a formal definition of DADGP and a

detailed explanation of mapping and scheduling process using DADGP.

9

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

!

I

Chapter 5 presents the experimental results of the proposed DADGP partitioning algorithm.
In this chapter, two other system partitioning algorithms are

presented in detail for comparison purposes to DADGP based partitioning algorithm. The software comparison result is also presented with many randomly generated task graphs, and their performance is recorded. Furthermore, two computationally

intensive multimedia application has been implemented using Rapid Prototyping Platform (RPP) and their results are presented. also presented. Some details of the RPP design flow is

In chapter 6, the thesis is summarized and the directi?ns of future research are

proposed.

r

a

10

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Chapter 2 Hardware Software Co-design
In a Hardware software co-design problem, the hardware and software must be

designed together to make sure that the target system not only functions properly but also meets perfonnance, cost and reliability goals. While a great deal of research has

addressed the individual design methods for software and hardware, not much is known about the joint design of these two domains. Due to advancement in VLSI technology,

I

high perfonnance microprocessors are cheap enough to be used in consumer products, and have stimulated research in embedded system co-design. of high perfonnance CPUs, we must develop new
des~gn

To be able to make use methodologies that allow

designers to predict implementation costs, refine an embedded system incrementally over multiple levels of abstraction, and create a working implementation. Hardware Software Co-design process involves solving The current of:

sub-problems

specifications, validation, and synthesis.

Although hardware software co-design

problem cannot be entirely separated, it is divided into three separate sections for the purpose of discussion.

2.1 System Specifications

The system design specifications that describe system level behavior is a difficult and challenging problem because it needs high abstraction yet requires fine details to reduce ambiguities during synthesis. Traditionally, these specifications were

11

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

written in plain English describing the system constraints and functionalities.

The

problem with English as a specification language is that very often, designers can misinterpret the meaning of intended idea. These ambiguities and misinterpretation

i
t

can occur more frequently when different people with different professional background consult the specification to start hardware and software design. It is very important to

capture the specification correctly early in the design cycle to reduce the Non Recurring Expenses (NRE) [8]. Many research works have been done to create a unified coThe idea is to

s

design environment by proposing a design specification language.
y,'

capture the specification with more details by augmenting the HDL and programming language like C. Such a method is known as homogeneous modeling, where hardware

"

e

and software is represented by a common unified language [11].

y
It

System-level specification languages may not always be textual.

Visual or

combination of visual and textual languages can be used to organize the overall system architecture. After all, humans do work and process images better than just plain SDL (Specification and Description Languages) is one of the

f:
n

textual description.

e

common languages of choice in this area, and PARSE process graph is another interesting approach to describe both hardware and software [12]. However, as more

and more details are added, graphical representations might not be suitable, and textual languages become mandatory to express system details completely. Nevertheless, ,

graphical representation is always good to have early in the design cycle for high a
Ie
~e

abstraction and easy visualization for the overall structure of an entire or its sub systems.

12

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

The exchange of system-level intellectual property (IP) models for creating executable specifications has become a key strategic element for efficient system to silicon design flows. As CtC++ is the dominant language used by chip architects,

system and software engineers prefer C-based approach to hardware modeling [11]. This demand has lead to a much popular homogeneous modeling open source system language known as SystemC [7]. The goal of SystemC is to facilitate the co-

verification of hardware-software systems by supplying a single language framework, where designer describes both hardware and software completely.
An immediate

advantage of having homogeneous modeling is that, it eliminates the need for complex programming language interfaces (PUs) or remote procedure calls (RPCs) interfaces, which will speed up the co-simulation process. SystemC also allows the user to When

successively refine models without translating it to an .HDL representation.

sufficient implementation details are available, the design can be handed to synthesis tools for circuit generation [3]. SystemC synthesis tools are still under development

by Synopsys Inc. and many other EDA vendors.

Heterogeneous modeling is another approach that can be used to model hardware and software early in the design cycle. The hardware and software are These

modeled using two different languages such as VHDL and etC++.

representations can then be ported to CAD tools, which allow hardware-software cosimulation for mixed language descriptions. examples of such tools [13, 14]. Seamless, Eaglei, CoWare N2C are

Appendix A contains Seamless tutorials to get started

in co-simulation environment using C and Verilog.

13

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

r
I
'"
~

g
0
i,

1

I

I
I
i
~

I

2.2 Validation and Co-simulation

Validation loosely refers to the process of determining the correctness of a design. Simulation remains the main tool to validate a model; however the importance of formal verification is growing especially for safety-critical embedded systems [15] . Formal verification is the process of mathematically checking the behavior of a system described by a formal model to satisfy a given property. systems is challenging because they are heterogeneous. In Simulating embedded these simulations

J.
n
I-

.f

c,

e
x
'I,

i
;
j
~

I c
~

t

part~cular,

1

·
I
I j
I I
i

J

contain both software and hardware components that must be simulated concurrently. This simulation challenge is known as the co-simulation problem. The basic co-

0

I

simulation problem is to reconcile two apparently conflicting requirements: · To execute the·software as fast as possible, often on a host machine that may be faster than the final embedded processor and certainly very different from it. · To keep the hardware and software simulations synchronized, so that they interact just as they will in the actual target system.

n

IS

~

It

~
;~

:g:

" &
~l

-e
,e
~

In hardware-software co-simulation, software· execution is simulated as being

executed on the target hardware.

Since gate and register transfer level hardware

)-

simulations are too slow for practical purposes, a more abstract execution model -is needed [16]. Moreover, as systems become complex, validation is necessary to insure

·e
d

that correct functionality and required performance levels are achieved in the implementation of a system model. between accuracy and performance. Different models can be employed with a tradeoff

14

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

·

Gate-level models are viable only for small validation problems, where either the processor is a simple one or very little code needs to be executed, or both.

·

Instruction-set architecture (ISA) models augmented with hardware interfaces. An ISA model is a standard processor simulator (often written in C) augmented with hardware interface infonnation for coupling to a logic simulator.

I

·

Bus-functional models are only hardware models of the processor interface that cannot run any software. Instead, they are configured (programmed) to make the interface appear as if software is running on the processor. A stochastic model of the processor and the program can be used to detennine the mix of bus transactions.

·

Translation-based models convert the target CPU code into a code that can be executed natively on the computer system executing the simulation. Preserving timing infonnation and coupling the

translated code to a hardware simulator are the major challenges.

When more accuracy is required and acceptable simulation perfonnance is not achievable on standard computers, designers sometimes resort to emulation. In this

case, configurable hardware can emulate the behavior of the system being designed. There are two types of validation during co-simulation of heterogeneous models: functional verification and perfonnance evaluation. During functional verification,

software part is executed on the host processor that communicates with the hardware part through HDL functional model of the system processor bus. In such simulation

15

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

e e

I
I
t
I
If

environments, the simulation time is very fast because software executes independent to the hardware simulator. To evaluate the performance of a system, VHDL model of a

I "
I
i
;

i

generic instruction set simulator that executes the software part on a functional model of the particu!ar microprocessor bus can be implemented. However, the simulation is

e n Ir

I f
~
~ ~

somewhat slower because software and hardware are synchronized to evaluate the correct timing of system operation. A more detailed discussion in functional

Ir d n n

; ,

I ..
~

t ~

verification and performance evaluation and their simulation results can be found else where [17] .

,
I
~

I

One popular commercial co-simulation tool is Seamless CVS by Mentor Graphics, which uses instruction set simulator, adapted memory, bus models and a target processor model to create virtual hardware environment [13]. The co-

· I i
I
~

I
~

~

simulation environment of Seamless is well modeled and gives accurate results in terms of timing and functionality of the entire system. Seamless tool has also brought new

t
fi

optimization algorithm during co-simulation to allow faster mstruction Set Simulation
~
~

(ISS).

The basic idea of faster ISS optimization scheme is that once a certain part of

the system has been verified, the simulation can bypassed the verified components to
)t

validate other parts of the system (Le. instruction fetch, memory reads and ~rite cycles etc). Another similar co-simulating tool is called CoWare's N2C and the methodology
In VIrtual Component Co-design (VCC) by Cadence, ·

,s

l.
~

of N2C can be found in [18].

i:
I,

the system behavior is verified separately from the system architecture.

Once system

t

behavior is verified, each functional block is mapped to the system architecture. Depending on the choice of partitioning (mapping function), the VCC system calculates the overall performance, and refines the architecture [19].

'e
n

16

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

These simulation environments rely heavily on the availability of a library containing processor or co-processor, communication, interface and memory models that may not be available. To avoid such problems, a more abstract approach is used
In this case, the

by Eaglei tool to simulate only functional behavior of the system.

simulation is more flexible and efficient at the cost of higher abstraction and fewer information details (such as timing and performance). Such simulation environment is

called Link Processor Model,. where the software runs on the host computer and communicates with another hardware simulating software.

I I
~
1

I

Rapid prototyping is another approach taken to design time dominated systems that require more than just functional verification. validating a target system yet to be manufactured. FPGA prototyping allows
~uch

1 I I

validating environment

provides design engineers with a more realistic data on correctness and performance than the system level simulation. The simulation now has a physical hardware

prototype in the loop, emulating the physical behavior of a system, which is implemented using FPGA technology for fast synthesis (e.g. Corsair) [9]. The only

downside of FPGA based prototyping is its limited flexibility during co-simulation. Unlike system level simulation environment, FPGA prototyping does not allow single stepping, register value checks or break points in the middle of operations. However,

the Rapid Prototyping Platform used by us solves this problem with the help of ARMs Integrator board and Multi-ICE technology. technology is described in Chapter 5 RPP section. A more detail description of this

17

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

,
:I

2.3 Synthesis

Synthesis can be broadly described as a stage in the design refinement where a

r

s
:l

I
I I
I ,.
~

high level 'Specification is translated into a less abstract specification.

For embedded

systems, synthesis combines the manual and automatic processes, and it is often divided into three stages: · Mapping to architecture, in which the general structure of an implementation is chosen. · Partitioning, in which the sections of a specification are bound to the architectural units. · Hardware and software synthesis, where the details of the units are filled.

s s It e e .s y
1.

I
i

Mapping from specification to architectural design is one of the key aspects of embedded system design. Supporting a designer to choose the right mix of

I I
~

I

components and implementation technologies is essential for the success of a final product. Generally speaking, the mapping problem takes functional specification as

~

e r, [s is

~
~

~

--)I

~

input and produces system architecture as an output and assignment of functions to architectural units. Architecture is generally composed of the following components.

.;g

-~

i

Partitioning determines which parts of the specification will be implemented on the
,;.~

']

~
-;0

above components, and their actual implementation will be created by software and hardware synthesis tool.

~

..::c;:-

~

18

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

·

Hardware components (e.g. microprocessors, microcontrollers, memories, 110 devices, ASIC's and FPGA's).

·

Software components (e.g. operating system, device drivers. procedures. and concurrent programs).

·

Interconnection media (e.g. abstract channels. busses. and shared memories).

The cost function optimized by the mapping process includes a mixture of time. hardware area and power consumption. where the relative importance depends heavily on the application type. Cost of time may be measured either as execution time for an Hardware area cost may

algorithm or as missed deadlines for a soft real-time system. be measured as chip, board, or memory size.

The components of the cost function Current

may take the form of a hard constraint or a quantity to be minimized.

synthesis-based methods almost invariably impose some restrictions on the target architecture in order to make the mapping problem manageable. For example. the

architecture may be limited to a library of pre-defined components due to vendor restrictions or interfacing constraints.

There are several types of architectural models, which use both processors and ASICs. Models included a processor with an ASIC, single processor with several All systems that automatically

ASICs. several processors with several ASICs.

synthesize circuits based on these models include an estimation system and a partitioning system. The estimation system allows the quick evaluation of alternative System partitioning allows the total task to

partitioning solutions in the design space.

19

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

be optimally shared by processors and ASICs, according to a given set of criteria including speed, cost or power.

System partitioning is required for any system design using more than one

I
I
1
1

component

It is a particularly interesting problem in embedded systems design Furthermore, as

because of their heterogeneous hardware and software unit mixtures.

we rapidly move towards an era of low cost high-speed processors and their cores, the boundary between software and hardware changes rapidly. What someone would

have said with certainty should have been implemented in hardware just a year ago, is probably implemented today in software for a fraction of the cost without sacrificing perfonnance.

.t
:t

Estimation tools have been notoriously ineffective in the past

Three of the

e

I I
I I
E

I

most widely used estimation tools have been profiling, hardware area estimation and execution time estimation. Profiling tools are a necessity to get information on how

long a particular segment of code takes to execute and how many times a loop is executed. Area estimation tools are used to assess the probable size of the hardware Lastly, executi.on time estimation
e~timates

;
t

I"

(ASIC) when it is implemented. execution time of hardware (ASIC).

the

d

r I
I
I

jO;

The tools used to estimate the size of area can be

I
y

extremely error prone, particularly since it is difficult to estimate the interconnection . area. The estimation error can be costly as the cost of chips (ASICS) is a step This situation is improved as more and more pre-

.

a

e
.0

I
I
I

i
~

I

I

If!

functional rather than linear.

fabricated cores are used in the design, which would then reduce the total amount of unknown interconnection area. The time taken for a particular ASIC to execute is

i

I

20

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

difficult to estimate without the final layout, since the clock frequency cannot be predicted. Often predictions are based on the number of cycles, but this is almost

useless without the clock cycle information.

Exploring the most common partitioning algorithms includes greedy heuristics, clustering methods, iterative improvement, and mathematical programming [16, 11]. These partitioning algorithms are usually effective and fast. be no clear winners among theses partitioning methods. However, there seems to

This is due to early research

efforts in this area and the intrinsic complexity of the problem, which seems to preclude an exact formulation with realistic cost functions. Furthermore, these partitioning

techniques depend on estimation and profiling tools to produce optimal partitions that make it quite unreliable if the estimation tools themselves .are not accurate.

After partitioning and sometimes before partitioning in order to provide cost estimates, the hardware and software components of the embedded system must be implemented. This process is also known· as co-synthesis because ,it involves Generally speaking, the constraints and

synthesizing both hardware and software.

optimization criteria for co-synthesis step are the same as those used during partitioning. Area and code size must be traded off against performance, which often dominates due to the real-time characteristics of many embedded systems. Cost considerations generally suggest the use of software running on off-the shelf processors, whenever possible. This choice, among other things, allows one to separate the software from the hardware during the synthesis process, relying on some form of pre-designed or customized interfacing mechanism. However, commercial tools for system synthesis

21

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

,

I

are not as mature as modeling and analysis tools.

Yet, because of its continuous

demand, EDA industry and researchers are working together to meet today's market demand.

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Chapter 3 System Partitioning Overview

3.1 Introduction

The key phase in the discipline of hardware-software co-design is the partitioning of system specifications into hardware and software modules for implementation, while keeping the system cost at the minimum. In other words, the

end goal of system partitioning is to minimize the hardware area, subjected to architectural and performance constraints such as memory size, timing constraints, power, etc. It is also known that such partitioning problem is NP complete, and many This chapter

algorithms and heuristics have been developed to solve this problem.

will discuss partitioning algorithms and heuristics that have been proposed by many researchers around the world to familiarize the reader in many methods and problems with the current co-synthesis approach.

23

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

3.2 Survey
A great deal of research work has addressed the co-synthesis and partitioning of system with one-CPU and ASIC hardware engine architecture [20, 21]. Given such

constraint, Potkonjak and Wolf [20] have addressed the problem of combining several
:I

concurrent tasks onto a single ASIC instead of designing a separate ASIC for each task. They discussed an iterative algorithm that combines tasks for a single ASIC implementation based on the bit-width requirements, register counts, source and destination locations of the task. The application-specific instruction processor

Ie )r Ie to

synthesis problem is to design a domain-specific processor by selecting the optimal "instruction set" for a class of applications. Typically, the class of applications is

.

:s,
ly er ly ns

analyzed to find the most commonly used instructions, and a data path and controller for

·

that instruction set is designed. problem.

Several bodies of research have addressed this

For instance, the optimal instruction set selection problem is formulated as

an integer linear program described by Ngoc and others [22].

Edwards and Forrest addressed the hardware-software partitioning for performance enhancement by finding the bottleneck in the software and moving that critical region to hardware [5]. Given a C code and taking the "performance profiler"

24

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

of it, the hot spots of the source code can be captured.

It then tries to accelerate the

software execution by implementing the hot spots to hardware components.

However,

before such transformation, one must calculate the performance gain versus the cost factor. If the solution is feasible (a good performance gain), new hardware and However, because the algorithm

modified software are generated and simulated.

I
t

never takes the transfer of parameters and data from memory or to other hardware into consideration, the overall improvement has not been as great as originally expected.
In some hardware software systems (when software is exchanged to hardware), data

transfer times accounts for almost 50% of the HW/SW execution time.

Another interesting solution was presented where formation of genetics was used to model the HW/SW partitioning procedure [23]. The algorithm takes the

control data flow graph where nodes represent functional elements and the edges represent control or data flow dependencies. First the HW/SW partitioning program is

mapped to a constraint satisfaction problem. Then the genetic algorithm is mapped to the constraint satisfaction problem by using a fitness function to generate successive chromosomes.
In genetic
hardware-softw~e

partitioning, three types of constraints The genetic algorithm uses the

were used and they are cost, timing, and concurrency.

25

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Ie
r,

fitness function to generate the next generation of chromosomes.

Selecting two

parents by performing crossover and mutations according to a given probability

it
d
n

I
10

i ·
iJ
iii

·

produces each generation.

Such chromosomes are decoded to calculate their fitness.

The main idea of genetic partitioning is that as the algorithm progresses, more stronger chromosomes will survive and their, children will also have higher probability of being fitter. The fitness functions are:

0

l.
a

I
I

Fitness= (FIT - coscpenalty) I FIT (if time_penalty=False and Concurrency_penalty=False) Fitness=(FIT coscpenalty) I (FIT x Time_pen_wt) (if time_penalty=True and Concurrency_penalty=False) Fitness=(FIT - coscpenalty) I (FIT x Con_pen_wt) (if time_penalty=False and Concurrency_penalty=True) Fitness=(FIT - coscpenalty) I (FIT x Time_pen_wt x Con_pen_wt) (if time_penalty=True and Concurrency_penalty=True) where

I
I
I ,.,
i
t ~
~

s
e

i I
Il
ill

· ·

FIT= Maximum of the coscpenalties in a population Time_pen_wt and Con_pen_wt are the weight values put to emphasize the violation of time and concurrency constraints. CosCpenalty is the sum of all the devices being used as Hardware.

s
S

t
~
't;

I %~

·

)

· I
~

.

'"
The method shows improvement of the average cost improving (decreasing) as time progresses. It is also concluded that as the search space (design space) increases,

~

~

"

!
i
~
~ ~

i

~

S

i

the genetic algorithm performs better as compared to other greedy and forward search approaches. However, as of yet the algorithm does not take into account the overhead

~

f ~

! t
,I
~

~

J
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

i

26

I

of the hardware interface and inter process communication.

Mapping and Implementation-Bin Selection (MmS) is another way of solving the hardware-software partitioning problem by heuristics [24]. The MmS partitioning

also work with a graph similar to control flow graph known as DAG where nodes represent computations and arcs represent the data and control precedence between nodes. The general structure of Mms is described in Figure 3.1. The GCLP

(Global CriticalitylLocal Phase) algorithm first traverses the DAG and maps each node to either hardware or software. such that an objective function is minimized. objective functions of GCLP algorithm are; The two

· Minimize finish time of the node (execution time) . · Minimize the percentage of resource consumed by the nodes (HW area and
SW size).
Fixed Nodes
GCLP

Free Nodes

IBS

Figure 3.1; MmS algorithm flow chart

27

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

However, the above objective functions contradict each other as if one would like to optimize the completion time, it will require more hardware and then the

I

I

percentage of resources consumed will not be optimum.

Therefore, the GCLP For example, if

algorithm selects an appropriate optimization objective at each step.

time is more critical factor then the objective function with the minimum completion time is selected; otherwise the one that minimizes the hardware area is selected. After

the completion of GCLP, all the nodes in the graph are selected as hardware and software.
)

Then the Implementation-Bin Selection (lBS) further selects the type of

implementation for each node. ..To select an appropriate implementation for the tagged node T, Bin Fraction Curve (BFC) is constructed for that tagged node. BFC is the

:l

I ..
I I g
J

I .,

curve obtained by calculating the bin fraction (BF) for each implementation is: · BF =No. of free nodes to L bin to meet time constraint / No. of free node Free nodes are the nodes that have not yet been mapped to either hardware or software, therefore for such nodes the algorithm tries to map them to H bin for minimizing the hardware area as long as the timing constraints are satisfactory. L bin

,.
;§

itr

i

t
~

J ,.
I
I
II
.a.

are the implementation of hardware-software which takes a lot of area/size but shorter computation time, and H bin are the implementation of hardware/software that takes little area/size but longer time to compute. The free node that is not mapped to H bin

i
i!

III

i I
""

I

I

iI

I

28

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

belongs to L bin as long as the hardware area constraints are satisfied.

The main idea

of BFC is to find the most variation in the BFC curve and selects that variable limit point for implementation that will result in the largest reduction in the area of free nodes. The MmS algorithm does not consider the communication overhead when calculating the objective function to minimize the completion time. Implementing nodes to L

bins of hardware at first seems to minimize the completion time; however, introduction of more hardware to the system can increase the communication overhead that degenerates the completion time for the overall system.

I

t

Another similar partitioning algorithm is ·proposed by Ondghiri and others, where the difference lies in the search technique [25]. Instead of using objective

functions to map nodes to hardware and software for a particular solution, the hierarchical design space is explored to provide various solutions. design space search is done by varying its granularity level. The hierarchical

Variation in granularity.
If the

allows the designer to start with an input behavior at the process level.

performance constraints are not satisfied, finer granularity is selected to increase the number of basic blocks. This operation is performed gradually by accessing The most complex model of the

successive levels in the hierarchy of the input system.

29

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

a
it

input system (operation level) is used only when the performance constraints are not satisfied by the higher complex model. Granularity feature in a co-design tool

:s.
g

provides an enlargement of the design space and avoids the use of a detailed and complex model unless the required performance is not reached by using simpler models. The analysis of this algorithm showed that too abstract or complex model did not provide an optimal balanced solution in general, and there exist an optimal solution at some level between the two extreme levels.

L
In

at

Most of the partitioning .algorithm worked first from the software side and tried
rs,

I
! ?

I

to move the critical region of the software to the hardware component.

The next

t
partitioning algorithm introduced by Togawa and others tries to do the opposite [26]. · Given an input assembly code generated by the compiler, the hardware-software partitioning algorithm first determines the types and number of required hardware units as an initial resource allocation for a processor core (such as multiple functional units, hardware loop units, and particular addressing units). Then the hardware units
!

ve he ::al ity the the ing the

;
i

:1

i

J
~
~

1

'l

determined at initial resource allocation are reduced one by one while the assembly code meets a given timing constraint. The execution time of the assembly code

becomes longer but the hardware cost for a processor core to execute it becomes smaller.

30

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Finally, it outputs an optimized assembly code and a processor configuration.

In this

partitioning environment, the solution will produce an optimal processor core for a particular assembly code and only for that assembly code. performance is limited to one particular type of application. Hence, the processor's

It is clear now that hardware-software partitioning can be considered as a process that can be performed by means of different algorithms. like adaptation of classical circuit partitioning algorithms [21, 27], standard optimization methods of simulated annealing [28] and Tabu search [12]. The constraint-driven system

partitioning algorithm presented by Lopez-VallejO" and others however suggest the use of a powerful cost function to consider system constraints in the hardware-software partitioning process [29]. This is performed by
formul~ting

different cost functions

that will drive the partitioning process.

The use of complex cost function allows the Another strong point of the proposed

algorithm to capture more aspects of the design.

cost function is its generality and therefore, it does not depend on the problem and can be easily extended for considering new design constraints. The cost matrix function

described by Lopez-Vallejo is general enough to be used in any partitioning algorithm that considers partitioning as a constraint satisfying problem [29].

31

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

is a The other researchers have also considered the hardware-software partitioning problem as constraint satisfying problem. The partitioning method by Hardt is based

's

on design specification analysis under the restriction of defined architecture and interface in order to make hardware-software partitioning problem feasible [4]. This

restriction is acceptable as there are many systems built from a standard architecture for general purpose computations. a set of interacting modules. During specification analysis, a design is thought of as The suitability of each module for hardware

implementation is examined during the four phases . · · · · The analysis phases take static aspects (SA) Dynamic runtime characteristics (DA) Parameter transportation costs (PA) Main memory access (MA).

.

These specification analysis phases result in a cost vector 'I'=(SA,DA,PA,MA) in which the partitioning algorithm tries to minimize '1'.

32

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

3.3 Summary
From all the partitioning technique discussed, most of the methods take static aspect fonn of the constraint satisfying problem by optimizing certain cost matrix function. Furthennore, most of the partitioning algorithms would take either

dependency graph or execution graph as an input to generate a new set of partitioned graph of hardware and software. The solutions presented, however, only seems to

work in ideal cases, as the hardware-software partitioning problem is still too complicated to deal with the actual implementation issues such as delays, communication overhead, interface overhead, etc. Hence, for a commercial product to

exist, hardware-software partitioning solution must deal with the implementation issues. The DADGP algorithm presented in this thesis verifies the perfonnance of the algorithm in simulation, and also in actual implementation to fully validate the proposed approach.

33

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

F

Cbapter4
DADGP-BASED HW/SW PARTITONING
I{

r

4.1 System Specifications

:l

We use textual representation for specification and graphical representation for
)

system partitioning and scheduling to incorporate the possibility of ever-changing demand.

)

ac++ is used as the initial system specification language, and through

profiling, the system specification is converted into DADGP representation for partitioning.
)

SystemC can also be easily incorporated into our approach for future The high lev61 system specification is translated into

improvements.

ac++ in the

form of modules so that each module can be evaluated and mapped to the process space during profiling (similar to SystemC). The translation levels of specification to Every system is made up of small

modules are also referred to as granularity level.
f

and large modules, and in order to partition a system, the level of system modules must

I

be decided.

For example, during the block matching step of MPEG, sum-of-absolute-

I
I

I

\f

differences are calculated to measure the similarity between the macroblock and image search area.
If one is to develop an IP block to calculate the sum-of-absolute-

differences, equation 4.1 is first translated into C/C++ specification, where the · granularity level is selected as sub, abs and sum modules. The partitioner will then use the information provided in Figures 4.1a and 4.1b to generate the initial DADGP as shown is Figure 4.1c (initial DADGP solution). Other granularity level can be

selected to gain different sub optimal partitioning results.

34

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I
IS;

IIM(i,j)-S(ix,jy)1
jSn

(4.1) sum-of-absolute-differences Figure 4.1a: Data table

Processing Elements (PEl component
sub ahs

PEO

PEl

6
4
3

5 8

sum

2

for ( i=O;i<=16;i++) { for G=O;j<=16;j++) { temp=sub (M(ij),S(i,j»; ~emp 1=abs(temp); result=sum(result,temp 1);
} } /I M(ij) is the object matrix, S(ij) is the search space matrix

Figure 4.1 b: C specification of blocl\ matching algorithm

One
Execution

Precedence edge

Data dependency

Figure 4.1c: Initial BADGP

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I'
4.2 DADGP Graph Representation
Graphs are discrete structures consisting of vertices and edges that connect these vertices. There are several different types of graphs that differ in terms of type Problems related to most of the

and number of edges that connect pairs of vertices. disciplines can be solved using graph models.

We show in this thesis how a DADGP First of all, we

graph is used to solve a hardware software partitioning problem.

introduce a formal definition of DADGP to understand the structure of this graph.

4.2.1 Formal Definition

A graph G is a pair (y, E), wher.e V is a set of vertices, and E is a set of edges between the vertices such that:
E ~ {(u,v) I u, v ev}.

There are also two types of edges E, directed edge (D and undirected edge (U) Where: D= {dl ... dn }, and the other non-directed precedence edge u=
{UI ··· Um }

to connect vertex V.

The graph G is connected with a directed edge if and only if the two vertices have producer consumer relationship. required by
V2

.

For example if vertex

VI

produces data that 'is The graph vertices

then

VI

and

V2

are connected by a directed edge dl.

are connected with undirected precedence dependency edge if and only if the two vertices are independent of each other in terms of data generation and consumption.

36

t
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

For example, if vertex own, then vertex
VI

VI

produces data and

V3

does not require such data to compute its

and

V3

are said to be independent.

The vertex and edge of a graph G can also be weighted. in terms of their execution time.

Vertices are weighted

Furthermore, a vertex can represent either software

functional node or some hardware functional node (ASIC), and its appropriate execution time values are assigned to each vertex. communication between two vertices. Every edge is also weighted to model the
VI

For example, if vertex

produces 32 bits of

data that is required by V2 then the weighted value of edge d l (that connects VI and V2) is 32 divided by the data transfer rate. Undirected edges will have weighted value of

zero since there is no data transfer required between vertices that are connected with undirected precedence edge U.

Finally, the graph G can not have any circuits or circular path.

For example,

from any vertex of G, there can not be any path that has the same starting vertex and ending vertex (starting vertex is a node where· the path begins, and ending vertex is a node where no more edges exists). Where path, P

={PI ... Pz}, and p is a set of distinct
The graph that

vertices and edges that are connected to each other with edges D or U.

follows these definitions can be called Directed Acyclic data Dependency Graph with Precedence (DADGP). A more detailed operation· that can be performed with

DADGP will be discussed in the following chapter.

37

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

4.3 Hardware-Software Partitioning Algorithm

System partitioning algorithm described in this section can be divided into three major components. · · · Profiling of C++ LD path search (Longest Delay) Mapping of LD path and Scheduling

The last two steps are repeated until an adequate solution is reached. explanation of LD path search method is provided in this section.

A more detailed The proposed

partitioning system flow chart is also shown in Figure 4.2 with the following assumptions: · · · Initial target architecture of one processor core. Every node is executable with at least one PE. All nodes can be implemented as either a hardware or a software module. · Inter PE communication is measured by the amount of data transferred, where transfer rate is same for all nodes. Communication' overhead is zero for nodes that are executed by the same PE. · The partitioner has all the necessary information including execution time of each node on different PEs, cost of adding PE, inter PE communication between all PEs, and initial system constraints (required system execution time and maximum hardware area).

38

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Profiling

Figure 4.2: DADGP design flow

4.3.1 Profiling

Profiling is performed by executing C++ based system specification on the target processor. The software profiling is a useful step as we must check whether an If we translate the system specification into

all software solution is acceptable.

software that can fulfill the deadline requirements on the target platform then system

39

-------- ----------------------

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

partitioning will not be necessary.

However, in most of the cases, all software solution

may not be possible for high performance real-time embedded systems and hardware software partitioning step needs to be performed. It is also vital to execute the C++

based system specification on the actual target platform to accurately collect the profiling data. This method also naturally considers SW-SW cominunication

overhead between two software tasks, and is included as part of the module execution time.

The profiler translates each module of C++ system specification into nodes with the following information:

· Execution time of each module · Start and end tiine of each module

·

Amount of data transfer

· The caller(s) of the module · The child(s) of the module

·

Module identification

· Execution order

The profiler uses the above information to generate the DADGP.

The unique

characteristics of DADGP is that it contains two types of edges to represent the system. · · Data dependency edge Precedence dependency edge

The data dependency edge is represented with an arrow symbol as shown in Figure 4.1c.

40

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Two nodes are connected with data dependency edge when they have a producerconsumer relationship. The precedence dependency edge is represented by a normal The precedence dependency captures the

line to connect two independent nodes.

order of execution between nodes and such nodes can be executed in parallel if desired. A more detailed discussion on DADGP is provided as part of mapping and scheduling.

4.3.2 Mapping and Scheduling

DADGP is a super set of Directed Acyclic Graph (DAG). with the only difference of having two types of connecting edges. Our contribution to DAG is the

introduction of precedence dependency edges to explicitly represent the independence and the execution orders between nodes. algorithmically friendly to capture non-parallel hardware-software partitioning. The I?AG representation is not
ex~utions

of independent nodes for

Exposing the independence and introducing

parallelism between independent nodes are not always the best decision when optimizing the execution time of a system due to inter PE communication overheads. The incorporation of DADGP to our partitioning method has allowed us to only expose the necessary parallelism for capturing wide rage of solutions.
'.

'

The Longest Delay path (LD_path) represents the longest execution route in a DADGP. LD_path is not just determined by the number of node hops. but it also depends on the execution time of each node and corresponding inter PE communication overhead as
. <

seen in equation 4.2.

·

!

·

41

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

(4.2)

where node niE {nl ... nN } and they must be connected with any type of edges (all edges D or U). p={ n i
···

ejE

E

n N , ej

···

eN-I} is a path from one root to any ending node.

P=( PI ... PM } is a collection of all paths from one root to any ending node. M is the total number of paths in a given graph. LD_path can be found with the following equation. LD Path= Max [LD time (Pi)] where k varies from 1 to M.
(4.3)

Finding an LD_path in a DADGP is similar to finding a bottleneck in the system. The LD_paths are used to improve the overall execution time by mapping A repeated searching and mapping of

one of the 'LD_path nodes to hardware.

DADGP reduces the search space and improves the convergence rate for an optimal solution. The LD_path searching algorithm is given below. L = { II ... IN}; IIset of all leaf nodes in a DADGP for ( i = 1; i++; i <= N ) lIN is the total # of leaf nodes P = Find_path(li); l!Finds all unique path from Ii to root(s) II now set P has all the paths from leaf to root max =0; for ( i = 1; i++; i <= M ) 11M is the total # of path{ temp = LD_time( Pi); if ( temp> max ) then{ max = temp; path = Pi; } } II After checking all path maximum delay path is found

42

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

4.3.3 Mapping and Scheduling of DADGP

This is the most sophisticated and important step of our partitioning algorithm.

After

finding the LD_path, one of the nodes in the path is mapped to the optimal hardware. However, to make such critical decision, following factors must be taken into consideration. · · · · · Parallelism in DADGP nodes PE resource limitation PE Execution time of nodes Inter PE communication Hardware area (cost)

The PE can be a dedicated hardware unit or -a software task being executed on a processor. The algorithm starts by finding the LD_path from a given DADGP and the All the nodes in the LD_path are

execution time of LD...:.path is also calculated.

mapped to appropriate hardware, one at a time and scheduled to calculate the overall system execution time. A node that allows maximum improvement of system

execution time is finally mapped as hardware and the DADGP is updated according to the final mapping decision. This process is repeated for all the LD-paths as explained

in the partitioning algorithm given below.

43

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

,I,

I

nA ' e1 ··· eB } IIA is the total number of node, and lIB is the total number of edges Previous_system_EXE 00; II highest allowable value by the system while System_EXE > Required_EXE) AND (CurrencHW_area> Required_HW_area)) { LD_path Find_LD_path (graph); llfind the LD_path from a given graph LD_path_EXE LD_time (LD_path); IIcalculated the execution time of LD_path Min_EXE = 00; II highest allowable value by the system for ( i = 1 ; i++ ; i <= A ) { G =map (DADGP, n j ) ; IIwhere G is a new DADGP with the node njE LD_path nodes mapped lias HW.
LD_path
1 ···

={n

«

=

=

=

(EXE, S, G_prime)

=schedule (G);

II G_prime updated G II S schedule of G II EXE execution time of G II schedule details are given in the schedule algorithm below

=

=

if ( EXE < Min_EXE ) then {
Min_EXE

=EXE;llsave the current optimal execution solution

graph =G_pnme;ll save the current partitioned DADGP Final_S }

=S;llsave the current schedule result after a valid IImapping

} II successfully found a node to be implemented as h3fdware

if ( previous_system_EXE < Min_EXE ) then
return (graph); IIreturn current partitioned graph IIsystem could not be improved any further, and it could IInot satisfy the given constraints. previous_system_EXE = Min_EXE;

II save previous solution

} II now the solution is found and the algorithm is terminated normally return (G, FinaCS); II return currently partitioned graph with its scheduling

44

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

The scheduling function "schedule (G)" is summarized as: a) b) c) Start scheduling from the root of DADGP. Traverse down the tree and schedule the earliest starting time node.

If a node is connected with precedence dependency edge, check to see
whether exposing parallelism can eliminate that edge.

If a precedence

dependency edge is eliminated, the structure of the DADGP may change and some nodes can be disconnected from the original graph resulting in two separate DADGP.

In this case, the new root of the disconnected DADGP

must be combined to make one DADGP by connecting it self and the original root to a new dummy node called "start". d)

If multiple descendents (or roots) exist, force schedule all descendents (or
roots) by adding necessary PE if required.

e)

Update PE resource library and generate the total execution time by using · the following equation:

where, nj _exe = execution time of a node that is currently in interest, HW_exe IPC

= HW execution ,time of node

nj

·

=Communication value introduced by mapping node

n, to

additional HW, hidden_node_EXE = smaller execution time value between two parallel modules.

45

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

r
4.3.4 Complexity of the Algorithm

One measure of efficiency of an algorithm is the time used by a computer to solve a problem by using the algorithm for a specified input value. A second measure

is the amount of memory required to implement the algorithm when input values are of a specified size.
An analysis of the time required to solve a problem of a particular

size determine the time complexity while analysis of the computer memory required involves the space complexity of the algorithm. The time and space complexity
It is obviously important

analysis of an algorithm is essential for its implementation.

to know whether an algorithm will produce the answer in microseconds, minutes, or years. Likewise, the required memory must be available to solve the problem.

Considerations of space complexity are tied with the data structures used to implement the algorithm. We assume that enough memory resources are available as the

proposed partitioning algorithm has already been implemented and executed without a memory deficiency. Hence, space complexity will not be' considered and we will

restrict our attention to time complexity.

Time complexity is described in terms of number of operations required instead of actual computer time because of the difference in time needed for different computers. Moreover, it is quite complicated to break down all the operations to the basic computer , operations. Furthermore, . the fastest computers in existence can perform basic bit

operations (for instance add, mUltiply, compare, or exchanging) in nano seconds but personal computers may require micro seconds that takes 1000 times longer to perform the same operation.

46

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

For simplicity, assume that there are n=2k paths in the DADGP graph where k is a nonnegative integer and k=log(n).
If n is the number of paths in the graph and it is

not a power of 2, then the graph can be considered as part of a larger graph with 2k+l paths where 2k<n<2k+l where 2k+l is the smallest power of 2 larger than n. at maximum the algorithm will take log(n) times to find the LD_Path. Therefore, Mapping

procedure only considers nodes in the LD_path and therefore the complexity of mapping algorithm is just the number of vertices in the LD_path, and this is bounded by N, which is the total number of nodes in the DADGP graph.

Scheduling algorithm also traverses down the DADGP and schedules the entire vertices (nodes) according to the resource
availab~lity

and

verte~

start time.

Therefore, the

complexity of the scheduling algorithm is also bounded by N because it can not consider more vertices than what is in the DADGP.
In such cases, the complexity of

the entire algorithm from LD_path search to mapping and scheduling is N X N X 10g(N) because LD path search, mapping and scheduling is iterative process of the partitioning algorithm.

47

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Chapter 5 Experimental Results
Heterogeneous system architectures are commonly found in high performance embedded systems. They are application specific systems that contain hardware General and special purpose

and/or software tailored for a particular application.

processors, digital signal processors, and ASICs are among the many components of these systems. In these systems, heterogeneous processors are tightly coupled with

low inter-process communication (IPC) overhead but with heavy resource constraints. Therefore, the schedulers for such heterogeneous systems need to account for IPC overhead and processor heterogeneity where a task has different execution times on different processors. Task scheduling for homogeneous multi-processors has been a

difficult problem in the past while scheduling problem for heterogeneous processors is much more difficult.

In this chapter we present experimental results showing the validity of DADGP based partitioning algorithm. First of all, we begin with a brief overview of two General Dynamic

simple yet well known partitioning and scheduling algorithms: Level [18] and Simulated Annealing technique [12].

Secondly, these two techniques

are implemented and a performance comparison of these algorithms with DADGP
technique is presented by using randomly generated graphs as their input. Lastly, the

.

results from two application implementations to the actual hardware-software system are shown to compare the simulated partitioned results. Block matching and SOBEL

48

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

edge detection applications are partitioned using the DADGP technique.

They are

implemented using a Rapid Prototyping Platform (RPP) containing an ARM7 processor and Xilinx FPGA for custom hardware.

5.1 GDL Scheduling Technique
·The GDL scheduling takes a standard DAG as an input task graph. A DAG

node represents a task to be executed on a processor and a directed edge indicates the data dependency between two nodes. specifies the amount of IPC overhead. Each edge is associated with a number that The algorithm assumes that the execution time

of a node Nj on a processor Pj, E(Nj,Pj), is known at compile-time for each processing element
If node N j (task) cannot be executed on proce~sor Pj, the value of E(Ni,Pj) is

infinite (a very high number). instruction for node Nj.

This occurs when processor Pj has no resource or

The algorithm also assumes that the target architecture has a

dedicated hardware for IPC so that inter-processor communication time can be overlapped with computation time in a schedule. An example DAG and its node execution-time table is shown in Figure 5.1.
PEO Cost=: 20 PEl Cost=:40
6

PE2 Cost=:50

A

3
2

3
9

B
C

7
5 2
2

5
1

1000
1

D
E

10

1000

Figure 5.1: An example of DAG and its node execution time table

49

------~---------

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

The scheduling objective of GDL is to minimize the scheduling length of the input DAG. The scheduling problem is NP-hard in the strong sense and therefore it GDL algorithm is one of the existing scheduling heuristics for

relies on heuristics.

heterogeneous scheduling problem and it is based on the list scheduling idea [18]. Each node is assigned a priority and GDL calls a node runnable when its ancestor nodes have been already scheduled. decreasing order of priority. The list scheduling schedules the runnable nodes in the The variants of list scheduling techniques differ in terms

of how to assign priorities to the nodes and on which processor a selected node is to be scheduled.

The schedule length can not be less than the maximum length (or critical path length) of a node to the terminal node. Therefore, to minimize the schedule length, it

is intuitive to assign the highest priority to a node from the longest critical path length. The critical path length of a node is the sum of execution time of nodes on the critical path and the IPC overheads incurred if these nodes are assigned to different processors. The IPC overheads are not known before the descendant nodes are scheduled, therefore a typical list scheduling technique considers only the' sum of execution times on the critical path to determine the priority of a node. node. We call it the static level SL(Ni) of a

The static level of a node becomes the critical path length if all nodes on the
In a heterogeneous system, however,

critical path are scheduled to the same processor.

.

a node has different execution times on different processors.

If we choose the smallest

execution time of a node in the static level computation, it may not be possible to assign the node to the same processor as its ancestor. is problematic for heterogeneous systems.
In this case, ignoring the IPC overhead

Therefore, the GDL scheduler defines the

50

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

assumed execution time of node Nj, denoted by E*CNj), as the median execution time of node Ni over all the processors.· If the median execution time is infinite, the largest finite execution time is substituted.

The GDL scheduler considers the effects of IPC overhead by adjusting the priority level when the node becomes runnable. DACNj,Pj) is defined to be the earliest

time that all data required by node Ni are available at Processor Pj, where IPC overhead is accounted for. TF{Pj) is further defined as the time that the last node assigned to the jth processor finishes its execution. The node Ni can not be scheduled before TCNi,Pj), To account for the A large

which is the maximum of DACNi,Pj) and TF{Pj) for processor Pj. varying processing speeds, they also defined positive
~(Nj.Pj)
~CNi,Pj)

= E*CNi) - E(Ni,Pj).

indicates that processor Pj executes node. Ni more rapidly than most of
~(Ni,Pj)

the other processors, while negative value of

indicates the opposite.

By

incorporating these terms, they first extended the static priority level to the dynamic priority level DLICNi,Pj) as given below:

DLICNj,Pj) level gives a higher priority to a node with regard to processor Pj. Higher static level means that it can be scheduled earlier or the it can be executed faster. Although DLI CNi,Pj) indicates how well node Ni is matched with processor Pj, but it
fails to consider how well the descendants of Ni are matched with Pj. If a descendant

node of Nj can not be scheduled on Pj due to resource constraints, the IPC overhead between node Ni and its descendant should be considered to estimate the cost of assigning N j to processor Pj. From this observation, GDL scheduler selects a

51

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

descendant of a node with the largest IPC overhead D(Nj) and another function F[Nj,D(Ni),Pj] is defined to indicate how quickly D(Ni) can be completed on any other processor if Nj is executed on Pj. Then, the effects of descendants on the level of node

DC(Nj,Pj) roughly indicates how well the "most expensive" descendant of node Ni matches with processor Pj, if Ni is scheduled on PjIncorporating the descendant

consideration term modifies the level of a node on processor Pj as:

In addition to the descendant consideration effect, a heterogeneous processing environment also introduces a cost associated with a node if it is unable to be executed on a certain processor. To characterize this resource scarcity cost, they selected an Then

optimal processor Pj* on the second best processor to maximize DL2(Ni,Pj). the "generalized" dynamic level is defined as:

GDL (Ni,P) ~ DL2(Ni, Pj*) + C(Ni).

The second term indicates an increase in the dynamic level if the node is forced to be scheduled on the second optimal processor. Now GDL scheduling technique Figure 5.2 shows

selects the runnable node of highest priority or highest GDL value. the overall flow of GDL algorithm.

52

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

System Functionality

Profiling

DAG

Calculate Priority with GDL

Schedule highest priority

NO

YES

c::::>

Finish

Figure 5.2: GDL algorithm flow chart

5.2 Simulated Annealing Based Partitioning
The idea of simulated annealing originated from metal processing. Annealing in metal processing is how a liquid becomes progressively more organized into a solid as the temperature falls slowly. Metropolis formalized this into an algorithm shown in Figure 5.3 [30]. Simulated annealing is similar to the well-known greedy algorithm [31] except for two key differences. Both incorporate the concept of neighbor (nodes),

53

)

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

which is created by making some changes to the current solution.

However, the

greedy algorithm always follows the neighbor with the largest gain, whereas simulated annealing picks random neighbors. accept a neighbor with a higher cost. In addition, the greedy algorithm will never On the other hand, simulated annealing may

J

accept a neighbor with higher cost, depending on the gain, temperature, or a randomly generated value. These differences have important implications; while the greedy

algorithm will always find the local minimum, simulated annealing attempts to find the global minimum. The other implication is that simulated annealing depends on

random numbers that makes it probabilistic in nature. As simulated annealing can be adapted to a multitude of problems, one has to adapt the algorithm for system partitioning. Our basic implementation of the simulated annealing algorithm is fairly

straightforward as shown in Figpre 5.3. Main course of Simulated Annealing events can be summarized in 4 steps:

i.
ii.

Starts with an initial partition and an initial simulated temperature The temperature is slowly decreased For each temperature, random moves are generated Any cost-improving move is accepted. Otherwise, it may still accept the move, but acceptance becomes less likely at lower temperatures as given below

iii.
iv.

·

Accept(

~cost,

temp ) returns 1 if the move should be accepted, otherwise it

returns a value in the range of [0,1] · Decrease Temp (temp) is often defined as temp_new =a x temp_old; where 0 < a<l · Equilibrium can be approximated as no improvements for some number of iterations

il ,

54

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

temp= initial temperature, cost=Objfct(P) while not Frozen loop
while not Equilibrium loop

P_tentative = RandomMove(P) cost_tentative = Objfct(P_tentative)
~cost

= cost tentative - cost ) > Random(O,l) ) then P = P_tentativecost cost cost tentative

if(

Accept(~cost,temp)

end if end loop

temp=DecreaseTemp(temp)
end loop

where: Accept( dCOSt, temp) =min( I, e-(~ost/temp») Objfct(p) returns a cost value of current partition P, and cost represents systems execution time and hardware area Figure 5.3: The basic simulated annealing algorithm.

5.3 Software Simulation
To compare
~e

perfonnance of our DADGP based partitioning algorithm, we
Simula~d

have implemented GDL and

Annealing algorithms.

Each partitioning

algorithm have been given the same set of randomly generated DAG ranging from size 3,9, 100,250, 500 to 1000, and their results are presented here. The DADGP based

partitioning algorithm has also been given the same set of graphs except that the DAG graph is first converted into DADGP (refer to Chapter 4.2 for detail).

55

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

The experimental results for DAG graph of size 3 is shown in Figure 5.4, which demonstrates the ability of DADGP partitioning algorithm that considers mUltiple descendants indirectly without the added complexity of their calculations.

Considering GDL algorithm [18] and its complexity, the scheduling inherits the traditional weakness of conventional list scheduling where global effect of scheduling decision is not measured properly. The GDL scheduler improved on list scheduling However,

by quantifying the scheduling effects on the descendants of a node.

considering just the first descendants is not enough to measure the global effect. Consider DAG graph of Figure 5.4 .and its corresponding parameters for GDL algorithm whose scheduler results are presented in
Figur~

5.5 in the form of Gantt chart.

After

scheduling node A, the GDL fails to consider the effect of processor selection for node C. GDL algorithm can only Jook up to node B (first descendent) as it schedules node

A on processing element PEO hoping that it will also assign node B to PEO in the next iteration. However, the final scheduling result suffers from a large inter-PE

communication overhead between A and B as node B is scheduled to processor PEl considering node C's execution time on processor PEO in the next iteration.

Tasks
A B

PEO
Cost=20
1

PEl
Cost= 50
.2 2

2
20

,

C

1

Figure 5.4:

DADGP without Precedence

56

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

PEO

A

PEl

B

c
11 13

Figure 5.5: GDL Scheduled Results

The DADGP initial graph is obtained in Figure 5.6 which is exactly the same as the DAG of Figure 5.4 because the graph does not have any precedence dependency edges and hence no parallel execution is possible. simple because there is only one path. Obtaining the LD-path is also

DADGP then tries to find a node that can

improve the overall system execution by mapping tasks to another PE (Processing Element) assuming that PEO is the target processor (soft,,:are) and PEl is the additional PE (ASIC, Processor, etc). Then the initial DADGP is given in Figure 5.6 our The

algorithm assumes that all nodes are initially executed as software (on PEO).

partitioner will first move node C to PEl to reduce the total execution time (C is the Min[EXED. In the next iteration, node B is moved to PEl to reduce inter PE In the third iteration, node A is finally

communication overhead between Band C.

moved to PEl to reduce the inter PE communication overhead, and the optimal scheduling is obtained as shown in figure 5.7.

Figure 5.6:

Initial all software DADGP solution

j

~-

,

57

).

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

( ,
'f

i

II
PEO
PEl
A

B

c
4 5

2

Figure 5.7:

DADGP Solution

Simulated Annealing algorithm also arrives to the optimal solution by assigning and scheduling the entire task to processor Pl. However, due to the selection of

random neighbors in simulated annealing, execution of simula~ion mUltiple times with the same data has given different results. But only the best results have been recorded.

The experimental results for bigger sized graph have been recorded and are shown in Table 5.1. The perfonnance gain is defined as the ratio of non-optimized execution Cost is the amount of hardware

time over optimized execution time of DADGP.

required, and simulated time is the time it takes for completion of simulation, and execution time is the target system execution time based on the partitioned results. The random DADGP graph generated for 9 nodes can be seen in Figure 5.8a. The

optimal solution obtained with DADGP based partitioning algorithm is shown in Figure 5.8b.

In comparing the perfonnance gain of these three algorithms, DADGP has shown outstanding results as shown in Figure 5.9. For smaller size graphs, all three This is The difference

algorithm have shown similar results in tenns of performance gain ratio. expected because the solution space for such a small graph is limited. appeared when the graph size is increased to 9 or more nodes.

In fact, GDL algorithm These results
. ,""
:~;

has shown lower perfonnance gain with the increase in graph size.

58

-----

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

show that GDL is suffering from wrong decision making as it can not consider multiple levels of descendants. Simulated Annealing has shown almost constant performance DADGP, however, shows increase in performance This characteristic is very desirable because

gain across different sized graphs.

gain as number of nodes are increased.

increase in graph size means that there are more opportunities for improvements, and DADGP algorithm is exposing various solution spaces.

1

2

(b) Optimal Solution

(a) Initial DADGP

Figure 5,8: Randomly generated Graph (9 nodes)
59

J
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Table 5.1:

Software Simulated Comparison Experiment Results

DADGP flofNodes 3 9 100 250 500 1000 3 9 100 250 500 1000 3 9 100 250 500 1000

Cost 50 195 400 350 600 550 70 125 220 320 370 570 70 95 200 360 550 770

Exe Time 5 18 7350 12250 19015 29400

Simulated Time 0.2s 0.43s 15.4s 71.3s 271.25s 486.1s GDL 0.6s 2.01s 237.16s 601.2s 1363.67s 3954.64s SA 0.72s 0.89s 20.1s 100.5s 324.4s 501.4s

Performance Gain Ratio 4.4 5.5 9.9 14.86 19.14 24.76 1.57 2.63 3.56 3.03 1.77 2.31 4.4 2.94 4.04 4.53 4.5 8.99

14 38 20472 60142 205422 314721 5 34 . 18021 40124 80804 80984

Where Exe Time is execution time of partitioned system when scheduled. Simulation time is the time it takes for an algorithm to partition a given system. Performance gain ratio is Exe Time of all software solution over partitioned solution.:

60

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

PRam

100

250
Nodes

500

aDADGP

DSA

Figure 5.9:

Perfonnance gains DADGP algorithm shows

The next important result is the simulated time.

improvement on all graphs, but it is also important that the algorithm is executed in a reasonable time. Figure 5.10 shows the simulated time for all three techniques vs. The GDL As the

graph size, where· DADGP method again indicated its superiority.

algorithm indicated slower simulation time due to its O(N3) complexity.

number of nodes increases in the graph, the simulated time increases exponentially. The runtime of DADGP and Simulated Annealing provide good results through out the experiment, keeping the simulated time below 10 minutes for a Pentium processor under the worse case scenario.

m 600Mhz

fI
61

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

, I
4000 3500 3000 2500
Second 2000

1500 1000 500 0 3
9

100

250
Nodes

500

1000

II DADGP

DSA

Fi~re

5.10:

Simulated time

It is important to note that performance gain must come with a reasonable price,

and this is evident in Figure 5.11 that shows the performance gain for DADGP algorithm. On average, DADGP solution is always expensive than GDL, however, The DADGP algorithm

increase in performance gain can compensate for its cost.

explored parallelism in the system to increase the performance; therefore, there must be additional components in the system to accommodate tasks concurrently. The

difficulty is to explore those parallelisms in the order of maximum performance gain with minimum cost. GDL algorithm seems to show the inverse relationship to maximize performance gain. It provides improvements to the system, but with more hardware Combining the results of Figures 5.9 and 5.11, we can The

.

components than necessary.

derive another important hardware to performance ratio as shown in Figure 5.12.

hardware cost to performance ratio indicates the performance gain of the system by

62

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

adding more gates to the system.

The results indicate that as system becomes more

complicated (bigger), it is more difficult to increase its performance by adding extra hardware as shown with SA and GDL algorithms. However, DADGP algorithm has

shown increase in this ratio indicating that the algorithm can add necessary hardware to increase the performance. The results are also related to maximum performance

bound as addition of more hardware after curtain performance boundary will only degenerate the system.

No.of gates

9

100

250
Nodes

500

1'1 DADGP

DSA

Figure 5.11:

Hardware area cost

63

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

0.09 0.08 0.07

o .Q6
0.05 0.04 0.03 0.02 0.01 0 3

9

100

250
Nodes

500

1000

II DADGP

OSA

Figure 5.12: Hardware cost - Performance ratio

5.4 Rapid Prototyping Platform
Rapid-Prototyping Platform (RPP) consists of an ARM7 CPU and FPGA based hardware components to enable the prototyping and design of embedded systems. The RPP features two or more daughter cards, housed on a motherboard (ARM's Integrator/AP board) that are: · · The ARM7TDMI core A re-programmable hardware module, featuring a Xilinx Virtex-2000E FPGA. The Integrator board allows stacking multiple cores (e.g. ARM7, ARM9) and logic modules (Xilinx or Altera) as shown in Figure 5.13. RPP provides a softwareThe design flow for the RPP

'I

programmable processor ,as well as hardware modules.

64

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

involves both software and hardware design tools. Figure 5.14 demonstrates the flow from specification to integration of hardware and software designs on the RPP.

Chip capacity continues to increase at an exponential rate and designs increase in size and complexity (e.g. embedded processors, third-party IP, mixed-signal components), design verification and proof of concept have become significant bottlenecks. The Rapid Prototyping Platform by ARM makes use of several key systemon-chip (SOC) concepts to enable researchers to prototype their designs quickly and with higher confidence. In the past. simulation was often sufficient means to verify

the proof of concept. However, with increase in chip complexity, simulation of large designs require many millions of clock cycles. The incorporation of embedded processors on a chip amplifies the problem of simulating embedded software on mUltiple processors. To address these problems, rapid prototyping systems with high-

capacity FPGAs and embedded processors are challenging the role of simulation for system-level verification. What may take days to simulate at cycle level accuracy can be reduced to several hours through the hardware-assisted simulation of hardware-software system.

Figure 5.13:

RPP (source CMC website)

65

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I
,
I

In the research community, ASIC implementation has often been used to demonstrate the proof of concept. A design that can be implemented on an ASIC may be ported quickly to an FPGA-based rapid prototyping system, and what is lost in design performance can be regained in engineering time. Assuming first-pass success of the design, ASIC implementation of a typical industry-capacity design requires longer engineering time, while FPGA implementation requires much shorter time. Furthermore, with almost 40% likelihood of a design re-spin, implementing to FPGA again saves engineering time, as each re-spin adds approximately 20% more engineering time to the entire design cycle [9].

To accelerate the process of achieving proof of concept, rapid prototyping systems effectively utilize the concept of reuse, which is the driving force behind the SOC revolution. In SOC context, re-use takes two forms: software re-use and hardware re-use. Both of these are achievable with the rapid prototyping platform and both are presented in RPP design flow in the form of Intellectual Property (IP) libraries (see Figure 5.14). Rapid prototyping system is based on an ARM AMBA bus to support

the re-use of hardware. A user needs to customize the rapid prototyping system to meet specific design requirements, and may require custom IP to execute some of the design functionality. A library of bus-independent IP is also available through Xilinx's LogiCORE system, in addition to the blocks already present in the system. Designers

.

can also create a hardware block and later incorporate the block to an intellectual property library for re-use in other designs. The RPP design flow supports the use of

Seamless, a co-design tool from Mentor Graphics for hardware/software co-verification. Furthermore, developers targeting the RPP environment can use C/C++ language to

66

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

program embedded software. Programming at such an abstract level opens the door for software re-use, as related standards evolve in the SOC community.

5.5 RPP Design Flow

Designing system with RPP is simple with the help from many EDA design tools. . The RPP design environment is flexible as one can incorporate many different design tools to program and synthesize the ARM7 processor and its programmable logic device. The platform also supports JTAG and Multi-ICE tools for debugging. This

section will introduce the RPP system environment and its capabilities. diagram of RPP design flow is given in Figure 5.14.

A detailed

5.5.1 Design Specifications

The design flow starts with a set of design requirements and system specifications, detailing the function of the system as well as constraints such as clock rate, power and operating conditions. These design specifications are usually set out on a written document or spreadsheet. This specification is used to derive design constraints, which guide the designer (and design tools) and provide a basis for evaluating the quality of the design throughout the flow.

67

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

System/Block Specification

Algorithm Design!Analysis HWIP Library Functional Simulation

HW/SW Partitioning

Synthesis Feedback Software Design Place/Route

L__
I I I

,...

,... ... ' ' ' ,
...

I_~~
I I I

',

:

I I I I I I I ______ - - - - - ______ 1 I 1

I

,-----------1
I

Timing Simulation

HW/SW Integration

Rapid Prototyping Platform

Figure 5.14:

RPP Design Flow

5.5.2 Algorithmic Design and Analysis

In the next step of the process, the system designer translates the specifications into a high-level algorithmic description of the system. This algorithmic design and analysis step is usually implemented in C/C++ or in the case of DSP systems, tools like

68

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Cadence SPW or Matlab can be used.

The algorithmic description allows the designer

to fully understand the system function before architectural details are developed. For example, in designing an audio filtering system using a finite-impulse response (FIR) digital filter, the designer can do the following steps before committing to implementation: · ,· Optimize the number of filter coefficients. Experiment with different windowing techniques to improve the filter response. · Even test the effects of fixed-point arithmetic (e.g, overflows) versus floating-point.

A Cadence's SPW tool specifies the

syste~

as a set of connected, A block diagram (filter

parameterized blocks (e.g, a FIR filter would be one block).

block, signal sources and sinks, channel models, etc.) can be simulated many times using different parameter settings to investigate the algorithm and determine the optimum system.

5.5.3 System Architecture Design (HW/SW Partitioning)

Once the designer has thoroughly exercised and optimized the algorithm at this high level, the implementation process can begin. The first step is the system architecture design, where functional units are mapped to various architectural units. Traditionally this has been a manual process for relatively simple systems. However,

as system-on-chip (SOC) designs become more and more complex and incorporate

69

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

more and more processing elements (e.g. embedded processors, DSPs, etc.), the design process requires tools like Cadence's Virtual Component Co-design (VCC). VCC

allows system designers to specify the system function at a high level of abstraction (using C/C++ functional models).
In a parallel activity, designers can model the

system architecture (microprocessor, bus architecture, memory, ASIC components, RTOS, etc.) with appropriate estimates on timing, power and cost. The system

designer can then map functional units onto architectural units and run a performance simulation to see if the function/architecture mapping is appropriate.

The designer can make changes to the system as well as mapping and resimulate to further explore the system design space. activity would be cumbersl;>me and slow, For a large system, this kind of Once this

if not impossible.

hardware/software partitioning stage is complete, the design is handed over to the hardware and software design teams. The system designer must create a specification for the hardware and software design teams (again stating constraints such as clock speed and power to guide the design processes).

5.5.4 HDL Hardware Coding

The hardware design flow uses a hardware description language, VHDL or Verilog, to create that portion of the system design. HDL coding can be done by hand (Le. using a text editing program to write the code), or by using HDL design tools such as HDL Designer (formerly known as Renoir) from Mentor Graphics. HDL Designer allows the complete hardware sub-system to be specified as individual blocks,

.

70

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

interconnected by wireslbuses. Design blocks can be regular RTL code, state diagrams, flow charts, truth tables or hierarchical block diagrams. HDL Designer can also create block diagrams from existing code, create testbenches and link to simulation and synthesis flow tools.

The HDL design process can be enhanced by the use of a hardware IP library. For example, Xilinx has a library of free IP cores in its LogiCORE product line. One of these cores is a parameterizable FIR filter core that designers can instantiate in their source code. The core comes with a simulation model and works in most commercial synthesis flows (e.g. Synopsys FPGA Compiler n). The LogiCORE library includes memory, DSP and mathematical functions.

5.5.5 Functional Simulation

Once the HDL is coded, it is verified through functional simulation (using a simulator such as Synopsys VSS or Cadence NC-Sim). The test bench is usually

created alongside the HDL, but can also be derived earlier in the process (for example, reusing test data from the algorithmic design phase). This simulation is technology-

independent and it does not contain timing or power data. The HDL code is modified and re-simulated until the function is verified. Some extra steps in this process (not shown in Figure 5.14) could include HDL linting (checking the code for compliance with coding standards), and test coverage. Test coverage involves evaluating how

much of the actual code is tested by the test bench and thus the completeness of the verification strategy.

r
I

71

"

/ '..\

,

l'o,

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

5.5.6 Synthesis

After functional simulation, synthesis process maps the RTL code to logic gates. Tools like FPGA Compiler II from Synopsys perform this task by using the constraints on timing to optimize the design. simulation by using gate-level delays. Designers can perform back-annotated timing Re-using the functional testbench step confirms This simulation also contains

that synthesis has not altered the design's functionality.

accurate timing information to confirm the operation of actual design within constraints

5.5.7 Place and Route

After synthesis, the de,signer performs place and route using the Xilinx design tools (e.g. Alliance 3.li). This step maps the logic gates from synthesis to functional units on the FPGA. The output of this step is a bitstream file that is a complete map of the design, configured for a particular Xilinx part (e.g. Virtex 2000E-PQ540-6). This file can be downloaded to the corresponding Xilinx FPGA for operation.

5.5.7 Application Software

Occurring parallel to hardware design flow is the software development desi¥" flow that creates the code for execution on the processor in the system (in the case 'of RPP, this is an ARM7TDMI processor). Software development can involve several

tools, including a real-time operating system (RTOS), instruction-set simulator (ISS) and code development tools (C/C++ compiler, linker, and assembler). An example of

72

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

an RTOS would be VRTX from Mentor Graphics.

ARM has its own suite of code As in the hardware domain,

development tools called ARM Developer Suite (ADS).

pre-designed routines from a software IP library can speed up the design process.

5.5.8 HWISW Integration

During the design of hardware and software, it is important to make sure that the hardware and software portions of the design will work together. They may be

thoroughly tested separately by hardware and software simulation, but if the interfaces between software and hardware are not well-designed, the system may not function properly. Testing the interfaces can be left to the final stage that is the actual HW/SW

integration on the rapid-prototyping platform. However,. this can also be done earlier using a HW/SW co-verification tool like Seamless. This tool links a hardware simulation (e.g. NC-Sim) with simulation of the software on an ISS, this can verify the system earlier. Errors due to interactions between the HW and SW components can

be caught early in the design cycle and save time and effort for both the hardware and software designers. Mter integration, the design is confirmed to be working.

Experiments on the design that can execute in real-time with real-time data (e.g. audio data coming from a PC sound card) can fine-tune the design. software can be made, implemented and tested very quickly. Changes to hardware or At this stage, the design

can be introduced into an ASIC design flow if desired, or simply stand as a proof-ofconcept design where fabrication is not needed or perhaps not affordable.

fI
73

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

5.6 Block Matching Implementation

5.6.1 Introduction to Block Matching

.

The block matching is an important computational part of MPEG video coding. MPEG has been by far the most popularly utilized motion estimation technique in video coding. It is interesting to note that even nowadays; with the tremendous

advancements in multimedia object and/or content-based manipulation of audio-visual information is very demanding particularly for multimedia data storage, retrieval, and distribution. The application of arbitrarily
sh~ped

objects has attracted significant

research attention, and has been included in the MPEG activities.

Difficulties encountered in motion estimation and compensation with arbitrarily shaped blocks are enormous and to avoid these difficulties, the block matching technique was proposed by Jain and Jain [32]. An image is partitioned into a set of

non-overlapped, equally spaced, fixed size, small rectangular blocks assuming a uniform translation motion within each block. This simple model considers

translation motion while other types of motions such as rotation and zooming of large objects, may be closely approximated by piecewise translation of these small blocks provided that these blocks are small. As a compromise, a size of 16 X 16 is considered

.

to be a good choice, (as specified in international video coding standards H.261, H.263, MPEG-l and MPEG-2) while for finer estimation sometimes a block size of 8 x 8 is

74

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

also used.

Displacement vectors for these blocks are estimated by finding their best
In this manner, motion estimation is

matched counterparts in the previous frame.

significantly easier than that for arbitrarily shaped blocks. Furthermore, the rectangular shape information is known to both the encoder and the decoder, and hence does not need to be encoded, which saves both computation load and side information.

We use Figure 5.15 to illustrate the block matching technique.

An image

frame at moment tn is segmented into non~overlapped p x q (block where) p = q = 16 are often used (Figure 5. 15(a». Consider one of the blocks centered at (x,y), it is assumed Consequently, only one displacement vector

that the block is translated as a whole. needs to be estimated for this block. tn-I.

Figure 5. 15(b) shows the previous frame at time

In order to estimate the displacement vector, a rectangular search window is

formed in frame

tn-I arId centered at the pixel (x,y).

Consider a pixel in the search

window, a rectangular correlation window of the same size p x q is opened with the pixel located in its center and a similarity measure (correlation) is calculated. Mter

the matching process completes for all candidate pixels in the search window, the correlation window corresponding to the largest similarity measure becomes the best match of the block under consideration in frame tn. The relative position between

these two blocks (the block and its best match) gives the displacement vector as shown in Figure 5. 15(b).

I f
75
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

H

(~,yo)

·
(x,y)

.J'~o)

·

r ..

(x,y)

,
I I I I

.~

· /)
6cv,)

._._._.-

I( .~ I

~.-.-.-.-.-.-.-.-.-.-.-.-.-.-

(a) tn frame An original block

(b) tn-l frame

Figure 5.15: Block matching

The size of the search window is determined by the size of correlation window and the maximum possible displacement along four directions: up, down, right, and left.
In Figure 5.16 these four quaritities are assumed to be the same and are denoted by d,

which is estimated from a priori knowledge about the translation motion.

Translation

motion includes the largest possible motion speed and the temporal interval between two consecutive frames (tn_tn-I).

76

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

q+2d
II>

d q

P+2d

p.

....
d
~

...

... .... d
d
,Ir

...

Figure 5.16: Search window and correlation windows

Block matching 'belongs to image matching and can be viewed from a wider perspective.
In many image processing tasks, we need to examine two images or two
Thes~

portions of images on pixel-by-pixel basis.

two image regions can be selected

either from a spatial image sequence (from two frames taken at the same time with two different sensors aiming at the same object), or from a temporal image sequences (from two frames taken at two different moments by the same sensor). The purpose is to Therefore,

determine the similarity between the two images or two portions of images. the similarity measure is a key element in the matching process.

However, instead of

finding the maximum similarity, an equivalent but yet more computationally efficient way of block matching is to find the minimum dissimilarity or matching error. The

dissimilarity D(s,t) (sometimes referred to as the error, distortion or distance) between two images tn and tn-I is defined as:
1
p q ·

D(s,t)= -LLM(fn(j,k)./n-1(j +s,k +t» 1m j=1 «=1

(5.1)

where M(u,v) is a metric that measures the dissimilarity between u and v.

r

77

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

The D(s,t) is also referred as the matching criterion or the D values.

Mean square

error (MSE) is most commonly used matching criterion where dissimilarity metric M(u, v) is defined as M(u,v) = (U_v)2 (5.2)

The searching strategy is another important issue to deal with in block matching. Figure 5.16 shows a search window, a correlation window and their sizes.
In

searching for the best match, the correlation window is moved to each candidate position within the search window. positions that need to be examined.
In this way, there are a total of (2d+l) x (2d+l)

The minimum dissimilarity gives the best match. While the full search

Apparently, this full search procedure is brute force in nature.

delivers good accuracy in searching for the best match, a large amount of computation is involved. We choose a full search method for implementation to increase the In the next section,

complexity of the system to make the problem more challenging.

we are familiarizing the readers to the Rapid Prototyping Pla(fonn (RPP) we employed for implementing the partitioned block matching system.

5.6.2 Specification
The most computationally intensive part of block matching is to calculate the matching criterion function as presented in Equation 5.1. After calculating the The

matching criterion of an image, a match is found and motion vector is calculated. image size and the search space of our system is 256 x 256.

Instead of reducing the

search space to near by micro block of previous image as it is usually done to reduce the

78

--- ---------

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

computation, we have implemented a full search method for the whole 256 x 256 image. Micro block size is selected at 8 x 8 to increase the computation complexity. To find a

matching 8 x 8 micro block, there are (256 - 8) rows and (256 - 8) columns in the image that requires 961 comparison operations. Furthermore, each comparison operation

calculates the matching criterion function that requires 64 additions, subtractions, multiplications and one division operation. However, to take the advantage of burst

transfer mode, each operation (addition, subtraction etc.) is performed for the whole image instead of per comparison. The bus speed is 20 MHz and the maximum bus transfer rate for an AMBA (AHB) system is 128 bits in burst mode. This means that instead of sending only 2048 bits (8 x 8 x 32 bits) per block matching with 961 separate bus transactions. There will be 961 block matching comparison operation for 256 x

256 image, we can send 1968128 (2048 x 961) bits in one bus transaction as a burst mode. This method has significantly reduced the. communication overhead between

different functional blocks.

Each image pixel represents a gray scale value from 0 to 255.

The granularity

level of block matching is chosen as operation level of subtraction, square, summation and division to calculate the matching criterion function. Each block has been created

in both software and hardware to create library information for the partitioning algorithm (Figure 5.17). The execution time of each block is also measured using the This tool allows execution time

hardware/software timer module developed in house.

measurements of hardware and software components for the RPP system components. The hardware/software timer is an essenti.al part of the partitioning process for an accurate simulation.

I r
79

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

SW Sub Square Sum Div 4.133s 6.1s 4.133s 2.34

HW

Area (gates) 100 500 100 700

0.5s Lis 0.5s 0.9s

Figu~e

5.17: Initial Block matching solution with library info

5.6.3 Software Simulation
The simulation results of block matching algorithm with various constraints are recorded and drawn in Figure 5.18. Each node in the graph represents an

improvement to system execution time with the addition, of one more hardware, components. This simulated result shows that with the current granularity level and

by employing hardware-software library of Figure 5.17, the system performance is within 18.23s
-+

5.284s as shown in Figure 5.18.

However, if the system

specification requires better performance (faster than 5.284s), a different granularity level must be selected with its corresponding hardware-software library. The change
·

in hardware/software library will allow partitioning algorithm to explore different lev,el of solution space.
If the system specification is bounded in the region of 18.23s
-+

5.284, the hardware-software partitioned results generated by DADGP partitioning algorithm will give the estimated performance when implemented.

80

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

To verify the results of simulated solution of partitioning, we have implemented the hardware software partitioned system using RPP and measured the actual execution time of the system and compared it to the simulated results. The measurements of the

two domains are similar that proves the accuracy of simulated results and verifies the partitioned hardware-software system as a valid solution. of the experiments is presented in a later section. A more detailed comparison

20 18 16 14
"0 t:

'" 12
0

u

10 8 6 4 2 0 0 500 600 700 1400

en

~

HWarea

Figure 5.18:

Simulated Performance Improvement Curve Block Matching

5.6.4 Overall Architecture
The overall system architecture of a partitioning solution is presented here for simplicity because the system architecture of other solutions are similar. The system

81

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

is implemented using RPP as incorporation of extra hardware modules is equivalent to loading the hardware component to the FPGA AHB bus system as shown in Figure 5.19. System uses the AHB (AMBA) bus system to connect ARM7 processor to FPGA. Therefore, all the sub components or the hardware blocks implemented in FPGA requires AHB bridge connection to communicate with other devices.
-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.-.~

APB = Advanced peripheral Bus AHB =Advanced High performance Bus SSRAM Controller. Address Decoder

I

ARM7

AHB AHB

II

II

AHB APB

1
I

Reg.

Xilinx FPGA

Ji
I I

,
i
I

r'---'-'-'-"--;

I

Multiplier

Block matching core

YI i

t_._._._._._._._._._._._._._._.~._._._._._._._._._._

ICrr:::rO
i.-._._._______.._._..

"-'--'--'----, I I I
I

Interrupt Controller

I I

Figure 5.19:

Overall system implementation

The simulated partitioning suggests that the very first solution to Block Matching DADGP shown in Figure 5.17 is to map the square operation to dedicated hardware. This partitioning result gives the most performance gain of 2.9 as compared to previous solution. The multiplier implemented for this operation is shown in Figure 5.20 that.is The parallel 32-bit multiplier is an unsigned multiplier

a parallel 32 bit multiplier.

using a carry save adder structure. A partial schematic of the multiplier is also shown in

82

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Figure 5.21.

This multiplier takes two 32 bit numbers and multiply them in parallel to

generate a 64-bits result.

a

X "00000000"
32 32

b(O)

b(l)

b(2)

b(31

prod(31) prod(63 downto 32)

prod(O)

Figure 5.20:

32 bit parallel multiplier

a

X "00000000"

b
Sum_io(31 downto 0) cio(31 downto 0)

sum_out(31 dowoto 0) cout(31 downto 0)

Figure 5.21: 32 bit carry save adder

I
f
83
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

l

5.6.5 Simulation vs. Actual Implementation
The implementation of mapping square function to the hardware unit has shown similar results to software simulation. The implemented system takes 13.7133

seconds to. complete, where as the software simulation estimated 13.49 seconds for completion. The results indicate a margin of error of 1.66 %. The rest of the The

implementation vs. the software simulation comparison is shown in Table 5.2. results show that the margin of error of all the partitioned solutions is within 2%.

The difference between the simulated hardware area and the actual hardware area indicated a very small margin of error as shown in Table 5.3. The main sources

of errors are due to ignoring the routing and interconnections area between the components. error increases. Furthermore, as more hardware is added to the system, the margin of These results show that a different scheme of estimating the hardware

area is required to accurately model the addition of mUltiple hardware units.

Table 5.2:

Execution time comparison result

Iteration
1st run 2 run 3rd run 4th run 5 run
th

Software simulation
18.23s 13.49s 9.85s 6.74s 5.384s

RPP Actual measurements
18.94s 13.7133s lO.55s 7.21s 5.88s

nd

.
t

84

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Table 5.3: Iteration 1 run 2 run 3 run 4th run 5 run
th
rd nd

Hardware area comparison result RPP Actual area measurements
N/A

Software simulation area 0 500 600 700 1400

st

512 634 755 1490

5.7 SOBEL Edge Detection Implementation

5.7.1 Introduction to SOBEL edge detection
The Sobel operator perfonns a 2-D spatial gradient measurement on an image. Typically this is used to find the approximate absolute gradient magnitude at each point in an input grayscale image. The Sobel edge detector uses a pair of 3x3 convolution

masks, one estimating the gradient in the x-direction and the othe"r estimating the gradient in the y-direction. actual image. A convolution mask is usually much smaller than the

As a result, the mask is convolved and sled over the image, The actual Sobel masks are shown in Figure

manipulating a square of pixels at a time. 5.22.

"

I f
85
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

-1 -2

0 0

+1 +2

+1

+2

+1

0

0

0

.
-1
0

+1

-1

-2

-1

Gx Figure 5.22: SOBEL masks

Gy

The magnitude of the gradient is then calculated using the formula:

(5.3)

An approximate magnitude can be calculated using:

I G I = I Gx I + I Gy I

(5.4)

The mask is convolved over an area of the input image and then shifts one pixel to the right and continues to the right until it reaches the end of a row. the beginning of the next row. It then starts at

The example in Figure 5.23 shows the mask being

convolved over the top left portion of the input image represented by the thick black

,

box.

The formula shows how a particular pixel in the output image would be

calculated. The center image.

of the mask is placed over the pixel you are manipulating in the

It is important to notice that pixels in the first and last rows, as well as the first

and last columns cannot be manipulated by a 3x3 mask. This is because when placing

86

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

the center of the mask over a pixel in the first row (for example), the mask will be outside the image boundaries.

Input Image
all a 2l a '2 a 22 au a 2l mll m2l mll

Mask
m'2 m22 mu m2l
b ll

Output Image
b 12 bu

b 2l b ll

b 22 b '2

b 2l b 33

all

a '2

a"

m'2

mll

Figure 5.23:

SOBEL

example

The Gx mask highlights the edges in the horizontal direction while the Gy mask highlights the edges in the vertical direction. After taking the magnitude of both, the A SOBEL edge detection algorithm

resulting output detects edges in both directions. is given below.

87

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Sobel Edge Detection Algorithm

#define ROWS 512 #define COLS 512 #define Threshold 100 main ()

{
unsigned char·image in [ROWS] [COLS]; unsIgned char image-out [ROWS] [COLS]; int r, c; /* row and column array counters */ int pixel; /* temporary value of pixel */ for (r=O; r<ROWS; r++) /*initialize output image array*/ . for (c=O; c<COLS; c++) image out [r] [c] = 0; /*filter the image and-store result in output array */ for (r=l; r<ROWS-1; r++) for (c=l; c<COLS-1; c++) { /* Apply Sobel operator. */ pixel = image in [r-1] [c+1] -image in [r-1] [c-1] + 2*image in[r] [c+1] - 2*image in[r] [c-1] + image in [r+1] [c+1] - image in [r+1] [c-1] ; /* Normalize and take absolute value */ pixel = abs(pixel/4); /* Check magnitude */ if (pixel > Threshold) pixel= 255;'/*EDGE VALUE;*/ /* Store in output array */ image out[r] [c] = (unsigned char) pixel;

}

-

}

5.7.2 Specification
The input to SOBEL edge detector system is 256 x 256 gray scale images. The most computationally intensive part of SOBEL edge detection is to calculate the gradients in x and y direction by using 3x3 convolution masks. The system's granularity level is chosen as operation level of square (SqX, SqY) and summation (add) . However, for the calculation of gradient in x and y directions, two smaller operations have been encapsulated (multiplication and addition, Gx, Gy). Dividing the system in

.

this fashion has allowed identical amount of data transfer for all blocks (256 x 256 x 32 bits). Therefore, the communication time between any blocks remains constant.

88

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Each block has been created in both software and hardware to create the library information for our partitioning algorithm as shown in (Figure 5.24). The interesting

part of this system compare to block matching system is that, its initial DADGP graph contains precedence dependence edges. This means that with the environment, the

partitioning algorithm will be able to explore parallelism that will result in modification of the DADGP representation as shown in the next section.

SW GxJGy
0.1

HW

Area (gates) 1200 500 100

9.4s

l.4s 0.9s 0.3s

SqX/SqY 5.2s Add
0.1

3.88s

0.1

Figure 5.24: Initial SOBEL solution with library info

5.7.3 Software simulation
The simulation results of SOBEL edge detection is drawn in Figure 5.25. Each node in the graph represents an impr?vement in overall execution time by the addition of one more hardware component. The simulated result shows that with the

current granularity level and hardware/software library, the system performance is
89

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

within range 33.8s -l- 2.8s. a faster system.

However, a different granularity level must be selected for

One possible solution of improving the system is to combine two or

more functional units into one hardware unit to improve the execution time and to reduce inter PE communication. The change in granularity level and hardware/software library will allow DADGP-based partitioning to explore different local minimum solution.

40 35 30 25
"0
0
rJl

u

0

c::

20 15 10 5 0 0 1200 2400 2900 3400 3500

en

HWarea Figure 5.25: Simulated Performance Improvement Curve (SOBEL)

Figure 5.26 shows how the initial DADGP structure changes by the proposed DADGP based partitioning. The dotted circle node represents a hardware mapped This

modules, while dotted line enclosing several nodes represent an LD Path.

simulation is executed by allowing the partitioning algorithm to explore the solution
90

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

space based on a large hardware constraint.

In this way, the partitioning algorithm

will make the best move according to the execution time.

It is observed that the

Longest Delay path changes as DADGP changes and the improvement ratio of the solution decreases. This shows that the DADGP partitioning algorithm always make However, if the hardware area constraint

the best performance improvement moves.

is considered such that the best performance improvement can not be chosen due to hardware area violation, then the next best performance improving solution is chosen without violating the hardware area constraint. For example, in Figure 5.26 (a), the

best performance improvement move is to choose Gx node as hardware, however if the hardware constraints is less than 1200 gates, the partitioning algorithm chooses the next best move by mapping SqX node to hardware. Therefore, depending on the hardware

area constraint, the partitioning algorithm suggests various .sub optimal solutions.

Similar to block matching, to verify the result of the simulation result as shown in Figure 5.25, we have implemented the partitioned system using RPP and measured the execution time of the system and compared it to the software simulated results. The measurements of the two domains are very close to each other which prove the accuracy and validity of simulated results. experiment is presented in the next section. A more detailed comparison of this

91

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

,, ,--....,
....

\

0.1

, .... _-,"

Gx

, ,

I

0.1

0.1

0.1

(b)

(c)

,,.--,
,
I

,

,

. . _-,'" \. . .-I" _
Gx , \, Gy
\.~'
I

\

U

I

I""~,-",,,,,
"

_._\
\

~

.....

0.1 ' ......

'\.

\',,'
....--...\
..... _... "....

" \
\
I

"\

1,' ,

.... ' \

i I

SqX

: = SqY

!
//
/

" it, .........' , ,'..
..

-/

/

/ 0.1./

......

....... ..,-.--.........

//
".

(d)

92

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

5.7.4 Simulation vs. Actual Implementation

All of the solution space explored by the software simulation and hardware implementation are shown in Tables 5.4 and 5.5. The measured results of

implementation as well as the software simulation comparison are presented in Table 5.4. The results of simulated vs. actual measurements show small margin of errors,

indicating that the software simulation accurately models the hardware-software interactions. The difference between the simulated hardware area and the actual As mentioned previously,

hardware area showed some margin of errors (Table 5.5).

the main source of error is due to area required for routing and interconnections between hardware components that has not been taken into account by our algorithm . Table 5.4: Execution time comparison result

.

Iteration
1 run 2nd run 3 run 4th run 5th run 6 th run Table 5.5:
rd st

Software simulation 33.08s 23.68s
15.88s 10.68s 6.385 2.85

Actual measurements 33.88s
24.05s 16.225 1O.96s 6.82s 2.92s

Hardware area comparison result

Iteration 1sl run
2 run 3 run 4th run 5th run 6 th run
rd nd

Software simulation area 0 1200 2400
2900 3400 3500

Actual area measurements
N/A

1215 2455 2997 3525 3700

93

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

Chapter 6 Conclusions and Future Work
6.1 Summary and Conclusions
We have introduced the concept of hardware-software co-design methodology. Various hardware software portioning methods are presented and compared to the DADGP-based system partitioning algorithm. The thesis presents a full design flow

from specification to implementation; using C/C++ language as system specification, DADGP based partitioning algorithm as design simulation tool, and partitioned system implementation on a rapid prototyping platform consisting of ARM? CPU and Xilinx FPGA.

Directed Acyclic data Dependence Graph with Precedence (DADGP) is an extension of DAG. DADGP-based partitioning algorithm can also work with DAG by · This characteristic has allowed us to compare the

converting DAG to DADGP.

performance of DADGP-based partitioning with other partitioning methods that use DAG as an input graph. The results demonstrate superior performance of DADGP as

compared to GDL and Simulated Annealing methods in terms of simulation time and quality of the partitioned solutions. The DADGP partitioning algorithm not only

produces an optimal partitioned solution for a given initial graph, but it also gives otlier . , partitioned solution between initial and optimal solution. This characteristic is very

important because various sub optimal solutions give more choices to the designer in terms of system cost and performance gain.

94

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

We demonstrated the verification of our DADGP partitioning technique.

Two

computationally intensive algorithms namely Block Matching and SOBEL edge detection have been designed and implemented using the DADGP design flow. The

results indicate that the performance gain for software simulated solution is very close to the actual system performance measured for both applications. However, the

hardware area estimation measurement is not accurate as our partitioning method does not consider the interconnection hardware area between multiple hardware units. Overall, the DADGP partitioning algorithm showed promising results. The

incorporation of DADGP partitioning algorithm, etC++ profiling, and rapid prototyping to the hardware-software co-design methodology has significantly reduced the design complexity of embedded systems.

6.2 Future Work
Followings are some of the directions of future research on hardware software
partitionin~

using DADGP algorithm:

·

More accurate measure of estimating hardware area and its interconnection is required.

· A more diverse and dynamic sets of hardware and software library need to
be developed. This improvement will allow DADGP partitioning

algorithm to generate profound hardware software partitioning.

· An automated approach to granularity selection is necessary to explore
broader solution space. Currently, the granularity level of system is

selected manually by the designer from experience.

95
f (

:it

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

·

An automated hardware software synthesis system is required to fully automate the design of hardware software systems. Currently, when the

partitions are decided, the system is manually integrated with the required glue logic to connect hardware and software components. systems are available from some FPGA vendors. · Finally, a uniform design environment is necessary to simplify the use of DADGP-based partitioning solution. Similar gluing

96

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

References
1) 2) Lee Garber and David Sims, "In pursuit of Hardware-Software Codesign", IEEE Computer, Vo1.31, No.6, pp. 12-14, June 1998. M. Eisenring, L. Thiele and E. Zitzler, "Conflicting Criteria in Embedded System Design", IEEE Design & Test of Computers, Vol. 17, No.2, pp. 51-59, April-June, 2000. 3) 4) Stan Y. Liao, "Towards a New Standard for System-level Design", in Proc. of the
~ighth

Int. Workshop on Hardware/Software Codesign, pp.2-6, 2000.

W. Hardt, "An automated approach to HW/SW-codesign [Hardware/software partitioning]", lEE Colloquium, on partitioning in Hru:dware Software Codesign pp. 411-4111,Feb 1995.

5)

M. D. Edwards and J. Forrest, "Hardware/software partitioning for performance enhancement", in Proc. of lEE Colloquium on Partitioning in Hardware Software Codesign, pp. 211-215, February 1995.

6)

D.R. Sadler, D.W. Lloyd and I.E. Jelly, "Object-based Hardware-Software Codesign", in Proc. of the IEEE 15 Annual Int. Compuie~s and Communications pp. 282-288, March, 1996.

7) 8) 9)

SystemC Inc. http://www.systemc.com R. B. Ramakrishna and M. S. Schlansker, "Embedded Computer Architecture and Automation", IEEE Computer, Vo1.34, No.4, pp. 75-83, April 2001.

F. Slomka, M. Dorfel, R. Munzenberger and R. Hofmann, "Hardware/Software
Codesign and Rapid Prototyping of Embedded Systems", IEEE Design & Test of Computers, Vol. 17, No.2, pp. 28-38, April-June 2000.

10) M. Jin and G.N. Khan, "Heterogeneous haradware-software system partitioning using extended directed acyclic graph", Parallel and distributed computing systems, in Proc. of the ISCA 16 Int. Conf. pp. 181-187, Reno Aug. 2003. 11) G.D. Micheli and R.K. Gupta, "Hardware/Software Co-design", in Proc. of the IEEE, Vol. 85, No.3, pp. 349-365, March 1997. 12) P. Eles, Z. Peng, K. Kuchcinski and A. Doboli. "System Level Hardware/Software Partitioning based on Simulated Annealing and Tabu Search.", Design Automation for Embedded Systems, Vo1.2, No.1, pp. 5-32, January 1997. 13) Mentor Graphics Corp. Seamless Co-verification. http://www.mentorgraphics.comlseamless 14) Synopsys Inc. Eaglei tools. http://www.synopsys.comleagle

97

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

15) R.P. Kurshan, Automata-Theoretic Verification of Coordinating Processes. Princeton, NJ, Princeton Univ. Press, 1994. 16) Rolf Ernst, "Codesign of Embedded Systems: Status and Trends", IEEE Design & Test of Computers, Vol. 15, No.2, pp. 45-53, April-June. 17) K. Pramataris, G. Lykakis and G. Stassinopoulos, "Hardware/Software cosimulation methodology based on two alternative approaches", in Proc. of the 6th IEEE Int. Conf. on, Vol.1, pp. 63-66,1999. 18) G.C. Sih and E.A. Lee, "A compile-Time Scheduling Heuristic for Interconnection-Constrained Heterogeneous Processor Architectures", IEEE Trans. Parallel and Distributed Systems, Vol. 4, No.2, pp. 175-187, February 1993. 19) F. Schirrmeister and AS. Vincentelli, "VIrtual Component Co-design - Applying function architecture co-design to automotive applications", Vehicle Electronics, in Proc. of the IEEE Int, Conf., pp. 221-226, Sept. 2001. 20) M. Potkonjak and W. Wolf, "Cost optimization in ASIC implementation of periodic hard-real time systems using behavioral synthesis techniques," Computer-Aided Design, in Proc. of the IEEE Int Conf. ICCAD, pp 446-451, Nov. 1995. 21) M.L. Lopez Vallejo, C.Caireras, J.C. Lopez, and L. Sanchez, "Coarse Grain Partitioning for Hardware-Software Co-design". In Proc. of the 22nd Euromicro Conf., pp 161-167, Sep 1996. 22) AN. Ngoc, M. Imai, A Shiomi, and N. Hikichi, "A hardware/software partitioning algorithm for designing pipelined ASIP's with least gate counts," in Proc. of the 33rd DAC, pp. 527-532, June 1996. 23) Saha, D. Mitra, and R.S. Basu, "Hardware software partitioning using genetic algorithm" in Proc of the Tenth Int. Conf. VLSI Design, pp. 155-160, 1997. 24) E.A Lee and A. Kalavade "The extended partitioning problem: hardware/software mapping and implementation-bin selection", in Proc. of the Sixth IEEE Int. Workshop on Rapid System Prototyping, pp. 12-18, 1995. 25) H. Ondghiri, B. Kaminska and J. Rajski, "A hardware/software partitioning technique with hierarchical design space exploration", in Proc. of the IEEE Conf. on Custom Integrated Circuits, pp. 95-98, 1997. 26) N. Togawa, T. Sakurai, M. Yanagisawa and T. Ohtsuki, "A hardware/software partitioning algorithm for processor cores of digital signal processing", in Proc. of the Asia and South Pacific Design Automation Conf., the ASP-DAC '99, Vol. 1, pp.335-338, 1999.

98

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

27) F. Vahid. "Modifying Min-Cut for Hardware and Software Functional Partitioning".
In Proc. of the Workshop on HW/SW Co-Design

CODES/CASHE'97, pp. 43, Mar 1997. 28) R. Ernst, J. Henkel, and T. Benner, "Hardware-Software Cosynthesis for Microcontrollers". IEEE Design & Test of Computers, pp 64-75, Dec. 1993. 29) M.L. Lopez-Vallejo, J Grajal and J.C. Lopez, "Constraint-driven system partitioning", in Proc. of the Design, Auto and Test in Europe Conf., pp. 411-416,
2000,

30) D.F. Wong, H.W. Leong and C.L. Lin, SimulatedAnnealingfor VLSI Design. Norwell: Kluwer Academic Publishers, 1988. 31) T. Cormen, C. Leirserson and R. Rivest, Introduction to Algorithms. Cambridge: MIT Press, 1990. 32) J.R. Jain and A.K.Jain, "Displacement measurement and its application in interframe image coding", IEEE Trans. Commun., Vol. 29,No.12, pp.1799-1808, Dec. 1981.

99

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

f

Appendix A: Block Matching Implementation Code
Software Components
I·
· bmTools.h · DEFINITION * Definitions common to all of the block matcher implementaitons

#define BM_PATTERN_WIDTH 8 #define BM_lMAGE_WIDTH 16

1* Map the processor and coprocessor mailboxes to left and right *1 1* respectively *1
#define PROC_MB MBL #define COPRO_MB MBR

·1
#ifndef BM_TOOLS_H #define BM_TOOLS_H #include "dpramSemaphore.h" #include "cveUtils.h" 1* Pointers to the different important areas in memory *1 #define PATTERNl «unsigned long*)Ox8000l000) 1* Pattern bank 1 *1 #define IMAGEl «unsigned long*)Ox8000ll00) I· Image bank 1 *1 #define RESULT ( (unsigned long*)Ox80003000) 1* Result area *1 #define PATTERN2 ( (unsigned long*)Ox80002000) 1* Pattern bank 2 *1 #define IMAGE2 «unsigned ' long·)Ox80002l00) 1* Image bank 2 *1 ( (unsigned #define MBR long*)OX80000004) I· Right mailbox *1 ( (unsigned #define MBL long*)OX80000000) 1* Left mailbox ·1 #define INTl (volatile unsigned long*)Ox20000000 1* Interrupt Pin 1 *1 (volatile unsigned #define INT2 long*)Ox2000000l (volatile unsigned #define INT3 long*)Ox20000002 (volatile unsigned #define INT4 long*)Ox20000003 (volatile unsigned #define INTMASKl long*)Ox20000004 1* Interupt Mask *1 (volatile unsigned #define INTMASK2 long*)Ox20000004 (volatile unsigned #define INTMASK3 long·)Ox20000004 (volatile unsigned #define INTMASK4 long*)Ox20000004 «unsigned #define SEM_BASE long*)OxEOOOOOOO) I· Semaphore area ·1 ( (unsigned #define CVE_SCREEN char·)OxCOOOOOOO) 1* Seamless "Console" *1 #define EVENTl «unsigned long*)Ox40000000) 1* Event generator *1 1* Pattern and image sizes ·1

1* Definition of the pattern structure *1 typedef struct pattern_type { unsigned long xPosition; 1* x Position of pattern in image *1 unsigned long yPosition; 1* y Position of pattern in image *1 unsigned long bitmap; /* bit map of 1 scan line of the pattern *1 } pattern; 1* Extern declarations for modules including this file *1
extern pattern banklPattern[3); extern pattern bank2Pattern[3);

1* Function prototypes *1 void init(void); void write-9attern(pattern pat, unsigned long* image, unsigned long* block); int check_result (pattern pat);
#endif

1* bmTools.C
* BM TOOLS block matcher test functions library * DEFINITION : * These functions are common to all of the block matcher implementations.*1 #include "bmTools.h" 1* Test data receptacles *1 pattern banklPattern[3]; pattern bank2Pattern[3);
/**************************************-**

write-9attern () This function is a quick and easy way to generate test data. It copies a pattern into a memory bank and the generates an image with the given pattern at the coordinates given by the pat parameter INPUT: pattern pat: A struct containing the

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

coords and the bitmap of the pattern in the image unsigned long* image : Pointer to memory for the image containing the pattern unsigned long* block : Pointer to memory that will contain the desired pattern OUTPUT: none
*****************************************/

position = 16*pat.yPosition+pat.xPosition; return (RESULT [0] =- (unsigned long)position);

/*****************************************

void write-pattern(pattern pat, unsigned long* image, unsigned long* block) int x,y;

init () Generates a set of test data. INPUT: none OUTPUT: none
*****************************************/

1* Ini~ialize the image for '(y=0;y<16;y++)
for (x=0;x<16;x++) image [16*y+x] =0;

*1

void init(void) bank1Pattern[0] .xposition · 8; bank1Pattern[O] .yPosition · 8; OxAAAAAAAA; bank1Pattern[0] .bitmap = bank1Pattern[1] .xPosition - 2; bank1Pattern[1] .yPosition - 1; OxBBBBBBBB; bank1Pattern[l] .bitmap bank1Pattern[2] .xPosition - 8; bank1Pattern[2] .yPosition - 9; OxCCCCCCCC; bank1Pattern[2] .bitmap bank2Pattern[0] .xPosition - 0; bank2Pattern[0] .yPosition - 0; OxDDDDDDDD; bank2Pattern[0] .bitmap bank2Pattern[1] .xPosition - 8; bank2Pattern[1] .yPosition - 9; OxEEEEEEEE; bank2Pattern[1] .bitmap bank2Pattern[2] .xPosition · 2; bank2Pattern[2] .yPosition - 2; bank2Pattern[2] .bitmap OxABCDABCD;

1* Copy the pattern into BLOCK and at the desired position in *1 1* the image *1
for (y=0;y<8;y++) for (x=0;x<8;x++) block[8*y+x]=pat.bitmap; image[16*(y + pat.yPosition) + x+pat.xPosition] = pat.bitmap;

/*****************************************

check_result() Verifies if the coprocaeesor found the pattern at the right place. INPUT: pattern pat: stuct containing the coordinates in the image that the pattern was written to. OUTPUT: true (nonzero) if the coprocessor returned the right coordinates. false otherwise
*****************************************/

1* bm_int.C
* -- Block Matcher with Synchronization Via Interrupts -* DEFINITION : * This program writes images in memory and notifies the * coprocessor by generating a direct into to INTREG

*1
#include <stdio.h> #include <stdlib.h>

int check_result(pattern pat) int position;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

#include "bmTools.h" #define IMAGE1_DONE Ox01 #define IMAGE2_DONE Ox02

1* Write the pattern, then send "mail" to the coprocessor *1 write-pattern(bank1pattern[image1loopl, IMAGE1, PATTERN1); ready1 ,. 0;
*EVENT1 ,. 1;

II Function prototypes extern nc"{ void ir~handlerFunc(void);
int int int int int imagebank; image1loop; image2loop; ready1; ready2;

while(ready2 == 0); 1* wait until memory bank 2 is free *1 1* Write the pattern, then send "mail" to the coprocessor *1 write-pattern(bank2Pattern[image2loop], IMAGE2, PATTERN2); ready2 ,. 0; *EVENT1 ,. 2;

/********* ··· ****************************\

void maine) Need we say more? INPUT none OUTPUT none
,************************************* ·· */

/ ··· *************************************/

int main(void)

void ir~handlerFunc() Function called by the low-level interrupt handler. INPUT none OUTPUT none
\********************** ·· **********.*****/

, 1* Indicate that we can write to both banks *1 ready1 = 1;
ready2 - 1;

void ir~handlerFunc() { unsigned long reg; if (reg= (*(INT1» int #1 { *(INT1) ,. reg; writing it back

-=
II

1)

II

look for

1* some init *1
imagebank - 1; #1 image1loop = 0; image2loop · 0; init () ;

II

we start in image bank

clear int by

switch (imagebank) case IMAGE1_DONE: if(check_result(bank1Pattern[image1loopl» out_string ("1: Image found\n"); else out_string ("1: Image not, found\n"); image1loop++; if (image1loop imagelloop ,. 0; ready1 = 1; imagebank++; image bank

1* Welcome message -- The output window sould pop to display this message *1 out_string("INTERRUPTIONS - EPM CIRCUS DEMO 2001\n\n") ; 1* setting interrupt #1 mask *INTMASK1 · 1; *1

1/ embedded softwares have no limit! that's infinite baby! fore;;)

>= J)

while(ready1 == 0); 1* wait until memory bank 1 is free *1

II

switch to next

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

break; case IMAGE2_DONE: if(check_result(bank2Pattern[image2loopl» out_string ("2: Image found\n"); else out_string ("2: Image not found\n"); image2loop++; if (image2loop >= 3) image2loop = 0; ready2 = 1; imagebank--; II switch to next image ·bank break; default: out_string ("Invalid interruptionll\n"); break;

else out_string("Invalid interruption!l\n");

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

VHDL Components
--Add32 -- add32.vhdl entity add32 and behavioral architecture library IEEE; use IEEE.std_Iogic_1164.all; entity add32 is port (a : in std_Iogic_vector(31 downto 0) ; in std_logic_vector(31 b downto 0) ; cin in std_Iogic; sum out std_logic_vector(31 downto 0) ; cout : out std_Iogic); end entity add32; library IEEE; use IEEE.std_Iogic_arith.all; -- defines "+" on unsigned architecture behavior of add32 is signal temp std_Iogic_vector(32 downto
0) ;

library IEEE; use IEEE.std_Iogic_1164.all; use IEEE.std_Iogic_textio.all; use IEEE.std_Iogic_arith.all; use STD.textio.all; architecture schematic of div_ser is subtype word is std_Iogic_vector(31 downto 0), 85 / 7 = 12 with remainder 1 (FFFFFFFA + 00000007 = 00000001) signal md : word := x"00000007", - multiplier or divisor signal hi word := X"OOOOOOOO"; - top of dividend (final remainder) signal 10 word := x"OOOOOOss"; - bottom of dividend signal cout - adder carry out signal divs word := x"OOOOOOOO"; - adder sum signal diva : word :- x"OOOOOOOO"; - shifted dividend signal divb : word :- x"OOOOOOOO"; - multiplexor output signal quo std_Iogic := '0', - quotient bit signal sub_add: std_Iogic := '1', - subtract first (also cin) signal clk system clock signal divenb - divide enable signal divclk - run division signal cntr : std_Iogic_vector(s downto 0) :- "000000"; counter begin .-- schematic clk <= not clk after 5 ns; -- 10 ns period cntr <= unsigned(cntr)+unsigned' ("000001") when clk'event and clk.'l'; -- cntr statement is equivalent to six bit adder and clocked register divenb <= '0' when cntr="10000l"; stop divide divclk <= clk and divenb after 50 pSI -- divider structure, not a component!

signal vcin : std_Iogic_vector'32 downto :~ X"OOOOOOOO""'O'; signal va : std_Iogic_vector(32 down to 0) := X"OOOOOOOO""'O'; signal vb : std_Iogic_vector(32 downto 0) :- X"OOOOOOOO""'O', -- 33 bits (32 downto 0) needed to compute cout begin -- circuits of add32 vcin(O) <= cin; va(31 downto 0) <= a; vb(31 downto 0) <= b; temp <= unsigned(va) + unsigned(vb) + unsigned (vcin) ; cout <= temp(32) after 10 PSI sum <= temp(31 downto 0) after 10 PSI end architecture behavior; -- of add32 --Divider -- div_ser.vhdl division implemented as serial adds (one 32 bit adder) needs component add32 non restoring division (remainder may need correction - in this case add divisor, because remainder not same sign as dividend.) 0) entity div_ser is divide serial -- test bench for

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

i·

diva <= hi(30 downto 0) & 10(31) after 50 PSi -- shift divb <= not md when sub_add='l' else md after SO pSi -- subtract or add adder:entity WORK.add32 port map (diva. divb, sub_add. divs, cout); quo <- not divs(31) after SO PSi -quotient bit
<= divs when divclk'event and hi divclk='l'; 10 <= 10(30 downto 0) & quo when divclk'event and divclk='l'; when sub_ad~ <- quo divclk'event and divclk='l';

entity add32csa is -- one stage of carry save adder for multiplier port ( in std_logic; b -- a multiplier bit
a

downto 0); -- multiplicand sum_in : in std_logic_vector(31 downto 0); -- sums from previous stage cin : in std_logic_vector(31 downto 0); -- carrys from previous stage sum_out : out std_logic_vector(31 downto 0); -- sums to next stage : out std_logic_vector(31 cout carrys to next stage downto 0»; end add32csa; architecture circuits of add32csa is signal zero : std_logic_vector(31 downto 0) :z X"OOOOOOOO"; signal aa : std_logic_vector(31 downto 0) :_ X"OOOOOOOO"; duplicates entity 90mponent fadd port in std_logic; port (a in std_logic; b cin in std_logic; out std_logic; s out std_logic); cout end component fadd; begin circuits of add32csa aa <- a when b-'l' else zero after 1 ns; stage: for I in 0 to 31 generate sta: fadd port map(aa(I), sum_in (I) , cin(I) · sum_out(I), cout(I»; end generate stage; end architecture circuits; -- of add32csa

printout: postponed process(clk) just to see values variable my_line LINE; -- not part of working circuit begin if clkz'O' then -- quiet time. falling clock if cntr."OOOOOO" then write (my_line, string' ("divisor-"»; write (my_line. md); writeline(output, my_line); end if; write (my_line. string' ("at count D»~; write (my_line. cntr); write (my_line. string' (" diva~"»; hwrite(my_line. diva); write (my_line. string' (" divb="»; hwrite(my_line. divb); write (my_line. string' (" hi="»; hwrite(my_line, hi); write (my_line. string' (" 10="»; hwrite(my_line. 10); write (my_line. string' (" quo="»; write (my_line, quo); writeline(output, my_line); end if; end process printout; end schematic; --Square function mu132c.vhdl parallel multiply 32 bit x 32 bit to get 64 bit unsigned product uses add32 component and fadd component, library IEEE; use IEEE.std_logic_1164.all;

--

.

library IEEE; use IEEE.std_logic_1164.all; entity mu132c is -- 32 x 32 = 64 bit unsigned product multiplier port (a : in std_logic_vector(31 downto 0); -- multiplicand b : in std_logic_vector(31 downto 0); -- multiplier prod: out std_logic_vector(63 downto 0»; -- product end mu132c; architecture circuits of mu132c is signal zero: std_logic_vector(31 downto

J

1

I

I
I;

I

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

0) := X"OOOOOOOO"; signal nc1 : std_logic; type arr32 is array(O to 31) of std_logic_vector(31 downto 0); signal s arr32; partial sums partial carries signal c arr32; signal ss arr32; shifted sums
componen~

add32csa is

-- duplicate

entity port port(b:in std_logic; a:in std_logic_vector(31 downto 0); sum_in:in std_logic_vector(31 downto
0) ;

cin:in std_logic_vector(31 downto 0); sum_out:out std_logic_vector(31 downto 0); cout:out std_logic_vector(31 downto 0»; end component add32csa; component add32 -- duplicate entity port port(a:in std_logic_vector(31 downto 0); b:in std_logic_vector(31 downto
0) ;

dout_unit (31 DOWNTO 0) ; nrd_unit nreset nwe_unit a_mem (31 downto 0) din_unit (31 DOWNTO 0) ; nack_mem ncs_mem nrd_mem nwe_mem d_mem (31 DOWNTO 0)
) ;

IN IN IN IN OUT OUT OUT OUT OUT OUT INOUT

std_logic_vector std_logic std_logic std_logic std_logic_vector std_logic_vector std_logic std_logic std_logic std_logic std_logic_vector

Declarations

cin in std_logic; sum:out std_logic_vector(31 downto 0); cout : out std_logic); end component add32; begin -- circuits of mu132c stO: add32csa port map(b(O), a; zero, zero, s(O), c(O»; CSA stage ss(O) <~ 'O'&s(O) (31 downto 1) after 1 ns; prod(O) <2 s(O) (0) after 1 ns; stage: for I in 1 to 31 generate st: add32csa port map(b(I), a, ss(I1) , c(I-1), s(I), c(I»; -- CSA stage ss(I) <= 'O'&S(I) (31 downto 1) after 1
nSi

LIBRARY ieee ; USE ieee.std_logic_1164.ALL; USE ieee.numeric_std.ALL; ARCHITECTURE memory_signal_fsm OF memory_signal_fsm IS -- Architecture Declarations TYPE STATE_TYPE IS ( idle. wrJlropagate, rdJlropagate, rd_8ck, wr_hold. wr_ack
) ;

prod(I) <= sCI) (0) afte~ 1 ns; end generate stage; add: add32 port map (ss (31), c (31), '0' · prod(63 downto 32), nc1); adder end architecture circuits; -- of mu132c --Memory FSM LIBRARY ieee ; USE ieee.std_logic_1164.all; USE ieee.numeric_std.a11; ENTITY memory_signal_fsm IS PORT ( IN a_unit (31 DOWNTO 0) IN clk

-- State vector declaration ATTRIBUTE state_vector : string; ATTRIBUTE state_vector OF memory_signal_fsm : ARCHITECTURE IS "current_state" Declare current and next state signals SIGNAL current_state : STATE_TYPE SIGNAL next_state STATE_TYPE BEGIN clocked: PROCESS ( clk. nreset

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

nwe_mem <=

'1';

-- Default Assignment To Internals BEGIN IF (nreset = 'O') THEN current_state <~ idle; Reset Values ELSIF (clk' EVENT AND clk = 'l') THEN current_state <= next_state; -- Default Assignment To Internals END IF; END PROCESS clocked; nextstate: PROCESS ( current_state. nrd_unit.nwe_unit) BEGIN CASE current_state IS WHEN idle => IF (nwe_unit = 'O') THEN next_state <= wr-propagate; ELSIF (nrd_unit - 'O') THEN next_state <= rd-propagate; ELSE next_state <- idle; END IF; WHEN wr-propagate => next state <- wr_hold; WHEN rd-propagate -> next - state <- rd_ack; WHEN rd_ack => next state <= idle; WHEN wr_hold -> next state <- wr_ack; WHEN wr_ack => next state <- idle; WHEN OTHERS => next_state ~- idle; END CASE; -- State Actions CASE current_state IS WHEN idle => d_mem <- (others => 'Z'); din_unit <- (others => 'Z'}; nwe_mem <- 'l.' ; nrd_mem <- '1' ; ncs_mem <- '11 ; a_mem <- (others => 'Z'); nack_mem <- '1'; WHEN wr-propagate -> if (current_state'event) then d_mem <- dout_unit; end if; din_unit <- (others -> 'Z'); nwe_mem <- '0';
nrd_mem
<-

'1';

ncs_mem <- · 0' ;

a_mem

<-

a_unit;

nack_mem <_ 11';

-

-

WHEN rd-propagate => d_mem <- (others => 'Z'); din_unit <- (others -> 'Z'); nwe_mem <- '1' ; nrd_mem <- '0' ; ncs_mem <- 10 1 ; a_mem <- a_unit; nack_mem <- 10' ; WHEN rd_ack -> if (current_state 'event} then din_unit <_ d_mem; end if; d_mem <- (others -> 'Z') ; nwe_mem <- '11 ; nrd_mem <- '1' ; ncs _mem <- '1' ; a_mem <- (others oo> 'Z') ; nack_mem <- '1' ; WHEN wr_hold -> if (current_state 'event} then d_mem <- dout_unit; end if; din_unit <- (others nwe_mem <- I l l ; nrd_mem <- '1' ; ncs_mem <- '0' ; a_mem <- a_unit; nack_mem <oo '0,' ;
-> 'Z');

END

PROCESS nextstate;

output : PROCESS a_unit. current_state. d_mem. dout_unit

BEGIN Default Assignment a_mem <= (others => 'Z'); nack_mem <= '1'; ncs_mem <= 111; nrd_mem <= '1';

)~
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

n

i

]'i'.' I,l.'

1
!
WHEN wr_ack d_mem
<~
~>

std_1ogic image_loaded std_1ogic data_in : IN std_logic_vector (31 downto 0); doneinit std_1ogic
) ;

(others =>. 'Z');
~>

IN

din_unit <= (others
nwe_mem nrd_mem ncs_mem
<=
<= <=

'Z');

'1';
11';

11';

: out

a_mem <= (others => 'Z'); nack_mem <= '1'; WHEN "'THERS =>

NULL;
END CASE;

Declarations END DataPath

END PROCESS output;
architecture datapath of DataPath is -- Concurrent Statements constant pattern_address ,integer : = 16#001000#; constant image_address integer --DataPath library ieee; USE ieee.numeric_std.all; use ieee.std_logic_arith.a1l; USE ieee.std_logic_1164.all;
:=

16#001100#;

constant pattern_address2 integer := 16#002000#; constant image_address2 := 16#002100#; constant result_address integer
:= 16#003000#;

integer

signal pattern: std_logic_vector(O to ENTITY DataPath IS PORT ( clk std_logic done std_logic nlocal_rst std_logic nstart std_logic IN IN IN IN BEGIN 2047); -- pattern strip signal image: std_logic_vector(O to 3839); image strip

datapath_mainJlr~cess:' process (c1k, nstart, nloca1_rst, loadpix, getpix,
pattern_loaded, image_loaded, done) variable internal_index : ieee.numeric_std.unsigned (7 downto 0); variable pattern_address_toconvert integer := pattern_address; variable image_address_toconvert integer := image_address; variable compare : boolean := true; - true tells we may proceed compare variable imageset : integer :- 1; which set is currently used to compare · image begin -- PROCESSING RESET or START if (n1ocal_rst = '0') then

address : OUT std_logic_vector (31 downto 0) index OUT ieee.numeric_std.unsigned (7 DOWNTO 0)
1-

nread std_logic nwrite std_1ogic match std_1ogic loadpix std_logic get pix std_logic data_out: OUT (31 downto 0)
;

OUT OUT OUT in in

pattern loaded

IN

match <= '0'; nread <= '1';

----------

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

nwrite

<=

'1';

(image_loaded = '1') then when image is found. terminate if (compare = true and (image(O to 255) & image(512 to 767) & image(1024 to 1279) & image(1536 to 1791) & image(2048 to 2303) & image(2560 to 2815)
&

internal_index := "00000000"; index <= internal_index; address <= (others => 'z'); data_out <= (others => 'Z'); doneinit <= '0'; compare :- true; end if; if (nstart'event and nstart
'0 ')

I

then reset common ports internal_index := "00000000"; data_out <= (others => 'Z'); index <= internal_index; match <= '0' ; nread <- 11' ; nwrite <= '1' ; compare :- true; -- set the memory image bank, we start with 1st image. then 2nd, -and 1st . if (imageset - 0) then imageset := 1; else imageset :- 0; end if; if (imageset = 0) then image_address_toconvert := image_address; pattern_address_toconvert := pattern_address; else image_address_toconvert :image_address2; pattern~address_toconvert :pattern_address2; end if; end if;

image (3072 to 3327) & image(3584 to 3839» - pattern) then match <= '1'; pattern found in image! nread < .. '1'; don't read anymore compare :- false; don't compare anymore -- write position to memory according to image set -- function will extend the sign to a negative value since -- data_out is a logic vector. We keep the 8 LSB. if (imageset .. 0) then data_out <"00000000000000000000000011111111- and conv_atd_logic_vector«image_address_tocon vert-image_address)/4-120.32); else data_out <"00000000000000000000000011111111" and conv_std_logic_vector«image_address_tocon vert-image_address2)/4-120,32); end if; no match, we load next pixel and disable compare else if (internal_index < "10000111") then compare :- false; compare on next pixel only else --if (internal_index >= 135) then compare :- true; end if; end if; end if;

I

!
I

-- PROLOGUE WHEN RESETING index TO 0 -----------------------------if «pattern_loaded'event and pattern_loaded = '1') or (image_loaded'event and image_loaded = '1'» then internal_index := "00000000"; index<=internal_index; end if; -- COMPARING IMAGE TO PATTERN WHEN IN COMPARE STATE -----------------------------if

I
I
j

!

PROCESSING MAIN LOOP WHEN LOADING PIXEL

I
j'l"-

!:1'f ,

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

J'

I Ii

it
k

if «loadpix = '1' and loadpix'event) or (getpix='l' and getpix'event) or (image_loaded = '1' and image_loaded'event» then

end if;

-- LOADING PIXEL AND SHIFT -- PRELOADING PATTERN
if~(pattern_loaded = '0') then generate next pixel and address to load next pixel if (loadpix ~ '1') then -- ask interface to read pixel address <= conv_std_logic_vector(pattern_address_toco nvert,32) ; nread <= '0'; pattern_address_toconvert := pattern_address_toconvert + 4; end if; -- get pixel on the line if (getpix = '1') then nread <= '1'; -- shift image pattern <= data_in & pattern(O to 2015);

elsif (image_loaded

=

'1') then

if (loadpix = '1') then -- load next pixel from image address <= conv_std_logic_vector(image_address_toconv ert,32); nread <= '0'; image_address_toconvert := image_address_toconvert + 4; end if; if (getpix = '1') then
nread
<= · 11 ;

image <= data_in & image(O to 3807); -- this shifts image internal_index :~ internal_index
+ 1;

+ 1;

index <= internal_index; update index compare := true; end if; end if.;

index <= internal_index; update index end if; -- PRELOADING IMAGE elsif (image_loaded = '0" and pattern loaded = '1') then if (loadpix = '1') then address <= conv_std_logic_vector(image_address_toconv ert,32); nread <= '0'; image_address_toconvert := image_address_toconvert + 4; end if; if (getpix
nread
<=

· ------------------------------

-- DONE HAS BEEN DETECTED AND WE TERMINATE elsif (done = '1' and done'event) then address <= conv_std_logic_vector(result_address,32); nwrite <= '0'; elsif (done = '0' and done'event) then nwrite <= '1'; end if; end process datapath_main-process; end datapath; --Controller LIBRARY ieee USE ieee.std_logic_1164.all; USE ieee.numeric_std.all; ENTITY controller IS PORT ( clk

=

'1') then

'1';

3807);

-- get information on the line image <= data_in & image(O to -- shift image internal_index
:=

internal_index

+ 1;

index <= internal_index

IN

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

doneinit index DOWNTO 0) ; match nack_mem nlocal - rst nstart done getpix image_loaded loadpix pattern loaded
) ;

IN IN IN IN IN IN OUT OUT OUT OUT OUT

std_logic unsigned (7 std_logic std_logic std_logic std_logic std_logic std_logic std_logic std_logic std_logic clocked: PROCESS ( clk. nlocal_rst

Decla:t:ations END controller LIBRARY ieee ; USE ieee.std_logic_1164.ALL; USE ieee.std_logic_arith.ALL; USE ieee.std_logic_1164.ALL; USE ieee.numeric_std.ALL; ARCHITECTURE fsm OF controller IS -- Architecture Declarations TYPE STATE_TYPE IS ( pp2. pi2. pil. PP1. preload_image. preload-pattern. init. idle. compare. save_result. c1. c2
) ;

BEGIN IF (nlocal_rst = '0') THEN current_state <- idle; Reset Values ELSIF (clk' EVENT AND clk ~ '1') THEN current_state <- next_state; -- Default Assignment To Internals END IF; END PROCESS clocked;

next state : PROCESS current_state. index. match, nack_mem. nstart

-- State vector declaration ATTRIBUTE state_vector : string; ATTRIBUTE state_vector OF fsm : ARCHITECTURE IS "current_state"

-- Declare current and next state signals SIGNAL SIGNAL BEGIN

BEGIN CASE current_state IS WHEN pp2 => next_state <- preload-pattern; WHEN pi2 -> next_state <- preload_image; WHEN pi1 -> IF (nack_mem - '0') THEN next_state <- pi2; ELSE next_state <- pi1; END IF; WHEN pp1 -> IF (nack_mem - '0') THEN next_state <- pp2; ELSE next_state <_ pp1; END IF; WHEN preload_image -> IF (index >- 120) THEN next_state <_ compare; ELSIF (index < 120) THEN next_state <- pili ELSE next_state <- preload_image; END IF; WHEN preload-pattern =>

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

IF (index >= 64) THEN next_state <= preload_image; ELSIF (index < 64) THEN next_state <= ppl; END IF; WHEN init -> next_state <= preload-pattern; WHEN idle => IIL (nstart =. '0') THEN next_state <= init; ELSE next_state <= idle; END IF; WHEN compare -> IF «index> 255-120) OR match '1') THEN next_state <= save_result; ELSIF (index < 256-120) THEN next_state <= cl; ELSE next_state <= compare; END IF; WHEN save_result => IF (nack_mem = '0') THEN next_state <= idle; ELSE next_state <= save_result; END IF; WHEN cl -> IF (nack_mem = '0') THEN next_state <= c2; ELSE next_state <= cl; END IF; WHEN c2 => next_state <= compare; WHEN OTHERS => next_state <= idle; END CASE; END PROCESS nextstate;

-- Default Assignment To Internals -- State Actions CASE current_state IS WHEN pp2 => getpix <= '1'; loadpix <s '0'; WHEN pi2 => getpix <= '1'; loadpix <= '0'; pattern loaded <= '1'; WHEN pil => loadpix <= '1'; pattern_loaded <= '1'; WHEN ppl => loadpix <= '1'; WHEN preload_image => image_loaded <= '0'; pattern loaded <= '1'; loadpix <= '0'; getpix <= '0'; WHEN preload-pattern => getpix <= '0'; loadpix <= '0'; pattern loaded <= '0'; image_loaded <= '0'; WHEN idle =>
done
<=

'Oli

output : PROCESS current_state

BEGIN Default Assignment done <= '0'; getpix <= '0'; image_loaded <= '0'; loadpix <= '0'; pattern_loaded <= '0';

image_loaded <= '0'; pattern loaded<= '0'; loadpix <= '0'; getpix <= '0'; WHEN compare -> image_loaded <- '1'; pattern_loaded <= '1'; loadpix <= '0'; getpix <= '0'; WHEN save_result => done <= '1'; image_loaded <= '1'; pattern_loaded <= 'l~; WHEN cl => loadpix <= '1'; image_loaded <- '1'; pattern loaded <= '1'; WHEN c2 => getpix <= '1'; loadpix <= '0'; image_loaded <= '1'; pattern_loaded <- '1'; WHEN OTHERS =>
NULL;

END CASE; END PROCESS output; -- Concurrent Statements

I

1

I

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

END fsm; --Block matching coprocessor LIBRARY ieee ; USE ieee.std_logic_1164.all; USE ieee.numeric_std.all;
) ;

nstart done getpix image_loaded loadpix pattern_loaded

IN OUT OUT OUT OUT OUT

std_logic std_logic std_logic std_logic std_logic std_logic

ENTITY co-processeur IS PORT ( clk IN IN data_in (31 DOWNTO 0) IN nack_mem nlocal_rst IN nstart IN ·address OUT (31 DOWNTO 0) data_out OUT (31 downto 0) nread OUT OUT nwrite
) ;

std_logic std_logic_vector std_logic std_logic std_logic std_logic_vector

std_logic std_logic

Declarations END co-processeur LIBRARY ieee ; USE ieee.std_logic_1l64.ALL; USE ieee.numeric_std.ALL; LIBRARY copro; ARCHITECTURE struct OF co-processeur IS -- Architecture declarations -- Internal signal declarations SIGNAL done std_logic; SIGNAL doneinit std_logic; SIGNAL getpix std_logic; SIGNAL image_loaded std_logic; unsigned (7 , SIGNAL index DOWNTO 0); SIGNAL loadpix std_logic; SIGNAL match std_logic; SIGNAL pattern loaded std_logic; -- Component Declarations COMPONENT controller PORT ( clk IN doneinit IN index IN DOWNTO 0); match IN nack_mem IN nlocal rst IN -

END COMPONENT; COMPONENT datapath PORT ( unsigned (7 index OUT DOWNTO 0); std_logic IN done std_logic OUT match std_logic IN image_loaded std_logic IN pattern_loaded IN std_logic getpix std_logic IN loadpix std_logic IN clk address OUT std_logic_vector (31 DOWNTO 0) ; st'd_logic nread : OUT data_out : OUT std_logic_vector (31 downto 0) ; std_logic nwrite : OUT : IN data in std_logic_vector (31 DOWNTO 0) ; std_logic IN nstart std_logic IN 'nlocal rst ,std_logic OUT doneinit

-

'

.

-

) ;

END COMPONENT; -- Optional embedded configurations -- pragma synthesis_off FOR ALL : controller USE ENTITY copro.controller; FOR ALL : data path USE ENTITY copro.datapath; -- pragma synthesis_on BEGIN Instance port mappings. 12 : controller PORT MAP ( clk => clk, doneinit "',. doneinit, =,. index, index match "'> match, nack_mem => nack_mem, nlocal rst => nlocal _rst, nstart => nstart, done, done getpix => getpix, image_loaded => image_ loaded,

I
1
t

I
I

I

std_logic ; std_logic ; unsigned (7 std_logic std_logic std_logic

-

~>

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

loadpix pattern_loaded
) ;

=> =>

loadpix, pattern loaded

Il :

datapath PORT MAP ( index done match illliige_loaded pattern_loaded getpix loadpix clk address nread data _out nwrite data in nstart nlocal- rst doneinit

-

index, done, => match, z> image_loaded, => pattern_loaded, => getpix, => loadpix, z> clk, -> address, -> nread, -> data _out, -> nwrite, -> data _in, -> nstart, -> nlocal rst, -> doneinit
=> =>

-- Declarations END bm_mem_interface_int LIBRARY ieee ; USE ieee.std_logic_1164.ALL; USE ieee.numeric_std.ALL; LIBRARY copro; ARCHITECTURE struct OF bm_mem_interface_int IS -- Architecture declarations -- Non hierarchical state machine declarations TYPE MACHINE3_STATE_TYPE IS ( idle, go, wait_done, send_irq
) ;

-

) ;

END struct; --Memory interface LIBRARY ieee ; USE ieee.std_logic_1164.all; USE ieee.numeric_std.all; ENTITY bm_mem_interface_int IS PORT ( a_bm IN std_logic_vector (31 DOWNTO 0) clk std_logic IN dout_bm std_logic_vector IN (31 DOWNTO 0) event_sig std_logic IN nrd_bm IN std_logic nreset IN std_logic nwe_bm IN std_logic a_dpram OUT std_logic_vector (31 downto 0) din_bm std_logic_vector OUT (31 DOWNTO 0) irq OUT std_logic nack_mem OUT std_logic ncs_dpram OUT std_logic nrd_dpram std_logic OUT nstart_bm OUT std_logic nwe_dpram OUT std_logic d_dpram INOUT std_logic_vector (31 DOWNTO 0)
) ;

-- Declare current and next state signals SIGNAL machine3_current_state MACHINE3_STATE_TYPE ; SIGNAL machine3_next_state MACHINE3_STATE_TYPE ; -- Internal signal declarations SIGNAL count integer; SIGNAL nack_mem_bm std_logic; SIGNAL nrst_cnt Component Declarations COMPONENT memory_signal_fsm PORT ( a_unit IN std_logic_vector (31 DOWNTO 0) ; elk IN std_logic ; dout_unit IN std_logic_vector (31 DOWNTO 0); nrd_unit IN std_logic nreset IN std_logic nwe_unit IN std_logic a_mem OUT std_logic_vector (31 downto 0); din_unit OUT std_logic_vecDor (31 DOWNTO 0); naek_mem OUT std_logic ncs_mem OUT std_logic nrd_mem OUT std_logic nwe_mem OUT std_logic d_mem INOUT std_logic_vector (31 DOWNTO 0)
) ;

END COMPONENT;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

-- Optional embedded configurations -- pragma synthesis_off FOR ALL : memory_signal_fsm USE ENTITY copro.memory_signal_fsm; -- pragma synthesis_on BEGIN Architecture concurrent statements HDL Embedded Block 3 comm_int Non hierarchical state machine machine3_clocked : PROCESS ( clk.
nr~set

END IF; WHEN wait_done => IF (nack_mem_bm .. '0') THEN machine3_next_state <ELSE machine3_next state <'" wait_done; END IF; WHEN send_irq => IF (count .. 4) THEN machine3_next_state <- idle; ELSE machine3_next_state <c send_irq; END IF; WHEN OTHERS => machine3_next_state <- idle; END CASE; END PROCESS machine3_nextstate;

BEGIN IF (nreset - '0') THEN machine3_current_state <= idle; - - Reset Values ELSIF (clk'EVENT AND clk c '1') THEN machine3_current_state <c machine3_next_state; Default Assignment To Internals END IF; END PROCESS machine3_clocked;

machine3_output : PROCESS machine3_current_state
--------.--~-------------------

BEGIN Default Assignment irq <- '0'; nrst_cnt <- '0'; nstart_bm <- '1'; Default Assignment To Internals
~-

,
i I ,
;
I
1

machine3_nextstate : PROCESS ( count. event_sig. machine3_current_state. nack_mem_bm. nwe_bm

BEGIN CASE machine3_current_state IS WHEN idle "'> IF (event_sig = '1') THEN machine3_next_state <= go; ELSE machine3_next_state <= idle; END IF; WHEN go => IF <nwe_bm .. '0') THEN machine3_next_state <= wait_done; ELSE machine3_next state <= go;

-- State Actions CASE machine3_current_state IS WHEN idle -> nstart_bm <- '1'; irq <- '0'; nrst_cnt <- '0'; WHEN go => nstart_bm <- '0'; irq <- '0'; nrst_cnt <- '0'; WHEN wait_done => nstart_bm <- '1'; irq <_ '0 1 ; nrst_cnt <c '0'; WHEN send_irq => nstart_bm <- '1'; irq <- '1'; nrst_cnt <= '1'; WHEN OTHERS =>
NULL;

t

t
..,
,. . ·1.: ·. (

:~

-_._-_.

~-----------------

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

)'

~,

1
END CASE; END PROCESS machine3_output; Concurrent Statements HDL Embedded Text Block 4 chgname chgname 3 nack_mem <= nack_mem_bm; HDL Embedded Text Block 5 counter counter 3 process (nrst_cnt. clk) begin if (nreset = '0') then count <= 0; elsif(nrst_cnt - '0') then count <= 0; elsif (clk'event and clk = '1') then if (count = 200) then count <= 0; else count <= count + 1; end if; end i f ; end process; -- Instance port mappings. bm_msfsm : memory_signal_fsm PORT MAP ( a_unit -> a_bm. elk _> clk. dout_unit -> dout_bm. nrd_unit -> nrd_bm. nreset -> nreset. nwe_unit => nwe_bm. a_mem -> a_dpram. din_unit => din_bm. nack_mem => nack mem_bm. ncs_mem => ncs_dpram. nrd_mem -> nrd_dpram. nwe_mem => nwe_dpram. d_mem => d_dpram
) ;

LIBRARY ieee USE ieee.std_Iogic_1164.ALL; USE ieee.numeric_std.ALL; LIBRARY basicarm; LIBRARY copro; ARCHITECTURE struct OF main_int IS Architecture declarations -- Internal signal declarations SIGNAL Intr_data_out : std_Iogic_vector(31 DOWNTO 0); SIGNAL a std_Iogic_vector(31 DOWNTO 0) ; SIGNAL a_dpram std_Iogic_vector(31 downto 0) ; SIGNAL address std_Iogic_vector(31 DOWNTO 0) ; SIGNAL be std_Iogic_vector(3 DOWNTO 0); SIGNAL busyl std_Iogic; SIGNAL busyr std_Iogic; SIGNAL clk std_Iogic; SIGNAL copro_O_add std_Iogic_vector(17 DOWNTO 0); SIGNAL copro_O_d std_Iogic_vector(31 DOWNTO 0); SIGNAL cs : std_Iogic; SIGNAL data_out std_Iogic_vector(31 DOWNTO 0); SIGNAL din std_Iogic_vector(31 DOWNTO 0); SIGNAL din_bm std_Iogic_vector(31 DOWNTO 0); SIGNAL dout std_Iogic_vector(31 downto 0);. SIGNAL dout_bm std_Iogic_vector(31 DOWNTO 0); SIGNAL dpram_O_cs SIGNAL dpram_O_d std_Iogic_vector(31 DOWNTO 0); SIGNAL eV_b std_Iogic; SIGNAL ev_c std_Iogic; SIGNAL ev_d std_Iogic; SIGNAL event_cs std_Iogic; SIGNAL event_sig std_Iogic; SIGNAL irq std_Iogic; SIGNAL mas std_Iogic_vector(l DOWNTO 0); SIGNAL nWAIT std_Iogic;

END struct; --Interrupt Main function LIBRARY ieee ; USE ieee.std_Iogic_1164.all; USE ieee.numeric_std.all; ENTITY main_int IS -- Declarations

I
i ~~
J

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

SIGNAL nack_mem_bm SIGNAL ncopro_O_be std_logic_vector(3 DOWNTO 0) ; SIGNAL ncopro_O_cs std_logic; std_logic; SIGNAL ncopro_O_oe std_logic; SIGNAL ncopro_O~we std_logic; SIGNAL nirq SIGNAL nmreq std_logic; std_logic; SIGNAL nread std_logic; SIGNAL nrst SIGNAL nrw std_logic; std_logic; SIGNAL nscreen_cs SIGNAL nsram_cs std_logic; SIGNAL nstart_bm std_logic; SIGNAL nwe_bm std_logic; SIGNAL oe std_logic; SIGNAL screen_d std_logic_vector(31 DOWNTO 0); SIGNAL seml std_logic; SIGNAL semr SIGNAL sram_d std_logic_vector(3l DOWNTO 0); SIGNAL we -- Component Declarations COMPONENT ARM_CORE PORT ( din IN std_logic_vector downto 0); mclk IN std_logic nWAIT std_logic IN IN nirq std_logic nreset IN std_logic OUT std_logic_vector a downto 0); dout std_logic_vector OUT downto 0); mas std_logic_vector OUT downto 0); nmreq std_logic OUT nrw OUT std_logic
) ;

std_logic nmreq IN std_logic IN nrw std_logic IN reset Intr_data_out OUT std_logic_vector (31 DOWNTO 0) ; : OUT be std_logic_vector (3 downto 0) ; : OUT din std_logic_vector (31 DOWNTO 0) ; std_logic nWAIT OUT std_logic ndpram_O_cs OUT std_logic nevent_cs OUT std_logic nintr_cs OUT std_logic nscreen_cs OUT std_logic nsem_cs OUT std_logic nsram_cs OUT std_logic oe OUT screen_d OUT std_logic_vector (31 DOWNTO 0) ; std_logic we : OUT dpram_O : INOUT std_logic_vector (31 DOWNTO 0) ; sram_d : INOUT std_logic_vector (31 DOWNTO 0)
);

END COMPONENT;
COMPON~DPRAM_MEM

(31

(31 (31 (1

END COMPONENT; COMPONENT CONTROLLER_MEM PORT ( Intr_data in IN std_logic_vector (31 DOWNTO 0) ; a : IN std_logic_vector (31 DOWNTO 0) ; clk : IN std~logic dout : IN std_logic_vector (31 DOWNTO 0) ; : IN mas std_logic_vector (1 downto 0) ;

PORT ( copro_add (17 DOWNTO 0); dpram_add (31 DOWNTO 0); ncopro_be (3 DOWNTO 0); ncopro_cs ncopro_oe ncopro_we ndpram_be (3 DOWNTO 0); ndpram_cs ndpram_oe ndpram_we seml semr intl intr busyl busyr copro_d (31 downto 0) ; d (31 downto 0)
) ;

IN IN IN IN IN IN IN IN IN IN IN IN OUT OUT INOUT INOUT INOUT INOUT

std_logic_vector std_logic_vector std_logic_vector std_logic std_logic std_logic std_logic_vector std_logic std_logic -std_logic std_logic std_logic std_logic std_logic std_logic std_logic std_logic_vector std_logic_vector

t
f

I I l
j
j

I

I

1

i I

I

END COMPONENT;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

\
COMPONENT EVENT_DEC PORT ( event_add IN (31 DOWNTO 0); event_cs IN event_we IN event_a OUT event_b OUT evenG._c OUT event_d OUT
) ;

std_1ogic std_logic std_logic std_logic std_logic std_logic

END COMPONENT;

COMPONENT INTERRUPT PORT ( IN a (31 DOWNTO 0) ; clk IN IN cs data in IN (31 DOWNTO 0) ; ev_a IN ev_b IN ev_c IN ev_d IN nrst IN oe IN we IN data_out OUT (31 DOWNTO 0) ; nirq : OUT

std_logic_vector std_logic std_logic std_logic_vector std_logic std_logic std_logic std_logic std_1ogic std_logic std_logic std_logic_vector

-

.

std_logic

) ;

END COMPONENT; COMPONENT SCREEN_MEM PORT ( data_screen : IN std_logic_vector (31 DOWNTO 0); nscreen_cs IN std_logic nscreen_we IN std_logic
) ;

END COMPONENT;

COMPONENT SRAM_MEM PORT ( nsram_be IN (3 DOWNTO 0); nsram_cs IN nsram_oe IN nsram_we IN sram_add (31 DOWNTO 0);
d

std_logic std_logic std_logic

PORT ( a_bm IN std_logic_vector (31 DOWNTO 0) ; clk IN std_logic ; dout_bm IN std_logic_vector (31 DOWNTO 0); event_sig IN std_1ogic nrd_bm std_logic IN nreset IN std_logic nwe_bm IN std_logic a_dpram OUT std_logic_vector (31 downto 0); din_bm OUT std_logic_vector (31 DOWNTO 0) ; irq OUT std_logic nack_mem OUT std_1ogic ncs_dpram OUT std_logic nrd_dpram OUT std_logic nstart_bm OUT std_logic nwe_dpram OUT std_logic d_dpram INOUT std_logic_vector (31 DOWNTO 0) ) : END COMPONENT; COMPONENT clock_generator PORT ( OUT clk std_logic OUT nrst std_logic ) : END COMPONENT; COMPONENT co-processeur PORT ( clk IN std_logic ; data_in IN std_logic_vector (31 DOWNTO 0); nack_mem std_logic IN nlocal - rst IN std_logic nstart IN std_logic address OUT std_logic_vector (31 DOWNTO 0); data_out OUT std_logic_vector (31 downto 0): nread OUT std_logic nwrite OUT std_logic ) : END COMPONENT; -- Optional embedded configurations -- pragma synthesis_off FOR ALL : ARM_CORE USE ENTITY basicarm.ARM_CORE; FOR ALL : CONTROLLER_MEM USE ENTITY basicarm.CONTROLLER_MEM; FOR ALL : DPRAM_MEM USE ENTITY

(31 downto 0)
) ;

END COMPONENT; COMPONENT bm mem_interface_int

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

basicarm.DPRAM_MEM; FOR ALL : EVENT_DEC USE ENTITY basicarm.EVENT_DEC; FOR ALL : INTERRUPT USE ENTITY basicarm.INTERRUPT; FOR ALL : SCREEN_MEM USE ENTITY basicarm.SCREEN_MEM; FOR ALL : SRAM_MEM USE ENTITY basicarm.SRAM_MEM; FOR ALL : bm mem_interface_int USE ENTITY copro.bm_mem_interface_int; FOR ALL : clock_generator USE ENTITY basicarm.clock-generator; FOR ALL : co-processeur USE ENTITY copro.co-processeur; -- pragma synthesis_on BEGIN Architecture concurrent statements HDL Embedded Text Block 2 addrcnvl ebl 1 copro_O_add <= a_dpram(17 downto 0); ncopro_O_be <= "0000"; HDL Embedded Text Block 4 eb3 eb2 3 semr CIK '11; seml <_ '11; Instance port mappings. 12 : ARM_CORE PORT MAP ( &> din, din mclk -> clk, nWAIT &> nWAIT, nirq => nirq, nreset => nrst, => a, a dout => dout, z> mas, mas nmreq => nmreq, nrw => nrw
) ;.

be din nWAIT ndpram_O_cs nevent_cs nintr_cs nscreen_cs nsem_cs nsram_cs oe screen_d we

=> be,

din, nWAIT, => dpram_O_cs, => event_cs,
=>
=>
~>

ca,

nscreen_cs, => OPEN, -> nsram_cs, -> oe ,
=>
->

we,

dpram_O_d, ,,> sram_d
->
) ;

DPRAM_l DPRAM_MEM PORT MAP ( copro_add -> copro_O_add, dpram_add => a, ncopro_be -> ncopro_O_be, ncopro_cs -> ncopro_O_cs, ncopro_oe => ncopro_O_oe, ncopro_we => ncopro_O_we, ndpram_be -> be, ndpram_cs -> dpram_O_cs, ndpram_oe -> oe, ndpram_we -> we, semI -> semI, semr -> semr, intI -> OPEN, intr -> OPEN, busyl -> busyl, busyr -> busyr, copro_d -> copro_O_d, d -> dpram_O_d

.

) ;

17

IS

CONTROLLER_MEM PORT MAP ( Intr_data- in a clk dout mas nmreq nrw reset Intr_data out :

: EVENT_DEC PORT MAP ( event_add event _cs event_we event_a event b event c event _d
) ;

=> -> -> z> =>
=>

->

a, event cs, we, event_sig, OPEN, OPEN, OPEN

data_out, => a, -> clk, => dout,
=>

16 : INTERRUPT

=> mas,

nmreq, nrw, => nrst, => Intr_data_out,
=> =>

PORT MAP a clk cs data in ev_a ev_b

a, clk, => cs, -> Intr_data_out, => irq, a> ev_b,
=> =>

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I
1
=:> =>

ev_c,
ev_d,

=> =>

we

=>

nrst, oe, we,

address data_out riread nwrite
) ;

=>
=>

.. >
=>

address. dout_bm. nread. nwe bm

nirq
) ;

=>

nirq

END struct;

I4 : SCaEEN_MEM PORT MAP ( data_screen nscreen_cs nscreen_we
) ;

=>
->

=>

screen_d. nscreen_cs. we

I3 : SRAM_MEM PORT MAP ( nsram_be nsram_cs nsram_oe
nsram_we
d
) ;

=>

=>
->
->

be. nsram_cs. oe.
we,

sram_add .. > a.

10 : bm_mem interface_int PORT MAP a_bm -> address. elk => clk. dout_bm ._> dout_bm. event_sig => event_sig. nrd_bm c> nread. nreset => nrst. nwe_bm _> nwe_bm. a_dpram -> a_dpram. din_bm -> din_bm. irq -> irq. nack_mem -> nack_mem_bm. ncs_dpram => ncopro_O_cs. nrd_dpram => neopro_O_oe. nstart_bm => nstart_bm. nwe_dpram => ncopro_O_we. d_dpram -> eopro_O_d
) ;

11 : clock_generator PORT MAP ( clk => elk. nrst => nrst
) ;

I9 : co_processeur PORT MAP elk => data - in -> nack_mem -> nlocal - rst => nstart =>

clk. din_bm. nack_mem_bm. nrst. nstart _bm.

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

1 ,.,
Image (Image&) ; -Image (); boo110ad(char*); boo1 save(char*); void disp1ay(char*); void annotate(char*, char*); ImageDatum getVa1ue(ImageChanne1, int, intI; void setValue(ImageChanne1, int, int, ImageDatum); boo1 isB1ack(int, intI; boo1 isWhite(int, intI; ImageDatum getGrey(int, intI; void settoB1ack(int, intI; void settoWhite(int, intI; void setGrey(int, int, ImageDatum) ; int height(); int width(); void RGBtoHSI(); void swap(Image* that);

I·'

Appendix B: SOBEL Edge Defection Implementation Code
Software Components
#ifndef INCLUDE_IMAGE_H #define INCLUDE_IMAGE_H #inc1ude <stdio.h> #define max (a, b) « (a) > (b) )? (a) : (b» #define min (a, b) « (a) < (b»? (a) : (b» const double PI = 3.1415926535; typedef int ImageDatum; #define dataToDoub1e(a) (double (a) 1255.0) #define doub1eToData(b) (ImageDatum(b*255.0» union Pixel { struct RGB_Pixe1 { ImageDatum r; ImageDatum g; ImageDatum b; } rgb; struct HSI _Pixel { ImageDatum h; ImageDatum S; ImageDatum i; } hsi;

II for internal use - not for the faint of heart void write_to_fp(FILE*); void read_from_fp(FILE*);
static boo1 showGUI; · static long memReq; protected: void init(int, intI; int h, w; ImageMode mode; Pixe1* p; Pixe1* get Pixel (int, intI; void openGUI(); void 10adRGB(char*,int,int); void saveRGB(char*); static FILE* guiRead; static FILE* guiwrite;
};

}; enum ImageMode Mode_RGB, Mode_HSI };
enum ImageChanne1 ch_Red, ch_B1ue, ch_Green, ch_Hue, ch_Saturation, ch_Intensity }; class ImageDisp1ayer; class Image { public: Image (int, int); Image(char*);

#endif
/********************************

*** image.cpp simple image manipulation *** functions: *** loading, saving, reading and chaging intensity values ***
\*******************************/

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

#include "image.h" #include #include #include # include #include # include #include # include #include #include #include <assert.h> <iostream.h> <fstream.h> <unistd.h> II fork() <math.h> II atan() sqrt() <stdio.h> II sscanf () <stdlib.h> II system() <sys/types.h> II socketpair () <sys/socket.h> II socketpair () <unistd.h> II fcntl () <fcnt1.h> II fcntl ()

public: ImageGallery(int); void addPane(QFrame*. char*); protected: int fd; QListBox* Ib; int maxHeight; int maxWidth; QWidget* panes[maxPanes]; virtual void resizeEvent(QResizeEvent*); protected slots: void dataReceived(int); void choo~elmage(int); };
//************************** ·· **/

II QT Stuff #include <qapp.h> #include <qwidget.h> #include <qpainter.h> #include <qsocketnotifier.h> #include <qmessagebox.h> #include <qlistbox.h> #include <qpixmap.h> #include <qlabel.h>
const int IbWidth=200; const int pad=S; const int maxPanes=lOO; static long Image::memReq = 0; II ImageDisplayer and ImageGallery should only be used from within the Image II class. Client coders should probably just call Image::display. class ImageDisplayer : public QFrame { Q_OBJECT; public: ImageDisplayer(QWidget* parent, Image *image) : QFrame(parent) { construct_ImageDisplayer(image) }; -ImageDisplayer(); protected: void construct_ImageDisplayer(Image *image); virtual void resizeEvent(QResizeEvent* ); QPixmap* pm; QLabel* Ibl; }; class ImageGallery Q_OBJECT; public QWidget {

Image::lmage(int h_in. int w_in) init(h_in. w_in);

Image::Image(char*fileName) II constructs an image and loads the specified file load (fileName) ;

Image::lmage(Image& i) { init(i.width(). i.height()); mode = i.mode; memcpy(p. i.p. width()*height()*sizeof(Pixel)) ; } void Image::init(int w_in. int h_in) h h in· w w_ini p = new Pixel[h*w]; mode s MOde_RGB; memReq += h*w;

-

.

bool Image::showGUI = true; Image::-Image() { if(p) delete[] p;
p = 0;

mode = Mode_RGB; memReq += h*w;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

t

Ii
} else { bool Image::load(char* fileName) int x, y; int w_in, h_in; unsigned char c; Pixel *cp; if(lstrstr(fileName, ".rgb n » II not an rgb file -convert it char *p; FILE* fp; char cmd[l2B] i get the dimensions p = tmpnam(O); sprintf(cmd, "imdim ts > ts n , fileName, pI; if(system(cmd» { II a non-zero return value from imdim II bad news. II TODO: deal with this.

I

II already rgb -- no conversion needed. char *p; p - fileName; II extract the image's dimensions from the filename while(*p && *p I- '-')
p++; p++;

loadRGB(fileName, w_in,

II

return true; bool Image::save(char *fileName) { char* Pi if(lstrstr(fileName, ".rgb"» II not an rgb file

j

II
fp · fopen(p, "r"); if (fscanf (fp, "'d 'd", &w_in, &h_in) 1= 2) { II couldn't scan two numbers from the file II this is bad news. II TODO: deal with this fclose(fp); unlink(p) ; in rgb format:

create temporary file

p - tmpnam(O); saveRGB(p); char cmd[lOO]i sprintf(cmd, "convert size tdxtd rgb:ts ts", w, h, p, fileName); if(system(cmd» { Ii TODO: Deal with error

i I

f

unlink (pI ; convert the file p - tmpnam(O); sprintf(cmd, "convert ts rgb:ts", fileName, pI; if(system(cmd» II TODO: Deal with error void Image::loadRGB(char* fileName, int w_in, int h_in) { init(w_in, h_in); ifstream in(fileName)i int x, y; Pixel *CPi unsigned char c;
~

II

} else {

I I rgb file saveRGB(fileName);
return true;

if

load the file init(w_in, h_in); loadRGB(p, w, h)i unlink(p) ;

II

I
I
'

~

;/t
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

for(y=Oiy<hiY++) { for(x=O;x<w;x++) i f (I in) return; cp ,. getPixel(x,
y) ;

case ch_Intensity return cp->hsi.i;

Ilshould never get here return 0;

in.get(c); cp->rgb.r in.get(c); cp->rgb.g in.get(c);-cp->rgb.b

min(255, C)i min(255, C)i min(255, c);

void Image::setValue(ImageChannel ch, int x, int y, ImageDatum i) ( Pixel *cp · getP1xel(x, y); switch (ch) ( case ch_Red cp->rgb.r ,. i; break; case ch_Green: cp->rgb.g i; break; case ch_Blue cp->rgb.b ,. i; break; case ch_Hue >hsLh ,. i; break; case ch_Saturation >hsi.s ,. i; break; case ch_Intensity >hsLi ,. i; break; cpcpcp-

void Image::saveRGB(char* fileName) { int x, y; Pixel *cp; of stream out(fileName); for(y=O;y<h;y++) ( for (x=O;X<WiX++) cp - getPixel(x,
y);

.

out « char) cp->rgb.r; out « char) cp->rgb.g; out « char) cp->rgb.b;

(unsigned (unsigned

.

(unsigned

Pixel* Image::getPixel(int x, int y) if«x<w)&&(y<h» IISorry J, I just couldn't let this go. -A. :) return(p + x + y*w); else return(NULL);

bool Image::isBlack(int x, int y) ( Pixel *cp ,. getPixel(x,y); return«cp->rgb.r=.O)
&&(cp->rg~.g.-O)

&&(cp->rgb.b.-O»; >hsi.lntensity==O»;

III I (cp-

lmageDatum Image::getValue(ImageChannel ch, int x, int y) Pixel *cp - getPixel(x, y); switch(ch) ( case ch_Red >rgb.r; case ch_Green: return cp>rgb.g;
case ch_Blue
return cp-

bool Image::isWhite(int x, int y) ( Pixel *cp ,. getPixel(x,y); return«cp->rgb.r ·· 255) &&(cp->rgb.g==255) &&(cp->rgb.b=-255»;

return cplmageDatum Image::getGrey(int x, int int sum,. 0; sum += getValue(ch_Red,x,y); sum += getValue(ch_Blue,x,y); sum += getValue(ch_Green,x,y); return(sum /= 3);
y~

>rgb.b; case ch_Hue return cp->hsi.h; case ch_Saturation return cp->hsi.s;

void Image::settoBlack(int x, int y) ( Pixel *cp ,. get Pixel (x,y) ;

I I

~

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

I

cp->rgb.r=O; cp->rgb.g=O; cp->rgb.b=O;

dataToDouble(cp->rgb.b); double e .. max(g. b); double f .. max(g. b); cp->hsLh doubleToData(PI/2 - atan«2*r-e-f)/rt3*(ef» I (2*PI»; cp->hsLs doubleToData(l - min(r. min(g. b»); cp->hsLi · doubleToData«r+g+b)/3.0); Ilcout « cp->hsi.h « " " « cp->hsi.s « · " « cp->hsi.i « endl;

void Image::settoWhite(int x. int y) ( Pixel *cp .. getPixel(x.y); cp->rgb.r=255; cp->rgb.g=255; cp->rgb.b=255;

void Image::setGrey(int x. int y. ImageDatum grey) { Pixel ~cp - getPixel(x.y); cp->rgb.r .. grey; cp->rgb.g · grey; cp->rgb.b - grey;

Ilcout
«

«

"(" «

w«

h «

"). «

endl;

int Image::height() return h;

int Image::width() return w;

void Image::swap(Image* that) thatassert (this->height () >height(»; assert (this->width() -- that>width(» ; Pixel *t; t · this->p; this->p .. that->p; that->p .. t;

void lmageDisplayer::construct_ImageDisplayer(I mage *i) { II start with the right size setGeometry(x(). y(). i->width(). i->height () ; II draw the image on and internal canvas pm ~ new QPixmap(i->width(). i>height(»; · QPainter* p · new QPainter; p->begin(pm); int x. y; for(y.O;y<i->height();y++) for(x-O;x<i->width();x++) p->setPen(QColor( max(O. min(255. i>getValue(ch_Red. x. y»). max(O. min(255. i>getValue(ch_Green. x. y»). max(O. min(255, i>getValue(ch_Blue. x. y»)

void Image::RGBtoHSI() ( Pixel *cp; mode - Mode_HSI; double rt3 · sqrt(3); int x. y; for(x=O;x<w;x++) for(y=O;y<h;y++) cp - getPixel(x. y); double r dataToDouble(cp->rgb.r); double 9 dataToDouble(cp->rgb.g); double b

»;

p->drawPoint(x. y); p->end() ;

II create a label to show the pixmap
Ibl - new QLabel(this ··· ); lbl->setPixmap(*pm);

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

-ic

ImageDisplayer::-ImageDisplayer() if(pm) delete[] pm;

void lmageDisplayer::resizeEvent(QResizeEvent* ) { lbl->setGeometry(O,O,width(), height () ); _ } FILE* Image::guiWrite · 0; FILE* Image::guiRead .. 0; void Image::openGUI() { II Create child process, if needed. if (lguiWrite) { int fd[2]; socketpair(AF_UNIX, SOCK_STREAM, 0, fd); i f (fork () { II in parent process II open a file stream for writing to the gui window. guiWrite - fdopen(fd[O]', ·w"); guiRead. fdopen(fd[O], Or"); } else { II in child process II create and display the lmageGallery window. int n - 0; char **c · 0; QApplication* app · new QApplication(n, c); ImageGallery *ig · new lmageGallery(fd[l]); ig->show() ;

II send the image fprintf(guiWrite, "itd td tsl", w, h, caption); write_to_fp(guiWrite); fflush(guiWrite); II wait for a confirmation char dev_null; fscanf(guiRead, "tc", &dev_null);
void Image::annotate(char* caption, char* rtf) { if(lshowGUI) return;

II make sure a window is opened openGUI(); II send t'he text fprintf(guiWrite, ·t td td\n", strlen(caption), strlen(rtf»; fwrite(caption, sizeof(char), strlen(caption) +1, guiWrite); fwrite(rtf, sizeof(char), strlen(rtf) +1, guiWrite); fflush(guiWrite); II wait for a confirmation char dev_null; fscanf(guiRead, ·tc·, &dev_null);
void Image::write_to_fp(FILE* fp) { fwrite(p, sizeof(Pixel), h*w, fp);

void Image::read_from_fp(FILE* fp) { fread(p, sizeof(Pixel), h*w, fp);

II when the window is closed, end this process app->setMainWidget(ig); exit(app->exec(»;

ImageGallery::lmageGallery(int fd_in) II remember the handle to the socket to from which to read fd .. fd_in; IIThis was in the example code. I'm not quite sure what it's for. -O'K II fcntl(fd, O_NONBLOCK);

void Image::display(char* caption) { if(lshowGUI) return; II make sure a window is opened openGUI();

II Arrange to be notified when new data arrives. QSocketNotifier *sn .. new QSocketNotifier(fd, QSocketNotifier::Read,

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

this); OObject::connect(sn, SIGNAL(activated(int», this, SLOT(dataReceived(int»); II Create a list box show the available images. Ib · new OListBox(this); lb- >show () ; connect (lb, SIGNAL(highlighted(int», this, SLOT(chooselmage(int»);

void ImageGallery::dataReceived(int socket) char caption[80l; int h, w; Image* img; OFrame* id; setCUrsor(waitCUrsor); FILE* fpRead · fdopen(socket,
"rn) ;

FILE* fpwrite - fdopen(socket,
awol ;

II Start with no images maxHeight .. 0; maxWidth · 0;

II

determine what kind of pane this is char t · fgetc(fpRead);

void ImageGallery::addPane(OFrame* w, char* caption) II add it the internal and visible lists Ib->insertltem(caption); panes[lb->count()-ll · w;

if(t ·· 'i') { get the image'S name, height and width fscanf(fpRead, ·td td t[Allsl", &w, &h, caption) ; fgetc(fpRead); 'II not sure why we need to do this - O'X

II

img · new Image(w, h);

II
widget

place and stylize the new

II read the image data directly into memory img->read_from_fp(fpRead);
I I creil,te it widget to display the image
id · new ImageDisplayer(this, img); } else if (t ·· 't') char rtf[4096l; int ~apLen, rtfLen; fscanf(fpRead, ·td td·, &capLen, &rtfLen); fgetc(fpRead); fread(caption, sizeof(char) , capLen+1, fpRead); fread(rtf, sizeof(char) , rtfLen+1, fpRead); OLabel* 1 · new OLabel(rtf, this);
1-

w->move(lbWidth+pad, pad); Ilw->setFrameStyle(OFrame::Box OFrame::Sunken);

II manage the size of our window maxHeight · max(maxHeight, w>height(»; setMinimumHeight(maxHeight+pad+pa
d);

maxWidth - max(maxWidth, w>width(»; setMinimumWidth(maxWidth+lbWidth+ pad+pad) ;

II TOOO: Look inot why this doesn't work. II special case: initial size

·

1*
if(lb->count() ·· 1) setGeometry (x(), y(), maxWidth+lbWidth+pad+pad. maxHeight+pad+pad);

>setAlignment(AlignTop);
1-

*1

>setMinimumWidth(lbWidth+200); 1->setMinimumHeight(300); id · 1; } else

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

return/

II add it to the list of images
addPane(id, caption)/ fprintf(fpWrite, "'c", t)/ fflush(fpWrite)/ setCUrsor(arrowCUrsor)/ void ImageGallery::resizeEvent(QResizeEvent*) lb->setFixedWidth(lbWidth); Ib->move(O, 0); Ib->setGeometry(O, pad, lbWidth, height()-2*pad); } void ImageGallery::chooseImage(int index) unsigned i; unsigned dex '" unsigned(index); for(i-O;i<lb->count();i++) (i==dex) ? (panes[i]->show(» : (panes[i]->hide(»;

argv[O] « endl;

cerr « " usage:"« " <threshold> <filename>" « exit(l);

thresh'" atoi(argv[l]); Image* src '" new Image(argv[2]); Image* dest '" new Image(src>width(), src->height(»; src->display("original")/ int x, y, sx, sy/ for(x-O/x<src->width()/x++) for(y=O/y<src->height();y++) src->setGrey(x, y, (src->getValue(ch_Red, x, y) + src->getValue(ch_Green, x, y) + src->getValue(ch_Blue, x,

y» 13) /
for(x-l/x<src->width()-l;x++) for (y=l;y<src->height ()-l;y++) sx'" convolve(src, x, y, Joe); sy'" convo1ve(src, x, y, ky);

#include "image.h" #include <iostream.h> const int Joe[) [3] { { -1, -2, -1}. { 0, 0, O}. { 1, 2, 1}}; const int ky[] [3] { { -1, 0, { -2, 0, { -1, 0,

-

if(sqrt(sx*sx+sy*sy»thresh) dest->settoBlack(x, y); else dest->settoWhite(x, y); dest->display("after Sobel edge detection"); dest->save("done.rgb"); #include "image.cpp.moc"

-

1}. 2} , 1}} ;

int convolve(Image *img, int x, int y, int
k [] [3] )

int xx, yy, r-O; for (xx=-l;xx<-l;xx++) for (yY=-l;yy<=l;yy++) r+= img>getGrey (x+xx, y+yy) * k[xx+1] [yy+l]; return r; int main(int argc, char** argyl { int thresh; if(argc 1= 3) cerr « "performs Sobel edge detection" « endl;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

VHDL Components
--Gx, Gy calculater (matrix multiplier)

**** ··· **********************************/
3x3matrix.v - 3X3 Matrix Multiply Implementation using basic equations Author: Matthew Aug 2, 2003 Date: Other modules instanced in this design: MULT18X18

--BRIEF DESCRIPTION --This code describes using a technique called time multiplexing to --leverage a fast hardware multiply in a relatively slow operation, --thereby increasing the efficiency of the implementation. --The operation being shown is a 3X3 matrix of constants times a 3 --component vector. The equations look like: --KA1 * A + KA2 * A + KA3 * A .. X --KB1 * A + KB2 * A + KB3 * A · X --KC1 * A + KC2 * A + KC3 * A · X --The hardware to accomplish this task consists of a multiplier fed by 3 --input registers and an accumulator to compute the three terms in each --line above. --DETAILED DESCRIPTION: --The multiplier output is fed into the adder A input. It takes 3 clk --cycles for the first valid mutiplier' output reach the adder input A. The --B input of the adder can be a zero or the adder's accumulating register. --By selecting a zero on the B input the adder just passes the input A --through to the accumulating register. By selecting the accumulating --register, the contents of the previous add can be added to the output of --the multiplier. --The repeating flow for the accumlating register will be for the 1st clk, --the mux output is '0', so we always pass the first argument through to --the accumulator register. For the 2nd

and 3rd elks, the accumulator --register is fed back and added to the output of the multiply. This is --made possible by using the cntr3 outputs as the select lines. --The following text describes the condition of the internal nodes after --consecutive clocks. The state of the nodes assumes the clock has --occured and data is stable. --clock multiplier adder adder output output --number output register register

--rst 0 --1 0 --2 0 --3 0
--4

X

X

X
X

x
X

KA1*A 1tB1*B

KA1*A KA1*A+KB1*B

KA1*A
--5 KC1*C KAl*A+KB1*B KA1*A+KB1*B+KC1*C KA2*A KA2*A --6 answer 1 KA1*A+KB1*B+KC1 KA2*A+KB2*B --7 KB2*B KA2*A --.8 KC2*C KA2*A+KB2*B KA2*A+KB2*B+KC2*C KA3*A --9 KA3*A KA2*A+KB2*B+KC2*C answer 2 KA3*A+KB3*B KB3*B --10 KA3*A KC3*C --11 KA3*A+KB3*B+KC3*C KA3*A+KB3*B --12 next KA1*A next KA1*A KA3*A+KB3*B+KC3*C answer 3

.

--*/
/***************************************** -******************************/

library IEEE; use IEEE.std_logic_1164.all; use IEEE.std_Iogic_arith.all; use IEEE.std_logic_unsigned.all; --library virtex;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

--use virtex.components.all; --library synplify; --use synplify.attributes.all; library unisims_ver; -- include this for modelsim simulation -- when using multl9xl9 entity matrix3x3 is port ( A, B, C: in std_logic_vector(ll downto 0); eLK, RST: in std_logic; CWEL: in std_logic_vector(l downto 0); KA, KB, KC: in std_logic_vector(9 downto 0); x, Y, Z: out std_logic_vector(11 downto 0»; end matrix3x3 ; architecture model of matrix3x3 is signal A_reg, B_reg, C_reg: std_logic_vector (11 downto 0); signal A_regl, B_regl, C_regl: std_logic_vector (11 downto 0); signal CWEL_reg,i_wait: std_logic_vector(l downto 0); signal cnt9_wait: std_logic_vector (2 downto 0); signal ain, bin: std_logic_vector (17 downto 0); signal KA1, KB1, KC1, KA2, KB2, KC2, KA3, KB3, KC3: std_logic_vector (9 downto 0); signal data_mux: std_logic_vector (11 downto 0); signal coeff_mux: std_logic_vector (9 downto 0); signal cntr9, cntr9_out : std_logic_vector (3 downto 0); signal P1_reg,adder_mux,sum: std_logic_vector (35 downto '0); signal Pl, P2, P3: std_logic_vector (35 downto 0) ; signal cntr3 : std_logic_vector (1 downto
0) ;

--/* ----------DATA INPUT SECTION------*/ --/* In the 3:1 data mux. To match the pipeline of the --Data inputs with the coeeficient inputs, the data values are registered first --At the input of the 3:1 mux and then again at the output of the 3:1 mux. --To make sure that the inputs don't change in the middle of a set of vector --summation, the inputs are held constant for 9 clks. This will ensure that --the input values seen by the 3x3 vector is the same for the first set of --answers. */

--/* cntr) to count 0-1-2-3-1-2-3 */ process (CLK,RST) begin if (RST:'1') then cntr3' <= ·00·; elsif (rising_edge (CLK» then if (cntr3 - W11W) 'then cntr3 <_ wOlw; else cntr3 <- cntr3 + 1; end if; end if; end process; --/* inputs registered twice to match the pipe length of the coefficients */
process (CLK,RST) begin if (RST - '1 ,) then A_reg1 <- (others=>'O'); B_regl <= (others->'O'); C_reg1 <= (others=>'O'); elsif (rising_edge (clk» then if (j - 0) then A_regl <- A; B_reg1 <= B; C_reg1
<z

C;

signal j : integer range 0 to 7; signal indexi : integer range 0 to 9; signal i : integer range 0 to 3; component MULT19X19 port ( A,B: in std_logic_vector (17 downto 0); P: out std_logic_vector (35 downto 0»; end component; begin

end if; end if; end process; process (CLK,RST) begin if (RST - '1') then A_reg <= (others->'O'); B_reg <= (others=>'O'); C_reg <- (others=>'O'); elsif (rising_edge (clk» then A_reg <= A_reg1; B_reg <= B_reg1; C_reg <= C_reg1; end if; end process;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

process (CLK,RST) begin if (RST z '1') then j <- 0 ; elsif (rising_edge (elk» then if ( j < 8) then j <_ j + 1; else j <- 0; end if; end if; end process;

end case; end if; end process;

--1* ----------COEFFIECIENT MUX SECTION-*I --I*cntr9 to count 0-1-2-3-4-5-6-7-8-9-1 *1
process (CLK,RST) begin if (RST-'l') then cntr9 <- "0000"; elsif (rising_edge (CLK» then if (cntr9 - "1001") then cntr9 <- "0001"; else cntr9 <- cntr9 + 1; end if; end if ; end process; process (clk,rst) begin if (rst - '1') then coeff_mux <- "0000000000"; data_mux <- (others -> '0'); elsif (rising_edge (elk» then case indexi is when 0 -> coeff_mux <- KA1; data_mux <- A_reg; · when 1 -> coeff_mux <- KB1; data_mux <- B_reg; when 2 -> coeff_mux <- KC1; data_mux <- C_reg; when 3 -> coeff_mux <- KA2; data_mux <_ A_reg; when 4 -> coeff_mux <- KB2; data_mux <- B_reg; when 5 -> coeff_mux <- XC2; data_mux <- C_reg; when 6 -> coeff_mux <- KA3; data_mux <- A_reg; when 7 -> coeff_mux <- KB3; data_mux <- B_reg; when 8 -> coeff_mux <- XC3; data_mux <_ C_reg; when others -> null; end case; end if; end process; process(CLK,RST) begin if (RST-'l') then i_wait <- "01"; elsif (rising_edge (CLK» then if (i_wait> ·00") then

--1* ----------MODE SELECT SECTION-----*I --1* mode select should be constant for 3
clk cycles to complete one set . --of coefficients. So modeselect is updated every 3rd clk *1 --1* cntr3 used to hold CWEL constant for 3 clocks. *1 process (CLK,RST) begin if (RST - '1') then CWEL_reg <- "00"; i <- 0; elsif (rising_edge (clk» then CWEL_reg <- CWEL; end if; if ( i < 4) then i <- i + 1; else i <- 0; end if; --end if; end process;

I ,
I

I
J

--1* coefficient register update. The register shd hold the --value for 3 elks to get the right output. *1
process (clk,rst) begin if (rst - '1') then KA1 <- "0000000000"; KB1 <"0000000000"; KC1 <- "0000000000"; KA2 <- "0000000000"; KB2 <"0000000000"; KC2 <- "0000000000"; KA3 <- "0000000000"; KB3 <"0000000000"; KC3 <- ·0000000000·; elsif (rising_edge (c1k» then case CWEL_reg is when "01" => KA1 <- KA; KB1 <= KB; KC1 <- KC; when "10" => KA2 <- KA; KB2 <KB; KC2 <- KC; when "11" => KA3 < .. KA; KB3 <KB; KC3 <- KC; when others => null;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

i_wait <= i_wait - '1'; else i_wait <- i_wait; end if; end if ; end process; process (CLK,RST) begin if (RST-'l') then inde~i <- 8; elsif (rising_edge (CLK» then if (i_wait. "oon) then if (indexi = 8) then indexi <= 0; else indexi <= indexi + 1; end if; end if; end if ; end process;

process (CLK,RST) begin if (RST = '1') then sum <- (others => '0'); elsif (rising_edge (clk» then sum <= P1_reg + adder_mux end if; end process;

--1* ----------OUTPUT SECTION------------*1 --1* At the output of the adder, the first valid X values appears at the 6th clk --after reset. After this, at every 3rd clk, a valid output values are obtained for --y ,Z, X, Y, Z and so on. This function is realised using- a enable cntr. The cntr --after reset, counts upto 3 at which point another output counter is enabled. The --output of the enable counter holds its value of 3 as long as it is not reset. *1 --1* output cntr starts after 4 clk to match the initial pipe --delays of inputs/coeeficients *1
process (CLK,RST) begin if (RST - '1') then cnt9_wait <- "ioo"; elsif (rising_edge (~lk» then if (cnt9_wait > ·000·) then cnt9_wait <- cnt9_wait - '1'; else cnt9_wait <= cnt9_wait; end if; end if; end-process; --I*cntr9_out to count 0-1-2-3-4-5-6-7-89-1-2-

--1* ----------MULTIPLIER SECTION-------*I --1* 9x pumped multiplier; P3 registered twice to match the pipelining of the first adder *1 ain <- "00000000· k coeff_mux; bin <"000000· k data_mux; MULT1: MULT18X18 port map( A =>'ain, B => bin, P -> P1);
-- registering multiplier outputs -process (CLK,RST) begin if (RST - '1') then P1_reg <= (others -> '0'); elsif (rising_edge (clk» then P1_reg <- P1; end if; end process;

--1* ----------ADDER SECTION------------*1 --1* Adder mux. Inputs a '0' every 3rd clk *1
process (cntr3(1) , cntr3(0) , sum) begin if (cntr3 - ·01") then adder_mux <= (others => '0'); else adder_mux <= sum; end if; end process; -- Final adder -

*1

I

process (CLK,RST) begin if (RST = '1') then cntr9_out <= "oooon; elsif (rising_edge (clk» then if (cnt9_wait = "DOD·) then if (cntr9_out - ·1001 n ) then cntr9_out-<= "0001"; else cntr9_out <= cntr9_out + 1; end if; end if;

I

I
Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

end if; end process;

__ /* adder output assigned to X.Y and Z */ process (clk.rst) begin if (rst - '1') then X <- "000000000000"; Y <~ "000000000000"; Z <- ·000000000000"; elsif (rising_edge (elk» then case cntr9_out is --when "0001" -> X <- X; Y <Y; Z <- Z; --when "0010" -> X <- X; Y <y; Z <- Z;

when "0011" -> X <- sum(ll downto 0); --Y <- Y; Z <- Z; --when "0100" -> X <- X; Y <Y; Z <- Z; --when "0101" -> X <- X; y <Y; Z <- Z;

I ,

when "0110" -> Y <- sum(ll downto 0); --X <- X; Z <- Z; --when "0111" -> X <- X; Y <Y; Z <- Z;

--when "1000"
Y; Z <- Z;

->

X

<-

X; Y

<-

when "1001" -> Z <- sum(ll downto 0) ; --X <- Xi y <'" Y; when others -> null; end case;
end if;

end process; end model;

Reproduced with permission of the copyright owner. Further reproduction prohibited without permission.

