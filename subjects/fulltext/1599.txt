TARGET DESIGN FOR LIDAR-BASED ICP POSE ESTIMATION FOR SPACE VISION TASKS

by

Aradhana Choudhuri B.Eng, Ryerson University, 2007

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Applied Science in the Program of Aerospace Engineering

Toronto, Ontario, Canada, 2009 ©Aradhana Choudhuri 2009

I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

ii

TARGET DESIGN FOR LIDAR-BASED ICP POSE ESTIMATION FOR SPACE VISION TASKS Author: Aradhana Choudhuri MASc, Aerospace Engineering, Ryerson University, 2009

Abstract
The goal of this thesis is to develop a methodology for designing 3D target shapes for accurate LIDAR pose estimation. Scanned from a range of views, this shape can be attached to the surface of a spacecraft and deliver accurate pose scanned. It would act as an LIDAR- based analogue to fiducial markers placed on the surface and viewed by CCD camera(s). Continuum Shape Constraint Analysis (CSCA) which assesses shapes for pose estimation and measures the performance of the Iterative Closest Point (ICP) Algorithm is used as a shape design tool. CSCA directly assesses the sensitivity of pose error to variation in viewing direction. Three of the CSCA measures, Noise Amplification Index, Minimal Eigen-value and Expectivity Index, were compared, and Expectivity Index was shown to be the best index to use as shape design tool. Using CSCA and numerical simulations, a Cuboctahedron was shown to be an optimal shape which delivers an accurate pose when viewed from all angles and the initial pose guess is close to the true poses. Separate from Constraint Analysis, the problem of shape ambiguity was addressed using numerical tools. The Cuboctahedron was modified in order to resolve shape ambiguity - the tendency of the ICP algorithm to converge with low registration error on a pose configuration geometrically identical, but actually different from a "true pose". The numerical characteristics of geometrical ambiguity were studied, and a heuristic design methodology to reduce shape ambiguity was developed and is presented in this thesis. A Reduced Ambiguity Cuboctahedron is the resultant shape that delivers an accurate pose from all views and does not suffer from shape ambiguity. The shapes were subjected to simulation and experimental validation. They were manufactured using 3D Rapid Prototyper, and a NEPTEC Design Group TriDAR Scanner was used to obtain experimental data for three shapes: the Tetrahedron, Cuboctahedron, and reduced Ambiguity Cuboctahedron. The Tetrahedron, which has poorly constrained views, was included in the testing process as a comparison shape. The simulation and experimental results were congruent, and validated the design methodology and the designed shapes.

iii

Acknowledgements
Firstly, I would like to acknowledge my supervisors, Dr. D. J. McTavish, Dr. G. Okouneva, and Dr. G. Liu, without whose support, direction, guidance, and criticism, this work could not have been carried out. This thesis is based primarily on theoretical work by Dr. D. J. McTavish and Dr. Okouneva in the area of Constraint Analysis, and I am very grateful for the opportunity to work on this project. My supervisors' dedication, clarity of thought and technical acumen are qualities that I hope to achieve in my own future career aspirations. Secondly, I would like to thank our research partners, the Neptec Research Group and the Canadian Space Agency. I would especially like to thank Gail Bouchette from Neptec for contributing her time to the project, and Chad English for making my presence at Neptec possible. Next, I would like to thank all the people in the Department of Aerospace Engineering at Ryerson University ­ professors, instructors, technical support staff, and administrators. I would especially like to thank Peter Bradley for his invaluable help in constructing the physical models used for testing. Finally, I would like to thank the precious people in my life that have selflessly provided support, encouragement, last-minute proofreading, and sanity-checks. My parents, to whom I owe the inspiration and guidance that has brought me to this point in my career path, Sujata and Sanjoy Choudhuri, for their technical and personal help. My sisters, Upasana and Sadhana, for their perseverance and unquestioning support. Adrian Marek, for sharing this journey with me, and my best friends Pierre Saint-Cyr and Rhett Lunn, for all the thousand-and-one things. I would also like to acknowledge all of my Teachers who have, over the years and despite my many failures, attempted to impart knowledge and teach me the qualities of compassion and excellence. I am humbled and privileged by your presence.

iv

Dedicated to Master Choa Kok Sui

v

Table of Contents
ABSTRACT........................................................................................................................................................III ACKNOWLEDGEMENTS................................................................................................................................IV TABLE OF CONTENTS ...................................................................................................................................VI TABLE OF FIGURES ....................................................................................................................................VIII TERMS AND ABBREVIATIONS...................................................................................................................... X 1 INTRODUCTION AND PREVIOUS WORK............................................................................................ 1 1.1 1.2 2 MOTIVATION ........................................................................................................................................ 5 THESIS ORGANIZATION ......................................................................................................................... 7

THEORETICAL FOUNDATIONS OF THE WORK................................................................................ 8 2.1 2.2 2.3 2.3.1 2.3.2 2.3.3 2.4 2.4.1 2.4.2 NOMENCLATURE .................................................................................................................................. 8 KEY DEFINITIONS ............................................................................................................................... 12 SUMMARY OF CONSTRAINT ANALYSIS ................................................................................................. 15 Discrete Point-Based Constraint Analysis ...................................................................................... 15 Continuum Shape Constraint Analysis............................................................................................ 16 CSCA Indices and Expected Value ................................................................................................. 19 A NOTE ON VIEW DIRECTIONS & FUNCTION REPRESENTATIONS IN THIS THESIS .................................... 20 View Directions ............................................................................................................................. 20 Function Representation................................................................................................................ 20

3

PRELIMINARY STUDIES FOR IDEAL SHAPE DESIGN.................................................................... 22 3.1 CONDITIONING MEASURES .................................................................................................................. 22 3.1.1 NAI ............................................................................................................................................... 22 3.1.2 EI.................................................................................................................................................. 24 3.1.3 ME ................................................................................................................................................ 25 3.2 STUDY OF SHAPE ELEMENTS ............................................................................................................... 27 3.2.1 Vertex Studies................................................................................................................................ 27 3.2.2 Face Studies .................................................................................................................................. 29 3.3 STUDY OF AMBIGUITY ........................................................................................................................ 32 3.3.1 ICP Pose Error Method................................................................................................................. 32 3.3.2 ICP Registration Error Method...................................................................................................... 34 3.3.3 Comparison of Ambiguity functions of various polyehdra ............................................................... 37

4

SHAPE DESIGN ....................................................................................................................................... 44 4.1 DESIGN OF WELL-CONSTRAINED SHAPE .............................................................................................. 46 4.1.1 Polyhedron & Candidate Shape-Family Selection .......................................................................... 46 4.1.2 Candidate Optimization................................................................................................................. 49 4.1.3 Numerical Simulations................................................................................................................... 53 4.2 DESIGN OF UNAMBIGUOUS SHAPE ........................................................................................................ 61 4.2.1 Candidate Selection & Optimization .............................................................................................. 61 4.2.2 Numerical Simulations................................................................................................................... 64

5

EXPERIMENTAL VALIDATION........................................................................................................... 70 5.1 5.2 5.3 EXPERIMENTAL DEVELOPMENT & SETUP............................................................................................. 70 EXPERIMENTAL LIMITATIONS & DATA CHARACTERISTICS ................................................................... 73 DATA & COMPARISON ........................................................................................................................ 75

6

CONCLUSIONS ....................................................................................................................................... 87

vi

6.1 6.2

SUMMARY OF SPECIFIC RESULTS ......................................................................................................... 87 FUTURE WORK ................................................................................................................................... 89

APPENDIX A: SENSITIVITY INDICES FOR DISCRETE-POINT POSE ESTIMATION........................... 91 MINIMUM EIGENVALUE INDEX.......................................................................................................................... 92 NOISE AMPLIFICATION INDEX ........................................................................................................................... 93 EXPECTIVITY INDEX ......................................................................................................................................... 94 REFERENCES................................................................................................................................................... 97

vii

Table of Figures
FIGURE 1: CONSTRAINT FOR A RECTANGULAR PRISM - POOR (LEFT), BETTER (MIDDLE), BEST (RIGHT) ...................... 5 FIGURE 2: 2D VISION MARKERS (LEFT), HYPOTHESIZED 3D LIDAR T ARGET/MARKER (RIGHT) ON ISS MODULE. [BASE IMAGE COURTESY OF NASA................................................................................................................ 6 FIGURE 3: SHAPE REGISTRATION ........................................................................................................................... 13 FIGURE 4: SELF-REGISTRATION ............................................................................................................................. 14 FIGURE 5: CONTINUUM SELF-REGISTRATION SETUP ............................................................................................... 17 FIGURE 6: DIRECTIONAL WEIGHTED SCAN ............................................................................................................. 18 FIGURE 7: SCAN ANGLES DECLINATION AND AZIMUTH ............................................................................................ 20 FIGURE 8: VIEW SPHERE (LEFT) & SIMPLE POLYHEDRON , VIEW SPHERE AND EI FUNCTION (RIGHT)....................... 21 FIGURE 9: SIMPLE SHAPE AND EI FUNCTION .......................................................................................................... 21 FIGURE 10: ICP ERROR VS. NAI ............................................................................................................................ 23 FIGURE 11: NAI FUNCTION MAP OF CUBE (TOP HEMISPHERE ONLY)...................................................................... 23 FIGURE 12: ICP ERROR VS. EI ............................................................................................................................... 24 FIGURE 13: EI FUNCTION MAP OF CUBE (TOP HEMISPHERE ONLY) ......................................................................... 25 FIGURE 14: ICP ERROR VS. ME ............................................................................................................................. 26 FIGURE 15: ME FUNCTION MAP OF CUBE (TOP HEMISPHERE ONLY)....................................................................... 26 FIGURE 16: POLYHEDRON GEOMETRY STUDY PARAMETERS ................................................................................... 27 FIGURE 17: 3-CORN WITH 45 O DIHEDRAL (LEFT) AND 6-CORN WITH 25 O DIHEDRAL (RIGHT).................................... 28 FIGURE 18: VERTEX STUDIES ................................................................................................................................ 28 FIGURE 19: 6-SIDED MESH WITH 70 O DIHEDRAL (LEFT) AND 3-SIDED MESH WITH 20O DIHEDRAL (RIGHT) ............... 29 FIGURE 20: FACE STUDY ....................................................................................................................................... 30 FIGURE 21: EI MAP OF TETRAHEDRON (TOP) AND CUBOCTAHEDRON (BOTTOM) ...................................................... 31 FIGURE 22: TWO POSE CONFIGURATIONS WITH SIMILAR LOW ICP REGISTRATION ERROR, SHOWING AMBIGUITY OF CUBE POLYHEDRON ..................................................................................................................................... 32 FIGURE 23: ICP POSE ERROR VS. INITIAL POSE ERROR FOR CUBE POLYHEDRON ..................................................... 33 FIGURE 24: POSE CLUSTERING SHOWING CUBE AMBIGUITY.................................................................................... 34 FIGURE 25: THE PRESENCE OF MULTIPLE LOCAL MINIMUMS IN THE ICP REGISTRATION ERROR FUNCTION DUE TO AMBIGUITY IN SHAPE.................................................................................................................................... 35 FIGURE 26: ICP REGISTRATION ERROR FUNCTION FOR CUBE.................................................................................. 36 FIGURE 27: POSE ERROR METHOD PLOT (TOP) AND REGISTRATION ERROR METHOD PLOT (BOTTOM) FOR TETRAHEDRON ............................................................................................................................................ 37 FIGURE 28: POSE ERROR METHOD PLOT (TOP) AND REGISTRATION ERROR METHOD PLOT (BOTTOM) FOR OCTAHEDRON .............................................................................................................................................. 38 FIGURE 29: POSE ERROR METHOD PLOT (TOP) AND REGISTRATION ERROR METHOD PLOT (BOTTOM) FOR ICOSAHEDRON ............................................................................................................................................. 39 FIGURE 30: POSE ERROR METHOD PLOT (TOP) AND REGISTRATION ERROR METHOD PLOT (BOTTOM) FOR CUBOCTAHEDRON........................................................................................................................................ 40 FIGURE 31: STANFORD BUNNY MESH .................................................................................................................... 41 FIGURE 32: STANFORD BUNNY ICP REGISTRATION ERROR FUNCTION .................................................................... 42 FIGURE 33: POSE ERROR METHOD PLOT FOR STANFORD BUNNY ............................................................................ 43 FIGURE 34: DESIGN PROCESS FOR T ARGET SHAPE CREATION ................................................................................. 45 FIGURE 35: EI MAP OF TETRAHEDRON ................................................................................................................... 46 FIGURE 36: EI MAP OF DODECAHEDRON ................................................................................................................ 47 FIGURE 37: EI MAP OF ELONGATED TRIANGULAR DIPYRAMID ............................................................................... 48 FIGURE 38: EI MAP OF CUBOCTAHEDRON .............................................................................................................. 48 FIGURE 39: SOLID ANGLE OVER A CONE OF VIEWS .................................................................................................. 49 FIGURE 40: TRANSFORMATION OPTIMIZATION FITNESS FUNCTION OF CUBOCTAHEDRON FOR 10O VIEW CONE ......... 51 FIGURE 41: FITNESS FUNCTION OF TETRAHEDRON FOR 10O VIEW CONE .................................................................. 51 FIGURE 42: TRANSFORMED CUBOCTAHEDRON FOR 10O VIEW CONE ........................................................................ 52 FIGURE 43: TRANSFORMED TETRAHEDRON FOR 10 DEGREE VIEW CONE ................................................................. 52 FIGURE 44: ICP REGISTRATION VS. EI FOR TETRAHEDRON ..................................................................................... 54

viii

FIGURE 45: ICP REGISTRATION ERROR VS. EI FOR REGULAR CUBOCTAHEDRON...................................................... 55 FIGURE 46: POSE ERROR VS. EI FOR TETRAHEDRON ............................................................................................... 56 FIGURE 47: POSE ERROR VS. EI FOR REGULAR CUBOCTAHEDRON ........................................................................... 57 FIGURE 48: REGULAR CUBOCTAHEDRON (TOP RIGHT), POSE ERROR VS. VIEW ANGLES FOR REGULAR CUBOCTAHEDRON (BOTTOM) ....................................................................................................................... 59 FIGURE 49: 10O OPTIMIZED CUBOCTAHEDRON (TOP RIGHT), POSE ERROR VS. VIEW ANGLES FOR 10O OPTIMIZED CUBOCTAHEDRON (BOTTOM) ....................................................................................................................... 60 FIGURE 50: CUBOCTAHEDRON POLYGON MAP AND NORMALS ................................................................................ 63 FIGURE 51: REDUCED AMBIGUITY CUBOCTAHEDRON POLYGON MAP AND NORMALS .............................................. 64 FIGURE 52: EI MAP OF REDUCED AMBIGUITY CUBOCTAHEDRON ............................................................................ 64 FIGURE 53: ICP REGISTRATION ERROR METHOD AMBIGUITY MEASURE FOR REDUCED AMBIGUITY CUBOCTAHEDRON ................................................................................................................................................................... 65 FIGURE 54: POSE ERROR METHOD MEASURE FOR REDUCED AMBIGUITY CUBOCTAHEDRON .................................... 66 FIGURE 55: ICP REGISTRATION ERROR VS. EI FOR REDUCED AMBIGUITY CUBOCTAHEDRON ................................... 67 FIGURE 56: POSE ERROR VS. EI FOR REDUCED AMBIGUITY CUBOCTAHEDRON ........................................................ 68 FIGURE 57: 3D PRINTER (RAPID PROTOTYPER)....................................................................................................... 70 FIGURE 58: SHAPES BEING PREPARED FOR MOUNTING ............................................................................................. 71 FIGURE 59: DIAGRAM OF E XPERIMENTAL SETUP .................................................................................................... 71 FIGURE 60: ROLL/YAW TRIPOD MOUNT PROVIDED BY NEPTEC ............................................................................... 72 FIGURE 61: MOUNTED CUBOCTAHEDRON (LEFT) AND LIDAR SCANNER & DATA COLLECTION STATION (RIGHT).... 72 FIGURE 62: THREE POSES OF THE REDUCED AMBIGUITY CUBOCTAHEDRON BEING PREPARED FOR SCANNING ........... 72 FIGURE 63: COMPLETE POINT CLOUD WITH BACKGROUND & TARGET OBTAINED FROM SCANNER............................ 74 FIGURE 64: LASER DOT SIZE ................................................................................................................................. 74 FIGURE 65: ARTIFACTS, FACE OBLIQUITY AND EDGE EFFECTS IN DATA .................................................................. 75 FIGURE 66: REGULAR TETRAHEDRON EXPERIMENTAL POSE E RROR & EXPECTED VALUE ........................................ 76 FIGURE 68: REGULAR TETRAHEDRON SIMULATION MEAN POSE ERROR AND E XPECTED VALUE .............................. 77 FIGURE 69: REGULAR CUBOCTAHEDRON E XPERIMENTAL POSE ERROR & MEAN POSE ERROR ................................. 78 FIGURE 69: REGULAR CUBOCTAHEDRON E XPERIMENTAL POSE ERROR & MEAN POSE ERROR BASED ON VIEW # ..... 79 FIGURE 71: REGULAR CUBOCTAHEDRON SIMULATION MEAN POSE ERROR AND EXPECTED VALUE.......................... 80 FIGURE 71: REGULAR CUBOCTAHEDRON SIMULATION MEAN POSE ERROR AND EXPECTED VALUE BASED ON VIEW # ................................................................................................................................................................... 81 FIGURE 72: REDUCED AMBIGUITY CUBOCTAHEDRON E XPERIMENTAL MEAN POSE ERROR AND EXPECTED VALUE .. 82 FIGURE 73: REDUCED AMBIGUITY CUBOCTAHEDRON E XPERIMENTAL MEAN POSE ERROR AND EXPECTED VALUE BASED ON VIEW # ........................................................................................................................................ 83 FIGURE 74: REDUCED AMBIGUITY CUBOCTAHEDRON SIMULATION MEAN POSE ERROR AND E XPECTED VALUE ....... 84 FIGURE 74: REDUCED AMBIGUITY CUBOCTAHEDRON SIMULATION MEAN POSE ERROR AND E XPECTED VALUE BASED ON VIEW # ................................................................................................................................................... 85

ix

Terms and Abbreviations
CA CCD CSCA DOF EI ICP LIDAR ME NAI Constraint Analysis Charge Coupled Device, a light sensitive device used in many digital cameras Continuum Shape Constraint Analysis Degree-Of-Freedom Expectivity Index Iterative Closest Point LIght Detection And Ranging Minimum Eigenvalue Noise Amplification Index

x

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

1 Introduction and Previous Work
Pose estimation is a fundamental area of computer vision. It estimates a rigid transformation between data points obtained from a scanner with model points available in different electronic forms. Pose estimation has applications such as reverse engineering and 3D shape reconstruction [14], feature tracking and object recognition ([69], [86], [87], [17], and [21]). Many schemes have been developed for shape registration, including registration from monocular 2D images [22], registration from stereo images [45], and registration from range data [55]. In many of these schemes, data is extracted from the images in the form of features such as edges, surfaces, graygradients etc. and 3D data is extrapolated from these features ([48], [90] and [91]). In the case of range data, 3D points are available directly from the scanner [43]. How the extracted features are further processed depends upon the application ­ for shape reconstruction, the data is meshed and surfaces created to reconstruct the original part(s), for feature tracking and recognition the data is compared to a number of models in a database and an appropriate

classification/recognition is assigned ([33] and [54]). Non-rigid transformations [25] are also utilized, mostly for medical [15] and human-pose estimation [11] studies. Pose estimation can take the form of 2D-2D, where two dimensional pose is extracted from 2D images [13], 2D-3D, where three dimensional pose is extracted from 2D images [65], and 3D3D, where three dimensional pose is extracted from 3D data ([22] and [32]). Pose estimation is of vital importance in a number of applications, including medical imaging, human pose estimation ([12] and [18]), industrial processes, and spacecraft rendezvous and docking ([19] and [20]).

A number of space operations have been identified that require unmanned rendezvous and docking capability ([3], [29], [31], [46], [66], [67], [78], [79], [92] and [93]). Current rendezvous and docking systems operate at very short distances (a few meters), providing only bearing and range towards the target [8], require that the target be oriented towards the approaching spacecraft, and may only be operated in certain lighting conditions. Current systems utilize fiducial markers ­ retro-reflectors or optical targets ­ to provide an easily detectable signal, and a review on usage of fiducial markers can be found in [26]. The use of LIDAR and advanced computer vision schemes lead to the possibility of new rendezvous and docking systems in the
Page 1

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

future ([1], [30], [73], [74] and [85]). These systems would provide autonomous detection of a satellite at distances of a few kilometers in any orientation, and provide precise pose estimation and range in any illumination condition. The Neptec TriDAR [23] is one such system, a hybrid sensor that combines triangulation and LIDAR. It uses LIDAR for blob detection at long distances, pose estimation at distances of 200 m, and a triangulation sensor for pose estimation at short distances ([80], [81] and [82]). The Neptec TriDAR has been developed from NEPTEC's Orbiter Boom Sensor System 3D laser camera that was used for Shuttle tile inspection on STS114 [84]. For both 2D-3D and 3D-3D pose estimation, the Iterative Closest Point (ICP) Algorithm, introduced by Besl et. al. [6] is one of the most commonly used methods in computer vision [64]. The task of the ICP algorithm is to create a point-to-point correspondence between model and data, and then minimize the square of the distance between each correspondence pair by iterative rigid transformations (translation and rotation) [6]. While it is one the most commonly used and most accurate algorithms for 3D pose estimation, ICP suffers from two major problems. Firstly, it is computationally intensive, leading to a high computational cost for dense data points [34], and secondly, it has a tendency to fall into local minima ­ areas that provide good convergence for the algorithm, but are not the global solution to the pose problem ([56] and [61]). One case of the local minima problem occurs due to object ambiguity ­ essentially, without some identifying features or context, one configuration of the shape may be indistinguishable from another. For example a cube is an ambiguous shape where given 3D points on the surface of the cube, they may fit any similar surface (including vertices or edges) on any side of the cube. In this case, there may be good ICP convergence onto an incorrect pose. Many variants of ICP ([97], [34], [49], [50], [89], [27], [28] and [83]) have been developed in order to improve ICP performance, both for speed and robustness, including weighted ICP (WICP), gradient-based methods [53], and the use of shape descriptors and invariants ([100], [75], [77], [4] and [99]). ICP registration error is defined as the mean point-to-point error between the data and its closestpoint on the surface of the model for the final best-fit pose determined by the ICP algorithm. ICP pose error is defined as the difference between the actual "truth pose" of the data, and the final best-fit pose estimate determined by the ICP algorithm [6]. Both of these values and therefore the algorithm's performance depend on the geometry of the object being studied. In order to predict

Page 2

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

or analyze ICP convergence, eigenvalue-based multivariate analysis is applied to ICP error covariance matrices [44] (of which there are many forms). Principal Component Analysis (PCA) is the simplest form of such multivariate analysis, where a large number of correlated dimensions (variables) are reduced to a smaller number of uncorrelated variables and principal components using the eigenvalue decomposition of the ICP error covariance matrix. Constraint analysis (CA), an application of PCA, directly assesses the sensitivity of shape registration error from ICP to variation in pose [63]. Eigenvalue-based metrics derived from CA can be used to determine the constraint of a given shape ([96] and [63]). Constraint Analysis is an attractive method of enhancing and predicting ICP as it is based on bulk calculation of data, avoids feature detection tasks, and is thus applicable to any shape[71]. This work is primarily based on a surface-integral approach to CA, labeled Continuum-Shape Constraint Analysis (CSCA) [71], which quantifies the constraint of any given shape. CSCA essentially turns constraint into a general well-defined shape property that is independent of scan parameters such as scan point density or noise characteristics [63]. The eigenvalue decomposition of the CSCA covariance matrix provides us with indices such as the Noise Amplification Index (NAI) ([96] and [68]) and the Expectivity Index (EI) [71] which can be used to directly assess the constraint of a given shape, and in the case of EI, directly predict ICP performance of the shape. Constraint Analysis leads to a number of applications for pose estimation in general, and space vehicle pose estimation in particular. These include: 1) Selection strategy of scan window(s) and scan path planning for consistent ICP-based pose estimation and pose tracking. Work using the discrete method of CA and NAI is presented in [88] 2) Shape design of industrial and space vehicle objects for high constraint and consist ICPbased pose estimation and pose tracking, regardless of scan parameters. In terms of the shape ambiguity problem, describing all the symmetries of the object and creating an metric that can map these symmetries is required. During the literature survey, a work by Kazhdan in [51] was discovered with utilized just such a metric for measuring symmetries in the context of 3D shape representation and model retrieval from a database. Kazhdan presented a symmetry descriptor, a collection of spherical functions that represent a 3D model as a collection

Page 3

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

of spherical functions that give the measure of a model's reflective and rotational symmetry with respect to every axis passing through the center of mass, and utilized the Fast Harmonic Transform and the Fast Inverse Wigner-D Transform to compute all the rotational and reflective symmetries for a model about its center of mass. Zabrodsky et. al. ([113], [111] and [112]) define a continuous measure of symmetry as the minimum amount of work needed to transform a model into a symmetric model, measured as the sum of the squared distances that the points would need to be moved.

Besl states that triangle-based polyhedral meshes are an ideal representation of 3D shapes for computer vision tasks [5]. Given that all our models will be faceted polyhedral models, and all complex shapes are derived from basic polyhedra, the study uses simple polyhedra as a starting point for the design of target shapes. A polyhedron is a 3D shape made up of planar polygonal faces. Two faces meet along edges, and any number of edges may meet at points called vertices. A polyhedron is convex if its surface does not self-intersect, and a line segment joining any two points of the polyhedra is contained within the interior volume of the polyhedron[42]. There exist an infinite number of polyhedra, many created from non-rigid transformations of certain symmetrical core polyhedral [42]. The core convex polyhedra used in this study are the Platonic, Archimedean and Johnson solids. A Platonic Solid has all faces as congruent regular polygons with each vertex having an equal number of faces meeting at it. Archimedean solids differ from Platonic solids in that they have two or more types of polygons as faces meeting at identical vertices. A Johnson Solid is a polyhedron which can have any type of polygons as faces, in any vertex configuration. There exist 5 Platonic, 13 Archimedean and 92 Johnson solids. Each of these solids fall into a different symmetry group. A symmetry group is defined as the group of all isometries under which it is invariant [42]. The symmetry groups include: 1. 2. 3. 4. 5. 6. Tetrahedral symmetry (Td), the symmetry group for a Tetrahedron Octahedral symmetry (Oh), the symmetry group for a Cube and Octahedron Icosahedral Symmetry (Ih), the symmetry group for an Icosahedron and Dodecahedron n-fold Pyramidal Symmetry (Cnv) n-fold Prismatic Symmetry (Dnh) n-fold Antiprismatic Symmetry (Dnv)

Page 4

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

1.1 Motivation
Accurate pose estimation is a critical task for space computer vision applications including autonomous rendezvous and docking of spacecraft modules and future satellite servicing tasks. For decades, docking systems have been utilizing passive imaging systems that cannot operate over long distances and under rapidly changing illumination conditions. LIDAR-based scanners, immune to ambient lighting, are the preferred alternatives, and are currently used for on-orbit operations in conjunction with conventional CCD cameras for 3D pose estimation. The Iterative Closest Point (ICP) algorithm is the one of the most commonly used and reliable methods for 3D pose estimation. As all iterative algorithms, it needs an initial guess which must be relatively close to the true pose: otherwise, ICP has a tendency to converge to the local minima different from the true pose. Shape geometry is another aspect which plays an important role in ICP accuracy: poorly constrained shapes do not deliver accurate pose estimation even if the initial pose guess is close to the true pose. For example, in the rectangular prism shown in Figure 1, the shape is poorly constrained at any of the face views. It can be freely translated in any direction except the direction normal to the face without change of the ICP error values. The shape is better constrained at an edge view as it is only free to translate along the edge. The shape is best constrained at a vertex because any translation or rotation will result in change of the ICP error values.

Figure 1: Constraint for a Rectangular Prism - Poor (left), Better (middle), Best (right)

Therefore, to select a well-constrained view is an important step in successful pose estimation process. For space operations, this preliminary analysis and design can be done at the missionplanning stage and an optimal shape and view can be selected for LIDAR scanning and

Page 5

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

consequent pose estimation. A "hypothetic" spacecraft whose body shape would be wellconstrained and provide good pose estimation could be designed. But that seems unrealistic, given the wide range of specific technical requirements for the spacecraft surface. Alternatively, a three-dimensional optimal target shape can be attached to a surface of a spacecraft, scanned by LIDAR and deliver an accurate pose. This shape is analogous to a set of fiducial markers (circular "black on white" or coded targets) as shown in Figure 2, optimally attached to the surface of the object and viewed by CCD cameras.

Figure 2: 2D Vision Markers (Left), Hypothesized 3D LIDAR Target/Marker (Right) on ISS Module. [Base Image Courtesy of NASA

The major contribution of this thesis is the design methodology to produce a 3D target shape for LIDAR based ICP pose estimation for space vision applications. The target needs to be both well constrained and unambiguous. The scan window problem is not considered, as in all cases, it is assumed that the entire target will be scanned, essentially providing a limited scan window on the entire spacecraft focused on the target. The major focus of this thesis will be on the development of a shape that provides good ICP convergence and low ICP error when scanned from a range of views. The object ambiguity problem will also be addressed via numerical simulations and analyses. LIDAR errors, edge effects, noise characteristics and problems associated with geometry-based LIDAR scanning are beyond the scope of this thesis, and will not be considered beyond a simple

Page 6

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 1: Introduction

demonstration of their existence. All simulated data is based upon rectangular even point spacing LIDAR raster scans, and all models of shapes studied are triangular mesh models.

1.2 Thesis Organization
Chapter 2, along with Appendix A, presents the theoretical background for this work. Chapter 3 contains preliminary studies necessary to select an appropriate conditioning measure, determine the effect of polyhedral shape elements (vertices and faces), and the relationship between shape ambiguity and shape symmetry. The results of Chapter 3 are applied in the design of a target shape in Chapter 4, which consists of two parts: shape design for constraint and shape design for reduced ambiguity. First, all the regular convex polyhedra (all Platonic, Archimedean and Johnson solids) were studied and compared for desired constraint characteristics, and a core shape selected from these for additional optimization. Then, the selected core shape was deformed under various stretch and skew transformations and optimized for best constraint under a variety of view ranges. Finally, the optimized shape was further transformed with additional skew transformations in order to break its rotational symmetry and reduce ambiguity. For experimental validation, presented in Chapter 5, two designed shapes and a tetrahedron were manufactured and subjected to LIDAR scans at the NEPTEC facility in Ottawa. The problem of scanner sensitivity and noise characteristics dependant upon shape geometry was not addressed in this thesis, and requires further research inputs. Despite some of the problems encountered due to variable noise characteristics in the data, requiring the use of manual point-deletion, the experimental data clearly showed the designed-for characteristics in the shapes in terms of pose error and expected value congruence. Final conclusions and recommendations for future work are presented in Chapter 6.

Page 7

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

2 Theoretical Foundations of the work
The theoretical foundations of this work are derived from certain concepts first introduced by Simon [96], and further developed and expanded by McTavish and Okouneva [63][71].

2.1 Nomenclature
Fo Observation Frame

FB

Object/Target Body Frame

Fm

Model Frame

{z i }

Set of observation points

{x i }

Position of the correspondence points on the model given in the Observation Frame

{ri }
ri

Set of correspondence points on the model

The point-wise Cartesian error vector set

The set of magnitudes of the point-wise Cartesian error vector set. Note ri that for self-registration, depicts the ri = 0 "True Pose" where is there is zero misalignment

i

A projection matrix that transforms a given pose into ri for a given point

^i n

The set of model surface normals at each point

Page 8

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

r

× i

 rx   × The skew matrix of {ri } ri =   ry    rz  

×

 0   rz  - ry 

- rz 0 rx

ry   - rx  0  

{i }

Set of zero-mean random vectors representing noise

The point-wise Cartesian error vector set for the point-to-surface
r ,i

projection, mimicking the "closest point" selection of algorithm

{ri } in

the ICP

r ,i , noise

The point-wise Cartesian error vector set for the point-to-surface project, disturbed by noise

r

A continuously variable local descriptor for the surface integral formulation, mimicking the point-wise Cartesian error

dm

The translation portion of the pose that aligns the Model Frame with the Observation Frame

M

The rotation portion of the pose that aligns the Model Frame with the Observation Frame

CM

The rotation matrix arising from the translation portion of the posealignment



A small translation vector



A small rotation vector

Page 9

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

p

The small pose misalignment vector

~ p

The small pose misalignment vector with a distance-scaled rotation vector set

A scale factor for scaling the rotation portion of the small pose
D

misalignment vector

E

The ICP cost function developed from the point-wise Cartesian error

E

The small-misalignment cost function

E ,noise

The small-misalignment cost function with additive noise

Eo

The cost-function associated with the additive noise

ES

The cost-function associated with the continuum version of selfregistration

ESv

The cost-function associated with the directional continuum version of selfregistration

E

The small-misalignment cost matrix

^ e

The error matrix projected onto the Observation Frame

ES

The cost matrix associated with the continuum version of self-registration

Page 10

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

ESv

The cost matrix associated with the directional continuum version of selfregistration

^ v

The view direction defined as a unit vector with components [ x

y

z]



Azimuth component of the view vector in non-Cartesian coordinates



Declination component of the view vector in non-Cartesian coordinates

v

The view factor that takes into account the surfaces observed by the scan and their angle to the view vector

Ap

The un-obscured projected area as seen from a viewpoint

E Sv,

The upper-left (translation) partition of the raw cost matrix.

k

Eigenvalues of the Area-normalized, rotation scaled version of the cost matrix

k NAI

Noise Amplification Index Value based on the Area-normalized, rotation scaled version of the cost matrix

kEI

Expectivity Index Value based on the Area-normalized, rotation scaled version of the cost matrix

kME

Minimum Eigenvalue Index Value based on the Area-normalized, rotation

Page 11

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

scaled version of the cost matrix

{p
N

2



}

The expected value of the mean pose-error

Number of scan-points



The standard deviation of the general point-to-point noise error.

2.2 Key Definitions
Shape Registration Registration is the task of finding correspondences between two or more sets of data. This can take the form of feature correspondence, or point correspondence. In the case of 3D-3D registration, point-correspondence often utilizes data from range scans. For "rigid" registration, given two sets of range data (either from two observations, or one observation and one model, or two models), the task is to find the relative rigid transformations (translation and rotation) that will align the two data sets. For model-based methods, registration is carried out between a set of observations and a model, illustrated in Figure 3. The observation of the object consists of N data points (in 3 ) located by the vector set {z i } as observed in the frame F o . The frame FB represents the pose of the object body to be determined. A set of corresponding points on the model, {ri } , is established relative to a model reference frame Fm . The location and orientation of the model represented by Fm in the observation frame is specified by the origin position d m and a rotation vector  M of the model reference frame Fm .

Page 12

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

Figure 3: Shape Registration

Pose Estimation Pose estimation is the task of finding some optimal translation (represented by the origin position of the model in the observation frame d m ) and rotation (represented by  M ) that minimizes the point-wise Cartesian error cost between the model and observation. Pose itself is most often represented as a 6-DOF vector. Iterative Closest Point (ICP) Algorithm The ICP algorithm registers a measured data set to a model using an iterative procedure. In the observation frame, the position of the model points is given by the set {x i } , with xi = d M + CM ri where CM is the rotation matrix corresponding to  M that transforms vector expressions from the model frame Fm to the reference frame F o . A point-based registration cost function E between the model and observed object is constructed from the sum of squared Euclidean distances ri = ri for the set of sampled pointes. The point-wise Cartesian error is constructed as ri = xi - z i . The cost function E is then:
1 N riT ri  2 i =1

E=

(1)

Page 13

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

The set of points x i are the transformed closest points {ri } on the model's surface to the data points z i . A pose estimate for the body is found by aligning the model frame Fm within the frame F o such that the above cost function is minimized. The optimal alignment problem is then one of determining values for d m and  M that minimize E. The rotation vector  M is

represented as a quaternion used for iterative pose calculation based on Horn's Method [41]. Horn's Method, outlined in [41], provides a closed-form solution to the two-frame pose correspondence problem. The ICP algorithm selects a new set of closet points {ri } for each iteration based on the previous iteration's pose to refine the pose estimate, till the cost function achieves a selected threshold value or the maximum number of iterations is reached. Self Registration The concept of self registration is first used by Simon [96], but not identified as such. McTavish & Okouneva [63] define the concept of self registration as an analytical construction that describes the perturbation of a model from itself.

Figure 4: Self-Registration

Constraint Analysis Constraint Analysis (CA) is a method that utilizes eigen analysis to assess the sensitivity of the ICP registration error to variations in pose is assessed. Using Constraint Analysis, the ICP registration cost can be expressed as functions of different components of the pose. A given shape may produce large ICP cost under some combination of translation and rotation (for example, a polyhedron may show large ICP cost under pitch motion and z-translation, but not

Page 14

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

yaw or roll motion). This means that the shape is poorly constrained in certain components of the pose vector, but not in others. CA assesses the sensitivity of the ICP registration error to each of the components of the pose vector (i.e. sensitivity to roll or pitch or yaw or translation in any given orthonormal direction).

2.3 Summary of Constraint Analysis
2.3.1 Discrete Point-Based Constraint Analysis
Under the self-registration principle, we define an ideal alignment E = 0 i.e., the data and model points are perfectly aligned with ri = 0 , as the true pose. The true pose is perturbed by a small displacement  and a small rotation  , to form the small pose p or misalignment vector:
  p=   

(2)

The physical extent of a shape from the key reference frame origin will lead to an imbalance of numerical influence between a dimensional translation and a dimensionless rotation. While the entire cost matrix could be non-dimensionlized by the normalization of point positions by a characteristic distance, this work deals with specific objects and pose accuracy needs to be assessed in a dimensional manner. For our purposes, the rotation portion of the pose vector
p needs to be dimensionally scaled to balance its numerical influence on the cost gradient. Using

~ is defined as: a scaling distance D the modified pose vector p
   1 0    p= =    = Dp  D  0 D1  

(3)

For all shapes considered in this study, the scaling distance D was chosen to be the average model radius. We now define the 3 × 6 projection matrix  i as a projection matrix that transforms a given pose into ri for a given point:
× ^ in ^ i  i = n 1 -ri  

(4)

Page 15

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

This mimics the "closest point" selection of {ri } in the ICP algorithm. The pointwise error vector becomes:
r ,i =  i p

(5)

The corresponding cost matrix is defined from the applicable projection matrices as: 1 N

E =


i =1

N

 i

i

(6)

The cost can then be constructed as:
1 E = p  E  p 2

(7)

We now add simple noise  i such that:
r ,i , noise =  i p -  i

(8)

Our small-misalignment cost function with additive noise is now:
E,noise = 1 1 ^ + p E  p Eo - pe 2 2

(9)

with: 1 N

Eo =

 
i =1 N  i

N

 i i

(10)

^= e

1 N


i =1

i

(11)

2.3.2 Continuum Shape Constraint Analysis
The continuum version of self-registration (Shown in Figure 5) replaces the stand-alone points from Figure 4 with differential surface area at a continuously variable location r.

Page 16

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

Figure 5: Continuum Self-Registration Setup

The cost function ES and cost matrix E S associated with the continuum version of selfregistration are defined as:
ES = 1  r r dS  2S (12)

ES =      dS
S

(13)

Where the applicable closest-point project matrix,   , is described in terms of the continuously
^ is the unit normal at the location r, such that: variable locator r and n

^ ^T  =  nn

^ ^ T r×  -nn 

(14)

The scanning instrument is assumed to scan the figure from a single specified viewpoint and generate data points in a uniform distribution. Only surface regions that are visible within the instrument's field-of-view will generate data. The relative location of the scan viewpoint (Figure 6) defines the casting of measurement points on the target object and can be considered analytically for self-registration. Also, the generated point density from a surface region will be proportional to its projected area in the view direction. The directional version of the cost matrix is developed by introducing a view factor v . The view aspect is demonstrated in Figure 6, and takes into account the surfaces observed by the scan and their angle to the view vector.
v ^ v ^ >0 ^ n ^ n v=  ^ 0 ^ n v  0

(15)

Page 17

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

Figure 6: Directional Weighted Scan

^ is the direction vector of the viewpoint from the surface location of r , which leads to our v

directional cost and matrix: ESv = 1  r r vdS 2 S (16)

ESv =       vdS
S

(17)

The continuum analog to the normalization by number of points is a normalization by area Ap , the un-obscured projected area as seen from the viewpoint can be computed as: Ap = trace {E Sv , } and E Sv, is the upper-left (translation) partition of the raw cost matrix. Finally, the continuum-shape area normalized version of the cost ESv and cost matrix E Sv are: 1 E Sv Ap 1 ESv Ap (18)

E Sv =

(19)

E =

(20)

This version of the cost and cost matrix is used for all further analysis and design in this work.

Page 18

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

2.3.3 CSCA Indices and Expected Value
The continuum version of the ICP cost matrix developed by McTavish & Okouneva [71] is an analogue to the discrete version developed by Simon [96] with an infinite point-density such that the scanned points approximate a surface. Therefore, we can expect the eigen characteristics of the matrix E Sv to be key indicators of constraint and hence ICP performance. All shape metrics used in this study are derived from the eigenvalues of this matrix:

k = eig {E Sv }

(21)

The three indices demonstrated and used in this study are Noise Amplification Index (NAI) which was first introduced by Nahvi & Hollenbach [68], the Expectivity Index (EI) which was first introduced by McTavish & Okouneva (See Appendix A), and minimum eigenvalues (ME). Additional explanations and derivations for the three indices used, developed by McTavish, are presented in Appendix A. In summary, the indices are defined as:

k NAI =

min max
1     k k 
-1

(22)

 kEI =   

(23)

kME = min

(24)

The expected value of the pose error can be computed directly from the EI and general noise characteristics of the data as:

{p

2



} = k1 i N

EI

(25)

Where N is the number of scan points and   is the standard deviation of the general point-topoint noise error.

Page 19

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

2.4 A Note on View Directions & Function Representations in this Thesis
The representations of vectors, views and rotations used in this thesis are presented in this section, with the equations used to convert between them. Additionally, an important graphical representation tool designed to various functions throughout the thesis is presented here.

2.4.1 View Directions
The view direction is defined as a unit vector with components [ x
y z ] . Often it is required to

represent the view or view vector using azimuth and declination angles, especially for certain optimization types. To this end, azimuth  and declination  (Figure 7) are calculated as:

 = arctan 2 ( y , x ) = 
 z - arccos  2  x + y2 + z2 2      (26)

Figure 7: Scan angles declination and azimuth

2.4.2 Function Representation
One of the main visualization and graphical representation tools used in this thesis is a functionsphere patch designed to show a function of three independent variables (the Cartesian coordinates of the view vector, x, y, z) in an intuitive and clear format. First, viewing directions are defined as a sphere map (Figure 8) of the desired resolution, and patched together to create a sphere-mesh. This mesh is demonstrated in Figure 8. The function value (index values, error

Page 20

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 2: Theoretical Foundations

values, noise values etc.) for a given shape for a particular view is found by projecting the view direction out from the origin through the sphere surface, and the radial distance of the intersection is then taken as the function value. Figure 8 (right) shows the function-map of EI, along with the shape being studied and the view-sphere. In order to read the function value from any given view vector, one can simply read the radial distance to the surface of the function-map along the direction of the view vector. For additional clarity, the plots are color-coded with blue as minimum and red as maximum. As an example, Figure 9 shows the value of the EI function for a simple cube polyhedron. From this point, the function-sphere will be omitted from function-map plots for clarity, with the actual shape being studied overlaid on the functionsphere. This allows one to see the geometrical regions and characteristics of the shape that give rise to different features of the function map. For example, in Figure 9, one can see that the highest values of EI (red) are found at the vertices of the cube.

Figure 8: View Sphere (Left) & Simple Polyhedron , View Sphere and EI Function (Right)

Figure 9: Simple Shape and EI Function

Page 21

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

3 Preliminary Studies for Ideal Shape Design
Preliminary studies were conducted towards establishing the appropriate tools, desired trends and values, and thresholds for ideal shape design. First, the conditioning measures Noise Amplification Index (NAI), Expectivity Index (EI), and Minimum Eigenvalue (ME) were compared, and a measure selected that best reflects desired goals. Next, the performance of polyhedron geometrical elements such as vertices and faces were studied in order to extract desirable geometry for shape design. Finally, shape ambiguity was explored.

3.1 Conditioning Measures
There are three main conditioning measures of interest to this study, NAI, EI and ME (See Chapter 2), each with their own design advantages and disadvantages. All conditioning measures are derived from the eigenvalues of the error cost matrix shown in Equation (20).

3.1.1 NAI
The Noise Amplification Index (NAI) is a heuristically designed measure that minimizes the maximum pose error, but it only provides information about the two extreme eigenvalues. Here we compare the NAI values of a simple cube shape with noisy ICP registration error data. In this graph, the ICP Registration Error is plotted against the NAI value of the shape, calculated from Equation (22).

Page 22

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 10: ICP Error vs. NAI

Notice that while low values of NAI correspond to high values of error, there is no statistical significance to high values of NAI except a general low error ­ i.e. for values of NAI higher than a certain threshold, there is no way of selecting a "well" constrained shape area/view from a "better" constrained shape area/view, as all NAI values beyond a certain threshold yield low error.

Figure 11: NAI Function Map of Cube (Top Hemisphere Only)

Page 23

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

The NAI function map of the cube is presented in Figure 11. As can be expected, vertex-views are well-constrained, and face views, especially where multiple faces are not visible, show bad constraint.

3.1.2 EI
The Expectivity Index is an analytically designed measure that minimizes the expected pose error. As explained earlier, the EI is mathematically designed to balance the constraint in all six degrees of freedom, instead of just comparing the minimum and maximum error degrees of constraint.

Figure 12: ICP Error vs. EI

In the ICP registration error vs. EI plot shown in Figure 12, we notice that EI does in fact predict ICP error, showing a specific statistical correlation between the two. Figure 13 is the EI function

Page 24

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

map of the same cube used earlier. Again, regions of good and bad constraint are similar to those found by using NAI, but intermediate zones are much better defined.

Figure 13: EI Function Map of Cube (Top Hemisphere Only)

3.1.3 ME
The Minimum Eigenvalue (ME) Index defined in Equation (23) limits the worst possible error in the minimum-cost pose solution due to additive noise. ICP registration error vs. ME values are shown in Figure 14, and the ME function map is shown in Figure 15. Notice the similarity of Figure 14 to the plot of ICP Error vs. NAI (Figure 10) ­ it is the contribution of ME to the NAI function that limits the worst possible error in NAI.

Page 25

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 14: ICP Error vs. ME

Figure 15: ME Function Map of Cube (Top Hemisphere Only)

Page 26

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

After considering each of the indices, we are left with either the EI or the ME as possible design tools ­ the NAI index does not predict pose error, and its usefulness occurs only because of the presence of the ME index within its equation. However, while the ME limits the worst possible error, i.e. it tells us which shapes, and which portions of shapes are badly constrained, it does not tell us which areas are best constrained. Therefore the EI index is chosen as a design tool due to its ability to account for badly constrained regions, as well as balance the contribution of all the eigenvalues of the cost matrix. Additionally, the analytical derivation of EI as presented in Appendix A makes this an extremely robust and reliable tool that can be used to directly assess the expected value of the pose error.

3.2 Study of Shape Elements
The 3D shape models used in this thesis for ICP pose estimation are faceted triangular meshes. In order to design a shape that delivers accurate pose estimation from a range of views, key shape elements, vertices and faces, must be analyzed.

3.2.1 Vertex Studies
Two parameters that characterize vertices are the number of faces connected to the vertex, and the dihedral axes between the faces, as shown in Figure 16. For the current analyses, regular ncorns are studied, such that the dihedral axes between any two adjacent faces are equal to any other face-set. As projected surface area has a direct effect on EI, the area-normalized version of the cost matrix (Equation (17)) is utilized, from a view that is parallel to the normal of the vertex being studied. The particulars of the polyhedral geometry are presented in Figure 16.

Figure 16: Polyhedron Geometry Study Parameters

Page 27

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 17: 3-Corn with 45 o Dihedral (left) and 6-Corn with 25 o Dihedral (right)

Polyhedral patches were created with an n number of sides connected to a common vertex. All patches had a common dihedral angle between their edges, shown in Figure 17. The resulting mesh was scanned from a view directly above the common vertex. In Figure 18, the value of EI is plotted versus dihedral angles for various n-corns.

Figure 18: Vertex Studies

Page 28

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

As can be seen from Figure 18, the lower the number of sides that share a vertex, the higher the EI profile. For a vertex that has 3 faces, the optimum value occurs as a dihedral angle of ~ 120 degrees. In general, the fewer the number of faces connected to a vertex, the greater the EI profile of the mesh, with the maximum EI values for all vertex configurations occurring for dihedral angles between 100 and 150 degrees.

3.2.2 Face Studies
Faces are characterized by two parameters as well: the number of faces that share edges with the face studied, and the dihedral angles between them. For this study, a n sided polygon was created with a surface normal parallel to the view vector, and additional polyhedral patches attached to each edge, shown in Figure 19. The dihedral angle between the attached polygons and the original n sided polygon was varied. Here, only polygons with edge-to-edge correspondence are studied, with equal dihedrals all on faces. In Figure 20, the EI values are plotted vs. dihedral angles for various n-sided figures.

Figure 19: 6-Sided Mesh with 70 o Dihedral (left) and 3-Sided Mesh with 20o Dihedral (right)

Page 29

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 20: Face Study

As seen from the figure above, the three-sided shape delivers the highest EI value, but shows general poor performance over a range of dihedral angles. As noted for the vertex study, the greater the number of sides connected to a face, the lower the index profile, which approaches zero for a faceted sphere. When combined with vertex effects, face effects define desirable geometry for well-constrained shapes. For example, a three-sided shape with a vertex dihedral angle of 120 degrees shows a good constraint profile from vertex views, but the same figure, when seen from face-views shows a very poor constraint profile.

In general, the fewer the number of polygons attached to a central polygon, the better the EI profile, with some specific exceptions to the 3 and 4 sided figures.

The entire range of EI values for all views on a polyhedron can be mapped, as shown in Figure 21. The value of EI from each view is mapped as a function ­ the color index on the function shows intensity of EI; the original face is provided for reference. A Tetrahedron, with a dihedral angle of ~ 70 degrees shows relatively high EI values at the vertices, and zero index values at the
Page 30

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

faces. In contrast, a Cuboctahedron, with a dihedral angle of ~ 120 degrees, each vertex connecting 4 sides, and each face connected to 3 or 4 sides. For this polyhedron, the dihedral angle is almost at the highest possible value for a 4-vertex, 3 and 4 face configuration.

Figure 21: EI Map of Tetrahedron (top) and Cuboctahedron (bottom)

Both figures and plotted on the same color scale. Given these results, we can identify our design requirement: a consistently high EI function over the entire range of views, without any dips and valleys (points where the EI function drops below a certain threshold range, or zeroes out).

Page 31

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

It should be noted that edges have a specific zeroing effect on the EI, as any edge will only have two faces attached to it, and therefore have zero index value. Edge effects on the EI are minimized and overwhelmed by face and vertex effects when the view vector encounters more than two faces.

3.3 Study of Ambiguity
For our purposes, ambiguity is said to be a property of geometric shapes where the ICP algorithm converges on a pose different from the truth pose with low registration error. In other terms, this means that one configuration (face, vertices etc.) of a shape is, without some appropriate context, indistinguishable from another, as shown in Figure 22. Two ways to demonstrate ambiguity have been explored in this study ­ using ICP Pose Error, and ICP Registration Error. All polyhedron sizes were normalized to present the same average radius, and all ICP poses scaled for rotation.

Figure 22: Two pose configurations with similar low ICP Registration Error, showing ambiguity of Cube polyhedron

3.3.1 ICP Pose Error Method
All polyhedrons to be studied were scanned from a view that yields a high EI value, and associated with a truth pose p T . For example, the cube shape is scanned from a vertex view. Then, the ICP algorithm is provided with a range of initial poses p I for the same data set, with

Page 32

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

the final ICP pose fit result from the algorithm as p . Each initial pose estimate is associated with a pose error p I , and the final pose error is p  calculated as:
p It = pT - pi = [  I  I ]

(27) (28)

p z = pT - p = [   ]

We can then plot the initial pose error versus the ICP pose error, as shown in Figure 23.

Figure 23: ICP Pose Error vs. Initial Pose Error for Cube Polyhedron

The figure below shows an example of ICP fits associated with each pose cluster. For example, all initial poses p I that converge to a pose equal to the truth pose will be clustered near the 0 value. All initial poses p I that converge onto a pose that is a single vertex away (in any direction, x, y, or z) from the truth pose will cluster at the next-best pose error values, and so on, such that the initial poses p I that converge onto a pose p that is diagonally opposite the truth pose (i.e. on the vertex farthest away from the vertex scanned) will cluster around the worst pose-error result.

Page 33

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 24: Pose Clustering showing Cube Ambiguity

This plot shows us two important features. Firstly, it presents the clustering of pose error values, showing the convergence of the ICP algorithm on an incorrect pose given an incorrect initial value. All ICP runs with initial values within a certain range will converge on a particular pose. For our cube polyhedron, there are four such pose clusters, each a different "distance" away from the truth pose. The range of initial poses close to the "truth vertex" converge onto the correct pose, while the range of initial poses close to the vertex diagonally opposite from the "truth vertex" show the maximum pose error. Secondly, given noisy data, statistical measures of such a plot like standard deviation or best-fit curve slope can be used as measures of ambiguity.

3.3.2 ICP Registration Error Method
The polyhedron to be studied is scanned from a view that yields a high EI value. For example, the cube shape is scanned from a vertex view. Then, the ICP algorithm is provided with a range of initial poses. The ICP algorithm is further modified to hold the pose rotation vector quaternion constant, and iterate through the translation portion in order to find the closest fit. After ICP

Page 34

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

convergence, the point-to-point ICP registration error is calculated. This yields a set of error values associated with each roll, pitch and yaw angle set of the initial pose estimate, and clearly shows the presence of multiple local minima. This shows that without knowledge of the polyhedron's true pose, the ICP algorithm may fall into any of these minimums. Figure 25 shows the ICP registration error function as a surface plot.

Figure 25: The Presence of multiple local minimums in the ICP Registration Error Function due to ambiguity in shape.

Given that we need to represent a function of three independent variables (view parameters x, y and z), we can use our function-sphere map again to show ICP registration error, as in Figure 26 for the cube shape.

Page 35

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 26: ICP Registration Error Function for Cube

Here, lower values of the function (blue) demonstrate low ICP registration error. The error is arbitrarily scaled for demonstration. This method has the advantage over the pose error method in that the number of minima can be counted and used as a measure of ambiguity, as long as the data is not too noisy and has clearly identifiable extrema. The pose error method shows pose clustering, i.e. convergence away from the true pose, but as each pose error is a magnitude calculation, it does not show how many distinct initial poses result in this erroneous convergence, for example, given the cube studied earlier, two distinct initial poses, associated with two distinct local minima may cluster around the same pose error value ­ a pose converging to the left of the true pose and one converging to the right of the true pose the same "distance" away from the true pose, and be a part of the same pose cluster.

Page 36

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

3.3.3 Comparison of Ambiguity functions of various polyehdra
The ambiguity characteristics and their relationship to shape geometry is studied here. The ICP Pose Error and ICP Registration Error method plots for multiple shapes are shown.

Figure 27: Pose Error Method Plot (Top) and Registration Error Method Plot (Bottom) for Tetrahedron

Page 37

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 28: Pose Error Method Plot (Top) and Registration Error Method Plot (Bottom) for Octahedron

Page 38

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 29: Pose Error Method Plot (Top) and Registration Error Method Plot (Bottom) for Icosahedron

Page 39

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 30: Pose Error Method Plot (Top) and Registration Error Method Plot (Bottom) for Cuboctahedron

Page 40

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Note that the tetrahedron has four local minima and each incorrect pose cluster has the same error value versus the truth pose because of the geometrical configuration of the shape (i.e. each "incorrect" vertex is exactly the same distance away, translationally and rotationally, from the "truth vertex"). There is an obvious relationship between the number of minima and the rotational geometry of the shape. To compare, we look at the degree of rotational symmetry of some of the shapes studied and their number of local minima in Table 1. Definitions of rotational symmetry and Orders of Symmetry are provided in Chapter 1.
Table 1: Comparison of Polyhedral Symmetry and Local Minima

Shape

Order of Symmetry

Number of Rotational Symmetries

Number of Local Minima

Tetrahedron Hexahedron (Cube) Octahedron Dodecahedron Icosahedron Truncated Tetrahedron Cuboctahedron

Td Oh Oh Ih Ih Td

12 24 24 60 60 12

4 8 8 20 20 4

Oh

24

8

Given this correlation between ambiguity and rotational symmetry, we compare the plots for a shape that has low rotational or mirror-rotational symmetry, the Stanford Bunny (Figure 31).

Figure 31: Stanford Bunny Mesh

Page 41

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Minimum Error View

Figure 32: Stanford Bunny ICP Registration Error Function

In Figure 32, it is clearly seen that the Stanford Bunny has one strong global minimum, and a surrounding area where the function approaches minimal values. The error function in Figure 32 has been scaled for demonstration. When we look at the Pose Error Method plot (Figure 33) for the Stanford Bunny (plotted on the same scale as that of the regular polyhedra), we notice that the overall pose error is low, and of similar magnitude, regardless of the magnitude of the initial pose estimate. This means that regardless of the orientation of the initial guess, the ICP algorithm is converging to a "good enough" pose. This, then, is the characteristic we are looking for when designing an ideal, ambiguity-free shape. However, it should be noted that the standard deviation of this plot, as well as the gradient of the ICP registration function is highly dependant upon the scan density, noise characteristics and constraint of the provided data, and therefore highly sensitive to variations in LIDAR sensors and noise. The general trend, however, is consistent, and enough to create crude guidelines for ambiguity reduction.

Page 42

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 3: Preliminary Studies

Figure 33: Pose Error Method Plot for Stanford Bunny

One strong global minimum (with some spread) in the registration-error function, and low pose error regardless of initial pose error magnitude in the pose error method plot are the characteristics we are looking for in an unambiguous target shape. Ambiguity is directly related to rotational symmetry of a shape, and therefore reducing the order of rotational symmetry of a shape will lead to an unambiguous shape. By combining the knowledge gained from these preliminary studies, we can use the EI and ambiguity indicators as tools to optimize an ideal target shape in the next chapter.

Page 43

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

4 Shape Design
The target shape design solution consists of two parts: design for optimal constraint, and design for reduced ambiguity. In the first part, a large number of shapes (Platonic, Archimedean and Johnson Solids) are studied, and the shape-family with the most desirable EI Function Map (as determined in Chapter 3) is selected. Here, shape-family refers to a specific polyhedron and all its derivatives by deformation, for example a shape-family would consist of a cube and all 6-sided prisms that are derived by deforming a cube. A view-cone is selected (the range of views for which the object has to be optimized), and the selected core shape (the undeformed, regular member of the shape-family) is deformed through iterative stretch and skew factors and a value for the fitness function of the shape is obtained for the view cone. The deformation values (stretch and skew) that yield maximal value for the fitness function are applied to the core shape. The new deformed shape is then processed through the ambiguity reduction process, where additional skews are applied to break the rotational symmetry of the shape while retaining high values of constraint. Finally, a reduced-ambiguity version of the high-constraint shape-family is created, and shapes are ready for final production and experimental validation. The design process is outlined in Figure 34.

Page 44

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 34: Design Process for Target Shape Creation

Page 45

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

4.1 Design of Well-Constrained Shape
For the optimal constraint design, the EI was used as a tool to select a family of polyhedra that have the desirable EI function characteristics defined in Chapter 3. Then, numerical optimizations were performed upon the selected core shape in order to select the 3D shape transformation that will yield maximal performance for a given range of viewing directions.

4.1.1 Polyhedron & Candidate Shape-Family Selection
Based on the analysis developed in Chapter 3, entire classes of polyhedra were studied for the first part of this design process. The regular and quasi-regular families studied for desirable elements were the Platonic, Archimedean and Johnson Solids. Ideally, we would be able to identify a family of shapes that do not have any low EI values, and present high constraint when viewed from all angles. For example, we can identify the tetrahedron immediately as a poor candidate.

Figure 35: EI Map of Tetrahedron

Looking at Figure 35, we notice that it has relatively high values of EI (and therefore good constraint) at the vertices, but at a view that is just a few degrees away from a vertex view, the EI drops sharply to zero, because the shape is poorly constrained from this view. Table 2 summarizes some of the results of the Shape-Family study.

Page 46

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Table 2: EI Minima/Maxima for Selected Polyhedra

Family

Name

Dihedral Angles

Max Index

Min Index

Platonic Platonic Archimedean Johnson

Tetrahedron Dodecahedron

70.53 116.56

0.0596 0.0644 0.0699 0.0649

0.0000 0.0626 0.0543 0.0000

Cuboctahedron 125.26 Elongated Triangular Dipyramid Various

The index maps of two of the above solids, the Dodecahedron and the Elongated Triangular Dipyramid, are shown below.

Figure 36: EI Map of Dodecahedron

Page 47

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 37: EI Map of Elongated Triangular Dipyramid

Of the 116 regular and quasi-regular polyhedra studied, as expected after the vertex and face study, the Cuboctahedron demonstrated the most desirable EI configuration. The EI function map of the Cuboctahedron is shown in Figure 35. There is a high index value from all views, and almost no gradient, and no index values ever drop to zero. Shapes with a higher number of sides, or faces consisting of higher-order polygons than a Cuboctahedron showed a more consistent value of EI, but lower overall constraint values. i.e. the gradient of the constraint function was low, as desired, but the maximum value of constraint was also low. The Cuboctahedron presented the most desirable tradeoff between low gradient and high EI maximums.

Figure 38: EI Map of Cuboctahedron

Page 48

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

The Cuboctahedron was chosen as our candidate for optimization and numerical study. Additionally, the Tetrahedron was chosen for further analysis in order to provide a comparison with the Cuboctahedron.

4.1.2 Candidate Optimization
A fitness function that measures the suitability of a shape for ICP pose estimation from a specified range of views (Figure 39) was defined as:
 

F =   f ( ,  ) sin(  )d d
0 0

(29)

Where f ( ,  ) is the value of the EI defined over a view specified by azimuth  and declination   . The fitness function is the mean value of the area-normalized EI over a solid angle of a cone with apex 2 , calculated using the double quadrature method.

Figure 39: Solid Angle over a cone of views

Additionally, a threshold value was established in order to ensure that the fitness function value is not affected by null or very small EI values.
 0   F =   f ( ,  ) sin( ) d d 0 0 if f ( , ) < 10 -8 if f ( ,  ) > 10 -8

(30)

The deformation process of a polyhedron can be defined in the following way: Let TXY be a set of numbers ( TXY = 0.005, 0.01, 0.015...,1) , called xy-skew ratios; and let TZ be a set of numbers,

Page 49

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

( TXY = 0.005, 0.01, 0.015..., 2) , called z-stretch ratios. Each vertex ( Vi = [ xi polyhedron is subjected to a translation presented in the following pseudocode.

yi

zi ] ) of a

function Vi = deformation( TXY , TZ , Vr ,i ) { for TXY = 0.005 : 0.005 :1 { for TZ = 0.005 : 0.005 : 2 { for i = 1:1: N {   TXY 1 -     skewi =  1 +  T   XY  

z r ,i   if z r ,i > z c z r , max   z r ,i   if z r ,i < z c z r ,min  

 skewi x r ,i    Vi =  skewi y r ,i    ( T )( z - z ) + z c c  Z r ,i } } } } where N is the number of vertices in the shape, polyhedron centroid, Vr ,i =   xr ,i yr ,i

[ xc

yc

zc ] are the coordinates of the

zr ,i   is the vertex-set of the unmodified, regular

polyhedron, and zr ,max , zr ,min are the maximum (highest) and minimum (lowest) z-coordinates of the unmodified regular polyhedron.

The fitness function for various shapes was studied. For example, looking at a 10o view cone, Figure 40 and Figure 41 show the fitness function over the transformation parameters the Cuboctahedron and the tetrahedron.

Page 50

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

F

Figure 40: Transformation Optimization Fitness Function of Cuboctahedron for 10o View Cone

F

Figure 41: Fitness Function of Tetrahedron for 10o View Cone

The Based on the fitness functions above, the optimal Cuboctahedron and tetrahedron are created for a 10o view cone.

Page 51

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 42: Transformed Cuboctahedron for 10o View Cone

In Figure 42 we notice that the shape of the Cuboctahedron has been transformed into something that resembles a pyramidal Tetrahedron-like shape. This follows from the fact that for a narrow vertex-view cone, the Tetrahedron performs well. Figure 43, the Tetrahedron has been transformed to improve a 10 degree view performance from the top vertex.

Figure 43: Transformed Tetrahedron for 10 Degree View Cone

Page 52

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

For a 360o view-cone, the untransformed regular Cuboctahedron was the optimal solution, and there existed no tetrahedron that would provide any non-zero fitness value for this cone. Since we desire high constraint from all views, the untransformed regular Cuboctahedron was chosen for experimental analysis & validation.

4.1.3 Numerical Simulations
Numerical simulations were carried out to verify the ICP performance of our optimized shapes. All shapes were scanned using a medium-sparse scan density (85 to 100 points per view), over the entire 360o view map. Random noise (2 ­ 4 [mm]) was added to each scanned point, for 100 noise trials per view case. The ICP Registration Error for the regular Cuboctahedron and the regular Tetrahedron were plotted versus the EI value for the shape. As can be seen in Figure 44, the Tetrahedron has poor performance, and high ICP error for low EI values. This occurs for any view that "sees" only two faces. It does contain some low error, high EI characteristics, but the large gap between low and high values, and the prevalence of the poor-performance poses validates the results in Section 4.1.1. In Figure 45 we notice that the regular Cuboctahedron has clustered low ICP registration error compared to the Tetrahedron. There are no values for which the EI is zero. Our candidate selection choice is validated as we look at the Pose Error performance of both shapes. In Figure 46, the Tetrahedron again demonstrates its high gradient, with high pose error/low EI and low pose error/high EI clusters. Conversely, Figure 47 (Regular Cuboctahedron Pose Error vs. EI) shows only the low pose error/high EI clusters, exactly as desired for high constraint performance from all views.

Page 53

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 44: ICP Registration vs. EI for Tetrahedron

Page 54

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 45: ICP Registration Error vs. EI for Regular Cuboctahedron

Page 55

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Expected Value from Theory * Mean Pose Error

Figure 46: Pose Error vs. EI for Tetrahedron

Page 56

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Expected Value from Theory * Mean Pose Error

Figure 47: Pose Error vs. EI for Regular Cuboctahedron

Page 57

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Finally, we look at the Pose Error vs. View Angles (Azimuth and Declination) for the 360o optimal Cuboctahedron (Figure 48) and the 10o optimal Cuboctahedron (Figure 49). Figure 48 shows low pose error from all views, as expected. Figure 49 for the 10-degree optimal Cuboctahedron shows low pose error for all views from 0o to a little more than 10o, and high pose error elsewhere. However, there is a spread of low pose error, and low pose error for more than just the 10o view-cone, demonstrating the remarkable constraint characteristics of the Cuboctahedron family of polyhedra.

Page 58

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 48: Regular Cuboctahedron (Top Right), Pose Error vs. View Angles for Regular Cuboctahedron (Bottom)

Page 59

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 49: 10o optimized Cuboctahedron (Top Right), Pose Error vs. View Angles for 10o optimized Cuboctahedron (Bottom)

Page 60

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

4.2 Design of unambiguous shape
Using the polygon connectivity and dihedral angle sets of the selected candidate, 3D transformations were applied to the polyhedron in order to produce unique sets of dihedral angles, which are then tested against the ambiguity measures defined in Chapter 3. Due to the difficulty in counting local minima in-loop, especially for shapes that have poorly defined gradients and regions of minima, the best-fit slope of the pose-error method was minimized by the optimization. Finally, from the shapes designed by the optimization process, the EI map was used again to select a final shape that had the best constraint characteristics. At this point it should be noted that the optimization process makes a number of assumptions regarding shape concavity thresholds and face obliquity thresholds (i.e. there is no bound on these quantities), which is unrealistic given poor LIDAR performance under certain conditions.

4.2.1 Candidate Selection & Optimization
Based on the results of Section 4.1, and the constraint characteristics of even heavily modified Cuboctahedra, the Cuboctahedron shape was chosen again as a base shape for the reduced ambiguity design process. As shown in Chapter 2, ambiguity is directly related to rotational symmetry, so our design process begins by identifying a method to break rotational symmetry. The transformations described in Section 4.1.2 were now modified to a xy-skew and an xz-skew: ( TXY = 0.005,0.01,0.015,....,1 ), applied to each vertex of the polyhedron Vi , i = 1,2,..., n , as follows:  skew z i x r ,i    Vi =  skew z i y r ,i    zi   where
  T XY 1 -    z  skew i =  1 +  T   XY   z r ,i   if z r ,i > z c z r , max   z r ,i   if z r ,i < z c z r , min  

(31)

(32)

and ( T XZ = 0.005,0.01,0.015,....,1 ), applied to each vertex of the polyhedron Vi , i = 1,2,..., n , as follows:

Page 61

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

 skew y i x r ,i    Vi =  yi   skew y i z r ,i    where
  T XZ 1 -     = 1 +  T   XZ   y r ,i   if y r ,i > y c y r , max   y r ,i   if y r ,i < y c y r ,min  

(33)

skew y i

(34)

The skew ratios were chosen with similar rationale as in the optimization-for-constraint step, with all variables the same (See Section 4.1.2). yr ,min , yr ,max , xr ,min , xr ,max are the minimum and maximum y and x coordinate values, respectively, of the unmodified polyhedron. Additionally, the Adjacent Dihedral Set of each polygonal of the Cuboctahedron mesh are defined as the dihedral angles between each polygon of the Cuboctahedron and the polygons that share an edge with it. For example, Polygon #14 (Shown in Figure 50) is surrounded by Polygons 16, 21 and 13. Dihedral angels are calculated as:
^ i n ^ j)  i , j = arccos(n

(35)

^ is the unit-normal of the given polyhedral patch, creating an Adjacent Dihedral Set for where n

Polygon #14 as [14 ,16  14, 21  14,13 ]. The Cuboctahedron has 20 such Dihedral Angle Sets, one for each triangular polygon (Even though the Cuboctahedron has 14 faces, each 4-sided face is broken down into 2 triangular polygons for a total of 2 x 6 + 8 triangles). The blue arrows in Figure 51 mark polygon normals.

Page 62

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 50: Cuboctahedron Polygon Map and Normals

The skews were then iterated such that the function G yielded a zero value if all Adjacent Dihedral Sets for the transformed shape are not unique (within a 3o arc) sets, and a value of 1 if the sets were unique. The threshold value of 3o was chosen arbitrarily, and should ideally depend on the characteristics of the LIDAR sensor, the point-density of the scan used, and noise characteristics. The transformation that yields both the best EI map (selected similarly to Section 4.1.1) is evaluated by applying the Pose-Error Method identified in Chapter 3. The resultant polyhedron is shown in Figure 51, with its EI Map in Figure 52. Green arrows in Figure 51 mark polygon normals.

Page 63

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 51: Reduced Ambiguity Cuboctahedron Polygon Map and Normals

Figure 52: EI Map of Reduced Ambiguity Cuboctahedron

4.2.2 Numerical Simulations
The results of the Pose Error Method evaluation presented below.

Page 64

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 53: ICP Registration Error Method Ambiguity Measure for Reduced Ambiguity Cuboctahedron

Page 65

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 54: Pose Error Method Measure for Reduced Ambiguity Cuboctahedron

Page 66

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 55: ICP Registration Error vs. EI for Reduced Ambiguity Cuboctahedron

Page 67

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

Figure 56: Pose Error vs. EI for Reduced Ambiguity Cuboctahedron

Page 68

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 4: Shape Design

The ICP Convergence and Pose Error characteristics of the Reduced-Ambiguity Cuboctahedron are comparable to the regular Cuboctahedron. ICP Registration error (Figure 55) is low, and the Pose Error vs. EI plot (Figure 56) shows the designed-for low pose error/high EI cluster. Based on the results of this chapter, three shapes (The Tetrahedron, the Regular Cuboctahedron, and the Reduced Ambiguity Cuboctahedron) were chosen for prototyping and experimental validation.

Page 69

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

5 Experimental Validation
Experimental Validation on three shapes (Regular Tetrahedron, Regular Cuboctahedron and the Reduced Ambiguity Cuboctahedron) was carried out in order to validate the design process, and provide real data for comparison with simulation data. At this point it should be noted that the simulation data presented in Chapter 4 is based on simple noise characteristics, scan point density and shape scale derived directly from the experimental setup, characteristics and test objects in order to better compare numerical simulation and experimental results.

5.1 Experimental Development & Setup
Mesh models of the Cuboctahedron and Reduced Ambiguity Cuboctahedron were exported and printed using a Rapid Prototyper (Figure 57). Figure 58 shows the two shapes printed. The shapes then had appropriate holes drilled into them for mounting. During the actual Experiment, the shapes were mounted on a roll-yaw mount at (Figure 60) provided by Neptec, and scan data was extracted using a commercial Laser Camera System (TriDAR) (Figure 61) developed by Neptec Design Group. The shapes were manually rotated to various pose configurations (Figure 62), and scanned using various scan types and scan densities. For the purpose of this thesis, all analysis is based on the 256x256 Raster Scan data.

Figure 57: 3D Printer (Rapid Prototyper)

Page 70

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 58: Shapes being prepared for mounting

Figure 59: Diagram of Experimental Setup

Page 71

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 60: Roll/Yaw Tripod Mount provided by Neptec

Figure 61: Mounted Cuboctahedron (Left) and LIDAR Scanner & Data Collection Station (Right)

Figure 62: Three poses of the Reduced Ambiguity Cuboctahedron being prepared for scanning

Page 72

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

5.2 Experimental Limitations & Data Characteristics
In order to align the experimental results with simulation, a number of assumptions and considerations were made: 1. The experimental results contained many background points, as well as noise that is extraneous to our studies. As shown in Figure 65, the data points exhibit a number of edge effects and artifacts. The data had to be cleaned manually to remove outliers, background, and some edge points from the original dataset. 2. All theoretical values have been calculated with the Parallel Ray Assumption. With a distance of only 4 meters between the scanner and the target, this assumption is no longer wholly valid. Additionally, the dot size of the laser (Figure 64) from the scanning device is large, leading to high noise. The actual value of the noise was calculated from experimental data by using the RMS mean of the point-to-point registration error value for the best-fit ICP pose. This noise was calculated for each scan and each target. 3. True Pose ­ uncertainty in the physical location of the origin [0,0,0] of the scanned data points (outside the scanner box), and uncertainties of physical setup measurement excludes the possibility of analytically calculating the true pose for each pose configuration. Therefore, ICP pose estimate resulting from the main 256x256 dense raster scan is used as the True Pose. Then, the scan is decomposed into sub sets of 100 points, creating 40 ­ 120 sparse scan sets, which are then compared against the ICP pose estimate from the dense scan in order to compute individual ICP Pose Error.

Page 73

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 63: Complete Point Cloud with Background & Target obtained from scanner

Figure 64: Laser Dot Size

Page 74

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 65: Artifacts, Face Obliquity and Edge Effects in Data

5.3 Data & Comparison
Figure 66 shows the experimental pose error and mean pose error for the Tetrahedron. There were 23 views (poses) scanned for this target shape, with an average point-to-point registration error of 3 mm. Looking at the mean pose error and expected value of the pose error calculated from Equation (24), we notice the similarity to simulation data (Figure 67), as well as the close congruence between the expected value of the error and experimental mean pose error. Figure 68 shows the experimental results for the Regular Cuboctahedron, also similar to simulation data (Figure 70). This target shape had slightly higher noise characteristics, averaging to approximately 4 mm ICP point-to-point registration error. Seven poses were scanned for this target. The tight clustering of the low-error high EI validates our design methodology in selecting a shape for high constraint characteristics.

Page 75

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 66: Regular Tetrahedron Experimental Pose Error & Expected Value

Page 76

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Expected Value from Theory * Mean Pose Error

Figure 67: Regular Tetrahedron Simulation Mean Pose Error and Expected Value

Page 77

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Expected Value from Theory * Mean Pose Error

Figure 68: Regular Cuboctahedron Experimental Pose Error & Mean Pose Error

Page 78

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 69: Regular Cuboctahedron Experimental Pose Error & Mean Pose Error based on View #

Page 79

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Expected Value from Theory * Mean Pose Error

Figure 70: Regular Cuboctahedron Simulation Mean Pose Error and Expected Value

Page 80

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 71: Regular Cuboctahedron Simulation Mean Pose Error and Expected Value based on View #

Page 81

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Expected Value from Theory * Mean Pose Error

Figure 72: Reduced Ambiguity Cuboctahedron Experimental Mean Pose Error and Expected Value

Page 82

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 73: Reduced Ambiguity Cuboctahedron Experimental Mean Pose Error and Expected Value based on View #

Page 83

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 74: Reduced Ambiguity Cuboctahedron Simulation Mean Pose Error and Expected Value

Page 84

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

Figure 75: Reduced Ambiguity Cuboctahedron Simulation Mean Pose Error and Expected Value based on View #

Page 85

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 5: Experimental Validation

The Reduced Ambiguity Cuboctahedron had the maximum ICP Registration Error overall, with an average of approximately 6 mm point-to-point error, possibly due to a greater degree of edge effects and effects due to face obliquity. 15 poses were scanned in the process. Figure 72 shows the experimentally obtained pose error and mean pose error, while Figure 73 shows the expected value of the pose error and mean pose error. When compared to the simulation data (Figure 74), we notice a higher error in experimental data. When the greater noise characteristics are taken into account, the higher pose error is adequately modeled by the expected value, as shown in Figure 73. The experimental results help us establish the validity of the Cuboctahedron as a desirable target shape in terms of constraint, as well as the simulation results and the expected value predicted by the Expectivity index. The uncertainty of True Pose, and the relatively low number of poses scanned makes valid calculation of the ambiguity of the experimental results difficult. However, given the difference in actual data and simulation data, it is obvious that scanner characteristics, including sensitivity to obliquity have to be taken into account when determining thresholds for the ambiguity-reduction process. Chapter 6 presents additional future work that has to be undertaken in order to apply the design methodology successfully.

Page 86

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 6: Conclusions

6 Conclusions
Accurate shape registration and pose estimation are critical tasks for computer vision applications including autonomous rendezvous and docking of spacecraft. Current docking systems utilize passive imaging cameras that cannot operate over long distances and in various illumination conditions. LIDAR-based scanners are the preferred alternatives for 3D pose estimation in space. The Iterative Closest Point (ICP) algorithm is the one of the most commonly used methods for 3D shape registration and pose estimation, but suffers from the problems of computational cost and a tendency to converge on local minima. Continuum Shape Constraint Analysis (CSCA) provides a tool that can be used to measure ICP performance for any 3D shape. Given the problem of ICP convergence for badly-constrained spacecraft shapes, this thesis works to design a 3D target shape for LIDAR scanners that would act as an analogue to fiducial markers for CCD cameras on spacecraft objects. The design of an ideal target shape eliminates or reduces the impact of various issues in the LIDAR-based pose estimation problem, including non-ideal scan windows and model uncertainties. It also allows us to design for maximum ICP performance, and eventually, reduced error due to model geometry. This work uses the theoretical development of Continuum Shape Constraint Analysis, and provides additional simulation and experimental validation of the tool. The study resulted in developing methodology for creating an "ideal" target shape for LIDAR based pose estimation. Following this methodology, two shapes were designed. The Cuboctahedron showed minimum registration and pose errors from all angles if the pose initial guess was close to the truth pose. The Reduced Ambiguity Cuboctahedron showed similar performance regardless of the initial guess. Specific results, as well as recommended future work are included in this section.

6.1 Summary of Specific Results
It was found that: 1. EI was shown to be the best (among NAI and ME) design tool for selecting and optimizing a geometric shape for LIDAR pose estimation.

Page 87

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 6: Conclusions

2. For vertex views of a shape, the EI profile was inversely proportional to the number of faces connected to this vertex. The vertex with 3 faces has the best EI profile for all dihedral angles. The max EI value for a n-sided vertex was always for angles between 100 and 150 degrees. 3. For face views, the fewer the number of polygons attached to a viewed face, the better the EI profile for the mesh with the exception of the 3 and 4 sided figures. 4. The edge views deliver zero EI (pose is unconstrained as only two faces are viewed) unless the view contains additional faces. 5. The best characteristic used for the target design was identified as a high overall EI profile without any steep local minima. 6. Of the family of convex polyhedra studied (Platonic, Archimedean and Johnson solids), the Cuboctahedron showed the most desirable EI function, and the EI function remained high constraint, no-zero/no-valley even under various stretch and skew transformations. 7. Shapes could be transformed and optimized for high constraint for a given range of views within a "view cone". For a full 360o view cone, the un-deformed Cuboctahedron provided the highest constraint, whereas for a 10
o

view cone (top view), a severely

deformed Cuboctahedron with a stretch factor of 1.8 and a skew factor of 1 (no-skew) was found to be ideal. 8. The multiple local-minima problem of ICP, referred to as shape ambiguity in this study, was addressed by looking at various polyhedra. Two methods of measuring shape ambiguity were designed: a. A method that utilizes ICP registration error and counts minima in the ICP registration error function demonstrated a clear correspondence between the number of ICP minima and the shape's rotational symmetry, but was difficult to use because of the difficulty in counting minima or determining threshold values for gradients. b. A method that utilizes ICP pose error and compares the pose-clustering of erroneous ICP output was found to demonstrate a general trend of increasing ICP pose error with an increasing ICP initial-guess pose error. Statistical values of the data output from this method, such as standard deviation and means can be used as a design tool.

Page 88

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 6: Conclusions

9. A shape was heuristically designed by varying the sets of normals that correspond to the shape's surface polygons, and analyzed using the ambiguity measurement tools in the study. It was found that breaking the rotational symmetry of the shape significantly reduces ambiguity, and lowers the number of local minima that ICP can fall into. 10. Experimental validation for both constraint and ambiguity was carried out on selected shapes. The Cuboctahedron's designed-for properties of high constraint and low ICP error were verified, as were the Tetrahedron's undesirable characteristics. The reducedambiguity Cuboctahedron was also verified to have high constraint. 11. It was also found that for reduced-ambiguity designs, the sensor characteristics relating to object geometry (face obliquity and edge-effects) need to be considered in order to reduce data noise.

6.2 Future Work
Additional research work is recommended primarily in the area of LIDAR sensor sensitivity to target geometry, and noise considerations. In order to enhance the design methodology presented in this work, modifications need to be made to the thresholds and optimization functions in order to account for such. A number of LIDAR scanners need to be studied in order to determine common key characteristic of sensitivity to target geometry, including edge prevalence and face obliquity. A custom scanner metric needs to be designed that will combine this sensitivity with the noise and dot characteristics of the scanners studied, and can be applied directly to the optimization processes developed in Chapter 4. A rigorous and analytical treatment of ambiguity is required in order to remove the reliance of the ambiguity-reduction process on numerical trends and solutions, especially where these numerical trends are not wholly clear. A custom ambiguity metric needs to be designed that can be used as a design tool, similar to the EI metric, to minimize the shape's ambiguity cost function, also to be developed.

Page 89

Ideal Target Design for LIDAR-based ICP Pose Estimation for Space Vision Tasks

Chapter 6: Conclusions

It should be noted that this study is focusing on a single ideal target in any configuration versus multiple non-ideal targets in an ideal configuration. A comparative analysis between these two methods needs to be carried out, in terms of constraint, ambiguity and scanner sensitivity.

Page 90

Appendix A: Sensitivity Indices for Discrete-Point Pose Estimation*
In this appendix we exercise the small misalignment form of the computed registration cost function to produce three types of sensitivity index for pose estimation. The first two of these are the Minimum-Eigenvalue and related Noise Amplification (NAI) Indices. The first is a basic result. Nahvi and Hollerbach [68] derived the second as a parameter error sensitivity index in a general form for nonlinear least-squares optimization and Simon adapts it in for pose estimation, using it extensively in [96] for assessing marker point configurations. Our alternate derivation in the self-registration context more directly deals with the attainable accuracy by starting from the true pose and moving to the noise induced perturbed minimum. The third index, the Expectivity Index, is developed and used for assessing general pose estimation accuracy. Our work also more explicitly focused on the size of the point-wise error. The solution to the small misalignment cost function with added noise is:
p = E -1e

(A.1)

We can re-express the discrete-point cost matrix E and the Jacobian factor e embedding the noise error in extended column form as:
 1   E=  2       1  e = 2       
T

 1     = col  T col  { i} { i}  2      1    = col  T col  { i} { i}  2    

T

(A.2)

We define pose-error uncertainty sensitivity indices k that range from zero when E is singular (unconstrained configuration) and favors better pose estimation with increasing value. The indices are written in terms of the const matrix eigenvalues {k } = eig {E} noting that these are

*

Reproduced from work by McTavish and Okouneva under the Ryerson/Neptec/CSA Partnership Project

Page 91

also the squared singular values of the col { i } matrix. For convenience, we write out the norm of the extended error vector as:

col { i } =


i =1

N

2 i

(A.3)

and we identify an upper bound  on the point-wise noise  i in order to write: col { i }  N   (A.4)

Minimum Eigenvalue Index
The Minimum Eigenvalue Index is the basic result found from separating the noise error from the Jacobian and fully consolidating the geometry terms of the pose solution:
p  col { i E-1}  col { i }

(A.5)

Since col  i E-1

{

}

T

col i E-1 = E-1 we obtain 1

{

}

p 

min

 col { i }

(A.6)

which is the standard result from linear algebra reflecting the maximum possible magnification of a norm-bounded vector. We define the Minimum Eigenvalue Index as

kmin
and rewrite (A.5) as: p 

min = kME

(A.7)

1

kME

 col { i }

(A.8)

Page 92

Noise Amplification Index
Although its authors [68] present the development of NAI in the context of a norm bound, it is essentially a heuristic modification of the Minimum Eigenvalue Index that seeks to favour a more "spherical" pose-error space (balanced gradient in all pose directions) over a "lessspherical" space. The square-root of the ratio of maximum to minimum eigenvalue of
E quantifies the ratio of extreme dimensions for the "error hyper-ellipsoid" [96] and is also the

condition number of the matrix col { i } denoted here as  . The inverse of this condition number has a maximum value of unity for a spherical pose-error space and less than unity otherwise. The NAI is thus constructed
1

k NAI



 k ME =

min   min = min max max

(A.9)

And satisfies the norm relationship

p 

1

k NAI

 col { i }

(A.10)

though not generally a minimum upper-bound relationship (unless  = 1 where k NAI coincides with kME . The same NAI can also be generated rapidly from (A.1) by not consolidating the geometry terms while generating a norm bound relationship:

p  E-1 i e  E-1 i col { i } i col { i }
leading directly to
 1  p   i  min 

(A.11)

(

max i col { i } =

)

1

k NAI

i col { i }

(A.12)

which leads to an alternative interpretation of NAI. Recognizing the that e is the spurious gradient of E added to the self-registration cost function due to noise, NAI is an index that takes the most significant possible impact on the gradient magnitude (provided by max ) and reflects it

Page 93

through the worst possible (i.e. lowest) gradient direction (governed by the reciprocal min ). NAI seeks to minimize the hypothetical net effect of these two undesirable events. Before proceeding, we make the following comment regarding the use of either the MinimumEigenvalue or the Noise Amplification Index. Though following from a consideration of poseerror norm, we are generally working with noise that includes a range of bias and zero-mean random components. Especially when working with the larger data sets of a LIDAR scan, the likelihood that the most deleterious distribution of error required to "max out" such a norm bound would ever occur can be dismissed. The norm bound form can thus be misleading, especially when written in terms of the point-wise error  using (A.4), i.e.,
 1  p   i  k NAI 

(

N i

)

(A.13)

which seems at first to indicate that the pose error is allowed to be larger if more points are used. Of course, as defined above, the k indices are dimensional with square-root of eigenvalue that also generally increases with

N . This still conceals the fact that with a random component of

noise error we will certainly find a lowering of the pose error due to simple averaging in the computed cost minimization. Although we use point-number normalized eigenvalues and indices in the text to tidy things up, the above comments are meant to underline the point that the norm-based indices are posed as general sensitivity metrics. Without further interpretation they may be used to compare different shapes or point configurations only under similar conditions with respect to the number of points involved and the nature of the error noise.

Expectivity Index
In this section we develop an index that is intended to differentiate between configurations or views according to net expected pose error across all directions in pose space. The actual location of the small-pose solution (A.1) is driven by the distribution of noise-error in the sample data set via the geometry of the nominal point locations. We avoid a heuristic appraisal of the net

Page 94

"size" of the pose-error space, and derive our index using elementary statistics, based on the assumption of zero-mean random noise. We examine the expected value of the pose-norm squared (i.e., the pose-error variance from the true pose):

{p

2



} =  {p p } = trace{ {p p }}
T T









(A.14)

We presume the noise error

{ i }

to be zero-mean, random and uncorrelated with a per-

component variance of  2 hence

 {  } = 
T

2

 



(A.15)

^ = col { } , and, defining  i

 {p

T



^T p =  2 itrace E -1

}

{(

) (E

T

-1

^T 

)} =  i (E
2

-1



^T 

)

2

(A.16)
F

where i F is the Frobenius matrix norm. Evaluating this norm via eigenvalues...

(E
hence

-1

^T 

)

2 F

1 ^ T ^ E-1 = eig E-1 = =  eig k E-1   k 
k

{ (

) }

k

k

k

(A.17)

 {p
Taking the square root

T



 1  p =  2 i    k k 

}

(A.18)

 {p

T



p =   i

}


k

1
k

(A.19)

leads to our definition of the Expectivity Index:

Page 95

kEI

   

1     k k 

-1

(A.20)

This averaging of the eigenvalues that falls out of the Frobenius norm is essentially the harmonic mean, but without the averaging number. This index can be used as a relative indicator of statistical pose estimate accuracy, but also as an absolute predictor via

{p

2



} = k1 i
EI



(A.21)

if the noise standard deviation   is known. Unlike NAI, the Expectivity Index does not indicate isotropy of the pose-error space and thus says nothing directly regarding the distribution of the pose-error, only the expected value of its standard deviation.

Page 96

References
[1] [2] Allen, A. C. M., Mak, N. N., & Langley, C. S. Development of a scaled ground testbed for lidar-based pose estimation. Robot Vision for Space Applications. Arthur, D., & Vassilvitskii, S. (2006). Worst-case and smoothed analyses of the ICP algorithm, with an application to the k-means method. Proceedings of the 47th Annual IEEE Symposium on Foundations of Computer Science, 153-164. Baumgartner, E. T., Schenker, P., Leger, C., & Huntsberger, T. L. (1998). Sensor-fused navigation and manipulation from a planetary rover. Proceedings of SPIE Symposium on Sensor Fusion and Decentralized Control in Robotic Systems, , 3523 Belongie, S., Malik, J., & Puzicha, J. (2002). Shape Matching and Object Recognition Using Shape Contexts. IEEE Tranactions. on Pattern Analysis and Machine Intelligence, Vol.24, No.4. Besl, P (1995). Triangles as a Primary Representation. Lecture Notes in Computer Science, Vol 994. 191 ­ 207. Besl, P.J., & McKay, N.D. (1992). A Method for Registration of 3-D Shapes. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 14(2), pp. 239­256. Blais, F., Picard, M., & Godin, G. (2003). Recursive model optimization using ICP and free moving 3D data acquisition. Proc. 3DIM, 251-258. Bondy, M., Krishnasamy, R., Crymble, D., & Jasiobedzki, P. (2007). Space vision marker system (SVMS). AIAA SPACE 2007 Conference & Exposition, Borges, G., & Aldon, M. (2002). Optimal mobile robot pose estimation using geometrical maps. IEEE Transactions on Robotics and Automation, 18(1), 87-94. Borzenko, O., Xu, W., Obsniuk, M., Chopra, A., Jasiobedzki, P., Jenkin, M., et al. (2006). Lights and camera: Intelligently controlled multi-channel pose estimation system. Proc. of the 4th IEEE Intl. Conf. on Computer Vision Systems (ICVS'06), 42. Brown, L. M., & Tian, Y. L. (2002). Comparative study of coarse head pose estimation. IEEE Workshop on Motion and Video Computing, Orlando FL, Dec. 5, , 6 Cappello, A., Cappozzo, A., La Palombara, P. F., Lucchetti, L., & Leardini, A. (1997). Multiple anatomical landmark calibration for optimal bone pose estimation. Human Movement Science, 16(2-3), 259-274. Chen, C. S., & Chang, W. Y. (2002). Pose estimation for generalized imaging device via solving non-perspective N point problem. Proceedings- IEEE International Conference on Robotics and Automation, , 3 2931-2937.

[3]

[4]

[5] [6] [7] [8] [9] [10]

[11] [12]

[13]

Page 97

[14] [15] [16] [17]

Chen, F., Brown, G. M., & Song, M. (2000). Overview of three-dimensional shape measurement using optical methods. Optical Engineering, 39, 10. Chen, M. (1999). 3-D deformable registration using a statistical atlas with applications in medicine. Carnegie Mellon University). Chen, Y., & Medioni, G. (1992). Object Modeling by Registration of Multiple Range Images. International Journal of Image and Vision Computing, 10(3), pp. 145­ 155. Christy, S., & Horaud, R. (1996). Euclidean shape and motion from multiple perspective views by ane iterations. IEEE Transactions on Pattern Analysis and Machine Intelligence, 18(11), 1098-1104. Cook, J., Chandran, V., Sridharan, S., & Fookes, C. (2004). Face recognition from 3d data using iterative closest point algorithm and gaussian mixture models. 3D Data Processing, Visualization and Transmission, 2004. 3DPVT 2004. Proceedings. 2nd International Symposium on, 502-509. Cropp, A., Palmer, P., & Underwood, C. (2000). Pose estimation of target satellite for proximity operations. Paper Presented at the 14 Th AIAA/USU Conference on Small Satellites, Logan, Utah, 2000. Published in Proceedings of the 14'h Annual AIAA/USU Conference on Small Satellites. Cropp, A., Palmer, P., McLauchlan, P., & Underwood, C. (2000). Estimating pose of known target satellite. Electronics Letters, 36, 1331. Delamarre, Q., & Faugeras, O. (2001). 3D articulated models and multiview tracking with physical forces. Computer Vision and Image Understanding, 81(3), 328-357. Dickinson, S., Pentland, A., & Rosenfeld, A. (1990). Qualitative 3-D shape reconstruction using distributed aspect graphmatching. Computer Vision, 1990. Proceedings, Third International Conference on, 257-262. English, C., Zhu, S., Smith, C., Ruel, S., & Christie, I. (2005). Tridar: A hybrid sensor for exploiting the complimentary nature of triangulation and LIDAR technologies. ISAIRAS 2005'-the 8th International Symposium on Artificial Intelligence, Robotics and Automation in Space. Edited by B. Battrick. ESA SP-603. European Space Agency, 2005. Published on CDROM., p. 79.1, Fdez-Valdivia, J., Garcia, J., & Garcia-Silvente, M. (1996). Simplifying cartographic boundaries by using a normalized measure of ambiguity. Computers and Geosciences, 22(6), 607-623. Feldmar, J., Declerck, J., Malandain, G., & Ayache, N. (1997). Extension of the ICP algorithm to nonrigid intensity-based registration of 3D volumes. Computer Vision and Image Understanding, 66(2), 193-206.

[18]

[19]

[20] [21] [22]

[23]

[24]

[25]

Page 98

[26]

Fiala, M. (2005). ARTag fiducial marker system applied to vision based spacecraft docking. Proceedings of the IEEE 2005 IROS Workshop on Robot Vision for Space Applications, 35. Gelfland, N., Ikemoto, L., Rusinkiewicz, S., & Levoy, M. (2003). Geometrically Stable Sampling for the ICP Algorithm. Proceedings of the 4th International Conference on 3D Digital Imaging and Modeling (3DIM 2003), Stanford CA. Gelfland, N., Mitra, N.J., Guibas, L.J, & Rottmann, H. (2005). Robust Global Registration. Eurographics symp. on Geometry Processing (SGP 2005). Gillett, R., Greenspan, M., Hartman, L., Dupuis, E., & Terzopoulos, D. (2001). Remote operations with supervised autonomy (rosa). Proceedings 6th International Symposium on Artificial Intelligence, Robotics and Automation in Space (ISAIRAS'01), Montreal, Goddard, J. S. (1997). Pose and motion estimation from vision using dual quaternionbased extended kalman filtering University of Tennessee, Knoxville. Goddard, J., Jatko, W., Ferrell, R., & Gleason, S. (1995). Robust pose determination for autonomous docking. ANS Sixth Topical Meeting on Robotics and Remote Systems, 767-774. Godin, G., Laurendeau, D., & Bergevin, R. (2001). A method for the registration of attributed range images. Proceedings of the Third International Conference on 3-d Digital Imaging and Modeling, 179-186. Gold, S., Rangarajan, A., Lu, C. P., Pappu, S., & Mjolsness, E. (1998). New algorithms for 2D and 3D point matching: Pose estimation and correspondence. Pattern Recognition, 31(8), 1019-1031. Granger, S., & Pennec, X. (2002). Multi-scale EM-ICP: A fast and robust approach for surface registration. Lecture Notes in Computer Science, 418-432. Greenspan, M., & Fraser, I. (2003). Tracking a sphere dipole. 16th International Conference on Vision Interface. Greenspan, M., & Jasiobedzki, P. (2002). Pose determination of a free-flying satellite. Motion Tracking and Object Recognition. MTOR02, Las Vegas, USA), , 24-27. Greenspan, M., Shang, L., & Jasiobedzki, P. (2004). Efficient tracking with the bounded hough transform. IEEE Computer Society Conference On Computer Vision And Pattern Recognition, 1 Gu, X., Gortler, S. J., & Cohen, M. F. (1997). Polyhedral geometry and the two-plane parameterization. Eurographics Rendering Workshop 97, 181-192. Hecker, Y., & Bolle, R. (1994). On Geometric Hashing and the Generalized Hough Transform. IEEE Trans. on Systems, Man and Cybernetics, Vol.24.

[27]

[28] [29]

[30] [31]

[32]

[33]

[34] [35] [36] [37]

[38] [39]

Page 99

[40]

Heinzmann, J., & Zelinsky, A. (1998). 3-D facial pose and gaze point estimation using a robust real-time tracking paradigm. Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition, 142-147. Horn, B.K.P. (1987) Closed-Form Solution of Absolute Orientation Using Unit Quaternions. Journal of the Optical Society of America, Vol. 4. Hume, A., "Exact descriptions of regular and Semi-regular polyhedra and their duals", Computing Science Technical Report No. 130, AT&T Bell Laboratories, Murray Hill, 1986. Jarvis, R. (1983). A perspective on range finding techniques for computer vision. IEEE Transactions on Pattern Analysis and Machine Intelligence, 5(2), 122-139. Jasiobedzki, P., Abraham, M., Newhook, P. & Talbot, J. (1999). Model Based Pose Estimation for Autonomous Operations in Space. Proceedings of the IEEE International Conference on Intelligence, Information and Systems. Jasiobedzki, P., Se, S., Bondy, M., Jakola, R., & MDA, S. M. Underwater 3D mapping and pose estimation for ROV operations. ONLINE [http://www.stephense.com/research/papers/oceans08.pdf]. Retrieved March 2nd 2009. Jasiobedzki, P., Se, S., Pan, T., Umasuthan, M., & Greenspan, M. Autonomous satellite rendezvous and docking using lidar and model based vision. Proc. of SPIE Vol, , 5798 55. Jebara, T. S. (1995). 3D pose estimation and normalization for face recognition. (Dissertation, McGill University, 1995). Jensen, B., Weingarten, J., Kolski, S., & Siegwart, R. (2005). Laser range imaging using mobile robots: From pose estimation to 3d-models. Proc.1st Range Imaging Research Day, Zurich, Switzerland, , 129-144. Johnson, A.E. & Herbert, M. (1999). Using Spin Images for Efficient Multiple Model Recognition in Cluttered 3-D Scenes. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol.21, No.5. Jost, T., & Hugli, H. (2002). A multi-resolution scheme ICP algorithm for fast shape registration. First International Symposium on 3D Data Processing Visualization and Transmission, 540-543. Kazhdan, M. M. (2004). Shape representations and algorithms for 3D model retrieval (Dissertation, Princeton University, 2004). Knoop, S., Vacek, S., & Dillmann, R. (2006). Sensor fusion for 3D human body tracking with an articulated 3d body model. Proceedings of the 2006 IEEE International Conference on Robotics and Automation (ICRA), Orlando, Florida.

[41] [42]

[43] [44]

[45]

[46]

[47] [48]

[49]

[50]

[51] [52]

Page 100

[53]

Kollnig, H., & Nagel, H. H. (1997). 3D pose estimation by directly matching polyhedral models to gray value gradients. International Journal of Computer Vision, 23(3), 283302. Leibe, B., Leonardis, A., & Schiele, B. (2004). Combined object categorization and segmentation with an implicit shape model. Workshop on Statistical Learning in Computer Vision, ECCV, 17-32. Lichter, M., & Dubowsky, S. (2004) State, shape, and parameter estimation of space objects from range images. 2004 IEEE International Conference on Robotics and Automation ICRA'04, Proceedings, 3 Liu, Y., & Rodrigues, M. A. (2002). Geometrical analysis of two sets of 3D correspondence data patterns for the registration of free-form shapes. Journal of Intelligent and Robotic Systems, 33(4), 409-436. Lu, F. (1995). Shape registration using optimization for mobile robot navigation. University of Toronto. Lu, X., Colbry, D., & Jain, A. (2004). Three-dimensional model based face recognition. Pattern Recognition, 2004. ICPR 2004. Proceedings of the 17th International Conference on Pattern Recognition. M.D. Shuster, "A Survey of Attitude Representations", Journal of the Astronautical Sciences, Vol. 41, No. 4, October­December 1993. Malassiotis, S., & Strintzis, M. G. (2005). Robust real-time 3D head pose estimation from range data. Pattern Recognition, 38(8), 1153-1165. Mateus, D., Horaud, R., Knossow, D., Cuzzolin, F., & Boyer, E. (2008). Articulated shape matching using laplacian eigenfunctions and unsupervised point registration. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Alaska. McKenna, S., & Gong, S. (1998). Real-time face pose estimation. Real-Time Imaging, 4(5), 333-347. McTavish, D., Okouneva, G. (2007). A New Approach to Geometrical Feature Assessment for ICP-Based Pose Measurement: Continuum Shape Constraint Analysis. Proceedings of the IEEE International Machine Vision and Image Processing Conference (IMVIP 2007), Maynooth, Ire. Meer, P., Mintz, D., Rosenfeld, A., & Kim, D. Y. (1991). Robust regression methods for computer vision: A review. International Journal of Computer Vision, 6(1), 59-70. Moeslund, T. B., & Granum, E. (2000). 3D human pose estimation using 2D-data and an alternative phase space representation. Workshop on Human Modeling, Analysis and Synthesis at CVPR, Hilton Head Island, South Carolina, , 16

[54]

[55]

[56]

[57] [58]

[59] [60] [61]

[62] [63]

[64] [65]

Page 101

[66]

Montgomery, J., Johnson, A., Roumeliotis, S. I., & Matthies, L. (2006). The JPL autonomous helicopter testbed: A platform for planetary exploration technology research and development. Journal of Field Robotics Special Issue on UAVs, Issue 3/4. Mourikis, A. I., Trawny, N., Roumeliotis, S. I., Johnson, A., & Matthies, L. (2007). Vision aided inertial navigation for precise planetary landing: Analysis and experiments. Proc. Robotics Systems and Science Conference. Nahvi, A., & Hollerbach, J.M., (1996). The Noise Amplification Index for Optimal Pose Selection in Robot Calibration", Proceedings of the 1996 IEEE International Conference on Robotics and Automation, Minneapolis MN. Nuchter, A., Surmann, H., Lingemann, K., Hertzberg, J., & Thrun, S. (2004). 6D SLAM with an application in autonomous mine mapping. IEEE International Conference on Robotics and Automation, , 2 1998-2003. O'Mara, D. & Owens, R. (1996) Measuring bilateral symmetry in digital images. In TENCON Digital Signal Processing Applications. IEEE Press. 151-156. Okouneva, G., McTavish, D., Choudhuri, A. & Ignakov, D. (2008). ICP Pose Estimation and Continuum Shape Constraint Analysis. Proc. ASTRO 2008, Montreal, QC, Canada. Preteux, F., & Malciu, M. (1998). Model-based head tracking and 3D pose estimation. Visual Conference on Image Processing, 94-110. Prusak, A., Melnychuk, O., Roth, H., & Schiller, I. (2008). Pose estimation and map building with a time-of-flight-camera for robot navigation. International Journal of Intelligent Systems Technologies and Applications, 5(3), 355-364. Reutebuch, S. E., Andersen, H. E., & McGaughey, R. J. (2005). Light detection and ranging (LIDAR): An emerging tool for multiple resource inventory. Journal of Forestry, 103(6), 286-292. Rodrigues, M., Fisher, R., & Liu, Y. (2002). Introduction: Special issue on registration and fusion of range images. Computer Vision and Image Understanding, 87, 1-7. Rosenhahn, B., & Sommer, G. (2005). Pose estimation in conformal geometric algebra part I: The stratification of mathematical spaces. Journal of Mathematical Imaging and Vision, 22(1), 27-48. Rosenhahn, B., Perwass, C., & Sommer, G. (2005). Pose estimation of 3D free-form contours. International Journal of Computer Vision, 62(3), 267-289. Roumeliotis, S., Johnson, A., & Montgomery, J. (2002). Augmenting inertial navigation with image-based motion estimation. IEEE International Conference on Robotics and Automation, 2002. Proceedings. ICRA'02, , 4

[67]

[68]

[69]

[70] [71]

[72] [73]

[74]

[75] [76]

[77] [78]

Page 102

[79]

Ruel, S., English, C., Anctil, M., & Church, P. (2005). 3DLASSO: Real-time pose estimation from 3D data for autonomous satellite servicing. International Symposium on Artificial Intelligence for Robotics and Automation in Space, Munich, Germany, Ruel, S., English, C., Anctil, M., & Church, P. (2005). 3DLASSO: Real-time pose estimation from 3D data for autonomous satellite servicing. International Symposium on Artificial Intelligence for Robotics and Automation in Space, Munich, Germany, Ruel, S., English, C., Anctil, M., Daly, J., Smith, C., & Zhu, S. (2006). Real-time 3D vision solution for on-orbit autonomous rendezvous and docking. Proceedings of SPIE, , 6220 622009. Ruel, S., English, C., Melo, L., Berube, A., Aikman, D., Deslauriers, A., et al. (2004) Field testing of a 3-D automatic target recognition and pose estimation algorithm. Automatic Target Recognition XIV (Sadjadi, F., Ed.), 5426, 102-111. Rusinkiewicz, S., & Levoy, M. (2001). Efficient variants of the ICP algorithm. Proc. 3DIM, 145-152. Samson, C. English, C., Deslauriers, A., Christie, I., Blais, F., Ferrie, F. (2004) Neptec 3D Laser Camera System: From Space Mission STS-105 to Terrestrial Applications (NRC Report 46565), Canadian Aeronautics and Space Journal, Vol.50, No.2. Samson, C., English, C., Deslauriers, A., Christie, I., & Blais, F. (2002). Imaging and tracking elements of the international space station using a 3D autosynchronized scanner. Proc. SPIE Vol. 4714, 16 Th Int. Symp. on Aerospace/Defence Sensing, Simulation and Controls (AeroSense 2002), 87-96. Scrapper Jr, C., Madhavan, R., & Balakirsky, S. (2008). Performance analysis for stable mobile robot navigation solutions. Unmanned Systems Technology X. Edited by Gerhart, Grant R. Se, S., & Jasiobedzki, P.(2007). Stereo-vision based 3D modeling for unmanned ground vehicles. Proc. of SPIE Vol. 6561 65610-65611. Shahid, K., Okouneva, G. (2007). Intelligent LIDAR Scanning Region Selection for Satellite Pose Estimation. Computer Vision and Image Understanding, Vol.107, 2007. Shang, L., Jasiobedzki, P., & Greenspan, M. (2005). Discrete Pose Space Estimation to Improve ICP Based Tracking. Proc. 5th Int. Conf. on 3D Digital Imaging and Modeling, Washington, DC, USA. Sharf, A., Shamir, A., & Hertzliya, I. C. (2004). Feature-sensitive 3D shape matching. Proc. Computer Graphics International, 596-599. Sigal, L., & Black, M. J. (2006). Measure locally, reason globally: Occlusion-sensitive articulated pose estimation. IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

[80]

[81]

[82]

[83] [84]

[85]

[86]

[87] [88] [89]

[90] [91]

Page 103

[92]

Sim, R., Griffin, M., Shyr, A., & Little, J. J. (2005). Scalable real-time vision-based SLAM for planetary rovers. IEEE IROS Workshop on Robot Vision for Space Applications, 16-21. Simard, L. (2002). Hierarchical pose estimation from range data for space applications. (Dissertation, McGill University, 2002). Simon, D. A., Hebert, M., & Kanade, T. (1993). Real-time 3-D pose estimation using a high-speed range sensor Carnegie Mellon University, The Robotics Institute. Simon, D., O'toole, R., Blackwell, M., Morgan, F., DiGioia, A. M., & Kanade, T. (1995). Accuracy validation in image-guided orthopaedic surgery. Medical Robotics and Computer Assisted Surgery, 19, 185-192. Simon, D.A. (1996). Fast and Accurate Shape-Based Registration. (Doctoral Dissertation, Carnegie Mellon University, 1996). Stockman, G. (1987). Object Recognition and Localization via Pose Clustering, Computer Vision, Graphics, and Image Processing, Vol.40, No.3. Sun, C. & Sherrah, J. (1997) 3d symmetry detection using the extended Gaussian image. IEEE PAMI, 19(2):164­168. Taati, B., & Greenspan, M. Satellite pose acquisition and tracking with variable dimensional local shape descriptors. Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems-Workshop on Robot Vision for Space Application (IROS05 RVSA), 4-9. Taati,B., Greenspan,M. (2005). Satellite Pose Acquisition and Tracking with Variable Dimensional Local Shape Descriptors. IEEE/RSJ IROS Workshop on Robot Vision for Space Applications, Edmonton, Canada , August 2005. Tarel, J. P., Civi, H., & Cooper, D. B. Pose estimation of free-form 3D objects without point matching using algebraic surface models. Proceedings of IEEE Workshop on Model-Based 3D Image Analysis, 13-21. Thomas, F., Ottaviano, E., Ros, L., & Ceccarelli, M. (2005). Performance analysis of a 3-2-1 pose estimation device. IEEE Transactions on Robotics, 21(3), 288-297. Trawny, N., Mourikis, A. I., Roumeliotis, S. I., Johnson, A. E., & Montgomery, J. F. (2007). Vision-aided inertial navigation for pin-point landing using observations of mapped landmarks. Journal of Field Robotics, 24(5), 357-378. Vranic, D. V., Saupe, D., & Richter, J. (2001). Tools for 3D-object retrieval: Karhunenloeve transform and spherical harmonics. IEEE 2001 Workshop Multimedia Signal Processing, 293-298.

[93] [94] [95]

[96] [97] [98] [99]

[100]

[101]

[102] [103]

[104]

Page 104

[105]

Wang, C. C., & Thorpe, C. (2002). Simultaneous localization and mapping with detection and tracking of moving objects. Proceedings- IEEE International Conference on Robotics and Automation, 3 2918-2924. Wang, C. C., & Thorpe, C. (2002). Simultaneous localization and mapping with detection and tracking of moving objects. Proceedings- IEEE International Conference on Robotics and Automation, 3 2918-2924. Wei, Y., Fradet, L., & Tan, T. (2002). Head pose estimation using gabor eigenspace modeling. Proceedings of the IEEE International Conference on Image Processing (ICIP2002, 1 281-284. Woffinden, D. C., & Geller, D. K. (2007). Relative angles-only navigation and pose estimation for autonomous orbital rendezvous. Journal of Guidance Control and Dynamics, 30(5), 1455. Wolfson, H & Rigoutsos, I. (1997). Geometric Hashing: An Overview. IEEE Comp. Sci. and Eng., Vol.4, No.4. Yang, G., Bondy, M., Greenspan, M., Jasiobedzki, P., & Doyon, M. (2004). On-orbit safety monitoring system-development and applications. Proceedings of Romansy 2004, 15th CISM-IFToMM Symposium on Robot Design, Dynamics and Control Zabrodsky, H., Peleg, S. & Avnir, D. (1992). A measure of symmetry based on shape similarity. In Proc. IEEE Conf. Computer Vision and Pattern Recognition, CVPR, pages 703­706, Los Alamitos, California, 15­18 1992. IEEE Press. Zabrodsky, H., Peleg, S. & Avnir, D. (1994). Continuous symmetry for shapes. 2nd Intl. Workshop on Visual Form, 594­613. Zabrodsky, H., Peleg, S. & Avnir, D. (1995). Symmetry as a continuous feature. IEEE PAMI, 17(12):1154­1156. Zhao, H. K., Osher, S., Merriman, B., & Kang, M. (2000). Implicit and non-parametric shape reconstruction from unorganized points using variational level set method. Computer Vision and Image Understanding, 80(3), 295-319. Zuffi, S., Leardini, A., Catani, F., Fantozzi, S., & Cappello, A. (1999). A model-based method for the reconstruction of total knee replacement kinematics. IEEE Transactions on Medical Imaging, 18(10), 981-991.

[106]

[107]

[108]

[109] [110]

[111]

[112] [113] [114]

[115]

Page 105

