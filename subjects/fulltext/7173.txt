DUAL FRONTIERS DATA ENVELOPMENT ANALYSIS: MULTIPLE RANKING APPROACHES FROM OPTIMISTIC AND PESSIMISTIC PERSPECTIVES

By Abdullah Maraee Aldamak

Bachelor in Industrial Engineering, King Fahad University of Petroleum and Minerals (KFUPM), Aldhahran, Saudi Arabia, 2006 Master of Manufacturing Management, University of Windsor, Windsor, Canada, 2009

A dissertation presented to Ryerson University in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Program of Mechanical & Industrial Engineering

Toronto, Ontario, Canada, 2017 © Abdullah Aldamak 2017

Author's Declaration
I hereby declare that I am the sole author of this dissertation. This is a true copy of the dissertation, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this dissertation to other institutions or individuals for the purpose of scholarly research. I further authorize Ryerson University to reproduce this dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research. I understand that my dissertation may be made electronically available to the public.

Abdullah Aldamak

ii

DUAL FRONTIERS DATA ENVELOPMENT ANALYSIS: MULTIPLE RANKING APPROACHES FROM OPTIMISTIC AND PESSIMISTIC PERSPECTIVES Doctor of Philosophy in Mechanical and Industrial Engineering, 2017

Abdullah Aldamak Mechanical and Industrial Engineering Ryerson University, Toronto, Canada

Abstract
The field of data envelopment analysis (DEA) has evolved rapidly since its introduction to decision-making science 40 years ago. DEA has since attracted the attention of many researchers because of its unique characteristic to measure the efficiency of multiple-input and multiple-output decision-making units (DMUs) without assigning prior weight to the input and output, unlike most available decision analysis tools. The body of research has resulted in a huge amount of literature and diverse DEA models with very many different approaches. DEA classifies all units under assessment into two groups: efficient with a 100% efficiency score and inefficient with a less than 100% efficiency score. This ability is considered both a strength and a weakness of the standard DEA model because, although it allows DEA to evaluate the efficiency of any dataset, it lacks the power to rank all DMUs, by giving full efficiency scores to many efficient units. This issue has attracted many researchers to investigate the weak

iii

discrimination power of classical DEA models, resulting in a subfield of research that focuses on DEA ranking. This thesis focuses on the development of the conventional DEA model, and an attempt has been made to study models that are considered as improved models, or approaches that bring a better ranking field, that may bring more accurate evaluation than the original DEA. After studying DEA ranking models, the thesis presents various models under the optimistic and pessimistic DEA ranking approaches. The first and fundamental contribution are the optimistic and pessimistic free disposal hull (FDH) models. In this study, authentic optimistic and pessimistic DEA models without convexity are developed from both input and output orientation. Further into the research investigation, extended models have been proposed, by combining the conventional and FDH ranking models with other different approaches in the literature. Chapter 4 of this thesis presents three extended FDH models: an FDH slack-based model, an FDH superefficiency model, and a dual frontier without infeasibility super-efficiency FDH model. Chapter 5 shows the development of extended models when virtual DMUs are considered. Improved virtual DMU models and improved FDH virtual DMU models are proposed in order to develop the DEA ranking ability from both optimistic and pessimistic approaches. The final model is an optimistic and pessimistic forecasting approach using regression analysis. The forecasting model can be used by decision makers to determine the resources needed for future planning to build an efficient new unit with reference to the current DMU set.

iv

Acknowledgements
Undergoing my PhD at Ryerson University has been a life-changing experience. During my PhD journey I met many people who have supported and encouraged me. I would like to thank those people who made this experience a possible and pleasant one when, at times, I thought it wouldn't even be possible. My first and deepest gratitude goes to the person who accepted me as his student, gave me the opportunity to do this work, and supported me in every step along the way. There are no words that can show my gratitude and appreciation to my supervisor, Prof. Saeed Zolfaghari. His guidance, enthusiasm, high standards, and professionalism helped me to learn how academic research is conducted. His availability and endless support helped me overcome all the challenges I faced during this journey, and to deal with stressful hard times. "Thank you" does not do him justice, but again, thank you, Prof. Saeed. It was an honor working under your supervision. I would also like to extend my gratitude to my PhD defense committee: Prof. Mohamad Jaber, Dr. Sharareh Taghipour, and Dr. Ahmad Ghasempoor, and the external members Dr. Medhat Shehata, and Dr. Walid Abdul-Kader. Their valuable feedback and suggestions during the internal and external defenses contributed immensely to the quality of this thesis. Moreover, I would like to express very special gratitude to Dr. Adel Hatami-Marbini for his valuable feedback and comments on the research work. His knowledge and expertise in the field was crucial to the development of some chapters in this thesis. I sincerely thank you for your great help, and I am also thankful for the academic conferences that gave me a research colleague and a life-lasting friendship. Also, I would like to thank my friend and colleague Dr.Rami Kinsarah for his great support along this research journey. Your support motivated me to pursue more results.

v

Certain people have given me ultimate support and encouragement. Having them in my life is what kept me going. My parents, Maraee Aldamak and Maraym Alhafi, you waited so long for this moment, and I am truly happy to see it approaching so we can celebrate it together. My parentsin-law, Adel Bakhsh and Bareah Sindi, this thesis truly wouldn't be possible without your unlimited support. I am also extremely thankful to my brother and sisters, Khaled, Reem, and Kholood, and all my nieces and nephews. As my family, you were very supportive from all the way back home, and I can't thank you enough. Also, I am very thankful to my second family here in Canada. I am thankful to every M5 member for being always there for me and my family, whenever we needed them. Thanks to this students group, having you abroad eased the struggles of this journey. This second family truly gave me a home away from home, and among them there are a few special ones who showed unconditional support; to them and to Bari and Omar I send my sincere gratitude and very special thanks for what they showed me along this journey. Last but not least, the most important acknowledgment and gratitude goes to my beloved wife, Rawaa Bakhsh. Sincerely, completing my PhD studies could not have been possible without your endless love, continued support, and unlimited care. I am very thankful and forever will be, to you and to our little Temo and to the one on the way.

Abdullah Aldamak
Toronto, September 2017

vi

Dedication
To My two fathers and beloved moms

To My loving wife who supported me all the way, my little Temo, who kept me going, and to my Sidra, who witnessed this from another world and is very soon to join ours

To Ammah "Ruqayah," who celebrated this before she went ­ RIP Ammah

To Our young "Majid," whose laughter will never be forgotten ­ RIP "Majoodi"

vii

Table of Contents
Author's Declaration .................................................................................................................... ii Abstract ......................................................................................................................................... iii Acknowledgements ....................................................................................................................... v Dedication .................................................................................................................................... vii List of Tables ............................................................................................................................... xii List of Figures ............................................................................................................................. xiv List of Acronyms ......................................................................................................................... xv Chapter 1: Introduction ............................................................................................................... 1 1.1. 1.2. 1.3. Background and motivation ................................................................................................. 2 Research overview ............................................................................................................... 4 Dissertation organization ..................................................................................................... 6

Chapter 2: Literature Review ...................................................................................................... 9 2.1. 2.2. 2.3. 2.3.1. 2.3.2. 2.3.3. 2.3.4. 2.3.5. 2.3.6. 2.3.7. 2.3.8. Introduction ........................................................................................................................ 10 Classical DEA model ......................................................................................................... 11 DEA ranking methods review ............................................................................................ 15 Cross-efficiency category ............................................................................................... 18 Super-efficiency category .............................................................................................. 21 Benchmarking category.................................................................................................. 24 Statistics and common weights category ....................................................................... 25 Inefficient DMUs category............................................................................................. 28 MCDM category ............................................................................................................ 29 Inefficient frontier category (Pessimistic frontier) ......................................................... 32 Virtual DMUs category .................................................................................................. 34

viii

2.3.9. 2.3.10. 2.4. 2.5.

DM interference category............................................................................................... 36 Fuzzy approach category ............................................................................................ 38

Discussion and literature contribution ............................................................................... 39 Summary and conclusion ................................................................................................... 46

Chapter 3: New Optimistic and Pessimistic DEA/FDH Models ............................................. 48 3.1. 3.2. 3.3. 3.4. 3.5. 3.6. Introduction ........................................................................................................................ 49 State of the art on pessimistic and optimistic DEA ........................................................... 50 Axiomatic foundation in DEA (optimistic DEA) .............................................................. 57 Pessimistic DEA ................................................................................................................ 61 Optimistic and pessimistic FDH ........................................................................................ 63 Summary and conclusion ................................................................................................... 69

Chapter 4: Improved Optimistic and Pessimistic FDH Models: An Integrated Approach 70 4.1. 4.2. 4.3. 4.4. 4.5. 4.6. Introduction ........................................................................................................................ 71 Slack-based FDH dual frontiers ......................................................................................... 71 Dual super-efficiency models ............................................................................................ 75 Dual super-efficiency FDH models without infeasibility .................................................. 77 Empirical illustration ......................................................................................................... 80 Summary and conclusion ................................................................................................... 91

Chapter 5: Optimistic and Pessimistic DEA Model with Virtual DMUs .............................. 92 5.1. 5.2. 5.2.1. 5.2.2. 5.2.3. 5.3. Introduction ........................................................................................................................ 93 Improved optimistic and pessimistic methods using virtual DMUs .................................. 93 Optimistic model with superstar virtual DMU ............................................................... 93 Pessimistic model with worst virtual DMU ................................................................... 95 Combining optimistic and pessimistic approaches ........................................................ 97 Illustrative example ............................................................................................................ 98 ix

5.4.

Summary and conclusion ................................................................................................. 103

Chapter 6: Optimistic and Pessimistic FDH Model with Virtual DMUs ............................ 104 6.1. 6.2. 6.2.1. 6.2.2. 6.2.3. 6.3. 6.4. Introduction ...................................................................................................................... 105 Improved optimistic and pessimistic FDH models using virtual DMUs ......................... 105 Optimistic and pessimistic FDH (Step1) ...................................................................... 106 Reshaping the FDH frontiers using virtual DMUs (Step2) .......................................... 111 Interval model of optimistic and pessimistic FDH (Step 3) ......................................... 114 Empirical illustration and results comparison.................................................................. 115 Summary and conclusion ................................................................................................. 125

Chapter 7: Estimating Efficiency of Customizable DMUs Using Optimistic and PessimisticVirtual FDH and DEA Models .............................................................................. 127 7.1. 7.2. 7.2.1. 7.2.2. 7.2.3. 7.2.4. 7.3. 7.3.1. 7.3.2. 7.3.3. 7.3.4. 7.4. Introduction ...................................................................................................................... 128 Estimation model using optimistic and pessimistic virtual DEA approach ..................... 128 Regressed optimistic DEA ........................................................................................... 129 Regressed pessimistic DEA ......................................................................................... 131 DEA dual frontiers estimation model........................................................................... 132 Illustrative example for the DEA forcasting model ..................................................... 133 Estimation model using optimistic and pessimistic virtual FDH approach ..................... 135 Regressed optimistic FDH ........................................................................................... 136 Regressed pessimistic FDH .......................................................................................... 138 FDH dual frontiers forecasting model .......................................................................... 139 Illustrative example for the FDH forcasting model ..................................................... 140 Summary and conclusion ................................................................................................. 141

Chapter 8: Summary and Conclusion..................................................................................... 143 8.1. Thesis summary ............................................................................................................... 144

x

8.2. 8.3.

Contribution and main findings ....................................................................................... 146 Directions for future work ............................................................................................... 148

References .................................................................................................................................. 150

xi

List of Tables
Table No.
Table 2.1 Table 2.2 Table 2.3 Table 2.4

Description
Raw data of graduate students evaluation Efficiency scores of graduate students using the CCR model Key applications using DEA ranking methods Features of the main ranking methods, along with their main advantages and disadvantages

Page No.
13 14 16 43

Table 3.1 Table 3.2 Table 4.1

Input and output data for 10 DMUs illustrative example Illustrative example results obtained for dual FDH model Input and output data for 10 DMUs with the results of SB models (4.1) and (4.2)

62 68 74

Table 4.2 Table 4.3

Input and output data of 15 cities (DMUs) Results for the input- and output-oriented FHDs from optimistic and pessimistic viewpoints

81 82

Table 4.4 Table 4.5

Results of the super-efficiency measures Results of the modified super-efficiency measures from the optimistic viewpoint

83 84

xii

Table No.
Table 4.6

Description
Results of the modified super-efficiency measures from the pessimistic viewpoint

Page No.
86

Table 4.7 Table 4.8 Table 5.1 Table 5.2 Table 5.3 Table 6.1 Table 6.2 Table 6.3 Table 6.4

Comparison of the results obtained from the four methods in the literature Spearman's rank correlation Comparison results of the proposed model with CCR and Wang et al. Raw data for bank branches evaluation Comparison results of the proposed model with CCR and Wang et al. Sales associates example ­ data and model comparison Input and output data of 31 DMUs (Wang et al. [157]) Results for the input- and output-oriented dual FDH models Results of the proposed input-oriented model compared with the Wang et al. [157] model

89 90 98 102 102 117 119 120 121

Table 6.5

Results of the proposed output-oriented model compared with the Wang et al. [157] model

123

Table 7.1 Table 7.2 Table 8.1

Comparison results of the proposed DEA forecasting model Comparison results of the proposed FDH forecasting model Comparison of the proposed models with the CCR model

134 141 148

xiii

List of Figures
Figure No.
Figure 1.1 Figure 2.1 Figure 2.2 Figure 3.1 Figure 3.2 Figure 5.1

Description
Thesis organization flow chart Efficiency frontier for the graduate student example Efficiency and inefficiency frontiers Dual DEA frontiers Dual FDH frontier vs CRS frontier New optimistic and pessimistic frontiers for graduate students' example

Page No.
8 14 33 52 63 100

Figure 6.1

Optimistic and pessimistic frontiers in CRS and FDH sales associates' example

110

Figure 6.2 Figure 7.1

New optimistic and pessimistic FDH frontiers Score comparisons of all models with the proposed final model

114 135

xiv

List of Acronyms
Acronym
ADMU AHP AIN AP BCC CC CCR CRS DEA DEA-WEI DM DMU DRS FDH IDEA IDMU IRS MCDM MRA PPS RTS SB SF VRS Analytic Hierarchy Process Data Envelopment Analysis Index Number Anderson and Peterson super-efficiency model Banker, Charnes, and Cooper model (variable return to scale model) Closeness Coefficient Charnes, Cooper, and Rhodes models (first DEA model) Constant Returns to Scale model Data Envelopment Analysis Data Envelopment Analysis Without Explicit Input Decision Maker Decision-Making Unit Decreasing Returns to Scale Free Disposal Hull Inverted Data Envelopment Analysis Ideal Decision-Making Unit Increasing Returns to Scale Multiple Criteria Decision Making Maximum Resonated Appreciative Production Possibilities Set Returns to Scale Slack-Based model Super-Efficiency model Variable Returns to Scale model

Description
Anti-ideal Decision-Making Unit

xv

Chapter 1: Introduction

1.1. Background and motivation
Data envelopment analysis (DEA), a well-known method for measuring efficiency between decision-making units (DMUs), was introduced more than 40 years ago when Charnes et al. [1] presented their so-called CCR model, through which they were able to transform the fractional linear measure of efficiency into a linear programming model. DEA has since attracted the attention of a number of researchers because of its unique ability to measure the efficiency of multiple-input and multiple-output DMUs without assigning prior weight to the input and output, resulting in the proposal of diverse DEA models by different authors. Indeed, empirical applications of DEA are found in many sectors, including education [2], banking [3, 4], manufacturing [5], logistics [6], telecommunication [7], healthcare [8], and even sports [9, 10].

DEA can be used as a decision analysis tool in several areas because it does not focus on finding universal relationships between all the units under assessment in the sample. Rather, DEA allows every unit in the dataset to have its own production function and then it evaluates the efficiency of that single unit by comparing it with the efficiency of the other units in the dataset. More specifically, DEA classifies all units into two groups: efficient with a 100% efficiency score, and inefficient with a less than 100% efficiency score. This classification is considered both a strength and a weakness of the standard DEA model because, although it allows DEA to evaluate the efficiency of any dataset, it lacks the power to rank all units. For instance, in practical applications, decision makers (DMs) are typically not just interested in classifying data into efficient and inefficient; more often, they wish to rank all units under evaluation. In order to overcome this discrimination problem of DEA, a modified approach is required to rank all DMUs under assessment.

2

This problem has been examined extensively by DEA researchers, and a number of ranking methods have been introduced, based on different techniques and approaches. Most of these methods can be considered to provide post-analysis to standard DEA models in order to achieve a better final ranking. However, a subgroup of research papers has focused on developing ranking methods specifically for DEA. Adler et al. [11] reviewed the literature on DEA ranking methods, for example, focused on the development of this research stream between 1986 and 2000.

This dissertation focuses on the development of the conventional DEA models, and an attempt was made to study models that are considered as improved models or approaches that bring better ranking and more accurate evaluation than the original DEA. This development of DEA literature is immense. To get a sense of the literature, Emrouznejad et al. [12] noted in 2008 that the body of DEA published work was nearly 7,000 entities. This number has increased rapidly in later years, for example, searching the sicencedirect.com database shows that the number of entities published in the field of data envelopment analysis is nearly 1,600 entities for each year between 2013 and 2015. Among this huge literature of theoretical articles and empirical studies, there is a subgroup of research work focused on DEA ranking methods. This subgroup of research work has become a vital component to any efficiency assessment process that involves DEA. The essence of ranking methods in decision science and DEA has resulted from the weak ability of the classical DEA model to distinguish among strong but different decision-making units. Most of the time, decision makers require full assessment rather than classifying DMUs to be either efficient or inefficient, and that is considered to be one on the main conventional DEA weaknesses. After identifying the weakness of the conventional DEA ranking method, a study of the literature was carried out, as shown in chapter 2. It was found that the six categories of DEA

3

ranking methods that were long ago introduced into the literature and discussed in the work of Adler et al. [11] are fairly mature and well developed. But while searching all other available methods, four new categories were identified that are still being developed under the topic of DEA ranking methods. These four developing approaches are the "pessimistic DEA frontier," "implying virtual DMUs," "decision-maker imposition," and "fuzzy DEA." Realizing that these four approaches are still under development was the motivation to study them more closely. After doing so, the conclusion was reached that the standard data envelopment analysis (DEA) model usually evaluates decision-making units (DMUs) using the best relative efficiency approach. This approach is known as the optimistic approach, and it is very common that this model returns many units with 100% efficiency scores, making it hard to rank these efficient DMUs. More so, the optimistic approach is biased if it alone is considered, as is shown mathematically later in chapter 3. This biasness in the conventional optimistic approach that is commonly used in DEA ranking methods was the motivation to work to focus the search on avoiding this drawback and focus on the approach that comprehensively incorporates optimistic and pessimistic approaches at the same time. And since the pessimistic approach is still under development, multiple directions are identified that it is believed will make a valuable contribution to the DEA literature at large and to the optimistic and pessimistic DEA literature specifically.

1.2. Research overview
With the first objective of overcoming the weak ability of the classical DEA method in bringing a full distinct ranking evaluation to all DMUs in the dataset, and with a second major objective of bringing unbiased assessment, this dissertation focused on achieving the goal of the first objective through combining optimistic and pessimistic approaches in order to avoid biased 4

evaluation. In other words, the research statement of this dissertation is developing an improved state of the art optimistic and pessimistic DEA framework, in order to achieve a better and unbiased efficiency assessment.

As a starting point, the dissertation studied the available ranking approaches in the literature, and, after close investigation of the literature of optimistic and pessimistic approaches, it brings new directions under the topic of pessimistic and optimistic DEAs. One of the main directions that this thesis contributes to the literature is the development of the free disposal hull (FDH) model in optimistic and mainly pessimistic approaches. Moreover, another direction that improves the results of optimistic and pessimistic approaches is using virtual DMUs in the assessment in order to improve the evaluation results. With these objectives and directions in mind, it is believed that this thesis contributes to the literature a general optimistic and pessimistic framework, based on two models. The first base is the FDH base, and the second base is the virtual DMU base. The research done under this framework led to a variation of models in each direction. For example, the original FDH model under the optimistic and pessimistic framework is useful in real-life scenarios where DEA assumptions need to be relaxed, but, on the other hand, did not show strong discrimination power. This resulted in further investigation to overcome this issue, and brought about three different variations of the model: one slack-based FDH model and one superefficiency FDH model, the latter suffering the problem, in some cases, of infeasibility, which led to the third variation of the super-efficiency model without infeasibility. The main objective of this research work is to overcome the ranking issue of the DEA model when it is applied to any existing data. Right through the body of research, the question has been raised of how the proposed models can serve future or non-existent virtual data. The

5

broadened aim, therefore, is a new model that integrates the previous model with regression analysis to serve the objective of estimation efficiency for future DMUs or customizable ones. The new integrated model is also built under the framework of optimistic and pessimistic approaches.

1.3. Dissertation organization
The following chapter of this thesis discusses the literature of the DEA ranking methods in detail, and presents a comprehensive review of this topic that should benefit any researcher working in this field. After investigating the complete body of the relevant literature, this thesis identified a gap in the field. The present review has recommended that researchers can develop similar ranking models to those discussed in the review for other types of DEA models. This thesis develops an extensive work that incorporates the approach of the seventh category, under the optimistic and pessimistic DEA category, with the DEA-FDH model and the virtual DMUs approach. This development of the research is presented in the remaining chapters of the thesis. Chapter 3 discusses in detail the optimistic and pessimistic approach and shows the development of optimistic and pessimistic FDH models from both input and output perspectives. This model can be considered the main contribution of this research work. As mentioned above, it is believed that this approach has never been investigated before, and that this model not only contributes to the theoretical part of DEA, but opens up new options of application for many empirical studies when the convexity assumption of conventional DEA needs to be relaxed. Chapter 3 can be considered as the foundation of this research, and the following chapters will present various models that can be considered as improved or extended models of the chapter 3 models.

6

Chapter 4 introduces and discusses an essential development of the optimistic and pessimistic FDH models presented in chapter 3. Slack-based model and super-efficiency models are developed and discussed in chapter 4 in detail. Chapters 5 and 6 describe the development of the optimistic and pessimistic models that incorporate virtual DMUs with dual frontier analysis. Two models are presented: one is the virtual DMUs approach with conventional DEA and the other one uses FDH-DEA. Chapter 7 discusses an estimation approach that aggregates the optimistic and pessimistic approach in order to predict future DMUs efficiencies based on past data. Chapter 8 highlights the main findings and possible future work. Figure 1.1 shows the general flow of the proposed work in this thesis. As mentioned in the previous section, the objective of the work presented in this dissertation is to develop a better ranking methodology that leads to better discrimination power. After reviewing the literature, the optimistic and pessimistic approach has been selected to be the general umbrella that all models will be developed under. Under this framework, four different approaches are proposed, with multiple models that lead to better discrimination in DEA, which is the initial goal of this thesis. Three approaches have been considered to achieve the ranking goal. The first approach is the FDH based approach and under that approach three generic models were developed: a basic dual FDH model, an improved dual slack based FDH model, and improved dual super efficiency FDH model. These three models are discussed in chapters 3 and chapter 4 of this thesis. The second approach is the virtual DMUs approach to increase discrimination, and this generic model is discussed in chapter 5. The third approach, which is a combination of the FDH approach and the virtual DMUs approach, is discussed in chapter 6. All these models deal with existing data, so another approach is proposed to serve estimation efficiency for future or virtual customizable data. 7

Figure 1.1 Thesis organization flow chart

8

Chapter 2: Literature Review

9

2.1. Introduction
This chapter aims to shed light on the DEA ranking methods. Existing methods have been reviewed, and, based on this review, the direction of the research has been identified. The following section will discuss the basic DEA model, and will show its weakness in bringing full discrimination assessment. This weakness raised the need in the literature to develop ranking methods. Section 2.3 will discuss all ranking methods in the literature and categorize them into 10 categories. The first category, generally known as the cross-efficiency approach, is the one in which DMUs are self- and peer-evaluated. The second category (Section 2.3.2), known as the super-efficiency approach, is where the DMU under assessment is excluded in order to improve the ranking. This method was first introduced by Andersen and Petersen in 1993 [13]. The third category includes the benchmarking approaches by which DMUs are ranked according to their relative importance to inefficient units. The fourth category describes statistical techniques directly applied after running a DEA model. A small group of papers is discussed in the fifth category, where, unlike other categories, ranking is shifted towards inefficient units instead of efficient ones. The sixth category is a mixed area where multiple criteria decision-making (MCDM) analysis is applied to rank DEA approaches. The seventh category considers the studies where units are ranked according to the inefficient frontier, in contrast to the standard DEA model. The eighth group involves ranking methods that use one or multiple virtual DMUs. The ninth category contains methods where the DM plays a major role in defining the ranking criteria for all DMUs. The last category includes those methods that use fuzzy concepts to rank all units under evaluation. This approach could also be considered as a subgroup of MCDM.

10

After reviewing most of the ranking methods in the literature, a detailed discussion of the review with the major findings will be presented in Section 2.4. Section 2.5 provides the concluding remarks and summary.

2.2. Classical DEA model
The basic efficiency measure utilized in DEA is the ratio of output to input, but this measure is only applicable to cases of a single input and output. In 1957, Farrell [14] implemented this basic concept and developed the efficiency frontier analysis. This analysis requires a group of observations to construct an efficient frontier. All units that lie on the efficient frontier are defined as "efficient units" (i.e., they have a 100% efficiency score), while all those that do not lie on the frontier are defined as "inefficient units." Their locations in relation to the efficient frontier are then used to calculate their efficiency scores. The frontier thus "envelops" the whole data [15]. Figure 2.1 shows a simple example of graduate student efficiency. Twenty years later, Charnes et al. [1] were able to transform the envelopment analysis concept from its graphical form into a linear program that does not restrict the number of inputs or outputs. As mentioned in the introduction, their CCR model measures the efficiency of all DMUs without requiring prior weight for the input and output. The concept of their model relies on assigning virtual weights to inputs and outputs and applies linear programming to ascertain the maximum efficiency of the DMU under assessment, repeating this process for all DMUs. The linear form of the CCR model for any dataset that has n DMUs with s outputs and m inputs is shown below, where maximizing the weighted sum of the output is the objective function, as follows [1]:

11

Max  = 1 1 + 2 2 + ... +   Subject to: 1 1 + 2 2 + ... +   = 1 1 1 + 2 2 + ... +    1 1 + 2 2 + ... +   ( = 1 ... , ) 1 , 2 , ... ,   0 1 , 2 , ... ,   0 (2.1)

For any DMUk, the DMU is considered efficient if k which is the efficiency score for that DMUk reaches a value of 1 [16]. The u's and the v's are the variables in the CCR models and mostly in all DEA models. The u's are defined as the virtual weights assigned to each output in the data, while the v's are defined as the virtual weights assigned to each input in the data. The x's represent the value of the input and the y's represent the values of the output for each associated DMU. In order to illustrate the above formulations, the following example is considered, where the aim is to evaluate seven graduate students based on their GPA scores (first output) and number of publications (second output). By assuming that all students share the same level of study and have an equal level of learning opportunities, their inputs are considered to be equal (with a score of 1). The raw data of the example is shown in Table 2.1.

12

Table 2.1 Raw data of graduate students evaluation
Input Student A B C D E F G
a

Outputs GPA 60 80 90 95 70 95 75 Publications 6 3 4 1 2 3 1

Unitya 1 1 1 1 1 1 1

Unity score is given to the input in order to keep the data within two dimensions and thus illustrate the example graphically by using the efficiency frontier analysis and CCR model.

To clarify and explain the previously mentioned formulations, the CCR model is formulated for student A in order to compute his/her efficiency score A as follows: Max.  = 60 1 + 6 2 Subject to: 1 1 = 1 60 1 + 6 2 - 1 1  0 80 1 + 3 2 - 1 1  0 90 1 + 4 2 - 1 1  0 95 1 + 1 2 - 1 1  0 70 1 + 2 2 - 1 1  0 95 1 + 3 2 - 1 1  0 75 1 + 1 2 - 1 1  0 1  0 1 , 2  0

13

Solving the above linear program would only lead to the efficiency score of student A. For simplicity we have assumed a unified input value to all graduate students, and that led to having trivial constraint where the input value 1 multiplied by v1 equal to 1, which means the virtual weights assigned to all DMUs input will always be equal to 1. Similar linear programs should therefore be constructed seven times. The overall results of all DMUs are shown in Table 2.2. Since this example has only two changing variables (i.e., GPA and publications), an efficiency frontier analysis could be obtained graphically as well, as shown in Figure 2.1.

Table 2.2 Efficiency scores of graduate students using the CCR model
DMU A B C D E F G Efficiency Score 1.00 0.86 1.00 1.00 0.74 1.00 0.79 Rank 1 5 1 1 7 1 6

Figure 2.1 Efficiency frontier for the graduate student example

The efficient DMUs can be easily observed from the results of the CCR model in Table 2.2 and the graph in Figure 2.1. Students A, C, D, and F achieve a 100% efficiency score, and all of these are located on the efficient frontier. However, it is clear that this evaluation lacks accuracy, since four out of seven students are classified as efficient with similar efficiency scores, implying

14

that the DM would not be able to rank more than half of the DMUs in this example, and that performance demonstrates the lack of discrimination power of the conventional CCR DEA model. Importantly, this thesis only focuses on the ranking methods of DEA, rather than alternative standard DEA models. Since the CCR model proposed in 1987, many models have been formulated as extensions or modifications. For example, Banker et al. [17] created the widely used BCC model that applies a variable returns to scale. Further, the multiplicative model was developed by Charnes et al. [18], the additive model by Charnes et al. [19], and slack-based models by Tone [20]. While all these alternative models are widely applied in DEA (see [21] for more details on their features and applications), some can resolve the ranking issue to a certain extent, whereas others, such as the BCC model, worsen the ranking situation. These differing outcomes have led to a recent increase in the focus on developing more accurate ranking methods, as described in the next section.

2.3. DEA ranking methods review
This review aims to shed light on major ranking methods that have been introduced to the DEA literature. The development of this area has grown a great deal since Adler et al. [11] reviewed ranking methods in 2002. Many methods have been introduced to the literature after 2002, and this thesis attempts to fill the gap in the literature and introduce an updated survey or literature review. This review discusses DEA ranking approaches and elaborates on new developed methodologies and models in each category that Adler et al. [11] discussed in 2002. Moreover, it brings four more categories that have matured over the past 14 years, and it is believed that special attention has to be paid to such development in the literature. All 10 categories will be discussed in detail in the following subsections.

15

This development of ranking methods has resulted in many ranking applications and empirical studies in the literature. Table 2.3 shows examples of real-world applications for each category discussed in this thesis.

Table 2.3 Key applications using DEA ranking methods
Category Reference Zerafat Angiz et al. [22] Application Area Banking Inputs Rent, full-time equivalent personnel, supplies Outputs Loan, accounts, bonds sold, deposits

Cross-efficiency Jahanshahloo et al. [23] Falagario et al. [24] Networking problem Supplier selection Factory location, cost of creating factory Price, execution time Finance, number of products Post-delivery maintenance, enhancement plans A. Esmaeilzadeh, A. Hadi-Vencheh [59] Super-efficiency Sueyoshi [25] Agriculture Cable TV service Operating cost, manpower Credit, insurance, purchasing, marketing, management activities, other operating costs Torgersen et al. [26] Human resources Total number of hours worked per week in each office Benchmarking handled, number of cases handled and closed Total number of cases handled and followed up, number of cases Revenue, viewer Unified

16

Friedman and Sinuany-Stern [27]

Academia

Department operation cost, faculty salaries

Grant money, number of publications, number of grad students,

Statistics

number of credit hours in the department Wang et al. [28] Manufacturing Operating cost, floor space Qualitative benefits, WIP, average number of jobs, average yields Jablonsky [29] Pension funds Number of customers, total assets, equity capital, total cost Appreciation of customer deposits, average appreciation of the last three years, net profit Wu et al. [30] Education Multiple aspects in : teaching resources, internationalization, extension education service, discipline and guidance , general education Wang et al. [31] Industrial Original value of fixed assets, current Gross industrial output value Multiple aspects in : faculty, teaching, research

MCDM

Inefficient frontier assets, number of staff and workers Azizi and Wang [32] Virtual DMU Sports ­ Olympic Games Gross domestic product, total population of the country or area Number of gold medals won, number of silver medals won,

17

number of bronze medals won by each country Ramón et al. [33] Sports ­ tennis players' DM interference performance Unified Percentage of 1st serve points won, percentage of 2nd serve points won... etc (7 Outputs were included) Zerafat Angiz et al. [34] Fuzzy ranking Banking Rent, full-time equivalent personnel, supplies Loan applications, new pass-book loans, life insurance sales, new accounts, closed accounts, travelers checks sold, bonds sold, bonds redeemed

2.3.1. Cross-efficiency category Cross-efficiency methods are based on the simple concept of peer evaluation alongside selfevaluation, which means that the efficiency of each DMU is calculated n times with reference to the other DMUs in the dataset. This results in an (nn) cross-efficiency matrix, with the diagonal elements of this matrix representing the self-efficiency scores obtained by directly implementing the CCR model.

18

Sexton et al. [35] introduced the concept of cross-efficiency and proposed that averaged peer evaluation and self-efficiency should be taken into consideration in order to accurately measure the efficiency score. The cross-efficiency approach is considered one of the most reliable ranking methods because it avoids bias in the self-evaluation. Doyle and Green [36] extended this technique by proposing aggressive and benevolent approaches to cross-efficiency and successfully developing a maverick index that combines the concepts of peer evaluation and self-evaluation as follows [36]:  =  -   (2.2)

where Ekk is the self-efficiency score and ek the cross-efficiency score. Thus, the higher the maverick index for DMUk, the more likely it is that this DMU has a doubtable self-evaluation score. In 2011, Jahanshahloo et al. [23] introduced an extended method to calculate the final efficiency score by using a technique for order preference according to the similarity to the ideal solution known as TOPSIS. A six-step procedure is applied to determine the final ranking of each DMU, based on its distance from the ideal and negative-ideal solutions. Zerafat Angiz et al. [22] developed another new approach that focuses on only ranking DMUs. By applying the cross-ranking matrix to the cross-efficiency matrix, they directly obtain a ranking order for all DMUs, rather than evaluating each DMU by taking the average score of the matrix. However, the major shortcoming of this method is its negligence of the actual score efficiency, even though it ultimately reflects an accurate ranking order. Another post-crossefficiency analysis was proposed in 2011 by Örkcü, and Bal [37]. Their method improves accuracy by using goal programming techniques after obtaining the optimal weight through the crossefficiency matrix.

19

In general, it can be concluded that the cross-efficiency approach has received high accreditation in the literature in terms of its influence on DEA ranking. Nevertheless, many of the developed models that use this approach are considered model extensions. For example, Guo and Wu [38] presented a model that restricts undesirable outputs by using a "maximal balanced index" with optimal shadow prices. Similarly, the model to improve cross-efficiency presented by Ramón et al. [39] prevents DMUs with zero weights in their profiles and eliminates certain inefficient DMUs from the cross-efficiency matrix in order to improve the accuracy of the final optimum weights. Recently, Oral et al. [40] introduced a maximum resonated appreciative (MRA) model in which, instead of letting each DMU depreciate other DMUs in the dataset, each DMU would rank the other DMUs in an appreciative way. The main contribution of the MRA model is that it integrates the voices of the DMUs under assessment, while avoiding aggregation. The crossefficiency method is widely applied in the literature, and, since its introduction, the method has received and is still receiving high research attention. Many alternative models that deal with certain cases have been developed. Wu et al. [41] proposed an interesting model that improves the results of cross-efficiency when it is not pareto optimal. Another model that deals with data that includes undesirable outputs is proposed by Liu et al. [42]. In general, this subsection concludes by saying that cross-efficiency evaluation has been used in various applications, e.g., efficiency evaluations of nursing homes, Sexton et al. [35]; R&D project selection, Oral et al. [43]; preference voting, Green et al. [44]; and others. However, as noted in Doyle and Green [36], the non-uniqueness of the DEA optimal weights/multipliers possibly reduces the usefulness of cross-efficiency. Specifically, cross-efficiency scores obtained from the original DEA are generally not unique, and depend on which of the alternate optimal solutions to the DEA linear programs is used. Moreover, the cross-efficiency method does not help the DM to

20

critically optimize the optimal weights during the evaluation. Further discussion on the pros and cons of cross-efficiency can be found in Zhu [45].

2.3.2. Super-efficiency category Andersen and Petersen [13], the originators of the super-efficiency (SF) method, adjusted the CCR model by excluding the DMU being tested from the set of constraints, which allows any efficient DMU to achieve a score greater than 1. The new model thus becomes [13]: Max  = 1 1 + 2 2 + ... +   Subject to: 1 1 + 2 2 + ... +   = 1 1 1 + 2 2 + ... +    1 1 + 2 2 + ... +   ( = 1 ... ,  &   ) 1 , 2 , ... ,   0 1 , 2 , ... ,   0 Similar to the CCR model, the efficiency score is represented by k and the x's and the y's represent values of the inputs and the outputs respectively associated for each DMU. The u's and the v's are the variables in the SF model. The u's are defined as the virtual weights assigned to each output in the data, while the v's are defined as the virtual weights assigned to each input in the data. The main difference in the SF model is in the constraints set, where    for any DMUk under assessment to allow its efficiency score to reach a higher value than 1. The super-efficiency model measures the distance between efficient units and the frontier after excluding it, which means the most efficient unit is the one that can reduce its outputs without (2.3)

21

becoming inefficient. Having the ability to obtain efficiency scores greater than 1 allowed Andersen and Petersen [13] to overcome the common shortcoming of the CCR model, namely, its inability to rank efficient DMUs when they all obtain a unity score. However, the super-efficiency model allows specialized units to achieve a very high score, a limitation that Sueyoshi [25] addressed by introducing the DEA adjusted index number (AIN) into the model. The benefit of the AIN is that it extends the efficiency score of efficient DMUs to a range between 100% and 200%, while the inefficient units' scores are measured in the range of 0 to 100%. In this model, the 100% score serves as a benchmarking point for the evaluation. Model (2.4) shows the AIN formula [25]:
   -   }  -      

 = 1 + {

(2.4)

Another major drawback of the super-efficiency model is its tendency to return infeasible results. This issue was addressed by Thrall [46] in 1996 and later by Cooper, Seiford, and Zhu [16], who discussed the conditions under which infeasibility might occur. Chen [48] also studied this tendency and found that when super-efficiency is returned with infeasible results, that means it was the highest super-efficiency to that DMU because there is no upper bound for the score. Chen [48] thus proposed a new method that requires using both the input-oriented and the output-oriented super-efficiency models to describe the type of infeasibility when it occurs. In his model, he described the infeasibility results as either very high unlimited efficiency or as an input-saving or output surplus for that DMU which returned an infeasible result. Cook et al. [49] proposed a modified super-efficiency model in which a super-efficiency score for efficient DMUs can be obtained even when feasible solutions do not exist. Moreover, their model returns efficiency scores similar to the original ones when feasibility is not considered an

22

issue. Their model is also able to switch all extreme points that cause infeasibility into non-extreme projections by making only a few minor changes to the original super-efficiency model in terms of the virtual weights variables. The infeasibility problem has encouraged many researchers to modify the super-efficiency model, such as the works presented by Amirteimoori et al. [50], Jahanshahloo et al. [51], Gholam Abri et al. [52], Du and Chen [53], and Pourmahmoud et al. [54]. Another model that has received good attention in the literature is the MAJ model that was developed by Mahriban et al. [55]. This model overcomes the infeasibility issue of the Anderson and Peterson [13] model plus the sensitivity of their model to small variations in data when the DMUs have smaller values as inputs or outputs. In the papers referred to [51, 56, 57], Jahanshahloo et al. proposed some different models as alternative developed versions of the MAJ and AP models. With a similar goal of overcoming the infeasibility of the super-efficiency model, Aldamak et al. [58] proposed a different method of calculating efficiency when the convexity assumption is relaxed by using the free disposal hull (FDH) approach. Another approach to enhance the superefficiency model is the work of Esmaeilzadeh, and Hadi-Vencheh [59], where a two-stage model is proposed in order to reduce the computational complexity and achieve better ranking. This body of research, suggests that despite the shortcomings of the super-efficiency method, it is commonly used in DEA applications, especially for detecting outliers. Scholars debate as to what extent the super-efficiency method should be used in data ranking, but it has been proved through simulation experiments by Banker and Chang [60] that the super-efficiency approach returns unsatisfactory results when it is used for measuring the efficiency scores of units under assessment.

23

2.3.3. Benchmarking category The benchmarking method examines the ranking importance of efficient units compared with inefficient ones; in other words, it assesses how frequent efficient units are used as a reference to inefficient units. In this category, Torgersen et al. [26] proposed a two-phase method through which DMs can benchmark efficient units according to their level of importance. First, the model applies the additive model to identify the slack value for all efficient units. For instance, let  = {  | = 0} where V is defined as the set of all efficient units that have slack values equal to zero. After identifying V in the second phase, the following model is applied to all DMUs [26]: 1 =   2 Subject to:    -   = 
   -    =   

(2.5)

  = 1
   ,  ,   0 and    ,    ,    

Similar to previous models,  represents the efficiency score and the x's and the y's represent the values of the inputs and the outputs respectively associated for each DMU. The radial measure E2i in this model is obtained by solving the above model, and the outcome shows the ratio of the maximum output when maintaining the same amount of inputs. Sinuany-Stern et al. [61] also applied the benchmarking concept, but in a different way. Their simple method involves ranking

24

efficient DMUs based on how frequently they are used to refer to inefficient DMUs. However, this method lacks accuracy, since different DMUs often obtain the same rank. Another benchmarking method, this time introduced by Jahanshahloo et al. [62], is based on changing the reference dataset by removing the efficient DMU and measuring how it affects both the frontier line and inefficient units. This method is applied in two stages. First, the DEA model is run in order to identify efficient and inefficient DMUs. Second, the scores of inefficient units are recalculated after excluding one of the efficient DMUs, and so on. So, the more the DMU influences the score of inefficient units, the stronger it is. The new rank of efficient units is then calculated by applying the following formula [62]:  =  ,  (2.6)

where b is the evaluated efficient DMU, jn is the set of inefficient units, and  is its number. Because this method eliminates the efficiency of the unit, it improves the accuracy of the ranking. In 2009, Lu and Lo [63] introduced a different approach, termed the "interactive benchmarking model." They proposed fixing one unit as the benchmark and pairing all other DMUs with it. According to this method, the efficiency score is then calculated with reference to the fixed unit. The process is repeated until all DMUs in the dataset serve as the fixed unit, and the final score of each DMU is computed by averaging all scores associated with that DMU.

2.3.4. Statistics and common weights category Traditional statistical approaches cannot be applied directly to DEA because of the differences in the characteristics of the data used for carrying out each method. While DEA tests 25

frontier efficiency or the frontier line according to the optimized summation of weighted outputs to the summation of the weighted inputs, classical statistics are directed to examining the average tendencies of the data. Nevertheless, some approaches combine these two methods by using statistics to better rank DEA-efficient and DEA-inefficient DMUs. For instance, Friedman and Sinuany-Stern [27] utilized canonical correlation analysis (CCA) in order to rank the DEA results on a predetermined scale, and fitted a different vector of weight so that every DMU achieved through DEA into one set of weights was determined by the CCA. By using the CCA method, they defined a new scaling ratio T as [27]:    =1    = =  =1    (2.7)

where W is the linear combination of the outputs and Z is the linear combination of the inputs. By obtaining T, their method proposed utilizing the largest eigenvalue of the CCA and applying it to the DEA results. The same authors [64] proposed another multi-stage approach that also utilizes a statistical methodology to discriminate optimal efficient and inefficient units. In the first stage, the results of the DEA model are classified into efficient and inefficient groups. In the second stage, the discriminant analysis of ratios is applied to these two groups in order to obtain the common input and output weights. In the third stage, a new efficiency score is generated for each DMU, based on the composite ratio of outputs to that of inputs. Similar to the CCR model, the x's and the y's represent values of the inputs and the outputs respectively associated for each DMU. The U's are

26

defined as the virtual weights assigned to each output in the data, while the V's are defined as the virtual weights assigned to each input in the data [64]:  =  =1    = 1, ... ,   =1   (2.8)

Accordingly, the unit that has the highest score is ranked as 1, and the lowest score receives the rank n. The main advantage of this approach is that it ranks both efficient and inefficient DMUs; moreover, this scale can also be validated by using non-parametric statistical tests. The idea of finding common weights and applying them to the results of the DEA analysis for each DMU has attracted many researchers since the release of the complicated models of Friedman and Sinuany-Stern [27]. Hashimoto and Wu [65], for instance, developed an approach that combines the DEA results, and compromises in order to achieve a common weight applicable to all DMUs. Similarly, Kao [66] developed a different approach by using the same tool, while Liu and Hsuan Peng [67] proposed a slightly different method that only aimed to rank efficient DMUs, but they also applied the common weight that best supports the optimization of group efficiency. Recently, Wang et al. [28] criticized most existing methods for being too complicated, hard to apply, or resulting in infeasible solutions. They proposed a new approach based on regression analysis in order to seek a set of common weights for ranking DMU efficiency. Their method aims to minimize the fitting error by computing the most favorable weights for each DMU. The model works by minimizing the error between targeted efficiency j* (j=1,..., n) and actual DEA efficiency j. It is hence most desirable that the subtraction of one efficiency from the other equals zero. The proposed model is as follows [28]:
   =  =1 { -  =1    =1   2

}

(2.9)

27

  0 ,  = 1, ... ,  Subject to: {    0 ,  = 1, ... ,  In some cases, researchers proposed a ranking method without changing the original DEA model. For example, Alirzaee and Afshairan [68] proposed a post-analysis method that only used the balance index as a tool to reach a complete ranking. A modified version of their model is introduced later to the literature by Wu et al. [69], where the maximal balance index is used instead. Another approach that is also considered as a post-analysis model is the model of Saati et al. [70]. In this model they introduced a two-step model using ideal DMU and, based on that, a new set of weights would be determined by the decision maker for the evaluation in the second step. The reliance on decision-maker judgment has been considered as a criticism by some researchers of the methods of this category, while, of course, it is debated by other scholars, who praise this characteristic. Lotfi et al. [71] proposed a different model that assures consistency and equitable weights allocation. With a similar goal of minimizing computational complexity, Hatami-Marbini et al. [72] introduced a new DEA model that calculates the reduced amount of input and output for each DMU in order to improve the efficiency evaluation of all DMUs.

2.3.5. Inefficient DMUs category Most existing methods do not attempt to rank inefficient DMUs because the standard DEA score for inefficient units is sufficient for ordering them according to their individual scores. For example, Bardhan et al. [73] addressed this issue by introducing a method of ranking inefficient DMUs. Specifically, they ranked DMUs based on the so-called measure of efficiency dominancy, where DMU values depend on their input and output values. This flexible model can then be applied

28

to rank inefficient DMUs alongside efficient ones by using the so-called measure of inefficiency dominance, which is computed for DMU0 based on the following equation [73]: 01-
+ -   =1  / =1  /  +  +

(2.10) 1

It is important to mention that some such methods have suggested reversing the efficiency frontier in order to use the inefficient frontier to rank DMUs. These methods can thus be used to rank inefficient DMUs, as discussed in Section 3.2.7.

2.3.6. MCDM category The models presented in the previous sections are generally considered to be single-level models that deal with single-level situations. However, a subgroup of DEA-related papers has focused on applying this analytical technique to situations that require multiple levels such as networking and supply chain assessment [74]. This subfield of the literature has used MCDM to develop DEA models that are applicable in multiple-level situations, including research works that have applied the MCDM concept in order to better rank DMUs in DEA standard models. Cook and Kress [75] described how DEA could be used to aggregate preferential votes. They argued that this problem could be conceptualized as one of maximizing the intensity of votes, given the ordinal nature of placements 1 to n, and offered an algorithm for aggregating votes fairly. The same authors later proposed a more generalized version of this DEA ranking approach [76], arguing that DEA is the optimal way in which to determine maximum ranking positions, given ordinal rank positions and weights. These two articles by Cook and Kress [75, 76] thus put forward a strong case for using DEA as a specific approach to MCDM when dealing with ordinal data.

29

Nonetheless, these two papers did not examine how to represent ordinal data when employing DEA models for MCDM. This problem was addressed, rather, in the work of Cook et al. [77], who presented a means of imposing both upper and lower bounds on the worth vectors of ranking positions, giving rise to a cone ratio DEA model that can be used whenever ordinal data are modeled. However, as Cook et al. [49] conceded, "Issues involving multiple ordinal factors and the relative importance and/or fuzziness aspects pertaining to such factors" are not addressed in the cone ratio DEA model. Given that real-world business problems typically involve more than one ordinal factor, in addition to some fuzziness around the relative importance of such factors, the early DEA work presented by Cook and colleagues [49] remains of limited value for overcoming the complex operational DEA-related problems that businesses often face. That aside, this research work laid the foundation for applying MCDM to DEA. In 1995, Troutt [78] used these approaches to suggest a means of estimating a parameter vector for x activities to be ranked, ordinarily based on expert estimates. According to Troutt's approach, the search for a mathematically ideal point of maximization or minimization in the DEA model is replaced by a means of optimizing expert estimates. One of the advantages of this method is that it takes advantage of human knowledge in operational contexts. Cook et al. [79] also addressed some of the problems they themselves had earlier identified by proposing a model in which DEA could be applied to both ranked and non-ranked ordinal data and in which the selection of a lower bound on factors was optimized, thereby updating the DEA model to be more useful in operational environments characterized by qualitative information. In 1997, Li and Reeves [80] extended this research stream further still in order to render the DEA model useful in complex environments. These authors explained that the weight distribution problem (i.e., that such distributions do not reflect real-life operating conditions) alone was enough

30

to render many DEA-based forms of MCDM useless in real-world settings, given that DEA models often over- or underestimate DMUs, based on their weights in single outputs or inputs. Li and Reeves [80] thus presented a new DEA model designed to address these shortcomings and tested it against numerous datasets in order to illustrate its superiority compared with past DEA models. Similarly, in the model proposed by Sinuany-Stern et al. [81], the weights of both inputs and outputs could be calculated more precisely without leading to unrealistic weight distributions. The work of Sinuany-Stern et al. [81] on DEA models in 2000 was carried out by using the analytic hierarchy process (AHP) approach, which was further developed by Jablonsky [29], who demonstrated that this approach could complement the use of DEA in MCDM. Jablonsky [29] concluded that the analytic hierarchy process approach is superior to DEA in a number of aspects, including the utilization of categorical inputs and sensitivity analysis, and that the only drawbacks are the greater time spent preparing pairwise comparison matrixes and carrying out the optimization. Despite Jablonsky's conclusion, however, DEA has remained a popular form of MCDM, with even Jablonsky's later work emphasizing the ongoing usefulness of DEA models [82]. A comprehensive case study of AHP on ranking universities is presented in the work of Wu et al. [30]. In the same vein, an improved three-stage ranking method that used the weighted sum approach was introduced by Lotfi et al. [83]. In the first stage, these authors ranked all DMUs based on an optimistic/pessimistic classification. Based on these ranking results, a secondary goal was defined and an average rank obtained. Finally, in the third stage, they applied the MCDM approach in order to ascertain a group rank by using the weighted sum method. Another approach that used Cook and Kress's work [75] as a foundation is developed by Toloo et al. [84], by which they switch the association rule of efficiency by considering only the output data of efficient DMUs. Similar

31

concepts have been applied by Ramón et al [39]. In summary, although the practical application of most of the proposed methods in the MCDM category is complicated, in certain situations such as a supply chain analysis, MCDM may be the only method that is able to solve multiple-level data.

2.3.7. Inefficient frontier category (Pessimistic frontier) Yamada et al. [85] were the first authors to propose a pessimistic way in which to evaluate DMUs, which they termed inverted DEA (IDEA). The concept of IDEA is to invert the CCR model and optimize the maximum input-to-output ratio. The proposed model is as follows [85]: Max  = 1 1 + 2 2 + ... +   Subject to: 1 1 + 2 2 +  +   = 1 1 1 + 2 2 +  +   - 1 1 + 2 2 +  +    0 ( = 1 ... , ) 1 , 2 , ... ,   0 1 , 2 , ... ,   0 Similar to previous models,  represents the efficiency score, and the x's and the y's represent the values of the inputs and the outputs respectively associated for each DMU, while the u's are defined as the virtual weights assigned to each output in the data, while the v's are defined as the virtual weights assigned to each input in the data. (2.11)

IDEA creates an inefficient frontier by which any unit not located on the frontier is considered efficient, and efficiency scores are assigned accordingly. Entani et al. [86] tested this proposition by using the standard DEA model and found an interesting shortcoming when applying 32

both DEA and IDEA, namely, that in any dataset, while there are two efficient DMUs under DEA, they are inefficient under IDEA, as shown in Figure 2.2.

Figure 2.2 Efficiency and inefficiency frontiers

Figure 2.2 can be considered as the foundation of all the models presented in this thesis, because it shows the biasness of a single frontier when it is applied alone to the evaluation. This problem led Entani et al. [86] to develop a new model with interval efficiency that consists of optimistic DEA and pessimistic IDEA viewpoints, which, combined, can calculate a better interval efficiency and thus a superior ranking approach. Further, Jahanshahloo and Afzalinejad [88] introduced a method that compared all DMUs against a fully inefficient frontier. Because this method excels in highlighting the worst performers, its use is recommended in critical situations where fully inefficient units are the main research targets. In 2007, Wang et al. [31] supported the findings of Entani et al. [86] and concluded that using only the pessimistic or the optimistic method in any approach leads to biased results, suggesting that both approaches should always be considered together. Their proposed approach consists of three main steps: first, calculate the efficiency score of each DMU by using the optimistic 33

approach (CCR model); second, calculate the efficiency score of each DMU by using the pessimistic approach; and third, take the geometric average of both scores to use as the final value for ranking purposes, which thus improves the discrimination power of the model. Building on the same argument, Azizi [87] introduced a model that uses both pessimistic and optimistic points of view to calculate interval efficiency, instead of taking the average of the scores. The advantage of Azizi's model over that of Wang et al. [31] is that this interval model is able to identify inefficient units as well. With a similar methodology of using optimistic and pessimistic approaches, Aldamak et al. [58] proposed a detailed study on using dual frontiers without convexity. In this paper, the optimistic and pessimistic frontiers transform to "staircase" shapes caused by applying the FDH model to both perspectives. This model can be practical for analysts when the convexity assumption of DEA models needs to be relaxed, especially in the elimination process.

2.3.8. Virtual DMUs category Introducing a virtual DMU is a new technique in the DEA literature that still requires further research in order to confirm the validity and flexibility of these proposed models. Wang and Luo [89] first introduced this concept in 2006 when they proposed two alternative DMUs, namely, an ideal decision-making unit (IDMU) and an anti-ideal decision-making unit (ADMU). The IDMU approach uses the lowest input in the data and assumes the maximum output, whereas an ADMU is a DMU that uses the maximum input to produce the minimum output of data. The method proposes that DEA be applied twice for both approaches and that the scores of both models be recorded in addition to the scores from the original DEA model. Indeed, Wang and Luo [89] claimed that accurate results could be derived by combining both measurements using the relative closeness method. They suggested the following index for ranking all DMUs [89]: 34

 =

   -     ( -  ) - (  -  )

(2.12)

where j* and *ADMU are the worst possible scores from DMUj and ADMU, respectively, and j* and *IDMU are the best possible scores from DMUj and IDMU, respectively. This method thus allows researchers to distinguish between DMUs according to their overall performance. Wang and Yang [90] also introduced a method similar to that presented by Entani et al. [86], based on the concept of virtual ADMUs. These authors measured the efficiency of all DMUs by calculating the worst and best performance of each DMU and computing the intervals that determined their efficiencies. They then used the Hurwicz criterion approach to rank each DMU, based on these interval values. This model is referred to as a bounded DEA model because the efficiency of the DMU in question is bounded between upper and lower bounds, which are then combined to determine the efficiencies. However, Azizi and Wang [32] proved that the Wang and Yang model is not capable of processing data with zero value in the output. Accordingly, an enhanced bounded model is developed in their research paper. Similar to Yang and Wang [90], Zheng [91] also introduced virtual IDMUs and ADMUs to a model in which ranking is computed by taking the square root of the score of each DMU with the best virtual DMU, multiplied by the score of that DMU with the worst virtual DMU. The virtual DMU category might also be considered as the most flexible of all the methods examined in this thesis, owing to its many variations, based on the ability to change the number and features of those virtual DMUs introduced to the data. For example, Sun [92] proposed two virtual DMUs and a common weight vector in order to rank the remaining units in the data, while Shetty and Pakkala's [93] method combined the virtual DMU approach with benchmarking. This method

35

is simpler and more accurate because it only measures efficiency scores based on one virtual DMU. Specifically, the inputs and outputs of that DMU are calculated by averaging all the other inputs and outputs to produce an inefficient DMU (as long as there is at least one in the original dataset). The procedure starts by running the new dataset after deleting one efficient unit at a time and observing the resulting effect on the virtual DMU. Efficient units are then ranked according to how they influence the efficiency score of the virtual DMU. Based on the same concept introduced in the previous section by Wang and Chen [31], Aldamak and Zolfaghari [94] assessed that a direct use of the pessimistic approach would result in biased treatment of the data. So, a new method is proposed using a DEA index number with the pessimistic approach, with an introduction to IDMU and ADMU to the data in order to generate a higher envelopment level and produce better discrimination between units under assessment.

2.3.9. DM interference category In this category, the DM "interferes" in the measurement of the efficiencies of the data under assessment, which could vary, according to the nature of the problem and the DM's preferences. In this category, Wang et al. [95] proposed a model that allows the DM to impose weight restrictions on DMUs. The model suggests that, after normalizing the data and applying the standard CCR model, DMs can impose restriction weights on the following linear programming model [95]:  =1  0  0 =  =1  0 Subject to:


(2.13)

  = 1
=1

36

 =1   1  =1      ,  = 1 , ... ,     ,  = 1 , ... , 

Similar to the CCR model, 0 represents the efficiency score for DMUo and the x's and the y's represent the values of the inputs and the outputs respectively associated for each DMU, while the u's are defined as the virtual weights assigned to each output in the data, while the v's are defined as the virtual weights assigned to each input in the data. The new model differs from the original CCR model by , which is the minimum weight restriction for either the inputs or outputs, and the fact that DMs are free to assign the weight. In order to validate this condition, it is, however, necessary to add the weight constraints, which require that the sum of all weights equals zero, otherwise, the problem could be easily rescaled, resulting in no value for the new weight restriction . The model thereby shows the ability to differentiate between all ranked DMUs. In cases where the DM is only concerned about the input variable of the data, Toloo [96] proposed a DEA approach without explicit inputs (DEA-WEI) where the most efficient DMU with pure output dataset is found. Recently, Toloo and Kresta [97] proposed the opposite model (DEAWEO), where the most efficient DMU is calculated without explicit outputs. As mentioned earlier, DM interference is widely open to the nature of the data and to the interest of the ranking approach. Primarily, the DM manipulates the weight sets in order to achieve the required ranking solution. Some methods use the DEA profiles of DMU in order to create new sets of weight that can be used in ranking approaches separately. Ramón et al. [33] developed a model that uses DEA profiles by minimizing the deviation between profiles.

37

2.3.10. Fuzzy approach category The fuzzy concept is rarely used for DEA outside the MCDM umbrella. One of the authors that has employed this technique, Wu [98] is notable for constructing a fuzzy preference relation after applying the standard DEA model, by pair-wising the efficiency scores. Thereafter, a multistage row-wise summation technique is used to rank all DMUs. More recently, other scholars have applied the fuzzy concept in order to rank DMUs in the DEA context. Zerafat Angiz et al. [34], for instance, proposed converting the output weight of the DEA model into a fuzzy number so that the resulting six-step model would be capable of ranking all efficient units without facing the infeasibility problem that arises through the use of earlier models. However, while the fuzzy concept has been used in DEA for dealing with data variation and variable coefficients, its implementation in DEA ranking is limited because of its inability to deal with accurate data. This concept is thus favored in DEA applications where data are inaccurate and only an estimated ranking is required by DMs [99]. Another approach under the fuzzy umbrella is an approach that combines the methods discussed in Section 3.8, of using virtual DMUs with fuzzy data. Hatami-Marbini et al. [100] proposed a framework for ideal-seeking fuzzy DEA. The models introduce ideal and anti-ideal DMUs to the data, and use a reference point. The ranking of the DMUs under assessment is determined, based on the distance from these reference points. In the same direction, another model is proposed by Hatami-Marbini [101] that uses a similar method, but the overall ranking is determined by calculating the closeness coefficient (CC) between data points under assessment and the two virtual DMUs. Liu also introduced a two-stage fuzzy method [102], where a nonlinear program is formed to obtain the efficiency scores and rank all DMUs accordingly. This recent method is useful when

38

the membership function of the fuzzy models is unknown. Another model by Wen et al. [103] incorporates a simulation approach and genetic algorithm in order to rank the proposed fuzzy DEA model. It is worth mentioning that under the fuzzy category, many DEA models have been developed within the concept of ranking, but it is widely considered that the fuzzy technique could be combined with DEA as a post-analysis to classical DEA model [104]. In other cases, the fuzzy approach can also be used as a cultivating tool for other enhanced DEA models, as in the work of Hatami-Marbini et al. [101] when they applied fuzzy theory to develop a cross-efficiency model to solve sourcing problems in a supply chain application.

2.4. Discussion and literature contribution
Publications and research work in the field of DEA have grown substantially since its introduction in 1978, resulting in major advancements in its methodologies, models, and real-world applications (see [74]). Within this development, a subfield of research has focused on developing the discrimination power of DEA by improving its capability to better rank all DMUs in any dataset under study. This literature analyzed these developments and classified the most relevant DEA ranking methodologies into 10 general categories. The first category includes methods based on cross-efficiency matrixes, where both selfand peer evaluations are applied to achieve a balanced ranking. Two main advantages of the crossevaluation method are that (i) it provides a ranking order for DMUs and (ii) it drops unrealistic weight schemes without asking the decision makers to yield a set of weight preferences (e.g., Anderson et al. [106]).

39

The second group of ranking methods utilizes the super-efficiency concept, where the DMU under assessment is excluded from the linear program of the DEA, thereby allowing it to achieve a score greater than 100%. Super-efficiency methods are broadly used in DEA because of their ability to detect outlying DMUs and provide sensitivity analysis. The main shortcoming of superefficiency models is the infeasibility issue for certain DMUs, particularly under the assumption of VRS, as discussed in the work of Cooper et al. [16], and Thrall [46]. In addition, the existing zero data may be problematic in the super-efficiency models. In this regard, Zhu [107] argued that the super-efficiency model under the assumption of CRS (constant returns to scale) is infeasible when an efficient DMU has zero inputs. Cooper et al. [16] looked into the infeasibility problem that occurs in different super-efficiency models in order to define the necessary and sufficient conditions for the infeasibility of these models. Though Lovell and Rouse [108] developed a user-defined scaling factor to make the VRS super-efficiency model feasible, Cook et al. [49] showed that Lovell and Rouse's [108] approach may have infeasible solutions. Chen [109] considered the input and output super-efficiency scores at the same time to treat the infeasibility that occurs in the VRS superefficiency model. In line with the findings of Chen [109] and Cook et al. [49], Lee et al. [110] showed that the infeasibility may be observed in inefficient performance. As discussed by Lee and Zhu [111], an identical problem associated with the presence of zero data can be observed in Cook et al. [49] and Lee et al. [110]. In a very recent study, Pourmahmoud et al. [54] showed that the RDM super-efficiency model becomes feasible when all range of possible improvements are strictly positive. The third group of methodologies is based on benchmarking all DMUs according to their usefulness, compared with the other units in the dataset. This method is also widely used because it is direct and simple in its application.

40

The methods in the fourth category are based on post-statistical analysis, in which a common weight is found and then all DMUs are ranked by using this value as the reference. In this category, decision-maker involvement is high, and multiple works have been proposed in the literature in order to sustain the criteria that decision makers use, without being biased. The following category discusses a methodology that ranks inefficient DMUs; while only one method was discussed, similar concepts were described in more depth in Section 2.3.7. The sixth category involves complex methods that utilize MCDM modeling in order to rank all efficient DMUs. Of the many MCDM papers in the DEA context, however, few have shifted towards examining the discrimination power of DEA models. The seventh category observes approaches that rank DMUs by using the inefficient frontier as the reference, rather than the efficiency frontier. Under this approach, all inefficient DMUs are excluded from the ranking process. Among all categories, this approach shows a different perspective in terms of developing overall unbiased evaluation. The eighth category discusses methods that introduce single or multiple virtual DMUs to the dataset. Each method in this category designs a virtual DMU in a way that best suits the methodology to rank all DMUs. The virtual DMU approach, although only recently introduced, continues to grow, with the addition of varied models in the literature. The ninth category touches on papers that have proposed ranking approaches that allow the DM to apply certain restrictions to the data. Finally, the last category includes papers that use the fuzzy approach to generate a ranking. The fuzzy concept is not widely applied for ranking DMUs because of its inability to provide an accurate assessment. Hatami-Marbini et al. [112] provided an excellent fuzzy DEA review by classifying the present methods in the literature. Although the -

41

level based approach is one of the best and widely used groups, it is not computationally efficient and cannot be straightforwardly applied in practice. In summary, Table 2.4 presents a general guide towards choosing the best fitting methodology when a ranking method is needed for certain DEA applications. Moreover, practitioners should always look into the resources available before choosing which method to apply for any ranking evaluation. Each category or approach discussed above is unique in term of resource requirements, which may include type and size of data, computational resources, techniques required, special situations, and the decision maker's preferences. Another aspect that analysts should consider when choosing a ranking method is the calculation requirements for each category. In this regard, analysts should try to answer questions such as: What are the weights restrictions? How many constraints and models does the problem have? How many variables are in each model? Answering these questions will also help in determining which ranking method should be used.

42

Table 2.4 Features of the main ranking methods, along with their main advantages and disadvantages

Introduction of a new concept

Ranking efficient DMUs

Reference weights

Advantages of the category

Disadvantages of the category

Cross-efficiency category Sexton et al. [35] Doyle and Green [36] Zerafat Angiz et al. [22] Super-efficiency category Andersen and Petersen [13] Sueyoshi [25] Chen [48] Benchmarking category Torgersen et al. [26] Sinuany-Stern et al. [61] Jahanshahloo et al. [62] Statistics category Friedman and Sinuany-Stern [27] Sinuany-Stern and Friedman [64] Hashimoto and Wu [65] Liu and Hsuan Peng [67] Wang et al. [28] Inefficient DMUs category Bardhan et al. [73]
× Restricts ranking to inefficient units × × × × × × × × × × Full ranking Detects fitting errors Complex application Occasional infeasible results × × × × × × × Simple and direct application × × × × × × Detects outliers Efficiency score greater than 100% Occasional infeasible results × × × × × × × × Unbiased for self-evaluation Accurate ranking Neglects actual score

43

MCDM category Troutt [78] Li and Reeves [80] Sinuany-Stern et al. [81] Jablonsky [82] Inefficient frontier category Yamada et al. [85] Entani et al. [86] Jahanshahloo and Afzalinejad [88] Wang et al. [31] Virtual DMU category Wang and Luo [89] Wang and Yang [90] Zheng [91] DM interference category Wang et al. [95] Fuzzy concept category Wu [98] Zerafat Angiz et al. [34]
× × × Useful with inaccurate data Vague inputs and outputs Occasional infeasible results × × Responsive to the DM Inconsistency × × × × Flexibility Full ranking in most models Changes the reference set in the original dataset × × × × Pessimistic ranking Detects worst units Useful in elimination process Reduces bias Changes the ranking order Dual calculation for every model and longer algorithm implied × × × × × × × Full ranking Responsive to the DM's preferences Complex and stretched methodology

44

This literature review can be considered as an attempt to fill the gap in the literature of DEA ranking methods. The literature development between 2002 until the time of publishing this article was very intensive. The main conclusion raised from developing 10 categories is that none of the proposed DEA ranking category is optimum for every evaluation assessment. At the same time, some methods have the advantage of a simple process and the provision of accurate results, while others reach similar results by using more complex procedures. One frequently raises the question: which DEA ranking method should one use? The answer to this question often depends upon the application being considered. Moreover, the fit of the characteristics of the data under assessment with the DM's preferences could be the main factor in determining a fit method that might be used to conduct a DMUs evaluation in the DEA context. This literature review discusses different situations, including the available information and objectives sought to be achieved for each category, which may help practitioners apply an appropriate DEA ranking category. In brief, this review with its classifications of ranking methods should aid researchers in advancing their work by:   improving the discrimination power of DEA and ranking DMUs under evaluation developing similar ranking models discussed in the review for other types of DEA such as network DEA (See Färe and Grosskopf [113]) or the FDH model, which is the focus of this thesis  allowing applications of DEA ranking methods for real decision-making problems such as multi-stage supply chains  making a comparison between different DEA ranking categories using statistical techniques such as Spearman's rank correlation coefficient, to observe how well the relationship between two methods works 45



developing a methodology to appropriately account for the issues of ranking of fuzzy efficiencies.

2.5. Summary and conclusion
In conclusion, a major finding of this review is that the absence of universal assessment criteria makes it impossible to evaluate all methods presented. Each method could be better than others according to the DM's preferences and evaluation objectives, which depend on the nature of the evaluation. Indeed, no ranking method was found to be either a universal or a superior method for ranking the efficiency of DEA models, and there remains considerable room for additions to the literature, since many tools have not yet been applied. As a general observation, it can be said that many of the methods were presented some time ago have been well developed, and the literature is saturated with discussions about them. On the other hand, some methods are considered fairly new and not yet properly examined and investigated, though they yield very good and accurate rankings. One of these approaches, as previously discussed, is the pessimistic frontier approach. The major advantage of this approach is its ability to bring full ranking to any dataset when its incorporated with standard efficiency frontier. Furthermore, its unique characteristic of avoiding biasness by incorporating both optimistic and pessimistic approaches is unlike all other approaches, which mainly only consider the optimistic models. This approach can be considered as a foundation approach to all new models developed in this thesis or the general framework of the thesis, as shown in the remaining chapters. Furthermore, this thesis adopted the virtual DMUs approach from the literature and some models developed in this thesis are also developed on that basis. This review has shed light on almost all available DEA ranking methods in the literature, and it should help any researcher or practitioner to build a foundation and comprehensive 46

understanding of DEA ranking methods and their development. It is hoped that the taxonomy and detailed review provided in this chapter will help users to decide on the direction of their work in terms of either DEA application or research investigation.

47

Chapter 3: New Optimistic and Pessimistic DEA/FDH Models

48

3.1. Introduction
The aim of frontier analysis is to construct the empirical analogue of the production function by the use of the production possibility set (PPS), also the so-called technology, whose frontier is used to evaluate firms [114]. DEA, a well-known non-parametric method in frontier analysis for measuring the relative efficiency between DMUs, was introduced more than 40 years ago when Charnes, Cooper, and Rhodes [1] presented their so-called CCR model for CRS, through which they were able to construct the PPS, based on mathematical programming techniques. The main idea behind the original DEA models is that an empirical best practice frontier is first constructed by enveloping the observed data through a minimal spanning hull, and then the efficiency measure is determined based on radial projection to the production frontier. DEA has since attracted the attention of many researchers because of its unique ability to measure the efficiency of multiple-input and multiple-output DMUs without assigning prior weight to the input and output, resulting in the proposal of a wide range of DEA models [74]. A remarkable DEA model developed in the literature is the free disposal hull (FDH) model that is based on an exceptionally powerful line of reasoning. Deprins et al. [115] were the first to propose an FDH model with a non-convex technology, and FDH was further developed by Tulkens [116]. FDH is different from the DEA family in that it requires the minimal satisfaction on the assumptions for creating the "staircase" shape of the FDH frontier production. That is, it does not require convexity and/or proportionality assumptions. Although fewer studies have been conducted on the FDH model than on classical DEA, FDH is considered a more justifiable orientation from the practical and theoretical views than the hypothesized convex assumption in DEA [118, 119].

49

Another specific characteristic of DEA models, so-called optimism, is to seek the most desirable input and output weights of a particular DMU, with the aim of radially projecting on the efficiency production frontier, making each unit appear in its most favorable light. Considerable research has been conducted regarding this characteristic of DEA. However, many DEA researchers have argued that using a pessimistic perspective in addition to the optimistic approach is important to render an equitable evaluation. Pessimistic DEA simply evaluates DMUs by constructing the inefficiency production frontier based on the least desirable weights to achieve the full inefficiency scores. An extensive body of literature exists regarding the incorporation of the pessimistic and optimistic approaches to achieve an unbiased evaluation. The remainder of this chapter is organized as follows. The next subsection presents a preliminary discussion of the major related research studies that incorporate optimistic and pessimistic approaches. In subsection 3.3, the axiomatic foundation of the optimistic DEA model is presented to develop the estimate formulation of the directional distance function from the input and output orientations. Subsection 3.4 discusses the pessimistic directional distance function for both the input- and output-oriented models. In subsection 3.5, the optimistic and pessimistic FDH models are developed for input- and output-oriented cases, and the models are extended to include slack-based models and super-efficiency models to rank the efficient units.

3.2. State of the art on pessimistic and optimistic DEA
There has been a series of research studies focusing on the development of classical DEA models while incorporating the pessimistic approach to achieve a better evaluation of the DMU under assessment. The main finding from this series of papers is that using only optimistic or only pessimistic DEA models is biased because there are two efficient DMUs under the optimistic DEA, 50

whereas they are inefficient under the pessimistic DEA, as shown in Figure 3.1. Since the dual frontiers approach is the main framework of the all models developed in this thesis, in this subsection a closer attention is paid to the main dual models in the literature and all extended models. Yamada et al.[119] were the first authors to propose a pessimistic method to evaluate DMUs, which they termed inverted DEA (IDEA). All research work that incorporates optimistic DEA with pessimistic DEA can be categorized into two categories. The first category is called interval efficiency, where the efficiency score of each DMU in the dataset is calculated as an interval between the optimistic and pessimistic frontiers. There are more studies devoted to this category than to the other one. The second category includes different approaches that assimilate both optimistic and pessimistic measures by directly applying some mathematical or statistical methods, such as averaging, virtual DMUs, or cross-efficiency, with the aim of combining both measures.

51

Figure 3.1 Dual DEA frontiers

The following paragraphs review the articles and research work related to the first category, namely, interval efficiency between optimistic and pessimistic DEA. Doyle et al. [120], and Entani et al. [86] were among the first to combine the inverted or pessimistic DEA with the conventional optimistic DEA. Their research resulted in an efficiency score that is obtained based on an efficiency interval in which the lower bound is the pessimistic score and the upper bound is the optimistic score. Entani et al. [86] constructed an interval model to calculate the efficiency, and these intervals are obtained from both optimistic and pessimistic scores. The model of Entani et al. can be considered the foundation model for the efficiency interval approach, where the final efficiency score for any DMU is denoted as an interval of the lower and upper limit efficiencies. Their model was initially proposed for crisp data and was 52

extended to consider interval data and fuzzy data. A major shortfall is that it works perfectly only with two-dimensional data, as the model uses variable frontiers for each DMU under evaluation. Entani and Tanka [121] tried to improve upon this model by adjusting the input and output of the data to make the upper bound of the efficiency interval equal 1 and the lower bound as large as possible to achieve the optimal evaluation. To overcome the shortfall of Entani et al. [86], Wang and Yang [90] introduced a method founded on the concept of virtual DMU called anti-ideal DMU (ADMU), which can be defined as a DMU that uses the maximum input value to produce the minimum output value. In their model, the efficiencies of all DMUs are obtained by calculating the worst and best performances of each DMU, and the interval efficiencies are calculated. Then, they used the Hurwicz criterion approach to rank each DMU, based on these interval values. This model is referred to as a bounded DEA model because the efficiency of the DMU in question is bounded between upper and lower bounds, which are then combined to determine the efficiency. The advantage of this method is that it incorporates most of the input and the output data when evaluating performance; however, it lacks feasibility when there is a zero value for any output in the data because the ADMU will obtain a zero value in its output. In the same direction, HatamiMarbini et al. [122] proposed the fuzzy version of Wang and Yang's [90] model to obtain the bounded fuzzy efficiency scores using a four-step framework. Wang and Yi [123] introduced an IDMU which consumes the minimum input and produces the maximum output, to determine the lower bound of the interval efficiency of optimistic and pessimistic scores. After obtaining the efficiency intervals, a Hurwicz criterion approach is incorporated into their model to achieve full evaluation and ranking. Wang and Luo [89] proposed an approach that evaluates efficiency using both the IDMU and ADMU. Wu [124] highlighted a problem in the previous model of Wang and Luo [89], namely, that a negative ideal point cannot

53

be computed. A revised model has been proposed, based on the previous model and incorporated with the TOPSIS approach to calculate the overall efficiency. Chen [125] also highlighted a scaling problem with the model of Wang and Luo [89], where optimistic scores are limited to no more than one, whereas the pessimistic scores are limited to no less than one. Chen proposed a rescaled model that claimed to be superior to the models of Wang and Luo [89], and Wu [124]. A significant research effort was undertaken after it was proven that the Wang and Yang [90] model is not capable of processing data with a zero value in the output. Azizi and Wang [32], and Azizi [126] developed general bounded models that overcome this limitation and measure the efficiencies of DMUs in the presence of each output and with the presence of zero values in the output. Similar to the previous approach, Azizi and Jahed [127] proposed an adjusted interval model as an extension of Entani et al. [86] that addresses data with zeros in each input and overcomes the feasibility issue of the model of Wang et al. [123]. Azizi and Ajirlu [128] developed an alternative to the model of Entani et al. called the bounded DEA model for crisp data. In this model, the IDMU and ADMU are introduced as virtual DMUs, and the model is developed accordingly. The advantage of this model is that it can identify all DMUs that are pessimistically inefficient. Moreover, the model requires fewer computational loops than Entani's model. Their proposed model was proven to be invalid by Chen [129] because it faces the same issue of not being able to determine the lower bound when there are zeros in the data. Chen [129] critiqued most models in the literature for having infeasibility because most interval models encounter the problem that the lower bound can be greater than the upper bound, and, in these cases, the efficiency measure is not feasible. Thus, Chen's model has three main advantages. First, the model eliminates any unreachability of the efficiency. Second, it can identify all DMUs as efficient or inefficient. Third, both the efficient and inefficient frontiers remain

54

untouched. Additionally, the computational requirements of the model are lower. In this paper, reliance is made on the critiques of Chen [129] of the models in the literature and presents a model that exhibits all the advantages of Chen's model. Jahanshahloo, et al. [130] proposed a ranking DEA model for crisp and interval data. Their procedure starts with obtaining the ideal points for efficient DMUs by applying the interval DEA model (the model of Entani et al.). Next, they introduce a virtual DMU called the special DMU that is similar to the anti-ideal DMU, which has the worst performance measure. Then, the total distance between the ideal points of all DMUs and the special DMU are calculated; the closest DMU is considered the best or most efficient, and all DMUs are ranked accordingly. In contrast to virtual DMU approaches, Azizi [87] introduced the bounded DEA model that is similar to the previous one but does not use virtual DMUs, leading to results similar to those of the Entani et al. interval models. Azizi et al. [131] also presented two models to obtain the upper and lower bounds of the efficiency scores when the input/output data are imprecise and are given in the form of an interval or ordinal relationship. Jahed et al. [132] presented a model that considers uncertain data or fuzzy data. Their approach develops two fuzzy interval DEA models, one based on the pessimistic frontier and the other based on the optimistic frontier. Both measures are combined by a quadratic average to obtain a final efficiency interval for all DMUs. As noted above, the second category of research work in the direction of optimistic and pessimistic approaches includes miscellaneous methodologies that combine both approaches via statistical or mathematical approaches. It is understood that Wang et al. [31] proposed the first paper in this category by the direct application of the geometric average between the optimistic and pessimistic scores to calculate the final efficiency value for ranking purposes. Amirteimoori [133] proposed super-efficiency models for both the optimistic and pessimistic approaches.

55

Another proposed model that used cross-efficiency with both optimistic and pessimistic DEAs after introducing ideal DMUs and anti-ideal DMUs is that of Wang et al. [134]. In their paper, they developed four cross-efficiency models, where the first aims to minimize the distance between DMUk and ADMU, the second aims to maximize the distance between DMUk and IDMU, the third maximizes the distance between the IDMU and ADMU, and the last maximizes the relative closeness of DMUk. Sun et al. [135] argued that using multiple weights for both approaches leads to a biased comparison between DMUs. Thus, they proposed two common weight models: one based on the optimistic view and the other based on the pessimistic view, without combining them, and left the decision on which model to use to the decision-maker's preference. Other models in this category are models that address imprecise data. Hatami-Marbini et al. [136] and [101] were the first to adapt the pessimistic optimistic frontiers to address imprecise data. Hatami-Marbini et al. [136] introduced the IDMU and ADMU as virtual DMUs and developed a four-stage fuzzy DEA model that incorporates TOPSIS to rank and evaluate all DMUs in the dataset. Another imprecise data model is that of Azizi et al. [137], which is considered a slack-based model for optimistic and pessimistic approaches that addresses imprecise data. Both models are combined with geometric values similar to the model of Wang et al. [31], with the only difference being that they use the slack-based model instead of classical DEA models. In this category, the work of Paradi et al. [138], Johnson and McGinnis [139], and Horta and Camanho [140] is also noted. In summary, this preliminaries section shows that incorporating optimistic and pessimistic DEAs leads to a better evaluation of DMUs and better discrimination power. However, a gap was found in the literature, that is, the lack of discussion on the non-convex frontier from the optimistic and pessimistic perspectives. According to the DEA literature on the double optimistic and

56

pessimistic frontiers, none of the existing models accommodate non-convex frontiers. As discussed by Cherchye et al. [141], and Agrell and Tind [142], non-convex frontiers are considered an important technology that may be closer to the real-life situation, where the convexity assumption can be relaxed and no hypothetical frontiers need to be constructed. Moreover, conventional DEA leads to the indivisibility of input and output, and in many cases, the convexity axiom may be broken. More discussion and empirical evidence can be found in the work of Farrell [143], Deprins et al. [115], Tulkens [116] and Kuosmanen [144]. This study contributes to the literature by providing a number of models that incorporate optimistic and pessimistic assessments without a convexity assumption, as discussed in the following sections of this chapter. The thesis proposes an interval DEA model with double frontiers without the convexity assumption, by constructing optimistic and pessimistic FDH models to overcome the shortfall of optimism and the convexity of conventional DEA.

3.3. Axiomatic foundation in DEA (optimistic DEA)
DEA, developed by Charnes et al. [1], is a data-driven frontier analysis technique for estimating a convex hull and measuring the radial distance between the frontier and each observation, called a DMU. Assume that the efficiency of n observed DMUs is evaluated based on m inputs and s
+ outputs. Each DMUj where j=1,2,...,n is characterized by an input vector    and an output + vector     . The production possibility set (PPS) T is defined as

T{(X,Y) | Y can be produced by X}

(3.1)

57

Due to the unknownness of T in practice, the empirical PPS, denoted by , can be expressed using the following axioms: (A1) no free lunch, (A2) boundedness, (A3) closedness, (A4) free  re et al. [145]) for a detailed disposability of both inputs and outputs, and (A5) convexity (see Fa explanation of the axioms). The empirical PPS  can be defined by means of n production units ( ,   ) j=1,2,...,n as the following set of linear inequalities[145]: (3.2)   {(X, Y)|  Xj j  X;  Yj j  Y; j  0}
j j

With reference to , the directional distance function can be defined as [145]: DT (X, Y; g x , g y ) = {|( X + g x , Y + g y )  T}


(3.3)

+ where (  ,   )  + is a pre-partitioned and arbitrary input-output direction. In line with the

general directional distance function, Chambers et al. [146], and Chambers et al. [147] developed a measure of distance to the production frontier, where (- ,  ) is chosen for (  ,   ). For a given PPS , the directional distance function  can be formulated as [147]: DT (Xo , Yo ; g x , g y ) = {|( Xo - Xo , Yo + Yo )  T}


(3.4)

 is used to simultaneously minimize the inputs and maximize the outputs of a given DMU. Based on the aforesaid axioms, strong disposability and VRS assumptions, the directional distance function (3.4) leads to the linear programming model (3.5) for calculating the directional distance function value of a DMUo under evaluation [147]:

58

DT (Xo , Yo ; g x , g y ) = (3.5) max {|  j Xj  Xo - Xo ;  j Yj  Yo + Yo ;  j = 1; j  0}
j j j

Geographically, distance function measures the distance between the observation ( ,  ) and the frontier estimated by  under the input and output orientations in the production space. The factor  in model (3.5) is called the Nerlove-Luenberger measure of technical inefficiency, and (1 - ) represents the technical efficiency of DMUo. The Shephard input and output distance functions can be expressed as follows [148]: Din (Xo , Yo ) = {|( Xo /, Yo )  T}


(3.6)

Dout (Xo , Yo ) =  {|( Xo , Yo /)  T}


If the input direction in (3.4), i.e.,   = 0, is not used, the directional and Shephard output distance functions are connected as  ( ,  , 0,   ) = (1/ ( ,  )) - 1 . Similarly, the directional and Shephard input distance functions are linked as  ( ,  ,   , 0) = 1 - (1/ ( ,  )). In other words, the Shephard input and output distance functions are reciprocal to the Farrell measures of input and output technical efficiency, which can be empirically estimated as [148]:

in 1/Din (Xo , Yo ) = Fo = min {|  j Xj  Xo ;  j Yj  Yo ; j  (B)} j j

(3.7)
out 1/Dout (Xo , Yo ) = Fo = max {|  j X j  Xo ;  j Yj  Yo ; j  (B)} j j

59

where   () indicates the type of returns to scale (RTS) assumption and the shape of the envelopment. (See Banker and Thrall [150] for a detailed discussion RTS.) The above models evaluate the radial efficiency using a given PPS, which is estimated by observations and axioms of convexity, free disposability and RTS. In this regard, one of the following assumptions can be included to define constant RTS (CRS), decreasing RTS (DRS), variable RTS (VRS) and increasing RTS (IRS) models (see Charnes et al. [1] and Bogetoft [150]): () = {  :   0}

() = {  :   0;    1}


() = {  :   0;   = 1}


() = {  :   0;    1}


() = {  :   = 1 ;  = {0,1}}
   If a DMUo under evaluation is located on the frontier, i.e.,  = 1), it is said  = 1 ( 

to be efficient; otherwise, it is called inefficient. In brief, all efficient DMUs construct the "efficient
  frontier." The value of  (   ) gauges the degree to which the outputs (inputs) of the DMU o

can be scaled up (down) pro rata, while preserving the PPS. The projected point for the output
  analysis is ( ,   ), where   1, whereas the projected point for the input analysis is     (   ,   ), where 0     1.

60

3.4. Pessimistic DEA
One can seek an inefficient frontier from observations with the aim of indicating the inefficient observations to obtain an insightful DEA analysis. From the output viewpoint, the inefficient frontier can be represented as a convex hull derived from the minimum output level, given an input level for which output levels less than the frontier value cannot be produced. Similarly, from the input viewpoint, the inefficient frontier is a convex hull defined by the maximum input level, given an output level for which input levels greater than the frontier value cannot be used. In other words, the most inefficient observations representing the worst possible performance construct the inefficient frontier.  , can be defined by n The empirical PPS estimating the inefficient frontier, denoted by  observations ( ,   ) j=1,2,...,n as follows:   {(X, Y)|  Xj j  X;  Yj j  Y; j  (B) } T
j j

(3.8)

 , the reciprocal Shephard input and output distance functions or the Farrell With respect to  measures of input and output technical efficiency can be expressed as follows:
in  in (Xo , Yo ) = F o 1/D = max {|  j Xj  Xo ;  j Yj  Yo ; j  (B) } j j

(3.9)
out  out (Xo , Yo ) = F o 1/D = min {|  j X j  Xo ;  j Yj  Yo ; j  (B) } j j

 (  ) gauges the degree to which the outputs (inputs) of DMUo can be The value of  scaled up (down) pro rata toward the inefficient frontier, while remaining in the PPS. The projected   ), indicates the point located on the inefficient point for the output perspective, as ( ,  61

  1 represents the distance between DMUo and the inefficient frontier. frontier, where 0     ,  ), in which    1 measures Analogously, the projected point for the input analysis is ( the distance between DMUo and the inefficient frontier. If a DMUo under evaluation is located on  = 1 (  = 1), it is said to be inefficient; otherwise, it is called the inefficient frontier, i.e.,  not inefficient. The difference is graphically illustrated between efficient and inefficient frontiers constructed from 10 observations, denoted as A, B,...,J, where each observed unit produces two outputs, using one input that has the same value for all units, as shown in Table 3.1 The dataset was originally used in Entani et al. [86]. The dual frontiers are depicted in Figure 3.2. The conventional CRS-DEA with an optimistic viewpoint results in the piecewise line AEJ as an efficient frontier, where DMUs A, E and J lie on this frontier and DMUs A, B, F and J construct an inefficient frontier. Table 3.1 Input and output data for 10 DMUs illustrative example
DMU Inputa Output 1 Output 2

A B C D E F G H I J
a

1 1 1 1 1 1 1 1 1 1

1 2 2 3 3 4 4 5 6 7

8 3 6 3 7 2 5 2 2 1

Unity score is given to the input in order to keep the data within two dimensions

62

Figure 3.2 Dual FDH frontier vs CRS frontier

3.5. Optimistic and pessimistic FDH
In this section, attention is drawn to the FDH model of Tulkens [116], which constructs a non-convex hull imposing strong disposability assumptions. The FDH model is a remarkable DEA model that differs from the other DEA models by requiring minimal satisfaction on the DEA assumptions where convexity is relaxed. The FDH frontier creates a "staircase" shape production set that does not require convexity and/or proportionality assumptions. In this regard, this section proposes an interval FDH for measuring the bounded efficiency, where the upper bound is obtained from the optimistic perspective and the lower bound is obtained from the pessimistic perspective. Mathematically, convexity assumption means for any production possibility set (PPS) T, if there are two points (X1 , Y1 )  T and (X2 , Y2 )  T , and for any weight 0    1, the 63

weighted sum {(1 - )(X1 , Y1 ) +  (X2 , Y2 )}  T . That means any points between the points can be considered as a part of the feasible PPS. For further explanation on convexity assumption, see the illustrative example presented in Figure 3.2. We can say that the efficiency CRS frontier (blue lines) and the inefficiency CRS frontier (red lines) are convex, and any points between the lines of the plotted DMUs belong to the feasible PPS. For instance, since DMUs E and J are connected through the frontier line, then any point located on the line EJ is also a feasible point. Although DEA is an estimator based on the assumption that the true production set is convex, in some real-life situations, the true production set may not be convex. The FDH is the most used non-convex DEA model in the literature. Hence, FDH measures the efficiency of a given observation to the frontier of the free disposal hull of the set of observations. As a more general version of the DEA estimator, the FDH model relaxes the convexity while preserving strong disposability and considering the VRS assumption [151]. In other words, dispensing with convexity leads to frontiers of a "staircase" shape that have a lower rate of convergence than conventional DEA. The FDH input and output efficiency scores for a given observation ( ,  ) can be expressed as [151]:
in-FDH Fo (Xo , Yo ) = inf {|(Xo , Yo )  T FDH } out-FDH Fo (Xo , Yo )

(3.10) } The distance

= sup {|(Xo , Yo )  T

FDH

where   = {(, )|      ;        ;   = 1 ;  = {0,1} } .

between the frontier and observation ( ,  ) is measured in terms of (3.10) in the input and output spaces. Thus, the efficiency score of DMUo can be measured by solving the following programs: (3.11)

in-FDH Fo (Xo , Yo ) = min {|  j Xj  Xo ;  j Yj  Yo ;  j = 1 ; j = {0,1} } j j j

64

out-FDH Fo (Xo , Yo ) = max {|  j Xj  Xo ;  j Yj  Yo ;  j = 1 ; j = {0,1}} j j j

The above programs are the integer programming models due to the integral variables  . Apart from the integral constraints, the FDH program (3.11) is identical to the VRS-DEA model.
  Thus,    and the FDH efficiency estimate is higher than the VRS efficiency estimate.  

By solving (3.10), the convexity constraint   = 1 takes one intensity variable  with a value of 1. The proposed model 3.11 is presented in compact format to maintain consistency with the format used in the FDH literature, but also it can be presented in an expanded format as:
-  ( ,  ) =   

 =1      ;

 = 1,2, ... , ,

 =1     ;  = 1,2, ... , ,   = 1 ;  = {0,1} ;
- (    ,   )

 = 1,2, ... , . (3.11b)  = 1,2, ... , 

=    =1     ;  =1      ;  = 1,2, ... , ,   = 1 ;  = {0,1} ;  = 1,2, ... , .

where n is the number of DMUs in the dataset, and m and s are the number of inputs and outputs, respectively. And  represents the efficiency score and the x's and the y's represent the values of the inputs and the outputs respectively associated for each DMU.This representation can be applied to all models presented in chapters 3 and 4. 65

In this chapter, over and above the non-convex efficient frontier, which analyzes the performance of the DMUs from the optimistic viewpoint, an inefficient non-convex frontier is indicated from the observations to represent the worst possible performance. The empirical PPS   can be expressed by n observations ( ,  estimating the non-convex inefficient frontier   ) j=1,2,...,n as follows:  FDH = {(X, Y)|  j Xj  Xo ;  j Yj  Yo ;  j = 1 ; j = {0,1} } T
j j j

(3.12)

  are contrary to   . The inequality constraints defined in  From the output space, the inefficient frontier can be considered a non-convex hull derived from the minimum output level, given a fixed level of input for which output levels less than the frontier value cannot be produced; analogously, from the input space, the inefficient frontier is a non-convex hull obtained from the maximum input level, given a fixed level of output for which input levels greater than the frontier value cannot be consumed. The associated measurements with   from the input and output perspectives are computed as: respect to the non-convex PPS 
in-FDH o  FDH } F (Xo , Yo ) = sup {|(Xo , Yo )  T out-FDH o F (Xo , Yo )

(3.13)

= inf {|(Xo , Yo )  T

 FDH

}

and equivalently, the following:
in-FDH o F (Xo , Yo ) = max {|  j Xj  Xo ;  j Yj  Yo ;  j = 1 ; j = {0,1} } j j j

(3.14)

out-FDH o F (Xo , Yo ) = min {|  j Xj  Xo ;  j Yj  Yo ;  j = 1 ; j = {0,1} } j j j

- and  - measure the extent to which the levels of outputs and inputs where  for a given DMUo can be increased and decreased proportionally with respect to the inefficient 66

frontier, while remaining in the PPS. Finally, if a DMUo under assessment lies on the inefficient - = 1 ( - = 1), then it is called inefficient; otherwise, it is called not frontier, i.e.,  inefficient. Integer programming problems, such as models (3.11) and (3.14), are intrinsically more difficult and time-consuming to solve than linear programming problems, and there is a lack of duality and simplex algorithms to assist in solving them. Reliance can be had on an equivalent FDH linear program introduced by Agrell and Tind [142] to address the computational complexity for large problems. The proposed model 3.11 is not linear, and that is what causes the complexity in calculating the efficiency score. To transform this model to a linear program, we need to replace the j = {0,1} by a linear constraint. By applying the Agrell and Tind [142] model, we replace the j = {0,1} constraint by j  0 but the efficiency score  will be calculated through a summation of the individual set of j while the virtual input and output constraints remain constant for every individual  (mathematical proof of equivalency between the two models is provided in Agrell and Tind [142]). In doing so, the upper limit of the interval efficiency of a DMUo in terms of the input and output spaces can be solved by the following linear programs:

in-FDH Fo (Xo , Yo ) = min { j |j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

(3.15)

out-FDH Fo (Xo , Yo ) = max { j |j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

Similarly, the lower limit of the interval efficiency of a DMUo in terms of the input and output spaces presented in model 3.14 can be solved by the following linear programs:

67

in-FDH o F (Xo , Yo ) = max { j |j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

(3.16)

out-FDH o F (Xo , Yo ) = min { j |j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

The earlier example in Section 3.4 is used to illustrate the above step of the proposed method. The FDH efficient frontier from the optimistic viewpoint is constructed by DMUs A, E, G, F, H, I and J, whereas the FDH inefficient frontier from the pessimistic viewpoint is built by DMUs A, C, B, D, F, H, I and J, as shown in Figure 3.2. The results from models (3.11) and (3.14) or models (3.15) and (3.16) are also reported in Table 3.2.

Table 3.2 Illustrative example results obtained for dual FDH model
DMU Input Output 1 Output 2 - ( ,  ) model (3.11), (3.15) 1 1.6667 1.6667 1.3333 1 1 1 1 1 1 - ( ,  )  model (3.14), (3.16) 1 1 1 1 0.6667 1 0.6 1 1 1

A B C D E F G H I J

1 1 1 1 1 1 1 1 1 1

1 2 2 3 3 4 4 5 6 7

8 3 6 3 7 2 5 2 2 1

68

3.6. Summary and conclusion
In this chapter, new DEA-FDH models from optimistic and pessimistic perspectives have been developed. Previous sections described the efficient and inefficient frontiers in FDH models to formulate boundary efficiency representations for the input- and output-oriented cases. These models presented in chapter 3 are very important to the user who needs to relax the convexity assumption of conventional DEA. As this study is conducted in a ranking development context, after developing the dual FDH models, it was realized that these models suffer from weak discrimination power. In the following chapter of this thesis, new improved optimistic and pessimistic models will be developed in order to increase the ranking abilities of the dual FDH model.

69

Chapter 4: Improved Optimistic and Pessimistic FDH Models: An Integrated Approach

70

4.1.Introduction
In the previous chapter of this thesis, optimistic and pessimistic FDH models have been proposed. These models may experience a lack of sufficient discrimination power. To overcome the weak discrimination power, integrated models are proposed and discussed in this chapter. Two improved versions of both approaches are developed. The first version formulates the models in the presence of the slack variables, and a detailed discussion is provided in Section 4.2. In the second improved version, FDH super-efficiency models are proposed in Section 4.3 and can be referred to as 1st FDH-SF integration. These super-efficiency models become infeasible. Thus, modified models without the infeasibility problem are discussed in Section 4.4 and can be referred to as 2nd FDH-SF integration. The chapter concludes with a comprehensive empirical study to illustrate the applicability of the proposed models.

4.2. Slack-based FDH dual frontiers
In order to develop slack-based models that help to distinguish between efficient DMUs a slack-based models are considered. A non-Archimedean infinitesimal constant, , is introduced in models (3.15) and (3.16), and that leads to strongly efficient solutions for the input- and outputoriented cases. In the recent work of Podinovski et al. [152] a theoretic proof shows that the nonArchimedean constant that is commonly used in the literature can also be replaced by a very small infinite value of epsilon for computational simplicity. Our models are developed using the nonArchimedean constant multiplied by the virtual weights of the slack variable as formulated below:

71

in-FDH (X Fo o , Yo )

= min { j + ( 1sj+ + 1sj- )|j Xj + sj- = j Xo ; j Yj - sj+
j

= j Yo ;  j = 1 ; j  0 }
j out-FDH Fo (Xo , Yo )

(4.1)

= max { j + (1sj+ + 1sj- )|j Xj + sj- = j X o ; j Yj - sj+
j

= j Yo ;  j = 1 ; j  0 }
j

in-FDH o F (Xo , Yo )

= max { j + (1sj+ + 1sj- )|j Xj - sj- = j Xo ; j Yj + sj+
j

= j Yo ;  j = 1 ; j  0}
j out-FDH o F (Xo , Yo )

(4.2)

= min { j + (1sj+ + 1sj- )|j Xj - sj- = j Xo ; j Yj + sj+
j

= j Yo ;  j = 1 ; j  0 }
j

where + and - are slack variables. According to the efficiency score and the optimal solutions obtained from models (4.1), three definitions can be introduced as follows:

72

- - Definition 1: If  ( ,  ) = 1 or  ( ,  ) = 1 and zero-slack ( + =  

- = 0), DMUo is called strongly FDH-efficient, implying that this unit is located on the strong efficient frontier.
- - Definition 2: If  ( ,  ) = 1 or  ( ,  ) = 1 and has at least one non 

zero slack variable (+  0 and/or -  0), DMUo is called weakly FDH-efficient, implying that this unit is located on the weak efficient frontier.
- - Definition 3: If  ( ,  ) < 1 or  ( ,  ) > 1, DMUo is called FDH 

inefficient, implying that this unit is not located on the efficient frontier. Similarly, according to the efficiency score and the optimal solutions derived from models (4.2), three definitions can be introduced as follows: - ( ,  ) = 1 or  - ( ,  ) = 1 and zero-slack ( + = Definition 4: If  - = 0), DMUo is called strongly FDH-inefficient, implying that this unit is located on the strong inefficient frontier. - ( ,  ) = 1 or  - ( ,  ) = 1 and has at least one nonDefinition 5: If  zero slack variable (+  0 and/or -  0), DMUo is called weakly FDH-inefficient, implying that this unit is located on the weak inefficient frontier. - ( ,  ) > 1 or  - ( ,  ) < 1, DMUo is called not-FDHDefinition 6: If  inefficient, implying that this unit is not located on the inefficient frontier. Table 4.1 shows the calculation of SB-FDH models for the same numerical example discussed in chapter 3. According to Table 4.1 and Figure 3.2, when considering the "staircase" shape of the efficient FDH frontier, DMUs A, E, G, I and J are classified as strongly FDH-efficient because their efficiency scores are equal to 1 and there is zero slack (Definition 1); DMUs F and H are classified as weakly FDH-efficient because there is a non-zero-slack, even with 100% 73

efficiency (Definition 2); and DMUs B, C and D are classified as FDH-inefficient because the efficiency does not equal 1 (Definition 3). Further, when considering the "staircase" shape of the inefficient FDH frontier, DMUs A, B, C and D, H, I and J are classified as strongly FDH-inefficient - ( ,  ) = 1 and there is zero slack (Definition 4), whereas DMUs E and G are because  - ( ,  )  1 . As can be observed in this classified as non-FDH-inefficient because  example, many of the observations belong to strongly FDH-efficient and strongly FDH-inefficient classifications with weak discrimination power. This problem in FDH stems from two reasons: (i) linear combinations of external observations are excluded when constructing the frontier that leads to the closest envelope to the data, and (ii) the radial efficiency of each DMU is based on that of other DMUs. Thereby, a relatively large number of DMUs normally lie on the efficient and inefficient FDH frontiers.

Table 4.1 Input and output data for 10 DMUs with the results of SB models (4.1) and (4.2)
DMU Input Output 1 Output 2 - ( ,  ) Model (3.11), (3.15) 1.00 1.67 1.67 1.33 1.00 1.00 1.00 1.00 1.00 1.00 Slacks
+ (1) + (2)

- ( ,  )  Model (3.14), (3.16) 1.00 1.00 1.00 1.00 0.67 1.00 0.60 1.00 1.00 1.00

Slacks
+ (1) + (2)

A B C D E F G H I J

1 1 1 1 1 1 1 1 1 1

1 2 2 3 3 4 4 5 6 7

8 3 6 3 7 2 5 2 2 1

0.00 0.67 0.67 0.00 0.00 0.00 0.00 1.00 0.00 0.00

0.00 0.00 0.00 1.00 0.00 3.00 0.00 0.00 0.00 0.00

0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

0.00 0.00 0.00 0.00 1.67 0.00 0.40 0.00 0.00 0.00

74

4.3. Dual super-efficiency models
In this section, it is sought to discriminate further between the FDH-efficient and FDHinefficient DMUs. To do so, newly improved FDH models are proposed that incorporate the superefficiency method proposed by Andersen and Petersen [13] into the models previously proposed in this thesis. In this regard, Van Puyenbroeck [118] proposed a modified FDH method using a super-efficiency procedure for ranking units that lie on the efficient FDH frontier. In line with the concept of super-efficiency, the following formulations can be expressed by excluding the evaluated unit DMUo from the PPS when focusing on the efficient FDH frontiers (4.3):
in-FDH SFo (Xo , Yo )

= min { j + ( 1sj+ + 1sj- )|j Xj + sj- = j Xo (j  o); j Yj - sj+
jo

= j Yo (j  o);  j = 1 ; j  0(j  o) }
jo out-FDH SFo (Xo , Yo )

(4.3)

= max { j + (1sj+ + 1sj- )|j Xj + sj- = j Xo (j  o); j Yj - sj+
jo

= j Yo (j  o);  j = 1 ; j  0(j  o) }
jo

- - In the above formulations,  ( ,  )  1 and  ( ,  )  1 if the units  

are

classified

as

strongly

(weakly)

FDH-efficient,

whereas

- ( ,  ) and

- -  ( ,  ) remain unchanged when - ( ,  ) < 1 and  ( ,  ) > 1  

with respect to models (4.1) (i.e., FDH-inefficient DMUs). As a result, the input- and output

75

oriented FDH models (4.3) improve the discrimination power by differentiating between FDHefficient DMUs. Similarly, it is possible to increase the discrimination power between FDH-inefficient DMUs by the following formulations when focusing on the inefficient FDH frontiers (4.4):
in-FDH o SF (Xo , Yo )

= max { j + (1sj+ + 1sj- )|j Xj - sj- = j Xo (j  o); j Yj + sj+
jo

= j Yo (j  o);  j = 1 ; j  0(j  o)}
jo out-FDH o SF (Xo , Yo )

(4.4)

= min { j + (1sj+ + 1sj- )|j Xj - sj- = j Xo (j  o); j Yj + sj+
jo

= j Yo (j  o);  j = 1 ; j  0(j  o) }
jo

- - ( ,  )  1 and   In the above formulations,    ( ,  )  1 if the units 

are

classified

as

strongly

(weakly)

FDH-inefficient,

whereas

-    ( ,  ) 

-   - ( ,  ) > 1 and  - ( ,  ) < 1  ( ,  ) remain unchanged when  

with respect to models (4.2) (i.e., non-FDH-inefficient DMUs). The super-efficiency model under the VRS assumption may be infeasible when there are some efficient DMUs under evaluation. A number of studies have attempted to resolve the infeasibility problem of the super-efficiency model (see, e.g., Lovell [108]; Lee and Zhu, [111]; Lee et al. [110]; Pourmahmoud et al. [153]). In the next section, models are developed to address the infeasibility problem of the super-efficiency measure in models (4.3) and (4.4). 76

4.4. Dual super-efficiency FDH models without infeasibility
In this regard, the concept introduced by Lee et al. [110] and Cook et al. [49] is considered. For the simplicity and understandability of the extension, models (3.11) and (3.14) can be considered without adding the slacks and the linearization versions. Firstly focusing on the optimistic DEA models (3.11), in the initial stage, the following model is solved to identify potential output surpluses in the efficient DMUo against the frontier constructed by the remaining DMUs [110]: (Xo , Yo ) Lin-FDH o = min { r |  j Yj  (1 - r )Yo ;  j = 1 ; j = {0,1}(j  o); r  0 }
r jo jo

(4.5)

 where  , r=1,...,s are the optimal solutions. The input-oriented model (3.11) (or the input oriented model (4.3)) is feasible if and only if  = 0 for all outputs in model (4.5). The input-

oriented FDH super-efficiency model from the optimistic viewpoint is then formulated as follows:
in-FDH (X SFo o , Yo )

(4.6) = min {|  j Xj  Xo ;  j Yj  (1 -  r )Yo ;  j = 1 ; j = {0,1}(j  o) }
jo jo jo

Next, the input-oriented FDH super-efficiency score from the optimistic viewpoint can be defined as:

77

yro rR ( ) yro -  r yro  +  , if R   ={ |R|  , if R = 

(4.7)

 where  = {|  > 0}1. According to model (4.5),  is the optimal solution of model (4.6) and

|R| is the cardinality of set R. Equation (4.7) shows that the super-efficiency score of (4.6) equals the input-oriented FDH model (4.3) when   =  for all outputs. Analogously, the following model can be solved to obtain potential input savings in the efficient DMUo against the frontier constructed by the remaining DMUs [110]: (Xo , Yo ) Lout-FDH o (4.8) = min { i |  j Xj  (1 + i )Xo ;  j = 1 ; j = {0,1}(j  o); i  0 }
i jo jo

where  , i=1,...,m are the optimal solutions. The output-oriented model (4.3) is feasible if and only if  = 0 for all inputs in model (4.7). The output-oriented FDH super-efficiency model from the optimistic viewpoint can be expressed as follows:
out-FDH (X SFo o , Yo )

= max {|  j Xj  (1 +  i )X o ;  j Yj  Yo ;  j = 1 ; j = {0,1}(j  o) }
jo jo jo

(4.9)

, from In the same manner, the output-oriented FDH super-efficiency score, denoted by  the optimistic viewpoint is defined as:

78

x +  i xio iI ( io ) 1 xio 1 +  , if I   |I|  =   1 if I =  {  ,

(4.10)

where  = {| > 0} according to model (4.8), where  is the optimal solution of model (4.9) and |I| is the cardinality of set I. To address the infeasibility issue, the pessimistic DEA models (3.14) are now focused on. In this manner, the input-oriented FDH super-efficiency model from the pessimistic viewpoint is established as
in-FDH (X o SF o , Yo )

= max {|  j Xj  Xo ;  j Yj  (1 +  r )Yo ;  j = 1 ; j = {0,1}(j  o) }
j jo jo

(4.11)

 where  , r=1,...,s are the optimal solutions of the following model:

in-FDH (Xo , Yo ) L o (4.12) = min { r |  j Yj  (1 + r )Yo ; ;  j = 1 ; j = {0,1}(j  o); r  0}
r jo jo  The input-oriented model (4.4) is feasible if and only if  = 0 for all outputs in model

(4.5). The input-oriented FDH super-efficiency score can be defined from the pessimistic viewpoint as: y +  r yro rR ( ro ) 1 1 yro +  , if R   ={  |R|    , if R = 

(4.13)

 where  = {| > 0} according to model (4.12), where   is the optimal solution of model

79

(4.12) and |R| is the cardinality of set R. Regarding the output-oriented FDH super-efficiency model, the following model is proposed, which can be solved for DMUo:
out-FDH (X o SF o , Yo )

= min {|  j Xj  (1 -
jo

 i )X o ;  j Yj jo

(4.14)  Yo ;  j = 1 ; j = {0,1}(j  o) }
jo

where  , i=1,...,m are the optimal solutions of the following model:

out-FDH (Xo , Yo ) L o (4.15) = min { i |  j Xj  (1 - i )Xo ;  j = 1 ; j = {0,1}(j  o); i  0 }
i jo jo

The output-oriented model (4.4) is feasible if and only if  = 0 for all inputs in model (4.7). From the optimistic viewpoint, the output-oriented FDH super-efficiency score, denoted , can be defined as by  xio iI ( ) xio -  i xio  +  , if I   ={ |I|  , if I = 

(4.16)

where  = {| > 0}, according to model (4.15), where   is the optimal solution of model (4.14) and |I| is the cardinality of set I.

4.5. Empirical illustration
This case study considers the performance of 15 cities in the US. The dataset is taken from 80

Chen [129] and was also used by Chen [48], where each city has three inputs: (I1) high-end housing price (1,000 US$), (I2) lower-end monthly housing rental (US$), and (I3) number of violent crimes, and three outputs: (O1) median household income (US$), (O2) number of individuals with a bachelor's degree (million), and (O3) number of doctors (thousand). The objective of this study is to use these interrelated inputs and outputs factors to evaluate the quality of living in the 15 US cities listed. The input-output dataset is shown in Table 4.2. First, the performance evaluation of the input- and output-oriented FDH models (4.1) from the optimistic viewpoint is studied, as reported in the second and third columns of Table 4.3. Table 4.2 Input and output data of 15 cities (DMUs) Input 1 Input 2 Input 3 Output 1 Output 2 DMU City Housing price 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Seattle Denver Philadelphia Minneapolis Raleigh St Louis Cincinnati Washington Pittsburgh Dallas Atlanta Baltimore Boston Milwaukee Nashville 586 475 201 299 318 265 467 583 347 296 600 575 351 283 431 Rental price 581 558 600 609 613 558 580 625 535 650 740 775 888 727 695 Violent crimes 1193.06 1131.64 3468 1340.55 634.7 657.5 882.4 3286.7 917.04 3714.3 2963.1 3240.75 2197.12 778.35 1245.75 Household Bachelor's income 46928 42879 43576 45673 40990 39079 38455 54291 34534 41984 43249 43291 46444 41841 40221 degree 0.6534 0.5529 1.135 0.729 0.319 0.515 0.3184 1.7158 0.4512 1.2195 0.9205 0.5825 1.04 0.321 0.2365 9.878 5.301 18.2 7.209 4.94 8.5 4.48 15.41 8.784 8.82 7.805 10.05 18.208 4.665 3.575

Output 3 Doctors

81

Table 4.3 Results for the input- and output-oriented FHDs from optimistic and pessimistic viewpoints
Optimistic DMU input-oriented model (4.1) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 1 1 1 1 1 1 0.962 1 1 1 1 1 1 1 0.882 Optimistic output-oriented model (4.1) 1 1 1 1 1 1 1.016 1 1 1 1 1 1 1 1.019 Pessimistic input- Pessimistic outputoriented model (4.2) 1 1 1 1 1.133 1.039 1 1 1 1 1 1 1 1 1 oriented model (4.2) 1 1 1 1 0.981 0.984 1 1 1 1 1 1 1 1 1

Apart from Cincinnati and Nashville (DMUs 7 and 15), all the cities are classified as FDHefficient, implying that there is no discrimination in 87% of the cities. Then, the performance of the cities from the pessimistic viewpoint is evaluated to provide further insight. In doing so, the input- and output-oriented FDH models (4.2) are solved to assess the cities in terms of the inefficient FDH frontiers, as presented in the fourth and fifth columns of Table 4.3. The results for Raleigh and St. Louis (DMUs 5 and 6) indicate that they can be considered as non-FDH-inefficient, whereas the remaining cities are FDH-inefficient with a weak discrimination. Models (4.1) and (4.2) indicate that the DMUs {1, 2, 3, 4, 8, 9, 10, 11, 12, 13, and 14} are simultaneously located on the efficient and inefficient frontiers. To improve the discrimination power, the super-efficiency 82

measures are obtained by dint of models (4.3) and (4.4). The second and third columns of Table 4.4 show the super-efficiency measures of the DMUs from the optimistic viewpoint, and the fourth and fifth columns show the super-efficiency measures of the DMUs from the pessimistic viewpoint.

Table 4.4 Results of the super-efficiency measures Optimistic input- Optimistic output- Pessimistic inputDMU oriented model (4.3) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 2.756 1.185 Infeasible 1.639 1.783 2.212 0.962 Infeasible 1.690 1.971 1.110 1.015 Infeasible 1.679 0.882 oriented model (4.3) 0.789 0.911 Infeasible 0.707 Infeasible Infeasible 1.016 0.427 Infeasible 0.931 0.793 0.846 0.469 0.934 1.019 oriented model (4.4) 0.811 0.908 0.935 0.930 1.134 1.040 Infeasible 0.987 Infeasible 0.336 0.421 0.385 0.873 0.956 Infeasible

Pessimistic output-oriented model (4.4) 1.411 1.668 1.075 1.264 0.981 0.984 2.209 Infeasible 1.165 Infeasible Infeasible Infeasible Infeasible 2.159 2.818

As expected and discussed in Section 4.2, the infeasibility issue occurs in a number of units. There are three, four, three, and five infeasibility cases for the input- and output-oriented models (4.3) and (4.4), respectively, as shown in Table 4.4. The infeasibility in the case of the

83

VRS super-efficiency is central to the DEA literature and has been the topic of considerable discussion in the conventional DEA models, as discussed in chapter 2. To address the infeasibility problem from the optimistic perspective, models (4.5) and (4.6) are applied for the input orientation, and models (4.8) and (4.9) for the output orientation. The results are reported in Table 4.5. Table 4.5 Results of the modified super-efficiency measures from the optimistic viewpoint
Input-oriented DMU 1 1 2 3 4 5 0 0 0 0 0 Model (4.5) 2 0 0 0.0837 0 0 3 0 0 0 0 0 Model (4.6) 2.7548 1.1846 1.7463 (2.8376) 1.639 1.783
Rank

Output-oriented Model (4.8) 1 0 0 0.3184 0 0 2 0 0 0 0 0 3 0 0 0 0 0.0359 Model (4.9) 0.7882 0.9114 0.4537 (0.2839) 0.7064 0.9534 (0.4968) 0.5812 (0.3889) 1.0162 0.4249 0.9677 (0.5024) 0.9307 0.7920 0.8458 0.4668 0.934 1.0191
Rank

2 11 1 10 7 5 14 4 8 6 12 13 3 9 15

8 11 1 7 5 2 14 3 6 12 9 10 4 13 15

6 7 8

0 0 0.1974

0 0 0.3385

0 0 0

2.2113 0.9621 1.0552 (2.4340) 1.6888 1.9696 1.1092 1.0142 1.5784 (2.6115) 1.6784 0.882

0.2 0 0

0.0986 0 0

0 0 0

9 10 11 12 13 14 15

0 0 0 0 0.0618 0 0

0 0 0 0 0 0 0

0 0 0 0 0.0004 0 0

0 0 0 0 0 0 0

0.043 0 0 0 0 0 0

0 0 0 0 0 0 0

84

A positive value of  indicates infeasibility, and a  of zero guarantees feasibility. For example, when evaluating DMU 1, model (4.5) or model (4.8) yields a zero value for all  s that guarantee the feasibility of the input- or output-oriented model (4.3), whereas when evaluating DMU 3, the input-oriented model (4.3) is infeasible due to 2 = 0.0837 in model (4.5). The modified input-and output-oriented FDH super-efficiency score in the infeasibility cases is recalculated using Equations (4.7) and (4.10), respectively, as shown in the parentheses in Table 4.5. An explanation of the calculation process of Equations (4.7) for DMU 3 is as follows. First, set R
 is defined as R = {2|2 > 0}, which indicates that   . Second, the following formulation is

considered:

(

() ) () - () ()

||

+

( ) .-(,)(.)  (o2) = ||

.

+ 1.7463 = 2.8376

Therefore, the modified FDH super-efficiency score for DMU 3 is 2.8376, in lieu of 1.7463. Finally, the complete ranking of the cities can be provided, based on the super-efficiency measures for the input and output orientations from the optimistic perspective, as presented in Table 4.5. This leads to a strong discrimination power compared to the earlier results from model (4.1) in both the input and output orientations. Accordingly, DMU 3 is the most superior city, whereas DMU 15 is the most inferior city in both the input and output orientations. DMUs 7 and 15 (Cincinnati and Nashville, respectively), which are inefficient FDH cities in terms of model (4.1), occupy the two last positions in the ranking order in Table 4.5. Similarly, for the inefficient frontier (pessimistic perspective), models (4.11) and (4.12) are applied for the input orientation and models (4.14) and (4.15) for the output orientation to improve the discrimination power. The results and ranking orders are shown in Table 4.6. 85

Table 4.6 Results of the modified super-efficiency measures from the pessimistic viewpoint
Input-oriented
DMU 1 1 2 3 4 5 6 7 0 0 0 0 0 0 0.0459 Model (4.12) 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 Model (4.11) 0.8106 0.9074 0.9345 0.9293 1.1338 1.0394 0.92290 (0.4696) 0.9860 0.96220 (0.4645) 0.3354 Model (4.15) Rank 9 7 5 6 1 2 11 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0

Output-oriented
Model (4.14) 1.4088 1.6649 1.0744 1.2627 0.9812 0.9840 2.2049 0.7974 (1.8114) 1.1647 1.1395 (2.2856) 1.2876 (2.3311) 1.5803 (2.6508) 0.9321 (2.0780) 2.1543 2.8112 Rank 6 7 3 5 1 2 11

8

0

0

0

3

0.0137

0

0.014

8

9

0.1135

0

0

12

0

0

0

4

10

0

0

0

15

0

0

0.1275

12

11

0

0

0

0.4204

13

0.0417

0

0

13

12

0

0

0

0.3844

14

0

0.0452

0.0857

14

13 14 15

0 0 0

0 0 0.3463

0 0 0.2531

0.8727 0.9560 0.7083 (0.4735)

8 4 10

0 0 0

0.1273 0 0

0 0 0

9 10 15

The positive value of  in Table 4.6 shows the infeasibility problem for the DMU under evaluation, while  = 0 for all the corresponding factors provides the feasibility condition. Model (4.12) is feasible for all cities, but when   0, the super-efficiency measure must be modified

86

using Equations (4.14) and (4.16), as reported in the parentheses in Table 4.6. As noted above, DMUs 5 and 6 are classified as non-FDH-inefficient (see Table 4.3), and their ranks of 1st and 2nd cannot demonstrate the goodness of performance. In other words, the purpose of the pessimistic perspective is to seek the DMUs that lie on the inefficient frontier (pessimistic perspective), and, due to the high number of FDH-inefficient units, the super-efficiency score is used to find the worst cities. According to the input and output orientations, DMUs 7, 9, 10, 11, 12 and 15 are the six worst cities with respect to the pessimistic viewpoint. Next, the method presented here is compared with the results of four existing methods in the literature. Wang et al. [123] proposed a pair of limited DEA models using the pessimistic efficiency for an ideal DMU as an upper limit and an efficiency of unity as a lower limit, to obtain the interval efficiencies. Wang and Yang [90] formulated a pair of limited DEA models using the optimistic efficiency of an anti-ideal DMU as the lower limit and an efficiency of unity as the upper limit to attain an interval efficiency. Azizi and Ajirlu [128] considered an efficiency of unity as an upper limit and the ratio of the optimistic efficiency of an anti-ideal DMU versus the pessimistic efficiency of an ideal DMU as a lower limit to measure the interval efficiency. To provide the ranking order of the DMUs, the midpoint of the interval efficiency for four methods is considered, as presented in Table 4.7. In order to compare the results of this study, it was decided to use the Spearman rank correlation model. It is a statistical model used for the ranking of two variables in order to assess how good the relationship between these variables is, and it can be described as using a monotonic function. To this end, the utilization of Spearman's rank correlation method is shown in Table 4.8. The Spearman correlation values presented in Table 4.8 indicate the correlation between two

87

different methods; the closer the correlation value to 1, the stronger the correlation between the ranking evaluations of represented approaches. It should be noted that these results are based on the FDH, whereas the four remaining methods are based on the CRS assumption. Consequently, the association between the techniques would be considered as statistically significant.

88

Table 4.7 Comparison of the results obtained from the four methods in the literature
DMU Wang and Yang (2007) Efficiency score 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 0.784 0.779 0.769 0.821 0.775 0.807 0.698 0.809 0.753 0.685 0.596 0.584 0.717 0.725 0.630 Rank 4 5 7 1 6 3 11 2 8 12 14 15 10 9 13 Azizi and Ajirlu (2010) Efficiency score 0.635 0.630 0.638 0.669 0.649 0.661 0.574 0.657 0.626 0.579 0.481 0.468 0.627 0.625 0.515 Rank 6 7 5 1 4 2 12 3 9 11 14 15 8 10 13 Wang et al. (2008) Efficiency score 1.553 1.539 1.510 1.615 1.515 1.585 1.378 1.602 1.471 1.338 1.173 1.150 1.381 1.391 1.238 Rank 4 5 7 1 6 3 11 2 8 12 14 15 10 9 13 Chen (2014) Efficiency score 0.512 0.501 0.513 0.516 0.514 0.515 0.458 0.515 0.492 0.466 0.365 0.353 0.512 0.509 0.399 Rank 6 9 5 1 4 2 12 3 10 11 14 15 7 8 13

89

Table 4.8 Spearman's rank correlation
Model (4.6) Model (4.6) Model (4.9) Model (4.11) Model (4.14) Wang and Yang (2007) Azizi and Ajirlu (2010) Wang et al. (2008) Chen (2014) 1 Model (4.9) 0.76 1 Model (4.11) 0.539 0.539 1 Model (4.14) 0.736 0.736 0.689 1 Wang and Yang (2007) 0.514 0.561 0.732 0.775 1 Azizi and Ajirlu (2010) 0.614 0.703 0.793 0.842 0.953 1 Wang et al. (2008) 0.514 0.561 0.732 0.775 1 0.953 1 Chen (2014) 0.646 0.696 0.828 0.804 0.918 0.982 0.918 1

90

4.6. Summary and conclusion
After proposing the fundamental optimistic and pessimistic FDH models in chapter 3, it was noticed that these models lack strong discrimination power between DMUs. Thus, slack-based FDH models and super-efficiency FDH models were developed from both optimistic and pessimistic perspectives to overcome the discrimination power issue in chapter 4. To improve the discrimination power, the models were formulated in the presence of the slacks to enable the evaluator to classify the DMUs into different groups. Furthermore, an optimistic super-efficiency FDH model and pessimistic super-efficiency FDH model were developed to achieve better discrimination between DMUs. Although these models yielded full discrimination, infeasibility may occur in some cases. To deal with the infeasibility problem, the FDH super-efficiency models related to the optimistic and pessimistic FDH were modified in both input and output orientations. Chapter 4 also presented a numerical example to elucidate the details of the proposed models as well as to compare final ranking results with four other existing models in the literature. By using Spearman's rank correlation method, a strong statistical correlation was identified between the models presented in this study and the models in the literature.

91

Chapter 5: Optimistic and Pessimistic DEA Model with Virtual DMUs

92

5.1.Introduction
In this chapter of the study, the focus is shifted to the eighth category of the DEA ranking method, which is the virtual DMU category discussed in Section 2.3.8. This approach is considered a post-analysis approach and will be used to improve the optimistic and pessimistic models that were discussed in chapter 3. This chapter will present an improved optimistic and pessimistic methodology that incorporates the virtual DMU approach. The model presented in this chapter differs from other models in the literature by providing an unbiased evaluation when virtual DMUs are applied in the assessment process.

5.2. Improved optimistic and pessimistic methods using virtual DMUs
This section suggests a new method for ranking that combines both the optimistic and pessimistic approaches, with the introduction of virtual units to the data. The method is discussed in detail in the following subsections. Also, an illustrative example will follow in Section 5.3 to show how the new model is able to reach full ranking. 5.2.1. Optimistic model with superstar virtual DMU The standard DEA model is considered as an optimistic approach to rank all DMUs based on using the efficient frontier, so all units located on the efficiency frontier will be considered as efficient DMUs or optimistically efficient DMUs. Model (5.1) shows the basic linear CCR program, where  is the efficiency score of DMUk under assessment [1]:

93

max  = 1 1 + 2 2 + ... +   Subject to: 1 1 + 2 2 + ... +   = 1 1 1 + 2 2 + ... +    1 1 + 2 2 + ... +   ( = 1, ... , ) 1 , 2 , ... ,   0 1 , 2 , ... ,   0 (5.1)

In model (5.1), the x's and the y's represent the values of the inputs and the outputs respectively associated for each DMU while the u's are defined as the virtual weights assigned to each output in the data, and the v's are defined as the virtual weights assigned to each input in the data. So for any DMUk , the DMU could be considered to be efficient if k was able to obtain a value of 1 [16]. The CCR model is also known as the optimistic model, or best relative efficiency model. Based on the CCR model, the score of all efficient DMUs will be equal to 1. In order to limit the ability of achieving a full score to only very efficient DMUs and for better envelopment to the dataset under assessment, it is proposed to introduce a superstar virtual unit, noted as DMUsuper. The super DMU is defined as a DMU that has the best output from all units in the dataset, and has the minimum input from all units in the dataset. So if there are n units to be evaluated in the dataset with m inputs and s outputs, then the value index for the input and output of that super virtual DMU that does not belong to the existing data is as follows: , =  ( 1 , 2 , 3 , ... . ,  )  = (1, 2, ... , ) , =  ( 1 , 2 , 3 , ... . ,  )  = (1, 2, ... , ) (5.2)

94

After the introduction of the super DMU, the optimistic model to compute the efficiency score of any DMUk will be exactly like model (5.1), except that k = 1, ... , n+1.The major advantage of introducing the virtual superstar DMU is that super DMU will help in eliminating more DMUs from the efficiency frontier, which means better discrimination power. According to Entani et al. [86], any approach that considers only the optimistic approach to evaluate the dataset will be considered biased. Therefore, a pessimistic approach is introduced and included in the model.

5.2.2. Pessimistic model with worst virtual DMU The optimistic approach of DEA is an approach that measures the efficiency of any DMU within a range between 0 and 1. The conventional CCR model is an example of the optimistic approach, where all units are trying to optimize the maximum score of 1. On the other hand, the pessimistic approach is an approach that focuses on creating an inefficient frontier, and ranks all DMUs according to that frontier. A minimization program is set and the inefficient DMUs will achieve the score of 1. The fractional program of the pessimistic approach is similar to the optimistic model, except that it is a minimization problem, and all constraints should be greater or equal to 1. So for any DMUk, the fractional pessimistic model will be as follows [85]:
   =

1 1 + 2 2 + ... +   1 1 + 2 2 + ... +  

subject to: 1 1 + 2 2 + ... +   1 1 1 + 2 2 + ... +   1 , 2 , ... ,   0 1 , 2 , ... ,   0 ( = 1 ... , ) (5.3)

95

In this proposal, it is suggested introducing the worst virtual DMU, DMUworst, which is defined as a DMU that has the maximum inputs from all units in the dataset and has the minimum outputs from all units in the dataset. So if there are n units to be evaluated in the dataset, with m inputs and s outputs, then the value index for the input and output of that worst virtual DMU that does not belong to the current dataset is as follows: , =  ( 1 , 2 , 3 , ... . ,  )  = (1, 2, ... , ) , =  ( 1 , 2 , 3 , ... . ,  )  = (1, 2, ... , ) (5.4)

Thus, for any DMUk, the efficiency score with the worst DMU under the pessimistic approach can be calculated as follows:
   = 1 1 + 2 2 + ... +  

Subject to: 1 1 + 2 2 + ... +   = 1 1 1 + 2 2 + ... +    1 1 + 2 2 + ... +   ( = 1, ... ,  + 1) 1 , 2 , ... ,   0 1 , 2 , ... ,   0 (5.5)

As mentioned, the pessimistic approach assigns a score of 1 to all inefficient units that are located on the inefficiency line. However, it is important to note that the pessimistic approach has no restriction on the efficiency scores achieved by the efficient units, and all DMUs are ranked in descending order from the top score to 1.

96

5.2.3. Combining optimistic and pessimistic approaches Both proposed models in subsections 5.2.1 and 5.2.2 will yield better ranking power for the DEA standard model, because the introduction of the virtual DMUs will prevent many DMUs from achieving the full efficiency score, as these virtual DMUs will change the frontier lines and allow more envelopment to all units in the data under assessment. But, as proved by Entani et al. [86], it is biased to use one model over the other one, even though using both models brings better discrimination power. Therefore, combining both models is an important step to reach an unbiased evaluation, and one way to combine both pessimistic and optimistic approaches is to take the geometric average of both scores. Detailed theorem and proof of this were provided in the work of Wang et al. [31], who suggested using the geometric average between the pessimistic and optimistic scores of each DMU and ranking all DMUs, accordingly. This chapter critiques the direct use of the pessimistic approach because the pessimistic approach could yield high scores of efficient units, while their optimistic scores are limited to only 1. In this model, it is suggested to use the DEA index number (AIN) to rescale the scores of all efficient units under the pessimistic approach. The AIN will restrict the scores of units under the pessimistic approach to 1-2. This index was used for the same purpose in the super-efficiency method by Sueyoshi [25]. The AIN index should be applied to the pessimistic approach as follows:
   = 1 + { }  -    

 -  

,  = 1, ... , 

(5.6)

So, applying the optimistic approach with the super-virtual DMU is considered as a first stage in this model. Applying the pessimistic approach with the worst virtual DMU, and rescaling the results by using the AIN index, is the second stage. The final score for DMUk is

97

calculated by using the arithmetic average of both scores, and it will range between 0.5 and 1.5. The final score can be calculated as follows: 


=

  +  2

(5.7)

We believe that the new proposed method provides better ranking for two reasons. First, by introducing the super and worst virtual DMUs, the model envelops more data with a distinctive score for every DMU. In other words, a limited number of DMUs will achieve equal scores under either the optimistic or the pessimistic approach. Second, the previous models in the literature that combined the pessimistic and optimistic approaches directly, without adjusting the pessimistic scores, could be biased, because the optimistic approach is limited to 1 or less, while there is no limitation on the pessimistic scores.

5.3. Illustrative example
In order to illustrate the above formulations with the new proposed model, the example discussed in chapter 2 is considered, of evaluating eight graduate students according to their GPA and their number of publications. The GPA will be considered as the first output and the number of publications will be considered as the second output. With the assumption that all students are at exactly the same level of study and have equal capability, each student will have one input with a score of 1. The raw data of the example are shown in Table 2.1. After applying the three steps, all the results of the CCR model, the Wang et al. model, and the new proposed model are shown in Table 5.1. The CCR models displaying its lack of discrimination is shown in the 2nd and 3rd columns. Columns 4-8 show the first two steps of the

98

proposed model. The last four columns compare the final score of the proposed model with the efficiency scores of the Wang et al. [31] model.

Table 5.1 Comparison results of the proposed model with CCR and Wang et al. model
Original CCR model Student A B C D E F G H Score 1.00 0.86 1.00 1.00 0.74 1.00 0.79 0.68 Rank 1 5 1 1 7 1 6 8 Optimistic with DMUsuper ( ) Score 1.00 0.84 0.95 1.00 0.74 1.00 0.79 0.68 Rank 1 5 4 1 7 1 6 8 Pessimistic with DMUworst (  ) Score 1.00 1.57 1.86 1.00 1.29 2.00 1.00 1.14 Rank 6 3 2 6 4 1 6 5 Proposed new Wang et al. model Score 1.00 1.04 1.19 1.00 0.88 1.21 0.89 0.83 Rank 4 3 2 4 7 1 6 8 model ( Score 1.00 1.21 1.40 1.00 1.01 1.50 0.89 0.91


)

Rank 5 3 2 5 4 1 8 7

It is observed from the table that the final score brought better discrimination between all DMUs in data except for students A and D. These two students are the outlier units in the data, and both are observed as efficient under the optimistic approach, with a score of 1, and at the same time, both are considered inefficient, with a score of 1 under the pessimistic approach. This behavior is very common in any dataset that has joint DMUs that connect both frontiers, and will be a score of 1 in this model. Figure 5.1 shows the location of the students on efficient and inefficient frontiers. The dashed lines show the original efficiency and inefficiency frontiers, while the dotted lines show the new frontiers with virtual super and worst DMUs. Similar to Chapter 4, the correlation between the proposed model and the model of Wang et al. [31] is shownthrough Spearman's correlation index. After applying the index formula, we found that 81% of the times 99

our models can match the ranking of Wang et al. [31] which is considered a fairly strong correlation.

Figure 5.1 New optimistic and pessimistic frontiers for graduate students' example

In the student example, more than one DMU achieved similar scores under pessimistic and optimistic approaches. This equality between DMUs was caused by using two-dimensional data. In order to show the discrimination power of the proposed model, another example of multiple inputs and multiple outputs is provided. In this example 12 bank branches are considered for evaluation based on three outputs which are all monetary gains for each branch: (O1) Interest per saving, (O2) Interest per loan, and (O3) Non-interest income, while the inputs are mixed between labor force (I1) and operating cost (I2) for each branch. This example shows the advantage of DEA ranking since different schemes with different criteria can be used and considered without weights 100

assignment in the evaluation process. The raw data of 12 bank branches are provided in Table 5.2 for detailed clarification [154]. Table 5.4 shows the results of the original CCR model, which has three full efficient DMUs, while the model proposed provides a complete full ranking of all DMUs. Moreover, this example shows that the ranking of all efficient DMUs under the geometric average method depends entirely on the ranking scheme of the pessimistic approach.

101

Table 5.2 Raw data for bank branches evaluation
Input Operating cost 829,326 342,554 262,008 301,114 244,918 326,759 269,277 288,521 165,573 218,150 132,788 924,037 Interest earned per saving 4,449,202 1,020,605 861,443 4,022,446 400,783 3,056,784 1,634,220 1,232,645 445,955 536,914 229,635 4,879,496 Output Interest earned per loan 4,786,608 1,686,859 1,516,144 6,491,851 654,434 1,994,946 2,291,636 1,788,427 904,764 1,036,494 387,528 8,471,185 Noninterest income 1,000,188 307,375 426,604 1,152,494 407,243 1,055,240 1,083,105 1,001,151 462,190 545,877 160,227 470,160

Branch

Employees

1 2 3 4 5 6 7 8 9 10 11 12

20 7 7 11 9 6 7 6 4 6 3 23

Table 5.3 Comparison results of the proposed model with CCR and Wang et al. [154]
Original CCR Branch model Score Rank Optimistic with DMUsuper ( ) Score Rank Pessimistic with DMUworst (  ) Score Rank Proposed new Wang et al. approach Score Rank approach ( Score


)

Rank

1 2 3 4 5 6 7 8 9 10 11 12

0.512 0.413 0.456 1.000 0.413 1.000 1.000 0.997 0.729 0.622 0.342 0.624

8 11 9 1 10 1 1 4 5 7 12 6

0.146 0.114 0.188 0.441 0.192 0.458 0.463 0.434 0.322 0.288 0.139 0.144

9 12 8 3 7 2 1 4 5 6 11 10

1.239 1.133 1.346 1.721 1.082 2.000 1.982 1.878 1.471 1.359 1.240 1.000

9 10 7 4 11 1 2 3 5 6 8 12

0.780 0.642 0.790 1.733 0.643 1.992 1.884 1.930 1.095 0.967 0.585 0.790

9 11 7 4 10 1 3 2 5 6 12 8

0.693 0.624 0.767 1.081 0.637 1.229 1.223 1.156 0.896 0.824 0.689 0.572

8 11 7 4 10 1 2 3 5 6 9 12

102

5.4. Summary and conclusion
In this chapter, a new dual frontiers model has been developed. The model uses virtual DMUs integrated with optimistic and pessimistic approaches. The integration was achieved by rescaling the pessimistic scores using the DEA index (AIN) and combining both approaches with the arithmetic average. The new method yielded better discrimination power because the added super and worst virtual DMUs adjust the frontier lines, allowing them to envelop more data. This wider envelopment by itself leads to better ranking power. The main point that has been raised in this chapter is that other models in the DEA literature use the pessimistic approach to avoid bias in the evaluation when the optimistic approach is solely applied, but at the same time, these methods tend to be biased toward the pessimistic approach when it is combined with the optimistic one. The new proposed method in this chapter differs from other methods in the literature by equalizing the weight assigned to both optimistic and pessimistic approaches, by preventing the pessimistic approach from reaching a high score in comparison to the optimistic approach, by applying the DEA index.

103

Chapter 6: Optimistic and Pessimistic FDH Model with Virtual DMUs

104

6.1. Introduction
This chapter can be considered as an extended topic of chapter 5. It proposes a new optimistic and pessimistic model using virtual DMUs, but with a relaxed convexity assumption. In Section 6.2, new optimistic and pessimistic FDH models are developed with the incorporation of virtual DMUs. It is worth mentioning that the virtual DMU approach is a fairly new approach in the literature, but very powerful in terms of bringing better discrimination between DMUs in the dataset. For that reason, it is used as a tool to develop or to extend the optimistic and pessimistic models presented in this dissertation.

This chapter discusses virtual DMU FDH models from both optimistic and pessimistic perspectives. Each prospective output and input-oriented model is presented, in order to deliver a comprehensive study. Section 6.3 shows the applicability of the proposed model, shown in an empirical illustration with application data borrowed from the literature, comparing the new results of the proposed models with other models in the literature.

6.2. Improved optimistic and pessimistic FDH models using virtual DMUs
This section refers to the FDH model of Tulkens [155], which creates a non-convex hull that imposes strong disposability assumptions. To this end, this section proposes an interval FDH for measuring the bounded efficiency, where the upper bound is obtained from the optimistic perspective and the lower bound is obtained from the pessimistic perspective. A three-step framework is proposed for the use of optimistic and pessimistic FDH models. The first step is based on the performance evaluation model proposed in this thesis, and the second step incorporates both optimistic and pessimistic models to create an interval measure based on both 105

approaches to enlarge the envelopment of both frontiers by introducing virtual DMUs. Finally, the upper and lower bounds for each DMU are combined to acquire the overall score required for providing a complete ranking order. In the following subsections, steps 1, 2 and 3 of the proposed method are presented in detail, followed by detailed empirical examples for illustration and literature comparison purposes.

6.2.1. Optimistic and pessimistic FDH (Step1) Although DEA is an estimator based on the assumption that the true production set is convex, the true production set may not be convex in some real-life situations. There are very few models that relax the convexity assumption, and the FDH is the most used non-convex DEA model in the existing literature. As a more general version of the DEA estimator, the FDH model relaxes the convexity while preserving strong disposability and considering the VRS assumption [151]. As a result, abolishing convexity leads to frontiers that have "staircase" shapes with much lower rates of convergence than conventional DEA. As discussed in chapter 3, the FDH input and output efficiency scores for a given observation ( ,  ) can be expressed as [151]:
-  ( ,  ) =  {|( ,  )    }  -  ( ,  ) =  {|( ,  )    } 

(6.1)

where

  = {(, )|      ;        ;   = 1 ;  = {0,1} }

and

the

distance between the frontier and observation ( ,  ) is measured in terms of Equation (6.1) in the input and output spaces. Thus, the efficiency score of DMUo is determined by calculating the factor  from either the input or output orientation as follows:

106

-  ( ,  ) =   

 =1      ;

 = 1,2, ... , ,

 =1     ;  = 1,2, ... , ,   = 1 ;  = {0,1} ;
- (    ,   ) =  

(6.2)  = 1,2, ... , .

 =1     ;

 = 1,2, ... ,  (6.3)

 =1      ;  = 1,2, ... , ,   = 1 ;  = {0,1} ;  = 1,2, ... , .

The above programs are integer programming models resulting from integral variables  . It is worth mentioning that FDH programs (6.2) and (6.3) are identical to the VRS-DEA model,
  thus,    means that the FDH efficiency estimate is higher than the VRS efficiency  

estimate. By solving both programs (6.2) and (6.3), the convexity constraint   = 1 requires one intensity variable  with a value of 1. This method seeks a comprehensive measure that integrates both optimistic and pessimistic viewpoints. Therefore, an inefficient non-convex frontier from the observations is indicated, to represent the worst possible performance. The empirical PPS estimating the non-convex inefficient   can be expressed in a manner contrary to   by flipping the inequality frontier    can be represented as follows: constraints. Thus, for any n observations ( ,   ) j=1,2,...,n,    = {(, )|      ;         ;   = 1 ;  = {0,1} }
  

(6.4)

107

In other words, in any output PPS, the inefficient frontier can be considered to be a nonconvex hull derived from the minimum output level, given a fixed input level for which output levels less than the frontier value cannot be produced. Similarly, from the input space, the inefficient frontier is a non-convex hull obtained from the maximum input level, given a fixed output level for which input levels greater than the frontier value cannot be consumed. Thus,   from the input and output perspectives can be similar to Equation (6.1), the non-convex PPS  defined as [151]: - ( ,  ) =  {: ( ,  )     }  - ( ,  ) =  {: ( ,  )     }  Based on model (6.5), equivalently: - ( ,  ) =     =1      ;  = 1,2, ... , , (6.6)  =1     ;  = 1,2, ... , ,   = 1 ;  = {0,1} ; - ( ,  ) =     =1     ;  = 1,2, ... , , (6.7)  =1      ;  = 1,2, ... , ,   = 1 ;  = {0,1} ;  = 1,2, ... , .  = 1,2, ... , . (6.5)

- and  - in the previous model are to measure the The primary functions of  extent to which the levels of outputs and inputs for any given DMUo can be increased and decreased proportionally with the inefficient frontier while remaining in the PPS. Similar to the

108

- = optimistic approach, if a DMUo under assessment lies on the inefficient frontier, where  - = 1), then it is inefficient; otherwise, it is not inefficient. 1 ( In general, integer programming problems are more difficult and time consuming to solve than linear programming problems, due to a lack of duality and simplex algorithms. To solve models (6.2), (6.3), (6.6), and, (6.7), the equivalent FDH linear program introduced by Agrell and Tind [105] must be relied on to address the computational complexity of large problems. In doing so, the upper limit of the interval efficiency of DMUo, in terms of the input and output spaces, can be solved using the following linear programs:
 -  ( ,  ) 

(6.8)

=   
=1

     ;

 = 1,2, ... , ;  = 1,2, ... , ,

     ;  = 1,2, ... , ;  = 1,2, ... , ,   = 1 ;   0 ;
 - (    ,   ) =  =1 

 = 1,2, ... , .

(6.9)  = 1,2, ... , ;  = 1,2, ... , ,

     ;

     ;  = 1,2, ... , , ;  = 1,2, ... , ,   = 1 ;   0 ;  = 1,2, ... , .

Similarly, the lower limit of the interval efficiency of DMUo in terms of the input and output spaces can be solved using the following linear programs:


- ( ,  ) =    
=1

(6.10)  = 1,2, ... , ;  = 1,2, ... , , 109

     ;

     ;  = 1,2, ... , ;  = 1,2, ... , ,   = 1 ;   0 ; - ( ,  ) =    =1       ;  = 1,2, ... , ;  = 1,2, ... , , (6.11)  = 1,2, ... , .

     ;  = 1,2, ... , ;  = 1,2, ... , ,   = 1 ;   0 ;  = 1,2, ... , .

The above models are the foundation for the methodology used; it is understood that the pessimistic FDH models (6.10) and (6.11) have not been introduced in the existing literature. In chapter 3 of this thesis, a different representation was introduced, and in this chapter a liner representation is used. To illustrate the difference between conventional DEA and FDH efficient and inefficient frontiers, 10 sales associates who produce two outputs per hour are used: the number of customers served and the number of items sold. Each sales associate is denoted as

Figure 6.1 Optimistic and pessimistic frontiers in CRS and FDH sales associates' example 110

DMU1, DMU2,...,DMU10, and their outputs are [1,8], [2,3], [2,6], [3,3], [4,7], [4,2], [5,5], [5,2], [7,2] and [8,1], respectively, as shown in Figure 6.1.

A conventional CRS DEA with an optimistic viewpoint results in a piecewise line that connects DMU1, DMU5, DMU7, DMU9, and DMU10 as an efficient frontier, while DMU1, DMU2, DMU6, and DMU10 construct an inefficient frontier. From the output orientation perspective, solving both models (6.16) and (6.18) results in FDH efficiency scores from optimistic and pessimistic approaches. Due to the "staircase" shape of efficiency, more DMUs are efficient and obtain a 100% efficiency score from the FDH optimistic perspective. As shown in Figure 6.1, DMU1, DMU5, DMU7, DMU8, DMU9, and DMU10 all lie on the efficient FDH frontier. Similarly, from the pessimistic perspective, more DMUs lie on the inefficient frontier and are considered fully inefficient, with a score of 1. In the example used, DMU1, DMU2, DMU3, DMU4, DMU6, DMU8, DMU9, and DMU10 are all located on the inefficient FDH frontier. Therefore, in the second step, virtual DMUs are introduced to reshape the frontiers from both perspectives to improve the discrimination power and to supply a better ranking order.

6.2.2. Reshaping the FDH frontiers using virtual DMUs (Step2) After developing models (6.8), (6.9), (6.10) and (6.11), the lack of discrimination power between the DMUs being assessed is highlighted. In many cases, the decision maker is looking for a full ranking to make crucial decisions such as allocating resources to the top DMUs or merging the very inefficient DMUs with very efficient DMUs. Thus, to limit the ability of achieving a full score to only very efficient DMUs and to better envelop the dataset under assessment, a super 111

virtual DMU is proposed, denoted as DMUsuper. This super DMU is defined as a DMU that consists of the maximal output and minimal input of all units. If n DMUs with m inputs and s outputs are evaluated, then the input and output values of the super DMU can be defined as follows:

, =  ( 1 , 2 , 3 , ... . ,  ),  = (1, 2, ... , ) , =  ( 1 , 2 , 3 , ... . ,  ),  = (1, 2, ... , ) (6.12)

In general, the introduction of DMUsuper enables the elimination of more DMUs from the efficiency frontier and moves them to the PPS, thus improving the discrimination power. The super DMU acts as an additional observation for the dataset. The upper efficiency bound of DMUs in the presence of DMUsuper can be computed using models (6.13) and (6.14) from both input and output orientations:
 -   ( ,   )

=   
=1

    , ;

 = 1,2, ... , ;  = 1,2, ... , ,  + 1, (6.13)

    , ;  = 1,2, ... , ,  = 1,2, ... , ,  + 1,   = 1 ;   0 ;
 -  ( ,  )

 = 1,2, ... , ,  + 1.

=   
=1

    , ;

 = 1,2, ... , ;  = 1,2, ... , ,  + 1, (6.14)

    , ;  = 1,2, ... , ;  = 1,2, ... , ,  + 1,   = 1 ;   0 ;  = 1,2, ... , ,  + 1. 112

- -  ( ,  ) represent the input- and output-oriented models  ( ,   ) and 

from the optimistic standpoint, respectively. An alternative virtual DMU called the worst DMU is then introduced, denoted by DMUworst; its input and output are computed as: , =  ( 1 , 2 , 3 , ... . ,  ),  = (1, 2, ... , ) , =  ( 1 , 2 , 3 , ... . ,  ),  = (1, 2, ... , ) (6.15)

Similarly, the lower limit of efficiency of the DMUs in the presence of DMU worst can be obtained using the following equations:
 -   ( ,  )

=   
=1

    , ;

 = 1,2, ... , ;  = 1,2, ... , ,  + 1, (6.16)

    , ;  = 1,2, ... , ;  = 1,2, ... , ,  + 1,   = 1 ;   0 ;
-   ( ,  ) =   =1 

 = 1,2, ... , ,  + 1.

    , ;

 = 1,2, ... , ;  = 1,2, ... , ,  + 1,

    , ;  = 1,2, ... , ;  = 1,2, ... , ,  + 1,   = 1 ;   0 ;  = 1,2, ... , ,  + 1. (6.17)

- -  ( ,  ) and  ( ,  ) represent the input- and output-oriented

models, respectively. The consequence of this step in the earlier example is to create a rectangular shape for PPS, using the optimistic and pessimistic frontiers (see Figure 6.2).

113

Figure 6.2 New optimistic and pessimistic FDH frontiers

6.2.3. Interval model of optimistic and pessimistic FDH (Step 3) When considering both frontiers for the overall evaluation results in two different measures for optimistic and pessimistic approaches, both measures are considered from input and output perspectives. One measurement is bounded between 0 and 1, while the other is greater than or equal to 1 and has no upper bound. In other words, the input-oriented FDH scores vary in a range between 0 and 1 from the optimistic perspective, whereas the pessimistic perspective scores are greater than or equal to 1. In contrast, in the output-oriented FDH models, the pessimistic perspective is bounded between 0 and 1, whereas the efficiency from the optimistic perspective is greater than or equal to 1.

114

We use the adjusted DEA index number (AIN) proposed by Sueyoshi [156] to address the above intricacies. For the input-oriented model, the final score of any DMUk under evaluation in the proposed FDH model is calculated as follows:

  =

 +1+(

 - min(  )      )- min(  )) max(    

2

,

 = 1, ... , 

(6.18)

-  are obtained from   - where  and   ( ,   ) in model (6.13) and  ( ,   )

in model (6.16), respectively. However, the final score of any DMUk under evaluation in the proposed FDH model under the output-oriented model is calculated as follows:

 

=

  +1+( 

-     -  

)

2

,

 = 1, ... , 

(6.19)

-  are obtained from  where  and  ( ,  ) in model (6.14) and  -   ( ,  ) in model (6.17), respectively.

6.3. Empirical illustration and results comparison
Using the previous example of the sales associates, the optimistic and pessimistic FDH models were applied to the data. The results of the output-oriented optimistic and pessimistic FDH models are shown in the fourth and fifth columns of Table 6.1. The results show a lack of discrimination power between most DMUs in the dataset, as most are located on the efficiency frontiers, as shown in Figure 6.1. After applying the proposed models, as explained in step 2, the

115

sixth and seventh columns show good discrimination from enlarging the envelopment process, and a full ranking and discrimination is achieved.

116

Table 6.1 Sales associates example ­ data and model comparison
Sales Associates Output 1 Input (Customers served) 1 1 1 1 1 1 1 1 1 1 1 2 2 3 4 4 5 5 7 8 Output 2 (Sales made) 8 3 6 3 7 2 5 2 2 1 Results of the optimistic outputoriented FDH (Model 6.9) 1.00 2.00 1.17 1.67 1.00 1.25 1.00 1.00 1.00 1.00 Results of the pessimistic outputoriented FDH (Model 6.11) 1.00 1.00 1.00 1.00 0.50 1.00 0.60 1.00 1.00 1.00 Optimistic outputoriented model with DMUsuper (Model 6.14) 1.00 2.67 1.33 2.67 1.14 2.00 1.60 1.60 1.14 1.00 Pessimistic outputoriented model with DMUworst (Model 6.17) 1.00 0.50 0.50 0.33 0.25 0.50 0.20 0.50 0.50 1.00

DMU1 DMU2 DMU3 DMU4 DMU5 DMU6 DMU7 DMU8 DMU9 DMU10

117

To illustrate a comprehensive explanation of the methodology and to compare the results with other models in the existing literature, the performance of 31 Chinese provinces is considered. The dataset is taken from the study by Wang et al. [157], where each province has three inputs and one output. Inputs 1 and 2 are the original value of fixed assets and current assets measured in 100 million RMB (Chinese currency), and Input 3 is the number of staff and workers at the end of the year, measured in 10,000 persons. The only output is the gross industrial output value measured in 100 million RMB. The input and output data are shown in Table 6.2. As shown in Table 6.3, only four DMUs achieved efficiency scores that were less than 100% under the optimistic approach, and only five DMUs were not efficient under the pessimistic approach. To resolve this issue of discrimination power, the model is applied to the dataset, and strong or full discrimination was achieved, as shown in Table 6.4 for the input-oriented FDH model and in Table 6.5 for the output-oriented FDH model.

118

Table 6.2 Input and output data of 31 DMUs ­ Wang et al. [157]
DMU DMU1 DMU2 DMU3 DMU4 DMU5 DMU6 DMU7 DMU8 DMU9 DMU10 DMU11 DMU12 DMU13 DMU14 DMU15 DMU16 DMU17 DMU18 DMU19 DMU20 DMU21 DMU22 DMU23 DMU24 DMU25 DMU26 DMU27 DMU28 DMU29 DMU30 DMU31
*

City Beijing Tianjing Hebei Liaoning Shanghai Jiangsu Zhejiang Fujiang Shandong Guangdong Gunagxi Hainan Shanxi* Neimenggu Jilin Heilongjiang Anhui Jiangxi Henan Hubei Hunan Chongqing Sichanuang Guizhou Yunnnan Tibet Shanxi* Gansu Qunghai Ningxia Sinkiang

Input 1 Fixed assets

Input 2 Current assets

Input 3 # Staff and workers

Output 1 Gross industrial

2402.79 2488.6 3532.84 5372.79 5373.06 6181.57 3753.68 2032.18 6297.37 8005.77 1296.41 264.43 2170.68 1385.74 1833.04 3233.51 1880.95 1154.45 3447.01 2989.31 1947.23 1151.58 2917.04 913.15 1409.92 59.58 1730.35 1165.68 505.81 362.21 1387.56

2005.63 1787.41 2000.19 3155.9 4370.38 5499.34 3377.81 1401.27 4076.79 6891.49 684.22 156.7 1221.05 603.7 1291.93 1567.07 1212.57 730.33 2216.51 1941.97 1107.19 865.97 1845.51 676.07 812.81 25.62 1084.49 713.65 223.06 212.73 578.79

113.13 120.19 269.75 295.18 204.94 518.19 323.22 155.55 522.37 572.79 91.25 12 183.56 85.34 134.85 195.17 162.61 108.85 345.2 230.36 166.71 90.79 208 68.34 77.07 2.92 124.98 91.25 15.87 22.41 46.52

2565.38 2606.38 3426.05 4249.46 6204.52 10452.87 6603.65 2616.12 8311.53 12480.93 1003.24 202.87 1216.86 748.97 1679.91 2460.88 1661.44 932.21 3494.96 3064.43 1627.94 962.32 2076.96 631.64 1063.36 16.43 1184.58 840.58 196.08 239.11 852.01

DMU13 and DMU27 are different provinces with similar English names.

119

Table 6.3 Results for the input- and output-oriented dual FDH models
Optimistic inputDMU oriented model (6.8) DMU1 DMU2 DMU3 DMU4 DMU5 DMU6 DMU7 DMU8 DMU9 DMU10 DMU11 DMU12 DMU13 DMU14 DMU15 DMU16 DMU17 DMU18 DMU19 DMU20 DMU21 DMU22 DMU23 DMU24 DMU25 DMU26 DMU27 DMU28 DMU29 DMU30 DMU31 1 1 1 1 1 1 1 1 1 1 1 1 0.9082 1 1 0.8943 1 1 1 1 1 1 0.7594 1 1 1 1 1 0.7562 1 1 Optimistic outputoriented model (6.9) 1 1 1 1 1 1 1 1 1 1 1 1 1.3654 1 1 1.0632 1 1 1 1 1 1 1.2597 1 1 1 1 1 1.0347 1 1 Pessimistic inputoriented model (6.10) 1 1.0326 1 1 1 1 1 1.3171 1 1 1 1.3225 1 1 1 1 1.0071 1 1 1 1.1011 1 1 1 1 1 1 1 1 1 1 Pessimistic outputoriented model (6.11) 1 0.7969 1 1 1 1 1 0.794 1 1 1 0.9666 1 1 1 1 0.7324 1 1 1 0.7475 1 1 1 1 1 1 1 1 1 1

120

Table 6.4 Results of the proposed input-oriented model compared with the Wang et al. [157] model
Input-oriented DMU Optimistic model (6.13) DMU1 DMU2 DMU3 DMU4 DMU5 DMU6 DMU7 DMU8 DMU9 DMU10 DMU11 DMU12 DMU13 DMU14 DMU15 DMU16 DMU17 DMU18 DMU19 DMU20 DMU21 0.027 0.025 0.018 0.012 0.015 0.010 0.017 0.030 0.010 0.007 0.047 0.245 0.029 0.044 0.034 0.019 0.033 0.053 0.018 0.021 0.032 Pessimistic model (6.16) 3.332 3.217 2.124 1.491 1.491 1.107 1.773 3.683 1.098 1.001 6.176 30.276 3.121 5.778 4.248 2.476 3.523 5.263 1.660 2.487 3.436 Pessimistic AIN 1.017 1.017 1.008 1.004 1.004 1.001 1.006 1.020 1.001 1.000 1.039 1.220 1.016 1.036 1.024 1.011 1.019 1.032 1.005 1.011 1.018 Final score model (6.18) 0.522 0.521 0.513 0.508 0.509 0.505 0.511 0.525 0.505 0.504 0.543 0.732 0.522 0.540 0.529 0.515 0.526 0.542 0.512 0.516 0.525 Wang et al. model Rank 13 12 8 4 5 2 6 16 3 1 23 30 14 21 18 9 17 22 7 10 15 1.295 1.421 1.377 1.210 1.488 1.720 1.746 1.651 1.682 1.678 1.186 1.224 0.759 0.974 1.155 1.317 1.105 0.976 1.182 1.361 1.119 12 7 8 14 6 2 1 5 3 4 15 13 30 25 18 11 20 24 16 10 19 Rank

121

DMU22 DMU23 DMU24 DMU25 DMU26 DMU27 DMU28 DMU29 DMU30 DMU31

0.053 0.022 0.066 0.043 1.000 0.036 0.052 0.185 0.166 0.064

6.309 2.745 8.382 5.679 134.371 4.583 6.278 15.828 22.103 5.770

1.040 1.013 1.055 1.035 2.000 1.027 1.040 1.111 1.158 1.036

0.546 0.517 0.561 0.539 1.500 0.531 0.546 0.648 0.662 0.550

25 11 27 20 31 19 24 28 29 26

0.987 0.994 0.831 1.171 0.566 0.958 0.973 0.846 0.998 1.375

23 22 29 17 31 27 26 28 21 9

122

Table 6.5 Results of the proposed output-oriented model compared with the Wang et al. [157] model
Output-oriented DMU Optimistic model (6.13) DMU1 DMU2 DMU3 DMU4 DMU5 DMU6 DMU7 DMU8 DMU9 DMU10 DMU11 DMU12 DMU13 DMU14 DMU15 DMU16 DMU17 DMU18 DMU19 DMU20 DMU21 4.8656 4.7890 3.6435 2.9379 2.0126 1.1952 1.8907 4.7711 1.5027 1.0015 12.4408 61.5218 10.2570 16.6643 7.4298 5.0722 7.5124 13.3887 3.5717 4.0733 7.6670 Pessimistic model (6.16) 0.0075 0.0074 0.0058 0.0045 0.0032 0.0019 0.0033 0.0075 0.0024 0.0013 0.0177 0.0825 0.0147 0.0233 0.0110 0.0077 0.0111 0.0190 0.0056 0.0064 0.0113 Pessimistic AIN 1.0051 1.0050 1.0035 1.0026 1.0013 1.0003 1.0012 1.0050 1.0007 1.0000 1.0151 1.0798 1.0122 1.0206 1.0085 1.0054 1.0086 1.0163 1.0034 1.0040 1.0088 Final score model (6.17) 0.5063 0.5062 0.5046 0.5035 0.5023 0.5011 0.5022 0.5062 0.5015 0.5007 0.5164 0.5811 0.5135 0.5220 0.5097 0.5065 0.5098 0.5177 0.5045 0.5052 0.5100 Wang et al. model Rank 12 10 8 6 5 2 4 11 3 1 21 29 18 26 15 13 16 23 7 9 17 1.2951 1.4206 1.3771 1.2099 1.4879 1.7200 1.7460 1.6507 1.6816 1.6777 1.1855 1.2237 0.7589 0.9742 1.1547 1.3168 1.1047 0.9762 1.1821 1.3609 1.1188 12 7 8 14 6 2 1 5 3 4 15 13 30 25 18 11 20 24 16 10 19 Rank

123

DMU22 DMU23 DMU24 DMU25 DMU26 DMU27 DMU28 DMU29 DMU30 DMU31

12.9698 6.0097 19.7597 11.7375 759.6427 10.5364 14.8482 63.6523 52.1975 14.6490

0.0184 0.0090 0.0274 0.0168 1.0000 0.0151 0.0209 0.0853 0.0702 0.0206

1.0158 1.0066 1.0247 1.0142 2.0000 1.0126 1.0183 1.0826 1.0675 1.0180

0.5171 0.5078 0.5261 0.5155 1.5000 0.5138 0.5196 0.5839 0.5688 0.5193

22 14 27 20 31 19 25 30 28 24

0.9865 0.9940 0.8314 1.1713 0.5660 0.9579 0.9727 0.8455 0.9975 1.3751

23 22 29 17 31 27 26 28 21 9

124

The results of the proposed model are compared with the results of Wanget al. [157] in the last columns of Table 6.4 and Table 6.5. By applying a Kendall ranking correlation [158], a strong correlation was observed between the ranking results of this model and the Wang et al. model. The Kendall correlation depends on finding a relationship between the data to determine Kendall's tau coefficient (), where the value of tau is equal to 1 if there is a very high agreement level between the two rankings (i.e., the two rankings are exactly similar); if the data are in complete disagreement, the value of tau is equal to 0. In the case of the proposed model, the correlation coefficients between the results of this model and the Wang et al. model are  = 0.49 ,  = 0.69 for both input- and output-oriented models. This degree of agreement is considered to be fairly high, considering that the proposed model is based on an FDH where convexity is relaxed, whereas the Wang et al. model is based on a CRS assumption.

6.4. Summary and conclusion
In this chapter, improved dual frontiers models that incorporate optimistic and pessimistic FDH with virtual DMUs have been developed. The virtual DMUs approach has been applied to dual FDH models in this study to achieve better and unbiased ranking. It is considered that the limited ability of the FDH approach in achieving high discrimination power has limited the attention paid to its application and development. This chapter, along with the previous chapter, has extended the investigation on the FDH model. Section 3 of this chapter proposed a comprehensive approach that uses optimistic and pessimistic approaches to achieve unbiased evaluations. It is understood that neither approach has previously been applied to the FDH approach in the existing literature. After obtaining both optimistic and pessimistic FDH measures, an algorithm was proposed to achieve full ranking 125

power for all DMUs in the dataset. In the second step, two virtual DMUs were added to the data to create a larger envelopment by enlarging the optimistic and pessimistic frontiers. The measurements across both approaches were combined using AINs, and full ranking was achieved. An empirical application that compared these results with those of other common models in the existing literature using a Kendall ranking correlation showed a high level of agreement between the proposed model and the existing models We believe that this proposed method contributes to the existing literature by providing better ranking. The methods developed in this study exhibit the following advantages: (1) although the PPS is expanded by introducing the super and worst virtual DMUs, the decrease in the number of efficient DMUs leads to improved discrimination; (2) the existing models generally combine pessimistic and optimistic approaches in a straightforward manner without adjusting the pessimistic scores for bias; and (3) there is no dual-frontier with virtual DMUs methodology in the existing literature that applies FDH when the convexity assumption must be relaxed. The results obtained show consistency when compared with other models in the literature, as a Kendall ranking correlation showed a high level of agreement between the proposed model and the existing models.

126

Chapter 7: Estimating Efficiency of Customizable DMUs Using Optimistic and PessimisticVirtual FDH and DEA Models

127

7.1. Introduction
A well-known strength of DEA is that it can evaluate the efficiency of any dataset; however, a weakness is that it lacks the discrimination power of creating a full ranking for all the efficient units in the dataset. For most decision makers, it is not enough to simply classify the firms under assessment into efficient or inefficient. On the other hand, regression analysis (RA) is a wellknown comparative efficiency technique that is widely used to determine the efficiency of units. RA uses least square methods to produce the average line, while DEA uses linear programming to obtain efficiency frontier lines. Both DEA and RA focus on finding or estimating the efficiency frontier of the data, and, for that reason, they are considered equivalent alternatives. However, DEA and RA result in different efficiency rankings, with major variations on their respective efficiency scores. This chapter suggests a new method that predicts the score of any possible data point by combining regressed optimistic and regressed pessimistic models. The chapter presents the methodology of the current method by applying the dual virtual models discussed in chapter 5 and chapter 6. The dual virtual DEA model is discussed in the following section of this chapter, along with illustrative examples to demonstrate the model. Section 7.3 discusses the proposed methodology incorporated with dual virtual FDH models. Both proposed methodologies show how the new models can predict the efficiency score of any DMU within or outside the dataset in reference to current available data.

7.2. Estimation model using optimistic and pessimistic virtual DEA approach
This section suggests a new method for forecasting customizable DMUs in any dataset. The methodology proposed in this section combines both the optimistic and pessimistic 128

approaches, with the introduction of virtual units to the data, similar to the approach discussed in Section 5.2. But in this section an additional step is taken that incorporates the optimistic and pessimistic models with regression analysis. The method is discussed in detail in the following subsections. Also, an illustrative example will follow in subsection 7.2.4. 7.2.1. Regressed optimistic DEA As noted above, in 1978, Charnes et al. [1] transformed envelopment analysis from its graphical form into a linear program. Their linear program LP requires no restrictions on the number of inputs or outputs. Furthermore, their CCR model assigns virtual weights to inputs and outputs, and this allows the model to measure efficiency without assigning prior weight to the input and output. All that was discussed in chapters 2 and 3, but this chapter will elaborate and present a different representation. On the virtual weights, the DEA model applies a linear program that maximizes the efficiency ratio of DMUs. Finally, the LP model is applied to all DMUs in the dataset one by one. To clarify this, it is supposed that there are n DMUs with s outputs and m inputs, so for every DMUk there are: Virtual input 1 1 + ... +    and Virtual output1 1 + ... +    where the virtual weight of the inputs are represented by Vi (i=1,..., m) and the virtual weight of the outputs are represented by Ur (r=1,...,s). The following function represents the DEA efficiency of any DMU:     

  =

129

In the CCR model, the weights of each DMU are selected so as to maximize the efficiency ratio. Charnes et al. maximized the efficiency of each DMUk by applying linear programming and solving the following fractional program [1]: max  = Subject to: 0 1 1 + 2 2 + ... +   1 1 1 + 2 2 + ... +   ( = 1 ... , ) (7.1) 1 1 + 2 2 + ... +   1 1 + 2 2 + ... +  

1 , 2 , ... ,   0 1 , 2 , ... ,   0

In the above program, the solution is calculated n times for every DMU in the data, each with its own efficiency score. The fractional model of CCR can be transformed into a linear form by normalizing the denominator of the objective function, as shown in Section 2.2. The model must also assume that no DMU will have a negative efficiency. So each DMU is classified as efficient if k obtains a value of 1. The CCR model is also known as the optimistic model and the best relative efficiency model. The previous standard DEA model used an optimistic approach to rank all DMUs, based on the efficiency frontier. Along this frontier, all units are considered efficient or optimistically efficient DMUs. Furthermore, as modeled in CCR, scores are equal to 1 for all efficient DMUs. In this section, a regressed optimistic model is presented. Based on Arnold et al. [159], a traditional, single output regression analysis will be applied to the DEA results to prepare the model for overall combination with the pessimistic model. In the model, the DEA efficiency score is

130

defined as a final optimum output for the regression function. The RA model of the score functions as follows:
 

 = 0 +     +      1 + 
=1 =1

(7.2)

where  is the estimated optimistic score for DMUk, whether included in the dataset or from another dataset; 0 is the optimistic intercept; Xki is the value of the ith output of DMUk; Ykl is the value of the lth input of DMUk; and  is the random error. Furthermore, it can be concluded that
 1+.

After applying both stages and obtaining the regressed optimistic function  , the score of any DMU in the data can be easily calculated. However, as Entani et al. [86] noted, approaches that utilize only the optimistic approach are biased. To eliminate this bias, the proposed model also includes a pessimistic approach in the following subsection.

7.2.2. Regressed pessimistic DEA The CCR model, an example of the optimistic approach, aims to optimize all units towards a maximum efficiency score of 1. In contrast, the pessimistic approach evaluates all DMUs along an inefficiency frontier. Rather than maximizing the efficiency ratio, ratios are minimized in the fractional program of the pessimistic approach. Inefficient DMUs receive a score of 1, and all constraints in the pessimistic approach should be greater than or equal to 1. The following represents the fractional pessimistic model for any DMUk [85]:

   =

1 1 + 2 2 + ... +   1 1 + 2 2 + ... +   131

(7.3)

 : 1 1 + 2 2 + ... +    1 ( = 1 ... , ) 1 1 + 2 2 + ... +   1 , 2 , ... ,   0 1 , 2 , ... ,   0 This section suggests introducing regression analysis to obtain efficiency scores using a pessimistic approach. After applying the RA, the final pessimistic efficiency scores can be calculated as follows:

  =  +    1 -  =1    + =1   

(7.4)

where  is the estimated pessimistic score for DMUk, whether included in the dataset or not;  is the regressed pessimistic intercept;  is the value of the ith output of DMUk; Ykl is the value of the lth input of DMUk; and  is the random error. Furthermore, it can be concluded that
 will always be greater than or equal to 1- .

7.2.3. DEA dual frontiers estimation model After developing regressed optimistic and regressed pessimistic models in Sections 7.2.1 and 7.2.2, it can be concluded that both models can be used to obtain efficiency scores of a data point or even predict a score of a virtual data point. However, relying on one approach lacks precision and introduces bias. Each model may lead to an inaccurate efficiency score; nevertheless, using one model over the other is biased, as shown in previous chapters of this thesis. Therefore, unbiased methods must combine pessimistic and optimistic approaches. This combination can be achieved by calculating the geometric average of both scores. Wang et al.

132

provided a detailed theorem and proof of this [31]. They advocated ranking all DMUs by taking the geometric average between the pessimistic and optimistic scores of each DMU. Following Wang et al., this subsection proposes to combine a regressed optimistic approach with a regressed pessimistic approach by taking their geometric average. The final efficiency score prediction formula of the proposed method can be calculated as follows:





= 

 0 +   =1    + =1   

( +

 =1   

+

-1   ) =1   

 =  ( )-1

(7.5)

7.2.4. Illustrative example for the DEA forcasting model To illustrate the new model proposed in this chapter, the multiple inputs and outputs example of bank branches presented in chapter 5 is used, where Table 5.5 shows the raw data of 12 bank branches. Table 7.1 shows the results of the optimistic model, pessimistic model, regressed optimistic model, regressed pessimistic model, and the final score of the proposed model.

133

Table 7.1 Comparison results of the proposed DEA forecasting model
Optimistic DMU model Score 1 2 3 4 5 6 7 8 9 10 11 12 0.512 0.413 0.456 1.000 0.413 1.000 1.000 0.996 0.729 0.622 0.342 0.624 Rank 8 11 9 1 10 1 1 4 5 7 12 6 Pessimistic model Score 1.189 1.000 1.370 3.005 1.000 3.968 3.548 3.736 1.646 1.504 1.000 1.000 Rank 8 9 7 4 9 1 3 2 5 6 9 9 Regressed optimistic model ( ) Score 0.613 0.513 0.526 1.064 0.329 0.895 0.996 0.999 0.624 0.612 0.409 0.527 Rank 6 10 9 1 12 4 3 2 5 7 11 8 Regressed pessimistic model ( ) Score 1.735 1.349 1.369 3.279 0.507 3.499 3.442 3.510 1.886 1.781 1.033 0.576 Rank 7 9 8 4 12 2 3 1 5 6 10 11 Proposed model ( Score 1.032 0.831 0.849 1.867 0.409 1.770 1.851 1.873 1.085 1.044 0.650 0.551


) Rank 7 9 8 2 12 4 3 1 5 6 10 11

It can be observed that both the regressed optimistic model and regressed pessimistic model are consistent with the original optimistic or pessimistic DEA. Figure 7.1 shows consistency between the proposed model and all other models. This allows reliance on the model for prediction. In addition, overcoming the issue of bias within each model, the final proposed model yields accurate results, and it can be used for efficiency score prediction on any virtual data point that does not belong to the data, but, of course, this evaluation is in reference to this specific dataset. For example, if virtual branch X is about to be established and the decision maker wants to know if this branch will be efficient or not, the proposed models can be applied. So, if the DM knows that a branch has the following resources: 12 employees, 800,000 operation cost, 2,000,000 interest earned per saving, 900,000 interest earned per loan, and 700,000 non-interest income, then by applying the proposed models (7.2), (7.4), and (7.5), the efficiency score for that customizable

134

branch will be 75.1% and it will be ranked as branch number 10 among the current available braches. So this is a major application benefit from the proposed models; moreover, these models can also be used to rank the existing data when discrimination between DMUs is needed.

Figure 7.1 Score comparisons of all models with the proposed final model

7.3. Estimation model using optimistic and pessimistic virtual FDH approach
This section develops a new method for forecasting customizable DMUs, similar to the previous approach presented in subsection 7.2. However, the model applied in this forecasting model is switched to the FDH model instead of the DEA model. The model proposed combines both the optimistic and pessimistic approaches to the data in a virtual context, similar to the approach discussed in Section 6.2. RA analysis is incorporated into the last step of the model in order to allow prediction application when a customizable DMU is available for alteration by the DM. A forecasting or prediction framework of three steps is proposed. Subsections 7.3.1, 7.3.2 and 135

7.3.3 discuss in detail the incorporation of the virtual FDH models and the regression approach. Subsection 7.3.4 discusses an empirical application of the methodology proposed.

7.3.1. Regressed optimistic FDH The FDH model of Tulkens [155] is applied in this section to create a non-convex hull that imposes strong disposability assumptions. To this end, this subsection presents an interval regressed FDH for measuring the bounded efficiency, where the upper bound is obtained from the regressed optimistic perspective and the lower bound is obtained from the regressed pessimistic perspective. To present the new proposed model, the FDH input and output oriented models presented in chapter 3 need to be borrowed as follows:

in-FDH Fo (Xo , Yo ) = min { j : j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

(3.15)

out-FDH Fo (Xo , Yo ) = max { j : j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

The formulations presented above show the input and output orientation of the FDH models. In this section, the regressed output orientation of the FDH model will be developed from the optimistic perspective. Input orientation can be developed similarly. From the above formulation, the developed optimistic output oriented virtual FDH model can be obtained by adding the super virtual DMU to the dataset. The DMUsuper consists of the maximal output and minimal input among all units in the dataset.

136

So, for any dataset that has n DMUs with m inputs and s outputs, the new formulation after virtual DMU introduction for the optimistic virtual FDH model will be as follows:
out-FDH Fsuper (Xo , Yo )

= max { j : j X j  j Xo ; j Yj  j Yo ;  j = 1 ; j  0 , where j
j j

(7.6)

= 1,2, ... .  + 1 }

In order to develop the regressed optimistic FDH model, the single output regression model of Arnold et al. [159] is applied. In this model, the FDH efficiency score is defined as a final optimum output for the regression function. The optimistic RA score function for any DMUk, is presented as follows:
    

= 0 +     +     1 + 
=1 =1

(7.7)

 where  is the estimated optimistic virtual FDH optimistic score for DMUk from the

output orientation, whether that DMUk is included in the dataset or not; 0 is the optimistic intercept; Xki is the value of the ith output of DMUk; Ykl is the value of the lth input of DMUk; and  is the random error. Furthermore, it can be concluded that  1+.
 After applying both stages and obtaining the regressed optimistic function  , the

score of any DMU in the dataset can be easily calculated. This first step of estimation can be useful when only the optimistic perspective is needed, but, as this study suggests, the pessimistic perspective should always be included in the evaluation, and that is what subsection 7.3.2 will discuss. 137

7.3.2. Regressed pessimistic FDH In contrast to the previous subsection, the pessimistic approach evaluates all DMUs along an inefficiency frontier. In order to do so, this section will discuss the development of the regressed virtual FDH model from the pessimistic perspective. Initially, the fundamental pessimistic FDH model that has been developed in this thesis needs to be built on. The basic FDH pessimistic model is presented in chapter 3 as follows:

in-FDH o F (Xo , Yo ) = max { j : j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

(3.16)

out-FDH o F (Xo , Yo ) = min { j : j Xj  j X o ; j Yj  j Yo ;  j = 1 ; j  0 } j j

In this section, the regressed virtual FDH model will be developed from output orientation only, and, similarly, the input orientation can be developed. So for any dataset that has n DMUs with m inputs and s outputs, the new formulation after introducing DMUworst for the pessimistic virtual FDH model will be as follows:
out-FDH Fworst (Xo , Yo )

(7.8)

= max { j : j Xj  j Xo ; j Yj  j Yo ;  j = 1 ; j  0 , where j
j j

= 1,2, ... .  + 1 }

where DMUworst is defined as a virtual DMU that has the minimal output and maximal input among all units in the dataset. In order to develop the regressed pessimistic FDH model, the

138

RA analysis is incorporated in a similar way to the previous section. So, the pessimistic RA score function for any DMUk, is:
    

= 0 +     +     1 + 
=1 =1

(7.9)

 where  is the estimated optimistic virtual FDH score for DMUk from the output

orientation, whether that DMUk is included in the dataset or not; 0 is the optimistic intercept; Xki is the value of the ith output of DMUk; Ykl is the value of the lth input of DMUk; and  is the random error. Furthermore, it can be concluded that  1+.
 After applying both stages and obtaining the regressed pessimistic function  , the

score of any DMU in the data can be easily calculated. This concludes the second to last step in the methodology of overall estimation. The final dual unbiased evaluation will be calculated in the following subsection. 7.3.3. FDH dual frontiers forecasting model Implementing one approach lacks precision and introduces bias. Both models introduced in the last two subsections may lead to an inaccurate efficiency score if solely used. Therefore, an unbiased approach must combine the pessimistic and optimistic approaches. This combination can be achieved by calculating the geometric average of both scores. Similar to the theorem of Wang et al. [31] in this subsection, a dual regressed optimistic and regressed pessimistic approach is presented, by combining the virtual regressed FDH optimistic and pessimistic models. The final efficiency score prediction formula of the method can be calculated as follows:

139

  

=   ( )-1





(7.10)

It must be noted that the above formula only calculates, or, in other words, estimates, the efficiency scores for customizable DMU from the output orientation only. In the following subsection, an illustrative example will be discussed.

7.3.4. Illustrative example for the FDH forcasting model In this subsection, the proposed model in the previous subsection will be illustrated by applying it to the sales associates example presented in Section 6.1. The application will show the behavior of regressed optimistic FDH and regressed pessimistic FDH and the final proposed model of the dual FDH forecasting.The objective of this application is to test the credibility of the proposed model. Table 7.2 shows the results of the optimistic model, the pessimistic model, the regressed optimistic model, the regressed pessimistic model, and the final score of the proposed model for the sales associates example.

140

Table 7. 2 Comparison results of the proposed FDH forecasting model
Optimistic Sales Associate virtual FDH model Score 1 2 3 4 5 6 7 8 9 10 1.000 2.667 1.333 2.667 1.143 2.000 1.600 1.600 1.143 1.000 Rank 9 1 6 1 7 3 4 4 7 9 Pessimistic virtual FDH model Score 1.000 0.500 0.500 0.333 0.250 0.500 0.200 0.500 0.500 1.000 Rank 9 4 4 3 2 4 1 4 4 9 Regressed optimistic FDH model Score 1.446 2.451 1.676 2.164 0.843 2.135 1.072 1.848 1.273 1.244 Rank 6 1 5 2 10 3 9 4 7 8 Regressed pessimistic FDH model Score 0.498 0.522 0.510 0.526 0.516 0.535 0.529 0.540 0.550 0.558 Rank 1 4 2 5 3 7 6 8 9 10 Dual regressed FDH model Score 0.848 1.131 0.925 1.067 0.660 1.069 0.753 0.999 0.837 0.833 Rank 6 1 5 3 10 2 9 4 7 8

7.4. Summary and conclusion
Since 1978, when DEA first emerged, a large body of research has been conducted on DEA, resulting in major developments in its methods and applications. A subfield of research, focusing on score prediction and the ranking of DMUs, has emerged. It is understood that the combination of optimistic and pessimistic DEAs with regression models has not yet been explored. In the proposed model in this chapter, a two-stage methodology for determining, and, in particular, predicting efficiency scores for any possible data point is presented. The first stage of the model individually applies RA to optimistic and pessimistic DEA models in order to obtain regressed optimistic scores and regressed pessimistic scores. In the second stage, both scores are combined through a geometric average technique. Combining both scores yields much more accurate results. This chapter has presented this methodology through the conventional DEA models and through the newly developed FDH that has been discussed in this study. Moreover, even though this model

141

is used for score prediction, it can also rank efficient DMUs, since the final scores of all DMUs tend to be much more discriminated than the scores generated from the standard DEA model.

142

Chapter 8: Summary and Conclusion

143

8.1. Thesis summary
The field of data envelopment analysis has a very interesting growth in the literature of decision analysis and economic science. Every day, researchers and practitioners add practical cases of DEA, along with theoretical development. As shown in the survey conducted by Liu et al. [160], the number of theoretical publications of DEA between 1978 till 1999 was always higher than the number of empirical publication. After 1999 the number of published application work increased to exceed the number of methodological publications until it reached almost double the number of accumulated theoretical published works. It can be stated that the theoretical DEA literature is quite mature, and the literature referred to in this thesis has shown how one topic, DEA ranking approaches, has evolved over the past 40 years. Many models have been developed and proposed, and the research observation can be made that most approaches are considered to be post-analysis development of the few fundamental DEA models. This study was able to identify a field that has not yet matured in terms of the topic of DEA ranking, and an attempt has been made to elaborate and develop fundamental and extended models in this field. All conventional DEA models conduct evaluation from the optimistic perspective by using single frontier analysis. This study focused on developing a ranking framework using both optimistic and pessimistic approaches, in order to avoid any bias in evaluation. This thesis proposed original FDH models from optimistic and pessimistic perspectives that consider both input and output orientation. These dual FDH models can be considered as a major contribution to the literature, due to their originality. Theoretically, the models contribute to the body of knowledge in the DEA field, but also it is believed that these models are very helpful to practitioners who need to apply DEA in real-life scenarios where the convexity assumption needs to be relaxed. Moreover, the proposed FDH model can be very useful in providing an unbiased 144

ranking approach, and more practical in certain applications, for example, integer data application and elimination process scenarios. As a part of the research, this thesis has delivered an elaborate analysis of the dual frontiers ranking approach. Besides the FDH models, several different models have been proposed. These models are needed mainly to deliver better accuracy for evaluation outcomes. Chapter 4 showed three different FDH models: the slack-based model, the super-efficiency model, and the superefficiency model without infeasibility. The super-efficiency model can be considered as a unique model with a very major contribution to the ranking literature. Many researchers criticize the superefficiency model for its continual infeasibility problem and its limited applicability for outliers' detection only, while this thesis proposes that SF-FDH models overcome the feasibility issue, to become an unbiased ranking method. Chapters 5 and 6 aimed to extend the development of the optimistic and pessimistic model to include another immature approach in the literature that incorporates virtual DMUs. Two improved models that incorporate virtual DMUs are proposed for conventional DEA and FDH from both the optimistic and pessimistic approaches. After discussing all new models, empirical application is carried out to show feasibility and applicability, in addition to the advantages of the proposed models. Finally, a major finding of this research is that using only the optimistic approach in any evaluation procedure might lead to a biased evaluation. The study included an estimation model that implements both optimistic and pessimistic approaches in order to predict the future resources needed to build a new decision-making unit in reference to any dataset. Chapter 7 tackles this goal by proposing a new dual regression model for estimating customizable DMUs. The proposed

145

methodology can be very effective because it relies on optimistic and pessimistic approaches. Both DEA and FDH models have been used to develop these estimation models.

8.2. Contribution and main findings
The topic of DEA ranking is a very rich topic, and there have been many attempts in the literature toward DEA ranking improvement. This thesis also seeks to achieve the goal of reaching strong discrimination power when DEA evaluation is applied to any existing data. The main finding in this thesis is that using only the conventional or optimistic DEA, as with most DEA ranking models in the literature, might lead to a biased evaluation. This body of research therefore proposes that researchers or practitioners should always include pessimistic approaches alongside optimistic approaches whenever DEA models are applied. In this dissertation, several models under the optimistic and pessimistic framework have been proposed. These models have two different bases: either an FDH base or a virtual DMU base. Further on in the research, both bases are combined to serve the ranking objective, like all other models presented beforehand in the thesis. As an extended objective, an estimation model has been proposed and discussed to provide a useful tool for practitioners who need to determine efficiency scores for customizable DMUs. These estimation models were also developed under the optimistic and pessimistic framework, and similarly used FDH and virtual DMUs as bases. In summary, this thesis contributes the following to the field of DEA:  A comprehensive literature review up to 2016 for all DEA ranking methods, with critical insights. The last DEA ranking review in the literature was carried out in 2002. In the

146

current review, new methods have been categorized and included as updated and major directions in the DEA ranking research field (see Aldamak and Zolfaghari [161]).  The fundamental contribution to the literature is the development of the FDH model from pessimistic and optimistic approaches. In this thesis, a comprehensive dual FDH frontiers framework is developed with a new representation of the optimistic FDH model. The proposed FDH model, fills a gap in the literature, since there is no pessimistic DEA-FDH model from both input and output orientations [58].  A slack-based (SB) FDH model has been developed from both optimistic and pessimistic approaches.  The weakness of the discrimination power in the FDH model has been addressed, by developing a super-efficiency FDH model (first SF-FDH integration). Based on the previous contributed model, an improved FDH super-efficiency model has been developed without infeasible results (second SF-FDH integration).  An improved ranking methodology using virtual DMUs with the dual frontiers of conventional DEA [94] and FDH has been used. This methodology is considered as an unbiased ranking method with optimistic and pessimistic approaches  An efficiency estimation model has been presented, based on the combination of the optimistic and pessimistic approaches, where customizable or future DMUs are within the scope of the assessment [162]. The objective of all models presented in this thesis is to improve the ranking efficiency of the classical DEA model and to develop models that are more applicable to real life scenarios by relaxing the strong assumptions of the conventional DEA model. Referring to Figure 1.1 in order to show the contribution of the developed models in summary, Table 8.1 compares the five generic

147

models developed in this thesis with the CCR model in regard to the following main criteria: strength of discrimination power (ranking), assumption disposability, and computational intensity. From the Table 8.1 results, we can observe that models 3 and 5 are the only models that are high in ranking power and disposing assumption, but both models require a further computational process.

Table 8.1 Comparison of the proposed models with the CCR model
Model Ranking Power Assumptions disposability Low High High High Low High Computational intensity Low Low Low High Moderate Moderate

CCR model Model 1: Dual FDH model Model 2: Dual slack based FDH model Model 3: Dual SF-FDH model Model 4: Dual virtual DMUs model Model 5: Dual virtual FDH model

Low Low Low High High High

8.3. Directions for future work
As mentioned earlier, the subfield of dual DEA frontiers analysis is fairly new, and there is much scope to develop the literature. This thesis has developed various models using multiple approaches. Also, there are common approaches in the literature that are worth investigating to see how dual analysis can be incorporated into them. A very interesting model might be the dual FDH cross-efficiency model, where the cross-efficiency matrix should be constructed from both perspectives. Also, fuzzy DEA is a hot research area within the DEA topic and it would be very interesting to investigate its compatibility to both DEA and FDH dual analysis.

148

Moreover, dual frontiers analysis has not been tested with many MCDM models. Even though MCDM is usually customized for special case problems, it would be worth investigating empirical applications, with a comparison of results between dual and single frontiers analysis. Also, it is worthwhile to mention that all models presented in this thesis are developed under the scope of evaluating discrete data that has no reciprocal relation over time. However, a new direction of research can focus on developing a dual FDH network model that can be applied to continuous series cases such as supply chain performance evaluation. We believe that this thesis has developed original theoretical models, and proposed new FDH approaches that are very suitable for real-life scenarios when some of the DEA axiomatic assumptions need to be waived. Future real-life empirical studies to show the applicability of the proposed models should contribute much to complete the picture of the dual frontiers framework proposed in this thesis.

149

References
[1] A. Charnes, W.W. Cooper, E. Rhodes, Measuring the efficiency of decision making units, European Journal of Operational Research, 2 (1978) 429-444. [2] A. Bessent, W. Bessent, J. Kennington, B. Reagan, An application of mathematical programming to assess productivity in the Houston Independent School District, Management Science, 28 (1982) 1355-1367. [3] E. Thanassoulis, Data envelopment analysis and its use in banking, Interfaces, 29 (1999) 1-13. [4] A. Ebrahimnejad, M. Tavana, F.H. Lotfi, R. Shahverdi, M. Yousefpour, A three-stage data envelopment analysis model with application to banking industry, Measurement, 49 (2014) 308-319. [5] M.I.M. Wahab, D. Wu, C.-G. Lee, A generic approach to measuring the machine flexibility of manufacturing systems, European Journal of Operational Research, 186 (2008) 137-149. [6] J. Xu, B. Li, D. Wu, Rough data envelopment analysis and its application to supply chain performance evaluation, International Journal of Production Economics, 122 (2009) 628-638. [7] W.W. Cooper, K.S. Park, G. Yu, An illustrative application of IDEA (Imprecise Data Envelopment Analysis) to a Korean mobile telecommunication company, Operations Research, 49 (2001) 807-820. [8] R. Jacobs, Alternative methods to examine hospital efficiency: Data envelopment analysis and stochastic frontier analysis, Health Care Management Science, 4 (2001) 103-115. [9] W.W. Cooper, J.L. Ruiz, I. Sirvent, Selecting non-zero weights to evaluate effectiveness of basketball players with DEA, European Journal of Operational Research, 195 (2009) 563574.

150

[10] T.R. Sexton, H.F. Lewis, Two-stage DEA: An application to major league baseball, Journal of Productivity Analysis, 19 (2003) 227-249. [11] N. Adler, L. Friedman, Z. Sinuany-Stern, Review of ranking methods in the data envelopment analysis context, European Journal of Operational Research, 140 (2002) 249-265. [12] A. Emrouznejad, B.R. Parker, G. Tavares, Evaluation of research in efficiency and productivity: A survey and analysis of the first 30 years of scholarly literature in DEA, Socioeconomic Planning Sciences, 42 (2008) 151-157. [13] P. Andersen, N.C. Petersen, A procedure for ranking efficient units in data envelopment analysis, Management Science,39 (1993) 1261-1264. [14] M.J. Farrell, The measurement of productivity efficiency, Journal of the Royal Statistical Society, 120 (A) (1957) 253-281. [15] R. Ramanathan, An introduction to data envelopment analysis: A tool for performance measurement, Thousand Oaks, Calif.: Sage Publications, 2003. [16] W.W. Cooper, L.M. Seiford, J. Zhu, Handbook on data envelopment analysis, 2004. [17] R.D. Banker, A. Charnes, W.W. Cooper, Some models for estimating technical and scale inefficiencies in data envelopment analysis, Management Science, 30 (1984) 1078-1092. [18] A. Charnes, W.W. Cooper, L. Seiford, J. Stutz, A multiplicative model for efficiency analysis, Socio-Economic Planning Sciences, 16 (1982) 223-224. [19] A. Charnes, W.W. Cooper, B. Golany, L. Seiford, J. Stutz, Foundations of data envelopment analysis for Pareto-Koopmans efficient empirical production functions, Journal of Econometrics, 30 (1985) 91-107. [20] K. Tone, A slacks-based measure of efficiency in data envelopment analysis, European Journal of Operational Research, 130 (2001) 498-509.

151

[21] W.W. Cooper, L.M. Seiford, K. Tone, Data envelopment analysis: A comprehensive text with models, applications, references and DEA-solver software, 2007. [22] M. Zerafat Angiz, A. Mustafa, M.J. Kamali, Cross-ranking of decision making units in data envelopment analysis, Applied Mathematical Modelling, 37 (2013) 398-405. [23] G.R. Jahanshahloo, M. Khodabakhshi, F. Hosseinzadeh Lotfi, M.R. Moazami Goudarzi, A cross-efficiency model based on super-efficiency for ranking units through the TOPSIS approach and its extension to the interval case, Mathematical and Computer Modelling, 53 (2011) 1946-1955. [24] M. Falagario, F. Sciancalepore, N. Costantino, R. Pietroforte, Using a DEA-cross efficiency approach in public procurement tenders, European Journal of Operational Research, 218 (2012) 523-529. [25] T. Sueyoshi, DEA non-parametric ranking test and index measurement: Slack-adjusted DEA and an application to Japanese agriculture cooperatives, Omega, 27 (1999) 315-326. [26] A.M. Torgersen, F.R. Forsund, S.A.C. Kittelsen, Slack-adjusted efficiency measures and ranking of efficient units, Journal of Productivity Analysis, 7 (1996) 379-398. [27] L. Friedman, Z. Sinuany-Stern, Scaling units via the canonical correlation analysis in the DEA context, European Journal of Operational Research, 100 (1997) 629-637. [28] Y.-M. Wang, Y. Luo, Y.-X. Lan, Common weights for fully ranking decision making units by regression analysis, Expert Systems with Applications, 38 (2011) 9122-9128. [29] J. Jablonsky, Measuring the efficiency of production units by AHP models, Mathematical and Computer Modelling, 46 (2007) 1091-1098. [30] H.-Y. Wu, J.-K. Chen, I.S. Chen, H.-H. Zhuo, Ranking universities based on performance evaluation by a hybrid MCDM model, Measurement, 45 (2012) 856.

152

[31] Y.M. Wang, K.S. Chin, J.B. Yang, Measuring the performances of decision-making units using geometric average efficiency, Journal of the Operational Research Society, 58 (2006) 929-937. [32] H. Azizi, Y.-M. Wang, Improved DEA models for measuring interval efficiencies of decisionmaking units, Measurement, 46 (2013) 1325-1332. [33] N. Ramón, J.L. Ruiz, I. Sirvent, Common sets of weights as summaries of DEA profiles of weights: With an application to the ranking of professional tennis players, Expert Systems With Applications, 39 (2012) 4882. [34] M. Zerafat Angiz L, A. Mustafa, A. Emrouznejad, Ranking efficient decision-making units in data envelopment analysis using fuzzy concept, Computers & Industrial Engineering, 59 (2010) 712-719. [35] T.R. Sexton, R.H. Silkman, A.J. Hogan, Data envelopment analysis: Critique and extensions, New Directions for Program Evaluation, 1986 (1986) 73-105. [36] J. Doyle, R. Green, Efficiency and cross-efficiency in DEA: Derivations, meanings and uses, Journal of the Operational Research Society, 45 (1994) 567-578. [37] H.H. Örkcü, H. Bal, Goal programming approaches for data envelopment analysis cross efficiency evaluation, Applied Mathematics and Computation, 218 (2011) 346-356. [38] D. Guo, J. Wu, A complete ranking of DMUs with undesirable outputs using restrictions in DEA models, Mathematical and Computer Modelling, (2012). [39] N. Ramón, J.L. Ruiz, I. Sirvent, Reducing differences between profiles of weights: A "peerrestricted" cross-efficiency evaluation, Omega, 39 (2011) 634-641. [40] M. Oral, G.R. Amin, A. Oukil, Cross-efficiency in DEA: A maximum resonated appreciative model, Measurement, 63 (2015) 159-167.

153

[41] J. Wu, J. Chu, J. Sun, Q. Zhu, DEA cross-efficiency evaluation based on Pareto improvement, European Journal of Operational Research, 248 (2016) 571-579. [42] X. Liu, J. Chu, P. Yin, J. Sun, DEA cross-efficiency evaluation considering undesirable output and ranking priority: A case study of eco-efficiency analysis of coal-fired power plants, Journal of Cleaner Production, (2016). [43] M. Oral, O. Kettani, P. Lang, A methodology for collective evaluation and selection of industrial R&D projects, Management Science, 37 (1991) 871-885. [44] R.H. Green, J.R. Doyle, W.D. Cook, Preference voting and project ranking using DEA and cross-evaluation, European Journal of Operational Research, 90 (1996) 461-472. [45] J. Zhu, DEA Cross Efficiency, Quantitative models for performance evaluation and benchmarking: Data envelopment analysis with spreadsheets, Springer International Publishing, Cham, 2014, pp. 61-92. [46] R.M. Thrall, Chapter 5, Duality, classification and slacks in DEA, Annals of Operations Research, 66 (1996) 109-138. [47] M.S. Lawrence, Z. Joe, Infeasibility of super-efficiency data envelopment analysis models, INFOR, 37 (1999) 174. [48] Y. Chen, Ranking efficient units in DEA, Omega, 32 (2004) 213-219. [49] W.D. Cook, L. Liang, Y. Zha, J. Zhu, A modified super-efficiency DEA model for infeasibility, Journal of the Operational Research Society, 60 (2009) 276-281. [50] A. Amirteimoori, G. Jahanshahloo, S. Kordrostami, Ranking of decision making units in data envelopment analysis: A distance-based approach, Applied Mathematics and Computation, 171 (2005) 122-135.

154

[51] G.R. Jahanshahloo, L. Pourkarimi, M. Zarepisheh, Modified MAJ model for ranking decision making units in data envelopment analysis, Applied Mathematics and Computation, 174 (2005) 1054-1059. [52] A. Gholam Abri, G.R. Jahanshahloo, F. Hosseinzadeh Lotfi, N. Shoja, M. Fallah Jelodar, A new method for ranking non-extreme efficient units in data envelopment analysis, Optimization Letters, 7 (2013) 309-324. [53] J. Du, Y. Chen, Super-efficiency based on a modified directional distance function, Omega, 41 (2013) 621-625. [54] J. Pourmahmoud, A. Hatami-Marbini, E. Babazadeh, A comment on a new super-efficiency model in the presence of negative data, Journal of the Operational Research Society, 67 (2016) 530­534 (2016). [55] S. Mehrabian, M.R. Alirezaee, G.R. Jahanshahloo, A complete efficiency ranking of decision making units in data envelopment analysis, Computational Optimization and Applications, 14 (1999) 261-266. [56] G.R. Jahanshahloo, F. Hosseinzadeh Lotfi, N. Shoja, G. Tohidi, S. Razavyan, Ranking using l1-norm in data envelopment analysis, Applied Mathematics and Computation, 153 (2004) 215-224. [57] G.R. Jahanshahloo, M. Sanei, F. Hosseinzadeh Lotfi, N. Shoja, Using the gradient line for ranking DMUs in DEA, Applied Mathematics and Computation, 151 (2004) 209-219. [58] A. Aldamak, A. Hatami-Marbini, S. Zolfaghari, Dual frontiers without convexity, Computers & Industrial Engineering, 101 (2016) 466-478. [59] A. Esmaeilzadeh, A. Hadi-Vencheh, A super-efficiency model for measuring aggregative efficiency of multi-period production systems, Measurement, 46 (2013) 3988.

155

[60] R.D. Banker, H. Chang, The super-efficiency procedure for outlier identification, not for ranking efficient units, European Journal of Operational Research, 175 (2006) 1311-1320. [61] Z. Sinuany-Stern, A. Mehrez, A. Barboy, Academic departments efficiency via DEA, Computers and Operations Research, 21 (1994) 543-556. [62] G.R. Jahanshahloo, H.V. Junior, F.H. Lotfi, D. Akbarian, A new DEA ranking system based on changing the reference set, European Journal of Operational Research, 181 (2007) 331337. [63] W.-M. Lu, S.-F. Lo, An interactive benchmark model ranking performers: Application to financial holding companies, Mathematical and Computer Modelling, 49 (2009) 172-179. [64] Z. Sinuany-Stern, L. Friedman, DEA and the discriminant analysis of ratios for ranking units, European Journal of Operational Research, 111 (1998) 470-478. [65] D. Wu, A. Hashimoto, A DEA-compromise programming model for comprehensive ranking, Journal of the Operational Research Society, 47(2) (2004) 73-81. [66] C. Kao, Data envelopment analysis with common weights: The compromise solution approach, Journal of the Operational Research Society, 56 (2005) 1196-1203. [67] F.-H.F. Liu, H. Hsuan Peng, Ranking of units on the DEA frontier with common weights, Computers and Operations Research, 35 (2008) 1624-1637. [68] M.R. Alirezaee, M. Afsharian, A complete ranking of DMUs using restrictions in DEA models, Applied Mathematics and Computation, 189 1550-1559. [69] J. Wu, F. Yang, L. Liang, A modified complete ranking of DMUs using restrictions in DEA models, Applied Mathematics and Computation, 217 (2010) 745-751.

156

[70] S. Saati, A. Hatami-Marbini, P.J. Agrell, M. Tavana, A common set of weight approach using an ideal decision making unit in data envelopment analysis, Journal of Industrial and Management Optimization, 8 (2012) 623-637. [71] F.H. Lotfi, A. Hatami-Marbini, P.J. Agrell, N. Aghayi, K. Gholami, Allocating fixed resources and setting targets using a common-weights DEA approach, Computers & Industrial Engineering, 64 (2013) 631-640. [72] A. Hatami-Marbini, M. Tavana, P.J. Agrell, F.H. Lotfi, Z.G. Beigi, A common-weights DEA model for centralized resource reduction and target setting, Computers & Industrial Engineering, 79 (2015) 195-203. [73] I. Bardhan, W. Bowlin, F., W. Cooper, W., T. Sueyoshi, Models and measures for efficiency dominance in DEA part 1: Additive models and MED measures, Journal of the Operations Research Society of Japan, 39 (1996) 322­332. [74] W.D. Cook, L.M. Seiford, Data envelopment analysis (DEA) ­ Thirty years on, European Journal of Operational Research, 192 (2009) 1-17. [75] W.D. Cook, M. Kress, A data envelopment model for aggregating preference rankings, Management Science, 36 (1990) 1302-1310. [76] W.D. Cook, M. Kress, A multiple criteria decision model with ordinal preference data, European Journal of Operational Research, 54 (1991) 191-198. [77] W.D. Cook, M. Kress, L.M. Seiford, On the use of ordinal data in data envelopment analysis, Journal of the Operational Research Society, 44 (1993) 133-140. [78] M.D. Troutt, A maximum decisional Efficiency estimation principle, Management Science, 41 (1995) 76-82.

157

[79] W.D. Cook, M. Kress, L.M. Seiford, Data envelopment analysis in the presence of both quantitative and qualitative factors, Journal of the Operational Research Society, 47 (1996) 945-953. [80] X.-B. Li, G.R. Reeves, A multiple criteria approach to data envelopment analysis, European Journal of Operational Research, 115 (1999) 507-517. [81] Z. Sinuany-Stern, A. Mehrez, Y. Hadad, An AHP/DEA methodology for ranking decision making units, International Transactions in Operational Research, 7 (2000) 109-124. [82] J. Jablonsky, Multicriteria approaches for ranking of efficient units in DEA models, Central European Journal of Operations Research, 20 (2011) 435-449. [83] F. Hosseinzadeh Lotfi, M. Rostamy-Malkhalifeh, N. Aghayi, Z. Ghelej Beigi, K. Gholami, An improved method for ranking alternatives in multiple criteria decision analysis, Applied Mathematical Modelling, 37 25-33. [84] M. Toloo, B. Sohrabi, S. Nalchigar, A new method for ranking discovered rules from data mining by DEA, Expert Systems with Applications, 36 (2009) 8503-8508. [85] Y. Yamada, T. Matsui, M. Sugiyama, An inefficiency measurement method for management systems, Journal of the Operations Research Society of Japan, 37(2) (1994) 158-168. [86] T. Entani, Y. Maeda, H. Tanaka, Dual models of interval DEA and its extension to interval data, European Journal of Operational Research, 136 (2002) 32-45. [87] H. Azizi, The interval efficiency based on the optimistic and pessimistic points of view, Applied Mathematical Modelling, 35 (2011) 2384-2393. [88] G.R. Jahanshahloo, M. Afzalinejad, A ranking method based on a full-inefficient frontier, Applied Mathematical Modelling, 30 (2006) 248-260.

158

[89] Y.-M. Wang, Y. Luo, DEA efficiency assessment using ideal and anti-ideal decision making units, Applied Mathematics and Computation, 173 (2006) 902-915. [90] Y.-M. Wang, J.-B. Yang, Measuring the performances of decision-making units using interval efficiencies, Journal of Computational and Applied Mathematics, 198 (2007) 253-267. [91] B.-y. Zheng, An improvement on DEA model for many efficient DMUs, Electronic

Commerce and Business Intelligence, 2009. ECBI 2009. International Conference on, 2009, pp. 246-249. [92] K. Sun, A new modified DEA model for distinguishing efficient decision making units, Management Science and Engineering, 2009. ICMSE 2009. International Conference on, 2009, pp. 196-200. [93] U. Shetty, T.P.M. Pakkala, Ranking efficient DMUs based on single virtual inefficient DMU in DEA, OPSEARCH, 47 (2010) 50-72. [94] A. Aldamak, S. Zolfaghari, An improved ranking for decision making units using optimistic and pessimistic approaches, 11th International Conference on Data Envelopment Analysis (DEA2013), Samsun, Turkey, 2013, pp. 35-45. [95] Y.-M. Wang, Y. Luo, L. Liang, Ranking decision making units by imposing a minimum weight restriction in the data envelopment analysis, Journal of Computational and Applied Mathematics, 223 (2009) 469-484. [96] M. Toloo, The most efficient unit without explicit inputs: An extended MILP-DEA model, Measurement, 46 (2013) 3628. [97] M. Toloo, A. Kresta, Finding the best asset financing alternative: A DEA-WEO approach, Measurement, 55 (2014) 288.

159

[98] D.D. Wu, Performance evaluation: An integrated method using data envelopment analysis and fuzzy preference relations, European Journal of Operational Research, 194 (2009) 227235. [99] C.T. Kuah, K.Y. Wong, F. Behrouzi, A review on data envelopment analysis (DEA), IEEE, pp. 168-173. [100] A. Hatami-Marbini, S. Saati, M. Tavana, An ideal-seeking fuzzy data envelopment analysis framework, Applied Soft Computing, 10 (2010) 1062-1070. [101] A. Hatami-Marbini, S. Saati, A. Makui, Ideal and anti-ideal decision making units: A fuzzy DEA approach, Journal of Industrial Engineering International, 6 (2010) 31-41. [102] S.-T. Liu, Fuzzy efficiency ranking in fuzzy two-stage data envelopment analysis, Optimization Letters, 8 (2014) 633-652. [103] M. Wen, C. You, R. Kang, A new ranking method to fuzzy data envelopment analysis, Computers and Mathematics with Applications, 59 (2010) 3398-3404. [104] E.E. Karsak, A two-phase robot selection procedure, Production Planning & Control, 9 (1998) 675-684. [105] P.J. Agrell, J. Tind, A dual approach to nonconvex frontier models, Journal of Productivity Analysis, 16 (2001) 129-147. [106] T.R. Anderson, K. Hollingsworth, L. Inman, The fixed weighting nature of a crossevaluation model, Journal of Productivity Analysis, 17 (2002) 249-255. [107] J. Zhu, Robustness of the efficient DMUs in data envelopment analysis, European Journal of Operational Research, 90 (1996) 451-460. [108] C. Lovell, A. Rouse, Equivalent standard DEA models to provide super-efficiency scores, Journal of the Operational Research Society, 54 (2003) 101-108.

160

[109] Y. Chen, Measuring super-efficiency in DEA in the presence of infeasibility, European Journal of Operational Research, 161 (2005) 545-551. [110] H.-S. Lee, C.-W. Chu, J. Zhu, Super-efficiency DEA in the presence of infeasibility, European Journal of Operational Research, 212 (2011) 141-147. [111] H.-S. Lee, J. Zhu, Super-efficiency infeasibility and zero data in DEA, European Journal of Operational Research, 216 (2012) 429-433. [112] A. Hatami-Marbini, S. Saati, M. Tavana, Data envelopment analysis with fuzzy parameters: An interactive approach, Optimizing, Innovating, and Capitalizing on Information Systems for Operations, (2013) 94-108. [113] R. Färe, S. Grosskopf, Intertemporal production frontiers, Boston: Kluwer Academic Publishers, 1996. [114] S. Grosskopf, The role of the reference technology in measuring productive efficiency, The Economic Journal, (1986) 499-513. [115] D. Deprins, L. Simar, H. Tulkens, Measuring labor efficiency in post offices, in: M. Marchand, P. Pestieau, H. Tulkens (Eds.) The performance of public enterprises: Concepts and measurements, North-Holland, Amsterdam, Netherlands, 1984, pp. 243­267. [116] H. Tulkens, On FDH efficiency analysis: Some methodological issues and applications to retail banking, courts, and urban transit, Journal of Productivity Analysis, 4 (1993) 183-210. [117] H. Tulkens, P.V. Eeckaut, Nonparametric efficiency, progress and regress measures for panel data: Methodological aspects, Springer, New York, NY, 2006. [118] T. Van Puyenbroeck, Some remarks on modified FDH, Journal of Productivity Analysis, 9 (1998) 81-94.

161

[119] Y. Yamada, T. Matsui, M. Sugiyama, An inefficiency measurement method for management-systems, Journal of the Operations Research Society of Japan, 37 (1994) 158168. [120] J.R. Doyle, R.H. Green, W.D. Cook, Upper and lower bound evaluation of multiattribute objects: Comparison models using linear programming, Organizational Behavior and Human Decision Processes, 64 (1995) 261-273. [121] T. Entani, H. Tanaka, Improvement of efficiency intervals based on DEA by adjusting inputs and outputs, European Journal of Operational Research, 172 (2006) 1004-1017. [122] A. Hatami-Marbini, M. Tavana, K. Gholami, Z.G. Beigi, A bounded data envelopment analysis model in a fuzzy environment with an application to safety in the semiconductor industry, Journal of Optimization Theory and Applications, 164 (2015) 679-701. [123] N.-S. Wang, W. Wang, R.-H. Yi, Evaluating the performances of decision-making units based on interval efficiencies, Journal of Computational and Applied Mathematics, 216 (2008) 328-343. [124] D. Wu, A note on DEA efficiency assessment using ideal point: An improvement of Wang and Luo's model, Applied Mathematics and Computation, 183 (2006) 819. [125] J.-X. Chen, A comment on DEA efficiency assessment using ideal and anti-ideal decision making units, Applied Mathematics and Computation, 219 (2012) 583. [126] H. Azizi, DEA efficiency analysis: A DEA approach with double frontiers, International Journal of Systems Science, 45 (2014) 2289-2300. [127] H. Azizi, R. Jahed, Improved data envelopment analysis models for evaluating interval efficiencies of decision-making units, Computers & Industrial Engineering, 61 (2011) 897901.

162

[128] H. Azizi, S.F. Ajirlu, Measurement of overall performances of decision-making units using ideal and anti-ideal decision-making units, Computers & Industrial Engineering, 59 (2010) 411-418. [129] J.-X. Chen, Overall performance evaluation: New bounded DEA models against unreachability of efficiency, Journal of the Operational Research Society, 65 (2014) 1120. [130] G.R. Jahanshahloo, F. Hosseinzadeh Lotfi, V. Rezaie, M. Khanmohammadi, Ranking DMUs by ideal points with interval data in DEA, Applied Mathematical Modelling, 35 (2011) 218229. [131] H. Azizi, A. Bahari, R. Jahed, Measuring the overall performances of decision-making units in the presence of imprecise data, Journal of Optimization in Industrial Engineering, 5 (2012) 63-72. [132] R. Jahed, A. Amirteimoori, H. Azizi, Performance measurement of decision-making units under uncertainty conditions: An approach based on double frontier analysis, Measurement, 69 (2015) 264-279. [133] A. Amirteimoori, DEA efficiency analysis: Efficient and anti-efficient frontier, Applied Mathematics and Computation, 186 (2007) 10-16. [134] Y.-M. Wang, K.-S. Chin, Y. Luo, Cross-efficiency evaluation based on ideal and anti-ideal decision making units, Expert Systems with Applications, 38 (2011) 10312-10319. [135] J. Sun, J. Wu, D. Guo, Performance ranking of units considering ideal and anti-ideal DMU with common weights, Applied Mathematical Modelling, 37 (2013) 6301. [136] A. Hatami-Marbini, S. Saati, M. Tavana, An ideal-seeking fuzzy data envelopment analysis framework, Applied Soft Computing Journal, 10 (2010) 1062-1070.

163

[137] H. Azizi, S. Kordrostami, A. Amirteimoori, Slacks-based measures of efficiency in imprecise data envelopment analysis: An approach based on data envelopment analysis with double frontiers, Computers & Industrial Engineering, 79 (2015) 42-51. [138] J.C. Paradi, M. Asmild, P.C. Simak, Using DEA and worst practice DEA in credit risk evaluation, Journal of Productivity Analysis, 21 (2004) 153-165. [139] A.L. Johnson, L.F. McGinnis, Outlier detection in two-stage semiparametric DEA models, European Journal of Operational Research, 187 (2008) 629-635. [140] I.M. Horta, A.S. Camanho, A nonparametric methodology for evaluating convergence in a multi-input multi-output setting, European Journal of Operational Research, 246 (2015) 554561. [141] L. Cherchye, T. Kuosmanen, T. Post, FDH directional distance functions with an application to European commercial banks, Journal of Productivity Analysis, 15 (2001) 201-215. [142] P.J. Agrell, J. Tind, A dual approach to nonconvex frontier models, Journal of Productivity Analysis, 16 (2001) 129-147. [143] M.J. Farrell, The convexity assumption in the theory of competitive markets, The Journal of Political Economy, 67 (1959) 377-391. [144] T. Kuosmanen, DEA with efficiency classification preserving conditional convexity, European Journal of Operational Research, 132 (2001) 326-342.  re, S. Grosskopf, C.A.K. Lovell, Production Frontiers, Cambridge University Press, [145] R. Fa Cambridge, England, 1994. [146] R.G. Chambers, Y. Chung, R. Färe, Profit, directional distance functions, and Nerlovian efficiency, Journal of Optimization Theory and Applications, 98 (1998) 351-364.

164

[147] R.G. Chambers, R. Färe, S. Grosskopf, Productivity growth in APEC countries, Pacific Economic Review, 1 (1996) 181-190. [148] R.W. Shepard, Theory of cost and production functions, Princeton University Press, Princeton, NY, 1970. [149] R.D. Banker, R.M. Thrall, Estimation of returns to scale using data envelopment analysis, European Journal of Operational Research, 62 (1992) 74-84. [150] P. Bogetoft, DEA on relaxed convexity assumptions, Management Science, 42 (1996) 457465. [151] D. Deprins, L. Simar, H. Tulkens, Measuring labor-efficiency in post offices, in: P. Chander, J. Drèze, C.K. Lovell, J. Mintz (Eds.) Public goods, environmental externalities and fiscal competition, Springer Science+Business Media, Boston, MA, 2006, pp. 285-309. [152] V.V Podinovski, and T. Bouzdine-Chameeva. "Solving DEA models in a single optimization stage: Can the non-Archimedean infinitesimal be replaced by a small finite epsilon?." European Journal of Operational Research 257.2 (2017): 412-419. [153] J. Pourmahmoud, A. Hatami-Marbini, E. Babazadeh, A comment on a new super-efficiency model in the presence of negative data, Journal of the Operational Research Society, (2015) doi: 10.1057/jors.2015.1045. [154] L.H. Caklovi, Tihomir, Measurement of DMU-efficiency by modified cross efficiency approach, Mathematical Communications, 17 (2012) (1331-0623). [155] H. Tulkens, On FDH efficiency analysis: Some methodological issues and applications to retail banking, courts, and urban transit, Journal of Productivity Analysis, 4 (1993) 183-210. [156] T. Sueyoshi, DEA non-parametric ranking test and index measurement: Slack-adjusted DEA and an application to Japanese agriculture cooperatives, Omega, 27 (1999) 315-326.

165

[157] Y.M. Wang, K.S. Chin, J.B. Yang, Measuring the performances of decision-making units using geometric average efficiency, Journal of the Operational Research Society, 58 (2006) 929-937. [158] M.G. Kendall, A new measure of rank correlation, Biometrika, 30 (1938) 81-93. [159] V.L. Arnold, I.R. Bardhan, W.W. Cooper, S.C. Kumbhakar, New uses of DEA and statistical regressions for efficiency evaluation and estimation ­ with an illustrative application to public secondary schools in Texas, Annals of Operations Research, 66 (1996) 255-277. [160] J.S. Liu, LYY Lu, W-M Lu, JY Lin, A survey of DEA applications, Omega 41, no. 5 (2013) 893-902. [161] A.M. Aldamak, S. Zolfaghari, Review of efficiency ranking methods in data envelopment analysis, Measurement (2017). [162] A.M. Aldamak, S. Zolfaghari, A two-stage prediction model for DEA efficiency scores. Data Envelopment Analysis and its Applications (2016, Feb). (Conference proceeding citation: Emrouznejad, A., R. Banker, H. Ahn and M. Afsharian (2016), Data Envelopment Analysis and its Applications: Proceedings of the 13th International Conference of DEA, August 2015, Braunschweig, Germany, DOI:

10.13140/RG.2.1.4082.9202/1, ISBN: 978 1 85449 497 9).

166

